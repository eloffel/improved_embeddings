   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]machine learning for humans
   [7]machine learning for humans
   [8]sign in[9]get started
     __________________________________________________________________

machine learning for humans, part 4: neural networks & deep learning

where, why, and how deep neural networks work. drawing inspiration from the
brain. convolutional neural networks (id98s) and recurrent neural networks
(id56s). real-world applications.

   [10]go to the profile of vishal maini
   [11]vishal maini (button) blockedunblock (button) followfollowing
   aug 19, 2017
this series is available as a full-length e-book! [12]download here. free for do
wnload, contributions appreciated ([13]paypal.me/ml4h)

   with deep learning, we   re still learning a function f to map input x to
   output y with minimal loss on the test data, just as we   ve been doing
   all along. recall our initial    problem statement    from [14]part 2.1 on
   supervised learning:
y = f(x) +   
training: machine learns f from labeled training data
testing: machine predicts y from unlabeled testing data

   the real world is messy, so sometimes f is complicated. in natural
   language problems large vocabulary sizes mean lots of features. vision
   problems involve lots of visual information about pixels. playing games
   requires making a decision based on complex scenarios with many
   possible futures. the learning techniques we   ve covered so far do well
   when the data we   re working with is not insanely complex, but it   s not
   clear how they   d generalize to scenarios like these.

   deep learning is really good at learning f, particularly in situations
   where the data is complex. in fact, id158s are
   known as universal function approximators because they   re able to
   [15]learn any function, no matter how wiggly, with just a single hidden
   layer.

   let   s look at the problem of image classification. we take an image as
   an input, and output a class (e.g., dog, cat, car).

   graphically, a deep neural network solving image classification looks
   something like this:
   [1*v-cd3i3sa1uztkqliinimq.png]
   image from jeff clune   s 1-hour [16]deep learning overview on youtube

   but really, this is a giant mathematical equation with millions of
   terms and lots of parameters. the input x is, say, a greyscale image
   represented by a w-by-h matrix of pixel brightnesses. the output y is a
   vector of class probabilities. this means we have as an output the
   id203 of each class being the correct label. if this neural net
   is working well, the highest id203 should be for the correct
   class. and the layers in the middle are just doing a bunch of matrix
   multiplication by summing activations x weights with non-linear
   transformations (id180) after every hidden layer to
   enable the network to learn a non-linear function.

   incredibly, you can use id119 in the exact same way that we
   did with id75 in [17]part 2.1 to train these parameters in
   a way that minimizes loss. so with a lot of examples and a lot of
   id119, the model can learn how to classify images of animals
   correctly. and that, in a nutshell   s nutshell, is    deep learning   .

where deep learning does well, and some history

   id158s have actually been around for a long time.
   their application has been historically referred to as cybernetics
   (1940s-1960s), connectionism (1980s-1990s), and then came into vogue as
   deep learning circa 2006 when neural networks started getting, well,
      deeper    ([18]goodfellow et al., 2016). but only recently have we
   really started to scratch the surface of their full potential.

   as described by andrej karpathy (director of ai at tesla, whom we tend
   to think of as the shaman of deep learning), there are generally    four
   separate factors that hold back ai:
    1. compute (the obvious one: moore   s law, gpus, asics),
    2. data (in a nice form, not just out there somewhere on the
       internet         e.g. id163),
    3. algorithms (research and ideas, e.g. backprop, id98, lstm), and
    4. infrastructure (software under you         linux, tcp/ip, git, ros, pr2,
       aws, amt, tensorflow, etc.)    ([19]karpathy, 2016).

   in the past decade or so, the full potential of deep learning is
   finally being unlocked by advances in (1) and (2), which in turn has
   led to further breakthroughs in (3) and (4)         and so the cycle
   continues, with exponentially more humans rallying to the frontlines of
   deep learning research along the way (just think about what you   re
   doing right now!)
   [1*jf1ncbvadh7fp0-qzp4xia.png]
   illustration by [20]nvidia, a leading maker of graphics processing
   units (gpus) which were originally built for for gaming but turned out
   to be well-suited to the type of [21]parallel computing required by
   deep neural networks

   in the rest of this section, we   ll provide some background from biology
   and statistics to explain what happens inside neural nets, and then
   talk through some amazing applications of deep learning. finally, we   ll
   link to a few resources so you can apply deep learning yourself, even
   sitting on the couch in your pajamas with a laptop, to quickly achieve
   greater-than-human-level performance on certain types of problems.

drawing inspiration from the brain (or is it just statistics?)         what happens
inside neural nets

neurons, id171, and layers of abstraction

   as you read these words you aren   t examining every letter of every
   word, or every pixel making up each letter, to derive the meaning of
   the words. you   re abstracting away from the details and grouping things
   into higher-level concepts: words, phrases, sentences, paragraphs.
yuor abiilty to exaimne hgiher-lveel fteaures is waht aollws yuo to unedrtsand w
aht is hpapening in tihs snetecne wthiout too mcuh troulbe (or myabe yuo sned to
o mnay dnruk txets).

   the same thing happens in vision, not just in humans but in animals   
   visual systems generally.

   brains are made up of neurons which    fire    by emitting electrical
   signals to other neurons after being sufficiently    activated   . these
   neurons are malleable in terms of how much a signal from other neurons
   will add to the activation level of the neuron (vaguely speaking, the
   weights connecting neurons to each other end up being trained to make
   the neural connections more useful, just like the parameters in a
   id75 can be trained to improve the mapping from input to
   output).
   [1*0uxck0boepvaeidzeqehzq.png]
   side-by-side illustrations of biological and artificial neurons, via
   [22]stanford   s cs231n. this analogy can   t be taken too
   literally         biological neurons can do things that artificial neurons
   can   t, and vice versa         but it   s useful to understand the biological
   inspiration. see wikipedia   s description of [23]biological vs.
   artificial neurons for more detail.

   our biological networks are arranged in a hierarchical manner, so that
   certain neurons end up detecting not extremely specific features of the
   world around us, but rather more abstract features, i.e. patterns or
   groupings of more low-level features. for example, the [24]fusiform
   face area in the human visual system is specialized for facial
   recognition.
   [1*thi4ew1o74eian8fx98ozw.png]
   [1*0a1b64c8s7fi7xmm4tcgfw.png]
   top: illustration of learning increasingly abstract features, via
   [25]nvidia. bottom: diagram of how an id158 takes
   raw pixel inputs, develops intermediate    neurons    to detect
   higher-level features (e.g. presence of a nose), and combines the
   outputs of these to create a final output. illustration from neural
   networks and deep learning ([26]nielsen, 2017).

   this hierarchical structure exhibited by biological neural networks was
   discovered in the 1950s when researchers david hubel and torsten wiesel
   were studying neurons in the visual cortex of cats. they were unable to
   observe neural activation after exposing the cat to a variety of
   stimuli: dark spots, light spots, hand-waving, and even pictures of
   women in magazines. but in their frustration, as they removed a slide
   from the projector at a diagonal angle, they noticed some neural
   activity! it turned out that diagonal edges at a very particular angle
   were causing certain neurons to be activated.

   iframe: [27]/media/a9eddb961e4bc9ca2d118b64525c2659?postid=cdad8aeae49b

   background via [28]knowing neurons

   this makes sense evolutionarily since natural environments are
   generally noisy and random (imagine a grassy plain or a rocky terrain).
   so when a feline in the wild perceives an    edge   , i.e. a line that
   contrasts from its background, this might indicate that an object or
   creature is in the visual field. when a certain combination of edge
   neurons are activated, those activations will combine to yield a yet
   more abstract activation, and so on, until the final abstraction is a
   useful concept, like    bird    or    wolf   .

   the idea behind a deep neural network is to mimic a similar structure
   with layers of artificial neurons.

why linear models don   t work

   to draw from stanford   s excellent deep learning course, [29]cs231n:
   convolutional neural networks and visual recognition, imagine that we
   want to train a neural network to classify images with the correct one
   of the following labels: ["plane", "car", "bird", "cat", "deer", "dog",
   "frog", "horse", "ship", "truck"].

   one approach could be to construct a    template   , or average image, of
   each class of image using the training examples, and then use a
   nearest-neighbors algorithm during testing to measure the distance of
   each unclassified image   s pixel values, in aggregate, to each template.
   this approach involves no layers of abstraction. it   s a linear model
   that combines all the different orientations of each type of image into
   one averaged blur.

   for instance, it would take all the cars         regardless of whether
   they   re facing left, right, center, and regardless of their color         and
   average them. the template then ends up looking rather vague and
   blurry.
   [1*6o4fahe9ehj_en5hykkjsa.png]
   example drawn from stanford   s [30]cs231n: convolutional neural networks
   and visual recognition, lecture 2.

   notice that the horse template above appears to have two heads. this
   doesn   t really help us: we want to be able to detect right-facing horse
   or a left-facing horse separately, and then if either one of those
   features is detected, then we want to say we   re looking at a horse.
   this flexibility is provided by deep neural nets, as we will see in the
   next section.

   deep neural networks approach the image classification problem using
   layers of abstraction

   to repeat what we explained earlier in this section: the input layer
   will take raw pixel brightnesses of an image. the final layer will be
   an output vector of class probabilities (i.e. the id203 of the
   image being a    cat   ,    car   ,    horse   , etc.)

   but instead of learning a simple linear model relating input to output,
   we   ll instead construct intermediate hidden layers of the network will
   learn increasingly abstract features, which enables us to not lose all
   the nuance in the complex data.
   [1*jyjubgdk41afi41dt4fy0q.png]
   source: [31]analytics vidhya

   just as we described animal brains detecting abstract features, the
   artificial neurons in the hidden layers will learn to detect abstract
   concepts         whichever concepts are ultimately most useful for capturing
   the most information and minimizing loss in the accuracy of the
   network   s output (this is an instance of unsupervised learning
   happening within the network).

   this comes at the cost of model interpretability, since as you add in
   more hidden layers the neurons start representing more and more
   abstract and ultimately unintelligible features         to the point that you
   may hear deep learning referred to as    black box optimization   , where
   you basically are just trying stuff somewhat at random and seeing what
   comes out, without really understanding what   s happening inside.

   id75 is interpretable because you decided which features
   to include in the model. deep neural networks are harder to interpret
   because the features are learned and aren   t explained anywhere in
   english. it   s all in the machine   s imagination.

some extensions and further concepts worth noting

     * deep learning software packages. you   ll rarely need to implement
       all the parts of neural networks from scratch because of existing
       libraries and tools that make deep learning implementations easier.
       there are many of these: tensorflow, caffe, torch, theano, and
       more.
     * convolutional neural networks (id98s). id98s are designed
       specifically for taking images as input, and are effective for
       id161 tasks. they are also instrumental in deep
       id23. id98s are specifically inspired by the way
       animal visual cortices work, and they   re the focus of the deep
       learning course we   ve been referencing throughout this article,
       stanford   s cs231n.
     * recurrent neural networks (id56s). id56s have a sense of built-in
       memory and are well-suited for language problems. they   re also
       important in id23 since they enable the agent to
       keep track of where things are and what happened historically even
       when those elements aren   t all visible at once. christopher olah
       wrote an [32]excellent walkthrough of id56s and lstms in the context
       of language problems.
     * deep id23. this is one of the most exciting areas
       of deep learning research, at the heart of recent achievements like
       openai defeating professional dota 2 players and deepmind   s alphago
       surpassing humans in the game of go. we   ll dive deeper in [33]part
       5, but essentially the goal is to apply all of the techniques in
       this post to the problem of teaching an agent to maximize reward.
       this can be applied in any context that can be gamified         from
       actual games like counter strike or pacman, to self-driving cars,
       to trading stocks, to (ultimately) real life and the real world.

deep learning applications

   deep learning is reshaping the world in virtually every domain. here
   are a few examples of the incredible things that deep learning can do   
     * facebook trained a neural network augmented by short-term memory to
       intelligently answer questions about the plot of lord of the rings.

   [1*qrt9wiik5jmx7jubqes7ra.png]
   research from [34]fair (facebook ai research) applying deep neural
   networks augmented by separate short-term memory to intelligently
   answer questions about the lotr storyline. this is the definition
   of epic.
     * self-driving cars rely on deep learning for visual tasks like
       understanding road signs, detecting lanes, and recognizing
       obstacles.

   [1*tjylgt3r40f3qqoribqgnw.jpeg]
   source: [35]business insider
     * deep learning can be used for fun stuff like art generation. a tool
       called [36]neural style can impressively mimic an artist   s style
       and use it to remix another image.

   [1*wymejyuifz0ugsgcmxn0qq.png]
   the style of van gogh   s [37]starry night applied to a picture of
   stanford   s campus, via justin johnson   s neural style implementation:
   [38]https://github.com/jcjohnson/neural-style

   other noteworthy examples include:
     * predicting molecule bioactivity for [39]drug discovery
     * face and object recognition for photo and video tagging
     * powering google search results
     * natural language understanding and generation, e.g. [40]google
       translate
     * the mars explorer robot curiosity is [41]autonomously selecting
       inspection-worthy soil targets based on visual examination

      and many, many, more.

now go do it!

   we haven   t gone into as much detail here on how neural networks are set
   up in practice because it   s much easier to understand the details by
   implementing them yourself. here are some amazing hands-on resources
   for getting started.
     * play around with the architecture of neural networks to see how
       different configurations affect network performance with the
       google   s [42]neural network playground.
     * get up-and-running quickly with this tutorial by google:
       [43]tensorflow and deep learning, without a phd. classify
       handwritten digits at >99% accuracy, get familiar with tensorflow,
       and learn deep learning concepts within 3 hours.
     * then, work through at least the first few lectures of
       [44]stanford   s cs231n and the first assignment of building a
       two-layer neural network from scratch to really solidify the
       concepts covered in this article.

further resources

   deep learning is an expansive subject area. accordingly, we   ve also
   compiled some of the best resources we   ve encountered on the topic, in
   case you   d like to go    deeper.
     * [45]deeplearning.ai, andrew ng   s new deep learning course with a
       comprehensive syllabus on the subject
     * [46]cs231n: convolutional neural networks for visual recognition,
       stanford   s deep learning course. one of the best treatments we   ve
       seen, with excellent lectures and illustrative problem sets
     * [47]deep learning & neural networks         accessible but rigorous
     * [48]deep learning book         foundational, more mathematical
     * [49]fast.ai         less theoretical, much more applied and black-boxy
     * see greg brockman (cto of openai)   s answer to the question    what
       are the best ways to pick up deep learning skills as an engineer?   
       [50]on quora

next up: time to play some games!

   last, but most certainly not least, is [51]part 5: reinforcement
   learning.
     __________________________________________________________________

enter your email below if you   d like to stay up-to-date with future content
         

   iframe: [52]/media/ba3502c3c2cc3159fdd3bda87c87164c?postid=cdad8aeae49b

on twitter? so are we. feel free to keep in touch         [53]vishal and
[54]samer         
     __________________________________________________________________

   more from machine learning for humans         
     * [55]part 1: why machine learning matters    
     * [56]part 2.1: supervised learning    
     * [57]part 2.2: supervised learning ii    
     * [58]part 2.3: supervised learning iii    
     * [59]part 3: unsupervised learning    
     * part 4: neural networks & deep learning    
     * [60]part 5: id23
     * [61]appendix: the best machine learning resources

   thanks to [62]sachin maini.
     * [63]machine learning
     * [64]artificial intelligence
     * [65]deep learning
     * [66]neural networks
     * [67]tech

   (button)
   (button)
   (button) 2.7k claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   [68]go to the profile of vishal maini

[69]vishal maini

   strategy & communications [70]@deepmindai. previously [71]@upstart,
   [72]@yale, [73]@trueventurestec.

     (button) follow
   [74]machine learning for humans

[75]machine learning for humans

   demystifying artificial intelligence & machine learning. discussions on
   safe and intentional application of ai for positive social impact.

     * (button)
       (button) 2.7k
     * (button)
     *
     *

   [76]machine learning for humans
   never miss a story from machine learning for humans, when you sign up
   for medium. [77]learn more
   never miss a story from machine learning for humans
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/cdad8aeae49b
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/machine-learning-for-humans?source=avatar-lo_h48jrpihmwjz-e8dd9a6c82a5
   7. https://medium.com/machine-learning-for-humans?source=logo-lo_h48jrpihmwjz---e8dd9a6c82a5
   8. https://medium.com/m/signin?redirect=https://medium.com/machine-learning-for-humans/neural-networks-deep-learning-cdad8aeae49b&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/machine-learning-for-humans/neural-networks-deep-learning-cdad8aeae49b&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@v_maini?source=post_header_lockup
  11. https://medium.com/@v_maini
  12. https://www.dropbox.com/s/e38nil1dnl7481q/machine_learning.pdf?dl=0
  13. http://paypal.me/ml4h
  14. https://medium.com/@v_maini/supervised-learning-740383a2feab
  15. http://neuralnetworksanddeeplearning.com/chap4.html
  16. https://www.youtube.com/watch?v=3lp9en5je2a&t=1631s
  17. https://medium.com/@v_maini/supervised-learning-740383a2feab
  18. http://www.deeplearningbook.org/contents/intro.html
  19. http://karpathy.github.io/2016/05/31/rl/
  20. https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/
  21. http://www.nvidia.com/object/what-is-gpu-computing.html
  22. http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf
  23. https://en.wikipedia.org/wiki/artificial_neuron#biological_models
  24. https://en.wikipedia.org/wiki/fusiform_face_area
  25. https://www.slideshare.net/nvidia/gpuaccelerated-deep-learning-for-cudnn-v2
  26. http://neuralnetworksanddeeplearning.com/chap1.html
  27. https://medium.com/media/a9eddb961e4bc9ca2d118b64525c2659?postid=cdad8aeae49b
  28. http://knowingneurons.com/2014/10/29/hubel-and-wiesel-the-neural-basis-of-visual-perception/
  29. http://cs231n.stanford.edu/syllabus.html
  30. http://cs231n.stanford.edu/syllabus.html
  31. https://www.analyticsvidhya.com/blog/2017/04/comparison-between-deep-learning-machine-learning/
  32. http://colah.github.io/posts/2015-08-understanding-lstms/
  33. https://medium.com/@v_maini/machine-learning-for-humans-part-5-reinforcement-learning-6eacf258b265
  34. https://www.facebook.com/fbairesearch/posts/362517620591864
  35. http://www.businessinsider.com/uber-driverless-car-in-pittsburgh-review-photos-2016-9/#to-try-the-cars-we-lined-up-at-ubers-advanced-technologies-center-in-the-strip-district-of-pittsburgh-a-small-neighborhood-on-the-allegheny-river-with-nearby-warehouses-the-atc-is-tucked-under-an-overpass-for-a-freight-train-keeping-it-secluded-1
  36. https://github.com/jcjohnson/neural-style
  37. https://en.wikipedia.org/wiki/the_starry_night
  38. https://github.com/jcjohnson/neural-style
  39. https://arxiv.org/abs/1510.02855
  40. https://translate.google.com/
  41. https://www.theatlantic.com/technology/archive/2017/06/mars-curiosity-rover/531339/
  42. http://playground.tensorflow.org/#activation=tanh&batchsize=10&dataset=circle&regdataset=reg-plane&learningrate=0.03&id173rate=0&noise=0&networkshape=4,2&seed=0.70277&showtestdata=false&discretize=false&perctraindata=50&x=true&y=true&xtimesy=false&xsquared=false&ysquared=false&cosx=false&sinx=false&cosy=false&siny=false&collectstats=false&problem=classification&initzero=false&hidetext=false
  43. https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/
  44. http://cs231n.stanford.edu/syllabus.html
  45. http://deeplearning.ai/
  46. http://cs231n.stanford.edu/syllabus.html
  47. http://neuralnetworksanddeeplearning.com/chap1.html
  48. http://www.deeplearningbook.org/
  49. http://fast.ai/
  50. https://www.quora.com/what-are-the-best-ways-to-pick-up-deep-learning-skills-as-an-engineer/answer/greg-brockman?srid=2sq8
  51. https://medium.com/@v_maini/reinforcement-learning-6eacf258b265
  52. https://medium.com/media/ba3502c3c2cc3159fdd3bda87c87164c?postid=cdad8aeae49b
  53. https://twitter.com/v_maini
  54. https://twitter.com/seriousssam
  55. https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12
  56. https://medium.com/@v_maini/supervised-learning-740383a2feab
  57. https://medium.com/@v_maini/supervised-learning-2-5c1c23f3560d
  58. https://medium.com/@v_maini/supervised-learning-3-b1551b9c4930
  59. https://medium.com/@v_maini/unsupervised-learning-f45587588294
  60. https://medium.com/@v_maini/reinforcement-learning-6eacf258b265
  61. https://medium.com/@v_maini/how-to-learn-machine-learning-24d53bb64aa1
  62. https://medium.com/@sachinmaini?source=post_page
  63. https://medium.com/tag/machine-learning?source=post
  64. https://medium.com/tag/artificial-intelligence?source=post
  65. https://medium.com/tag/deep-learning?source=post
  66. https://medium.com/tag/neural-networks?source=post
  67. https://medium.com/tag/tech?source=post
  68. https://medium.com/@v_maini?source=footer_card
  69. https://medium.com/@v_maini
  70. http://twitter.com/deepmindai
  71. http://twitter.com/upstart
  72. http://twitter.com/yale
  73. http://twitter.com/trueventurestec
  74. https://medium.com/machine-learning-for-humans?source=footer_card
  75. https://medium.com/machine-learning-for-humans?source=footer_card
  76. https://medium.com/machine-learning-for-humans
  77. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  79. https://medium.com/p/cdad8aeae49b/share/twitter
  80. https://medium.com/p/cdad8aeae49b/share/facebook
  81. https://medium.com/p/cdad8aeae49b/share/twitter
  82. https://medium.com/p/cdad8aeae49b/share/facebook
