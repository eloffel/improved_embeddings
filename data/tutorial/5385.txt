   #[1]github [2]recent commits to asreader:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]7
     * [35]star [36]97
     * [37]fork [38]32

[39]rkadlec/[40]asreader

   [41]code [42]issues 8 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   this is an implementation of the attention sum reader model as
   presented in "text comprehension with the attention sum reader network"
   available at [47]http://arxiv.org/abs/1603.01547.
     * [48]4 commits
     * [49]1 branch
     * [50]0 releases
     * [51]fetching contributors
     * [52]view license

    1. [53]python 96.8%
    2. [54]shell 3.2%

   (button) python shell
   branch: master (button) new pull request
   [55]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/r
   [56]download zip

downloading...

   want to be notified of new releases in rkadlec/asreader?
   [57]sign in [58]sign up

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [61]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [62]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [63]permalink
   type         name         latest commit message commit time
        failed to load latest commit information.
        [64]asreader
        [65]data
        [66]license.txt
        [67]readme.md
        [68]prerequisites.sh

readme.md

attention sum reader

introduction

   this is a theano/blocks implementation of the attention sum reader
   model as presented in "text comprehension with the attention sum reader
   network" available at [69]http://arxiv.org/abs/1603.01547. we encourage
   you to familiarize yourself with the model by reading the above article
   prior to studying the particulars of this implementation.

quick start

   if you want to get started as fast as possible try this:
./prerequisites.sh
cd asreader
./quick-start-cbt-ne.sh

   if you do not have a gpu available, remove the device=gpu flag from
   quick-start-generic.sh. however note that training the text
   comprehension tasks on a cpu is likely to take a prohibitively long
   time.

   this should install the prerequisites, download the cbt dataset, train
   two models on the named-entity part of the data, form an ensemble and
   report the accuracies.

license

      copyright ibm corporation. 2016.

   this licensed material is licensed for academic, non-commercial use
   only . the licensee may use, copy, and modify the licensed materials in
   any form without payment to ibm for the sole purposes of evaluating and
   extending the licensed materials for non-commercial purposes. the above
   copyright notice and this permission notice shall be included in all
   copies or substantial portions of the licensed materials..

   notwithstanding anything to the contrary, ibm provides the licensed
   materials on an "as is" basis and ibm disclaims all warranties, express
   or implied, including, but not limited to, any implied warranties or
   conditions of merchantability, satisfactory quality, fitness for a
   particular purpose, title, and any warranty or condition of
   non-infringement. ibm shall not be liable for any direct, indirect,
   incidental, special, exemplary or economic consequential damages
   arising out of the use or operation of the licensed materials. ibm
   shall not be liable for loss of, or damage to, data, or for lost
   profits, business revenue, goodwill, or anticipated savings. ibm has no
   obligation to provide maintenance, support, updates, enhancements or
   modifications to the licensed materials.

detailed usage

installation

quick installation

   provided you have python with pip installed, running
prerequisites.sh

   should install blocks and dependencies for you. it also downloads the
   children's book test dataset and the id98 and daily mail news datasets.
   we are aware that the news data download sometimes crashes. rerunning
   the script prepare-rec-data.sh should be able to resume the download if
   that happens (alternatively you can download the datasets from
   [70]http://cs.nyu.edu/~kcho/dmqa/).

   however if you prefer to install the dependencies by yourself, some
   details are below:

dependencies:

    1. hdf5 (required for installing blocks) in the debian/ubuntu family
       of distributions, you should be able to install the library using
sudo apt-get install libhdf5-serial-dev

       otherwise installation instructions and source download can be
       found at [71]http://hdfgroup.org/hdf5/release/obtain5.html
    2. blocks and its dependencies installation instructions can be found
       at blocks.readthedocs.io/en/latest/setup.html. you should be able
       to install blocks including theano and other dependencies using pip
       by running
pip install git+http://github.com/mila-udem/blocks.git@359afad119f8c6ac0ebc3cc6e
c6e6475656babae -r https://raw.githubusercontent.com/mila-udem/blocks/master/req
uirements.txt --user


       it is important to use older version of blocks since the latest
       version isn   t backward compatible.
    3. nltk + punkt corpus this tokenizer that we use for reading the babi
       datasets can be installed using
pip install nltk --user
python -m nltk.downloader punkt

getting data

children book test

   children book test data should be already downloaded by the quick start
   script. if you skipped this script you can prepare the data by
   prepare-cbt-data.sh

id98 and daily mail

   the best way how to get the id98 and dailymail datasets is to download
   the questions and stories files from [72]http://cs.nyu.edu/~kcho/dmqa/.
   place them into folder $clone_dir/data and run a script
   $clone_dir/data/prepare-rc-data-downloaded.sh.

   alternatively you can use a script $clone_dir/data/prepare-rc-data.sh
   that downloads the data using the original scripts from
   [73]https://github.com/deepmind/rc-data. however, the news data
   download sometimes crashes. therefore it is often necessary to download
   missing articles by re-running generate_questions.py script.

   now when you have id98 and dailymail datasets you can use them to train
   the models:
cd asreader
./quick-start-id98.sh
./quick-start-dm.sh

training models

   the model can be trained by running the text-comprehension/as_reader.py
   script. the simplest usage is:
python text_comprehension/as_reader.py --dataset_root data/cbtest/data/ --train
train.txt --valid valid.txt --test test.txt

   where the .txt files are the appropriate datasets. some of the
   recommended configurations can be copied from the quick-start-cbt-ne.sh
   script

   you may need to prepend the following prefixes in front of the command
   and run it from the project root directory
theano_flags="floatx=float32,device=gpu" pythonpath="$pythonpath:./"

   some of the most useful command line arguments you may wish to use are
   the following
     * --dataset_type [cbt|id98|babi] - the type of dataset that is being
       used. defaults to the children's book test
     * -b 32 ... batch size - larger values usually speed up training
       however increase the memory usage
     * -sed 256 ... source embedding dimension
     * -ehd 256 ... the number of hidden units in each half of the
       bidirectional gru encoders
     * -lr 0.001 ... learning rate
     * --output_dir ... output directory for the validation and test
       prediction files
     * --patience_metric accuracy ... when this metric stops improving,
       training is eventually stopped
     * -p 1 ... the number of epochs for which training continues since
       achieving the best value of the patience metric
     * --own_eval ... runs a script that eb
     * --append_metaparams ... includes the metaparameters in the filename
       of the generated prediction files - useful when generating multiple
       models
     * --weighted_att ... instead of attention sum, use the weighted
       attention model to which we compare the asreader in the paper the
       full list of parameters with descriptions can be displayed by
       running the script with the -h flag.

ensembling

   as_reader.py can generate the predictions for the test and validation
   datasets into the output directory. by default the predictions are
   generated every epoch. the text_comprehension/eval/copybestpredictions
   directory can then be used to find the time at which model achieved the
   best validation accuracy and it copies the corresponding validation and
   test predictions to a separate folder. an example syntax is
python text_comprehension/eval/copybestpredictions.py -vp cbtest_ne_valid_2000ex
.txt. -tp cbtest_ne_test_2500ex.txt. -i out_dir -o out_dir/best_predictions

   where -vp and -tp give the prefixes of the validation and test
   predictions respectively. these are usually the validation and test
   dataset filenames.

   once the best_predictions directory contains only one test and one
   validation prediction for each model, we can fuse these using the
   text_comprehension/eval/fusion.py for instance using the following
   command:
python text_comprehension/eval/fusion.py -pr "out_dir/best_predictions/*.y_hat_v
alid" -o $out_dir/best_predictions/simple_fusion.y_hat -t foo --fusion_method av
erageall

   where -pr gives an expression for the validation predictions to be used
   and -o specifies the file to output.

   the script provides three methods of fusion toggled by the
   --fusion_method parameter:
     * averageall - the ensemble prediction is a mean of all the supplied
       single-model predictions
     * pbest - sorts the candidate models by validation accuracy and
       selects the best proportion p of models to form the ensemble
     * addimprover - sorts the candidate models by validation accuracy and
       then tries adding them to the ensemble in that order keeping each
       model in the ensemble only if it improves its val. accuracy

contributors

   rudolf kadlec, martin schmid, ondrej bajgar, tamir klinger, ladislav
   kunc, jan kleindienst

     *    2019 github, inc.
     * [74]terms
     * [75]privacy
     * [76]security
     * [77]status
     * [78]help

     * [79]contact github
     * [80]pricing
     * [81]api
     * [82]training
     * [83]blog
     * [84]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [85]reload to refresh your
   session. you signed out in another tab or window. [86]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/rkadlec/asreader/commits/master.atom
   3. https://github.com/rkadlec/asreader#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/rkadlec/asreader
  32. https://github.com/join
  33. https://github.com/login?return_to=/rkadlec/asreader
  34. https://github.com/rkadlec/asreader/watchers
  35. https://github.com/login?return_to=/rkadlec/asreader
  36. https://github.com/rkadlec/asreader/stargazers
  37. https://github.com/login?return_to=/rkadlec/asreader
  38. https://github.com/rkadlec/asreader/network/members
  39. https://github.com/rkadlec
  40. https://github.com/rkadlec/asreader
  41. https://github.com/rkadlec/asreader
  42. https://github.com/rkadlec/asreader/issues
  43. https://github.com/rkadlec/asreader/pulls
  44. https://github.com/rkadlec/asreader/projects
  45. https://github.com/rkadlec/asreader/pulse
  46. https://github.com/join?source=prompt-code
  47. http://arxiv.org/abs/1603.01547
  48. https://github.com/rkadlec/asreader/commits/master
  49. https://github.com/rkadlec/asreader/branches
  50. https://github.com/rkadlec/asreader/releases
  51. https://github.com/rkadlec/asreader/graphs/contributors
  52. https://github.com/rkadlec/asreader/blob/master/license.txt
  53. https://github.com/rkadlec/asreader/search?l=python
  54. https://github.com/rkadlec/asreader/search?l=shell
  55. https://github.com/rkadlec/asreader/find/master
  56. https://github.com/rkadlec/asreader/archive/master.zip
  57. https://github.com/login?return_to=https://github.com/rkadlec/asreader
  58. https://github.com/join?return_to=/rkadlec/asreader
  59. https://desktop.github.com/
  60. https://desktop.github.com/
  61. https://developer.apple.com/xcode/
  62. https://visualstudio.github.com/
  63. https://github.com/rkadlec/asreader/tree/291425c23e888bac19dcbd58bd4481e575a4d75f
  64. https://github.com/rkadlec/asreader/tree/master/asreader
  65. https://github.com/rkadlec/asreader/tree/master/data
  66. https://github.com/rkadlec/asreader/blob/master/license.txt
  67. https://github.com/rkadlec/asreader/blob/master/readme.md
  68. https://github.com/rkadlec/asreader/blob/master/prerequisites.sh
  69. http://arxiv.org/abs/1603.01547
  70. http://cs.nyu.edu/~kcho/dmqa/
  71. http://hdfgroup.org/hdf5/release/obtain5.html
  72. http://cs.nyu.edu/~kcho/dmqa/
  73. https://github.com/deepmind/rc-data
  74. https://github.com/site/terms
  75. https://github.com/site/privacy
  76. https://github.com/security
  77. https://githubstatus.com/
  78. https://help.github.com/
  79. https://github.com/contact
  80. https://github.com/pricing
  81. https://developer.github.com/
  82. https://training.github.com/
  83. https://github.blog/
  84. https://github.com/about
  85. https://github.com/rkadlec/asreader
  86. https://github.com/rkadlec/asreader

   hidden links:
  88. https://github.com/
  89. https://github.com/rkadlec/asreader
  90. https://github.com/rkadlec/asreader
  91. https://github.com/rkadlec/asreader
  92. https://help.github.com/articles/which-remote-url-should-i-use
  93. https://github.com/rkadlec/asreader#attention-sum-reader
  94. https://github.com/rkadlec/asreader#introduction
  95. https://github.com/rkadlec/asreader#quick-start
  96. https://github.com/rkadlec/asreader#license
  97. https://github.com/rkadlec/asreader#detailed-usage
  98. https://github.com/rkadlec/asreader#installation
  99. https://github.com/rkadlec/asreader#quick-installation
 100. https://github.com/rkadlec/asreader#dependencies
 101. https://github.com/rkadlec/asreader#getting-data
 102. https://github.com/rkadlec/asreader#children-book-test
 103. https://github.com/rkadlec/asreader#id98-and-daily-mail
 104. https://github.com/rkadlec/asreader#training-models
 105. https://github.com/rkadlec/asreader#ensembling
 106. https://github.com/rkadlec/asreader#contributors
 107. https://github.com/
