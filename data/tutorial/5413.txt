   #[1]deep ideas    feed [2]deep ideas    comments feed [3]deep ideas   
   deep learning from scratch v: multi-layer id88s comments feed
   [4]alternate [5]alternate

   [6]facebook[7]twitter[8]email[9]rss[10]linkedin[11]tumblr

   [12]deep ideas logo deep ideas retina logo

a blog on artificial intelligence, deep learning and cognitive science

     * [13]home
     * [14]list of articles
     * [15]about me
     * ____________________
          

   [16]previous [17]next

     * [18]view larger image

deep learning from scratch v: multi-layer id88s

   this is part 5 of a series of tutorials, in which we develop the
   mathematical and algorithmic underpinnings of deep neural networks from
   scratch and implement our own neural network library in python,
   mimicing the [19]tensorflow api. start with the first part: [20]i:
   computational graphs.
     * [21]part i: computational graphs
     * [22]part ii: id88s
     * [23]part iii: training criterion
     * [24]part iv: id119 and id26
     * [25]part v: multi-layer id88s
     * [26]part vi: tensorflow

multi-layer id88s

motivation

   many real-world classes that we encounter in machine learning are not
   linearly separable. this means that there does not exist any line with
   all the points of the first class on one side of the line and all the
   points of the other class on the other side. let   s illustrate this with
   an example.

   iframe:
   [27]https://tech.io/playground-widget/f3056ba234245d4d41c44310ee657eff7
   849/multi-layer-id88s/282357/example

   iframe:
   [28]https://tech.io/playground-widget/3ba0b9380fa5326b2ef084cc28b57ec57
   849/multi-layer-id88s/132330/example

   as we can see, it is impossible to draw a line that separates the blue
   points from the red points. instead, our decision boundary has to have
   a rather complex shape. this is where multi-layer id88s come into
   play: they allow us to train a decision boundary of a more complex
   shape than a straight line.

computational graph

   as their name suggests, multi-layer id88s (mlps) are composed of
   multiple id88s stacked one after the other in a layer-wise
   fashion. let   s look at a visualization of the computational graph:

   [mlp.png]

   as we can see, the input is fed into the first layer, which is a
   multidimensional id88 with a weight matrix $w_1$ and bias vector
   $b_1$. the output of that layer is then fed into second layer, which is
   again a id88 with another weight matrix $w_2$ and bias vector
   $b_2$. this process continues for every of the $l$ layers until we
   reach the output layer. we refer to the last layer as the output layer
   and to every other layer as a hidden layer.

   an mlp with one hidden layers computes the function

   $$\sigma(\sigma(x \, w_1 + b_1) w_2 + b_2) \,,$$

   an mlp with two hidden layers computes the function

   $$\sigma(\sigma(\sigma(x \, w_1 + b_1) w_2 + b_2) \, w_3 \,,$$

   and, generally, an mlp with $l-1$ hidden layers computes the function

   $$\sigma(\sigma( \cdots \sigma(\sigma(x \, w_1 + b_1) w_2 + b_2)
   \cdots) \, w_l + b_l) \,.$$

implementation

   using the library we have built, we can now easily implement
   multi-layer id88s without further work.

   iframe:
   [29]https://tech.io/playground-widget/3ba0b9380fa5326b2ef084cc28b57ec57
   849/multi-layer-id88s/132331/multi-layer%20id88

   as we can see, we have learned a rather complex decision boundary. if
   we use more layers, the decision boundary can become arbitrarily
   complex, allowing us to learn classification patterns that are
   impossible to spot by a human being, especially in higher dimensions.

recap

   congratulations on making it this far! you have learned the foundations
   of building neural networks from scratch, and in contrast to most
   machine learning practitioners, you now know how it all works under the
   hood and why it is done the way it is done.

   let   s recap what we have learned. we started out by considering
   computational graphs in general, and we saw how to build them and how
   to compute their output. we then moved on to describe id88s,
   which are linear classifiers that assign a id203 to each output
   class by squashing the output of $w^tx+b$ through a sigmoid (or
   softmax, in the case of multiple classes). following that, we saw how
   to judge how good a classifier is     via a id168, the
   cross-id178 loss, the minimization of which is equivalent to maximum
   likelihood. in the next step, we saw how to minimize the loss via
   id119: by iteratively stepping into the direction of the
   negative gradient. we then introduced id26 as a means of
   computing the derivative of the loss with respect to each node by
   performing a breadth-first search and multiplying according to the
   chain rule. we used all that we   ve learned to train a good linear
   classifier for the red/blue example dataset. finally, we learned about
   multi-layer id88s as a means of learning non-linear decision
   boundaries, implemented an mlp with one hidden layer and successfully
   trained it on a non-linearly-separable dataset.

next steps

   the upcoming sections will be focused on providing hands-on experience
   in neural network training. continue with the next part: [30]vi:
   tensorflow

share this:

     * [31]click to share on twitter (opens in new window)
     * [32]click to share on facebook (opens in new window)
     * [33]click to share on google+ (opens in new window)
     * [34]click to share on skype (opens in new window)
     * [35]click to share on linkedin (opens in new window)
     * [36]click to print (opens in new window)
     * [37]click to share on pocket (opens in new window)
     * [38]click to share on tumblr (opens in new window)
     * [39]click to share on reddit (opens in new window)
     * [40]click to share on telegram (opens in new window)
     * [41]click to share on pinterest (opens in new window)
     * [42]click to share on whatsapp (opens in new window)
     *

related

   by [43]daniel| 2018-05-07t14:06:22+00:00 august 26th,
   2017|[44]artificial intelligence, [45]deep learning, [46]machine
   learning, [47]python, [48]tensorflow|[49]3 comments

stay updated

   subscribe to the mailing list and get updated about new blog posts by
   email.
   ____________________
   [ ] i consent to my submitted data being collected via this form*
   sign up now

   thank you for subscribing.

   something went wrong.

   i respect your privacy and take protecting it seriously

follow me on twitter

   [50]my tweets

   copyright 2017 daniel sabinasz
   [51]facebook[52]twitter[53]email[54]rss[55]linkedin[56]tumblr

references

   visible links
   1. http://www.deepideas.net/feed/
   2. http://www.deepideas.net/comments/feed/
   3. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/feed/
   4. http://www.deepideas.net/wp-json/oembed/1.0/embed?url=http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/
   5. http://www.deepideas.net/wp-json/oembed/1.0/embed?url=http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/&format=xml
   6. http://fb.me/deepideas.net
   7. https://twitter.com/deepideas_net
   8. mailto:daniel@sabinasz.net
   9. http://www.deepideas.net/feed/
  10. https://www.linkedin.com/in/daniel-sabinasz-7b220b100/
  11. https://deepideas.tumblr.com/
  12. http://www.deepideas.net/
  13. http://www.deepideas.net/
  14. http://www.deepideas.net/list-of-articles/
  15. http://www.deepideas.net/about-me/
  16. http://www.deepideas.net/deep-learning-from-scratch-iv-gradient-descent-and-id26/
  17. http://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/
  18. https://i2.wp.com/www.deepideas.net/wp-content/uploads/2017/08/neuron.jpg?fit=900,300
  19. http://www.tensorflow.org/
  20. http://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/
  21. http://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/
  22. http://www.deepideas.net/deep-learning-from-scratch-ii-id88s/
  23. http://www.deepideas.net/deep-learning-from-scratch-iii-training-criterion/
  24. http://www.deepideas.net/deep-learning-from-scratch-iv-gradient-descent-and-id26/
  25. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/
  26. http://www.deepideas.net/deep-learning-from-scratch-vi-tensorflow/
  27. https://tech.io/playground-widget/f3056ba234245d4d41c44310ee657eff7849/multi-layer-id88s/282357/example
  28. https://tech.io/playground-widget/3ba0b9380fa5326b2ef084cc28b57ec57849/multi-layer-id88s/132330/example
  29. https://tech.io/playground-widget/3ba0b9380fa5326b2ef084cc28b57ec57849/multi-layer-id88s/132331/multi-layer id88
  30. http://www.deepideas.net/deep-learning-from-scratch-vi-tensorflow/
  31. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=twitter
  32. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=facebook
  33. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=google-plus-1
  34. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=skype
  35. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=linkedin
  36. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/#print
  37. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=pocket
  38. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=tumblr
  39. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=reddit
  40. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=telegram
  41. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/?share=pinterest
  42. https://api.whatsapp.com/send?text=deep learning from scratch v: multi-layer id88s http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/
  43. http://www.deepideas.net/author/daniel/
  44. http://www.deepideas.net/category/artificial-intelligence/
  45. http://www.deepideas.net/category/artificial-intelligence/machine-learning/deep-learning/
  46. http://www.deepideas.net/category/artificial-intelligence/machine-learning/
  47. http://www.deepideas.net/category/python/
  48. http://www.deepideas.net/category/artificial-intelligence/machine-learning/tensorflow/
  49. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/#comments
  50. https://twitter.com/deepideas_net
  51. http://fb.me/deepideas.net
  52. https://twitter.com/deepideas_net
  53. mailto:daniel@sabinasz.net
  54. http://www.deepideas.net/feed/
  55. https://www.linkedin.com/in/daniel-sabinasz-7b220b100/
  56. https://deepideas.tumblr.com/

   hidden links:
  58. http://www.deepideas.net/deep-learning-from-scratch-v-multi-layer-id88s/
  59. https://www.facebook.com/deepideas.net/
