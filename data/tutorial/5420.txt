   /
   [1]index
   [2]about
   /art
   [3]anycubic kossel       
   [4]make a ferenova
   /lit
   [5]why smart people have bad ideas
   /on_learning
   [6]compiling tensorflow
   [7]learning resources
   [8]fast dcgan in keras
   [9]gan                      
   [10]id119                
   [11]training of artists
   [12]baby steps for ml
   [13]residual network in keras
   /on_learning/audio
   [14]behind wavenet
   /on_learning/image
   [15]fast lsgan in canton
   [16]on style transfer             
   /on_learning/motor_model
   [17]learn models of motors
   /on_learning/npeg
   [18]npeg            
   /on_learning/activations
   [19]id180
   [20]rectified linear unit                   
   /on_learning/rl
   [21]bipedalwalker-v2
   [22]ddpg method
   [23]learning to run
   [24]music generation
   [25]rl is progressing rapidly
   [26]v-rep + gym = rl
   /on_learning/gru
   [27]gru and convolutional gru
   /on_life
   [28]            
   [29]                  
   [30]power system analysis
   [31]               
   [32]                     
   [33]                     
   [34]          no code
   [35]numjs
   [36]         

v-rep + openai gym = rl

   v-rep: the powerful, user friendly, and free-to-use robot simulation
   platform for researchers and hackers. supports basically everything.

   openai gym: the de facto standard interface for id23.

   so, how can we hook v-rep onto an gym environment, so that we could
   perform 3d robotic simulations step-by-step in python?

remote controlled v-rep

   v-rep provides a set of apis accessible from socket, with dynamic
   libraries and binding for python, lua and a bunch of languages.

   you will have to write some python code to:
    1. start a v-rep instance from python
    2. connect to the instance you've started
    3. load the scene file (the scene we are about to simulate)
    4. start the simulation
    5. step the simulation
    6. read/write something from/to v-rep to control the simulation and
       record data
    7. goto 5 several times
    8. stop the simulation
    9. (important) check to see if the simulation actually stopped.
   10. goto 4 several times
   11. kill the v-rep instance from python if no longer needed.

   which means a lot of code.

   good news: i wrote a library called vrepper, available at
   [37]https://github.com/ctmakro/vrepper, that could correctly handle the
   routine mentioned above. you should at least look at the code - which
   may save you a lot of precious time, that i've spent already.

   you may expand your own functionality. consult v-rep's remote api
   manual.

an example on the usage of vrepper

   here i made a 3d cart-pole environment in v-rep.

   it contains camera output rendered with opengl in v-rep, so that you
   could see how the simulation went with v-rep running in headless mode
   (mode without gui).

   video demonstration below:

   to run the example above, here's what you have to do:
# install v-rep 3.40 (latest version as the time of writing) for your operating
system. make sure the vrep executable is in your path variable.

$ pip install tensorflow numpy
$ pip install canton

$ pip install opencv-python # won't always work. just make sure you have opencv3
 installed, and you could "import cv2" in python.

$ git clone https://github.com/ctmakro/cv2tools # visualization utility
$ pip install -e ./cv2tools
$ git clone https://github.com/ctmakro/vrepper
$ pip install -e ./vrepper

$ git clone https://github.com/ctmakro/gymnastics
$ cd gymnastics

# then simply follow the video:
$ ipython -i test_cartpole.py

agent.load_weights() # load the neural network weights
test()


   happy learning!

   file: vrep.md

   last modified: 2017-05-13 18:32

references

   1. https://ctmakro.github.io/site/index.html
   2. https://ctmakro.github.io/site/bio.html
   3. https://ctmakro.github.io/site/art/anycubic_kossel.html
   4. https://ctmakro.github.io/site/art/ferenova.html
   5. https://ctmakro.github.io/site/lit/why_bad_idea.html
   6. https://ctmakro.github.io/site/on_learning/tf1c.html
   7. https://ctmakro.github.io/site/on_learning/course_resources.html
   8. https://ctmakro.github.io/site/on_learning/fast_gan_in_keras.html
   9. https://ctmakro.github.io/site/on_learning/gan.html
  10. https://ctmakro.github.io/site/on_learning/gd.html
  11. https://ctmakro.github.io/site/on_learning/artist.html
  12. https://ctmakro.github.io/site/on_learning/how_to.html
  13. https://ctmakro.github.io/site/on_learning/resnet_keras.html
  14. https://ctmakro.github.io/site/on_learning/audio/wavenet_arch.html
  15. https://ctmakro.github.io/site/on_learning/image/fast_lsgan.html
  16. https://ctmakro.github.io/site/on_learning/image/style_transfer.html
  17. https://ctmakro.github.io/site/on_learning/motor_model/motor.html
  18. https://ctmakro.github.io/site/on_learning/npeg/npeg.html
  19. https://ctmakro.github.io/site/on_learning/activations/index.html
  20. https://ctmakro.github.io/site/on_learning/activations/relu.html
  21. https://ctmakro.github.io/site/on_learning/rl/bipedal.html
  22. https://ctmakro.github.io/site/on_learning/rl/ddpg.html
  23. https://ctmakro.github.io/site/on_learning/rl/l2r.html
  24. https://ctmakro.github.io/site/on_learning/rl/musicgen.html
  25. https://ctmakro.github.io/site/on_learning/rl/rl.html
  26. https://ctmakro.github.io/site/on_learning/rl/vrep.html
  27. https://ctmakro.github.io/site/on_learning/gru/gru.html
  28. https://ctmakro.github.io/site/on_life/beijing.html
  29. https://ctmakro.github.io/site/on_life/cc.html
  30. https://ctmakro.github.io/site/on_life/electrical.html
  31. https://ctmakro.github.io/site/on_life/fanqiang.html
  32. https://ctmakro.github.io/site/on_life/gd10000.html
  33. https://ctmakro.github.io/site/on_life/lang.html
  34. https://ctmakro.github.io/site/on_life/nocode.html
  35. https://ctmakro.github.io/site/on_life/numjs.html
  36. https://ctmakro.github.io/site/on_life/reprod.html
  37. https://github.com/ctmakro/vrepper
