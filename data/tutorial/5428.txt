   #[1]rss

[2]fast.ai

   making neural nets uncool again

   [3]home [4]about [5]our mooc [6]posts by topic

      fast.ai 2019. all rights reserved.

introducing pytorch for fast.ai

   written: 08 sep 2017 by jeremy howard

   the next [7]fast.ai courses will be based nearly entirely on a new
   framework we have developed, built on [8]pytorch. pytorch is a
   different kind of deep learning library (dynamic, rather than static),
   which has been adopted by many (if not most) of the researchers that we
   most respect, and in [9]a recent kaggle competition was used by nearly
   all of the top 10 finishers.

   we have spent around a thousand hours this year working with pytorch to
   get to this point, and we are very excited about what it is allowing us
   to do. we will be writing a number of articles in the coming weeks
   talking about each aspect of this. first, we will start with a quick
   summary of the background to, and implications of, this decision.
   perhaps the best summary, however, is this snippet from the start of
   our first lesson:
   excerpt from lesson 1, showing 99.32% accuracy excerpt from lesson 1,
   showing 99.32% accuracy

fast.ai   s teaching goal

   our goal at fast.ai is for there to be nothing to teach. we believe
   that the fact that we currently require high school math, one year of
   coding experience, and seven weeks of study to become a world-class
   deep learning practitioner, is not an acceptable state of affairs (even
   although this is less prerequisites for any other course of a similar
   level). everybody should be able to use deep learning to solve their
   problems with no more education than it takes to use a smart phone.
   therefore, each year our main research goal is to be able to teach a
   wider range of deep learning applications, that run faster, and are
   more accurate, to people with less prerequisites.

   we want our students to be able to solve their most challenging and
   important problems, to transform their industries and organisations,
   which we believe is the potential of deep learning. we are not just
   trying to teach people how to get existing jobs in the field     but to
   go far beyond that.

   therefore, since we first ran our deep learning course, we have been
   constantly curating best practices, and benchmarking and developing
   many techniques, trialling them against kaggle leaderboards and
   academic state-of-the-art results.

why we tried pytorch

   as we developed our second course, [10]cutting-edge deep learning for
   coders, we started to hit the limits of the libraries we had chosen:
   [11]keras and [12]tensorflow. for example, perhaps the most important
   technique in natural language processing today is the use of
   [13]attentional models. we discovered that there was no effective
   implementation of attentional models for keras at the time, and the
   tensorflow implementations were not documented, rapidly changing, and
   unnecessarily complex. we ended up writing our own in keras, which
   turned out to take a long time, and be very hard to debug. we then
   turned our attention to implementing dynamic teacher forcing, for which
   we could find no implementation in either keras or tensorflow, but is a
   critical technique for accurate [14]neural translation models. again,
   we tried to write our own, but this time we just weren   t able to make
   anything work.

   at that point the first pre-release of pytorch had just been released.
   the promise of pytorch was that it was built as a dynamic, rather than
   static computation graph, framework (more on this in a later post).
   dynamic frameworks, it was claimed, would allow us to write regular
   python code, and use regular python debugging, to develop our neural
   network logic. the claims, it turned out, were totally accurate. we had
   implemented attentional models and dynamic teacher forcing from scratch
   in pytorch within a few hours of first using it.

some pytorch benefits for us and our students

   the focus of our second course is to allow students to be able to read
   and implement recent research papers. this is important because the
   range of deep learning applications studied so far has been extremely
   limited, in a few areas that the academic community happens to be
   interested in. therefore, solving many real-world problems with deep
   learning requires an understanding of the underlying techniques in
   depth, and the ability to implement customised versions of them
   appropriate for your particular problem, and data. because pytorch
   allowed us, and our students, to use all of the flexibility and
   capability of regular python code to build and train neural networks,
   we were able to tackle a much wider range of problems.

   an additional benefit of pytorch is that it allowed us to give our
   students a much more in-depth understanding of what was going on in
   each algorithm that we covered. with a static computation graph library
   like tensorflow, once you have declaratively expressed your
   computation, you send it off to the gpu where it gets handled like a
   black box. but with a dynamic approach, you can fully dive into every
   level of the computation, and see exactly what is going on. we believe
   that the best way to learn deep learning is through coding and
   experiments, so the dynamic approach is exactly what we need for our
   students.

   much to our surprise, we also found that many models trained quite a
   lot faster on pytorch than they had on tensorflow. this was quite
   against the prevailing wisdom, that said that static computation graphs
   should allow for more optimization to be done, which should have
   resulted in higher performance in tensorflow. in practice, we   re seeing
   some models are a bit faster, some a bit slower, and things change in
   this respect every month. the key issues seem to be that:
     * improved developer productivity and debugging experience in pytorch
       can lead to more rapid development iterations, and therefore better
       implementations
     * smaller, more focussed development community in pytorch looks for
          big wins    rather than investing in micro-optimization of every
       function.

why we built a new framework on top of pytorch

   unfortunately, pytorch was a long way from being a good option for part
   one of the course, which is designed to be accessible to people with no
   machine learning background. it did not have anything like the clear
   simple api of keras for training models. every project required dozens
   of lines of code just to implement the basics of training a neural
   network. unlike keras, where the defaults are thoughtfully chosen to be
   as useful as possible, pytorch required everything to be specified in
   detail. however, we also realised that keras could be even better. we
   noticed that we kept on making the same mistakes in keras, such as
   failing to shuffle our data when we needed to, or vice versa. also,
   many recent best practices were not being incorporated into keras,
   particularly in the rapidly developing field of natural language
   processing. we wondered if we could build something that could be even
   better than keras for rapidly training world-class deep learning
   models.

   after a lot of research and development it turned out that the answer
   was yes, we could (in our biased opinion). we built models that are
   faster, more accurate, and more complex than those using keras, yet
   were written with much less code. we   ve implemented recent papers that
   allow much more reliable training of more accurate models, across a
   number of fields.

   the key was to create an oo class which encapsulated all of the
   important data choices (such as preprocessing, augmentation, test,
   training, and validation sets, multiclass versus single class
   classification versus regression, et cetera) along with the choice of
   model architecture. once we did that, we were able to largely
   automatically figure out the best architecture, preprocessing, and
   training parameters for that model, for that data. suddenly, we were
   dramatically more productive, and made far less errors, because
   everything that could be automated, was automated. but we also provided
   the ability to customise every stage, so we could easily experiment
   with different approaches.

   with the increased productivity this enabled, we were able to try far
   more techniques, and in the process we discovered a number of current
   standard practices that are actually extremely poor approaches. for
   example, we found that the combination of [15]batch normalisation
   (which nearly all modern id98 architectures use) and model
   [16]pretraining and fine-tuning (which you should use in every project
   if possible) can result in a 500% decrease in accuracy using standard
   training approaches. (we will be discussing this issue in-depth in a
   future post.) the results of this research are being incorporated
   directly into our framework.

   there will be a limited release for our [17]in person students at usf
   first, at the end of october, and a public release towards the end of
   the year. (by which time we   ll need to pick a name! suggestions
   welcome   ) (if you want to join the in-person course, there   s still room
   in the [18]international fellowship program.)

what should you be learning?

   if it feels like new deep learning libraries are appearing at a rapid
   pace nowadays, then you need to be prepared for a much faster rate of
   change in the coming months and years. as more people enter the field,
   they will bring more skills and ideas, and try more things. you should
   assume that whatever specific libraries and software you learn today
   will be obsolete in a year or two. just think about the number of
   changes of libraries and technology stacks that occur all the time in
   the world of web programming     and yet this is a much more mature and
   slow-growing area than deep learning. so we strongly believe that the
   focus in learning needs to be on understanding the underlying
   techniques and how to apply them in practice, and how to quickly build
   expertise in new tools and techniques as they are released.

   by the end of the course, you   ll understand nearly all of the code
   that   s inside the framework, because each lesson we   ll be digging a
   level deeper to understand exactly what   s going on as we build and
   train our models. this means that you   ll have learnt the most important
   best practices used in modern deep learning   not just how to use them,
   but how they really work and are implemented. if you want to use those
   approaches in another framework, you   ll have the knowledge you need to
   develop it if needed.

   to help students learn new frameworks as they need them, we will be
   spending one lesson learning to use tensorflow, [19]mxnet, [20]cntk,
   and keras. we will work with our students to port our framework to
   these other libraries, which will make for some great class projects.

   we will also spend some time looking at how to productionize deep
   learning models. unless you are working at google-scale, your best
   approach will probably be to create a simple rest interface on top of
   your pytorch model, running id136 on the cpu. if you need to scale
   up to very high volume, you can export your model (as long as it does
   not use certain kinds of customisations) to [21]caffe2 or cntk. if you
   need computation to be done on a mobile device, you can either export
   as mentioned above, or use an on-device library.

how we feel about keras

   we still really like keras. it   s a great library and is far better for
   fairly simple models than anything that came before. it   s very easy to
   move between keras and our new framework, at least for the subset of
   tasks and architectures that keras supports. keras supports lots of
   backend libraries which means you can run keras code in many places.

   it has a unique (to our knowledge) approach to defining architectures
   where authors of custom layers are required to create a build() method
   which tells keras what shape output it creates for a given input. this
   allows users to more easily create simple architectures because they
   almost never have to specify the number of input channels for a layer.
   for architectures like densenet which concatenate layers it can make
   the code quite a bit simpler.

   on the other hand, it tends to make it harder to customize models,
   especially during training. more importantly, the static computation
   graph on the backend, along with keras    need for an extra compile()
   phase, means that it   s hard to customize a model   s behaviour once it   s
   built.

what   s next for fast.ai and pytorch

   we expect to see our framework and how we teach pytorch develop a lot
   as we teach the course and get feedback and ideas from our students. in
   past courses students have developed a lot of interesting projects,
   many of which have helped other students   we expect that to continue.
   given the accelerating progress in deep learning, it   s quite possible
   that by this time next year, there will be very different hardware or
   software options that will make todays    technology quite obsolete.
   although based on the quick adoption of new technologies we   ve seen
   from the pytorch developers, we suspect that they might stay ahead of
   the curve for a while at least   

   in our next post, we   ll be talking more about some of the standout
   features of pytorch, and dynamic libraries more generally.
   this post is tagged: [ [22]technical [23]courses ] (click a tag for
   more posts in that category).

related posts

     * [24]fast.ai embracing swift for deep learning 06 mar 2019
     * [25]a conversation about tech ethics with the new york times chief
       data scientist 04 mar 2019
     * [26]dairy farming, solar panels, and diagnosing parkinson's
       disease: what can you do with deep learning? 21 feb 2019

references

   1. https://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/atom.xml
   2. https://www.fast.ai/
   3. https://www.fast.ai/
   4. https://www.fast.ai/about/
   5. http://course.fast.ai/
   6. https://www.fast.ai/topics
   7. http://course18.fast.ai/
   8. http://pytorch.org/
   9. https://www.kaggle.com/c/planet-understanding-the-amazon-from-space
  10. http://course18.fast.ai/part2
  11. https://keras.io/
  12. https://www.tensorflow.org/
  13. https://distill.pub/2016/augmented-id56s/
  14. https://github.com/fastai/courses/blob/master/deeplearning2/translate-pytorch.ipynb
  15. https://gab41.lab41.org/batch-id172-what-the-hey-d480039a9e3b
  16. https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html
  17. https://www.usfca.edu/data-institute/certificates/deep-learning-part-one
  18. http://www.fast.ai/2017/09/08/international-fellowship/
  19. https://mxnet.incubator.apache.org/
  20. https://github.com/microsoft/cntk
  21. http://pytorch.org/tutorials/advanced/super_resolution_with_caffe2.html
  22. https://www.fast.ai/tag/technical
  23. https://www.fast.ai/tag/courses
  24. https://www.fast.ai/2019/03/06/fastai-swift/
  25. https://www.fast.ai/2019/03/04/ethics-framework/
  26. https://www.fast.ai/2019/02/21/dl-projects/
