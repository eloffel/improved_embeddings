   [1]view on github

heterogeneous supervision for id36:
a representation learning approach

[2]liyuan liu, [3]xiang ren, qi zhu, [4]shi zhi, [5]huan gui, [6]heng ji,
[7]jiawei han

   [8]paper [9]slides [10]reference

id36

   sentence-level id36: classify a relation mention into a
   set of relation types of interest or not-target-type (none)

   relation mention
          an entity pair with a sentence / context.
          e.g., ("hussein", "amman'', hussein was born in amman on 14
          november 1935.)

   relation types of interest
          a set of relation types.
          e.g., {born-in, president-of, died-in, parents-of, ...}

   id36
          predict born-in for ("hussein", "amman'', hussein was born in
          amman on 14 november 1935.)

distant supervision

   automatically generate annotations by knowledge base (kb).
   return r for (e1, e2, s) if r(e1, e2) in kb

   for example, because born-in(obama, usa) and president-of(obama, usa)
   and citizen-of(obama, usa) exists in kb, ("obama", "usa", obama was
   born in honolulu, hawaii, usa as he has always said) would be annotated
   as born-in (correct) and president-of (wrong).

heterogeneous supervision

   distant supervision only encodes kb, while we have more than kb.
     * knowledge base:
          + return born_in for (e1, e2, s) if born_in(e1, e2) in kb
          + return died_in for (e1, e2, s) if died_in(e1, e2) in kb
     * heuristic patterns:
          + return born_in for (e1, e2, s) if match('* born in *', s)
          + return died_in for (e1, e2, s) if match('* died in *', s)

   heterogeneous supervision encodes heterogeneous supervision by means of
   labeling functions.

challenges

     * original id36 task
     * true label discovery: resolves conflicts among heterogeneous
       supervision

   conflicts among heterogeneous supervision

our solution

intuition

     * id36: matching appropriate relation type to context.
          + ("obama", "usa", obama was born in honolulu, hawaii, usa as he
            has always said) should not be categorized as president-of,
            since the context does not match.
     * true label discovery: finding most reliable annotation w.r.t.
       context.
          + a labeling function could be more reliable for a subset of
            instances comparing to the rest.

   since context plays an important role in both tasks, we employed
   representation learning to capture context information, and bridges
   these two tasks.

a representation learning approach

   framework

experiments

labeling function

     * knowledge base: directly adopting annotations of distant
       supervision.
     * heuristic patterns: human constructed by analysis of annotations
       generated by kb

true label discovery

   in table 1, the first two relation mentions come from wiki-kbp, and
   their annotations are {born-in, none}. the last two are created by
   replacing key words of the first two. key words are marked as bold and
   entity mentions are marked as italics.

   caption: table 1. context-aware true label discovery

   relation mention rehession [11]investment
   \ [12]universal [13]schemas
   ann demeulemeester ( born 1959 , waregem , belgium ) is ... born-in
   none
   raila odinga was born at ..., in maseno, kisumu district, ... born-in
   none
   ann demeulemeester ( elected 1959 , waregem , belgium ) is ... none
   none
   raila odinga was examined at ..., in maseno, kisumu district, ... none
   none

   investment and universal schemas refer none as true type for all four
   instances in table 1. and our method infers born-in as the true label
   for the first two relation mentions. after replacing the matched
   contexts (born) with other words (elected and examined), our method no
   longer trusts born-in since the modified contexts are no longer
   matched, then infers none as the true label. in other words, our
   proposed method infer the true label in a context aware manner.

id36

   here, we summarize performance comparison with several relation
   extraction systems over kbp 2013 dataset (sentence-level extraction) in
   table. 2.

   caption: table. 2 performance on wiki-kbp

                 method               precision recall   f1
   dsl ([14]mintz et al., 2009)       0.3301    0.5446 0.4067
   multir ([15]hoffmann et al., 2011) 0.3045    0.5277 0.3810
   fcm ([16]gorid113y et al., 2015)     0.2523    0.5258 0.3410
   cotype-rm ([17]ren et al., 2017)   0.3701    0.4767 0.4122
   rehession (our)                    0.3677    0.4933 0.4208

resources

   softwares and labeling functions have been uploaded to [18]github

reference

   please cite the following paper if you find the codes and datasets
   useful:

   @inproceedings{liu2017rehession,
     title={heterogeneous supervision for id36: a
   representation learning approach},
     author={liu, liyuan and ren, xiang and zhu, qi and zhi, shi and gui,
   huan and ji, heng and han, jiawei},
     booktitle={proc. emnlp},
     year={2017}
   }

   by [19]slate theme

   published with [20]github pages

references

   1. https://github.com/liyuanlucasliu/rehession
   2. https://liyuanlucasliu.github.io/
   3. http://xren7.web.engr.illinois.edu/
   4. http://shizhi2.web.engr.illinois.edu/
   5. http://huangui2.web.engr.illinois.edu/
   6. http://nlp.cs.rpi.edu/hengji.html
   7. http://hanj.cs.illinois.edu/
   8. https://arxiv.org/pdf/1707.00166.pdf
   9. https://liyuanlucasliu.github.io/rehession/resources/rehession.pdf
  10. https://liyuanlucasliu.github.io/rehession/#ref
  11. http://cogcomp.org/papers/pasternackro10.pdf
  12. http://www.aclweb.org/anthology/n13-1008
  13. http://www.aclweb.org/anthology/n13-1008
  14. http://aclweb.org/anthology/p09-1113
  15. http://raphaelhoffmann.com/publications/acl2011.pdf
  16. http://www.aclweb.org/anthology/d15-1205
  17. https://arxiv.org/pdf/1610.08763.pdf
  18. https://github.com/liyuanlucasliu/rehession
  19. https://github.com/jasoncostello
  20. http://pages.github.com/
