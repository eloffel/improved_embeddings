   #[1]aylien    highlights of emnlp 2017: exciting datasets, return of the
   clusters, and more! comments feed [2]alternate [3]alternate

   [4]products [5]research [6]blog [7]company [8]contact

   [9]blog

   [10]general [11]product [12]data science [13]research [14]get started

   from the blog
   product
   product updates and how-to guides for our text analysis api, news api,
   and text analysis platform
   data science
   using text and image analysis for fun and insightful data science
   projects
   research
   the latest updates from our research team.
   general
   company updates & news
   from the aylien.com

   [15]products [16]research [17]blog [18]company [19]contact

   [20]sebastian ruder
   18 sep, 2017
   research
   highlights of emnlp 2017: exciting datasets, return of the clusters,
   and more!

highlights of emnlp 2017: exciting datasets, return of the clusters, and
more!

   four members of our research team spent the past week at the conference
   on empirical methods in natural language processing (emnlp 2017) in
   copenhagen, denmark. the conference handbook can be found [21]here and
   the proceedings can be found [22]here.

   the program consisted of two days of workshops and tutorials and three
   days of main conference. videos of the conference talks and
   presentations can be found [23]here.the conference was superbly
   organized, had a great venue, and a social event with fireworks.

   fireworks

   figure 1: fireworks at the social event

   with 225 long papers, 107 papers, and 9 tacl papers accepted, there was
   a clear uptick of submissions compared to last year. the number of long
   and short paper submissions to emnlp this year was even higher than
   those at acl for the first time within the last 13 years, as can be
   seen in figure 2.

   emnlp

   figure 2: long and short paper submissions at acl and emnlp from
   2004-2017

   in the following, we will outline our highlights and list some research
   papers that caught our eye. we will first list overall themes and will
   then touch upon specific research topics that are in line with our
   [24]areas of focus. also, we   re proud to say that we had four papers
   accepted to the conference and workshops this year! if you want to see
   the aylien team   s research, check out the research sections of our
   website and our blog. with that said, let   s jump in!


exciting datasets

   evaluating your approach on conll-2003 or ptb is appropriate for
   comparing against previous state-of-the-art, but kind of boring. the
   two following papers introduce datasets that allow you to test your
   model in more exciting settings:
     * [25]durrett et al. release a new id20 dataset. the
       dataset evaluates models on their ability to identify products
       being bought and sold in online cybercrime forums.
     * [26]kutuzov et al. evaluate their id27 model on a new
       dataset that focuses on predicting insurgent armed groups based on
       geographical locations.
     * while he did not introduce a new dataset, nando de freitas made the
       point during [27]his keynote that the best environment for learning
       and evaluating language is simulation.

   sdf

   figure 3: nando de freitas    vision for ai research

return of the clusters

   brown clusters, an agglomerative, hierarchical id91 of word types
   based on contexts that was introduced in 1992 seem to come in vogue
   again. they were found to be particularly helpful for cross-lingual
   applications, while clusters were key features in several approaches:
     * [28]mayhew et al. found that brown cluster features were an
       important signal for cross-lingual ner.
     * [29]botha et al. use word clusters as a key feature in their small,
       efficient feed-forward neural networks.
     * [30]mekala et al.   s new id194s cluster word
       embeddings, which give it an edge for text classification.
     * in his talk at the sclem workshop, noah smith cites the benefits of
       using brown clusters as features for tasks such as id52 and
       id31.

   emnlp3

   figure 4: noah smith on the benefits of id91 in his invited talk
   at the [31]sclem workshop

distant supervision

   distant supervision can be leveraged to collect large amounts of noisy
   training data, which can be useful in many applications. some papers
   used novel forms of distant supervision to create new corpora or to
   train a model more effectively:
     * [32]lan et al. use urls in tweets to collect a large corpus of
       paraphrase data. paraphrase data is usually hard to create, so this
       approach facilitates the process significantly and enables a
       continuously expanding collection of paraphrases.
     * [33]felbo et al. show that training on fine-grained emoji detection
       is more effective for pre-training sentiment and emotion models.
       previous approaches primarily pre-trained on positive and negative
       emoticons or emotion hashtags.

data selection

   the current generation of deep learning models is excellent at learning
   from data. however, we often do not pay much attention to the actual
   data our model is using. in many settings, we can improve upon the
   model by selecting the most relevant data:
     * [34]fang et al. reframe active learning as id23
       and explicitly learn a data selection policy. active learning is
       one of the best ways to create a model with as few annotations as
       possible; any improvement to this process is beneficial.
     * [35]van der wees et al. introduce dynamic data selection for id4,
       which varies the selected subset of the training data between
       different training epochs. this approach has the potential to
       reduce the training time of id4 models at comparable or better
       performance.
     * [36]ruder and plank use bayesian optimization to learn data
       selection policies for id21 and investigate how well
       these transfer across models, domains, and tasks. this approach
       brings us a step closer towards gaining a better understanding of
       what constitutes similarity between different tasks and domains.

character-level models

   characters are nowadays used as standard features in most sequence
   models. the [37]subword and character-level models in nlp workshop
   discussed approaches in more detail, with invited talks on subword
   language models and character-level id4.
     * [38]schmaltz et al. find that character-based sequence-to-sequence
       models outperform word-based models and models with character
       convolutions for sentence correction.

     * [39]ryan cotterell gave a great, movie-inspired tutorial on
       combining the best of fsts (cowboys) and sequence-to-sequence
       models (aliens) for string-to-string transduction. while evaluated
       on morphological segmentation, the tutorial raised awareness in an
       entertaining way that often the best of both worlds, i.e. a
       combination of traditional and neural approaches performs best.

   emnlp4

   figure 5: ryan cotterell on combining fsts and id195 models for
   string-to-string transduction

id27s

   research in id27s has matured and now mainly tries to 1)
   address deficits of id97, such as its ability of dealing with oov
   words; 2) extend it to new settings, e.g. modelling the relations of
   words over time; and 3) understand the induced representations better:
     * [40]pinter et al. propose an approach for generating oov word
       embeddings by training a character-based bilstm to generate
       embeddings that are close to pre-trained ones. this approach is
       promising as it provides us with a more sophisticated way to deal
       with out-of-vocabulary words than replacing them with an <unk>
       token.
     * [41]herbelot and baroni slightly modify id97 to allow it to
       learn embeddings for oov words from few data.
     * [42]rosin et al. propose a model for analyzing when two words
       relate to each other.
     * [43]kutuzov et al. propose another model that analyzes how two
       words relate to each other over time.
     * [44]hasan and curry improve the performance of id27s on
       word similarity tasks by re-embedding them in a manifold.
     * [45]yang et al. introduce a simple approach to learning
       cross-domain id27s. creating embeddings tuned on a small,
       in-domain corpus is still a challenge, so it is nice to see more
       approaches addressing this pain point.
     * [46]mimno and thompson try to understand the geometry of id97
       better. they show that the learned id27s are positioned
       diametrically opposite of their context vectors in the embedding
       space.

cross-lingual transfer

   an increasing number of papers evaluate their methods on multiple
   languages. in addition, there was an excellent tutorial on
   [47]cross-lingual word representations, which summarized and tried to
   unify much of the existing literature. slides of the tutorial are
   available [48]here.
     * [49]malaviya et al. train a many-to-one id4 to translate 1017
       languages into english and use this model to predict information
       missing from typological databases.
     * [50]mayhew et al. introduce a cheap translation method for
       cross-lingual ner that only requires a bilingual dictionary. they
       even perform a case study on uyghur, a truly low-resource language.
     * [51]kim et al. present a cross-lingual id21 model for
       id52 without parallel data. parallel data is expensive to
       create and rarely available for low-resource languages, so this
       approach fills an important need.
     * [52]vulic et al. propose a new cross-lingual transfer method for
       inducing verbnets for different languages. the method leverages
       vector space specialisation, an effective id27
       post-processing technique similar to retro-fitting.
     * [53]braud et al. propose a robust, cross-lingual discourse
       segmentation model that only relies on pos tags. they show that
       dependency information is less useful than expected; it is
       important to evaluate our models on multiple languages, so we do
       not overfit to features that are specific to analytic languages,
       such as english.

   emnlp56

   figure 6: anders s  gaard demonstrating the similarities between
   different cross-lingual embedding models at the cross-lingual
   representations tutorial

summarization

   [54]the workshop on new frontiers of summarization brought researchers
   together to discuss key issues related to id54. much
   of the research on summarization sought to develop new datasets and
   tasks:
     * [55]katja filippova (google research, switzerland) gave an
       interesting talk on sentence compression and passage summarization
       for q&a. she described how they went from syntax-based methods to
       deep learning.
     * [56]volkse et al. created a new summarization corpus by looking for
          tl;dr    on reddit. this is another example of a creative use of
       distant supervision, leveraging information that is already
       contained in the data in order to create a new corpus.
     * [57]falke and gurevych won the best resource paper award for
       creating a new summary corpus that is based on concept maps rather
       than textual summaries. the concept map can be explored using a
       [58]graph-based document exploration system, which is available as
       a demo [59]here.
     * [60]pasunuru et al. use id72 to improve abstractive
       summarization by leveraging entailment generation.
     * [61]isonuma et al. also use id72 with document
       classification in conjunction with curriculum learning.
     * [62]li et al. propose a new task, reader-aware multi-document
       summarization, which uses comments of articles, along with a
       dataset for this task.
     * [63]naranyan et al. propose another new task, split and rephrase,
       which aims to split a complex sentence into a sequence of shorter
       sentences with the same meaning, and also release a new dataset.
     * [64]ghalandari revisits the traditional centroid-based method and
       proposes a new strong baseline for id57.

bias

   data and model-inherent bias is an issue that is receiving more
   attention in the community. some papers investigate and propose methods
   to address the bias in certain datasets and evaluations:
     * [65]chaganty et al. investigate bias in the evaluation of knowledge
       base population models and propose an importance sampling-based
       evaluation to mitigate the bias.
     * dan jurasky gave a truly insightful [66]keynote about his three
       year-long study analyzing the body camera recordings his team
       obtained from the oakland police department for racial bias.
       besides describing the first contemporary linguistic study of
       officer-community member interaction, he also provided entertaining
       insights on the language of food (cheaper restaurants use terms
       related to addiction, more expensive venues use language related to
       indulgence) and the challenges of interdisciplinary publishing.
     * [67]dubossarsky et al. analyze the bias in word representation
       models and propose that recently proposed laws of semantic change
       must be revised.
     * [68]zhao et al. won the best paper award for an approach using
       lagrangian relaxation to inject constraints based on corpus-level
       label statistics. an important finding of their work is bias
       amplification: while some bias is inherent in all datasets, they
       observed that models trained on the data amplified its bias. while
       a gendered dataset might only contain women in 30% of examples, the
       situation at prediction time might thus be even more dire.

   emnlp7

   figure 7: zhao et al.   s proposed method for reducing bias amplification

argument mining & debate analysis

   argument mining is closely related to summarization. in order to
   summarize argumentative texts, we have to understand claims and their
   justifications. this research area had the [69]4th workshop on argument
   mining dedicated to it:
     * [70]hidey et al. analyse the semantic types of claims (e.g.
       agreement, interpretation) and premises (ethos, logos, pathos) in
       the subreddit [71]change my view. this is another creative use of
       reddit to create a dataset and analyze linguistic patterns.
     * [72]wachsmut et al. presented an argument web search engine, which
       can be queried [73]here.
     * [74]potash and rumshinsky predict the winner of debates, based on
       audience favorability.
     * [75]swamy et al. also forecast winners for the oscars, the us
       presidential primaries, and many other contests based on user
       predictions on twitter. they create a dataset to test their
       approach.
     * [76]zhang et al. analyze the rhetorical role of questions in
       discourse.
     * [77]liu et al. show that argument-based features are also helpful
       for predicting review helpfulness.

multi-agent communication

   multi-agent communication is a niche topic, which has nevertheless
   received some recent interest, notably in the representation learning
   community. most papers deal with a scenario where two agents play a
   communicative referential game. the task is interesting, as the agents
   are required to cooperate and have been observed to develop a common
   pseudo-language in the process.
     * [78]andreas and klein investigate the structure encoded by id56
       representations for messages in a communication game. they find
       that the mistakes are similar to the ones made by humans. in
       addition, they find that negation is encoded as a linear
       relationship in the vector space.
     * [79]kottur et al. show in their best short paper that language does
       not emerge naturally when two agents are cooperating, but that they
       can be coerced to develop compositional expressions.

   emnlp8

   figure 8: the multi-agent setup in the paper of kottur et al.

id36

   extracting relations from documents is more compelling than simply
   extracting entities or concepts. some papers improve upon existing
   approaches using better distant supervision or adversarial training:
     * [80]liu et al. reduce the noise in distantly supervised relation
       extraction with a soft-label method.
     * [81]zhang et al. publish tacred, a large supervised dataset
       knowledge base population, as well as a new model.
     * [82]wu et al. improve the precision of id36 with
       adversarial training.

document and sentence representations

   learning better sentence representations is closely related to learning
   more general word representations. while id27s still have to
   be contextualized, sentence representations are promising as they can
   be directly applied to many different tasks:
     * [83]mekala et al. propose a novel technique for building document
       vectors from id27s, with good results for text
       classification. they use a combination of adding and concatenating
       id27s to represent multiple topics of a document, based
       on word clusters.
     * [84]conneau et al. learn sentence representations from the snli
       dataset and evaluate them on 12 different tasks.

   these were our highlights. naturally, we weren   t able to attend every
   session and see every paper. what were your highlights from the
   conference or which papers from the [85]proceedings did you like most?
   let us know in the comments below.

                       [86]text analysis api - sign up

   stay informed
   subscribe to our newsletter to recieve regular updates about aylien,
   direct to your inbox.
   [87]sebastian ruder
   research scientist @ aylien
   sebastian is a phd student in natural language processing at the
   insight research centre for data analytics and a research scientist at
   aylien. previously, he worked with microsoft, ibm extreme blue, and
   google summer of code. his main research interest lies in using deep
   learning for id20 in nlp. in his spare time, he loves to
   travel, read, blog, and learn new languages.
   twitter: @seb_ruder
   read next
   [88]will gannon
   [89]how ryanair handles a pr crisis     a text analysis case study
   25 sep, 2017
   how ryanair handles a pr crisis     a text analysis case study
   related articles
   [90]sebastian ruder
   7 nov, 2018
   [91]emnlp 2018 highlights: inductive bias, cross-lingual learning, and
   more

   the post discusses highlights of the 2018 conference on empirical
   methods in natural language processing (emnlp 2018). you can find past
   highlights of conferences here. you can find all 549 [   ]
   [92]read    
   [93]john glover
   28 feb, 2018
   [94]funded phd and masters opportunities 2018

   at aylien we are using recent advances in artificial intelligence to
   try to understand natural language. part of what we do is building
   products such as our text analysis platform, [   ]
   [95]read    
   [96]sebastian ruder
   26 jul, 2018
   [97]acl 2018 highlights: understanding representations and evaluation
   in more challenging settings

   i attended the 56th annual meeting of the association for computational
   linguistics (acl 2018) in melbourne, australia from july 15-20, 2018
   and presented three papers . it is foolhardy to [   ]
   [98]read    
   [99]john glover
   17 may, 2017
   [100]a call for research collaboration at aylien 2017

   at aylien we are using recent advances in artificial intelligence to
   try to understand natural language. part of what we do is building
   products such as our text analysis api [   ]
   [101]read    
   let's talk

   products

   [102]text analysis api [103]news api [104]text analysis platform
   company

   [105]about us [106]in the news [107]jobs
   content

   [108]resources [109]blog
   get in touch

   [110]contact sales [111]press [112]email us
   stay informed

   [113]privacy policy [114]terms and conditions

   copyright    2018 aylien ltd. all rights reserved.

references

   visible links
   1. http://blog.aylien.com/highlights-emnlp-2017-exciting-datasets-return-clusters/feed/
   2. http://blog.aylien.com/wp-json/oembed/1.0/embed?url=http://blog.aylien.com/highlights-emnlp-2017-exciting-datasets-return-clusters/
   3. http://blog.aylien.com/wp-json/oembed/1.0/embed?url=http://blog.aylien.com/highlights-emnlp-2017-exciting-datasets-return-clusters/&format=xml
   4. https://aylien.com/products
   5. https://aylien.com/research
   6. http://blog.aylien.com/
   7. https://aylien.com/about
   8. https://aylien.com/contact
   9. http://blog.aylien.com/
  10. http://blog.aylien.com/category/general/
  11. http://blog.aylien.com/category/product/
  12. http://blog.aylien.com/category/data-science/
  13. http://blog.aylien.com/category/research/
  14. https://aylien.com/products/
  15. https://aylien.com/products
  16. https://aylien.com/research
  17. http://blog.aylien.com/
  18. https://aylien.com/about
  19. https://aylien.com/contact
  20. http://blog.aylien.com/author/sebastian/
  21. http://emnlp2017.net/downloads/handbook.pdf
  22. http://aclweb.org/anthology/d/d17/
  23. https://ku.cloud.panopto.eu/panopto/pages/sessions/list.aspx#folderid="9042b495-7b6b-4169-a5a1-d250cc0ee4ec"
  24. https://aylien.com/research/
  25. http://aclweb.org/anthology/d/d17/d17-1274.pdf
  26. http://aclweb.org/anthology/d/d17/d17-1194.pdf
  27. http://emnlp2017.net/invited-speakers.html
  28. http://aclweb.org/anthology/d/d17/d17-1268.pdf
  29. http://aclweb.org/anthology/d/d17/d17-1308.pdf
  30. http://aclweb.org/anthology/d/d17/d17-1070.pdf
  31. https://sites.google.com/view/sclem2017/home
  32. http://aclweb.org/anthology/d/d17/d17-1127.pdf
  33. http://aclweb.org/anthology/d/d17/d17-1169.pdf
  34. http://aclweb.org/anthology/d/d17/d17-1064.pdf
  35. http://aclweb.org/anthology/d/d17/d17-1148.pdf
  36. http://aclweb.org/anthology/d/d17/d17-1038.pdf
  37. https://sites.google.com/view/sclem2017/home
  38. http://aclweb.org/anthology/d/d17/d17-1297.pdf
  39. https://ryancotterell.github.io/
  40. http://aclweb.org/anthology/d/d17/d17-1010.pdf
  41. http://aclweb.org/anthology/d/d17/d17-1030.pdf
  42. http://aclweb.org/anthology/d/d17/d17-1122.pdf
  43. http://aclweb.org/anthology/d/d17/d17-1194.pdf
  44. http://aclweb.org/anthology/d/d17/d17-1033.pdf
  45. http://aclweb.org/anthology/d/d17/d17-1311.pdf
  46. http://aclweb.org/anthology/d/d17/d17-1307.pdf
  47. http://emnlp2017.net/tutorials/day2/xling_word_rep.html
  48. http://people.ds.cam.ac.uk/iv250/tutorial/xlingrep-tutorial.pdf
  49. http://aclweb.org/anthology/d/d17/d17-1267.pdf
  50. http://aclweb.org/anthology/d/d17/d17-1268.pdf
  51. http://www.aclweb.org/anthology/d/d17/d17-1301.pdf
  52. http://aclweb.org/anthology/d/d17/d17-1269.pdf
  53. http://aclweb.org/anthology/d/d17/d17-1257.pdf
  54. https://summarization2017.github.io/
  55. https://research.google.com/pubs/author39008.html
  56. http://www.aclweb.org/anthology/w/w17/w17-4508.pdf
  57. http://aclweb.org/anthology/d/d17/d17-1322.pdf
  58. https://github.com/ukplab/emnlp2017-graphdocexplore
  59. http://cmaps.ukp.informatik.tu-darmstadt.de/graph-doc-explorer/#!/
  60. http://www.aclweb.org/anthology/w17-4504
  61. http://aclweb.org/anthology/d/d17/d17-1222.pdf
  62. http://www.aclweb.org/anthology/w/w17/w17-4512.pdf
  63. http://aclweb.org/anthology/d/d17/d17-1065.pdf
  64. http://www.aclweb.org/anthology/w/w17/w17-4511.pdf
  65. http://aclweb.org/anthology/d/d17/d17-1110.pdf
  66. http://emnlp2017.net/invited-speakers.html
  67. http://aclweb.org/anthology/d/d17/d17-1119.pdf
  68. http://aclweb.org/anthology/d/d17/d17-1319.pdf
  69. https://argmining2017.wordpress.com/
  70. http://www.aclweb.org/anthology/w/w17/w17-5102.pdf
  71. https://www.reddit.com/r/changemyview/
  72. http://www.aclweb.org/anthology/w/w17/w17-5106.pdf
  73. http://www.args.me/
  74. http://aclweb.org/anthology/d17-1260
  75. http://aclweb.org/anthology/d/d17/d17-1166.pdf
  76. http://aclweb.org/anthology/d/d17/d17-1164.pdf
  77. http://aclweb.org/anthology/d/d17/d17-1143.pdf
  78. http://aclweb.org/anthology/d/d17/d17-1310.pdf
  79. http://aclweb.org/anthology/d/d17/d17-1320.pdf
  80. http://aclweb.org/anthology/d17-1189
  81. http://aclweb.org/anthology/d/d17/d17-1004.pdf
  82. http://aclweb.org/anthology/d/d17/d17-1187.pdf
  83. http://aclweb.org/anthology/d/d17/d17-1070.pdf
  84. http://aclweb.org/anthology/d/d17/d17-1071.pdf
  85. http://aclweb.org/anthology/d/d17/
  86. http://cta-redirect.hubspot.com/cta/redirect/1942801/02bc9816-b470-4328-9625-fad8d92a8811
  87. http://blog.aylien.com/author/sebastian/
  88. http://blog.aylien.com/author/will/
  89. http://blog.aylien.com/ryanair-handles-pr-crisis-text-analysis-case-study/
  90. http://blog.aylien.com/author/sebastian/
  91. http://blog.aylien.com/emnlp-2018-highlights-inductive-bias-cross-lingual-learning-and-more/
  92. http://blog.aylien.com/emnlp-2018-highlights-inductive-bias-cross-lingual-learning-and-more/
  93. http://blog.aylien.com/author/john/
  94. http://blog.aylien.com/funded-phd-masters-opportunities-2018/
  95. http://blog.aylien.com/funded-phd-masters-opportunities-2018/
  96. http://blog.aylien.com/author/sebastian/
  97. http://blog.aylien.com/acl-2018-highlights-understanding-representations-and-evaluation-in-more-challenging-settings/
  98. http://blog.aylien.com/acl-2018-highlights-understanding-representations-and-evaluation-in-more-challenging-settings/
  99. http://blog.aylien.com/author/john/
 100. http://blog.aylien.com/call-research-collaboration-aylien/
 101. http://blog.aylien.com/call-research-collaboration-aylien/
 102. https://aylien.com/text-api/
 103. https://aylien.com/news-api/
 104. https://aylien.com/text-analysis-platform/
 105. https://aylien.com/about/
 106. https://aylien.com/in-the-news/
 107. https://aylien.com/jobs/
 108. https://aylien.com/resources/
 109. http://blog.aylien.com/
 110. https://aylien.com/contact/
 111. https://aylien.com/in-the-news/
 112. https://aylien.com/contact/
 113. https://aylien.com/privacy/
 114. https://aylien.com/terms/

   hidden links:
 116. https://aylien.com/
 117. http://blog.aylien.com/?s=
 118. http://blog.aylien.com/?s=
 119. http://blog.aylien.com/category/product/
 120. http://blog.aylien.com/category/data-science/
 121. http://blog.aylien.com/category/research/
 122. http://blog.aylien.com/category/general/
 123. http://blog.aylien.com/highlights-emnlp-2017-exciting-datasets-return-clusters/sebastian@aylien.com
 124. https://twitter.com/_aylien
 125. https://www.linkedin.com/company-beta/1195911/
 126. https://www.facebook.com/aylieninc
