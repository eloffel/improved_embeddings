id49 as recurrent neural networks

[1]shuai zheng*, [2]sadeep jayasumana*, [3]bernardino romera-paredes, vibhav
vineet^, zhizhong su, dalong du, chang huang, [4]philip h. s. torr.

[5]torr vision group, university of oxford, stanford university, baidu idl

* equal contribution.
^ work conducted while authors at the university of oxford.
[6]online demo for semantic image segmentation.
     __________________________________________________________________

system overview about crf-id56

   pixel-level labelling tasks, such as semantic segmentation, play a
   central role in image understanding. recent approaches have attempted
   to harness the capabilities of deep learning techniques for image
   recognition to tackle pixel-level labelling tasks. one central issue in
   this methodology is the limited capacity of deep learning techniques to
   delineate visual objects. to solve this problem, we introduce a new
   form of convolutional neural network that combines the strengths of
   convolutional neural networks (id98s) and id49
   (crfs)-based probabilistic graphical modelling. to this end, we
   formulate mean-field approximate id136 for the conditional random
   fields with gaussian pairwise potentials as recurrent neural networks.
   this network, called crf-id56, is then plugged in as a part of a id98 to
   obtain a deep network that has desirable properties of both id98s and
   crfs. importantly, our system fully integrates crf modelling with id98s,
   making it possible to train the whole deep network end-to-end with the
   usual back-propagation algorithm, avoiding offline post-processing
   methods for object delineation. we apply the proposed method to the
   problem of semantic image segmentation, obtaining top results on the
   challenging pascal voc 2012 segmentation benchmark.

   key words: end-to-end system, convolutional neural networks,
   fully-connected id49, semantic image segmentation
     __________________________________________________________________

   iframe: [7]https://www.youtube.com/embed/h5qvqreibxc

   news

   shuai zheng, anurag arnab, and bernardino romera-paredes have presented
   a guest tutorial titled "[8]holistic image understanding with deep
   learning and dense random fields" at eccv 2016.

   with [9]anurag arnab, sadeep jayasumana, shuai zheng and philip h. s.
   torr, new paper [10]"higher order id49 in deep
   neural networks" improves semantic image segmentation by integrating
   super-pixel cues, id164, and semantic image segmentation.

   our [11]crf-id56 semantic image segmentation demo website won the best
   demo award at iccv 2015 (international conference on id161),
   december, 2015.

   the full source code has been released. check it out from [12]this
   github repository. model is also available in [13]matconvnet.

   this approach sets a new state-of-the-art in semantic image
   segmentation in [14]pascal voc 2010-2012 benchmarks, april, 2015.
     __________________________________________________________________

   iccv2015 paper:
   [15]pdf paper
   [16]ieee official version

   [17]arxiv info

   [18]poster for crf-id56 paper in iccv 2015

   [19]talk at rework deep learning summit

   [20]crf-id56 example results
     __________________________________________________________________

   please cite
@inproceedings{crfasid56_iccv2015,
author = {shuai zheng and sadeep jayasumana and bernardino romera-paredes and vi
bhav vineet and zhizhong su and dalong du and chang huang and philip torr},
title = {id49 as recurrent neural networks},
booktitle = {international conference on id161 (iccv)},
year = {2015}
}

   [21]beyond our work

   [22]latest semantic image segmentation work
     __________________________________________________________________

   source code and models is now available on
   [23]https://github.com/torrvision/crfasid56.
   [24]sign your email to receive the latest news about our project.
     __________________________________________________________________

   iframe: [25]https://www.youtube.com/embed/-gpza71oeqa
     __________________________________________________________________

   application: semantic image segmentation

   example results on pascal voc 2011 validation set:
   example results

   more semantic image segmentation results of crf-id56 can be found at
   [26]photoswipe gallery.
   pascal voc 2012 leader board results on the 1st of may, 2015. check the
   leaderboard for the latest results.
                   approaches                  mean intersection-union
   oxford_tvg_crf_id56_coco                              74.7
   deeplab-crf-coco-largefov                            72.7
   oxford_tvg_crf_id56_voc(trained on voc 2012)          72.0
   deeplab-msc-crf-largefov                             71.6
   msra-boxsup (trained on coco)                        71.0
   context_deep_id98_crf                                 70.7
   deeplab-crf-coco-strong                              70.4
   deeplab-crf-largefov                                 70.3
   deeplab-crf-msc                                      67.1
   deeplab-crf                                          66.4
   crf_id56 (trained on voc 2011)                        65.2
   tti_zoomout_16                                       64.4
   hypercolumn                                          62.6
   fcn-8s                                               62.2
   msra_cfm                                             61.8
   tti_zoomout                                          58.4
   sds                                                  51.6
   nus_uds                                              50.0
   ttic-divmbest-rerank                                 48.1
   bonn_o2pcpmc_fgt_segm                                47.8
   bonn_o2pcpmc_fgt_segm                                47.5
   bonngc_o2p_cpmc_csi                                  46.8
   bonn_cmbr_o2p_cpmc_lin                               46.7

   nb:
   1. oxford_tvg_crf_id56 are fine-tuned on the voc 2012 official training
   set + berkeley augmented dataset.
   2. oxford_tvg_crf_id56_coco are fine-tuned on the voc 2012 official
   training set + berkeley augmented dataset ([27]berkeley sbd extra
   annotation) + subset of coco 2014 training ([28]image list) dataset.
   3. pascal voc measure segmentation accuracy using the intersection over
   union (iu), defining as .

   [29]online demo for semantic image segmentation is on. check it out.
   pascal-context results (59 classes), 2015
                 approaches               mean intersection-union
   end-to-end-trainable-higher-order-crfs          41.30
   boxsup                                          40.50
   crf-id56                                         39.28
   fcn-8s                                          35.10
   cfm                                             34.40
   o2p                                             18.1
     __________________________________________________________________

   acknowledgement
   we thank caffe team, especially jon long, evan shelhamer, and yangqing
   jia. we would like to thank the fruitful suggestions from sebastian
   nowozin, and carsten rother. we also would like to acknowledge the
   discussions and helps from junjie yan, yinan yu, yi yang, kai yu, and
   many others at baidu institute of deep learning. this work is supported
   by epsrc (ep/i001107/2), and erc grant (321162-helios). this work is
   also strongly suppported by oxford advanced research computing service
   team, including steven young, dugan witherick, mihai duta, ian bush,
   and etc. we gratefully acknowledge the support of nvidia corporation
   with the donation of the titan z gpu used for this research.
     __________________________________________________________________

   faq
   1. q: can you share some insights about the good results, especially
   the drastically increased accuracy?
   a: the improvement of our new results on voc 2012 leader board are due
   to training on the ms coco + voc 2012 official training set + berkeley
   augmented dataset with more carefully chosen nn training parameters. in
   the current arxiv version, we included only some preliminary
   experimental results where we used only voc 2011 training set +
   berkeley augmented dataset without making much effort to optimise the
   nn training parameters such as the learning rate.
   2. q: how can i collect those semantic image labels and train on my own
   data?
   a: you can use the segmentation annotation tool like [30]labelme, and
   superpixel-based [31]js-segment-annotator from kyamagu. after you label
   a few thousands images, you should be able to train your own
   segmentation model based on our [32]crf-id56 code.
   3. q: would crf-id56 works with other unary?
   a: yes.
   4. q: why padding 100 in conv_1_1 in crf-id56 released model?
   a: this is due to the design of fcn and vgg networks. the actually
   padding number is computed by taking into account the whole network. as
   long as this padding number is greater than 80, it would make sense. as
   shown in the fcn version 2 scripts, the actual padding used in conv_1_1
   is 100-1, and the offset in last crop layer is 19. see more details in
   test_coord_map.py in caffe.

   more questions and answers can be found at github [33]issue page.
     __________________________________________________________________

   press coverage
   1. [34]play a fun game of stump the next generation photo recognition
   program, 26, june, 2015.
   2. [35]show hn hacker news, 26, june, 2015.
   2. [36]deep learning image segmentation demo, reddit,
   interentisbeautiful, 28, june, 2015.
   3. [37]hybrid animal results, reddit, 28, june, 2015.
   4. [38]desarrollan un sistema de reconocimiento de objetos en
   fotograf  as, 29, june, 2015.
   5. [39]crf-id56 was shown as an example application in an article about
   mocha.jl deep learning, 1, september, 2015.
   6. [40]bbc click program hilights semantic image segmentation demo with
   crf-id56, 22 aug 2015.
   7. [41]bbc click program "best bits from 2015" highlights semantic
   image segmentation demo with crf-id56 with two other projects from
   torr-vision, december, 2015.
     __________________________________________________________________

   [42]locations of site visitors

   please enable javascript to view the [43]comments powered by disqus.

references

   1. http://kylezheng.org/
   2. http://www.robots.ox.ac.uk/~sadeep/
   3. http://romera-paredes.com/
   4. http://www.robots.ox.ac.uk/~phst/
   5. http://www.robots.ox.ac.uk/~tvg/
   6. http://www.robots.ox.ac.uk/~szheng/crfasid56demo
   7. https://www.youtube.com/embed/h5qvqreibxc
   8. http://www.robots.ox.ac.uk/~szheng/res_crfid56/eccv2016_tutorial_id98_crf.pdf
   9. http://www.robots.ox.ac.uk/~aarnab/
  10. http://arxiv.org/abs/1511.08119
  11. http://crfasid56.torr.vision/
  12. http://github.com/torrvision/crfasid56
  13. http://www.vlfeat.org/matconvnet/pretrained/#semantic-segmentation
  14. http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6
  15. http://www.robots.ox.ac.uk/~szheng/papers/crfasid56.pdf
  16. http://dx.doi.org/10.1109/iccv.2015.179
  17. http://arxiv.org/abs/1502.03240
  18. http://www.robots.ox.ac.uk/~szheng/papers/postercrfasid56.pdf
  19. http://t.co/p2mmnyumde
  20. http://www.robots.ox.ac.uk/~szheng/res_crfid56/crfasid56-example.pptx
  21. http://scholar.google.co.uk/scholar?cites=4680896688857314530&as_sdt=2005&sciodt=0,5&hl=en
  22. https://github.com/kjw0612/awesome-deep-vision#semantic-segmentation
  23. https://github.com/torrvision/crfasid56
  24. http://goo.gl/forms/77cj7guegu
  25. https://www.youtube.com/embed/-gpza71oeqa
  26. http://www.robots.ox.ac.uk/~szheng/crfid56voc12/
  27. http://www.cs.berkeley.edu/~bharath2/codes/sbd/download.html
  28. http://www.robots.ox.ac.uk/~szheng/res_crfid56/train_coco2014_rgb.txt
  29. http://www.robots.ox.ac.uk/~szheng/crfasid56demo
  30. https://github.com/csailvision/labelmeannotationtool
  31. https://github.com/kyamagu/js-segment-annotator
  32. https://github.com/torrvision/crfasid56/
  33. https://github.com/torrvision/crfasid56/issues
  34. https://www.inverse.com/article/4144-play-a-fun-game-of-stump-the-next-gen-photo-recognition-program
  35. https://news.ycombinator.com/item?id=9774181
  36. https://www.reddit.com/r/internetisbeautiful/comments/3bb7mh/deep_learning_image_segmentation_from_oxford/
  37. http://www.reddit.com/r/hybridanimals/comments/3bd9gw/hybrid_animals_vs_oxfords_semantic_image/
  38. http://www.qore.com/noticias/38337/desarrollan-un-sistema-de-reconocimiento-de-objetos-en-fotografias
  39. http://devblogs.nvidia.com/parallelforall/mocha-jl-deep-learning-julia/
  40. https://www.youtube.com/watch?v=qzsvfe5i2gy
  41. http://www.bbc.co.uk/iplayer/episode/b06ttymw/click-26122015
  42. http://m.maploco.com/details/4115bbbh
  43. https://disqus.com/?ref_noscript
