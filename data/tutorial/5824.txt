cs294-112 deep id23 hw3:

id24 on atari

due october 2nd, 11:59 pm

1

introduction

this assignment requires you to implement and evaluate id24 with con-
volutional neural networks for playing atari games. the id24 algorithm
was covered in lecture, and you will be provided with starter code. you may
modify the code to use any automatic di   erentiation package you want, though
the default code uses tensorflow, and you may    nd it easier to use that. you
may run the code either on gpu or cpu. a gpu machine will be faster, but
you should be able to get good results with about 20 hours of compute on a
modern cpu.

please start early! the questions will require you to perform multiple runs of
id24, each of which can take quite a long time. furthermore, depending on
your implementation, you may    nd it necessary to tweak some of the parameters,
such as learning rates or exploration schedules, which can also be very time
consuming. the actual coding for this assignment will involve about 50 lines of
code, but the evaluation may take a very long time.

2

installation

obtain the code from: https://github.com/berkeleydeeprlcourse/homework
to run the code, go into the hw3 directory and simply execute:

python r u n d q n a t a r i . py

it will not work however until you    nish implementing the algorithm in id25.py
you will also need to install the dependencies, which are openai gym, ten-
sorflow, and opencv (which is used to resize the images). remember to also
follow the instructions for installing the atari environments for openai gym,
which can be found on the openai gym github page. to install opencv, run
   pip install opencv-python   . if you have trouble with    mpeg you can install it
via homebrew or apt-get depending on your system.
there are also some slight di   erences between di   erent versions of tensorflow
in regard to initialization. if you get an error inside id25 utils.py related to vari-

1

able initialization, check the comment inside initialize interdependent variables,
it explains how to modify the code to be compatible with older versions of ten-
sorflow.
you may want to look at run id25 atari.py before starting the implementation.
this    le de   nes the convolutional network you will be using for image-based
atari playing, de   nes which atari game will be used (pong is the default), and
speci   es the hyperparameters.

3

implementation

the    rst phase of the assignment is to implement a working version of q-
learning. the default code will run the pong game with reasonable hyperpa-
rameter settings. the starter code already provides you with a working replay
bu   er, all you have to do is    ll in parts of id25.py, by searching for    your
code here.    the comments in the code describe what should be imple-
mented in each section. you may    nd it useful to look inside id25 utils.py to
understand how the replay bu   er works, but you should not need to modify it.
you may also look inside run id25 atari.py to change the hyperparameters or
the particular choice of atari game. once you implement id24, answering
some of the questions may require changing hyperparameters, neural network
architectures, and the game, which should be done by editing run id25 atari.py
to determine if your implementation of id24 is performing well, you
should run it with the default hyperparameters on the pong game. our reference
solution gets a reward of around -20 to -15 after 500k steps, -15 to -10 after 1m
steps, -10 to -5 after 1.5m steps, and around +10 after 2m steps on pong. the
maximum score of around +20 is reached after about 4-5m steps. however,
there is considerable variation between runs.

to accelerate debugging, you may also check out run id25 ram.py, which
runs the game pong but using the state of the emulator ram instead of images
as observations. this version will run faster, especially if you   re not using a
gpu, but takes more iterations and probably won   t converge to as good of a
solution. you may use this version for debugging your algorithm, though you
are not required to report results for it. our reference solutions with the default
hyperparameters gets around -19.9 after 500k steps, -19.2 after 1m steps, -15.0
after 1.5m steps, and -13.2 after 2m steps.

4 evaluation

once you have a working implementation of id24, you should prepare a
report. the report should consist of one    gure for each question below, similarly
to homework 1. you should turn in the report as one pdf and a zip    le with your
code. if your code requires special instructions or dependencies to run, please
include these in a    le called readme inside the zip    le. for all the questions
below, it is your choice how long to run for. although running for 2-4m steps

2

is ideal for a solid evaluation, especially when running on cpu, this may be
di   cult. we strongly recommend running at least 1m steps, and including at
least one run of 4m steps for question 1.
if you have severe computational
constraints and    nd that you are unable to run image-based atari fast enough
for evaluating the design choices in q2, you may use the ram version for q2
only, but q1 results must use images.
if you use ram state for q2, please
specify this in the caption.

include a learning curve plot
question 1: basic id24 performance.
showing the performance of your implementation on the game pong. the x-axis
should correspond to number of time steps (consider using scienti   c notation)
and the y-axis should show the mean 100-episode reward as well as the best
mean reward. these quantities are already computed and printed in the starter
code. be sure to label the y-axis, since we need to verify that your implemen-
tation achieves similar reward as ours.
if you needed to modify the default
hyperparameters to obtain good performance, include the hyperparameters in
the caption. you only need to list hyperparameters that were modi   ed from the
defaults.

question 2: experimenting with hyperparameters. now let   s analyze
the sensitivity of id24 to hyperparameters. choose one hyperparameter
of your choice and run at least three other settings of this hyperparameter, in
addition to the one used in question 1, and plot all four values on the same
graph. your choice what you experiment with, but you should explain why you
chose this hyperparameter in the caption. examples include:
learning rates,
neural network architecture, exploration schedule or exploration rule (e.g. you
may implement an alternative to  -greedy), etc. discuss the e   ect of this hyper-
parameter on performance in the caption. you should    nd a hyperparameter
that makes a nontrivial di   erence on performance. note: you might consider
performing a hyperparameter sweep for getting good results in question 1, in
which case it   s    ne to just include the results of this sweep for question 2 as
well, while plotting only the best hyperparameter setting in question 1.

for question 2, you may run on other games or multiple games, but
note:
please submit results for question 1 using only the game pong. running on
multiple games may require considerable time or computing power, so it is not
required, but encouraged. if you have any other interesting experiments you
wish to report on, you may include those after your answer to question 2.
interesting additional experiments or extensions will be considered for bonus
points.

5 submission

email the report you prepared as described above to berkeleydeeprlcourse@gmail.com,
with subject line    deep rl assignment 3    by 11:59pm on october 2nd.

3

