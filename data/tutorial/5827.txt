   #[1]openai

     * [2]about
     * [3]progress
     * [4]resources
     * [5]blog

   (button)

   (button)

     * [6]about
         ______________________________________________________________

     * [7]progress
         ______________________________________________________________

     * [8]resources
         ______________________________________________________________

     * [9]blog
         ______________________________________________________________

     * [10]jobs
     __________________________________________________________________

   april 27, 2016     4 minute read

openai gym beta

   we're releasing the public beta of [11]openai gym, a toolkit for
   developing and comparing [12]id23 (rl) algorithms. it
   consists of a growing suite of [13]environments (from [14]simulated
   robots to [15]atari games), and a site for [16]comparing and
   reproducing results.

   openai gym is compatible with algorithms written in any framework, such
   as [17]tensorflow and [18]theano. the environments are written in
   python, but we'll soon make them easy to use from any language. we
   originally built openai gym as a tool to accelerate our own rl
   research. we hope it will be just as useful for the broader community.
     __________________________________________________________________

getting started

   if you'd like to dive in right away, you can work through our
   [19]tutorial. you can also help out while learning by [20]reproducing
   [21]a [22]result.
     __________________________________________________________________

why rl?

   id23 (rl) is the subfield of machine learning
   concerned with decision making and motor control. it studies how an
   agent can learn how to achieve goals in a complex, uncertain
   environment. it's exciting for two reasons:
     * rl is very general, encompassing all problems that involve making a
       sequence of decisions: for example, controlling a robot's motors so
       that it's able to [23]run and [24]jump, making business decisions
       like pricing and inventory management, or playing [25]video games
       and [26]board games. rl can even be applied to supervised learning
       problems with [27]sequential [28]or [29]structured outputs.
     * rl algorithms have started to achieve good results in many
       difficult environments. rl has a long history, but until recent
       advances in deep learning, it required lots of problem-specific
       engineering. deepmind's [30]atari results, [31]brett from
       [32]pieter abbeel's group, and [33]alphago all used deep rl
       algorithms which did not make too many assumptions about their
       environment, and thus can be applied in other settings.

   however, rl research is also slowed down by two factors:
     * the need for better benchmarks. in supervised learning, progress
       has been driven by large labeled datasets like [34]id163. in rl,
       the closest equivalent would be a large and diverse collection of
       environments. however, the existing open-source collections of rl
       environments don't have enough variety, and they are often
       difficult to even set up and use.
     * lack of standardization of environments used in publications.
       subtle differences in the problem definition, such as the reward
       function or the set of actions, can drastically alter a task's
       difficulty. this issue makes it difficult to reproduce published
       research and compare results from different papers.

   openai gym is an attempt to fix both problems.
     __________________________________________________________________

the environments

   openai gym provides a diverse suite of environments that range from
   easy to difficult and involve many different kinds of data. we're
   starting out with the following collections:
     * [35]classic control and [36]toy text: complete small-scale tasks,
       mostly from the rl literature. they're here to get you started.
     * [37]algorithmic: perform computations such as adding multi-digit
       numbers and reversing sequences. one might object that these tasks
       are easy for a computer. the challenge is to learn these algorithms
       purely from examples. these tasks have the nice property that it's
       easy to vary the difficulty by varying the sequence length.
     * [38]atari: play classic atari games. we've integrated the
       [39]arcade learning environment (which has had a big impact on
       id23 research) in an [40]easy-to-install form.
     * [41]board games: play go on 9x9 and 19x19 boards. two-player games
       are fundamentally different than the other settings we've included,
       because there is an adversary playing against you. in our initial
       release, there is a fixed opponent provided by [42]pachi, and we
       may add other opponents later (patches welcome!). we'll also likely
       expand openai gym to have first-class support for multi-player
       games.
     * [43]2d and 3d robots: control a robot in simulation. these tasks
       use the [44]mujoco physics engine, which was designed for fast and
       accurate robot simulation. included are some environments from a
       recent [45]benchmark by uc berkeley researchers (who incidentally
       will be [46]joining us this summer). mujoco is proprietary
       software, but offers [47]free trial licenses.

   over time, we plan to greatly expand this collection of environments.
   contributions from the community are more than welcome.

   each environment has a version number (such as [48]hopper-v0). if we
   need to change an environment, we'll bump the version number, defining
   an entirely new task. this ensures that results on a particular
   environment are always comparable.
     __________________________________________________________________

evaluations

   we've made it easy to [49]upload results to openai gym. however, we've
   opted not to create traditional leaderboards. what matters for research
   isn't your score (it's possible to overfit or hand-craft solutions to
   particular tasks), but instead the generality of your technique.

   we're starting out by maintaining a [50]curated list of contributions
   that say something interesting about algorithmic capabilities.
   long-term, we want this curation to be a community effort rather than
   something owned by us. we'll necessarily have to figure out the details
   over time, and we'd would love your [51]help in doing so.
     __________________________________________________________________

   we want openai gym to be a community effort from the beginning. we've
   starting working with partners to put together resources around openai
   gym:
     * [52]nvidia: technical [53]q&a with john.
     * [54]nervana: implementation of a [55]id25 openai gym agent.
     * [56]amazon web services (aws): $250 credit vouchers for select
       openai gym users. if you have an evaluation demonstrating the
       promise of your algorithm and are resource-constrained from scaling
       it up, [57]ping us for a voucher. (while supplies last!)

   during the public beta, we're looking for feedback on how to make this
   into an even better tool for research. if you'd like to help, you can
   try your hand at improving the state-of-the-art on each environment,
   reproducing other people's results, or even implementing your own
   environments. also please join us in the [58]community chat!
     __________________________________________________________________

   authors
   [59]greg brockman[60]john schulman
     __________________________________________________________________

     * [61]about
     * [62]progress
     * [63]resources
     * [64]blog
     * [65]charter
     * [66]jobs
     * [67]press

     *
     *

   sign up for our newsletter
   ____________________ (button)
   right

references

   visible links
   1. https://openai.com/blog/rss/
   2. https://openai.com/about/
   3. https://openai.com/progress/
   4. https://openai.com/resources/
   5. https://openai.com/blog/
   6. https://openai.com/about/
   7. https://openai.com/progress/
   8. https://openai.com/resources/
   9. https://openai.com/blog/
  10. https://openai.com/jobs/
  11. https://gym.openai.com/
  12. https://openai.com/blog/openai-gym-beta/#rl
  13. https://gym.openai.com/envs
  14. https://gym.openai.com/envs/humanoid-v0
  15. https://gym.openai.com/envs/mspacman-v0
  16. https://gym.openai.com/envs/cartpole-v0#feed
  17. https://www.tensorflow.org/
  18. https://github.com/theano/theano
  19. https://gym.openai.com/docs
  20. https://gym.openai.com/evaluations/eval_umw59dycqe6j75lxtmpa
  21. https://gym.openai.com/evaluations/eval_lei8i8v2qlqegzbxcvriaa
  22. https://gym.openai.com/evaluations/eval_glkkkintm6glmcoqrzuhq
  23. https://gym.openai.com/envs/humanoid-v0
  24. https://gym.openai.com/envs/hopper-v0
  25. https://gym.openai.com/envs#atari
  26. https://gym.openai.com/envs#board_game
  27. http://arxiv.org/abs/1511.06732
  28. http://arxiv.org/abs/0907.0786
  29. http://arxiv.org/abs/1601.01705
  30. https://deepmind.com/id25.html
  31. http://news.berkeley.edu/2015/05/21/deep-learning-robot-masters-skills-via-trial-and-error/
  32. https://openai.com/blog/welcome-pieter-and-shivon
  33. https://googleblog.blogspot.com/2016/01/alphago-machine-learning-game-go.html
  34. http://www.image-net.org/
  35. https://gym.openai.com/envs#classic_control
  36. https://gym.openai.com/envs#toy_text
  37. https://gym.openai.com/envs#algorithmic
  38. https://gym.openai.com/envs#atari
  39. http://www.arcadelearningenvironment.org/
  40. https://github.com/openai/gym#atari
  41. https://gym.openai.com/envs#board_games
  42. http://pachi.or.cz/
  43. https://gym.openai.com/envs#mujoco
  44. http://www.mujoco.org/
  45. http://arxiv.org/abs/1604.06778
  46. https://openai.com/blog/team-plus-plus/
  47. https://www.roboti.us/trybuy.html
  48. https://gym.openai.com/envs/hopper-v0
  49. https://gym.openai.com/docs#uploading
  50. https://gym.openai.com/docs#review
  51. https://gym.openai.com/docs#help
  52. http://www.nvidia.com/
  53. https://devblogs.nvidia.com/parallelforall/train-reinforcement-learning-agents-openai-gym
  54. http://www.nervanasys.com/
  55. http://www.nervanasys.com/openai
  56. https://aws.amazon.com/
  57. mailto:gym@openai.com
  58. https://gym.openai.com/chat
  59. https://openai.com/blog/authors/greg/
  60. https://openai.com/blog/authors/john/
  61. https://openai.com/about/
  62. https://openai.com/progress/
  63. https://openai.com/resources/
  64. https://openai.com/blog/
  65. https://openai.com/charter/
  66. https://openai.com/jobs/
  67. https://openai.com/press/

   hidden links:
  69. https://openai.com/
  70. https://openai.com/
  71. https://twitter.com/openai
  72. https://www.facebook.com/openai.research
