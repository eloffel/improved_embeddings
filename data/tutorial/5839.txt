   [1]fork me on github

   [loop.svg]

reinforcejs

     * [2]about
     * [3]gridworld: dp
     * [4]gridworld: td
     * [5]puckworld: id25
     * [6]waterworld: id25

   # about **reinforcejs** is a id23 library that
   implements several common rl algorithms supported with fun web demos,
   and is currently maintained by
   [@karpathy](https://twitter.com/karpathy). in particular, the library
   currently includes: ### id145 for solving finite (and not
   too large), deterministic mdps. the solver uses standard tabular
   methods will no bells and whistles, and the environment must provide
   the dynamics.
   [dpsolved.jpeg]
   right: a simple gridworld solved with a id145. very
   exciting. head over to the [7]gridworld: dp demo to play with the
   gridworld environment and policy iteration.
   ### tabular temporal difference learning both sarsa and id24 are
   included. the agent still maintains tabular value functions but does
   not require an environment model and learns from experience. support
   for many bells and whistles is also included such as eligibility traces
   and planning (with priority sweeps). ### deep id24
   reimplementation of [mnih et
   al.](http://www.nature.com/nature/journal/v518/n7540/full/nature14236.h
   tml) atari game playing model. the approach models the action value
   function q(s,a) with a neural network and hence allows continuous input
   spaces. however, with a fixed number of discrete actions. the
   implementation includes most of the bells and whistles (e.g. experience
   replay, td error clamping for robustness). ### policy gradients the
   implementation includes a stochastic policy gradient agent that uses
   reinforce and lstms that learn both the actor policy and the value
   function baseline, and also an implementation of recent deterministic
   policy gradients by [silver et
   al](http://www0.cs.ucl.ac.uk/staff/d.silver/web/publications_files/dete
   rministic-policy-gradients.pdf). to make a lot of this happen (e.g.
   lstms in particular), the library includes a fork of my previous
   project [recurrentjs](https://github.com/karpathy/recurrentjs), which
   allows one to set up graphs of computations over matrices and perform
   automatic backprop. i do not include the demo for policy gradient
   methods because the current implementations are unfortunately finicky
   and unstable (both stochastic and deterministic). i still include the
   code in the library in case someone wants to poke around. i suspect
   that either there are bugs (it's proving difficult to know for sure),
   or i'm missing some tips/tricks needed to get them to work reliably. #
   example library usage including the library (currently there is no
   nodejs support out of the box): ```javascript ``` for most applications
   (e.g. simple games), the id25 algorithm is a safe bet to use. if your
   project has a finite state space that is not too large, the dp or
   tabular td methods are more appropriate. as an example, the id25 agent
   satisfies a very simple api:
// create an environment object
var env = {};
env.getnumstates = function() { return 8; }
env.getmaxnumactions = function() { return 4; }

// create the id25 agent
var spec = { alpha: 0.01 } // see full options on id25 page
agent = new rl.id25agent(env, spec);

setinterval(function(){ // start the learning loop
  var action = agent.act(s); // s is an array of length 8
  //... execute action in environment and get the reward
  agent.learn(reward); // the agent improves its q,policy,model, etc. reward is
a float
}, 0);

   in other words, you pass the agent some vector and it gives you an
   action. then you reward or punish its behavior with the `reward`
   signal. the agent will over time tune its parameters to maximize the
   rewards it obtains. the full source code is on [8]github under the mit
   license.

references

   1. https://github.com/karpathy/reinforcejs
   2. https://cs.stanford.edu/people/karpathy/reinforcejs/index.html
   3. https://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_dp.html
   4. https://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_td.html
   5. https://cs.stanford.edu/people/karpathy/reinforcejs/puckworld.html
   6. https://cs.stanford.edu/people/karpathy/reinforcejs/waterworld.html
   7. https://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_dp.html
   8. https://github.com/karpathy/reinforcejs
