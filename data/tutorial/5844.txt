   #[1]unity technologies blog    feed [2]unity technologies blog   
   comments feed [3]unity technologies blog    introducing: unity machine
   learning agents toolkit comments feed [4]alternate [5]alternate
   [6]alternate [7]alternate [8]alternate [9]alternate [10]alternate
   [11]alternate [12]alternate [13]alternate [14]alternate [15]alternate
   [16]alternate [17]alternate

   iframe: [18]//www.googletagmanager.com/ns.html?id=gtm-5hxf38

     * [19]products
     * [20]solutions
     * [21]made with unity
     * [22]learn
     * [23]community
     * [24]asset store
     * [25]get unity

     * [26]forums
     * [27]answers
     * [28]feedback
     * [29]issue tracker
     * [30]blog
     * [31]beta program
     * [32]evangelists
     * [33]user groups
     * [34]advisory panel

search unity

     * [35]home
     * [36]products
     * [37]solutions
     * [38]made with unity
     * [39]learn
     * [40]community
     * [41]asset store
     * [42]get unity

   language
     * [43]      
     * [44]espa  ol
     * [45]         
     * [46]         
     * [47]portugu  s

   [48]

unity blog

   [49]subscribe to rss
   ____________________ go

introducing: unity machine learning agents toolkit

   [50]arthur juliani, september 19, 2017
   [51]machine learning

   our two [52]previous [53]blog entries implied that there is a role
   games can play in driving the development of id23
   algorithms. as the world   s most popular creation engine, unity is at
   the crossroads between machine learning and gaming. it is critical to
   our mission to enable machine learning researchers with the most
   powerful training scenarios, and for us to give back to the gaming
   community by enabling them to utilize the latest machine learning
   technologies. as the first step in this endeavor, we are excited to
   introduce [54]unity machine learning agents toolkit.

   iframe: [55]https://www.youtube.com/embed/tmoz3ojbtn0

training intelligent agents

   machine learning is changing the way we expect to get intelligent
   behavior out of autonomous agents. whereas in the past the behavior was
   coded by hand, it is increasingly taught to the agent (either a robot
   or virtual avatar) through interaction in a training environment. this
   method is used to learn behavior for everything from industrial robots,
   drones, and autonomous vehicles, to game characters and opponents. the
   quality of this training environment is critical to the kinds of
   behaviors that can be learned, and there are often trade-offs of one
   kind or another that need to be made. the typical scenario for training
   agents in virtual environments is to have a single environment and
   agent which are tightly coupled. the actions of the agent change the
   state of the environment, and provide the agent with rewards.

   unity analytics, machine learning, ai

   the typical id23 training cycle.

   at unity, we wanted to design a system that provide greater flexibility
   and ease-of-use to the growing groups interested in applying machine
   learning to developing intelligent agents. moreover, we wanted to do
   this while taking advantage of the high quality physics and graphics,
   and simple yet powerful developer control provided by the unity engine
   and editor. we think that this combination can benefit the following
   groups in ways that other solutions might not:
     * academic researchers interested in studying complex multi-agent
       behavior in realistic competitive and cooperative scenarios.
     * industry researchers interested in large-scale parallel training
       regimes for robotics, autonomous vehicle, and other industrial
       applications.
     * game developers interested in filling virtual worlds with
       intelligent agents each acting with dynamic and engaging behavior.

unity machine learning agents toolkit

   we call our solution [56]unity machine learning agents toolkit
   (ml-agents toolkit for short), and are happy to be releasing an open
   beta version of our sdk today! the ml-agents sdk allows researchers and
   developers to transform games and simulations created using the unity
   editor into environments where intelligent agents can be trained using
   deep id23, evolutionary strategies, or other machine
   learning methods through a simple to use python api. we are releasing
   this beta version of unity ml-agents toolkit as open-source software,
   with a set of example projects and baseline algorithms to get you
   started. as this is an initial beta release, we are actively looking
   for feedback, and encourage anyone interested to contribute on our
   [57]github page. for more information on unity ml-agents toolkit,
   continue reading below! for more detailed documentation, see our
   [58]github wiki.

learning environments

   learning agents, ai, machine learning, unity analytics

   a visual depiction of how a learning environment might be configured
   within unity ml-agents toolkit.

   the three main kinds of objects within any learning environment are:
     * agent     each agent can have a unique set of states and
       observations, take unique actions within the environment, and
       receive unique rewards for events within the environment. an
       agent   s actions are decided by the brain it is linked to.
     * brain     each brain defines a specific state and action space, and
       is responsible for deciding which actions each of its linked agents
       will take. the current release supports brains being set to one of
       four modes:
          + external     action decisions are made using tensorflow (or your
            ml library of choice) through communication over an open
            socket with our python api.
          + internal (experimental)     actions decisions are made using a
            trained model embedded into the project via
            [59]tensorflowsharp.
          + player     action decisions are made using player input.
          + heuristic     action decisions are made using hand-coded
            behavior.
     * academy     the academy object within a scene also contains as
       children all brains within the environment. each environment
       contains a single academy which defines the scope of the
       environment, in terms of:
          + engine configuration     the speed and rendering quality of the
            game engine in both training and id136 modes.
          + frameskip     how many engine steps to skip between each agent
            making a new decision.
          + global episode length     how long the episode will last. when
            reached, all agents are set to done.

   the states and observations of all agents with brains set to external
   are collected by the external communicator, and communicated to our
   python api for processing using your ml library of choice. by setting
   multiple agents to a single brain, actions can be decided in a batch
   fashion, opening the possibility of getting the advantages of parallel
   computation, when supported. for more information on how these objects
   work together within a scene, see our [60]wiki page.

flexible training scenarios

   with unity ml-agents toolkit, a variety of training scenarios are
   possible, depending on how agents, brains, and rewards are connected.
   we are excited to see what kinds of novel and fun environments the
   community creates. for those new to training intelligent agents, below
   are a few examples that can serve as inspiration. each is a
   prototypical environment configurations with a description of how it
   can be created using the ml-agents sdk.
     * single-agent     a single agent linked to a single brain. the
       traditional way of training an agent. an example is any
       single-player game, such as chicken. (demo project included    
          gridworld   )

   iframe: [61]https://www.youtube.com/embed/fiqsmdwegt8

     * simultaneous single-agent     multiple independent agents with
       independent reward functions linked to a single brain. a
       parallelized version of the traditional training scenario, which
       can speed-up and stabilize the training process. an example might
       be training a dozen robot-arms to each open a door simultaneously.
       (demo project included        3dball   )

   iframe: [62]https://www.youtube.com/embed/fq0jbaicyna

     * adversarial self-play     two interacting agents with inverse reward
       functions linked to a single brain. in two-player games,
       adversarial self-play can allow an agent to become increasingly
       more skilled, while always having the perfectly matched opponent:
       itself. this was the strategy employed when training alphago, and
       more recently used by openai to train a [63]human-beating 1v1 dota
       2 agent. (demo project included        tennis   )
     * cooperative multi-agent     multiple interacting agents with a shared
       reward function linked to either a single or multiple different
       brains. in this scenario, all agents must work together to
       accomplish a task than couldn   t be done alone. examples include
       environments where each agent only has access to partial
       information, which needs to be shared in order to accomplish the
       task or collaboratively solve a puzzle. (demo project coming soon)
     * competitive multi-agent     multiple interacting agents with inverse
       reward function linked to either a single or multiple different
       brains. in this scenario, agents must compete with one another to
       either win a competition, or obtain some limited set of resources.
       all team sports would fall into this scenario. (demo project coming
       soon)
     * ecosystem     multiple interacting agents with independent reward
       function linked to either a single or multiple different brains.
       this scenario can be thought of as creating a small world in which
       animals with different goals all interact, such a savanna in which
       there might be zebras, elephants, and giraffes, or an autonomous
       driving simulation within an urban environment. (demo project
       coming soon)

additional features

   beyond the flexible training scenarios made possible by the
   academy/brain/agent system, the unity ml-agents toolkit also includes
   other features which improve the flexibility and interpretability of
   the training process.
     * monitoring agent   s decision making     since communication in unity
       ml-agents toolkit is a two-way street, we provide an agent monitor
       class in unity which can display aspects of the trained agent, such
       as policy and value output within the unity environment itself. by
       providing these outputs in real-time, researchers and developers
       can more easily debug an agent   s behavior.

   unity machine learning, ai, analytics, learning-agents

   above each agent is a value estimate, corresponding to how much future
   reward the agent expects. when the right agent misses the ball, the
   value estimate drops to zero, since it expects the episode to end soon,
   resulting in no additional reward.
     * curriculum learning     it is often difficult for agents to learn a
       complex task at the beginning of the training process. curriculum
       learning is the process of gradually increasing the difficulty of a
       task to allow more efficient learning. the unity ml-agents toolkit
       supports setting custom environment parameters every time the
       environment is reset. this allows elements of the environment
       related to difficulty or complexity to be dynamically adjusted
       based on training progress.

   unity analytics, machine learning, ai, unity

   different possible configurations of the gridworld environment with
   increasing complexity.
     * complex visual observations     unlike other platforms, where the
       agent   s observation might be limited to a single vector or image,
       the unity ml-agents toolkit allows multiple cameras to be used for
       observations per agent. this enables agents to learn to integrate
       information from multiple visual streams, as would be the case when
       training a self-driving car which required multiple cameras with
       different viewpoints, a navigational agent which might need to
       integrate aerial and first-person visuals, or an agent which takes
       both a raw visual input, as well as a depth-map or object-segmented
       image.

   two different camera views on the same environment. when both are
   provided to an agent, it can learn to utilize both first-person and
   map-like information about the task to defeat the opponent.
     * imitation learning (coming soon)     it is often more intuitive to
       simply demonstrate the behavior we want an agent to perform, rather
       than attempting to have it learn via trial-and-error methods. in a
       future release, the unity ml-agents toolkit will provide the
       ability to record all state/action/reward information for use in
       supervised learning scenarios, such as imitation learning. by
       utilizing imitation learning, a player can provide demonstrations
       of how an agent should behave in an environment, and then utilize
       those demonstrations to train an agent in either a standalone
       fashion, or as a first-step in a id23 process.

an evolving platform

   as mentioned above, we are excited to be releasing this open beta
   version of unity machine learning agents toolkit today, which can be
   downloaded from our [64]github page. this release is only the
   beginning, and we plan to iterate quickly and provide additional
   features for both those of you who are interested in unity as a
   platform for machine learning research, and those of you who are
   focused on the potential of machine learning in game development. while
   this beta release is more focused on the former group, we will be
   increasingly providing support for the latter use-case. as mentioned
   above, we are especially interested in hearing about use-cases and
   features you would like to see included in future releases of unity
   ml-agents toolkit, and we will be welcoming pull requests made to the
   github repository. please feel free to reach out to us at
   [65]ml-agents@unity3d.com to share feedback and thoughts. if the
   project sparks your interests, come join [66]the unity machine learning
   team!

   happy training!

related posts

[67]the obstacle tower challenge is live!

   [68]arthur juliani
   february 18, 2019   [69]5
   [70]machine learning [71]technology

[72]obstacle tower challenge: test the limits of intelligence systems

   [73]danny lange
   january 28, 2019   [74]14
   [75]community [76]machine learning

[77]fostering ai research: meet us at aaai-19

   [78]marwan mattar +1
   january 18, 2019   [79]2
   [80]machine learning [81]technology

[82]ml-agents toolkit v0.6: improved usability of brains and imitation
learning

   [83]vincent-pierre berges
   december 17, 2018   [84]4
   [85]machine learning [86]technology

[87]how to get the most out of friend invites in your app

   [88]caitlin w
   november 28, 2018   [89]13
   [90]asset store

[91]introducing unity   s guiding principles for ethical ai

   [92]unity technologies
   november 28, 2018   [93]5
   [94]machine learning

72 comments

   [95]subscribe to comments

   comments are closed.
    1. ruben aster
       [96]november 12, 2017 at 4:07 pm
       damn that   s cool! :)
       so, what i   ve noticed is that agents have a list of states with a
       fixed size, which is ok when you have a constant environment like 1
       ball and 1 platform that tries to keep the ball on it.
       but how about having enemies which spawn dynamically? or when these
       enemies shoot bullets? we   d need a dynamic list of states for that.
       how would you implement this scenario?
    2. kirby
       [97]november 4, 2017 at 11:19 pm
       heads up, you have a dead link:
       > for more information on how these objects work together within a
       scene, see our wiki page.
          wiki page    currently points here:
       [98]https://github.com/unity-technologies/python-rl-control/wiki
       that repo doesn   t appear to exist anymore.
    3. paul
       [99]november 4, 2017 at 10:38 pm
       i   m happy because this looks cool. but i   m sad because i didn   t
       think of it first! :'(
    4. krishnan
       [100]november 3, 2017 at 7:19 pm
       awesome!
       when do we have more algorithms than just ppo?
    5. riya bansal
       [101]november 3, 2017 at 10:33 am
       thanks for sharing such a wonderful article.
       [102]http://www.broachindia.com/
    6. shrey pareek
       [103]october 31, 2017 at 5:09 pm
       hello,
       this seems like a great toolbox for integrating unity with python.
       a quick question though. any clue when the imitation learning tool
       would be available?
       thank you
    7. michael knight
       [104]october 30, 2017 at 2:21 am
       thanks for writing this article. i   ve always been interested in
       a.i. i would love to apply some of this to our knight o.s. project.
       [105]http://myknightrider2000.blogspot.ca
    8. arthur drikis
       [106]october 27, 2017 at 11:35 am
       hi,
       it   s a great tool and i   ve been really enjoying working with it the
       last few days.
       though, while messing around with it, i   ve noticed that the
       training process itself uses only about 12% of gpu power and around
       50% of my cpu.
       am i missing some feature that would let me to use the gpu to its
       full potential?
         1. arthur juliani
            [107]october 27, 2017 at 5:11 pm
            hi arthur,
            you are correct in noticing that the id23
            algorithm we use (ppo) isn   t as gpu efficient as it could be.
            the problem stems from the fact that the network is used in
            two ways: deciding actions (id136) and training (gradient
            descent). if the batch size is large enough, the training step
            can fully utilize the gpu. however, during experience
            collection, the network is only being used to pick actions,
            and this is much less computationally efficient. there are
            possible methods for better utilizing the gpu, such as having
            separate threads collect experience and update the network.
            these however add complexity to the system, and require tuning
            in and of themselves to ensure they are providing the level of
            benefit desired. it is something we are aware of, and will be
            keeping in mind as we develop future algorithms.
              1. arthur drikis
                 [108]october 31, 2017 at 2:58 pm
                 thanks for the reply!
                 i would like to ask another question, though.
                 so far i haven   t been able to successfully train a neural
                 network in any environment other than 3dball.
                 in tennis i got to around 18m steps, and the cumulative
                 reward seems to be stagnant with seemingly random spikes:
                 [109]http://prntscr.com/h4dhaq
                 while training with gridworld it looks like i   ve been
                 getting worse and worse results. so far i   m at 4.5m
                 steps, and the reward is just going down.
                 [110]http://prntscr.com/h4diha
                 i tried to mess around with buffer size, batch size and
                 hidden unit amount, but it didn   t seem to make much of a
                 difference.
                 what am i doing wrong here?
                 should i just wait for more steps?
                 also, it would be really cool if we could get our hands
                 on the values that were used for training the pre-trained
                 tf models for each of the examples.
    9. data science training in hyderabad
       [111]october 25, 2017 at 2:43 pm
       hi,
       thanks for sharing such a wonderful article with us
       we are expecting more articles from this blog
   10. andrea maria
       [112]october 25, 2017 at 11:52 am
       thank you for the information. machine learning has its roots in
       statistics and mathematical optimization. machine learning covers
       techniques in supervised and unsupervised learning for applications
       in prediction, analytics, and data mining. if you want machine
       learning services.
       visit:[113]https://www.usmsystems.com/machine-learning/
   11. analyticspath
       [114]october 23, 2017 at 1:13 pm
       thanks for the valuable information about machine learning and
       other professional courses trend setting today.
       if any doubts regarding machine learning please visit this website
       [115]http://www.analyticspath.com/machine-learning-training-in-hyde
       rabad
   12. duyth
       [116]october 21, 2017 at 4:20 am
       sorry, i failed to understand but after running the 3dball
       training, what   s the outcome from the training / i mean, is there a
       result file that we can get & reuse ?
         1. arthur juliani
            [117]october 21, 2017 at 8:46 pm
            yep! you get a model file that you can add back into the
            project itself. see the getting started guide for more info:
            [118]https://github.com/unity-technologies/ml-agents/blob/mast
            er/docs/getting-started-with-balance-ball.md#embedding-trained
            -brain-into-unity-environment-experimental
   13. anonymous
       [119]october 19, 2017 at 9:14 am
       just curious. can i use this on android, ios platform?
       even if it did, i guess with unity as middle interpreter of python
       code, it will be overkill for normal phone cpu.
         1. arthur juliani
            [120]october 20, 2017 at 3:01 am
            hi zara, by using our    internal    brain, and the
            tensorflowsharp plugin, you can put trained brains into
            projects for android and ios. you just won   t be able to do the
            actual training on those devices. for more information, see
            here:
            [121]https://github.com/unity-technologies/ml-agents/blob/mast
            er/docs/using-tensorflow-sharp-in-unity-(experimental).md
   14. jeffrey
       [122]october 16, 2017 at 5:42 pm
       i really love this. i   ve been playing with it for the last three
       days.
       what i really need now, as a ml newb, is a step-by-step guide that
       answers a few questions. i understand that this isn   t a good place
       for answering questions. i don   t want answers here. just hoping
       that in time these questions will be answered in the documentation
       section of ml-agents on github. thanks!
       what is the workflow? when i run the training, do i    load saved
       model   ? should i only be running a training once? if i run it
       multiple times does it keep learning? it seems my agent gets worse
       at tasks, not better even though i feel like i   m rewarding
       correctly. there is clearly some learning going on but if i leave
       it going overnight (6-8 hours) there doesn   t seem to be any
       improvement.
       do i run a training many times in a row by finishing one, then
       immediately rerunning the ppo script? or do i need to set
       everything up. set the steps to a crazy number. run once. export
       model?
       how do i set up the cameras? is there more than just adding them to
       the agent? do i need to set up the    resolution    stuff in the brain?
       along with a tuning guide. steps. learning rate. what to change if
       things don   t seem to go right. and how long for simple tasks.
         1. arthur juliani
            [123]october 16, 2017 at 10:44 pm
            hi jeffrey,
            glad to hear that you are enjoying playing around with it!
            when you run the ppo notebook (or ppo.py) the neural network
            model will be trained for the number of steps set in
            max_steps. if you interrupt training, you can set load_model
            to true, and then continue training. once you reach the
            max_steps, if your model isn   t sufficiently trained you can
            continue training by increasing max_steps. i would recommend
            looking at the tensorboard logs though to track performance.
            if your reward isn   t gradually increasing over time, there may
            be issues with the reward structure of the environment, or the
            agent may not be getting the information it needs to solve the
            task. we have a preliminary    best practices    document for
            creating environments
            [124]https://github.com/unity-technologies/ml-agents/blob/mast
            er/docs/best-practices.md , but i agree that it would be a
            good idea to add a similar page for the training process
            itself, and that is something we will work on putting
            together.
   15. chris
       [125]october 14, 2017 at 11:31 pm
       this is a great topic to dive into!
   16. swordmaster swordmaster
       [126]october 13, 2017 at 3:37 pm
       great    i developed an asset about machine learning for unity as
       well :
       [127]https://www.assetstore.unity3d.com/en/#!/content/93236
       this id158s chose the back propagation
       algorithm to learn something,and the demo is
       about a car learning how to get out of the maze.
   17. sergei
       [128]october 7, 2017 at 12:18 pm
       will there be future training with the teacher? learning for the
       known action for the state list. data, for example, is collected in
       player mode. data type state list -> action list
         1. arthur juliani
            [129]october 7, 2017 at 10:23 pm
            hi sergei,
            this feature is what we are calling    imitation learning.    it
            will be coming in the next release, which we hope to have out
            in the next few weeks!
   18. michael
       [130]october 5, 2017 at 5:08 am
       i   m trying to fallow the getting started with the balance ball
       example tutorial and i managed to get through the tutorial on how
       to set up python/tensorflow
       ([131]http://blog.nitishmutha.com/tensorflow/2017/01/22/tensorflow-
       with-gpu-for-windows.html) via the tutorial that was linked in the
       balance ball example tutorial. but when i try to run the jupyter
       ppo table i get this error :
       modulenotfounderror traceback (most recent call last)
       in ()
       1 import numpy as np
       2 import os
          -> 3 import tensorflow as tf
       4
       5 from ppo.history import *
       modulenotfounderror: no module named    tensorflow   
       i   m not sure what i did wrong or what to try to do to fix this :(
       any ideas at all would be helpful.
         1. michael
            [132]october 5, 2017 at 6:01 am
            ok, so i was actually able to get past that last error above.
            i just did not realize i needed to install tensor into the
            python folder, my bad. but i do have a another question. i am
            having trouble observing the training process. i open anaconda
            and put in the tensorboard    logdir=   summaries line and it runs
            but i   m not able to do anything else without stopping it and i
            don   t see anything that shows me how the training is going. i
            let the training go on for a few minutes and then continued to
            the last cell and then continue past that and then stop
            running the table by pressing the interrupt kernel button. i
            look in the models folder but i don   t see an exported model. i
            do see model-50000.cptk.index and some other files but not a
            3dball.bytes so i am confused on how to properly end running
            the cells or if i did something else wrong. any help would be
            welcome.
              1. arthur juliani
                 [133]october 6, 2017 at 1:49 am
                 hi michael, you need to launch a web browser and navigate
                 to localhost:6006 to view the training information once
                 launching tensorboard.
                 i am unsure why you aren   t seeing the .bytes file. do you
                 get a message letting you know it was created when you
                 run that cell?
   19. andre infante
       [134]september 29, 2017 at 1:00 am
       is there a timeline for supervised learning support? i have an
       application that would be much easier to train with supervision,
       and am not sure if i should wait or try to get it to train with the
       existing rl support.
         1. arthur juliani
            [135]september 30, 2017 at 5:53 am
            hi andre,
            we are currently actively developing the imitation learning
            support, and hope to have it out within a few weeks. if you
            are adventurous, you can check out the dev-broadcast branch of
            the repository, where we are developing it. the feature allows
            brain types besides external to    broadcast    their
            states/actions to the python api for use in supervised
            learning. of course, it is still in development so there will
            likely be bugs. if you happen to find any, please let us know!
              1. andre infante
                 [136]october 1, 2017 at 10:08 pm
                 i will check it out, thank you!
   20. max
       [137]september 26, 2017 at 11:02 am
       arthur,
       could you help me and stitch together your implementation of a3c
       algo into this?
       i am looking at it but porting model seems to be above my skillset.
       if not, i would gladly accept a short how-to of how shall i do it.
       thanks!
         1. arthur juliani
            [138]september 26, 2017 at 6:18 pm
            hi max,
            we include an implementation of ppo with ml-agents. ppo is a
            more reliable and efficient algorithm than a3c, so it is
            included instead. one difference is that the included ppo
            isn   t asynchronous, but it could be made to be though some
            adjustments.
            [139]https://github.com/unity-technologies/ml-agents/tree/mast
            er/python
              1. max
                 [140]september 27, 2017 at 10:00 am
                 thanks for pointing me in the right direction!
                 i reevaluated my approach and found a way to do my thing
                 with ppo, where i will (maybe, will see how it will work
                 without it) apply ga for evolutionary reasons.
                 i have another question tho, when i set 2 brains in
                 academy, i change every    brain_name    to    name    inside
                    for name in env.brain_names:   , but get this error:     you
                 have 2 brains, you need to feed a dictionary of brain
                 names a keys, and actions as values   , at line    new_info =
                 trainer.take_action(info, env, name)   . can you show me
                 how to properly feed it?
                 thanks!
   21. bart burkhardt
       [141]september 26, 2017 at 10:44 am
       i got the 3dball project to work using the jupyter notebook.
       but it looks like unity is running at 1 fps. also it starts in a
       tiny window,
       is it supposed to be so slow when learning? i tried on a nvidia
       1060 and 1070
         1. arthur juliani
            [142]september 26, 2017 at 6:16 pm
            hi bart. when training, we speed up the engine to 100x, which
            causes a drop in frame-rate. although it looks slow, the
            engine is actually processing thousands of steps of
            simulation, and is running correctly.
   22. ryan potter
       [143]september 25, 2017 at 7:29 pm
       oh,    . you just made my day. i was attempting to use unity a few
       months ago as the environment in my ai research, but was struggling
       with implementing the ml algorithms i needed (id98s, anns, etc) with
       c#. i put it on ice and switched to a home-brew 2d environment in
       python on linux so i could make progress on the ai, keeping basic
       unity-like structure so i could switch back at some point easily.
       looks like i can switch back now :)
       this is so perfect.
       thank you!!
   23. lee
       [144]september 25, 2017 at 9:32 am
       where is sample project files of these games ml used in this blog
       thread?
         1. arthur juliani
            [145]september 25, 2017 at 8:12 pm
            hi lee,
            you can find the example projects in the repository here:
            [146]https://github.com/unity-technologies/ml-agents .
   24. mikejmc
       [147]september 25, 2017 at 7:32 am
       exciting direction    any plans to work with apple   s ml framework and
       swift?
   25. tejas ramanuj
       [148]september 25, 2017 at 4:40 am
       how to get started with unity machine learning
   26. xype
       [149]september 23, 2017 at 4:27 pm
       oh and well i could at least try to help you out if you insist on
       continuing down this space when you could be spending the money
       completing features you have been putting off for a couple of years
       now which are more important   ..
       you should talk to some of the colleges that focus on behavioural
       analysis and study.
       [150]http://paco.psy.gla.ac.uk/index.php?option=com_jdownloads&view
       =viewcategories&itemid=62 is an example there are 2 or 3 focused on
       this niche of research, that particular one uses mocap systems,
       taking volunteers to do natural motion, then studying and
       programming computers to recognize gender, attitude, and emotion
       from body motion. another focuses on interaction between humans,
       and even more on general physics and flow of movement. a last one i
       try to avoid because it is funded by darpa and that just spooks me.
       it is the recognition from a distance project. ties right into
       this, and those schools would llikely be happy to provide you with
       their research, publications, and findings if you in turn expand
       their knowledgebase and cases by publishing your own findings based
       on the research guidelines defined in the project licenses to use
       the mocap databases. ai learning should definately be learning
       cases of how to react based on subtle actions of the thing it is
       interfacing against.
   27. xype
       [151]september 23, 2017 at 4:16 pm
       eh this is really interesting stuff, however as a content
       creation/game development/high end rendering platform which is
       awesome but has a lot of bugs and a undeserved bad reputation, i
       really do not thing you need to be here. besides aren   t you guys
       afraid of ai   maybe it is time for hollywood to remake the old hal
          would you like to play a game       .
       funny i saw an asset the other day that started with hal, i don   t
       even know what it was, i saw that much and changed the page.
   28. michael bechauf
       [152]september 22, 2017 at 1:17 am
       really cool demo! i was able to run the 3dball code and it worked
       nicely. a few questions though    
       how do you run the tennis application? i did not find any
       instructions, so i assumed it would also require the ppo notebook,
       but training took a very long time. when i stopped training after
       1000 iterations, and tried to persist the binary model, i got the
       error attributeerror:    nonetype    object has no attribute
          model_checkpoint_path   . maybe i forgot something?
       second, why do you call the internal brain model experimental? is
       that simply because you load the tensorflow library into the unity
       engine which may cause instabilities?
       and finally, what are you plans regarding unity libraries? do you
       intend to develop your own ml models, or is the job of ml-agent
       essentially to provide convenient bindings to existing ml
       frameworks?
         1. arthur juliani
            [153]september 22, 2017 at 6:55 pm
            hi michael,
            you are right that training tennis takes longer     at least 1
            million steps. it is often the case that most complex
            id23 problems take in the millions of steps.
            for example, many atari games take roughly 200 million steps
            of training to achieve super-human performance.
            in order to create the binary file you need to have at least
            one model checkpoint saved. to make those saves happen more
            frequently, you can adjust save_freq in the hyperparameters.
            we refer to internal as    experimental    because it hasn   t been
            thoroughly tested enough for us to recommend to game
            developers as a method for actually controlling game-ai in
            released games. in the coming months we hope to provide a
            version we feel strongly enough about take the    experimental   
            tag off.
            with ml-agents we are currently supporting tensorflow
            integration, but if other solutions present themselves in the
            future we may explore them as well.
   29. renato vargas
       [154]september 21, 2017 at 6:08 pm
       i   m currently using v-rep for my research with rl. the project is
       game-related, but it   s also related to robotics, which it   s what
       prevents me from trying unity for this specific use case. for
       example, having a nao robot fully working ready for importing was
       really important.
       i know it   s not directly related to ml, but do you guys have any
       plans to expand more towards the field of robotics / having robot
       models available to researches?
       having said that, i   ll definitely try it on different projects!
   30. jordy henry
       [155]september 21, 2017 at 4:23 pm
       thats amazing, i have one question, can i pass a previous made
       dataset to the brain, lets say for example, i have one script that
       save all the inputs of my players, and i have access to it, and i
       want to turn all this input into a dataset, to start to train a
       brain based on it.
       it is possible ?
         1. arthur juliani
            [156]september 22, 2017 at 6:56 pm
            hi jordy,
            this feature is coming soon. you can read a little more about
            it above, under    imitation learning.   
   31. ramy dergham
       [157]september 21, 2017 at 2:57 pm
       what about the performance on mobile phones with games that
       contains huge number of states? a game like poker for example have
       a huge amount of states and it has a partial observable environment
       were the agent can   t see the opponent   s cards. is it possible to
       make use your ml for a game like poker on mobile platforms?
         1. arthur juliani
            [158]september 22, 2017 at 7:05 pm
            hi ramy,
            this is a good question! the state-size of the problem doesn   t
            necessarily increase the complexity of the model. for example,
            learning from an 8-bit 128x128x3 pixel image contains a huge
            state-space 256^49152, yet we can use convolutional networks
            with a few layers to learn to generalize between them. a
            network like that can actually run relatively easily on a
            phone.
            of course, on the other side of that is something like
            alphago, which ran on a supercomputer    i think for many games
            though it will be possible to distill the important
            information into a relatively small network which can
            generalize within the domain. especially as smartphones begin
            to integrate more powerful ml-specific hardware, like apple is
            doing with iphone x.
   32. jonney shih
       [159]september 21, 2017 at 11:00 am
       hi, when machine learning is run? in editor or runtime or both?
       also can it be done offline?
   33. sanghwa
       [160]september 21, 2017 at 7:31 am
       can i use pytorch instead of tensorflow?
         1. arthur juliani
            [161]september 22, 2017 at 7:06 pm
            hi,
            you can definitely use pytorch for training! the only thing
            that won   t be possible is to embed the trained pytorch model
            back into the unity game/simulation itself.
   34. liven
       [162]september 20, 2017 at 10:15 pm
       do we need python language knowledge for using ml-agent ?
         1. arthur juliani
            [163]september 20, 2017 at 10:27 pm
            good question. right now we are including a pre-made
            id23 algorithm called ppo with ml-agents.
            you should be able to use it to train simple agents without
            needing to understand how to modify it yourself.
            we understand though that many unity game developers mainly
            have expertise in c#, so we are exploring ways to enable
            developers to train agents without the need to manually
            interact with python.
              1. liven
                 [164]september 21, 2017 at 2:33 am
                 thank you for the answer.
                 really hope you   ll adapt the feature in c#.
                 right now, i am stuck at the    installing dependencies   
                 step and sent an email for details.
   35. andre
       [165]september 20, 2017 at 8:30 pm
       until now i had only seen the udacity self driving car demo that
       also worked with a socket connection. i could only get it to run on
       my old macbook tough. also i did the training on a cloud instance
       [166]https://medium.com/towards-data-science/introduction-to-udacit
       y-self-driving-car-simulator-4d78198d301d
       really looking forward to running the projects form this blogpost
       as well.
   36. berte adam
       [167]september 20, 2017 at 7:40 pm
       im having an issue with the installation of tensorflow, i   m running
       windows 8.1 64bit python 3.6.1 64bit anaconda 3
       [168]https://drive.google.com/open?id=0b6px6xu8ryexa2m2cg5befbsoe1i
       tknrcdrpy1lqavnkmetr
   37. seb
       [169]september 20, 2017 at 6:51 pm
       great !
       how are trained brains saved ?
         1. arthur juliani
            [170]september 20, 2017 at 6:56 pm
            if you use tensorflow to create the neural network, the saved
            brain is saved as a tensorflow model, which can be converted
            to a .bytes file, and embedded into the unity project
            directly. for more information, check out this walkthrough:
            [171]https://github.com/unity-technologies/ml-agents/wiki/gett
            ing-started-with-balance-ball.
   38. bond
       [172]september 20, 2017 at 2:50 pm
       i must yes, it   s good
       but the question here is why is that unity is copying openai
       strategy in unity as is, ai learning from players is a maths
       project from dota2 but there are flaws with the system learning as
       with the kind of pitch one has made
   39. romano
       [173]september 20, 2017 at 10:00 am
       does this work on windows too or linux only? (sorry if asking
       stupid question :d:d)
         1. arthur juliani
            [174]september 20, 2017 at 6:38 pm
            we are targeting support for windows, mac, and linux (plus
            eventually mobile and console). currently mac and linux are
            the more heavily tested environments. if you encounter an
            issue on windows, please let us know here:
            [175]https://github.com/unity-technologies/ml-agents/issues.
              1. renato vargas
                 [176]september 21, 2017 at 5:55 pm
                 it seems like a good timing for a official release of the
                 linux editor :)
   40. yosider
       [177]september 20, 2017 at 4:19 am
       very cool project!!
       i   m looking foward to supports for (spoken) language learning.
         1. arthur juliani
            [178]september 20, 2017 at 6:36 pm
            hi! unity actually already has a solution for speech
            recognition in games:
            [179]https://labs.unity.com/article/speech-recognition-and-vr
            . i hope that is what you are looking for!
   41. faizan khan
       [180]september 19, 2017 at 11:27 pm
       perfect! i have done my machine learning subject project in game
       machine learning    i didn   t quite get anything sophisticated    i wish
       unity machine learning would have introduced 5 months ago.???
   42. faizan khan
       [181]september 19, 2017 at 11:27 pm
       perfect! i have done my machine learning subject project in game
       machine learning    i didn   t quite get anything sophisticated    i wish
       unity machine learning would have introduced 5 months ago.??
   43. samuel otero
       [182]september 19, 2017 at 9:19 pm
       very cool, i was already wanting to do a game that implemented
       id23 in unity and this will go a long way towards
       that. in my case the agent would start off with a trained behavior
       with the player being able to modify the behavior as part of the
       gameplay.
   44. apcrol
       [183]september 19, 2017 at 9:01 pm
       great stuff but i wish to see more examples of applications for
       this agents.
         1. arthur juliani
            [184]september 20, 2017 at 6:31 pm
            more demo projects and videos are definitely on the way! we
            are also interested in sharing example projects that others
            might make.
   45. alan mattano
       [185]september 19, 2017 at 7:02 pm
       ai and an external database can be good for automatically adjust
       the starting rendering settings looking to the player hardware when
       the game starts.
   46. kamran bigdely shamloo
       [186]september 19, 2017 at 6:39 pm
       this is immensely useful for game development and ai researchers.
       unity is going the right direction.
   47. laura
       [187]september 19, 2017 at 6:22 pm
       cannot wait to see the ecosystem demos!

share

categories

   [188]all

   [189]aec

   [190]asset store

   [191]automotive

   [192]community

   [193]events

   [194]machine learning

   [195]made with unity

   [196]rants & raves

   [197]services

   [198]technology

   [199]unity ads

   [200]unity analytics

popular posts

   [201]

sound design and music     buried memories volume 1: yggdrasil icon pack

   april 4, 2019
   [202]

join unity at gdc 2019     our biggest yet

   february 19, 2019
   [203]

srp batcher: speed up your rendering!

   february 28, 2019
   [204]

unity ranks top of the charts in the singular 2019 roi index

   february 27, 2019
   [205]

on dots: c++ & c#

   february 26, 2019
   [206]

hololens 2 is coming: what you need to know

   february 26, 2019

   purchase
     * [207]subscription
     * [208]asset store
     * [209]resellers

   education
     * [210]student
     * [211]educator

   download
     * [212]unity
     * [213]beta program
     * [214]press material
     * [215]whitepapers

   labs
     * [216]research

   resources
     * [217]learn
     * [218]community
     * [219]documentation
     * [220]unity qa
     * [221]faq
     * [222]services status
     * [223]certification
     * [224]connect

   about unity
     * [225]company facts
     * [226]blog
     * [227]events
     * [228]careers
     * [229]press
     * [230]contact
     * [231]partners
     * [232]affiliates
     * [233]security

   get unity news
   ____________________ sign up
   [ ] i agree to the [234]unity privacy policy and the processing and use
   of my information

nearly there...

   to start receiving news from unity technologies, click on the link
   we've sent to your e-mail account.

oops...

   something went wrong, please try again.

   language
     * [235]english
     * [236]      
     * [237]         
     * [238]portugu  s
     * [239]              
     * [240]espa  ol
     * [241]         

   partners
   [242]facebook [243]twitter [244]instagram [245]linkedin [246]youtube
      2019 unity technologies
     * [247]legal
     * [248]privacy policy
     * [249]cookies

references

   visible links
   1. https://blogs.unity3d.com/feed/
   2. https://blogs.unity3d.com/comments/feed/
   3. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/feed/
   4. https://blogs.unity3d.com/en/2017/09/19/introducing-unity-machine-learning-agents/
   5. https://blogs.unity3d.com/cn/2017/09/19/introducing-unity-machine-learning-agents/
   6. https://blogs.unity3d.com/kr/2017/09/19/introducing-unity-machine-learning-agents/
   7. https://blogs.unity3d.com/pt/2017/09/19/introducing-unity-machine-learning-agents/
   8. https://blogs.unity3d.com/ru/2017/09/19/introducing-unity-machine-learning-agents/
   9. https://blogs.unity3d.com/es/2017/09/19/introducing-unity-machine-learning-agents/
  10. https://blogs.unity3d.com/jp/2017/09/19/introducing-unity-machine-learning-agents/
  11. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/
  12. https://blogs.unity3d.com/cn/2017/09/19/introducing-unity-machine-learning-agents/
  13. https://blogs.unity3d.com/kr/2017/09/19/introducing-unity-machine-learning-agents/
  14. https://blogs.unity3d.com/pt/2017/09/19/introducing-unity-machine-learning-agents/
  15. https://blogs.unity3d.com/ru/2017/09/19/introducing-unity-machine-learning-agents/
  16. https://blogs.unity3d.com/es/2017/09/19/introducing-unity-machine-learning-agents/
  17. https://blogs.unity3d.com/jp/2017/09/19/introducing-unity-machine-learning-agents/
  18. https://www.googletagmanager.com/ns.html?id=gtm-5hxf38
  19. https://unity3d.com/products
  20. https://unity3d.com/solutions
  21. https://unity3d.com/showcase
  22. https://unity3d.com/learn
  23. https://unity3d.com/community
  24. https://unity3d.com/asset-store
  25. https://unity3d.com/get-unity
  26. http://forum.unity3d.com/
  27. http://answers.unity3d.com/
  28. http://feedback.unity3d.com/
  29. http://issuetracker.unity3d.com/
  30. http://blogs.unity3d.com/
  31. https://unity3d.com/unity/beta
  32. https://unity3d.com/community/evangelists
  33. https://unity3d.com/community/user-groups
  34. https://unity.com/advisorypanel
  35. https://unity3d.com/
  36. https://unity3d.com/unity
  37. https://unity3d.com/solutions
  38. https://unity3d.com/showcase
  39. https://unity3d.com/learn
  40. https://unity3d.com/community
  41. https://unity3d.com/asset-store
  42. https://unity3d.com/get-unity
  43. https://unity3d.com/cn/
  44. https://unity3d.com/es/
  45. http://japan.unity3d.com/
  46. https://unity3d.com/kr/
  47. https://unity3d.com/pt/
  48. https://blogs.unity3d.com/
  49. https://blogs.unity3d.com/feed
  50. https://blogs.unity3d.com/author/arthur-juliani/
  51. https://blogs.unity3d.com/category/machine-learning/
  52. https://blogs.unity3d.com/2017/06/26/unity-ai-themed-blog-entries/
  53. https://blogs.unity3d.com/2017/08/22/unity-ai-reinforcement-learning-with-id24/
  54. https://github.com/unity-technologies/ml-agents
  55. https://www.youtube.com/embed/tmoz3ojbtn0
  56. https://github.com/unity-technologies/ml-agents
  57. https://github.com/unity-technologies/ml-agents
  58. https://github.com/unity-technologies/ml-agents/wiki
  59. https://github.com/migueldeicaza/tensorflowsharp
  60. https://github.com/unity-technologies/python-rl-control/wiki
  61. https://www.youtube.com/embed/fiqsmdwegt8
  62. https://www.youtube.com/embed/fq0jbaicyna
  63. https://blog.openai.com/dota-2/
  64. https://github.com/unity-technologies/ml-agents
  65. mailto:ml-agents@unity3d.com
  66. https://careers.unity.com/position/senior-software-engineer-machine/785895
  67. https://blogs.unity3d.com/2019/02/18/the-obstacle-tower-challenge-is-live/
  68. https://blogs.unity3d.com/author/arthur-juliani/
  69. https://blogs.unity3d.com/2019/02/18/the-obstacle-tower-challenge-is-live/#com
  70. https://blogs.unity3d.com/category/machine-learning/
  71. https://blogs.unity3d.com/category/technology/
  72. https://blogs.unity3d.com/2019/01/28/obstacle-tower-challenge-test-the-limits-of-intelligence-systems/
  73. https://blogs.unity3d.com/author/danny-lange/
  74. https://blogs.unity3d.com/2019/01/28/obstacle-tower-challenge-test-the-limits-of-intelligence-systems/#com
  75. https://blogs.unity3d.com/category/community-news/
  76. https://blogs.unity3d.com/category/machine-learning/
  77. https://blogs.unity3d.com/2019/01/18/fostering-ai-research-meet-us-at-aaai-19/
  78. https://blogs.unity3d.com/author/marwan-mattar/
  79. https://blogs.unity3d.com/2019/01/18/fostering-ai-research-meet-us-at-aaai-19/#com
  80. https://blogs.unity3d.com/category/machine-learning/
  81. https://blogs.unity3d.com/category/technology/
  82. https://blogs.unity3d.com/2018/12/17/ml-agents-toolkit-v0-6-improved-usability-of-brains-and-imitation-learning/
  83. https://blogs.unity3d.com/author/vincentpierre/
  84. https://blogs.unity3d.com/2018/12/17/ml-agents-toolkit-v0-6-improved-usability-of-brains-and-imitation-learning/#com
  85. https://blogs.unity3d.com/category/machine-learning/
  86. https://blogs.unity3d.com/category/technology/
  87. https://blogs.unity3d.com/2018/11/28/how-to-get-the-most-out-of-friend-invites-in-your-app/
  88. https://blogs.unity3d.com/author/caitlin/
  89. https://blogs.unity3d.com/2018/11/28/how-to-get-the-most-out-of-friend-invites-in-your-app/#com
  90. https://blogs.unity3d.com/category/asset-store/
  91. https://blogs.unity3d.com/2018/11/28/introducing-unitys-guiding-principles-for-ethical-ai/
  92. https://blogs.unity3d.com/author/unitytech/
  93. https://blogs.unity3d.com/2018/11/28/introducing-unitys-guiding-principles-for-ethical-ai/#com
  94. https://blogs.unity3d.com/category/machine-learning/
  95. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/feed/
  96. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364452
  97. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364190
  98. https://github.com/unity-technologies/python-rl-control/wiki
  99. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364187
 100. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364160
 101. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364128
 102. http://www.broachindia.com/
 103. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364050
 104. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364011
 105. http://myknightrider2000.blogspot.ca/
 106. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363936
 107. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363956
 108. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-364033
 109. http://prntscr.com/h4dhaq
 110. http://prntscr.com/h4diha
 111. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363836
 112. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363823
 113. https://www.usmsystems.com/machine-learning/
 114. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363740
 115. http://www.analyticspath.com/machine-learning-training-in-hyderabad
 116. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363642
 117. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363667
 118. https://github.com/unity-technologies/ml-agents/blob/master/docs/getting-started-with-balance-ball.md#embedding-trained-brain-into-unity-environment-experimental
 119. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363557
 120. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363595
 121. https://github.com/unity-technologies/ml-agents/blob/master/docs/using-tensorflow-sharp-in-unity-(experimental)
 122. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363467
 123. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363483
 124. https://github.com/unity-technologies/ml-agents/blob/master/docs/best-practices.md
 125. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363450
 126. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363409
 127. https://www.assetstore.unity3d.com/en/#!/content/93236
 128. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363141
 129. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363155
 130. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363086
 131. http://blog.nitishmutha.com/tensorflow/2017/01/22/tensorflow-with-gpu-for-windows.html
 132. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363087
 133. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-363116
 134. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362817
 135. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362852
 136. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362915
 137. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362738
 138. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362748
 139. https://github.com/unity-technologies/ml-agents/tree/master/python
 140. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362779
 141. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362736
 142. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362745
 143. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362718
 144. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362702
 145. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362728
 146. https://github.com/unity-technologies/ml-agents
 147. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362693
 148. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362689
 149. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362615
 150. http://paco.psy.gla.ac.uk/index.php?option=com_jdownloads&view=viewcategories&itemid=62
 151. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362613
 152. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362526
 153. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362572
 154. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362503
 155. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362473
 156. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362577
 157. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362468
 158. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362578
 159. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362431
 160. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362416
 161. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362581
 162. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362364
 163. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362369
 164. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362410
 165. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362359
 166. https://medium.com/towards-data-science/introduction-to-udacity-self-driving-car-simulator-4d78198d301d
 167. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362343
 168. https://drive.google.com/open?id=0b6px6xu8ryexa2m2cg5befbsoe1itknrcdrpy1lqavnkmetr
 169. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362334
 170. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362337
 171. https://github.com/unity-technologies/ml-agents/wiki/getting-started-with-balance-ball
 172. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362309
 173. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362294
 174. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362332
 175. https://github.com/unity-technologies/ml-agents/issues
 176. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362499
 177. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362289
 178. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362331
 179. https://labs.unity.com/article/speech-recognition-and-vr
 180. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362277
 181. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362273
 182. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362263
 183. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362261
 184. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362328
 185. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362255
 186. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362249
 187. https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/#comment-362245
 188. https://blogs.unity3d.com/
 189. https://blogs.unity3d.com/category/aec/
 190. https://blogs.unity3d.com/category/asset-store/
 191. https://blogs.unity3d.com/category/automotive/
 192. https://blogs.unity3d.com/category/community-news/
 193. https://blogs.unity3d.com/category/events/
 194. https://blogs.unity3d.com/category/machine-learning/
 195. https://blogs.unity3d.com/category/made-with-unity/
 196. https://blogs.unity3d.com/category/rants/
 197. https://blogs.unity3d.com/category/services/
 198. https://blogs.unity3d.com/category/technology/
 199. https://blogs.unity3d.com/category/unity-ads/
 200. https://blogs.unity3d.com/category/unity-analytics/
 201. https://blogs.unity3d.com/2019/04/04/sound-design-and-music-buried-memories-volume-1-yggdrasil-icon-pack/
 202. https://blogs.unity3d.com/2019/02/19/join-unity-at-gdc-2019-our-biggest-yet/
 203. https://blogs.unity3d.com/2019/02/28/srp-batcher-speed-up-your-rendering/
 204. https://blogs.unity3d.com/2019/02/27/unity-ranks-top-of-the-charts-in-the-singular-2019-roi-index/
 205. https://blogs.unity3d.com/2019/02/26/on-dots-c-c/
 206. https://blogs.unity3d.com/2019/02/26/hololens-2-is-coming-what-you-need-to-know/
 207. https://store.unity3d.com/
 208. https://www.assetstore.unity3d.com/
 209. https://store.unity3d.com/reseller
 210. https://store.unity3d.com/education#student
 211. https://store.unity3d.com/education#educator
 212. https://unity3d.com/unity/download
 213. https://unity3d.com/unity/beta
 214. https://unity3d.com/public-relations/downloads
 215. https://unity3d.com/whitepapers
 216. http://research.unity3d.com/
 217. https://unity3d.com/learn
 218. https://unity3d.com/community
 219. https://unity3d.com/learn/documentation
 220. https://unity3d.com/unity/qa
 221. https://unity3d.com/unity/faq
 222. http://status.cloud.unity3d.com/
 223. https://certification.unity.com/
 224. https://connect.unity.com/
 225. https://unity3d.com/public-relations
 226. https://blogs.unity3d.com/
 227. https://unity3d.com/events
 228. https://unity3d.com/jobs
 229. https://unity3d.com/public-relations
 230. https://unity3d.com/contact
 231. https://unity3d.com/partners
 232. https://unity3d.com/affiliates
 233. https://unity3d.com/security
 234. https://unity3d.com/company/legal/privacy-policy
 235. https://blogs.unity3d.com/en/2017/09/19/introducing-unity-machine-learning-agents/
 236. https://blogs.unity3d.com/cn/2017/09/19/introducing-unity-machine-learning-agents/
 237. https://blogs.unity3d.com/kr/2017/09/19/introducing-unity-machine-learning-agents/
 238. https://blogs.unity3d.com/pt/2017/09/19/introducing-unity-machine-learning-agents/
 239. https://blogs.unity3d.com/ru/2017/09/19/introducing-unity-machine-learning-agents/
 240. https://blogs.unity3d.com/es/2017/09/19/introducing-unity-machine-learning-agents/
 241. https://blogs.unity3d.com/jp/2017/09/19/introducing-unity-machine-learning-agents/
 242. http://www.facebook.com/unity3d
 243. http://www.twitter.com/unity3d
 244. https://www.instagram.com/unitytechnologies
 245. https://www.linkedin.com/company/unity-technologies
 246. https://www.youtube.com/user/unity3d
 247. https://unity3d.com/legal
 248. https://unity3d.com/legal/privacy-policy
 249. https://unity3d.com/legal/cookie-policy#cookies

   hidden links:
 251. https://unity3d.com/
 252. https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f
 253. https://twitter.com/intent/tweet?url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f&text=introducing%3a+unity+machine+learning+agents+toolkit&via=unity3d
 254. https://www.linkedin.com/sharearticle?mini=true&url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f&title=introducing%3a+unity+machine+learning+agents+toolkit&summary=our+two+previous+blog+entries+implied+that+there+is+a+role+games+can+play+in+driving+the+development+of+reinforcement+learning+algorithms.+as+the+world%e2%80%99s+most+popular+creation+engine%2c+unity+is+at+the+crossroads+between+machine+learning+and+gaming.+it+is+critical+to+our+mission+to+enable+machine+learning+researchers+with+the+most+powerful+training+%5b%26hellip%3b%5d&source=unity3d+blog
 255. https://plus.google.com/share?url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f
 256. https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f
 257. https://twitter.com/intent/tweet?url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f&text=introducing%3a+unity+machine+learning+agents+toolkit&via=unity3d
 258. https://www.linkedin.com/sharearticle?mini=true&url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f&title=introducing%3a+unity+machine+learning+agents+toolkit&summary=our+two+previous+blog+entries+implied+that+there+is+a+role+games+can+play+in+driving+the+development+of+reinforcement+learning+algorithms.+as+the+world%e2%80%99s+most+popular+creation+engine%2c+unity+is+at+the+crossroads+between+machine+learning+and+gaming.+it+is+critical+to+our+mission+to+enable+machine+learning+researchers+with+the+most+powerful+training+%5b%26hellip%3b%5d&source=unity3d+blog
 259. https://plus.google.com/share?url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f
 260. https://blogs.unity3d.com/2019/02/18/the-obstacle-tower-challenge-is-live/
 261. https://blogs.unity3d.com/2019/01/28/obstacle-tower-challenge-test-the-limits-of-intelligence-systems/
 262. https://blogs.unity3d.com/2019/01/18/fostering-ai-research-meet-us-at-aaai-19/
 263. https://blogs.unity3d.com/2018/12/17/ml-agents-toolkit-v0-6-improved-usability-of-brains-and-imitation-learning/
 264. https://blogs.unity3d.com/2018/11/28/how-to-get-the-most-out-of-friend-invites-in-your-app/
 265. https://blogs.unity3d.com/2018/11/28/introducing-unitys-guiding-principles-for-ethical-ai/
 266. https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f
 267. https://twitter.com/intent/tweet?url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f&text=introducing%3a+unity+machine+learning+agents+toolkit&via=unity3d
 268. https://www.linkedin.com/sharearticle?mini=true&url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f&title=introducing%3a+unity+machine+learning+agents+toolkit&summary=our+two+previous+blog+entries+implied+that+there+is+a+role+games+can+play+in+driving+the+development+of+reinforcement+learning+algorithms.+as+the+world%e2%80%99s+most+popular+creation+engine%2c+unity+is+at+the+crossroads+between+machine+learning+and+gaming.+it+is+critical+to+our+mission+to+enable+machine+learning+researchers+with+the+most+powerful+training+%5b%26hellip%3b%5d&source=unity3d+blog
 269. https://plus.google.com/share?url=https%3a%2f%2fblogs.unity3d.com%2f2017%2f09%2f19%2fintroducing-unity-machine-learning-agents%2f
 270. https://blogs.unity3d.com/
 271. http://www.cloudmoolah.com/
 272. http://www.facebook.com/
 273. https://unity3d.com/partners/google/daydream
 274. https://unity3d.com/partners/intel
 275. https://unity3d.com/partners/microsoft
 276. http://www.nintendo.com/
 277. http://www.oculus.com/
 278. https://unity3d.com/partners/qualcomm
 279. https://unity3d.com/partners/samsung
 280. http://www.sony.com/
 281. https://developer.vuforia.com/
 282. http://www.mi.com/
