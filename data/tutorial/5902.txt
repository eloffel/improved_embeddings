        the neuroevolution of augmenting topologies (neat) users page

                                  [net.jpg]

   [speciation.jpg]

                 now there is a [1]hyperneat users page too!

   last updated 5/5/15[2] (list of updates)
   i created this page because of growing interest in the use and
   implementation of the neat method. i have been corresponding with an
   expanding group of users. because the same points come up more than
   once, it makes sense to have a place where people can come and tap into
   the expanding knowledge we have about the software and the method
   itself.

   i continue to support the neat community from my new position as an
   assistant professor at the university of central florida in the
   [3]school of electrical engineering and computer science, where my
   research continues as director of the [4]evolutionary complexity
   research group (eplex).

   we also developed an extension to neat called [5]hyperneat that can
   evolve neural networks with millions of connections and exploit
   geometric regularities in the task domain. the [6]hyperneat page
   includes links to publications and a general explanation of the
   approach.

   new! so that the record of how i thought of neat is not lost, i have
   made available copies of the [7]original notes from january 2000 where
   i first thought of neat. it turns out that i unintentionally documented
   my own thinking process when i thought of neat because i was scribbling
   notes about it as i thought it through. these are those notes, with
   some commentary to explain what i was thinking about.

   tutorial available: wesley tansey has provided a [8]helpful tutorial on
   setting up a tic-tac-toe experiment in sharpneat 2. it should be
   instructive for anyone aiming to create an experiment in sharpneat.

   -[9]kenneth stanley

    want to see neat used in a video game? check out [10]galactic arms race or
    [11]nero.

contents

   [12]introduction - which version of neat should you use?
   [13]neat users group - join the group to discuss your projects
   [14]book available with step by step chapter on neat
   [15]neat software faq - questions that mostly relate to coding issues
   or using the actual software.
   [16]general neat methodology faq - more broad questions regarding
   general methodology or philosophy behind neat.
   [17]neat users and projects
   [18]the future of neat
   [19]neat publications

  introduction

   this page is intended for [20]neat users, particularly those using one
   of the available versions of neat or writing a version of their own.
   over the past few years, several versions of neat have become available
   for different platforms and languages. the remainder of this
   introduction will introduce the available software, and attempt to help
   the user choose the right package for his or her needs. the current
   crop of neat software is available at:

  [21]the neat software catalog

   the question for many people first coming to neat is which package is
   right for me? there are several factors to consider:

   first, how closely does the package you want follow my (ken's) original
   neat source code? for most people this won't be a big issue, since all
   the packages work. however, if you want to strictly reproduce my
   experimental results, you may want the most faithful code available.
   for this purpose, either my original version or ugo vierruci's jneat
   are probably the best choices, since jneat was written directly off of
   my original c++ source code.

   second, what is your favorite platform? if you prefer linux, my c++
   version is appropriate. if you prefer windows, mat buckland's c++ would
   be better. since java and matlab run on all platforms, if you want to
   use java or matlab, platform is not a consideration. sharpneat, written
   in c#, can also run on either platform.

   third, what language do you prefer? since neat is available in c++,
   java, matlab, delphi, and c#, there are now several choices.

   fourth, what experiments would you like built in? jneat, matlab neat,
   sharpneat, anji, and the original neat c++ all come with xor. the
   original neat c++ and sharpneat also come with pole balancing. windows
   neat c++ comes with a nice graphical minesweeper demo. delphi neat has
   some entertaining 3d robot control experiments. sharpneat includes an
   incremental predator/prey experiment. anji comes with tic tac toe. if
   you are planning a new experiment, it may be helpful to look at the
   code for similar experiments.

   your best option will be based on some combination of the above
   considerations. of course, if you want neat for platform x or language
   y and they aren't available, you may want to write your own version of
   neat. i am happy to hear about such projects so you should [22]let me
   know what you're thinking of. i can give you advice or point you to any
   similar projects you may not be aware of.

  neat users discussion group

   derek james created a [23]neat users group on yahoo to encourage the
   discussion of ideas, questions, and variations of neat. the community
   of neat users and those interested in neat can benefit greatly from the
   availability of this forum. please feel free to join the discussion!

  paperback book available with chapter on neat

   for people who are interested in learning about neat, but prefer
   explanations intended for general audiences to reading research-level
   papers, i am happy to recommend [24]ai techniques for game programming
   by mat buckland. most of the final chapter of this book describes neat
   in a fun and simple style. the book also comes with source code. this
   book is a good resource for hobbyists or video game programmers
   interested in ai techniques. (researchers should still refer to the
   neat research publications available below.) it also includes useful
   introductions to id107 and neural networks. note that
   coding questions in the faq on this page refer to my own source code
   release and not the code in this book, though some answers may still be
   useful.

neat software faq

   please note: in general, most answers refer to the original c++ code
   intended for linux, which i wrote myself. the java code, written by
   [25]ugo vierucci , was made to follow the c++ code faithfully, so most
   answers will apply to the java version as well. however, pole balancing
   experiments are not included in the java version so any questions on
   pole balancing will not apply to jneat. [26]mat buckland's windows
   version and also [27]christian mayr's matlab version were written
   independently. therefore, code-related answers below probably do not
   apply to the windows or matlab distributions.
     * what is neat?
       neat stands for neuroevolution of augmenting topologies. it is a
       method for evolving id158s with a genetic
       algorithm. neat implements the idea that it is most effective to
       start evolution with small, simple networks and allow them to
       become increasingly complex over generations. that way, just as
       organisms in nature increased in complexity since the first cell,
       so do neural networks in neat. this process of continual
       elaboration allows finding highly sophisticated and complex neural
       networks.
     * will you release neat software?
       yes, a number of versions of neat are available. please see the
       [28]introduction.
     * when is the next version coming out?
       i don't have a specific software development schedule since i am
       mostly focused on research. i will post notification when new
       versions become available. note that a number of independent
       projects are ongoing, so other people may also be releasing their
       own versions of neat. i will try to make all such releases
       available through this page. the neat users group also has new code
       posted occasionally.
     * can you notify me about updates?
       there are currently a fair amount of people working on new neat
       software and/or experiments. to keep up to date, i suggest
       periodically checking this page, and also joining the [29]neat
       users group run by derek james. you can also [30]e-mail me with
       software-related questions.
     * does neat have documentation?
       yes, a 17 page documentation file is included in the original (and
       now out-of-date) [31]c++ software release. the more current neat
       c++ release is at [32]http://nn.cs.utexas.edu/?neat-c however, the
       documentation may still be helpful.
       the [33]java version has its own documentation in a readme file, as
       well as a quickstart file. the java version is easier to get
       started with and has a nice gui. the c++ version has more
       experiments included, and a guile scripting interface.
       if you want to understand neat as a software package, i suggest
       reading the documentation in the c++ distribution whether or not
       you ultimately choose to use java. that doc file will give you a
       good idea of how to design your own experiments in neat.
       the [34]windows version comes with a short readme about running the
       minesweeper experiment that it comes with. however, you will have
       to look directly to the source code of that distribution to answer
       coding-related questions. you can also e-mail its author, [35]mat
       buckland.
       the [36]matlab version also comes with a short readme. a faq may
       eventually be made available.
     * what are traits and how can i use them?
       this question refers to my c++ release of neat, which has a vector
       of "traits" in each genome. (jneat also has traits.)
       if you read the 17-page documentation, i mention that traits are
       not used in this release version of neat. traits are reserved for
       future use. i built them in from the start to support some
       expansions i have in mind. in other words, they can be ignored and
       have no effect on anything.
       however, any genome must have at least 1 trait (look at
       xorstartgenes for example, which has 3 dummy traits) in order to be
       valid. (in other words, if you create a starter (spawning) genome
       for some new experiment, it should have at least one trait, even
       though that trait means nothing.)
     * you say traits are reserved for future use. what will they be used
       for?
       in the future, traits will allow the system to evolve highly
       complex neural models, much more sophisticated than the simple
       sigmoidal neurons currently used. the neurons will be able to
       evolve plasticity parameters (like real neurons in the brain) by
       pointing to a trait that describes the plasticity of the neuron.
       the details will be made available as the related research
       proceeds.
       new: preliminary work with traits and synaptic plasticity has
       already been completed and is now reported in [37]this paper.
     * how are networks with arbitrary topologies activated?
       the activation function, bool network::activate(), gives the
       specifics. the implementation is of course considerably different
       than for a simple layered feedforward network. each node adds up
       the activation from all incoming nodes from the previous timestep.
       (the function also handles a special "time delayed" connection, but
       that is not used by the current version of neat in any experiments
       that we have published.) another way to understand it is to realize
       that activation does not travel all the way from the input layer to
       the output layer in a single timestep. in a single timestep,
       activation only travels from one neuron to the next. so it takes
       several timesteps for activation to get from the inputs to the
       outputs. if you think about it, this is the way it works in a real
       brain, where it takes time for a signal hitting your eyes to get to
       the cortex because it travels over several neural connections.
     * can you explain some of the neat parameters?
       explaining all the neat parameters can be tricky because there are
       so many different versions of neat. there are often subtle
       differences in meaning among these parameters from one version to
       another, even if they have the same name. however, it can still
       help to give a general idea what a certain set of parameters mean.
       therefore, i am posting here a copy of an answer from the neat
       users group to one such question that explains some (though not
       all) parameters. while the particulars may not be exactly like your
       neat implementation, they may still help to clarify some general
       questions:
       > disjointcoefficient 2.0 [?]
       > excesscoefficient 2.0 [?]
       > weightdifferencecoefficient 1.0 [?]
       these are the standard neat compatibility coefficients for the
       compatibility equation the determines how far apart two individuals
       are for the purposes of speciation. in general, the question is how
       many gene differences are worth an average distance of 1.0 in
       weights. the numbers above say that an average difference of 1.0 in
       weights is like having two genes not shared between the two
       individuals. that is pretty reasonable.
       > compatibilitythreshold 6.0 [?]
       this parameter relates to the coefficients above. it can be thought
       of as, how many genes not shared does it take for individuals to be
       considered in a different species. however, it is only relevant at
       the start because the next parameter lets it change.
       > compatibilitymodifier 0.3 [?]
       this number means the threshold changes at a rate of 0.3 per
       generation, which is reasonable. it does not change if the
       speciessize target is already met.
       > dropoffage 15.0 [?]
       in 15 generations a species will be penalized if it is not making
       progress.
       > survivalthreshold 0.2 [?]
       only the top 20% of each species is allowed to reproduce. controls
       greediness within species.
       > mutationpower 2.5 [?]
       mutations of weight go up to 2.5 in a single mutation. you wouldn't
       want it over 5.0 or so.
     * how do i compile your linux version of neat in such and such
       operating system?
       as i get specific information from users about how they compiled
       under specific systems, i will post the information under this
       question. in the meantime, i have only used neat in debian and red
       hat linux, and cannot comment on other systems. clearly, the
       includes and libs must be significantly altered to reflect the
       organization of your version of linux or unix.
       new: linux neat in windows: darren izzard wrote the following about
       compiling my c++ version of neat (which i wrote for linux) under
       windows:
       "i have compiled your c++ version of neat under windows using
       cygwin without much difficulty. i removed the visualization code,
       and, as you might expect, includes and libs needed modifying a
       little.
       the version of swig i'm using is 1.3.16 and there were two main
       steps getting it to work:-
       1. change glist() to swig_init() as mentioned on your site
       2. insert the following lines in neatswig.i at some point between
       the %} line and the class declarations:
       %nodefault population
       %nodefault network
       the output seems to require no editing, and in fact i have
       reinstated the wrapper-generating lines in the makefile. (nb. "cp
       neatswig_wrap.c neatswig_wrap.cpp" needs changing to "cp
       neatswig_wrap.cxx neatswig_wrap.cpp" for 1.3.16.)"
     * what are "stolen babies?"
       you will notice a portion of the population::epoch() method that
       deals with babies_stolen. babies stolen is something in the code
       that we never used in experiments described in the papers. babies
       stolen takes offspring away from bad species and distributes them
       among the best species. in other words, it makes the search more
       greedy. it can speed up solutions on some problems. the more babies
       stolen, the more biased the search. there is a global system
       parameter you can set in the ".ne" files called "babies_stolen."
       any number above 0 will cause the system to "steal" offspring
       rights from the poorer species and redistribute them to the better
       species. the standard algorithm works fine with babies_stolen=0.
       you can try setting it higher to see if it enhances performance.
     * i want to rewrite neat in a new programming language. would you be
       interested?
       absolutely. [38]let me know your plans! remember, neat already
       exists in c++, java, and matlab, and a delphi version is partially
       available.
     how should i test my own version of neat to make sure it works?
       most people choose xor as their first test. xor is very simple and
       does not make a very interesting scientific experiment; however, it
       is a good way to check whether your system works. here are some
       things to consider if you are testing with xor and not finding a
       solution:
          + make sure recurrency is disabled for the xor test. if neat is
            able to add recurrent connections, it may solve xor by
            memorizing the order of the training set. (which is why you
            may even want to randomize order to be most safe) all
            documented experiments with xor are without recurrent
            connections. interestingly, xor can be solved by a recurrent
            network with no hidden nodes.
          + most people report xor is easier to solve with a steepened
            gain on the sigmoid function.
          + some have suggested that a weight cap can help, though i
            haven't had a problem solving xor without a weight cap myself.
          + be careful about what you consider a 1 and what you consider a
            0 and how they are penalized/rewarded. i generally said < 0.5
            is 0 and >= 0.5 is 1 for the purposes of a solution. however,
            for the purposes of fitness, the distance from the actual
            output to the intended output is used, which provides a
            gradient. for example 0.9 is 0.1 away from 1. most people use
            sum squared error.
          + the weight mutation power is important. you may want to fiddle
            with it a bit because sometimes it is too low or too high when
            you first set up the system. also, some people like to use
            uniform mutation distributions and others use normal
            distributions, and the two distributions may benefit from
            different mutation powers.
          + if you decide to use the species compatibility coefficients
            and thresholds from my own .ne settings files (provided with
            my neat release), then do not normalize the terms in the
            compatibility function, because i did not do this with my .ne
            files. in other words, even though my papers suggest
            normalizing (dividing my number of genes), since i didn't do
            that the coefficients that i used will not work the same for
            you if you normalize. if you strongly desire to normalize, you
            will need to find your own appropriate coefficients and
            threshold.
          + please [39]let me know if you remember any of your own
            problems that you eventually fixed when you were expeirmenting
            with xor.
       thanks to bryan adams, derek james, john arrowwood, and colin green
       for providing input about this question
     * i can get xor_test and pole1_test working but pole2_test does not
       work. what's going on?
       you probably have the wrong starter genome in the file
       pole2startgenes. in the documentation it mentions this, but it is a
       confusing aspect of the distribution.
       there are 2 different kinds of pole2_test experiments: the markov
       and the non-markov. they both use a different starter genome,
       because the non-markov one uses fewer sensors. however, the
       pole2_test always reads from the file "pole2startgenes," no matter
       which version of the experiment you run.
       that means the correct version must be copied into pole2startgenes
       before you begin. notice there are two files, "pole2startgenes1"
       and "pole2startgenes2." pole2startgenes1 has the right genes for
       the markovian test, whereas pole2startgenes2 has the non-markovian
       version. so, for example, you have to do:
       % cp pole2startgenes1 pole2startgenes
       if you are running the markovian version.
       of course, when you run the markov version (which takes 7 inputs)
       and run it with the 4 input non-markov network, it can never solve
       the problem and only gets up to about 60 steps.
     * i am trying to write my own speciation code and i can't get it to
       work! help!
       well, this could mean a lot of things, but the neat software may be
       a good reference point for you. also, you may be having trouble
       with getting the right parameters. take a look at some of the ".ne"
       files to see good parameters for speciation. also, please see the
       next question, which may give you some helpful ideas.
     * is there a way to automatically set the compatibility threshold for
       speciation? (important)
       yes, and this technique may be crucial for problems that take
       hundreds of generations or more. this technique keeps the number of
       species stable in neat. there is some commented-out code in
       population::epoch that adjusts the compatibility threshold up or
       down depending on whether you have fewer or more than a specified
       target number of species::
       //we can try to keep the number of species constant at this number
       int num_species_target=10;
       int num_species=species.size();
       double compat_mod=0.3; //modify compat thresh to control speciation
       //keeping species diverse
       //this commented out code forces the system to aim for
       // num_species species at all times, enforcing diversity
       //this tinkers with the compatibility threshold, which
       // normally would be held constant
       if (generation>1) {
       if (num_species<num_species_target)
       compat_threshold-=compat_mod; //compat_mod works well at about 0.3
       else if (num_species>num_species_target)
       compat_threshold+=compat_mod;
       if (compat_threshold<0.3) compat_threshold=0.3;
       }
       this dynamic thresholding allows neat to control the number of
       species, saving you from needing to guess the right threshold for
       your experiment. (although you must still specify a reasonable
       number of species for your population size.) uncomment this code in
       genetics.cpp in order to get the benefits of dynamic thresholding.
     * too many genes are becoming disabled! what should i do?
       if you have the mutate_toggle_enable_prob too high (in your .ne
       file), this an obvious culpit.
       otherwise, it may be that your task surprisingly doesn't need all
       the inputs you are providing it. neat may have discovered this and
       disabled a lot of genes in order to get rid of those useless
       inputs.
       it is still possible that somehow, neat prematurely discovered
       genes that it disabled to get some early gains, but is having
       trouble making progress beyond that point because those genes
       turned out to be needed in the long run. in such a situation (which
       i have found to be rare) you may want to edit the mating code such
       that disabled genes are only disabled in the offspring if they are
       disabled in the more fit parent. this fix will keep the disabling
       of genes to a minimum.
       note that genes in neat often become reenabled in mating, because
       there is a built-in id203 that genes will become reenabled
       during mating even if they are disabled in one or more parent.
       one user suggested that instead of disabling genes, they can be
       reset to a 0 weight, and gradually climb back into significance. i
       have not tried this idea but you may want to play with it if you
       have time.
     * neat takes up too much memory. can i save memory somehow?
       yes. look at this constructor inside the organism class (from the
       c++ code; the java code should be similar):
       organism(double fit, genome *g,int gen) {
       fitness=fit;
       orig_fitness=fitness;
       gnome=g;
       net=gnome->genesis(gnome->genome_id);
       species=0; //start it in no species
       expected_offspring=0;
       generation=gen;
       eliminate=false;
       error=0;
       winner=false;
       champion=false;
       super_champ_offspring=0;
       //debug vars
       pop_champ=false;
       pop_champ_child=false;
       high_fit=0;
       mut_struct_baby=0;
       mate_baby=0;
       }
       note the line: net=gnome->genesis(gnome->genome_id); what this
       means is that as soon as an organism is created (inside the
       reproduce method) with its constructor, its respective network is
       also created through genesis. in other words, all phenotypes are
       represented in memory simultaneously, even though they don't have
       to be. in most cases, you only need 1 phenotype (network)
       represented in memory at a time, at the time of evaluation.
       therefore, you simply need to change the constructor and comment
       out the genesis line. instead, perform genesis immediately
       preceding evaluation of an organism, and then, immediately after
       that, delete the network. thus, networks are created and destroyed
       serially, freeing up an enormous amount of space. you will notice
       50-75% memory usage reductions. (the next release of neat will work
       this way, but it's easy enough to edit the code in the version you
       have. note that the provided experiments in general do not take up
       very much memory and thus won't need this fix. however, if you are
       using massive populations or working in high-dimensional domains,
       it may help you a lot!)
     * how do i get swig to work?
       first, [40]download the latest version. if you are still having
       problems, make sure you read the swig-related documentation in the
       17-page doc file that came with c++ neat.
       swig is buggy in my experience. you may have to play around to get
       casts right and functions names may change with different versions.
       different c++ compilers may react differently to the same swig
       code.
       one important problem that has been pointed out: swig may replace
       underscores "_" with hyphens "-", causing great confusion! if you
       are trying to run "pole2_test", for example, and it is not working,
       swig may have changed the name to "pole2-test." the following also
       may help (from a neat user who had swig problems):
       "the version of swig i have generates a function called swig_init()
       instead of glist(). i've replaced the code in neatmain.cpp with the
       following, and now it compiles":
       extern "c" {
       extern void swig_init(void);
       };
       void
       main_prog(int argc, char *argv[])
       {
       swig_init();
       scm_shell(argc, argv);
       }
     * how do i ensure that a network stabilizes before taking its
       output(s) for a classification problem?
       the cheap and dirty way to do this is just to activate n times in a
       row where n>1, and hope there are not too many loops or long
       pathways of hidden nodes.
       the proper (and quite nice) way to do it is to check every hidden
       node and output node from one timestep to the next, and see if
       nothing has changed, or at least not changed within some delta.
       once this criterion is met, the output must be stable.
       note that output may not always stabilize in some cases. also, for
       continuous control problems, do not check for stabilization as the
       network never "settles" but rather continuously reacts to a
       changing environment. generally, stabilization is used in
       classification problems, or in board games.
     * why is there no hard bound to the maximum and minimum possible
       connection weight strengths?
       please note: the short answer to this question is that there really
       should be a bound.
       the mutation strength itself basically causes a natural soft bound
       to arise on its own. by imposing your own bounds, you may have
       created a range that is intolerant to the strength of your mutation
       operator. note that it is the relative strengths of weights that
       matters towards creating their functionality, so no bound is
       necessary. however, networks with low bounds on weights will tend
       to produce smoother output (i.e. numbers between 0 and 1 rather
       than only 0 and 1). if you must have a bound, you need to be
       careful it is high enough to allow several weight mutations to
       carry you from 0 to either the higher or lower bound (you don't
       want your smallest mutations to cause radical relative
       differences). in very long evolutionary runs (say 500 or more
       generations), a limit may be helpful in preventing some connections
       from becoming so powerful that new connections cannot hope to
       compete. it is a simple matter to put in hard bounds if you desire.
       here is some code to put in bounds. it can be inserted at the end
       of mutate_link_weights:
       //cap the weights at 8.0 (experimental)
       if (((*curgene)->lnk)->weight>8.0) ((*curgene)->lnk)->weight=8.0;
       else if (((*curgene)->lnk)->weight<-8.0)
       ((*curgene)->lnk)->weight=-8.0;
     * are there any heuristics for deciding on the weight mutation rate?
       preliminary experiments indicate that high weight mutation rates
       (i.e. 50% or more) are useful for control tasks, but lower rates
       (i.e. under 1%) are more appropriate for high input games like
       othello. it may be that the number of inputs is the critical
       factor, and that low-input tasks respond better to high mutation
       weights. although i do not have concrete statistics from which to
       draw strong conclusions, a good rule of thumb is to change the
       weight mutation rate if the systems seems to be performing below
       expectations.
     * can the speciation code be made more efficient?
       since the neat algorithm in general takes up far less computation
       time than the actual evaluations in the task, improving the code's
       efficiency is not an urgent need. however, there is a clever way to
       make speciation faster. thanks to mattias fagerlund for this idea:
       "if you add a species hint to your individuals, speciation runs
       much faster. when a child is created, copy the species of the
       mother into the species_hint of the child. when it's time to place
       the child in a species, first try the species hint. if the child
       belongs there, then we're ready. if it doesn't test all species and
       pick the first species that's compatible. since the speciating
       events are few and far between, each individual will be tested
       against 1 species instead of maybe 13-30 species. if the number of
       species is great, the saving can be great too."
     can i start neat with some inputs disconnected? (important)
       the reason this question is important is that if we can start neat
       with some inputs disconnected, then we can allow neat to decide
       which inputs are important. this process has two good effects: (1)
       you can start minimally even in problems with many inputs and (2)
       you don't need to know a priori what the important features of the
       domain are. recent results (2005) reported in [41]this paper
       suggest that this approach can be quite effective.
       unfortunately, my c++ version of neat, ugo's jneat, and possibly
       other versions cannot automatically start this way, even if given a
       genome with some nodes disconnected. the reason is that in
       crossover, neat was originally designed to drop nodes that aren't
       connected to the network. therefore all the disconnected inputs
       would be lost forever.
       however, neat can easily be fixed to allow starting this way. all
       that needs to be done is to insert some code into the mating
       routines that ensures all nodes get inserted into the offspring's
       genome:
       //new: make sure all sensors and outputs are included
       for(curnode=(g->nodes).begin();curnode!=(g->nodes).end();++curnode)
       {
       if ((((*curnode)->gen_node_label)==input)||
       (((*curnode)->gen_node_label)==bias)||
       (((*curnode)->gen_node_label)==output)) {
       if (!((*curnode)->nodetrait)) nodetraitnum=0;
       else
       nodetraitnum=(((*curnode)->nodetrait)->trait_id)-(*(traits.begin())
       )->trait_id;
       //create a new node off the sensor or output
       new_onode=new nnode((*curnode),newtraits[nodetraitnum]);
       //add the new node
       node_insert(newnodes,new_onode);
       }
       }
       in my c++ code, this must be placed in mate_multipoint,
       mate_multipoint_avg, and mate_singlepoint. (note that in general no
       one uses mate_singlepoint so if you don't use it, you don't need to
       worry about it.) a similar piece of code would need to be inserted
       into jneat's corresponding functions.
       the place to put the code in mate_multipoint is right after the
       section starting with the comment, "figure out which genome is
       better," that ends with "else p1better=false." (near the beginning
       of mate_multipoint.) in mate_multipoint_avg, it should be placed
       after the line "avgene=new gene(0,0,0,0,0,0,0);".
       the insertion of this code will now allow you to start with genomes
       with some inputs disconnected, and neat will add inputs as it sees
       fit!
       additional code: one nice mutation which that be helpful if you
       start with some sensors disconnected is an add_sensor mutation,
       which immediately connects a randomly chosen sensor which was
       previously disconnected to all the outputs at once. that way, the
       sensor can be fully integrated immediately. here is [42]java code
       for jneat by shimon whiteson and [43]c++ code for ken's original
       neat (translated from shimon's code by ken) that give neat this new
       kind of mutation. note that the call for this mutation still must
       be added to species::reproduce in order for neat to use it!
       more information: the newer rtneat code distirbution includes the
       above fixes. however, peter chervenski notes an additional possible
       problem and its fix:
       consider a network with no genes at all - where even a single link
       does not exist. in the first few generations, there are such
       networks - due to the very small id203 for adding a link.
       when mutate_add_node() is called for such a genome, something
       happens or it just tries to traverse the genes vector, but there is
       nothing to be split. so i added this line of code (before
       everything in the function):
       // there is no link to split
       if (this->genes.size() == 0) return false;

general neat methodology faq

   this faq addresses questions that are more abstract or philosophical in
   nature.
     * can you tell me more about speciation and how your method of
       speciation compares to other methods?
       if you look in the references section of [44]our paper, you will
       notice a reference to "mahfoud," which you can get off of citeseer.
       this dissertation is probably the single best review of speciation
       methods that exists.
       that said, the history of speciation is mostly in the area
       "multi-modal function optimization," where evolution is looking for
       multiple solutions at the same time. for example, you might want to
       find several optima for a problem, or several solutions that can
       work together to form a supersolution.
       in contrast, neat uses it for a much different purpose, which is
       protecting innovation. you might wonder why no one has used
       speciation for this purpose in neuroevolution before (in fact, i am
       not sure if it has been used explicitly for this purpose at all in
       the past). the reason is that neural networks previously seemed
       virtually impossible to compare, particularly when their topologies
       differed. in order to speciate, there needs to be some distance
       metric, but if you have no idea how two genomes compare with one
       another, there is no hope for comparison. historical markings
       suddenly made comparison easy, changing the entire problem. in
       addition, perhaps people did not identify the need for speciation
       in neuroevolution.
       you may want to know why we used speciation over the island model
       (or any other model- many exist). the answer is that speciation is
       very natural- it is much the way it works in the real world. the
       main point is that in our speciation model, species arise for
       intrinsic reasons. in other words, the species "just pop up on
       their own," naturally, rather than being imposed extrinsically,
       from the outside, as in the island model. no one knows what species
       or how many species should arise, so neat lets evolution sort it
       out. if a new species appears, the system detects it and separates
       it out. if a species gets good, neat lets it grow relative to other
       species. this is opposed to models where the programmer decides
       what the species are, how big they are, etc..
     * is neat similar to the gep method of genetic programming?
       a description of the gep method can be found [45]here . the paper
       is referenced:
       ferreira, c., (2001). gene expression programming: a new adaptive
       algorithm for solving problems, complex systems, 13 (2): 87 - 129.
       i will contrast the methods. gep evolves program trees while neat
       evolves neural networks, but since both evolve structures they are
       worth comparing.
       on the surface gep has several similarities to neat:
          + evolves structure to some extent (up to a fixed size, unlike
            neat)
          + linear chromosomes
          + preserves syntactic correctness
       however, the differences are very significant:
          + in gep, chromosomes have fixed length. complexification is not
            possible. gep does what almost every other structure evolving
            system does, which is arbitrarily permute over different
            structures in no particular direction (either from more
            complex to less, or less comples to more).
          + although syntactic correctness is preserved (which is a gain
            in the genetic programming world), there is no provision for
            preventing radically different parents from mating. (i.e. the
            analogue of the competing conventions problem for gp's still
            exists) in other words, there is nothing like neat's
            historical marking mechanism.
          + there is no speciation, and no forseeable systematic method
            for speciating under the gep framework, so innovation cannot
            be protected and, as in the last point, many innappropriate
            crossovers will occur.
       it is clear that the authors had a similar vision in mind when they
       created this algorithm to what i was aiming for with neat, but the
       algorithms are quite different in the end. it does bring up the
       possibility of applying neat to evolving non-neural structures such
       as genetic programs, since neat is in principle a general algorithm
       for evolving structure.
     * does neat solve the competing conventions problem?
       first let me clarify, as darrell whitley pointed out, the competing
       conventions problem is the problem of having the same functionality
       represented by different permutations of the same set of connection
       weights. thus, neat is addressing a broader problem, which really
       should be termed the "variable length genome problem," which arises
       from having different topologies and weight configurations in the
       same population. that said, the variable length genome problem is
       the problem of crossing over or comparing neural networks (or other
       structured phenotypes) with different topologies and weights that
       implement similar functionalities. neat's method of matching up
       genomes and measuring compatility for speciation using historical
       markings may be considered a "solution" to the problem of variable
       length genomes in the sense that any two genomes can now be matched
       up in the most sensible manner possible no matter how divergent
       their topologies, and neat can also be considered a solution
       because genomes that are too divergent are not allowed to mate at
       all, avoiding incompatibilities. however, in another sense, one
       could say that the variable length genome problem can never be
       "solved" because it is inherent in any system that generates
       different constructions that solve the same problem. for example,
       both a bird and a bat represent solutions to the problem of flight,
       yet they are not compatible since they are different conventions of
       doing the same thing. the same situation can happen in neat, where
       very different structures might arise that do the same thing. of
       course, such structures will not mate, avoiding the serious
       consequence of damaged offspring. still, it can be said that since
       disparate representations can exist simultaneously, incompatible
       genomes are still present and therefore the problem is not
       "solved." ultimately, it is subjective whether or not the problem
       has been solved. it depends on what you would consider a solution.
       however, it is at least correct to say, "the problem of variable
       length genomes is avoided."
       note that for those who do not consider neat a solution, it follows
       that nature also does not solve the problem, since disparate
       solutions exist in nature. this line of thought generally implies
       that nothing can solve the variable length genome problem.
     * what if i want to evolve a network with
       self-similarities/symmetries/repeating patterns?
       new it turns out that you can do this kind of evolution with neat.
       a recent theory (2006) explaining how is in our paper,
       [46]compositional pattern producing networks: a novel abstraction
       of development .
       a broad review is in our paper, [47]a taxonomy for artificial
       embryogeny.
     * why does neat use a bias node instead of having a bias parameter in
       each node?
       mainly because not all nodes need a bias. thus, it would
       unnecessarily enlarge the search space to be searching for a proper
       bias for every node in the system. instead, we let evolution decide
       which nodes need biases by connecting the bias node to those nodes.
       this issue is not a major concern; it could work either way. you
       can easily code a bias into every node and try that as well.
     * have you tried using non-sigmoid id180?
       yes, that is what cppns do. see [48]compositional pattern producing
       networks: a novel abstraction of development .
       the kinds of id180 available to neat biases the
       kinds of functions it is likely to evolve. as in all machine
       learning, the right bias (if you can find it) provides and
       advantage.
     * how does neat avoid bloat?
       for those who don't know, bloat is a major problem in genetic
       programming (gp) that results from genomes getting bigger and
       bigger without any corresponding increase in fitness, leading to
       unwieldy programs that cannot be optimized further.
       gp permutes through different structures of widely varying size and
       topology. neat does not permute in this way. rather, it builds up
       structures slowly, piece by piece, each piece being tested
       carefully. as structures diverge in neat, they are placed into
       different species so they won't interfere with each other. thus
       there are multiple simultaneous and divergent lines of principled
       build-up of structure. such an approach is more bloat-proof. also,
       crossover in neat is itself bloat-proof, since it does not involve
       tacking on arbitrary trees of structure from widely varying
       topologies. finally, the way neat is implemented, it only adds
       excess or disjoint genes from the more fit parent in a crossover of
       genomes with divergent histories. therefore, you don't get excess
       baggage from inferior solutions.
       there is another important reason that neat avoids bloat that i did
       not mention above. as long as a network represented by a small
       number of genes is competitive, its species will survive in the
       population. in other words, if a species of small genomes "bloats"
       through some genetic cause such as mutation or crossover, the new
       bloated offspring will end up in a different species. unless the
       new species is superior to the old one, the old species will
       survive unbloated and separated from its more bloated successor.
       only when a more complex species displays superior performance will
       the less bloated species become obsolete and begin to shrink. thus,
       unbloated species stick around for as long as they can perform
       well. the moral: speciation prevents bloat!
     * how can neat "start minimally" in a high-input/high-output domain?
       recall that "starting minimally" means beginning evolution with a
       population of networks with minimal structure. in the experiments
       in our papers so far, "minimal structure" means no hidden nodes.
       however, in domains with a very large number of inputs and/or
       outputs, things get weird. let us say you have 50 inputs and 50
       outputs, which might be reasonable for a board-game type domain.
       then if you start with networks with only direct connections, you
       would have 2,500 connections. in contrast, a network with 5 hidden
       nodes would have only 50*5+5*50=500 connections. so at a certain
       point, when the input/output space becomes quite large, the meaning
       of a minimal network changes. in general this happens when a
       reasonable number of hidden nodes for solving the task is
       significantly lower than the number of inputs and/or outputs.
       the conclusion is that you need to be creative about the topologies
       of your initial population in such high-dimensional domains. one
       option, which has not been explored much, is to begin with a
       fully-connected network of a few hidden nodes and without direct
       connections. direct connections will then evolve on their own, and
       new nodes will be added as needed.
       that said, the real answer is that if you are starting with a lot
       of inputs and outputs fully connected, then you are violating the
       principal of starting minimally! however, to be true to the neat
       method, the more appropriate approach would be to start with only a
       subset of the total inputs and outputs, and allow evolution to add
       inputs and outputs as it sees fit, as they help increase fitness.
       my current software distribution does not implement this idea, but
       if you are working in such domains, you should consider that it is
       really the most appropriate approach, and perhaps you should
       consider implementing it before proceeding. question [49]"can i
       start neat with some inputs disconnected?" above gives the code
       necessary to start this way, with some inputs not present in the
       initial genome. update: based on recent results (2005), starting
       with many inputs disconnected appears to be a powerful and
       effective approach. see [50]this paper for more info on these
       results.
       here is a tip for game-playing domains: if you have, say, a board
       with n possible positions, you can get away with only 1 output
       instead of n outputs by moving all n outputs to the inputs. you
       concatenate these n extra inputs with the 2n (or however many)
       normal inputs you have for specifying board position. we will call
       the new n inputs, "candidate inputs." interpret the single output
       as answering the question, "should i move to position [the current
       1 of n candidate inputs nodes that is active]?" so you would poll
       the network for every possible move of the n candidate moves, and
       see which one it likes best. if you try this idea, let me know how
       it compares to the standard n-output method of deciding the next
       move since i don't know of much research on this idea. it greatly
       reduces the number of connections needed to represent a solution.
       [51]this paper explains yet another approach to dealing with high
       input/output domains: instead of evolving a complete set of inputs
       for the whole field of a game, you can evolve a smaller "roving
       eye" that scans the board at will.
     * should a record of innovations be kept around forever, or only for
       the current generation?
       in my implementation of neat, the record is only kept for a
       generation, but there is nothing wrong with keeping them around
       forever. in fact, it may work better. here is the long explanation:
       the reason i didn't keep the record around for the entire run in my
       implementation of neat was because i felt that calling something
       the same mutation that happened under completely different
       circumstances was not intuitive. that is, it is likely that several
       generations down the line, the "meaning" or contribution of the
       same connection relative to all the other connections in a network
       is different than it would have been if it had appeared generations
       ago. i used a single generation as a yardstick for this kind of
       situatiom, although that is admittedly ad hoc.
       that said, functionally speaking, i don't think there is anything
       wrong with keeping innovations around forever. the main effect is
       to generate fewer species. conversely, not keeping them around
       leads to more species..some of them representing the same thing but
       separated nonetheless. it is not currently clear which method
       produces better results under what circumstances.
       note that as species diverge, calling a connection that appeared in
       one species a different name than one that appeared earlier in
       another just increases the incompatibility of the species. this
       doesn't change things much since they were incompatible to begin
       with. on the other hand, if the same species adds a connection that
       it added in an earlier generation, that must mean some members of
       the species had not adopted that connection yet...so now it is
       likely that the first "version" of that connection that starts
       being helpful will win out, and the other will die away. the third
       case is where a connection has already been generally adopted by a
       species. in that case, there can be no mutation creating the same
       connection in that species since it is already taken. the main
       point is, you don't really expect too many truly similar structures
       with different markings to emerge, even with only keeping the
       record around for 1 generation.
       which way works best is a good question. if you have any
       interesting experimental results on this question, please let me
       know.
     * is there another way to do fitness sharing?
       yes. it turns out that the number of offspring alotted to a species
       using fitness sharing as i implemented it is equivalent to the
       following:
       offspring = (averagespeciesfitness /
       total_of_averagespeciesfitnesss) * populationsize
       note that this treatment penalizes species that have very high
       quality solutions if they also have poor solutions. that means that
       species need to produce consistently good solutions in order to
       survive, rather than just produce one rare good solution. it is
       possible that the maximum species fitness could be used instead of
       the average fitness, which would result in this equation:
       offspring = (maxspeciesfitness / total_of_averagespeciesfitnesses)
       * populationsize
       in this case, species with a single very good member would be
       highly rewarded. it is not immediately clear which method is
       better, but both the latter is certainly worth trying. note that
       rewarding species based on their max fitness means investing in
       solutions that may be very inconsistent. in other words, if the
       best member of a species consistently produces poor offspring, the
       algorithm will not detect this. thus, there may be an advantage to
       using the average fitness as my implementation of neat does, since
       it promotes more robust solutions. however, on the other hand, the
       downside of using the average fitness is that we might miss very
       good peak solutions because they happen to be occur in species that
       otherwise contain many mediocre or poor solutions. thus, there
       appears to be a trade-off between the two strategies and further
       research is warranted. in preliminary experiments, mattias
       fagerlund reported no noticable difference between the two
       alternatives.
       a possible compromise is to take the average of only the top n% of
       a species (those members that get to reproduce).
     * is there a way to use negative fitnesses in neat?
       you may have noticed that if you try to use negative fitnesses,
       neat breaks down because of fitness sharing, which requires
       positive fitness values.
       real carbonneau suggested the following solution to this problem:
       compute fitness as you wish, with negative values if desired. then,
       adjust all the fitnesses by replacing them with the distance
       between the actual fitness and the lowest fitness in the
       population. this will scale all the fitnesses above zero, keeping
       the relationships stable.

neat users and projects

   there is so much work going on with neat that i have stopped trying to
   keep track of it here. instead, one way to find information projects
   with neat (aside from the several neat packages available) is to
   [52]search google for "augmenting topologies" or to [53]search google
   scholar for "augmenting topologies" also.

the future of neat

   [54]hypercube-based neat (hyperneat) is the future of neat.

   hyperneat software and source has also become available:
     * [55]hypersharpneat c# by david d'ambrosio. this package extends
       colin green's sharpneat to run as hyperneat. a scalable robot food
       gathering domain is included.
     * [56]hyperneat c++ by jason gauci. includes the scalable big
       box/little box visual discrimination task and a convenient gui for
       exploring the substrate.

neat publications

    note more recent papers from after i moved to ucf are [57]here.

   note: the last three papers are the best introduction to neat

   the following papers talk about the neat method. i conclude each
   reference with some commentary describing what the paper is about. the
   links also lead to abstracts before you download the papers. [58]my
   homepage has links to all my papers, including papers not specifically
   about neat.

   [59]ph.d. dissertation: efficient evolution of neural networks through
   complexification
   kenneth o. stanley
   department of computer sciences, the university of texas at austin
   technical report~ai-tr-04-39, august 2004.
   comment: extensive descriptions of both the neat method and associated
   experiments. 180 pages.
   [60]evolving neural network agents in the nero video game
   kenneth o. stanley, bobby d. bryant, and risto miikkulainen
   department of computer sciences, the university of texas at austin
   proceedings of the [61]ieee 2005 symposium o n computational
   intelligence and games (cig'05). piscataway, nj: ieee, 2005.
   winner of the best paper award at cig'05
   comment: this 8-page paper describes how neat was adapted to work in
   real-time in the [62]nero video game.
   [63]automatic feature selection in neuroevolution
   shimon whiteson, peter stone, kenneth o. stanley, risto miikkulainenn
   and nate kohl
   department of computer sciences, the university of texas at austin
   to appear in:proceedings of the genetic and evolutionary computation
   conference (gecco-2005).
   comment: describes how starting neat with most inputs disconnected and
   letting neat decide which ones to connect is more effective than
   starting with all inputs connected, particularly in problems with many
   potential inputs.
   [64]real-time neuroevolution in the nero video game
   kenneth o. stanley, bobby d. bryant, and risto miikkulainen
   department of computer sciences, the university of texas at austin
   [65]ieee transactions on evolutionary computation, volume 9, number 6,
   pages 653-668, december 2005.
   comment: journal paper describes how neat was enhanced to run in
   real-time inside a new genre of video game where agents are trained by
   the player during gameplay.
   [66]evolving a roving eye for go
   kenneth o. stanley and risto miikkulainen
   department of computer sciences, the university of texas at austin
   proceedings of the genetic and evolutionary computation conference
   (gecco-2004). new york, ny: springer-verlag, 2004
   comment: this conference paper describes how a roving eye of a fixed
   input size can be evolved to play go on boards of different sizes, and
   how an eye trained on a smaller board can go on to learn on a larger
   board better than an eye trained starting on the larger board.
   [67]evolving adaptive neural networks with and without adaptive
   synapses
   kenneth o. stanley, bobby d. bryant, and risto miikkulainen
   department of computer sciences, the university of texas at austin
   proceedings of the 2003 ieee congress on evolutionary computation
   (cec-2003). canberra, australia: ieee press, 2003
   comment: conference paper describing experiments evolving neural
   networks with synpatic weights that change over time according to local
   hebbian rules. explains how traits are used in neat: see section 2.4 of
   this paper. traits are referred to as a rule set in the paper.
   [68]competitive coevolution through evolutionary complexification
   kenneth o. stanley and risto miikkulainen
   department of computer sciences, the university of texas at austin
   [69]journal of artificial intelligence research 21: 63-100, 2004.
   comment: this 38 page journal article expands on the importance
   complexification from a minimal starting point, and shows how it leads
   to the discovery of more complex structures than would otherwise be
   possible.
   [70]continual coevolution through complexification
   kenneth o. stanley and risto miikkulainen
   department of computer sciences, the university of texas at austin
   to appear in proceedings of the genetic and evolutionary computation
   conference (gecco-2002). san francisco, ca: morgan kaufmann, 2002
   comment: conference paper about using the idea of complexification in
   neat to allow for continual elaboration on strategies leading to a
   sustained arms race in competitive coevolution.
   [71]efficient evolution of neural network topologies
   kenneth o. stanley and risto miikkulainen
   department of computer sciences, the university of texas at austin
   proceedings of the 2002 congress on evolutionary computation (cec '02).
   piscataway, nj: ieee, 2002
   comment: a short conference paper that describes neat from the
   perspective of deconstructing the system using ablation studies.
   [72]efficient id23 through evolving neural network
   topologies
   kenneth o. stanley and risto miikkulainen
   department of computer sciences, the university of texas at austin
   to appear in proceedings of the genetic and evolutionary computation
   conference (gecco-2002). san francisco, ca: morgan kaufmann, 2002
   comment: a conference paper that describes neat from the point of view
   of performance and visualization.
   winner of the [73]best paper award in id107
   [74]evolving neural networks through augmenting topologies
   kenneth o. stanley and risto miikkulainen
   department of computer sciences, the university of texas at austin
   [75]evolutionary computation 10(2):99-127, 2002.
   comment: a journal paper including a comprehensive description of the
   neat method, as well as substantial background information and
   performance analysis. should be useful for implementing your own
   version of neat.

   note: a complete list of my publications can be found on my
   [76]homepage.

  contact me here:

   [77]kstanley@cs.ucf.edu
   last updated 12/12/14
   updates: this page has been substantially revised on 8/31/03. new
   answers were added to the ends of both faqs as of 5/8/03. a [78]new
   paper on evolving synaptic plasticity (using traits) is available
   through the this page as of 6/22/03. a neat user's group opened on
   yahoo on 8/26/03. more projects listed on 12/4/03. on 12/21/03 mattias
   fagerlund released full source code and demos for delphi neat. 2/16/04:
   a [79]new question explains how to start neat with genomes with some
   inputs initially disconnected from the the network. 3/5/04: the
   [80]question on starting disconnected now links to code for
   mutate_add_sensor both in java and c++. 3/24/04: added [81]link to new
   paper on evolving a roving eye with neat for go. 4/7/04: added link to
   sharpneat, a new neat software package. 6/9/04: added link to anji
   (another neat java implementation). 9/14/04: added [82]question and
   answer about testing with xor. 9/15/04: elaborated answer on testing
   with xor. 10/27/04: added 2 more papers to the publications list.
   5/4/05: added 2 more papers (feature selection and nero award winner)
   and updated answers to faq questions on starting with some inputs
   disconnected, also pointing them to the new paper. 9/7/05: linked ashot
   petrosian's [83]neat code documentation 1/20/06: changed link to nero
   tech report to the journal paper that replaced it. 9/8/06: added links
   to rtneat source code and neat4j, a new java-based neat release.
   10/12/06: updated answer to question, "can i start neat with some
   inputs disconnected?" 5/20/07: added link to eplex in intro text.
   1/10/08: fixed broken links, updated out-of-date text, added hyperneat
   links. 1/16/08: updated answer to "have you tried using non-sigmoid
   id180" to cite cppns. 4/24/08: added link to my original
   notes wherein i thought of the neat algorithm. 5/9/08: updated mention
   of hyperneat at top of page to link to more papers. 2/8/09: added link
   to eplex publications. 4/17/09: linked to hyperneat users page. 1/6/10:
   removed broken link to neat code documentation. 3/9/10: fixed link to
   delphineat (now goes to eplex server) 6/15/10: added links to neat4j
   and encog neat. 7/19/10: added question, "can you explain some of the
   neat parameters?" 7/19/10: added link to wesley tansey's sharpneat 2
   ttt tutorial. 9/5/11: small change to hyperneat text and links at top
   of page. 1/12/12: added link to objectiveneat package. 9/19/12: added
   link to peter chervenski's multineat software package. 3/2/13: added
   link to eric laukien's neat visualizer package. 9/17/13: added link to
   fernando torres' reorganized github version of neat c++. 4/21/14: added
   link to fred mitchell's rubyneat platform. 10/30/14: added link to sean
   dougherty's accneat software package. 12/12/14: added link to daniel
   jallov's unityneat software package. 5/5/15: switched list of neat
   software packages to link to neat software catalog

references

   1. http://eplex.cs.ucf.edu/hyperneatpage/hyperneat.html
   2. https://www.cs.ucf.edu/~kstanley/neat.html#updates
   3. http://www.eecs.ucf.edu/
   4. http://eplex.cs.ucf.edu/
   5. http://eplex.cs.ucf.edu/hyperneatpage/hyperneat.html
   6. http://eplex.cs.ucf.edu/hyperneatpage/hyperneat.html
   7. http://eplex.cs.ucf.edu/neat_origins/neatorigin1.html
   8. http://www.nashcoding.com/?p=90
   9. http://www.cs.ucf.edu/~kstanley
  10. http://gar.eecs.ucf.edu/
  11. http://nerogame.org/
  12. https://www.cs.ucf.edu/~kstanley/neat.html#intro
  13. https://www.cs.ucf.edu/~kstanley/neat.html#group
  14. https://www.cs.ucf.edu/~kstanley/neat.html#book
  15. https://www.cs.ucf.edu/~kstanley/neat.html#faq1
  16. https://www.cs.ucf.edu/~kstanley/neat.html#faq2
  17. https://www.cs.ucf.edu/~kstanley/neat.html#users
  18. https://www.cs.ucf.edu/~kstanley/neat.html#future
  19. https://www.cs.ucf.edu/~kstanley/neat.html#papers
  20. http://www.cs.ucf.edu/~kstanley
  21. http://eplex.cs.ucf.edu/neat_software/
  22. mailto:kstanley@eecs.ucf.edu
  23. http://groups.yahoo.com/group/neat/
  24. http://www.amazon.com/exec/obidos/asin/193184108x/qid=1034633319/sr=1\1-1/ref=sr_11_1/104-5338435-0523903
  25. mailto:vierugo@yahoo.it
  26. mailto:fup@ai-junkie.com
  27. mailto:matlab_neat@web.de
  28. https://www.cs.ucf.edu/~kstanley/neat.html#intro
  29. http://groups.yahoo.com/group/neat/
  30. mailto:kstanley@cs.ucf.edu
  31. http://nn.cs.utexas.edu/soft-view.php?softid=4
  32. http://nn.cs.utexas.edu/?neat-c
  33. http://nn.cs.utexas.edu/soft-view.php?softid=5
  34. http://nn.cs.utexas.edu/soft-view.php?softid=6
  35. mailto:fup@ai-junkie.com
  36. http://nn.cs.utexas.edu/soft-view.php?softid=23
  37. https://www.cs.ucf.edu/~kstanley/neat.html#adaptpaper
  38. mailto:kstanley@cs.ucf.edu
  39. mailto:kstanley@cs.ucf.edu
  40. http://www.swig.org/
  41. https://www.cs.ucf.edu/~kstanley/neat.html#feature_selection
  42. http://www.cs.ucf.edu/~kstanley/mutate_add_sensor_java
  43. http://www.cs.ucf.edu/~kstanley/mutate_add_sensor
  44. http://nn.cs.utexas.edu/keyword?stanley:alife03
  45. http://www.gene-expression-programming.com/webpapers/gep.pdf
  46. http://eplex.cs.ucf.edu/index.php?option=com_content&task=view&id=14&itemid=28#stanley.gpem07
  47. http://nn.cs.utexas.edu/keyword?stanley:alife03
  48. http://eplex.cs.ucf.edu/index.php?option=com_content&task=view&id=14&itemid=28#stanley.gpem07
  49. https://www.cs.ucf.edu/~kstanley/neat.html#disconnected
  50. https://www.cs.ucf.edu/~kstanley/neat.html#feature_selection
  51. https://www.cs.ucf.edu/~kstanley/neat.html#go
  52. http://www.google.com/search?source=ig&hl=en&rlz=&q="augmenting+topologies"
  53. http://scholar.google.com/scholar?source=ig&hl=en&rlz=&q="augmenting+topologies"&um=1&ie=utf-8&sa=n&tab=ws
  54. http://eplex.cs.ucf.edu/hyperneatpage/hyperneat.html
  55. http://eplex.cs.ucf.edu/index.php?option=com_content&task=view&id=17&itemid=32#hypersharpneat
  56. http://eplex.cs.ucf.edu/index.php?option=com_content&task=view&id=17&itemid=32#hyperneat1
  57. http://eplex.cs.ucf.edu/publications/
  58. http://www.cs.ucf.edu/~kstanley
  59. http://nn.cs.utexas.edu/keyword?stanley:phd04
  60. http://nn.cs.utexas.edu/keyword?stanley:cig05
  61. http://csapps.essex.ac.uk/cig/
  62. http://nerogame.org/
  63. http://nn.cs.utexas.edu/keyword?whiteson:gecco05
  64. http://nn.cs.utexas.edu/keyword?stanley:ieeetec05
  65. http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1545941
  66. http://nn.cs.utexas.edu/keyword?stanley:gecco04
  67. http://www.cs.utexas.edu/users/nn/pub-view.php?record_key(pubs)=pubid&pubid(pubs)=131
  68. http://nn.cs.utexas.edu/keyword?stanley:jair04
  69. http://www.jair.org/
  70. http://nn.cs.utexas.edu/keyword?stanley:gecco02a
  71. http://nn.cs.utexas.edu/pub-view.php?pubid=114
  72. http://nn.cs.utexas.edu/keyword?stanley:gecco02b
  73. http://www-illigal.ge.uiuc.edu:8080/gecco-2002/awards-winners.html
  74. http://nn.cs.utexas.edu/keyword?stanley:ec02
  75. http://www-mitpress.mit.edu/catalog/item/default.asp?ttype=4&tid=25
  76. http://www.cs.ucf.edu/~kstanley
  77. mailto:kstanley@cs.ucf.edu
  78. https://www.cs.ucf.edu/~kstanley/neat.html#adaptpaper
  79. https://www.cs.ucf.edu/~kstanley/neat.html#disconnected
  80. https://www.cs.ucf.edu/~kstanley/neat.html#disconnected
  81. https://www.cs.ucf.edu/~kstanley/neat.html#go
  82. https://www.cs.ucf.edu/~kstanley/neat.html#xor
  83. https://www.cs.ucf.edu/~kstanley/neat.html#neatref
