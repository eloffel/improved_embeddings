                  shared task: machine translation of news

   the recurring translation task of the [1]wmt workshops focuses on news
   text and (mainly) european language pairs. for the year the language
   pairs are:
     * chinese-english
     * czech-english
     * finnish-english
     * german-english
     * latvian-english
     * russian-english
     * turkish-english

   the first three european language pairs are sponsored by the eu
   horizon2020 projects qt21 and cracker, the finnish-english task is
   sponsored by the university of helsinki, funding for the last two
   language pairs come from yandex, and the chinese-english task is
   sponsored by several chinese institutions (see footer). we provide
   parallel corpora for all languages as training data, and additional
   resources [2]for download.

  goals

   the goals of the shared translation task are:
     * to investigate the applicability of current mt techniques when
       translating into languages other than english
     * to examine special challenges in translating between european
       languages, including word order differences and morphology
     * to investigate the translation of low-resource, morphologically
       rich languages
     * to create publicly available corpora for machine translation and
       machine translation evaluation
     * to generate up-to-date performance numbers for european languages
       in order to provide a basis of comparison in future research
     * to offer newcomers a smooth start with hands-on experience in
       state-of-the-art id151 methods

   we hope that both beginners and established research groups will
   participate in this task.

  important dates

   release of training data for shared tasks january, 2017
   test data released (except zh-en/en-zh)   may 2, 2017
   translation submission deadline           may 8, 2017
   test week for en-zh/zh-en                 may 15-22, 2017
   start of manual evaluation                may 15, 2017
   end of manual evaluation (provisional)    june 4, 2017

  task description

   we provide training data for seven language pairs, and a common
   framework. the task is to improve methods current methods. this can be
   done in many ways. for instance participants could try to:
     * improve word alignment quality, phrase extraction, phrase scoring
     * add new components to the open source software of the baseline
       system
     * augment the system otherwise (e.g. by preprocessing, reranking,
       etc.)
     * build an entirely new translation systems

   participants will use their systems to translate a test set of unseen
   sentences in the source language. the translation quality is measured
   by a manual evaluation and various automatic id74.
   participants agree to contribute to the manual evaluation about eight
   hours of work.

   you may participate in any or all of the seven language pairs. for all
   language pairs we will test translation in both directions. to have a
   common framework that allows for comparable results, and also to lower
   the barrier to entry, we provide a common training set.

   we also strongly encourage your participation, if you use your own
   training corpus, your own sentence alignment, your own language model,
   or your own decoder.

   if you use additional training data or existing translation systems,
   you must flag that your system uses additional data. we will
   distinguish system submissions that used the provided training data
   (constrained) from submissions that used significant additional data
   resources. note that basic linguistic tools such as taggers, parsers,
   or morphological analyzers are allowed in the constrained condition.

   your submission report should highlight in which ways your own methods
   and data differ from the standard task. we may break down submitted
   results in different tracks, based on what resources were used. we are
   mostly interested in submission that are constrained to the provided
   training data, so that the comparison is focused on the methods, not on
   the data used. you may submit contrastive runs to demonstrate the
   benefit of additional training data.

  data

    licensing of data

   the data released for the wmt17 new translation task can be freely used
   for research purposes, we just ask that you cite the wmt17 shared task
   overview paper, and respect any additional citation requirements on the
   individual data sets. for other uses of the data, you should consult
   with original owners of the data sets.

    training data

   the provided data is mainly taken from public data sources such as the
   [3]europarl corpus, and the [4]un corpus. additional training data is
   taken from the news commentary corpus, which we re-extract every year
   from the task.

   we have added suitable additional training data to some of the language
   pairs.
   you may also use the following monolingual corpora released by the ldc:
     * ldc2011t07 [5]english gigaword fifth edition
     * ldc2009t13 [6]english gigaword fourth edition
     * ldc2007t07 [7]english gigaword third edition
     * ldc2009t27 [8]chinese gigaword fourth edition

   note that the released data is not tokenized and includes sentences of
   any length (including empty sentences). all data is in unicode (utf-8)
   format. the following moses tools allow the processing of the training
   data into tokenized format:
     * tokenizer tokenizer.perl
     * detokenizer detokenizer.perl
     * lowercaser lowercase.perl
     * sgml wrapper wrap-xml.perl

   these tools are available in the [9]moses git repository.

    development data

   to evaluate your system during development, we suggest using the 2016
   test set. the data is provided in raw text format and in an sgml format
   that suits the nist scoring tool. we also release other dev and test
   sets from previous years.

   year cs-en de-en fi-en lv-en ru-en tr-en zh-en
   2008              
   2009              
   2010              
   2011              
   2012                                  
   2013                                  
   2014                                  
   2015                                    
   2016                                            

   the 2017 test sets will be created from a sample of online newspapers
   from august 2016. the english-x sets are created using equal sized
   samples of english, and language x, with each sample professionally
   translated into the other language.

   we have released development data for the tasks that are new this year,
   i.e. chinese-english and latvian-english. it is created in the same way
   as the test set.

   the news-test2011 set has three additional czech translations that you
   may want to use. you can download them from [10]charles university.

    download

     * parallel data:

   file size cs-en de-en fi-en lv-en ru-en tr-en zh-en notes
   [11]europarl v7 628mb                   same as previous year, [12]corpus
   home page
   [13]europarl v8 238mb                   lv-en is new for this year,
   [14]corpus home page
   [15]common crawl corpus 876mb                     same as last year
   [16]news commentary v12 162mb                       updated
   [17]czeng 1.6 3.1gb                 new for 2017. [18]register and
   download czeng 1.6.
   yandex corpus 121mb                 [19]ru-en
   [20]wiki headlines 9.1mb                   provided by cmu..
   [21]setimes2 44 mb                 distributed by [22]opus
   [23]un parallel corpus v1.0 3.6 gb                   new for 2017.
   [24]register and download
   [25]rapid corpus of eu press releases 156 mb                     new for
   2017. prepared by [26]tilde
   [27]leta translated news 2 mb                 new for 2017. prepared by
   the university of latvia
   [28]digital corpus of european parliament 123 mb                 new for
   2017. prepared by the university of latvia
   [29]online books 309 kb                 new for 2017. prepared by the
   university of latvia
   [30]cwmt corpus                 new for 2017.
     * monolingual language model training data:

   corpus cs de en fi lv ru tr zh all languages
   combined notes
   [31]europarl v7/v8 [32]32mb [33]107mb [34]99mb [35]95mb [36]29mb

   news commentary
   [37]14mb [38]19mb [39]22mb     [40]19mb     [41]129mb updated
   common crawl
   [42]10.5gb [43]102gb [44]103 gb [45]5.3gb [46]800mb [47]42gb [48]18gb
   [49]33gb   deduplicated with development and evaluation sentences
   removed. english was updated 31 january 2016 to remove bad utf-8.
   latvian and chinese are new this year, others are as last year.
   downloads can be verified with [50]sha512 checksums. [51]more english
   is available for unconstrained participants.
   news crawl: articles from 2007 [52]3.7mb [53]92mb [54]198mb
   [55]302mb

   news crawl
   extracted article text from various online news publications.
   the data sets from 2007-2015 (except latvian), are the same as [56]last
   year's.
   news crawl: articles from 2008 [57]191mb [58]313mb [59]672mb
     [60]2.3mb     [61]1.5gb
   news crawl: articles from 2009 [62]194mb [63]296mb [64]757mb
     [65]5.1mb     [66]1.6gb
   news crawl: articles from 2010 [67]107mb [68]135mb [69]345mb
   [70]2.5mb     [71]727mb
   news crawl: articles from 2011 [72]389mb [73]746mb [74]784mb
   [75]564mb     [76]3.1gb
   news crawl: articles from 2012 [77]337mb [78]946mb [79]751mb
   [80]568mb     [81]3.1gb
   news crawl: articles from 2013 [82]395mb [83]1.6gb [84]1.1gb
   [85]730mb     [86]4.3gb
   news crawl: articles from 2014 [87]380mb [88]2.1gb [89]1.4gb [90]52mb
   [91]52mb [92]801mb     [93]5.3gb (excludes lv)
   news crawl: articles from 2015 [94]360mb [95]2.2gb [96]1.3gb [97]203mb
   [98]154mb [99]608mb     [100]4.8g (excludes lv)
   news crawl: articles from 2016 [101]252mb [102]1.6gb [103]1gb
   [104]163mb [105]123mb [106]418mb [107]77mb   [108]3.7g
   news discussions. version 1 from 2014/15 [109]1.7gb   extracted from
   comment sections of online newspapers. version 2 is new for this year.
   news discussions. version 2 from 2015/16 [110]6.3gb
       the common crawl monolingual data is hosted by amazon web services
       as a [111]public data set. the underlying s3 url is
       s3://web-language-models/wmt16/deduped.
     * [112]development sets (27 mb)
     * [113]test sets
     * new: [114]improved translations for zh test sets
     * new: [115]all submissions (in mt-compareval analysis tool)
     * new: [116]all submissions (tarball)
    preprocessed data new for 2017.
       we provide preprocessed versions of all training and development
       data (so far without zh-en). these are preprocesed with standard
       moses tools and ready for use in mt training. this preprocessed
       data is distributed with the intention that it will be useful as a
       standard data set for future research. the preprocessed data can be
       obtained [117]here
    test set submission punctuation in the official test sets will be
       encoded with ascii characters (not complex unicode characters) as
       much as possible. you may want to [118]normalize your system's
       output before submission.
       to submit your results, please first convert into into sgml format
       as required by the nist id7 scorer, and then upload it to the
       website [119]matrix.statmt.org.
       for chinese output, you should submit unsegmented text, since our
       primary measure is human evaluation. for automatic scoring (in the
       matrix) we use id74 computed on characters, scoring with v1.3 of
       the nist scorer only. a script to convert a chinese sgm file to
       characters can be found [120]here.
       sgml format
       each submitted file has to be in a format that is used by standard
       scoring scripts such as nist id7 or ter.
       this format is similar to the one used in the source test set files
       that were released, except for:

     * first line is <tstset trglang="en" setid="newstest2017"
       srclang="any">, with trglang set to either en, de, fr, es, cs or
       ru. important: srclang is always any.
     * each document tag also has to include the system name, e.g.
       sysid="uedin".
     * closing tag (last line) is </tstset>

   the script [121]wrap-xml.perl makes the conversion of a output file in
   one-segment-per-line format into the required sgml file very easy:

   format: wrap-xml.perl language src_sgml_file system_name < in > out
   example: wrap-xml.perl en newstest2016-src.de.sgm google <
   decoder-output > decoder-output.sgm

    upload to website

   upload happens in three easy steps:
    1. go to the website [122]matrix.statmt.org.
    2. create an account under the menu item account -> create account.
    3. go to account -> upload/edit content, and follow the link "submit a
       system run"
          + select as test set "newstest2017" and the language pair you
            are submitting
          + select "create new system"
          + click "continue"
          + on the next page, upload your file and add some description

   if you are submitting contrastive runs, please submit your primary
   system first and mark it clearly as the primary submission.

  evaluation

   evaluation will be done both automatically as well as by human
   judgement.
     * manual scoring: we will collect subjective judgments about
       translation quality from human annotators. if you participate in
       the shared task, we ask you to perform a defined amount of
       evaluation per language pair submitted. the amount of manual
       evaluation is tbd for 2016.
     * as in previous years, we expect the translated submissions to be in
       recased, detokenized, xml format, just as in most other translation
       campaigns (nist, tc-star).

  acknowledgements

   this conference has received funding from the european union's horizon
   2020 research and innovation programme under grant agreements 645452
   ([123]qt21) and 645357 ([124]cracker).
   we thank [125]yandex for their donation of data for the russian-english
   and turkish-english news tasks, and the university of helsinki for
   their donation for the finnish-english news tasks. the chinese-english
   task is sponsored by nanjing university, xiamen university, the
   institutes of computing technology and of automation, chinese academy
   of science, northeastern university (china) and datum data co., ltd

references

   1. http://www.statmt.org/wmt17/index.html
   2. http://www.statmt.org/wmt17/translation-task.html#download
   3. http://www.statmt.org/europarl/
   4. https://cms.unov.org/uncorpus/
   5. http://www.ldc.upenn.edu/catalog/catalogentry.jsp?catalogid=ldc2011t07
   6. http://www.ldc.upenn.edu/catalog/catalogentry.jsp?catalogid=ldc2009t13
   7. http://www.ldc.upenn.edu/catalog/catalogentry.jsp?catalogid=ldc2007t07
   8. https://catalog.ldc.upenn.edu/ldc2009t27
   9. https://github.com/moses-smt/mosesdecoder
  10. https://ufal-point.mff.cuni.cz/xmlui/handle/11858/00-097c-0000-0008-d259-7
  11. http://www.statmt.org/wmt13/training-parallel-europarl-v7.tgz
  12. http://www.statmt.org/europarl/
  13. http://data.statmt.org/wmt17/translation-task/training-parallel-ep-v8.tgz
  14. http://www.statmt.org/europarl/
  15. http://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz
  16. http://data.statmt.org/wmt17/translation-task/training-parallel-nc-v12.tgz
  17. http://ufal.mff.cuni.cz/czeng/czeng16
  18. http://ufal.mff.cuni.cz/czeng/czeng16
  19. https://translate.yandex.ru/corpus?lang=en
  20. http://www.statmt.org/wmt15/wiki-titles.tgz
  21. http://opus.lingfil.uu.se/setimes2.php
  22. http://opus.lingfil.uu.se/
  23. https://cms.unov.org/uncorpus/
  24. https://cms.unov.org/uncorpus/
  25. http://data.statmt.org/wmt17/translation-task/rap 016.tgz
  26. http://tilde.com/
  27. http://data.statmt.org/wmt17/translation-task/leta.v1.tgz
  28. http://data.statmt.org/wmt17/translation-task/dcep.lv-en.v1.tgz
  29. http://data.statmt.org/wmt17/translation-task/books.lv-en.v1.tgz
  30. http://nlp.nju.edu.cn/cwmt-wmt/
  31. http://www.statmt.org/europarl/
  32. http://www.statmt.org/wmt14/training-monolingual-europarl-v7/europarl-v7.cs.gz
  33. http://www.statmt.org/wmt14/training-monolingual-europarl-v7/europarl-v7.de.gz
  34. http://www.statmt.org/wmt14/training-monolingual-europarl-v7/europarl-v7.en.gz
  35. http://www.statmt.org/wmt15/europarl-v8.fi.tgz
  36. http://data.statmt.org/wmt17/translation-task/europarl-v8.lv.tgz
  37. http://data.statmt.org/wmt17/translation-task/news-commentary-v12.cs.gz
  38. http://data.statmt.org/wmt17/translation-task/news-commentary-v12.de.gz
  39. http://data.statmt.org/wmt17/translation-task/news-commentary-v12.en.gz
  40. http://data.statmt.org/wmt17/translation-task/news-commentary-v12.ru.gz
  41. http://data.statmt.org/wmt17/translation-task/training-monolingual-nc-v12.tgz
  42. http://web-language-models.s3-website-us-east-1.amazonaws.com/wmt16/deduped/cs.xz
  43. http://web-language-models.s3-website-us-east-1.amazonaws.com/wmt16/deduped/de.xz
  44. http://web-language-models.s3-website-us-east-1.amazonaws.com/wmt16/deduped/en-new.xz
  45. http://web-language-models.s3-website-us-east-1.amazonaws.com/wmt16/deduped/fi.xz
  46. http://web-language-models.s3-website-us-east-1.amazonaws.com/wmt17/deduped/lv.xz
  47. http://web-language-models.s3-website-us-east-1.amazonaws.com/wmt16/deduped/ru.xz
  48. http://web-language-models.s3-website-us-east-1.amazonaws.com/wmt16/deduped/tr.xz
  49. http://web-language-models.s3-website-us-east-1.amazonaws.com/ngrams/zh/deduped/zh.deduped.xz
  50. http://data.statmt.org/ngrams/wmt16/checksums
  51. http://data.statmt.org/ngrams/deduped_en/
  52. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2007.cs.shuffled.gz
  53. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2007.de.shuffled.gz
  54. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2007.en.shuffled.gz
  55. http://www.statmt.org/wmt13/training-monolingual-news-2007.tgz
  56. http://www.statmt.org/wmt16/translation-task.html
  57. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2008.cs.shuffled.gz
  58. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2008.de.shuffled.gz
  59. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2008.en.shuffled.gz
  60. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2008.ru.shuffled.gz
  61. http://www.statmt.org/wmt13/training-monolingual-news-2008.tgz
  62. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2009.cs.shuffled.gz
  63. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2009.de.shuffled.gz
  64. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2009.en.shuffled.gz
  65. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2009.ru.shuffled.gz
  66. http://www.statmt.org/wmt13/training-monolingual-news-2009.tgz
  67. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2010.cs.shuffled.gz
  68. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2010.de.shuffled.gz
  69. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2010.en.shuffled.gz
  70. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2010.ru.shuffled.gz
  71. http://www.statmt.org/wmt13/training-monolingual-news-2010.tgz
  72. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2011.cs.shuffled.gz
  73. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2011.de.shuffled.gz
  74. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2011.en.shuffled.gz
  75. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2011.ru.shuffled.gz
  76. http://www.statmt.org/wmt13/training-monolingual-news-2011.tgz
  77. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2012.cs.shuffled.gz
  78. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2012.de.shuffled.gz
  79. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2012.en.shuffled.gz
  80. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2012.ru.shuffled.gz
  81. http://www.statmt.org/wmt13/training-monolingual-news-2012.tgz
  82. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2013.cs.shuffled.gz
  83. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2013.de.shuffled.gz
  84. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2013.en.shuffled.gz
  85. http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2013.ru.shuffled.gz
  86. http://www.statmt.org/wmt14/training-monolingual-news-2013.tgz
  87. http://www.statmt.org/wmt15/training-monolingual-news-crawl-v2/news.2014.cs.shuffled.v2.gz
  88. http://www.statmt.org/wmt15/training-monolingual-news-crawl-v2/news.2014.de.shuffled.v2.gz
  89. http://www.statmt.org/wmt15/training-monolingual-news-crawl-v2/news.2014.en.shuffled.v2.gz
  90. http://www.statmt.org/wmt15/training-monolingual-news-crawl-v2/news.2014.fi.shuffled.v2.gz
  91. http://data.statmt.org/wmt17/translation-task/news.2014.lv.shuffled.gz
  92. http://www.statmt.org/wmt15/training-monolingual-news-crawl-v2/news.2014.ru.shuffled.v2.gz
  93. http://www.statmt.org/wmt15/training-monolingual-news-2014.v2.tgz
  94. http://data.statmt.org/wmt16/translation-task/news.2015.cs.shuffled.gz
  95. http://data.statmt.org/wmt16/translation-task/news.2015.de.shuffled.gz
  96. http://data.statmt.org/wmt16/translation-task/news.2015.en.shuffled.gz
  97. http://data.statmt.org/wmt16/translation-task/news.2015.fi.shuffled.gz
  98. http://data.statmt.org/wmt17/translation-task/news.2015.lv.shuffled.gz
  99. http://data.statmt.org/wmt16/translation-task/news.2015.ru.shuffled.gz
 100. http://data.statmt.org/wmt16/translation-task/training-monolingual-news-crawl.tgz
 101. http://data.statmt.org/wmt17/translation-task/news.2016.cs.shuffled.gz
 102. http://data.statmt.org/wmt17/translation-task/news.2016.de.shuffled.gz
 103. http://data.statmt.org/wmt17/translation-task/news.2016.en.shuffled.gz
 104. http://data.statmt.org/wmt17/translation-task/news.2016.fi.shuffled.gz
 105. http://data.statmt.org/wmt17/translation-task/news.2016.lv.shuffled.gz
 106. http://data.statmt.org/wmt17/translation-task/news.2016.ru.shuffled.gz
 107. http://data.statmt.org/wmt17/translation-task/news.2016.tr.shuffled.gz
 108. http://data.statmt.org/wmt17/translation-task/training-monolingual-news-crawl.tgz
 109. http://www.statmt.org/wmt15/news-discuss-v1.en.txt.gz
 110. http://data.statmt.org/wmt17/translation-task/news-discuss.2015-2016.en.shuffled.gz
 111. https://aws.amazon.com/public-data-sets/
 112. http://data.statmt.org/wmt17/translation-task/dev.tgz
 113. http://data.statmt.org/wmt17/translation-task/test.tgz
 114. http://data.statmt.org/wmt17/translation-task/test-update-1.tgz
 115. http://wmt.ufal.cz/
 116. http://data.statmt.org/wmt17/translation-task/wmt17-submitted-data-v1.0.tgz
 117. http://data.statmt.org/wmt17/translation-task/preprocessed
 118. http://www.statmt.org/wmt11/normalize-punctuation.perl
 119. http://matrix.statmt.org/
 120. http://www.statmt.org/wmt17/tokenizechinese.py
 121. http://www.statmt.org/wmt11/wrap-xml.perl
 122. http://matrix.statmt.org/
 123. http://www.qt21.eu/
 124. http://www.meta-net.eu/projects/cracker/
 125. http://www.yandex.com/
