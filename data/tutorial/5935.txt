   #[1]apple machine learning journal

[2]machine learning journal[3]     machine learning journal

real-time recognition of handwritten chinese characters spanning a large
inventory of thirty thousand characters real-time recognition of handwritten
chinese characters spanning a large inventory of 30,000 characters

   vol. 1, issue 5     september 2017 september two thousand seventeen by
   handwriting recognition team
     __________________________________________________________________

   handwriting recognition is more important than ever given the
   prevalence of mobile phones, tablets, and wearable gear like
   smartwatches. the large symbol inventory required to support chinese
   handwriting recognition on such mobile devices poses unique challenges.
   this article describes how we met those challenges to achieve real-time
   performance on iphone, ipad, and apple watch (in scribble mode). our
   recognition system, based on deep learning, accurately handles a set of
   up to 30,000 characters. to achieve acceptable accuracy, we paid
   particular attention to data collection conditions, representativeness
   of writing styles, and training regimen. we found that, with proper
   care, even larger inventories are within reach. our experiments show
   that accuracy only degrades slowly as the inventory increases, as long
   as we use training data of sufficient quality and in sufficient
   quantity.

introduction

   handwriting recognition can enhance user experience on mobile devices,
   particularly for chinese input given the relative complexity of
   keyboard methods. chinese handwriting recognition is uniquely
   challenging, due to the large size of the underlying character
   inventory. unlike alphabet-based writing, which typically involves on
   the order of 100 symbols, the set of h  nz   characters in chinese
   national standard gb18030-2005 contains 27,533 entries, and many
   additional logographic characters are in use throughout greater china.

   for computational tractability, it is usual to focus on a restricted
   number of characters, deemed most representative of usage in daily
   life. thus, the standard gb2312-80 set includes only 6,763 entries
   (3,755 and 3,008 characters in the level-1 and level-2 sets,
   respectively). the closely aligned character set used in the popular
   casia databases, built by the institute of automation of chinese
   academy of sciences, comprises a total of 7,356 entries [4][6]. the
   scut-couch database has similar coverage [5][8].

   these sets tend to reflect commonly used characters across the entire
   population of chinese writers. at the individual user level, however,
   what is    commonly used    typically varies from one person to the next.
   most people need at least a handful of characters deemed    infrequently
   written,    as they occur in, e.g., proper names relevant to them. thus
   ideally chinese handwriting recognition algorithms need to scale up to
   at least the level of gb18030-2005.

   while early recognition algorithms mainly relied on structural methods
   based on individual stroke analysis, the need to achieve stroke-order
   independence later sparked interest into statistical methods using
   holistic shape information [6][5]. this obviously complicates
   large-inventory recognition, as correct character classification tends
   to get harder with the number of categories to disambiguate [7][3].

   on latin script tasks such as mnist [8][4], convolutional neural
   networks (id98s) soon emerged as the way to go [9][11]. given a
   sufficient amount of training data, supplemented with synthesized
   samples as necessary, id98s decidedly achieved state-of-the-art results
   [10][1], [11][10]. the number of categories in those studies, however,
   was very small (10).

   when we started looking into the large-scale recognition of chinese
   characters some time ago, id98s seemed to be the obvious choice. but
   that approach required scaling up id98s to a set of approximately 30,000
   characters, while simultaneously maintaining real-time performance on
   embedded devices. this article focuses on the challenges involved in
   meeting expectations in terms of accuracy, character coverage, and
   robustness to writing styles.

system configuration

   we adopt in this work a general id98 architecture similar to that used
   in previous handwriting recognition experiments on the mnist task (see,
   e.g., [12][1], [13][10]). the configuration of the overall system is
   illustrated in fig. 1.
   figure 1. typical id98 architecture (with 2 consecutive stages of
   convolution and subsampling) [14]a diagram of a convolutional neural
   network that shows input on the left and output on the right. the
   diagram shows four inner layers that represent feature maps. the layers
   are convolution, subsampling, convolution, and subsampling.

   the input is a medium-resolution image (for performance reasons) of
   48x48 pixels representing a chinese handwritten character. we fed this
   input to a number of feature extraction layers alternating convolution
   and subsampling. the last feature extraction layer is connected to the
   output via a fully connected layer.

   from one convolution layer to the next, we chose the size of the
   kernels and the number of feature maps so as to derive features of
   increasingly coarser granularity. we subsampled through a max-pooling
   layer [15][9] using a 2x2 kernel. the last feature layer typically
   comprises on the order of 1,000 small feature maps. finally, the output
   layer has one node per class, e.g., 3,755 for the h  nz   level-1 subset
   of gb2312-80, and close to 30,000 when scaled up to the full inventory.

   as baseline, we evaluated the previously described id98 implementation
   on the casia benchmark task [16][6]. while this task only covers h  nz  
   level-1 characters, there exist numerous reference results for
   character accuracy in the literature (e.g., in [17][7] and [18][14]).
   we used the same setup based on casia-olhwdb, db1.0-1.2, split in
   training and testing datasets [19][6], [20][7], yielding about one
   million training exemplars.

   note that, given our product focus, the goal was not to tune our system
   for the highest possible accuracy on casia. instead our priorities were
   model size, evaluation speed, and user experience. we thus opted for a
   compact system that works real-time, across a wide variety of styles,
   and with high robustness towards non-standard stroke order. this led to
   an image-based recognition approach even though we evaluate on online
   datasets. as in [21][10], [[22]11], we supplemented actual observations
   with suitable elastic deformations.

   table 1 shows the results using the id98 of figure 1, where the
   abbreviation    hz-1    refers to the h  nz   level-1 inventory (3,755
   characters), and    cr(n)    denotes top-n character recognition accuracy.
   in addition to the commonly reported top-1 and top-10 accuracies, we
   also mention top-4 accuracy because, as our user interface was designed
   to show 4 character candidates, the top-4 accuracy is an important
   predictor of user experience in our system.

   table 1. results on casia on-line database, 3,755 characters. standard
   training, associated model size = 1mb
   inventory training cr(1) cr(4) cr(10)
   hz-1      casia    87.4% 94.5% 98.1%

   the figures in table 1 compare with online results in [23][7] and
   [24][14] averaging roughly 93% for top-1 and 98% for top-10 accuracy.
   thus, while our top-10 accuracy is in line with the literature, our
   top-1 accuracy is slightly lower. this has to be balanced, however,
   against a satisfactory top-4 accuracy, and perhaps even more
   importantly, a model size (1 mb) smaller than any comparable system in
   [25][7] and [26][14].

   the system in table 1 is trained only on casia data, and does not
   include any other training data. we were also interested in folding in
   additional training data collected in-house on ios devices. this data
   covers a larger variety of styles (cf. next section) and comprises a
   lot more training instances per character. table 2 reports our results,
   on the same test set with a 3,755-character inventory.

   table 2. results on casia on-line database, 3,755 characters. augmented
   training, associated model size = 15mb
   inventory training  cr(1) cr(4) cr(10)
   hz-1      augmented 88.4% 96.5% 98.3%

   though the resulting system has a much greater footprint (15 mb),
   accuracy only improves slightly (about 2% absolute for top-4 accuracy).
   this suggests that, by and large, most styles of characters appearing
   in the test set were already well-covered in the casia training set. it
   also indicates that there is no downside in folding more training data:
   the presence of additional styles is not deleterious to the underlying
   model.

scaling up to 30k characters

   since the ideal set of    frequently written    characters varies from one
   user to the next, a large population of users requires an inventory of
   characters much larger than 3,755. exactly which ones to select,
   however, is not entirely straightforward. simplified chinese characters
   defined with gb2312-80 and traditional chinese characters defined with
   big5, big5e, and cns 11643-92 cover a wide range (from 3,755 to 48,027
   h  nz   characters). more recently came hkscs-2008 with 4,568 extra
   characters, and even more with gb18030-2000.

   we wanted to make sure that users are able to write their daily
   correspondence, in both simplified and traditional chinese, as well as
   names, poems and other common markings, visual symbols, and emojis. we
   also wanted to support the latin script for the occasional product or
   trade name with no id68. we followed unicode as the
   prevailing international standard of character encoding, as it
   encapsulates almost all of the above mentioned standards. (note that
   unicode 7.0 can specify over 70,000 characters in its extensions b-d,
   with more being considered for inclusion). our character recognition
   system thus focused on the h  nz   part of gb18030-2005, hkscs-2008,
   big5e, a core ascii set, and a set of visual symbols and emojis, for a
   total of approximately 30,000 characters, which we felt represented the
   best compromise for most chinese users.

   after selecting the underlying character inventory, it is critical to
   sample the writing styles that users actually use. while there are
   formal clues as to what styles to expect (cf. [27][13]), there exist
   many regional variations, e.g., (i) the use of the u+2ebf (   ) radical,
   or (ii) the cursive u+56db (   ) vs. u+306e (   ). rendered fonts can also
   contribute to confusion as some users expect specific characters to be
   presented in a specific style. as a speedy input tends to drive toward
   cursive styles, it tends to increase ambiguity, e.g. between u+738b (   )
   and u+4e94 (   ). finally, increased internationalization sometimes
   introduces unexpected collisions: for example, u+4e8c (   ), when
   cursively written, may conflict with the latin characters    2    and    z   .

   our rationale was to offer users the whole spectrum of possible input
   from printed to cursive to unconstrained writing [28][5]. to cover as
   many variants as possible, we sought data from writers from several
   regions in greater china. we were surprised to find that most users
   have never seen many of the rarer characters. this unfamiliarity
   results in hesitations, stroke-order errors, and other distortions
   which we needed to take into account. we collected data from paid
   participants across various age groups, gender, and with a variety of
   educational backgrounds. the resulting handwritten data is unique in
   many ways: comprising several thousands users, written with a finger,
   not a stylus, on ios devices, in small batches of data. one advantage
   is that the sampling of ios devices results in a very clear handwritten
   signal.

   we found a wide variety of writing styles. figures 2-4 show some
   examples of the    flower    character u+82b1 (   ), in printed, cursive, and
   unconstrained styles.
   figure 2. printed radical variations of u+82b1 (   ) [29]this figure
   shows four variations of the flower character in a printed style.
   figure 3. cursive radical variations of u+82b1 (   ) [30]this figure
   shows four variations of the flower character in a cursive style.
   figure 4. unconstrained variations of u+82b1 (   ) [31]this figure shows
   three unconstrained variations of the flower character.

   the fact that, in daily life, users often write quickly and
   unconstrained can lead to cursive variations that have a very
   dissimilar appearance. conversely, sometimes it also leads to
   confusability between different characters. figures 5-7 show some of
   the concrete examples we observe in our data. note that it is
   especially important to have enough training material to distinguish
   cursive variations such as in figure 7.
   figure 5. variations of u+7684 (   ) [32]this figure shows three
   variations of the same character, each looks dissimilar to the others.
   figure 6. variations of u+4ee5 (   ) [33]this figure shows three
   variations of the same character, each looks dissimilar to the others.
   figure 7. similar shapes of u+738 (   ) and u+4e94 (   ) [34]this figure
   shows two variations of the same character, each looks dissimilar to
   the other.

   with the guiding principles discussed previously, we were able to
   collect tens of millions of character instances for our training data.
   compare the 3,755-character system in the previous section with the
   results shows in table 3, on the same test set, after increasing the
   number of recognizable characters from 3,755 to approximately 30,000.

   table 3. results on casia on-line database, 30k characters
   inventory cr(1) cr(4) cr(10) model size
   30k       85.6% 95.2% 97.5%  15 mb

   note that the model size remains the same, as the system of table 2 was
   simply restricted to the    hz-1    set of characters, but was otherwise
   identical. accuracy drops marginally, which is to be expected, since
   the vastly increased coverage creates additional confusability of the
   kind mentioned earlier, for example           vs.    z   .

   compare tables 1-3 and you   ll see that multiplying coverage by a factor
   of 10 does not entail 10 times more errors, or 10 times more storage.
   in fact, as the model size goes up, the number of errors increases much
   more slowly. thus, building a high-accuracy chinese character
   recognition that covers 30,000 characters, instead of only 3,755, is
   possible and practical.

   to get an idea of how the system performs across the entire set of
   30,000 characters, we also evaluated it on a number of different test
   sets comprising all supported characters written in various styles.
   table 4 lists the average results.

   table 4. average results on multiple in-house test sets comprising all
   writing styles, 30,000 characters
   inventory cr(1) cr(4) model size
   30k       88.1% 95.1% 15 mb

   of course, the results in tables 3-4 are not directly comparable, since
   they were obtained on different test sets. nonetheless, they show that
   top-1 and top-4 accuracies are in the same ballpark across the entire
   inventory of characters. this is a result of the largely balanced
   training regimen.

discussion

   the total set of cjk characters in unicode (currently around 75,000
   [35][12]) could increase in the future, as the ideographic rapporteur
   group (irg) keeps on suggesting new additions from a variety of
   sources. admittedly, these character variants will be rare (e.g., used
   in historical names or poetry). nevertheless, this is of high interest
   to every person whose name happens to contain one of those rare
   characters.

   so, how well do we expect to handle larger inventories of characters in
   the future? the experiments discussed in this article support learning
   curves [36][2] based on training and test error rates with a varying
   amount of training data. we can therefore extrapolate asymptotic
   values, regarding both what our accuracy would look like with more
   training data, and how it would change with more characters to
   recognize.

   for example, given the 10-times larger inventory and corresponding
   (less than) 2% drop in accuracy between tables 1 and 3, we can
   extrapolate that with an inventory of 100,000 characters and a
   corresponding increase in training data, it would be realistic to
   achieve top-1 accuracies around 84%, and top-10 accuracies around 97%
   (with the same type of architecture).

   in summary, building a high-accuracy handwriting recognition system
   which covers a large set of 30,000 chinese characters is practical even
   on embedded devices. furthermore, accuracy only degrades slowly as the
   inventory goes up, as long as training data of sufficient quality is
   available in sufficient quantity. this bodes well for the recognition
   of even larger character inventories in the future.

references

   [1] d.c. ciresan, u. meier, l.m. gambardella, and j. schmidhuber,
   convolutional neural network committees for handwritten character
   classification, in 11th int. conf. document analysis recognition (icdar
   2011), beijing, china, sept. 2011.

   [2] c. cortes, l.d. jackel, s.a. jolla, v. vapnik, and j.s. denker,
   learning curves: asymptotic values and rate of convergence, in advances
   in neural information processing systems (nips 1993), denver, pp.
   327   334, dec. 1993.

   [3] g.e. hinton and k.j. lang, shape recognition and illusory
   conjunctions, in proc. 9th int. joint conf. artificial intelligence,
   los angeles, ca, pp. 252   259, 1985.

   [4] y. lecun, l. bottou, y. bengio, and p. haffner, gradient    based
   learning applied to document recognition, proc. ieee, vol. 86, no. 11,
   pp. 2278   2324, nov. 1998.

   [5] c.-l. liu, s. jaeger, and m. nakagawa, online recognition of
   chinese characters: the state-of-the-art, ieee trans. pattern analysis
   machine intelligence, vol. 26, no. 2, pp. 198   213, feb. 2004.

   [6] c.-l. liu, f. yin, d.-h. wang, and q.-f. wang, casia online and
   offline chinese handwriting databases, in proc. 11th int. conf.
   document analysis recognition (icdar 2011), beijing, china, sept. 2011.

   [7] c.-l. liu, f. yin, q.-f. wang, and d.-h.wang, icdar 2011 chinese
   handwriting recognition competition,in 11th int. conf. document
   analysis recognition (icdar 2011), beijing, china, sept. 2011.

   [8] y. li, l. jin , x. zhu, t. long, scut-couch2008: a comprehensive
   online unconstrained chinese handwriting dataset (icfhr 2008),
   montreal, pp. 165   170, aug. 2008.

   [9] k. jarrett, k. kavukcuoglu, m. ranzato, and y. lecun, what is the
   best multi-stage architecture for object recognition?, in proc. ieee
   int. conf. id161 (iccv09), kyoto, japan, sept. 2009.

   [10] u. meier, d.c. ciresan, l.m. gambardella, and j. schmidhuber,
   better digit recognition with a committee of simple neural nets, in
   11th int. conf. document analysis recognition (icdar 2011), beijing,
   china, sept. 2011.

   [11] p.y. simard, d. steinkraus, and j.c. platt, best practices for
   convolutional neural networks applied to visual document analysis, in
   7th int. conf. document analysis recognition (icdar 2003), edinburgh,
   scotland, aug. 2003.

   [12] unicode, chinese and japanese,
   [37]http://www.unicode.org/faq/han_cjk.html, 2015.

   [13] f.f. wang, chinese cursive script: an introduction to handwriting
   in chinese, far eastern publications series, new haven, ct: yale
   university press, 1958.

   [14] f. yin, q.-f. wang, x.-y. xhang, and c.-l. liu, icdar2013 chinese
   handwriting recognition competition, in 11th int. conf. document
   analysis recognition (icdar 2013), washington dc, usa, sept. 2013.

contact us

   [38]send questions or feedback via email

jobs at apple

   [39]apply now for a career at apple

tools for innovation

   [40]apple developer program

   [41]    copyright    2018 apple inc. all rights reserved. copyright two
   thousand seventeen apple inc. all rights reserved.
   [42]subscribe [43]privacy policy [44]terms of use [45]legal

references

   1. https://machinelearning.apple.com/feed.xml
   2. https://machinelearning.apple.com/
   3. https://machinelearning.apple.com/
   4. https://machinelearning.apple.com/2017/09/12/handwriting.html#6
   5. https://machinelearning.apple.com/2017/09/12/handwriting.html#8
   6. https://machinelearning.apple.com/2017/09/12/handwriting.html#5
   7. https://machinelearning.apple.com/2017/09/12/handwriting.html#3
   8. https://machinelearning.apple.com/2017/09/12/handwriting.html#4
   9. https://machinelearning.apple.com/2017/09/12/handwriting.html#11
  10. https://machinelearning.apple.com/2017/09/12/handwriting.html#1
  11. https://machinelearning.apple.com/2017/09/12/handwriting.html#10
  12. https://machinelearning.apple.com/2017/09/12/handwriting.html#1
  13. https://machinelearning.apple.com/2017/09/12/handwriting.html#10
  14. https://machinelearning.apple.com/images/journals/handwriting/feature-mapping.png
  15. https://machinelearning.apple.com/2017/09/12/handwriting.html#9
  16. https://machinelearning.apple.com/2017/09/12/handwriting.html#6
  17. https://machinelearning.apple.com/2017/09/12/handwriting.html#7
  18. https://machinelearning.apple.com/2017/09/12/handwriting.html#14
  19. https://machinelearning.apple.com/2017/09/12/handwriting.html#6
  20. https://machinelearning.apple.com/2017/09/12/handwriting.html#7
  21. https://machinelearning.apple.com/2017/09/12/handwriting.html#10
  22. https://machinelearning.apple.com/2017/09/12/handwriting.html#11
  23. https://machinelearning.apple.com/2017/09/12/handwriting.html#7
  24. https://machinelearning.apple.com/2017/09/12/handwriting.html#14
  25. https://machinelearning.apple.com/2017/09/12/handwriting.html#7
  26. https://machinelearning.apple.com/2017/09/12/handwriting.html#14
  27. https://machinelearning.apple.com/2017/09/12/handwriting.html#13
  28. https://machinelearning.apple.com/2017/09/12/handwriting.html#5
  29. https://machinelearning.apple.com/images/journals/handwriting/chw-fig-2.png
  30. https://machinelearning.apple.com/images/journals/handwriting/chw-fig-3.png
  31. https://machinelearning.apple.com/images/journals/handwriting/chw-fig-4.png
  32. https://machinelearning.apple.com/images/journals/handwriting/chw-fig-5.png
  33. https://machinelearning.apple.com/images/journals/handwriting/chw-fig-6.png
  34. https://machinelearning.apple.com/images/journals/handwriting/chw-fig-7.png
  35. https://machinelearning.apple.com/2017/09/12/handwriting.html#12
  36. https://machinelearning.apple.com/2017/09/12/handwriting.html#2
  37. http://www.unicode.org/faq/han_cjk.html
  38. mailto:machine-learning@apple.com
  39. https://www.apple.com/jobs/
  40. https://developer.apple.com/
  41. https://www.apple.com/
  42. https://machinelearning.apple.com/feed.xml
  43. https://www.apple.com/privacy/privacy-policy/
  44. https://www.apple.com/legal/internet-services/terms/site.html
  45. https://www.apple.com/legal/
