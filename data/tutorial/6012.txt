   #[1]deep ideas    feed [2]deep ideas    comments feed [3]deep ideas   
   robot localization ii: the histogram filter comments feed [4]alternate
   [5]alternate

   [6]facebook[7]twitter[8]email[9]rss[10]linkedin[11]tumblr

   [12]deep ideas logo deep ideas retina logo

a blog on artificial intelligence, deep learning and cognitive science

     * [13]home
     * [14]list of articles
     * [15]about me
     * ____________________
          

   [16]previous [17]next

     * [18]view larger image self-driving car

robot localization ii: the histogram filter

   this is part 2 in a series of articles explaining methods for robot
   localization, i.e. determining and tracking a robot   s location via
   noisy sensor measurements. you should start with the first part:
   [19]robot localization i: recursive bayesian estimation

idea

   the histogram filter is the most straightforward solution to represent
   continuous beliefs. we simply divide $dom(x_t)$ into $n$ disjoint bins
   $b_0,    , b_{n   1}$ such that $\cup_i b_{i} = dom(x_t)$. then we define a
   new state $x_t^\prime \in \{0,    , n     1\}$ where $x_t^\prime = i$ if
   and only if $x_t \in b_i$. since $x_t^\prime$ has a discrete, finite
   state space, we can use the discrete bayes filter to calculate
   $bel(x_t^\prime)$.

   $bel(x_t^\prime)$ is an approximation for $bel(x_t)$ then: for each bin
   $b_i$, it gives us the id203 that $x_t$ is in that bin. the more
   bins we use, the more accurate the approximation becomes, with the
   downside of increasing computational complexity.

example

   to make this more clear, we shall apply the histogram filter to a
   global localization example as displayed in the following image:

   a self-driving car lives in a one-dimensional, cyclic world that is 5
   meters wide. by cyclic, we mean that if it is in the rightmost cell and
   moves one step to the right, it   s back in the leftmost cell. the
   robot   s position at each time step is given as $pos_t \in [0, 5)$,
   which is the only state variable. it has a sensor that is, under
   uncertainty, able to tell the color of the wall next to it. we assume
   that the car is constantly moving right under noise, at an expected
   speed of one meter per time step.

   in order to apply the histogram filter, we choose the following
   decomposition of the state space: $b_0 = [0, 1)$, $b_1 = [1, 2)$, $b_2
   = [2, 3)$, $b_3 = [3, 4)$, $b_4 = [4, 5)$. this way, the position can
   be measured as a discrete variable $pos_t^\prime \in \{0,    , 4\}$,
   which is an estimate of the true, continuous position. each discrete
   position corresponds to exactly one of the distinguished grid cells in
   the above image.

   we can now specify the transition and sensor models. we assume that the
   car intends to move exactly one grid cell to the right at each time
   step, but that the inaccuracy of the motor causes it to move 2 grid
   cells in 5% of the cases, not move at all in 5% of the cases and move
   exactly 1 grid cell in 90% of the cases. this results in the following
   transition model:

   $$
   p(pos_t^\prime = x + 2 \; mod \, 5 \; \vert \; pos_{t   1}^\prime = x) =
   0.05\\
   p(pos_t^\prime = x + 1 \; mod \, 5 \; \vert \; pos_{t   1}^\prime = x) =
   0.9\\
   p(pos_t^\prime = x \; \vert \; pos_{t   1}^\prime = x) = 0.05
   $$

   as for the sensors, we assume that in 90% of the cases the measured
   color is correct and in 10% of the cases it is incorrect, yielding the
   following sensor model:

   $$
   p(measuredcolor_t = blue \; \vert \; pos_t^\prime = 0, 2, 3) = 0.9\\
   p(measuredcolor_t = orange \; \vert \; pos_t^\prime = 0, 2, 3) = 0.1\\
   p(measuredcolor_t = blue \; \vert \; pos_t^\prime = 1, 4) = 0.1\\
   p(measuredcolor_t = orange \; \vert \; pos_t^\prime = 1, 4) = 0.9
   $$

   let   s now use the discrete bayes filter to calculate the car   s belief
   for three time steps where the sensor measurements are orange, blue and
   orange in that order. we assume that the car starts at the very left
   (but it does not know that it does) and travels exactly one grid cell
   to the right per time step (which it does not know either). we can
   represent the belief as a 5-dimensional row vector $bel(pos_t^\prime) =
   (bel_{t,1}, bel_{t,2} bel_{t,3}, bel_{t,4}, bel_{t,5})$ where
   $bel_{t,i}$ represents the id203 that the robot is in cell $i$ at
   time-step $t$.

t = 0

   the car has no prior knowledge about its position. thus, it starts out
   with the following belief:

   $bel(pos_0^\prime) = (0.2, 0.2, 0.2, 0.2, 0.2)$

t = 1

   first, it projects the previous belief to the current time step:
   $\overline{bel}(pos_1^\prime) = \sum_{pos_0^\prime} p(pos_1^\prime \;
   \vert \; pos_0^\prime) \cdot bel(pos_0^\prime)$
   $= (0.05, 0.9, 0.05, 0.0, 0.0) \cdot 0.2 + (0.0, 0.05, 0.9, 0.05, 0.0)
   \cdot 0.2$
   $+ (0.0, 0.0, 0.05, 0.9, 0.05) \cdot 0.2 + (0.05, 0.0, 0.0, 0.05, 0.9)
   \cdot 0.2$
   $+ (0.9, 0.05, 0.0, 0.0, 0.05) \cdot 0.2 = (0.2, 0.2, 0.2, 0.2, 0.2)$

   this results in the same belief as before, which shouldn   t surprise us,
   since each cell was equally likely to be the car   s position at time $t
   = 0$ and therefore, since the robot just moved blindly, each cell is
   still equally likely to be its position at time $t = 1$.

   now the robot updates the projected belief with the sensor input:

   $bel(pos_1^\prime) = \eta \cdot p(measuredcolor_1 = orange \; \vert \;
   pos_1^\prime) \cdot \overline{bel}(pos_1^\prime)$
   $= \eta \cdot (0.1, 0.9, 0.1, 0.1, 0.9) \cdot (0.2, 0.2, 0.2, 0.2,
   0.2)$
   $= \eta \cdot (0.02, 0.18, 0.02, 0.02, 0.18)$
   $= (0.04762, 0.42857, 0.04762, 0.04761, 0.42857)$

   where the last step follows by dividing the vector by the sum over all
   vector values so that the probabilities sum up to 1. we can see that
   each of the two orange cells are equally likely to have caused the
   sensor measurement. thus, the robot currently has two salient theories
   on where it might be.

t = 2

   $\overline{bel}(pos_2^\prime) = \sum_{pos_1^\prime} p(pos_2^\prime \;
   \vert \; pos_1^\prime) \cdot bel(pos_1^\prime)$
   $= (0.39048, 0.08571, 0.39048, 0.06667, 0.06667)$

   $bel(pos_2^\prime) = \eta \cdot p(measuredcolor_2 = orange \; \vert \;
   pos_2^\prime) \cdot \overline{bel}(pos_2^\prime)$
   $= \eta \cdot (0.9, 0.1, 0.9, 0.9, 0.1) \cdot (0.39048, 0.08571,
   0.39048, 0.06667, 0.06667)$
   $= (0.45165, 0.01102, 0.45165, 0.07711, 0.00857)$

t = 3

   $\overline{bel}(pos_3^\prime) = \sum_{pos_2^\prime} p(pos_3^\prime \;
   \vert \; pos_2^\prime) \cdot bel(pos_2^\prime)$
   $= (0.03415, 0.40747, 0.05508, 0.41089, 0.09241)$$bel(pos_3^\prime) =
   \eta \cdot p(measuredcolor_3 = orange \; \vert \; pos_3^\prime) \cdot
   \overline{bel}(pos_3^\prime)$
   $= \eta \cdot (0.1, 0.9, 0.1, 0.1, 0.9) \cdot (0.03415, 0.40747,
   0.05508, 0.41089, 0.09241)$
   $= (0.00683, 0.73358, 0.01102, 0.08219, 0.16637)$

   we can see that after 3 time steps the robot is already about 73%
   certain that it is in the second grid cell. after another 3 time steps
   of travelling right and sensing the correct colors, it is 94% certain
   about its position.

   the disadvantage of the histogram filter is obvious: we are not able to
   tell the id203 of each possible state. we are only able to tell
   the id203 that the state is in a certain region of the state
   space. this disadvantage might be circumvented by using a very
   fine-grained decomposition of the state space, but this drastically
   increases the computational complexity.

   continue with the next part: [20]robot localization iii: the kalman
   filter

share this:

     * [21]click to share on twitter (opens in new window)
     * [22]click to share on facebook (opens in new window)
     * [23]click to share on google+ (opens in new window)
     * [24]click to share on skype (opens in new window)
     * [25]click to share on linkedin (opens in new window)
     * [26]click to print (opens in new window)
     * [27]click to share on pocket (opens in new window)
     * [28]click to share on tumblr (opens in new window)
     * [29]click to share on reddit (opens in new window)
     * [30]click to share on telegram (opens in new window)
     * [31]click to share on pinterest (opens in new window)
     * [32]click to share on whatsapp (opens in new window)
     *

related

   by [33]daniel| 2017-09-22t17:00:51+00:00 september 15th,
   2017|[34]artificial intelligence, [35]machine learning, [36]robotics,
   [37]self-driving cars|[38]2 comments

stay updated

   subscribe to the mailing list and get updated about new blog posts by
   email.
   ____________________
   [ ] i consent to my submitted data being collected via this form*
   sign up now

   thank you for subscribing.

   something went wrong.

   i respect your privacy and take protecting it seriously

follow me on twitter

   [39]my tweets

   copyright 2017 daniel sabinasz
   [40]facebook[41]twitter[42]email[43]rss[44]linkedin[45]tumblr

references

   visible links
   1. http://www.deepideas.net/feed/
   2. http://www.deepideas.net/comments/feed/
   3. http://www.deepideas.net/robot-localization-histogram-filter/feed/
   4. http://www.deepideas.net/wp-json/oembed/1.0/embed?url=http://www.deepideas.net/robot-localization-histogram-filter/
   5. http://www.deepideas.net/wp-json/oembed/1.0/embed?url=http://www.deepideas.net/robot-localization-histogram-filter/&format=xml
   6. http://fb.me/deepideas.net
   7. https://twitter.com/deepideas_net
   8. mailto:daniel@sabinasz.net
   9. http://www.deepideas.net/feed/
  10. https://www.linkedin.com/in/daniel-sabinasz-7b220b100/
  11. https://deepideas.tumblr.com/
  12. http://www.deepideas.net/
  13. http://www.deepideas.net/
  14. http://www.deepideas.net/list-of-articles/
  15. http://www.deepideas.net/about-me/
  16. http://www.deepideas.net/robot-localization-recursive-bayesian-estimation/
  17. http://www.deepideas.net/unbalanced-classes-machine-learning/
  18. https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/09/self_driving_car.jpg?fit=1000,350
  19. http://www.deepideas.net/robot-localization-recursive-bayesian-estimation/
  20. http://www.deepideas.net/robot-localization-kalman-filter/
  21. http://www.deepideas.net/robot-localization-histogram-filter/?share=twitter
  22. http://www.deepideas.net/robot-localization-histogram-filter/?share=facebook
  23. http://www.deepideas.net/robot-localization-histogram-filter/?share=google-plus-1
  24. http://www.deepideas.net/robot-localization-histogram-filter/?share=skype
  25. http://www.deepideas.net/robot-localization-histogram-filter/?share=linkedin
  26. http://www.deepideas.net/robot-localization-histogram-filter/#print
  27. http://www.deepideas.net/robot-localization-histogram-filter/?share=pocket
  28. http://www.deepideas.net/robot-localization-histogram-filter/?share=tumblr
  29. http://www.deepideas.net/robot-localization-histogram-filter/?share=reddit
  30. http://www.deepideas.net/robot-localization-histogram-filter/?share=telegram
  31. http://www.deepideas.net/robot-localization-histogram-filter/?share=pinterest
  32. https://api.whatsapp.com/send?text=robot localization ii: the histogram filter http://www.deepideas.net/robot-localization-histogram-filter/
  33. http://www.deepideas.net/author/daniel/
  34. http://www.deepideas.net/category/artificial-intelligence/
  35. http://www.deepideas.net/category/artificial-intelligence/machine-learning/
  36. http://www.deepideas.net/category/artificial-intelligence/robotics/
  37. http://www.deepideas.net/category/artificial-intelligence/robotics/self-driving-cars/
  38. http://www.deepideas.net/robot-localization-histogram-filter/#comments
  39. https://twitter.com/deepideas_net
  40. http://fb.me/deepideas.net
  41. https://twitter.com/deepideas_net
  42. mailto:daniel@sabinasz.net
  43. http://www.deepideas.net/feed/
  44. https://www.linkedin.com/in/daniel-sabinasz-7b220b100/
  45. https://deepideas.tumblr.com/

   hidden links:
  47. http://www.deepideas.net/robot-localization-histogram-filter/
  48. https://www.facebook.com/deepideas.net/
