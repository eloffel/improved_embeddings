   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]udacity inc
     * [9]ai
     * [10]autonomous systems
     * [11]business
     * [12]data science
     * [13]programming
     * [14]the official udacity blog
     __________________________________________________________________

challenge #2: using deep learning to predict steering angles

[15]udacity self-driving car challenge #2

   [16]go to the profile of oliver cameron
   [17]oliver cameron (button) blockedunblock (button) followfollowing
   sep 29, 2016
   [1*ot8tzuziz-xjs68tgpj7qw.png]

the udacity self-driving car

   as detailed in [18]this post, a critical part of our process in
   launching the [19]self-driving car nanodegree program is to build our
   own self-driving vehicle. to achieve this, we formed a core
   self-driving car team with [20]google self-driving car founder and
   [21]udacity president [22]sebastian thrun. one of the first decisions
   we made together? open source code, written by hundreds of students
   from across the globe!

   we are breaking down the problem of making the car autonomous into
   udacity challenges. the first challenge is complete, and you can read
   about it [23]here. we   re now ready to introduce challenge #2!
     __________________________________________________________________

challenge #2         now open

   you may have seen [24]this incredible video from nvidia, one of our
   [25]nanodegree partners, which highlights their efforts of teaching a
   car how to drive using only cameras and deep learning. their dave-2
   deep learning system is capable of driving in many different weather
   conditions, avoiding obstacles, and even going off-road! you may have
   noticed their setup looks pretty similar to our 2016 lincoln mkz, and
   that   s for good reason. one of the first ways that we want to get this
   car on the road is to implement a similar end-to-end solution, and
   release that to the world for free.

   the second challenge for the udacity self-driving car initiative is to
   replicate these results using a convolutional neural network that you
   design and build!

   end-to-end solutions like this, where a single network takes raw input
   (camera imagery) and produces a direct steering command, are considered
   the holy-grail of current autonomous vehicle technology, and are
   speculated to populate the first wave of self-driving cars on roads and
   highways. by letting the car figure out how to interpret images on its
   own, we can skip a lot of the complexity that exists in manually
   selecting features to detect, and drastically reduce the cost required
   to get an autonomous vehicle on the road by avoiding lidar-based
   solutions.

   we want students to show us what they can produce, and compete for an
   incredible array of prizes! by contributing to challenge #2, you and
   your team will not only get to run your code on a real self-driving
   car, but you   ll be in the running for cash, and even a trip to mountain
   view, california to brainstorm with sebastian thrun, father of the
   self-driving car and founder of [26]udacity!

   looking for some more specific rules and information? read on!
     __________________________________________________________________

challenge overview

   the purpose of the challenge is to take image frames from a camera
   mounted to the windshield of our car, and predict the appropriate
   steering angle using convolutional neural networks and deep learning.
   training can take as long as you   d like, but the final network itself
   has to run in real-time.

   while the dataset may include auxilary information, you may only use
   camera imagery and steering wheel angle information to train. the topic
   containing steering wheel information will not be present in the
   testing dataset. the extra data is only there to give you a full
   picture of the current state of the car, and to become familiar with
   the data format. to be clear, your network may only use camera imagery
   as input to your neural network.

   the metric used to determine the winner will be measured and evaluated
   by the network   s performance in simulation. teams will be provided with
   two rosbag-based datasets; one will be accompanied by steering angles,
   but the other won   t. training should be completed on the first dataset,
   and testing on the second. teams will be required to generate a csv
   file indicating their networks steering decisions, and this file will
   be uploaded and processed to determine team rankings. at the end of the
   competition period, the winning team   s code will be adapted and
   integrated into our self-driving car platform, and taken out for a spin
   on the real deal.

prizes

   first place: one-time sum of $10,000
   second place: all-expenses-paid trip for the team leader and 2 other
   teammates to udacity hq in mountain view, california to meet and
   brainstorm with sebastian thrun
   third place: to be announced!

timeline

   start date: 09/29/2016
   end date: late november 2016

essential rules

     * toolchain used must be python on top of tensorflow.
     * one team per participant, one submission per team, no maximum team
       size.
     * teams must have a designated lead who will submit their team   s
       entry.
     * a submission will be considered ineligible if it was developed
       using code containing or depending on software that is not approved
       by the [27]open source initiative, or a license that prohibits
       commercial use.
     * no restrictions on training time, but must process a frame faster
       than 1/20th of a second.
     * winners must submit runnable code (with documentation and
       description of resources/dependencies required to run the solution)
       with reproducible results within (1) week of being selected as the
       challenge winner.
     * all code submitted will be open-sourced, and there should be no
       expectation of maintaining exclusive ip over submitted code.
     * no hand-labelling of test dataset allowed.

   for full contest rules, [28]please read this.
     __________________________________________________________________

scoring

   [29]udacity will provide the teams with two datasets, training and
   testing. the training set will be accompanied by steering wheel angle
   values for each frame, but the testing/evaluation set will not. the
   teams will then build a model on the training data, use it to predict
   on the testing data, and create a file with predicted steering angles
   for the test set (again for each frame). teams will then upload this
   file with predictions to our servers, and we will calculate the score
   against the actual steering angles from the test set. teams will test
   their code and evaluate locally before their submission by splitting
   the training set into their own training and validation set.

evaluation metric

   root mean square error. from [30]wikipedia:

     the root-mean-square deviation (rmsd) or root-mean-square error
     (rmse) is a frequently used measure of the differences between
     values (sample and population values) predicted by a model or an
     estimator and the values actually observed. the rmsd represents the
     sample standard deviation of the differences between predicted
     values and observed values.
     __________________________________________________________________

frequently asked questions

submission format & details

   teams will be able to submit their final results only once on the
   testing set in csv format via email to
   [31]self-driving-car@udacity.com. the submission email must be
   accompanied by a list of teammates, team name, and code/documentation.
   more information on this format will be released in the coming weeks.

how do i get started?

    1. download the [32]datasets here.
    2. install ubuntu 14.04 in a [33]virtual machine or directly onto your
       system.
    3. install [34]ros to playback data and convert into different
       formats.
    4. begin building and testing your convolutional neural network using
       tensorflow.
    5. submit your results to [35]self-driving-car@udacity.com with code
       (preferably in a git repo) and team information.

data format

   all sensor data including imagery and steering wheel angles is provided
   in the rosbag format. to playback this data, you will need to
   [36]install ros on a ubuntu linux platform and test from there.
   additionally, you can convert the data into any format you like.

definition of real-time performance

   video processing latency has not been measured yet on target hardware
   with gige camera. anticipate a gtx 1070, i7   4770te cpu, and 16gb+ ram.
   there is some wiggle room on    real time performance.    essentially, your
   network has to process 15+ frames a second. we expect difficulty here
   with replication until we have an aws/azure instance specification for
   later challenges.

open source tools clarification

   in pre and post processing of your neural networks, you may use
   proprietary code and tools, as long as your final code/network/solution
   operates independently of any closed source code, as defined in the
   above rules.
     __________________________________________________________________

here we go!

   [37]udacity is dedicated to democratizing education, and we couldn   t be
   more excited to bring this philosophy to such a revolutionary
   platform   the self-driving car! we anticipate this project to have an
   incredible impact on the industry, giving anyone access to the tools
   required to get an autonomous vehicle on the road. help us achieve this
   dream by [38]joining a team and competing in our challenges. plus, if
   you   re looking to gain the skills necessary to launch a career building
   cars that drive themselves, we encourage you to check out our
   [39]self-driving car nanodegree program.

   thanks to [40]maccallister higgins.
     * [41]self driving cars
     * [42]autonomous vehicles
     * [43]open source
     * [44]startup
     * [45]machine learning

   (button)
   (button)
   (button) 255 claps
   (button) (button) (button) 17 (button) (button)

     (button) blockedunblock (button) followfollowing
   [46]go to the profile of oliver cameron

[47]oliver cameron

   ceo voyage. we   re building a self-driving car!

     (button) follow
   [48]udacity inc

[49]udacity inc

   learning for the jobs of today, tomorrow, and beyond

     * (button)
       (button) 255
     * (button)
     *
     *

   [50]udacity inc
   never miss a story from udacity inc, when you sign up for medium.
   [51]learn more
   never miss a story from udacity inc
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/f42004a36ff3
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://medium.com/udacity/challenge-2-using-deep-learning-to-predict-steering-angles-f42004a36ff3&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://medium.com/udacity/challenge-2-using-deep-learning-to-predict-steering-angles-f42004a36ff3&source=--------------------------nav_reg&operation=register
   8. https://medium.com/udacity?source=logo-lo_grzz5uyaxlg7---b7bbc4597459
   9. https://medium.com/udacity/tagged/artificial-intelligence
  10. https://medium.com/udacity/tagged/autonomous-vehicles
  11. https://medium.com/udacity/tagged/digital-marketing
  12. https://medium.com/udacity/tagged/data-science
  13. https://medium.com/udacity/tagged/programming
  14. https://blog.udacity.com/
  15. https://medium.com/udacity/were-building-an-open-source-self-driving-car-ac3e973cd163#.fb7vtlrfn
  16. https://medium.com/@olivercameron?source=post_header_lockup
  17. https://medium.com/@olivercameron
  18. https://medium.com/udacity/were-building-an-open-source-self-driving-car-ac3e973cd163#.xvv50px6m
  19. https://www.udacity.com/drive
  20. https://medium.com/@google
  21. https://medium.com/@udacity
  22. https://medium.com/@thrun
  23. https://medium.com/udacity/challenge-1-3d-model-for-camera-mount-f5ffcc1655b5#.2986wyunb
  24. https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/
  25. https://udacity.com/drive
  26. https://medium.com/@udacity
  27. http://opensource.org/
  28. https://www.udacity.com/legal/contests
  29. https://medium.com/@udacity
  30. https://en.wikipedia.org/wiki/root-mean-square_deviation
  31. mailto:self-driving-car@udacity.com
  32. http://github.com/udacity/self-driving-car
  33. https://www.virtualbox.org/
  34. http://wiki.ros.org/
  35. mailto:self-driving-car@udacity.com
  36. http://wiki.ros.org/
  37. https://medium.com/@udacity
  38. http://nd013.udacity.com/
  39. https://www.udacity.com/drive
  40. https://medium.com/@maccallister.h?source=post_page
  41. https://medium.com/tag/self-driving-cars?source=post
  42. https://medium.com/tag/autonomous-vehicles?source=post
  43. https://medium.com/tag/open-source?source=post
  44. https://medium.com/tag/startup?source=post
  45. https://medium.com/tag/machine-learning?source=post
  46. https://medium.com/@olivercameron?source=footer_card
  47. https://medium.com/@olivercameron
  48. https://medium.com/udacity?source=footer_card
  49. https://medium.com/udacity?source=footer_card
  50. https://medium.com/udacity
  51. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  53. https://medium.com/p/f42004a36ff3/share/twitter
  54. https://medium.com/p/f42004a36ff3/share/facebook
  55. https://medium.com/p/f42004a36ff3/share/twitter
  56. https://medium.com/p/f42004a36ff3/share/facebook
