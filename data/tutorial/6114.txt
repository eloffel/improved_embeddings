   #[1]pyimagesearch    feed [2]pyimagesearch    comments feed
   [3]pyimagesearch    convolutions with opencv and python comments feed
   [4]alternate [5]alternate

[6]navigation

   [7]pyimagesearch [8]pyimagesearch be awesome at opencv, python, deep
   learning, and id161

   [9]home

main menu

     * [10]start here
     * [11]practical python and opencv
     * [12]pyimagesearch gurus
     * [13]opencv 3 & 4 tutorials
     * [14]free crash course
     * [15]about
     * [16]contact

   [17]return to content

convolutions with opencv and python

   by [18]adrian rosebrock on july 25, 2016 in [19]deep learning,
   [20]pyimagesearch gurus, [21]tutorials

   figure 12: finding horizontal gradients in an image using the sobel-y
   operator and convolutions.

   i   m going to start today   s blog post by asking a series of questions
   which will then be addressed later in the tutorial:
     * what are image convolutions?
     * what do they do?
     * why do we use them?
     * how do we apply them?
     * and what role do convolutions play in deep learning?

   the word    convolution    sounds like a fancy, complicated term     but it   s
   really not. in fact, if you   ve ever worked with id161, image
   processing, or opencv before, you   ve already applied
   convolutions, whether you realize it or not!

   ever apply blurring or smoothing? yep, that   s a convolution.

   what about edge detection? yup, convolution.

   have you opened photoshop or gimp to sharpen an image? you guessed it    
   convolution.

   convolutions are one of the most critical, fundamental building-blocks
   in id161 and image processing. but the term itself tends to
   scare people off     in fact, on the the surface, the word even appears
   to have a negative connotation.

   trust me, convolutions are anything but scary. they   re actually quite
   easy to understand.

   in reality, an (image) convolution is simply an element-wise
   multiplication of two matrices followed by a sum.

   seriously. that   s it. you just learned what convolution is:
    1. take two matrices (which both have the same dimensions).
    2. multiply them, element-by-element (i.e., not the dot-product, just
       a simple multiplication).
    3. sum the elements together.

   to understand more about convolutions, why we use them, how to apply
   them, and the overall role they play in deep learning + image
   classification, be sure to keep reading this post.

   looking for the source code to this post?
   [22]jump right to the downloads section.

a quick note on pyimagesearch gurus

   before we get started, i just wanted to mention that the first half of
   this blog post on kernels and convolutions is based on the    kernels   
   lesson inside the [23]pyimagesearch gurus course.

   while the kernels lesson goes into a lot more detail than what this
   blog post does, i still wanted to give you a taste of what
   pyimagesearch gurus     my magnum opus on id161     has to offer.

   if you like this tutorial, there are over 168 lessons covering 2,161+
   pages of content on image basics, deep learning, automatic license
   plate recognition (anpr), face recognition, and much more inside
   pyimagesearch gurus.

   to learn more about the pyimagesearch gurus course (and grab 10 free
   sample lessons), just click the button below:

           [24]click here to learn more about pyimagesearch gurus!

convolutions with opencv and python

   think of it this way     an image is just a multi-dimensional matrix. our
   image has a width (# of columns) and a height (# of rows), just like a
   matrix.

   but unlike the traditional matrices you may have worked with back in
   grade school, images also have a depth to them     the number of channels
   in the image. for a standard rgb image, we have a depth of 3     one
   channel for each of the red, green, and blue channels, respectively.

   given this knowledge, we can think of an image as a big matrix
   and kernel or convolutional matrix as a tiny matrix that is used for
   blurring, sharpening, edge detection, and other image processing
   functions.

   essentially, this tiny kernel sits on top of the big image and slides
   from left-to-right and top-to-bottom, applying a mathematical operation
   (i.e., a convolution) at each (x, y)-coordinate of the original image.

   it   s normal to hand-define kernels to obtain various image processing
   functions. in fact, you might already be familiar with blurring
   (average smoothing, gaussian smoothing, median smoothing, etc.), edge
   detection (laplacian, sobel, scharr, prewitt, etc.), and sharpening
       all of these operations are forms of hand-defined kernels that
   are specifically designed to perform a particular function.

   so that raises the question, is there a way to automatically learn
   these types of filters? and even use these filters for image
   classification and id164?

   you bet there is.

   but before we get there, we need to understand kernels and convolutions
   a bit more.

kernels

   again, let   s think of an image as a big matrix and a kernel as tiny
   matrix (at least in respect to the original    big matrix    image):
   figure 1: a kernel is a small matrix that slides from left-to-right and
   top-to-bottom across a larger image. at each pixel in the input image,
   the neighborhood of the image is convolved with the kernel and the
   output stored. source, pyimagesearch gurus

   figure 1: a kernel is a small matrix that slides from left-to-right and
   top-to-bottom across a larger image. at each pixel in the input image,
   the neighborhood of the image is convolved with the kernel and the
   output stored. [25]source: pyimagesearch gurus

   as the figure above demonstrates, we are sliding the kernel from
   left-to-right and top-to-bottom along the original image.

   at each (x, y)-coordinate of the original image, we stop and examine
   the neighborhood of pixels located at the center of the image kernel.
   we then take this neighborhood of pixels, convolve them with the
   kernel, and obtain a single output value. this output value is then
   stored in the output image at the same (x, y)-coordinates as the center
   of the kernel.

   if this sounds confusing, no worries, we   ll be reviewing an example in
   the    understanding image convolutions    section later in this blog post.

   but before we dive into an example, let   s first take a look at what a
   kernel looks like:
   figure 2: a 3 x 3 kernel that can be convolved with an image using
   opencv and python. source: pyimagesearch gurus.

   figure 2: a 3 x 3 kernel that can be convolved with an image using
   opencv and python. [26]source: pyimagesearch gurus

   above we have defined a square 3 x 3 kernel (any guesses on what this
   kernel is used for?)

   kernels can be an arbitrary size of m x n pixels, provided that both m
   and n are odd integers.

   note: most kernels you   ll typically see are actually square n x
   n matrices.

   we use an odd kernel size to ensure there is a valid integer (x,
   y)-coordinate at the center of the image:
   figure 3: a 3 x 3 kernel with a valid integer center (x, y)-coordinate
   (left). a 2 x 2 kernel without a valid integer (x, y)-center. source,
   pyimagesearch gurus

   figure 3: a 3 x 3 kernel with a valid integer center (x, y)-coordinate
   (left). a 2 x 2 kernel without a valid integer (x, y)-center (right).
   [27]source: pyimagesearch gurus

   on the left, we have a 3 x 3 matrix. the center of the matrix is
   obviously located at x=1, y=1 where the top-left corner of the matrix
   is used as the origin and our coordinates are zero-indexed.

   but on the right, we have a 2 x 2 matrix. the center of this matrix
   would be located at x=0.5, y=0.5. but as we know, without applying
   interpolation, there is no such thing as pixel location (0.5, 0.5)    
   our pixel coordinates must be integers! this reasoning is exactly why
   we use odd kernel sizes     to always ensure there is a valid (x,
   y)-coordinate at the center of the kernel.

understanding image convolutions

   now that we have discussed the basics of kernels, let   s talk about a
   mathematical term called convolution.

   in image processing, a convolution requires three components:
    1. an input image.
    2. a kernel matrix that we are going to apply to the input image.
    3. an output image to store the output of the input image convolved
       with the kernel.

   convolution itself is actually very easy. all we need to do is:
    1. select an (x, y)-coordinate from the original image.
    2. place the center of the kernel at this (x, y)-coordinate.
    3. take the element-wise multiplication of the input image region and
       the kernel, then sum up the values of these multiplication
       operations into a single value. the sum of these multiplications is
       called the kernel output.
    4. use the same (x, y)-coordinates from step #1, but this time, store
       the kernel output in the same (x, y)-location as the output image.

   below you can find an example of convolving (denoted mathematically as
   the    *    operator) a 3 x 3 region of an image with a 3 x 3 kernel used
   for blurring:
   figure 4: convolving a 3 x 3 input image region with a 3 x 3 kernel
   used for blurring. source: pyimagesearch gurus

   figure 4: convolving a 3 x 3 input image region with a 3 x 3 kernel
   used for blurring. [28]source: pyimagesearch gurus

   therefore,
   figure 5: the output of the convolution operation is stored in the
   output image. source: pyimagesearch gurus

   figure 5: the output of the convolution operation is stored in the
   output image. [29]source: pyimagesearch gurus

   after applying this convolution, we would set the pixel located at the
   coordinate (i, j) of the output image o to o_i,j = 126.

   that   s all there is to it!

   convolution is simply the sum of element-wise id127
   between the kernel and neighborhood that the kernel covers of the input
   image.

implementing convolutions with opencv and python

   that was fun discussing kernels and convolutions     but now let   s move
   on to looking at some actual code to ensure you understand how kernels
   and convolutions are implemented. this source code will also help you
   understand how to apply convolutions to images.

   open up a new file, name it convolutions.py , and let   s get to work:
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   1
   2
   3
   4
   5
   # import the necessary packages
   from skimage.exposure import rescale_intensity
   import numpy as np
   import argparse
   import cv2

   we start on lines 2-5 by importing our required python packages. you
   should already have numpy and opencv installed on your system, but you
   might not have [30]scikit-image installed. to install scikit-image,
   just use pip :
   convolutions with opencv and python

   $ pip install -u scikit-image_______________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   $ pip install -u scikit-image

   next, we can start defining our custom convolve  method:
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   ____________________________________________________________
   def convolve(image, kernel):________________________________
   	# grab the spatial dimensions of the image, along with_____
   	# the spatial dimensions of the kernel_____________________
   	(ih, iw) = image.shape[:2]_________________________________
   	(kh, kw) = kernel.shape[:2]________________________________
   ____________________________________________________________
   	# allocate memory for the output image, taking care to_____
   	# "pad" the borders of the input image so the spatial______
   	# size (i.e., width and height) are not reduced____________
   	pad = (kw - 1) // 2________________________________________
   	image = cv2.copymakeborder(image, pad, pad, pad, pad,______
   		cv2.border_replicate)_____________________________________
   	output = np.zeros((ih, iw), dtype="float32")_______________
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   def convolve(image, kernel):
   # grab the spatial dimensions of the image, along with
   # the spatial dimensions of the kernel
   (ih, iw) = image.shape[:2]
   (kh, kw) = kernel.shape[:2]

   # allocate memory for the output image, taking care to
   # "pad" the borders of the input image so the spatial
   # size (i.e., width and height) are not reduced
   pad = (kw - 1) // 2
   image = cv2.copymakeborder(image, pad, pad, pad, pad,
   cv2.border_replicate)
   output = np.zeros((ih, iw), dtype="float32")

   the convolve  function requires two parameters: the (grayscale) image
   that we want to convolve with the kernel .

   given both our image  and kernel  (which we presume to be numpy
   arrays), we then determine the spatial dimensions (i.e., width and
   height) of each (lines 10 and 11).

   before we continue, it   s important to understand that the process of
      sliding    a convolutional matrix across an image, applying the
   convolution, and then storing the output will actually decrease the
   spatial dimensions of our output image.

   why is this?

   recall that we    center    our computation around the center (x,
   y)-coordinate of the input image that the kernel is currently
   positioned over. this implies there is no such thing as    center    pixels
   for pixels that fall along the border of the image. the decrease in
   spatial dimension is simply a side effect of applying convolutions to
   images. sometimes this effect is desirable and other times its not, it
   simply depends on your application.

   however, in most cases, we want our output image to have the same
   dimensions as our input image. to ensure this, we apply padding (lines
   16-19). here we are simply replicating the pixels along the border of
   the image, such that the output image will match the dimensions of the
   input image.

   other padding methods exist, including zero padding (filling the
   borders with zeros     very common when building convolutional neural
   networks) and wrap around (where the border pixels are determined by
   examining the opposite end of the image). in most cases, you   ll see
   either replicate or zero padding.

   we are now ready to apply the actual convolution to our image:
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   ____________________________________________________________
   def convolve(image, kernel):________________________________
   	# grab the spatial dimensions of the image, along with_____
   	# the spatial dimensions of the kernel_____________________
   	(ih, iw) = image.shape[:2]_________________________________
   	(kh, kw) = kernel.shape[:2]________________________________
   ____________________________________________________________
   	# allocate memory for the output image, taking care to_____
   	# "pad" the borders of the input image so the spatial______
   	# size (i.e., width and height) are not reduced____________
   	pad = (kw - 1) // 2________________________________________
   	image = cv2.copymakeborder(image, pad, pad, pad, pad,______
   		cv2.border_replicate)_____________________________________
   	output = np.zeros((ih, iw), dtype="float32")_______________
   ____________________________________________________________
   	# loop over the input image, "sliding" the kernel across___
   	# each (x, y)-coordinate from left-to-right and top to_____
   	# bottom___________________________________________________
   	for y in np.arange(pad, ih + pad):_________________________
   		for x in np.arange(pad, iw + pad):________________________
   			# extract the roi of the image by extracting the_________
   			# *center* region of the current (x, y)-coordinates______
   			# dimensions_____________________________________________
   			roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]____
   ____________________________________________________________
   			# perform the actual convolution by taking the___________
   			# element-wise multiplicate between the roi and__________
   			# the kernel, then summing the matrix____________________
   			k = (roi * kernel).sum()_________________________________
   ____________________________________________________________
   			# store the convolved value in the output (x,y)-_________
   			# coordinate of the output image_________________________
   			output[y - pad, x - pad] = k_____________________________
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   # loop over the input image, "sliding" the kernel across
   # each (x, y)-coordinate from left-to-right and top to
   # bottom
   for y in np.arange(pad, ih + pad):
   for x in np.arange(pad, iw + pad):
   # extract the roi of the image by extracting the
   # *center* region of the current (x, y)-coordinates
   # dimensions
   roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]

   # perform the actual convolution by taking the
   # element-wise multiplicate between the roi and
   # the kernel, then summing the matrix
   k = (roi * kernel).sum()

   # store the convolved value in the output (x,y)-
   # coordinate of the output image
   output[y - pad, x - pad] = k

   lines 24 and 25 loop over our image ,    sliding    the kernel from
   left-to-right and top-to-bottom 1 pixel at a time.

   line 29 extracts the region of interest (roi) from the image  using
   numpy array slicing. the roi  will be centered around the current (x,
   y)-coordinates of the image . the roi  will also have the same size as
   our kernel , which is critical for the next step.

   convolution is performed on line 34 by taking the element-wise
   multiplication between the roi  and kernel , followed by summing the
   entries in the matrix.

   the output value k  is then stored in the output  array at the same (x,
   y)-coordinates (relative to the input image).

   we can now finish up our convolve  method:
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   ____________________________________________________________
   def convolve(image, kernel):________________________________
   	# grab the spatial dimensions of the image, along with_____
   	# the spatial dimensions of the kernel_____________________
   	(ih, iw) = image.shape[:2]_________________________________
   	(kh, kw) = kernel.shape[:2]________________________________
   ____________________________________________________________
   	# allocate memory for the output image, taking care to_____
   	# "pad" the borders of the input image so the spatial______
   	# size (i.e., width and height) are not reduced____________
   	pad = (kw - 1) // 2________________________________________
   	image = cv2.copymakeborder(image, pad, pad, pad, pad,______
   		cv2.border_replicate)_____________________________________
   	output = np.zeros((ih, iw), dtype="float32")_______________
   ____________________________________________________________
   	# loop over the input image, "sliding" the kernel across___
   	# each (x, y)-coordinate from left-to-right and top to_____
   	# bottom___________________________________________________
   	for y in np.arange(pad, ih + pad):_________________________
   		for x in np.arange(pad, iw + pad):________________________
   			# extract the roi of the image by extracting the_________
   			# *center* region of the current (x, y)-coordinates______
   			# dimensions_____________________________________________
   			roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]____
   ____________________________________________________________
   			# perform the actual convolution by taking the___________
   			# element-wise multiplicate between the roi and__________
   			# the kernel, then summing the matrix____________________
   			k = (roi * kernel).sum()_________________________________
   ____________________________________________________________
   			# store the convolved value in the output (x,y)-_________
   			# coordinate of the output image_________________________
   			output[y - pad, x - pad] = k_____________________________
   ____________________________________________________________
   	# rescale the output image to be in the range [0, 255]_____
   	output = rescale_intensity(output, in_range=(0, 255))______
   	output = (output * 255).astype("uint8")____________________
   ____________________________________________________________
   	# return the output image__________________________________
   	return output______________________________________________
   40
   41
   42
   43
   44
   45
   # rescale the output image to be in the range [0, 255]
   output = rescale_intensity(output, in_range=(0, 255))
   output = (output * 255).astype("uint8")

   # return the output image
   return output

   when working with images, we typically deal with pixel values falling
   in the range [0, 255]. however, when applying convolutions, we can
   easily obtain values that fall outside this range.

   in order to bring our output  image back into the range [0, 255], we
   apply the rescale_intensity  function of scikit-image (line 41). we
   also convert our image back to an unsigned 8-bit integer data type on
   line 42 (previously, the output  image was a floating point type in
   order to handle pixel values outside the range [0, 255]).

   finally, the output  image is returned to the calling function on line
   45.

   now that we   ve defined our convolve  function, let   s move on to the
   driver portion of the script. this section of our program will handle
   parsing command line arguments, defining a series of kernels we are
   going to apply to our image, and then displaying the output results:
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   ____________________________________________________________
   def convolve(image, kernel):________________________________
   	# grab the spatial dimensions of the image, along with_____
   	# the spatial dimensions of the kernel_____________________
   	(ih, iw) = image.shape[:2]_________________________________
   	(kh, kw) = kernel.shape[:2]________________________________
   ____________________________________________________________
   	# allocate memory for the output image, taking care to_____
   	# "pad" the borders of the input image so the spatial______
   	# size (i.e., width and height) are not reduced____________
   	pad = (kw - 1) // 2________________________________________
   	image = cv2.copymakeborder(image, pad, pad, pad, pad,______
   		cv2.border_replicate)_____________________________________
   	output = np.zeros((ih, iw), dtype="float32")_______________
   ____________________________________________________________
   	# loop over the input image, "sliding" the kernel across___
   	# each (x, y)-coordinate from left-to-right and top to_____
   	# bottom___________________________________________________
   	for y in np.arange(pad, ih + pad):_________________________
   		for x in np.arange(pad, iw + pad):________________________
   			# extract the roi of the image by extracting the_________
   			# *center* region of the current (x, y)-coordinates______
   			# dimensions_____________________________________________
   			roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]____
   ____________________________________________________________
   			# perform the actual convolution by taking the___________
   			# element-wise multiplicate between the roi and__________
   			# the kernel, then summing the matrix____________________
   			k = (roi * kernel).sum()_________________________________
   ____________________________________________________________
   			# store the convolved value in the output (x,y)-_________
   			# coordinate of the output image_________________________
   			output[y - pad, x - pad] = k_____________________________
   ____________________________________________________________
   	# rescale the output image to be in the range [0, 255]_____
   	output = rescale_intensity(output, in_range=(0, 255))______
   	output = (output * 255).astype("uint8")____________________
   ____________________________________________________________
   	# return the output image__________________________________
   	return output______________________________________________
   ____________________________________________________________
   # construct the argument parse and parse the arguments______
   ap = argparse.argumentparser()______________________________
   ap.add_argument("-i", "--image", required=true,_____________
   	help="path to the input image")____________________________
   args = vars(ap.parse_args())________________________________
   ____________________________________________________________
   # construct average blurring kernels used to smooth an image
   smallblur = np.ones((7, 7), dtype="float") * (1.0 / (7 * 7))
   largeblur = np.ones((21, 21), dtype="float") * (1.0 / (21 * 
   ____________________________________________________________
   # construct a sharpening filter_____________________________
   sharpen = np.array((________________________________________
   	[0, -1, 0],________________________________________________
   	[-1, 5, -1],_______________________________________________
   	[0, -1, 0]), dtype="int")__________________________________
   47
   48
   49
   50
   51
   52
   53
   54
   55
   56
   57
   58
   59
   60
   61
   # construct the argument parse and parse the arguments
   ap = argparse.argumentparser()
   ap.add_argument("-i", "--image", required=true,
   help="path to the input image")
   args = vars(ap.parse_args())

   # construct average blurring kernels used to smooth an image
   smallblur = np.ones((7, 7), dtype="float") * (1.0 / (7 * 7))
   largeblur = np.ones((21, 21), dtype="float") * (1.0 / (21 * 21))

   # construct a sharpening filter
   sharpen = np.array((
   [0, -1, 0],
   [-1, 5, -1],
   [0, -1, 0]), dtype="int")

   lines 48-51 handle parsing our command line arguments. we only need a
   single argument here, --image , which is the path to our input path.

   we then move on to lines 54 and 55 which define a 7 x 7 kernel and a 21
   x 21 kernel used to blur/smooth an image. the larger the kernel is, the
   more the image will be blurred. examining this kernel, you can see that
   the output of applying the kernel to an roi will simply be the average
   of the input region.

   we define a sharpening kernel on lines 58-61, used to enhance line
   structures and other details of an image. explaining each of these
   kernels in detail is outside the scope of this tutorial, so if you   re
   interested in learning more about kernel construction, i would suggest
   [31]starting here and then playing around with the [32]excellent kernel
   visualization tool on setosa.io.

   let   s define a few more kernels:
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   ____________________________________________________________
   def convolve(image, kernel):________________________________
   	# grab the spatial dimensions of the image, along with_____
   	# the spatial dimensions of the kernel_____________________
   	(ih, iw) = image.shape[:2]_________________________________
   	(kh, kw) = kernel.shape[:2]________________________________
   ____________________________________________________________
   	# allocate memory for the output image, taking care to_____
   	# "pad" the borders of the input image so the spatial______
   	# size (i.e., width and height) are not reduced____________
   	pad = (kw - 1) // 2________________________________________
   	image = cv2.copymakeborder(image, pad, pad, pad, pad,______
   		cv2.border_replicate)_____________________________________
   	output = np.zeros((ih, iw), dtype="float32")_______________
   ____________________________________________________________
   	# loop over the input image, "sliding" the kernel across___
   	# each (x, y)-coordinate from left-to-right and top to_____
   	# bottom___________________________________________________
   	for y in np.arange(pad, ih + pad):_________________________
   		for x in np.arange(pad, iw + pad):________________________
   			# extract the roi of the image by extracting the_________
   			# *center* region of the current (x, y)-coordinates______
   			# dimensions_____________________________________________
   			roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]____
   ____________________________________________________________
   			# perform the actual convolution by taking the___________
   			# element-wise multiplicate between the roi and__________
   			# the kernel, then summing the matrix____________________
   			k = (roi * kernel).sum()_________________________________
   ____________________________________________________________
   			# store the convolved value in the output (x,y)-_________
   			# coordinate of the output image_________________________
   			output[y - pad, x - pad] = k_____________________________
   ____________________________________________________________
   	# rescale the output image to be in the range [0, 255]_____
   	output = rescale_intensity(output, in_range=(0, 255))______
   	output = (output * 255).astype("uint8")____________________
   ____________________________________________________________
   	# return the output image__________________________________
   	return output______________________________________________
   ____________________________________________________________
   # construct the argument parse and parse the arguments______
   ap = argparse.argumentparser()______________________________
   ap.add_argument("-i", "--image", required=true,_____________
   	help="path to the input image")____________________________
   args = vars(ap.parse_args())________________________________
   ____________________________________________________________
   # construct average blurring kernels used to smooth an image
   smallblur = np.ones((7, 7), dtype="float") * (1.0 / (7 * 7))
   largeblur = np.ones((21, 21), dtype="float") * (1.0 / (21 * 
   ____________________________________________________________
   # construct a sharpening filter_____________________________
   sharpen = np.array((________________________________________
   	[0, -1, 0],________________________________________________
   	[-1, 5, -1],_______________________________________________
   	[0, -1, 0]), dtype="int")__________________________________
   ____________________________________________________________
   # construct the laplacian kernel used to detect edge-like___
   # regions of an image_______________________________________
   laplacian = np.array((______________________________________
   	[0, 1, 0],_________________________________________________
   	[1, -4, 1],________________________________________________
   	[0, 1, 0]), dtype="int")___________________________________
   ____________________________________________________________
   # construct the sobel x-axis kernel_________________________
   sobelx = np.array((_________________________________________
   	[-1, 0, 1],________________________________________________
   	[-2, 0, 2],________________________________________________
   	[-1, 0, 1]), dtype="int")__________________________________
   ____________________________________________________________
   # construct the sobel y-axis kernel_________________________
   sobely = np.array((_________________________________________
   	[-1, -2, -1],______________________________________________
   	[0, 0, 0],_________________________________________________
   	[1, 2, 1]), dtype="int")___________________________________
   63
   64
   65
   66
   67
   68
   69
   70
   71
   72
   73
   74
   75
   76
   77
   78
   79
   80
   # construct the laplacian kernel used to detect edge-like
   # regions of an image
   laplacian = np.array((
   [0, 1, 0],
   [1, -4, 1],
   [0, 1, 0]), dtype="int")

   # construct the sobel x-axis kernel
   sobelx = np.array((
   [-1, 0, 1],
   [-2, 0, 2],
   [-1, 0, 1]), dtype="int")

   # construct the sobel y-axis kernel
   sobely = np.array((
   [-1, -2, -1],
   [0, 0, 0],
   [1, 2, 1]), dtype="int")

   lines 65-68 define a [33]laplacian operator that can be used as a form
   of edge detection.

   note: the laplacian is also very useful for [34]detecting blur in
   images.

   finally, we   ll define two [35]sobel filters on lines 71-80. the first
   (lines 71-74) is used to detect vertical changes in the gradient of the
   image. similarly, lines 77-80 constructs a filter used to
   detect horizontal changes in the gradient.

   given all these kernels, we lump them together into a set of tuples
   called a    kernel bank   :
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   ____________________________________________________________
   def convolve(image, kernel):________________________________
   	# grab the spatial dimensions of the image, along with_____
   	# the spatial dimensions of the kernel_____________________
   	(ih, iw) = image.shape[:2]_________________________________
   	(kh, kw) = kernel.shape[:2]________________________________
   ____________________________________________________________
   	# allocate memory for the output image, taking care to_____
   	# "pad" the borders of the input image so the spatial______
   	# size (i.e., width and height) are not reduced____________
   	pad = (kw - 1) // 2________________________________________
   	image = cv2.copymakeborder(image, pad, pad, pad, pad,______
   		cv2.border_replicate)_____________________________________
   	output = np.zeros((ih, iw), dtype="float32")_______________
   ____________________________________________________________
   	# loop over the input image, "sliding" the kernel across___
   	# each (x, y)-coordinate from left-to-right and top to_____
   	# bottom___________________________________________________
   	for y in np.arange(pad, ih + pad):_________________________
   		for x in np.arange(pad, iw + pad):________________________
   			# extract the roi of the image by extracting the_________
   			# *center* region of the current (x, y)-coordinates______
   			# dimensions_____________________________________________
   			roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]____
   ____________________________________________________________
   			# perform the actual convolution by taking the___________
   			# element-wise multiplicate between the roi and__________
   			# the kernel, then summing the matrix____________________
   			k = (roi * kernel).sum()_________________________________
   ____________________________________________________________
   			# store the convolved value in the output (x,y)-_________
   			# coordinate of the output image_________________________
   			output[y - pad, x - pad] = k_____________________________
   ____________________________________________________________
   	# rescale the output image to be in the range [0, 255]_____
   	output = rescale_intensity(output, in_range=(0, 255))______
   	output = (output * 255).astype("uint8")____________________
   ____________________________________________________________
   	# return the output image__________________________________
   	return output______________________________________________
   ____________________________________________________________
   # construct the argument parse and parse the arguments______
   ap = argparse.argumentparser()______________________________
   ap.add_argument("-i", "--image", required=true,_____________
   	help="path to the input image")____________________________
   args = vars(ap.parse_args())________________________________
   ____________________________________________________________
   # construct average blurring kernels used to smooth an image
   smallblur = np.ones((7, 7), dtype="float") * (1.0 / (7 * 7))
   largeblur = np.ones((21, 21), dtype="float") * (1.0 / (21 * 
   ____________________________________________________________
   # construct a sharpening filter_____________________________
   sharpen = np.array((________________________________________
   	[0, -1, 0],________________________________________________
   	[-1, 5, -1],_______________________________________________
   	[0, -1, 0]), dtype="int")__________________________________
   ____________________________________________________________
   # construct the laplacian kernel used to detect edge-like___
   # regions of an image_______________________________________
   laplacian = np.array((______________________________________
   	[0, 1, 0],_________________________________________________
   	[1, -4, 1],________________________________________________
   	[0, 1, 0]), dtype="int")___________________________________
   ____________________________________________________________
   # construct the sobel x-axis kernel_________________________
   sobelx = np.array((_________________________________________
   	[-1, 0, 1],________________________________________________
   	[-2, 0, 2],________________________________________________
   	[-1, 0, 1]), dtype="int")__________________________________
   ____________________________________________________________
   # construct the sobel y-axis kernel_________________________
   sobely = np.array((_________________________________________
   	[-1, -2, -1],______________________________________________
   	[0, 0, 0],_________________________________________________
   	[1, 2, 1]), dtype="int")___________________________________
   ____________________________________________________________
   # construct the kernel bank, a list of kernels we're going__
   # to apply using both our custom `convole` function and_____
   # opencv's `filter2d` function______________________________
   kernelbank = (______________________________________________
   	("small_blur", smallblur),_________________________________
   	("large_blur", largeblur),_________________________________
   	("sharpen", sharpen),______________________________________
   	("laplacian", laplacian),__________________________________
   	("sobel_x", sobelx),_______________________________________
   	("sobel_y", sobely)________________________________________
   )___________________________________________________________
   82
   83
   84
   85
   86
   87
   88
   89
   90
   91
   92
   # construct the kernel bank, a list of kernels we're going
   # to apply using both our custom `convole` function and
   # opencv's `filter2d` function
   kernelbank = (
   ("small_blur", smallblur),
   ("large_blur", largeblur),
   ("sharpen", sharpen),
   ("laplacian", laplacian),
   ("sobel_x", sobelx),
   ("sobel_y", sobely)
   )

   finally, we are ready to apply our kernelbank  to our --input  image:
   convolutions with opencv and python
   python

   # import the necessary packages_____________________________
   from skimage.exposure import rescale_intensity______________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import cv2__________________________________________________
   ____________________________________________________________
   def convolve(image, kernel):________________________________
   	# grab the spatial dimensions of the image, along with_____
   	# the spatial dimensions of the kernel_____________________
   	(ih, iw) = image.shape[:2]_________________________________
   	(kh, kw) = kernel.shape[:2]________________________________
   ____________________________________________________________
   	# allocate memory for the output image, taking care to_____
   	# "pad" the borders of the input image so the spatial______
   	# size (i.e., width and height) are not reduced____________
   	pad = (kw - 1) // 2________________________________________
   	image = cv2.copymakeborder(image, pad, pad, pad, pad,______
   		cv2.border_replicate)_____________________________________
   	output = np.zeros((ih, iw), dtype="float32")_______________
   ____________________________________________________________
   	# loop over the input image, "sliding" the kernel across___
   	# each (x, y)-coordinate from left-to-right and top to_____
   	# bottom___________________________________________________
   	for y in np.arange(pad, ih + pad):_________________________
   		for x in np.arange(pad, iw + pad):________________________
   			# extract the roi of the image by extracting the_________
   			# *center* region of the current (x, y)-coordinates______
   			# dimensions_____________________________________________
   			roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]____
   ____________________________________________________________
   			# perform the actual convolution by taking the___________
   			# element-wise multiplicate between the roi and__________
   			# the kernel, then summing the matrix____________________
   			k = (roi * kernel).sum()_________________________________
   ____________________________________________________________
   			# store the convolved value in the output (x,y)-_________
   			# coordinate of the output image_________________________
   			output[y - pad, x - pad] = k_____________________________
   ____________________________________________________________
   	# rescale the output image to be in the range [0, 255]_____
   	output = rescale_intensity(output, in_range=(0, 255))______
   	output = (output * 255).astype("uint8")____________________
   ____________________________________________________________
   	# return the output image__________________________________
   	return output______________________________________________
   ____________________________________________________________
   # construct the argument parse and parse the arguments______
   ap = argparse.argumentparser()______________________________
   ap.add_argument("-i", "--image", required=true,_____________
   	help="path to the input image")____________________________
   args = vars(ap.parse_args())________________________________
   ____________________________________________________________
   # construct average blurring kernels used to smooth an image
   smallblur = np.ones((7, 7), dtype="float") * (1.0 / (7 * 7))
   largeblur = np.ones((21, 21), dtype="float") * (1.0 / (21 * 
   ____________________________________________________________
   # construct a sharpening filter_____________________________
   sharpen = np.array((________________________________________
   	[0, -1, 0],________________________________________________
   	[-1, 5, -1],_______________________________________________
   	[0, -1, 0]), dtype="int")__________________________________
   ____________________________________________________________
   # construct the laplacian kernel used to detect edge-like___
   # regions of an image_______________________________________
   laplacian = np.array((______________________________________
   	[0, 1, 0],_________________________________________________
   	[1, -4, 1],________________________________________________
   	[0, 1, 0]), dtype="int")___________________________________
   ____________________________________________________________
   # construct the sobel x-axis kernel_________________________
   sobelx = np.array((_________________________________________
   	[-1, 0, 1],________________________________________________
   	[-2, 0, 2],________________________________________________
   	[-1, 0, 1]), dtype="int")__________________________________
   ____________________________________________________________
   # construct the sobel y-axis kernel_________________________
   sobely = np.array((_________________________________________
   	[-1, -2, -1],______________________________________________
   	[0, 0, 0],_________________________________________________
   	[1, 2, 1]), dtype="int")___________________________________
   ____________________________________________________________
   # construct the kernel bank, a list of kernels we're going__
   # to apply using both our custom `convole` function and_____
   # opencv's `filter2d` function______________________________
   kernelbank = (______________________________________________
   	("small_blur", smallblur),_________________________________
   	("large_blur", largeblur),_________________________________
   	("sharpen", sharpen),______________________________________
   	("laplacian", laplacian),__________________________________
   	("sobel_x", sobelx),_______________________________________
   	("sobel_y", sobely)________________________________________
   )___________________________________________________________
   ____________________________________________________________
   # load the input image and convert it to grayscale__________
   image = cv2.imread(args["image"])___________________________
   gray = cv2.cvtcolor(image, cv2.color_bgr2gray)______________
   ____________________________________________________________
   # loop over the kernels_____________________________________
   for (kernelname, kernel) in kernelbank:_____________________
   	# apply the kernel to the grayscale image using both_______
   	# our custom `convole` function and opencv's `filter2d`____
   	# function_________________________________________________
   	print("[info] applying {} kernel".format(kernelname))______
   	convoleoutput = convolve(gray, kernel)_____________________
   	opencvoutput = cv2.filter2d(gray, -1, kernel)______________
   ____________________________________________________________
   	# show the output images___________________________________
   	cv2.imshow("original", gray)_______________________________
   	cv2.imshow("{} - convole".format(kernelname), convoleoutput
   	cv2.imshow("{} - opencv".format(kernelname), opencvoutput)_
   	cv2.waitkey(0)_____________________________________________
   	cv2.destroyallwindows()____________________________________
   94
   95
   96
   97
   98
   99
   100
   101
   102
   103
   104
   105
   106
   107
   108
   109
   110
   111
   112
   # load the input image and convert it to grayscale
   image = cv2.imread(args["image"])
   gray = cv2.cvtcolor(image, cv2.color_bgr2gray)

   # loop over the kernels
   for (kernelname, kernel) in kernelbank:
   # apply the kernel to the grayscale image using both
   # our custom `convole` function and opencv's `filter2d`
   # function
   print("[info] applying {} kernel".format(kernelname))
   convoleoutput = convolve(gray, kernel)
   opencvoutput = cv2.filter2d(gray, -1, kernel)

   # show the output images
   cv2.imshow("original", gray)
   cv2.imshow("{} - convole".format(kernelname), convoleoutput)
   cv2.imshow("{} - opencv".format(kernelname), opencvoutput)
   cv2.waitkey(0)
   cv2.destroyallwindows()

   lines 95 and 96 load our image from disk and convert it to grayscale.
   convolution operators can certainly be applied to rgb (or other
   multi-channel images), but for the sake of simplicity in this blog
   post, we   ll only apply our filters to grayscale images).

   we start looping over our set of kernels in the kernelbank  on line 99
    and then apply the current kernel  to the gray  image on line 104 by
   calling our custom convolve  method which we defined earlier.

   as a sanity check, we also call cv2.filter2d  which also applies our
   kernel  to the gray  image. the cv2.filter2d  function is a much more
   optimized version of our convolve  function. the main reason i included
   the implementation of convolve  in this blog post is to give you a
   better understanding of how convolutions work under the hood.

   finally, lines 108-112 display the output images to our screen.

example convolutions with opencv and python

   today   s example image comes from a photo i took a few weeks ago at my
   favorite bar in south norwalk, ct     [36]cask republic. in this image
   you   ll see a glass of my favorite beer (smuttynose findest kind ipa)
   along with three 3d-printed pokemon from the (unfortunately, now
   closed) industrial chimp shop:
   figure 6: the example image we are going to apply our convolutions to.

   figure 6: the example image we are going to apply our convolutions to.

   to run our script, just issue the following command:
   convolutions with opencv and python
   shell

   $ python convolutions.py --image 3d_pokemon.png_____________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   $ python convolutions.py --image 3d_pokemon.png

   you   ll then see the results of applying our smallblur  kernel to the
   input image:
   figure 7: applying a small blur convolution with our "convolve"
   function and then validating it against the results of opencv's
   "cv2.filter2d" function.

   figure 7: applying a small blur convolution with our    convolve   
   function and then validating it against the results of opencv   s
      cv2.filter2d    function.

   on the left, we have our original image. then in the center we have the
   results from the convolve  function. and on the right, the results from
   cv2.filter2d . as the results demonstrate, our output matches
   cv2.filter2d , indicating that our convolve  function is working
   properly. furthermore, our original image now appears    blurred    and
      smoothed   , thanks to the smoothing kernel.

   next, let   s apply a larger blur:
   figure 8: as we convolve our image with a larger smoothing kernel, our
   image becomes more blurred.

   figure 8: as we convolve our image with a larger smoothing kernel, our
   image becomes more blurred.

   comparing figure 7 and figure 8, notice how as the size of the
   averaging kernel increases, the amount of blur in the output
   image increases as well.

   we can also sharpen our image:
   figure 9: using a sharpening kernel enhances edge-like structures and
   other details in our image.

   figure 9: using a sharpening kernel enhances edge-like structures and
   other details in our image.

   let   s compute edges using the laplacian operator:
   figure 10: applying the laplacian operator via convolution with opencv
   and python.

   figure 10: applying the laplacian operator via convolution with opencv
   and python.

   find vertical edges with the sobel operator:
   figure 11: utilizing the sobel-x kernel to find vertical images.

   figure 11: utilizing the sobel-x kernel to find vertical images.

   and find horizontal edges using sobel as well:
   figure 12: finding horizontal gradients in an image using the sobel-y
   operator and convolutions.

   figure 12: finding horizontal gradients in an image using the sobel-y
   operator and convolutions.

the role of convolutions in deep learning

   as you   ve gathered through this blog post, we must manually hand-define
   each of our kernels for applying various operations such as smoothing,
   sharpening, and edge detection.

   that   s all fine and good, but what if there was a way to learn these
   filters instead? is it possible to define a machine learning algorithm
   that can look at images and eventually learn these types of operators?

   in fact, there is     these types of algorithms are a sub-type of neural
   networks called convolutional neural networks (id98s). by applying
   convolutional filters, nonlinear id180, pooling, and
   id26, id98s are able to learn filters that can detect edges
   and blob-like structures in lower-level layers of the network     and
   then use the edges and structures as building blocks, eventually
   detecting higher-level objects (i.e., faces, cats, dogs, cups, etc.) in
   the deeper layers of the network.

   exactly how do id98s do this?

   i   ll show you     but it will have to wait for another few blog posts
   until we cover enough basics.

summary

   in today   s blog post, we discussed image kernels and convolutions. if
   we think of an image as a big matrix, then an image kernel is just
   a tiny matrix that sits on top of the image.

   this kernel then slides from left-to-right and top-to-bottom, computing
   the sum of element-wise multiplications between the input image and the
   kernel along the way     we call this value the kernel output. the kernel
   output is then stored in an output image at the same (x, y)-coordinates
   as the input image (after accounting for any padding to ensure the
   output image has the same dimensions as the input).

   given our newfound knowledge of convolutions, we defined an opencv and
   python function to apply a series of kernels to an image. these
   operators allowed us to blur an image, sharpen it, and detect edges.

   finally, we briefly discussed the roles kernels/convolutions play in
   deep learning, specifically convolutional neural networks, and how
   these filters can be learned automatically instead of needing
   to manually define them first.

   in next week   s blog post, i   ll be showing you how to train your first
   convolutional neural network from scratch using python     be sure to
   signup for the pyimagesearch newsletter using the form below to be
   notified when the blog post goes live!

downloads:

   if you would like to download the code and images used in this post,
   please enter your email address in the form below. not only will you
   get a .zip of the code, i   ll also send you a free 17-page resource
   guide on id161, opencv, and deep learning. inside you'll find
   my hand-picked tutorials, books, courses, and libraries to help you
   master cv and dl! sound good? if so, enter your email address and i   ll
   send you the code immediately!

   email address: ____________________

   download the code!

resource guide (it   s totally free).

   get your free 17-page id161 and deep learning resource guide
   pdf
   enter your email address below to get my free 17-page id161,
   opencv, and deep learning resource guide pdf. inside you'll find my
   hand-picked tutorials, books, courses, and python libraries to help you
   master id161 and deep learning!
   ____________________
   download the guide!

   [37]blurring, [38]convolutional neural network, [39]convolutions,
   [40]deep learning, [41]edge detection, [42]gradients, [43]kernels,
   [44]opencv, [45]sharpen
   [46]installing keras for deep learning
   [47]lenet     convolutional neural network in python

50 responses to convolutions with opencv and python

    1. winston chen july 25, 2016 at 2:57 pm [48]#
       thanks for sharing the concept of convolution. very clear
       introductions and simple examples.
       [49]reply
          + adrian rosebrock july 27, 2016 at 2:30 pm [50]#
            no problem, i   m happy i could help introduce the topic
            winston!     
            [51]reply
    2. juan tapia july 25, 2016 at 10:03 pm [52]#
       dear adria
       i have a doubt with this!
       this procedure describe the correlation between matrix and not the
       convolution.
       in a convolution we have a minus sign in the middle of the
       equation, thus we need to turn and swipe the second matrix. make
       sense for you?
       [53]reply
          + adrian rosebrock july 27, 2016 at 2:26 pm [54]#
            hey juan     thanks for the comment, although i   m not sure i
            understand your question. can you please elaborate?
            [55]reply
               o buchtak july 31, 2016 at 4:59 am [56]#
                 juan is right. when you   re doing convolution, you   re
                 supposed to flip the kernel both horizontally and
                 vertically in the case od 2d images. hence the minus
                 sign. it obvisouly doesn   t matter for symmetric kernels
                 like averaging etc., but in general it can lead to nasty
                 bugs for example when trying to accelerate the
                 computation using convolution theorem and fft.
                 on the other hand, as far as i   m aware, caffe framework
                 also only performs correlation in their convolutional
                 layers, while several other libraries do it by the book.
                 so, be aware of these things when trying to convert
                 pre-trained models for instance   
                 [57]reply
                    # adrian rosebrock july 31, 2016 at 10:35 am [58]#
                      oh i see     now i understand the question. thanks for
                      the clarification buchtak.
                      [59]reply
    3. dd july 25, 2016 at 11:28 pm [60]#
       hi,
       thanks for this beautifully written post. it very well explains the
       concept in a simple language. code example and visuals are real
       bonus. keep up the good work.
       thanks!
       [61]reply
          + adrian rosebrock july 27, 2016 at 2:26 pm [62]#
            thanks, i   m happy i could help!
            [63]reply
    4. vani july 26, 2016 at 7:31 am [64]#
       great job ..
       [65]reply
          + adrian rosebrock july 27, 2016 at 2:00 pm [66]#
            thank you vani.
            [67]reply
    5. kenny july 27, 2016 at 11:57 am [68]#
       cool stuff adrian      a pleasure to read your enthusiasm and
       excitement      keep going!
       [69]reply
          + adrian rosebrock july 27, 2016 at 1:53 pm [70]#
            thanks kenny!     
            [71]reply
               o bashir august 21, 2017 at 7:59 pm [72]#
                 hi
                 please tell me which method is the best for detect any
                 object into the large image by using nns?
                 [73]reply
                    # adrian rosebrock august 22, 2017 at 10:47 am [74]#
                      which method is    best    really depends on your
                      application and what you   re actually trying to
                      detect. i would suggest looking into popular object
                      detection frameworks such as yolo, faster r-id98s,
                      and ssds.
                      [75]reply
    6. ian august 29, 2016 at 7:23 pm [76]#
       dear adrian,
       these examples require the skimage library. is it possible to
       install that library on the raspberry pi 3 model b?
       thanks.
           ian
       [77]reply
          + adrian rosebrock august 30, 2016 at 12:44 pm [78]#
            yes, please refer to the [79]scikit-image documentation.
            [80]reply
    7. amrosik september 14, 2016 at 3:29 am [81]#
       applying a laplacian operation twice, does that correspond to a
       sqared-laplacian operator?
       [82]reply
          + adrian rosebrock september 15, 2016 at 9:35 am [83]#
            why would you take the laplacian of the laplacian? is there a
            particular reason you need to do that?
            [84]reply
    8. hygo oliveira september 23, 2016 at 8:42 pm [85]#
       wonderful tutorial. it helped me very much.
       [86]reply
          + adrian rosebrock september 27, 2016 at 8:54 am [87]#
            thanks hygo, i   m glad it was able to help you understand
            convolutions     
            [88]reply
    9. [89]luis jos   september 26, 2016 at 9:23 am [90]#
       hi adrian klose,
       nice tutorial! i wonder i you have experience in performing the
       opposite operation: deconvolution.
       thanks again for sharing your knowledge to the world!
       luis
       [91]reply
   10. pyofey october 11, 2016 at 4:54 am [92]#
       nice post adrian,
       i wanted to know if there is some method to intuitively de-blur
       blurred images. like of course we need to de-convolve with the blur
       causing kernel but in most practical scenarios we dont know that
       kernel and resort to brute-force blind de-convolution.
       so can we perform blind deconvolution using (say) some ml
       algorithm?
       [93]reply
          + adrian rosebrock october 11, 2016 at 12:51 pm [94]#
            it really depends on the level of which you are trying to
            deblur the image. applying deblurring using a simple kernel is
            unlikely to give you ideal results. the current
            state-of-the-art involves applying machine learning to deblur
            images. here is a link [95]to a recent nips paper so you can
            learn more about the topic.
            [96]reply
   11. atti november 29, 2016 at 5:21 am [97]#
       thanks for a great post adrian,
       i encountered a small issue with one of the snippets. i had to
       convert pad to an int since cv2.copymakeborder expects ints as
       paddings. thought i`d let you know.
       # allocate memory for the output image, taking care to
       #    pad    the borders of the input image so the spatial
       # size (i.e., width and height) are not reduced
       pad = int((kw     1) / 2)
       image = cv2.copymakeborder(image, pad, pad, pad, pad,
       cv2.border_replicate)
       [98]reply
          + adrian rosebrock november 29, 2016 at 7:55 am [99]#
            thanks for sharing atti! just to clarify, were you using
            python 2.7 or python 3?
            [100]reply
               o joel january 1, 2017 at 2:15 pm [101]#
                 i encountered the same, using python 3.5.2, opencv 3.1.0.
                 i applied the same fix as atti.
                 thank you for the great blog!
                 [102]reply
                    # joel january 1, 2017 at 3:05 pm [103]#
                      ps:
                      i used anaconda 3 to make the whole installation
                      process simpler. using anaconda has the added bonus
                      of a more consistent experience between linux and
                      win10.
                      [104]reply
          + oleg august 24, 2017 at 9:52 am [105]#
            atti thank you for your message. i also has problem with with
            this code but i added int (pad = int((kw     1) / 2)) how you
            wrote and this code work. thank you.
            [106]reply
   12. lugia february 7, 2017 at 5:57 pm [107]#
       thanks for sharing the post. i   ve subscribed one of your book and
       really like it.
       [108]reply
          + adrian rosebrock february 10, 2017 at 2:15 pm [109]#
            thanks for picking up a copy lugia, i appreciate it!
            [110]reply
   13. zoya february 24, 2017 at 12:30 pm [111]#
       sir, i encountered this error while running that code    can u help
       me through this
       ubuntu@ubuntu-inspiron-5559:~/myproject$ python convolutions.py
       usage: convolutions.py [-h] -i image
       convolutions.py: error: argument -i/   image is required
       [112]reply
          + adrian rosebrock february 27, 2017 at 11:24 am [113]#
            you need to supply the --image command line argument to the
            script. i would suggest you read up on [114]command line
            arguments before continuing.
            [115]reply
   14. gero noerenberg march 1, 2017 at 7:15 am [116]#
       hi adrian,
       wonderful tutorial as all your posts! thank you.
       i need help with an issue i   m running in:
       applying the sharpening filter the call to cv2.filter2d(gray, -1,
       kernel) run into an exception:
       cv2.error:
       c:\slave\wininstallermegapack\src\opencv\modules\imgproc\src\templm
       atch.cpp:61: error: (-215) depth == tdepth || tdepth == cv_32f
       would be great to get an hint how to solve this.
       many thanks
       gero
       [117]reply
          + adrian rosebrock march 2, 2017 at 6:51 am [118]#
            is it only the sharpening kernel? or all other kernels?
            [119]reply
   15. shadab april 1, 2017 at 6:45 am [120]#
       hi adrian! thanks for the amazing post. although i am a little
       stuck on the range of    for    loops in convolve function.
       instead of , for e.g. for    x   , np.arange(pad, iw + pad), shoudn   t
       it be just np.arange(pad, iw) since while cutting out the roi you
       are considering the extra pad width ( by adding    pad    value to x )
       ?
       thank you.
       [121]reply
          + adrian rosebrock april 3, 2017 at 2:11 pm [122]#
            if i understand your question correctly, the np.arange
            function is non-inclusive on the upper end, hence we add the
            extra pad value.
            [123]reply
   16. yashaswini april 16, 2017 at 7:49 am [124]#
       thanks for the detailed and clear explanation. i have to define a
       kernel for a specific template (a part of the image ) and match it
       with a series of other images. when i do so, the shapes of the
       kernel and images are not the same. it pops the error message
       saying    operands could not be broadcast together     . is there a
       different kind of padding that i should follow?
       thanks in advance     
       [125]reply
          + adrian rosebrock april 16, 2017 at 8:49 am [126]#
            the shapes of the kernel and image shouldn   t be the same since
            the kernel essentially slides across the input image. it
            sounds like you   re not extracting the roi of the input image
            correctly before applying the kernel. if the input region is
            smaller than the kernel size, simply pad the input roi.
            [127]reply
   17. mashariki september 5, 2017 at 6:22 pm [128]#
       thanks a lot for demystifying these hard topics.
       [129]reply
   18. unlimitedjava november 7, 2017 at 2:14 am [130]#
       thanks for your sharing good information.
       i have tested this source code for height 1640, width 1190 bitmap
       image.
       it   s too slow in my virtualbox ubuntu 16.04.
       thank you.
       [131]reply
          + adrian rosebrock november 9, 2017 at 7:04 am [132]#
            we normally don   t process images larger than 600px along its
            maximum dimension (unless we are applying a specific technique
            that is geared towards large images). resize your image and it
            will run significantly faster.
            [133]reply
   19. kesava prasad november 7, 2017 at 11:13 pm [134]#
       hi adrian,
       great post. btw, to find scratches from an image (of a metal part)
       is it a good idea to use convolution?
       [135]reply
          + adrian rosebrock november 9, 2017 at 6:44 am [136]#
            that really depends on your input images. i   ve never tried to
            detect scratches on metal but i imagine you might be able to
            (1) devise a kernel that reveals scratch-like regions or (2)
            train a network that learns a set of filters that activates
            under scratch regions.
            [137]reply
   20. [138]robert maria december 12, 2017 at 1:51 am [139]#
       hi adrian!
       thank you for this post! could you please help me understand how 3d
       convolutions store color information? am i able to detect green
       cats from rgb images if my first convolutional layer uses 3d
       filters? or do we use 3d filters to capture information related to
       shape, edges?
       thank you,
       robert
       [140]reply
          + adrian rosebrock december 12, 2017 at 9:02 am [141]#
            i assume you are referring to deep learning in which case the
            convolutions are learned from your input images. if your input
            images contain green cats then the lower layers of the network
            will learn color blobs and edge-like regions. mid-layers of
            the network combine this information to form contours,
            outlines, and intersections. the highest layers of the network
            start to form these semantic concepts such as    cat   ,    dog   ,
            etc. id98s are able to encode color information starting from
            the input layer.
            [142]reply
   21. jan december 15, 2017 at 4:18 pm [143]#
       thank you for this post! could you please help me how to apply
       convolution to apply    directional weighted median filter   . which
       uses the absolute sum of differences between center pixel and
       pixels aligned in four main direction, to detect random valued
       noise.
       [144]reply
   22. [145]foad august 10, 2018 at 6:14 pm [146]#
       i   m also trying to implement the convolution of arbitrary shaped
       ndarrays in numpy here:
       [147]http://bit.ly/2mhjcex
       you may wanna take a look.
       [148]reply
   23. tool_elucidator november 6, 2018 at 8:49 am [149]#
       hello sir, ia have a question do you know how the inbuilt
       convolution function performs this operation ?
       i mean the cv2.filter2d or the cuda::createconvolution ?
       thanks a lot sir your post solve all my questions about convolution
       [150]reply

trackbacks/pingbacks

    1. [151]lenet - convolutional neural network in python - pyimagesearch
       - august 1, 2016
       [   ] layers later in this series of posts (although you should
       already know the basics of how convolution operations work); but in
       the meantime, simply follow along, enjoy the lesson, and learn how
       to implement your [   ]
    2. [152]how to get better answers to your id161 questions -
       pyimagesearch - february 27, 2017
       [   ] particular, i vividly remember struggling with the concept
       of kernels and convolutions     i simply couldn   t translate the
       mathematics in my textbook to an actual practical [   ]

leave a reply [153]click here to cancel reply.

   comment
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________

   ______________________________name (required)

   ______________________________email (will not be published) (required)

   ______________________________website

   submit comment

   search...___________ (search)

resource guide (it   s totally free).

   [154]get your free 17-page id161 and deep learning resource
   guide pdf

   get your free 17 page id161, opencv, and deep learning
   resource guide pdf. inside you'll find my hand-picked tutorials, books,
   courses, and libraries to help you master cv and dl.

                           [155]download for free!

deep learning for id161 with python book     out now!

   [156]deep learning with id161 and python kickstarter

   you're interested in deep learning and id161, but you don't
   know how to get started. let me help. [157]my new book will teach you
   all you need to know about deep learning.

   click here to master deep learning

you can detect faces in images & video.

   [158]learn how to detect faces in images and video

   are you interested in detecting faces in images & video? but tired of
   googling for tutorials that never work? then let me help! i guarantee
   that my new book will turn you into a face detection ninja by the end
   of this weekend. [159]click here to give it a shot yourself.

   click here to master face detection

pyimagesearch gurus: now enrolling!

   the pyimagesearch gurus course is now enrolling! inside the course
   you'll learn how to perform:
     * automatic license plate recognition (anpr)
     * deep learning
     * face recognition
     * and much more!

   click the button below to learn more about the course, take a tour, and
   get 10 (free) sample lessons.

   take a tour & get 10 (free) lessons

hello! i   m adrian rosebrock.

   i'm an entrepreneur and ph.d who has launched two successful image
   search engines, [160]id my pill and [161]chic engine. i'm here to share
   my tips, tricks, and hacks i've learned along the way.

learn id161 in a single weekend.

   [162]become an opencv guru

   want to learn id161 & opencv? i can teach you in a single
   weekend. i know. it sounds crazy, but it   s no joke. my new book is your
   guaranteed, quick-start guide to becoming an opencv ninja. so why not
   give it a try? [163]click here to become a id161 ninja.

   click here to become an opencv ninja

subscribe via rss

   [164]pyimagesearch rss feed

   never miss a post! subscribe to the pyimagesearch rss feed and keep up
   to date with my image search engine tutorials, tips, and tricks
     * [165]popular

     * [166]raspbian stretch: install opencv 3 + python on your raspberry
       pi september 4, 2017
     * [167]install guide: raspberry pi 3 + raspbian jessie + opencv 3
       april 18, 2016
     * [168]home surveillance and motion detection with the raspberry pi,
       python, opencv, and dropbox june 1, 2015
     * [169]install opencv and python on your raspberry pi 2 and b+
       february 23, 2015
     * [170]ubuntu 16.04: how to install opencv october 24, 2016
     * [171]real-time id164 with deep learning and opencv
       september 18, 2017
     * [172]basic motion detection and tracking with python and opencv may
       25, 2015

   find me on [173]twitter, [174]facebook, and [175]linkedin.

      2019 pyimagesearch. all rights reserved.

   [tr?id=1465896023527386&ev=pageview&noscript=1]

   [email]
   [email]

references

   1. http://feeds.feedburner.com/pyimagesearch
   2. https://www.pyimagesearch.com/comments/feed/
   3. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/feed/
   4. https://www.pyimagesearch.com/wp-json/oembed/1.0/embed?url=https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/
   5. https://www.pyimagesearch.com/wp-json/oembed/1.0/embed?url=https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/&format=xml
   6. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#navigation
   7. https://www.pyimagesearch.com/
   8. https://www.pyimagesearch.com/
   9. https://www.pyimagesearch.com/
  10. https://www.pyimagesearch.com/start-here-learn-computer-vision-opencv/
  11. https://www.pyimagesearch.com/practical-python-opencv/
  12. https://www.pyimagesearch.com/pyimagesearch-gurus/
  13. https://www.pyimagesearch.com/opencv-tutorials-resources-guides/
  14. https://www.pyimagesearch.com/free-opencv-computer-vision-deep-learning-crash-course/
  15. https://www.pyimagesearch.com/about/
  16. https://www.pyimagesearch.com/contact/
  17. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#top
  18. https://www.pyimagesearch.com/author/adrian/
  19. https://www.pyimagesearch.com/category/deep-learning-2/
  20. https://www.pyimagesearch.com/category/pyimagesearch-gurus/
  21. https://www.pyimagesearch.com/category/tutorials/
  22. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/
  23. https://www.pyimagesearch.com/pyimagesearch-gurus/?src=post-convolutions
  24. https://www.pyimagesearch.com/pyimagesearch-gurus/?src=post-convolutions
  25. https://www.pyimagesearch.com/pyimagesearch-gurus/?src=post-convolutions
  26. https://www.pyimagesearch.com/pyimagesearch-gurus/?src=post-convolutions
  27. https://www.pyimagesearch.com/pyimagesearch-gurus/?src=post-convolutions
  28. https://www.pyimagesearch.com/pyimagesearch-gurus/?src=post-convolutions
  29. https://www.pyimagesearch.com/pyimagesearch-gurus/?src=post-convolutions
  30. http://scikit-image.org/
  31. https://en.wikipedia.org/wiki/kernel_(image_processing)
  32. http://setosa.io/ev/image-kernels/
  33. http://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.html
  34. https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/
  35. https://en.wikipedia.org/wiki/sobel_operator
  36. http://caskrepublic.com/
  37. https://www.pyimagesearch.com/tag/blurring/
  38. https://www.pyimagesearch.com/tag/convolutional-neural-network/
  39. https://www.pyimagesearch.com/tag/convolutions/
  40. https://www.pyimagesearch.com/tag/deep-learning/
  41. https://www.pyimagesearch.com/tag/edge-detection/
  42. https://www.pyimagesearch.com/tag/gradients/
  43. https://www.pyimagesearch.com/tag/kernels/
  44. https://www.pyimagesearch.com/tag/opencv/
  45. https://www.pyimagesearch.com/tag/sharpen/
  46. https://www.pyimagesearch.com/2016/07/18/installing-keras-for-deep-learning/
  47. https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/
  48. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-402975
  49. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-402975
  50. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403108
  51. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403108
  52. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-402990
  53. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-402990
  54. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403105
  55. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403105
  56. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403307
  57. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403307
  58. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403315
  59. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403315
  60. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-402993
  61. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-402993
  62. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403104
  63. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403104
  64. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403014
  65. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403014
  66. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403102
  67. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403102
  68. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403089
  69. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403089
  70. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403093
  71. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-403093
  72. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-432903
  73. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-432903
  74. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-432982
  75. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-432982
  76. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-405149
  77. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-405149
  78. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-405183
  79. http://scikit-image.org/docs/stable/install.html
  80. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-405183
  81. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406131
  82. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406131
  83. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406179
  84. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406179
  85. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406602
  86. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406602
  87. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406824
  88. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406824
  89. http://opensourcelab.salazarserrano.com/
  90. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406759
  91. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-406759
  92. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-407935
  93. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-407935
  94. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-407977
  95. http://lxu.me/projects/did98/
  96. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-407977
  97. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-412129
  98. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-412129
  99. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-412142
 100. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-412142
 101. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-414901
 102. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-414901
 103. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-414904
 104. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-414904
 105. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-433176
 106. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-433176
 107. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-417239
 108. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-417239
 109. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-417483
 110. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-417483
 111. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418360
 112. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418360
 113. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418551
 114. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
 115. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418551
 116. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418706
 117. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418706
 118. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418808
 119. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-418808
 120. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-421687
 121. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-421687
 122. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-421860
 123. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-421860
 124. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-422921
 125. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-422921
 126. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-422929
 127. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-422929
 128. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-434197
 129. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-434197
 130. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-439870
 131. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-439870
 132. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-440099
 133. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-440099
 134. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-439948
 135. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-439948
 136. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-440082
 137. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-440082
 138. http://none/
 139. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-442923
 140. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-442923
 141. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-442949
 142. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-442949
 143. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-443382
 144. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-443382
 145. https://twitter.com/fsfarimani
 146. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-473933
 147. http://bit.ly/2mhjcex
 148. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-473933
 149. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-485718
 150. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#comment-485718
 151. https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/
 152. https://www.pyimagesearch.com/2017/02/27/how-to-get-better-answers-to-your-computer-vision-questions/
 153. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#respond
 154. https://app.monstercampaigns.com/c/mdoijtrmex7bpm0rp2hn/
 155. https://app.monstercampaigns.com/c/mdoijtrmex7bpm0rp2hn/
 156. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 157. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 158. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-face-detection
 159. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-face-detection
 160. http://www.idmypill.com/
 161. http://www.chicengine.com/
 162. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-single-weekend
 163. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-single-weekend
 164. http://feeds.feedburner.com/pyimagesearch
 165. https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/#tab-pop
 166. https://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/
 167. https://www.pyimagesearch.com/2016/04/18/install-guide-raspberry-pi-3-raspbian-jessie-opencv-3/
 168. https://www.pyimagesearch.com/2015/06/01/home-surveillance-and-motion-detection-with-the-raspberry-pi-python-and-opencv/
 169. https://www.pyimagesearch.com/2015/02/23/install-opencv-and-python-on-your-raspberry-pi-2-and-b/
 170. https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/
 171. https://www.pyimagesearch.com/2017/09/18/real-time-object-detection-with-deep-learning-and-opencv/
 172. https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/
 173. https://twitter.com/pyimagesearch
 174. https://www.facebook.com/pyimagesearch
 175. http://www.linkedin.com/pub/adrian-rosebrock/2a/873/59b
