   #[1]github [2]recent commits to tacotron:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]125
     * [35]star [36]1,428
     * [37]fork [38]341

[39]kyubyong/[40]tacotron

   [41]code [42]issues 71 [43]pull requests 1 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   a tensorflow implementation of tacotron: a fully end-to-end
   text-to-id133 model
   [47]tts [48]tensorflow [49]speech-synthesis-model [50]speech
     * [51]123 commits
     * [52]2 branches
     * [53]0 releases
     * [54]fetching contributors
     * [55]apache-2.0

    1. [56]python 100.0%

   (button) python
   branch: master (button) new pull request
   [57]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/k
   [58]download zip

downloading...

   want to be notified of new releases in kyubyong/tacotron?
   [59]sign in [60]sign up

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [62]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [63]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [64]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [65]permalink
   type            name           latest commit message  commit time
        failed to load latest commit information.
        [66]fig                   [67]final draft       jan 27, 2018
        [68].gitignore
        [69]license
        [70]readme.md
        [71]data_load.py
        [72]eval.py
        [73]harvard_sentences.txt
        [74]history.md
        [75]hyperparams.py
        [76]modules.py
        [77]networks.py
        [78]prepro.py
        [79]synthesize.py         [80]final draft       jan 27, 2018
        [81]train.py              [82]final draft       jan 27, 2018
        [83]utils.py

readme.md

a (heavily documented) tensorflow implementation of tacotron: a fully
end-to-end text-to-id133 model

requirements

     * numpy >= 1.11.1
     * tensorflow >= 1.3
     * librosa
     * tqdm
     * matplotlib
     * scipy

data

   [84][68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b69
   70656469612f636f6d6d6f6e732f372f37322f576f726c645f456e676c6973685f42696
   26c655f436f7665722e6a7067]

   [85][68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b69
   70656469612f636f6d6d6f6e732f7468756d622f662f66362f4e69636b5f4f666665726
   d616e5f61745f554d42435f25323863726f707065642532392e6a70672f34343070782d
   4e69636b5f4f666665726d616e5f61745f554d42435f25323863726f707065642532392
   e6a7067]

   [86][68747470733a2f2f696d6167652e7368757474657273746f636b2e636f6d2f7a2f
   73746f636b2d766563746f722d6c6a2d6c6574746572732d666f75722d636f6c6f72732
   d696e2d61627374726163742d6261636b67726f756e642d6c6f676f2d64657369676e2d
   6964656e746974792d696e2d636972636c652d616c7068616265742d6c65747465722d3
   431383638373834362e6a7067]

   we train the model on three different speech datasets.
    1. [87]lj speech dataset
    2. [88]nick offerman's audiobooks
    3. [89]the world english bible

   lj speech dataset is recently widely used as a benchmark dataset in the
   tts task because it is publicly available. it has 24 hours of
   reasonable quality samples. nick's audiobooks are additionally used to
   see if the model can learn even with less data, variable speech
   samples. they are 18 hours long. [90]the world english bible is a
   public domain update of the american standard version of 1901 into
   modern english. its original audios are freely available [91]here.
   kyubyong split each chapter by verse manually and aligned the segmented
   audio clips to the text. they are 72 hours in total. you can download
   them at [92]kaggle datasets.

training

     * step 0. download [93]lj speech dataset or prepare your own data.
     * step 1. adjust hyper parameters in hyperparams.py. (if you want to
       do preprocessing, set prepro true`.
     * step 2. run python train.py. (if you set prepro true, run python
       prepro.py first)
     * step 3. run python eval.py regularly during training.

sample synthesis

   we generate speech samples based on [94]harvard sentences as the
   original paper does. it is already included in the repo.
     * run python synthesize.py and check the files in samples.

training curve

   [95][training_curve.png]

attention plot

   [96][attention.gif]

generated samples

     * [97]lj at 200k steps
     * [98]nick at 215k steps
     * [99]web at 183k steps

pretrained files

     * keep in mind 200k steps may not be enough for the best performance.
     * [100]lj 200k
     * [101]web 200k

notes

     * it's important to monitor the attention plots during training. if
       the attention plots look good (alignment looks linear), and then
       they look bad (the plots will look similar to what they looked like
       in the begining of training), then training has gone awry and most
       likely will need to be restarted from a checkpoint where the
       attention looked good, because we've learned that it's unlikely
       that the loss will ever recover. this deterioration of attention
       will correspond with a spike in the loss.
     * in the original paper, the authors said, "an important trick we
       discovered was predicting multiple, non-overlapping output frames
       at each decoder step" where the number of of multiple frame is the
       reduction factor, r. we originally interpretted this as predicting
       non-sequential frames during each decoding step t. thus were using
       the following scheme (with r=5) during decoding.
t    frame numbers
-----------------------
0    [ 0  1  2  3  4]
1    [ 5  6  7  8  9]
2    [10 11 12 13 14]
...

       after much experimentation, we were unable to have our model
       learning anything useful. we then switched to predicting r
       sequential frames during each decoding step.
t    frame numbers
-----------------------
0    [ 0  1  2  3  4]
1    [ 5  6  7  8  9]
2    [10 11 12 13 14]
...

       with this setup we noticed improvements in the attention and have
       since kept it.
     * perhaps the most important hyperparemeter is the learning rate.
       with an intitial learning rate of 0.002 we were never able to learn
       a clean attention, the loss would frequently explode. with an
       initial learning rate of 0.001 we were able to learn a clean
       attention and train for much longer get decernable words during
       synthesis.
     * check other tts models such as [102]dctts or [103]deep voice 3.

differences from the original paper

     * we use noam style warmup and decay.
     * we implement gradient clipping.
     * our training batches are bucketed.
     * after the last convolutional layer of the post-processing net, we
       apply an affine transformation to bring the dimensionality up to
       128 from 80, because the required dimensionality of highway net is
       128. in the original id199 paper, the authors mention
       that the dimensionality of the input can also be increased with
       zero-padding, but they used the affine transformation in all their
       experiments. we do not know what the tacotron authors chose.

papers that referenced this repo

     * [104]efficiently trainable text-to-speech system based on deep
       convolutional networks with guided attention
     * [105]storytime - end to end neural networks for audiobooks

   jan. 2018, kyubyong park & [106]tommy mulc

     *    2019 github, inc.
     * [107]terms
     * [108]privacy
     * [109]security
     * [110]status
     * [111]help

     * [112]contact github
     * [113]pricing
     * [114]api
     * [115]training
     * [116]blog
     * [117]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [118]reload to refresh your
   session. you signed out in another tab or window. [119]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/kyubyong/tacotron/commits/master.atom
   3. https://github.com/kyubyong/tacotron#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/kyubyong/tacotron
  32. https://github.com/join
  33. https://github.com/login?return_to=/kyubyong/tacotron
  34. https://github.com/kyubyong/tacotron/watchers
  35. https://github.com/login?return_to=/kyubyong/tacotron
  36. https://github.com/kyubyong/tacotron/stargazers
  37. https://github.com/login?return_to=/kyubyong/tacotron
  38. https://github.com/kyubyong/tacotron/network/members
  39. https://github.com/kyubyong
  40. https://github.com/kyubyong/tacotron
  41. https://github.com/kyubyong/tacotron
  42. https://github.com/kyubyong/tacotron/issues
  43. https://github.com/kyubyong/tacotron/pulls
  44. https://github.com/kyubyong/tacotron/projects
  45. https://github.com/kyubyong/tacotron/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/tts
  48. https://github.com/topics/tensorflow
  49. https://github.com/topics/speech-synthesis-model
  50. https://github.com/topics/speech
  51. https://github.com/kyubyong/tacotron/commits/master
  52. https://github.com/kyubyong/tacotron/branches
  53. https://github.com/kyubyong/tacotron/releases
  54. https://github.com/kyubyong/tacotron/graphs/contributors
  55. https://github.com/kyubyong/tacotron/blob/master/license
  56. https://github.com/kyubyong/tacotron/search?l=python
  57. https://github.com/kyubyong/tacotron/find/master
  58. https://github.com/kyubyong/tacotron/archive/master.zip
  59. https://github.com/login?return_to=https://github.com/kyubyong/tacotron
  60. https://github.com/join?return_to=/kyubyong/tacotron
  61. https://desktop.github.com/
  62. https://desktop.github.com/
  63. https://developer.apple.com/xcode/
  64. https://visualstudio.github.com/
  65. https://github.com/kyubyong/tacotron/tree/379bb7f54c3359ffe97d1f09a773bc6da49eba6f
  66. https://github.com/kyubyong/tacotron/tree/master/fig
  67. https://github.com/kyubyong/tacotron/commit/24740a881a979839970ece46fa76e8a033c6151e
  68. https://github.com/kyubyong/tacotron/blob/master/.gitignore
  69. https://github.com/kyubyong/tacotron/blob/master/license
  70. https://github.com/kyubyong/tacotron/blob/master/readme.md
  71. https://github.com/kyubyong/tacotron/blob/master/data_load.py
  72. https://github.com/kyubyong/tacotron/blob/master/eval.py
  73. https://github.com/kyubyong/tacotron/blob/master/harvard_sentences.txt
  74. https://github.com/kyubyong/tacotron/blob/master/history.md
  75. https://github.com/kyubyong/tacotron/blob/master/hyperparams.py
  76. https://github.com/kyubyong/tacotron/blob/master/modules.py
  77. https://github.com/kyubyong/tacotron/blob/master/networks.py
  78. https://github.com/kyubyong/tacotron/blob/master/prepro.py
  79. https://github.com/kyubyong/tacotron/blob/master/synthesize.py
  80. https://github.com/kyubyong/tacotron/commit/24740a881a979839970ece46fa76e8a033c6151e
  81. https://github.com/kyubyong/tacotron/blob/master/train.py
  82. https://github.com/kyubyong/tacotron/commit/24740a881a979839970ece46fa76e8a033c6151e
  83. https://github.com/kyubyong/tacotron/blob/master/utils.py
  84. https://camo.githubusercontent.com/d2a5eb92fa4427f49bdb226fc40ef312611b36dc/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f372f37322f576f726c645f456e676c6973685f4269626c655f436f7665722e6a7067
  85. https://camo.githubusercontent.com/f241c040285ccd03e4cc13566525ab4bc19fc714/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f662f66362f4e69636b5f4f666665726d616e5f61745f554d42435f25323863726f707065642532392e6a70672f34343070782d4e69636b5f4f666665726d616e5f61745f554d42435f25323863726f707065642532392e6a7067
  86. https://camo.githubusercontent.com/6b4af3a62cab5a6eb4ded9e731394ffac7f9cf92/68747470733a2f2f696d6167652e7368757474657273746f636b2e636f6d2f7a2f73746f636b2d766563746f722d6c6a2d6c6574746572732d666f75722d636f6c6f72732d696e2d61627374726163742d6261636b67726f756e642d6c6f676f2d64657369676e2d6964656e746974792d696e2d636972636c652d616c7068616265742d6c65747465722d3431383638373834362e6a7067
  87. https://keithito.com/lj-speech-dataset/
  88. https://www.audible.com.au/search?searchnarrator=nick+offerman
  89. https://www.kaggle.com/bryanpark/the-world-english-bible-speech-dataset
  90. https://en.wikipedia.org/wiki/world_english_bible
  91. http://www.audiotreasure.com/webindex.htm
  92. https://www.kaggle.com/bryanpark/the-world-english-bible-speech-dataset
  93. https://keithito.com/lj-speech-dataset/
  94. http://www.cs.columbia.edu/~hgs/audio/harvard.html
  95. https://github.com/kyubyong/tacotron/blob/master/fig/training_curve.png
  96. https://github.com/kyubyong/tacotron/blob/master/fig/attention.gif
  97. https://soundcloud.com/kyubyong-park/sets/tacotron_lj_200k
  98. https://soundcloud.com/kyubyong-park/sets/tacotron_nick_215k
  99. https://soundcloud.com/kyubyong-park/sets/tacotron_web_183k
 100. https://www.dropbox.com/s/8kxa3xh2vfna3s9/lj_logdir.zip?dl=0
 101. https://www.dropbox.com/s/g7m6xhd350ozkz7/web_logdir.zip?dl=0
 102. https://github.com/kyubyong/dc_tts
 103. https://github.com/kyubyong/deepvoice3
 104. https://arxiv.org/abs/1710.08969
 105. http://web.stanford.edu/class/cs224s/reports/pierce_freeman.pdf
 106. https://github.com/kyubyong/tacotron/blob/master/tmulc18@gmail.com
 107. https://github.com/site/terms
 108. https://github.com/site/privacy
 109. https://github.com/security
 110. https://githubstatus.com/
 111. https://help.github.com/
 112. https://github.com/contact
 113. https://github.com/pricing
 114. https://developer.github.com/
 115. https://training.github.com/
 116. https://github.blog/
 117. https://github.com/about
 118. https://github.com/kyubyong/tacotron
 119. https://github.com/kyubyong/tacotron

   hidden links:
 121. https://github.com/
 122. https://github.com/kyubyong/tacotron
 123. https://github.com/kyubyong/tacotron
 124. https://github.com/kyubyong/tacotron
 125. https://help.github.com/articles/which-remote-url-should-i-use
 126. https://github.com/kyubyong/tacotron#a-heavily-documented-tensorflow-implementation-of-tacotron-a-fully-end-to-end-text-to-speech-synthesis-model
 127. https://github.com/kyubyong/tacotron#requirements
 128. https://github.com/kyubyong/tacotron#data
 129. https://github.com/kyubyong/tacotron#training
 130. https://github.com/kyubyong/tacotron#sample-synthesis
 131. https://github.com/kyubyong/tacotron#training-curve
 132. https://github.com/kyubyong/tacotron#attention-plot
 133. https://github.com/kyubyong/tacotron#generated-samples
 134. https://github.com/kyubyong/tacotron#pretrained-files
 135. https://github.com/kyubyong/tacotron#notes
 136. https://github.com/kyubyong/tacotron#differences-from-the-original-paper
 137. https://github.com/kyubyong/tacotron#papers-that-referenced-this-repo
 138. https://github.com/
