   #[1]github [2]recent commits to transformer:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]90
     * [35]star [36]2,098
     * [37]fork [38]680

[39]kyubyong/[40]transformer

   [41]code [42]issues 66 [43]pull requests 6 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   a tensorflow implementation of the transformer: attention is all you
   need
   [47]attention-mechanism [48]translation [49]attention-is-all-you-need
   [50]implementation [51]transformer
     * [52]32 commits
     * [53]1 branch
     * [54]0 releases
     * [55]7 contributors
     * [56]apache-2.0

    1. [57]python 93.3%
    2. [58]perl 6.5%
    3. [59]shell 0.2%

   (button) python perl shell
   branch: master (button) new pull request
   [60]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/k
   [61]download zip

downloading...

   want to be notified of new releases in kyubyong/transformer?
   [62]sign in [63]sign up

launching github desktop...

   if nothing happens, [64]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [65]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [66]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [67]download the github extension for visual studio
   and try again.

   (button) go back
   kyubyong park kyubyong park
   kyubyong park and kyubyong park [68]changed ckpt address
   latest commit [69]2234b42 mar 3, 2019
   [70]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [71]eval/1
   [72]fig [73]updated to tf1.12 feb 18, 2019
   [74]test/1
   [75]tf1.2_legacy [76]updated to tf1.12 feb 18, 2019
   [77].gitignore
   [78]license [79]initial commit jun 17, 2017
   [80]readme.md
   [81]data_load.py
   [82]download.sh
   [83]hparams.py
   [84]model.py
   [85]modules.py [86]added use_bias=false to linear projections mar 3,
   2019
   [87]multi-id7.perl
   [88]prepro.py
   [89]requirements.txt
   [90]test.py
   [91]train.py [92]updated to tf1.12 feb 18, 2019
   [93]utils.py

readme.md

[updated] a tensorflow implementation of [94]attention is all you need

   when i opened this repository in 2017, there was no official code yet.
   i tried to implement the paper as i understood, but to no surprise it
   had several bugs. i realized them mostly thanks to people who issued
   here, so i'm very grateful to all of them. though there is the
   [95]official implementation as well as several other unofficial github
   repos, i decided to update my own one. this update focuses on:
     * readable / understandable code writing
     * modularization (but not too much)
     * revising known bugs. (masking, positional encoding, ...)
     * updating to tf1.12. (tf.data, ...)
     * adding some missing components (bpe, shared weight matrix, ...)
     * including useful comments in the code.

   i still stick to iwslt 2016 de-en. i guess if you'd like to test on a
   big data such as wmt, you would rely on the official implementation.
   after all, it's pleasant to check quickly if your model works. the
   initial code for tf1.2 is moved to the [96]tf1.2_lecacy folder for the
   record.

requirements

     * python==3.x (let's move on to python 3 if you still use python 2)
     * tensorflow==1.12.0
     * numpy>=1.15.4
     * sentencepiece==0.1.8
     * tqdm>=4.28.1

training

     * step 1. run the command below to download [97]iwslt 2016
       german   english parallel corpus.

bash download.sh

   it should be extracted to iwslt2016/de-en folder automatically.
     * step 2. run the command below to create preprocessed
       train/eval/test data.

python prepro.py

   if you want to change the vocabulary size (default:32000), do this.
python prepro.py --vocab_size 8000

   it should create two folders iwslt2016/prepro and iwslt2016/segmented.
     * step 3. run the following command.

python train.py

   check hparams.py to see which parameters are possible. for example,
python train.py --logdir mylog --batch_size 256 --dropout_rate 0.5

     * step 3. or download the pretrained models.

wget -qo- --show-progress https://dl.dropbox.com/s/efv2gmq5hu3np43/log.tar.gz |
tar xz

training loss curve

   [98][loss.png]

learning rate

   [99][lr.png]

id7 score on devset

   [100][id7.png]

id136 (=test)

     * run

python test.py --ckpt log/1/iwslt2016_e17l2.78-26078 (or yourckptfile or yourckp
tfiledirectory)

results

     * typically, machine translation is evaluated with id7 score.
     * all evaluation results are available in [101]eval/1 and
       [102]test/1.

   tst2013 (dev) tst2014 (test)
   26.69         22.46

notes

     * beam decoding will be added soon.
     * i'm going to update the code when tf2.0 comes out if possible.

     *    2019 github, inc.
     * [103]terms
     * [104]privacy
     * [105]security
     * [106]status
     * [107]help

     * [108]contact github
     * [109]pricing
     * [110]api
     * [111]training
     * [112]blog
     * [113]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [114]reload to refresh your
   session. you signed out in another tab or window. [115]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/kyubyong/transformer/commits/master.atom
   3. https://github.com/kyubyong/transformer#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/kyubyong/transformer
  32. https://github.com/join
  33. https://github.com/login?return_to=/kyubyong/transformer
  34. https://github.com/kyubyong/transformer/watchers
  35. https://github.com/login?return_to=/kyubyong/transformer
  36. https://github.com/kyubyong/transformer/stargazers
  37. https://github.com/login?return_to=/kyubyong/transformer
  38. https://github.com/kyubyong/transformer/network/members
  39. https://github.com/kyubyong
  40. https://github.com/kyubyong/transformer
  41. https://github.com/kyubyong/transformer
  42. https://github.com/kyubyong/transformer/issues
  43. https://github.com/kyubyong/transformer/pulls
  44. https://github.com/kyubyong/transformer/projects
  45. https://github.com/kyubyong/transformer/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/attention-mechanism
  48. https://github.com/topics/translation
  49. https://github.com/topics/attention-is-all-you-need
  50. https://github.com/topics/implementation
  51. https://github.com/topics/transformer
  52. https://github.com/kyubyong/transformer/commits/master
  53. https://github.com/kyubyong/transformer/branches
  54. https://github.com/kyubyong/transformer/releases
  55. https://github.com/kyubyong/transformer/graphs/contributors
  56. https://github.com/kyubyong/transformer/blob/master/license
  57. https://github.com/kyubyong/transformer/search?l=python
  58. https://github.com/kyubyong/transformer/search?l=perl
  59. https://github.com/kyubyong/transformer/search?l=shell
  60. https://github.com/kyubyong/transformer/find/master
  61. https://github.com/kyubyong/transformer/archive/master.zip
  62. https://github.com/login?return_to=https://github.com/kyubyong/transformer
  63. https://github.com/join?return_to=/kyubyong/transformer
  64. https://desktop.github.com/
  65. https://desktop.github.com/
  66. https://developer.apple.com/xcode/
  67. https://visualstudio.github.com/
  68. https://github.com/kyubyong/transformer/commit/2234b4268355ccc073d8f0535fdd395289001151
  69. https://github.com/kyubyong/transformer/commit/2234b4268355ccc073d8f0535fdd395289001151
  70. https://github.com/kyubyong/transformer/tree/2234b4268355ccc073d8f0535fdd395289001151
  71. https://github.com/kyubyong/transformer/tree/master/eval/1
  72. https://github.com/kyubyong/transformer/tree/master/fig
  73. https://github.com/kyubyong/transformer/commit/85e2dd95c99993c1e6e4193a0493fef5832e4bc1
  74. https://github.com/kyubyong/transformer/tree/master/test/1
  75. https://github.com/kyubyong/transformer/tree/master/tf1.2_legacy
  76. https://github.com/kyubyong/transformer/commit/85e2dd95c99993c1e6e4193a0493fef5832e4bc1
  77. https://github.com/kyubyong/transformer/blob/master/.gitignore
  78. https://github.com/kyubyong/transformer/blob/master/license
  79. https://github.com/kyubyong/transformer/commit/dba8a112edb0d0328943d4fa344573baa14f1ed1
  80. https://github.com/kyubyong/transformer/blob/master/readme.md
  81. https://github.com/kyubyong/transformer/blob/master/data_load.py
  82. https://github.com/kyubyong/transformer/blob/master/download.sh
  83. https://github.com/kyubyong/transformer/blob/master/hparams.py
  84. https://github.com/kyubyong/transformer/blob/master/model.py
  85. https://github.com/kyubyong/transformer/blob/master/modules.py
  86. https://github.com/kyubyong/transformer/commit/6715edcb79022b1a92ba7b9edd1b3c6b53cebf28
  87. https://github.com/kyubyong/transformer/blob/master/multi-id7.perl
  88. https://github.com/kyubyong/transformer/blob/master/prepro.py
  89. https://github.com/kyubyong/transformer/blob/master/requirements.txt
  90. https://github.com/kyubyong/transformer/blob/master/test.py
  91. https://github.com/kyubyong/transformer/blob/master/train.py
  92. https://github.com/kyubyong/transformer/commit/85e2dd95c99993c1e6e4193a0493fef5832e4bc1
  93. https://github.com/kyubyong/transformer/blob/master/utils.py
  94. https://arxiv.org/abs/1706.03762
  95. https://github.com/tensorflow/tensor2tensor
  96. https://github.com/kyubyong/transformer/blob/master/tf1.2_legacy
  97. https://wit3.fbk.eu/download.php?release=2016-01&type=texts&slang=de&tlang=en
  98. https://github.com/kyubyong/transformer/blob/master/fig/loss.png
  99. https://github.com/kyubyong/transformer/blob/master/fig/lr.png
 100. https://github.com/kyubyong/transformer/blob/master/fig/id7.png
 101. https://github.com/kyubyong/transformer/blob/master/eval/1
 102. https://github.com/kyubyong/transformer/blob/master/test/1
 103. https://github.com/site/terms
 104. https://github.com/site/privacy
 105. https://github.com/security
 106. https://githubstatus.com/
 107. https://help.github.com/
 108. https://github.com/contact
 109. https://github.com/pricing
 110. https://developer.github.com/
 111. https://training.github.com/
 112. https://github.blog/
 113. https://github.com/about
 114. https://github.com/kyubyong/transformer
 115. https://github.com/kyubyong/transformer

   hidden links:
 117. https://github.com/
 118. https://github.com/kyubyong/transformer
 119. https://github.com/kyubyong/transformer
 120. https://github.com/kyubyong/transformer
 121. https://help.github.com/articles/which-remote-url-should-i-use
 122. https://github.com/kyubyong/transformer#updated-a-tensorflow-implementation-of-attention-is-all-you-need
 123. https://github.com/kyubyong/transformer#requirements
 124. https://github.com/kyubyong/transformer#training
 125. https://github.com/kyubyong/transformer#training-loss-curve
 126. https://github.com/kyubyong/transformer#learning-rate
 127. https://github.com/kyubyong/transformer#id7-score-on-devset
 128. https://github.com/kyubyong/transformer#id136-test
 129. https://github.com/kyubyong/transformer#results
 130. https://github.com/kyubyong/transformer#notes
 131. https://github.com/
