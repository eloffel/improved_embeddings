   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]freecodecamp.org
     * [9]dev
     * [10]learn to code for free
     __________________________________________________________________

deep learning for developers: tools you can use to code neural networks on
day 1

   [11]go to the profile of emil wallner
   [12]emil wallner (button) blockedunblock (button) followfollowing
   oct 3, 2017

   the current wave of deep learning took off five years ago. exponential
   progress in computing power followed by a few success stories created
   the hype.

   deep learning is the technology that drives cars, beats humans at atari
   games, and diagnoses cancer.
   [1*q_9gcuodubwgtsfjdikdua.jpeg]
   photo by [13]arif wahid on [14]unsplash

   when i started learning deep learning i spent two weeks researching. i
   selected tools, compared cloud services, and researched online courses.
   in retrospect, i wish i could have built neural networks from day one.
   that   s what this article is set out to do.

   you don   t need any prerequisites. yet a basic understanding of
   [15]python, the [16]command line, and [17]jupyter notebook will help.

   deep learning is a branch of machine learning. it   s proven to be an
   effective method to find patterns in [18]raw data, such as an image or
   sound.

   say you want to make a classification of cat and dog images. without
   specific programming, it first finds the edges in the pictures. then it
   builds patterns from them. next, it detects noses, tails, and paws.
   this enables the neural network to make the final classification of
   cats and dogs.

   but, there are better machine learning algorithms for structured data.
   for example, if have you an ordered excel sheet with consumer data and
   you want to predict their next order. then you can take a
   [19]traditional approach and use [20]simpler machine learning
   algorithms.

core logic

   imagine a machine with randomly adjusted cogwheels =    . the cogs are
   stacked in layers and they all impact each other. initially, the
   machine does not work. the cogs are randomly adjusted and they all need
   to be tuned to give the correct output.

   an engineer will then examine all the cogs and mark which cogs are
   causing the error. he starts with the last layer of cogs, the result of
   all errors combined. once he knows the errors the last layer is
   causing, he works backward. this way he can calculate how much each cog
   is contributing to the error. we call this process back propagation.

   the engineer then tunes each cog based on the error each made and runs
   the machine again. he keeps running the machine, calculates the errors
   and tunes each cog. he stays in this routine until the machine gives
   the correct output.
   [1*qdqenmogtawmnngsskxmyq.png]

   neural networks operate in the same way. it knows the input and output
   and adjusts cogs to find the correlation between the two. given an
   input, it tunes the cogs to predict the output. it then compares the
   predicted values with the real values.

   to minimize the errors, the difference is between the predicted values
   and the real values. the neural network tunes the cogwheels. it tunes
   the cogs until the difference between the predicted and the real value
   is as low as possible.

   minimizing the error in an optimal way is id119. the errors
   are calculated with the error / cost function.

a shallow id158

   many think of id158s as digital replicas of our
   [21]neocortex. it   s not true.

   we don   t know how enough about our brains to make that claim. it was a
   source of inspiration for frank rosenblatt, the inventors of neural
   networks.
   [1*jmvyump68xab3zjunhqxwq.png]

   play with the [22]neural network simulator for one or two hours to get
   an intuition for it.

   we   ll start by implementing a simple neural network to get to know the
   syntax in [23]tflearn. a classic 101 problem to start with is the
   [24]or operator. although neural networks are better suited for other
   types of data, it   s a good problem to understand how it works.
   [1*1zh2lcq5qqfv3gnpm8q7rg.png]

   all deep learning programs follow the same core logic:
     * it starts with including libraries, then importing and cleaning the
       data. all the input are translated into [25]digits, regardless if
       it   s images, audio or a sensory data.
       these long lists of numbers are the input for our neural networks
     * now design your neural network
       choose the type and amount of layer to have in your network
     * then it enters the learning process.
       it knows the input and output values and searches for the
       correlation between them
     * the final step gives you a prediction from your trained neural
       network.

   here is the code for our neural network:

   iframe: [26]/media/3e96e9afeb8eb46deca91b482135f2b4?postid=34c4435ae6b

   output
training step: 2000  | total loss: 0.00072 | time: 0.002s
| sgd | epoch: 2000 | loss: 0.00072 -- iter: 4/4
testing or operator
0 or 0: [[ 0.04013482]]
0 or 1: [[ 0.97487926]]
1 or 0: [[ 0.97542077]]
1 or 1: [[ 0.99997282]]

   line 1 the lines starting with # are comments
   they are used to explain the code

   line 2 include the tflearn library
   this allows us to use deep learning functions from google   s
   [27]tensorflow

   line 5   6 data from the table are stored in lists
   the dot at the end of each number maps each integer into floats
   it stores numbers with decimal values which make the calculations
   precise

   line 9 initialize the neural net and specify the dimension or shape of
   our input data
   every or operator comes in a pair and thus has the shape of 2
   none is a default value and represents the batch size

   line 10: our output layer.
   the activation function maps the output in the layer between an
   interval
   in our case, we use a sigmoid function that maps the value between 0
   and 1

   [28]read more about lines 9 and 10.

   line 11 apply the [29]regression
   the [30]optimizer chooses which algorithm to minimize the cost function
   the learning rate decides how fast to modify the neural network, and
   the loss variable decides how to calculate the errors

   line 14 selects which neural network to use
   it   s also used to specify where to store the training logs

   line 15 trains your neural network and model
   select your input data (or) and the true labels (y_truth)
   epochs determines how many times to run all your data through your
   neural network
   if you set snapshot=true it would validate the model after each epoch

   line 18   22 makes a prediction with your trained model
   in our case, it returns the id203 of returning true/1

   [31]read more about lines 14   22.

   output labels the first result means that the combination [0.] & [0.]
   has a has a 4% id203 of being true, and so on. training step
   indicates how many batches you have trained.

   since the data can fit into one batch it   s the same as [32]epoch. if
   the data is too big for the memory you need to break down the training
   in chunks. the loss measures the sum of errors from each epoch.

   sgd stands for stochastic id119 and method to minimize the
   cost function.

   iter displays the current data index and the total amount of input
   items.

   you can find the above logic and syntax in almost every tflearn neural
   network. the best way to get a feel for the code is to modify it and
   create a couple of errors.
   [1*ia1vqeudtujxbb0nf8gq9q.png]
   the loss curve shows the amount of errors for each training step

   with [33]tensorboard you can visualize each experiment and build an
   intuition for how each parameter changes the training.

   here is a suggestion of some examples that you can run. i   d recommend
   playing with it for a couple of hours to get used to the environment
   and the tflearn parameters.

   experiments
     * increase the training and epochs
     * try adding and changing a parameter to each function from the
       documentation
       for example g = tflearn.fullyconnected(g, 1, activation=   sigmoid   )
       becomes tflearn.fullyconnected(g, 1, activation=   sigmoid   ,
       bias=false)
     * add integers in the input data
     * change the shape in the input layer
     * change the activation function in the output layer
     * use a different method for id119
     * change how the neural network calculates the cost
     * change the x and y to and and not logic operators
     * change the output data to xor logic operators
       for example swap the last y_truth from [1.] to [0.]
       you have to add a layer in your network for it to work
     * make it learn faster
     * find a way to make each learning step take more than 0.1 second

getting started

   python combined with tensorflow is the most common stack for deep
   learning.

   tflearn is a high-level framework that runs on-top of tensorflow.

   another common framework is [34]keras. it   s a more robust library, but
   i find the tflearn syntax cleaner and easier to understand.

   they are both high-level frameworks that run on-top of tensorflow.

   you can run simple neural networks on your computer   s cpu. but most
   experiments will take several hours or even weeks to run. that   s why
   most use modern gpus for deep learning, often through a cloud service.

   the easiest solution for cloud gpus is [35]floydhub. if you have basic
   command line skills, it shouldn   t take more than 5 minutes to set up
   floydhub.

   [36]use the floydhub docs to install the floyd-cli command line tool.
   floydhub also provides support on their intercom chat if you get stuck
   at any point.

   iframe: [37]/media/486fde65bfda9f1488f9863f9201e926?postid=34c4435ae6b

   let   s run your first neural network in floydhub using tflearn, jupyter
   notebook, and tensorboard.

   after installing and logging in to floydhub, download the files you
   need for this guide.

   go to your terminal and type the following command:
git clone [38]https://github.com/emilwallner/deep-learning-101.git

   open the folder and initiate floydhub:
cd deep-learning-101
floyd init 101

   the floydhub web dashboard will open in your browser, and you will be
   prompted to create a new floydhub project called 101. once that's done,
   go back to your terminal and run the same initcommand.
floyd init 101

   now you are ready to run your neural network job on floydhub.

   with the floyd runcommand, you can pass in various settings. in our
   case, we will want to:
     * mount a public dataset on floydhub, which i   ve already uploaded.
       at the data directory type--data
       emilwallner/datasets/cifar-10/1:data
       you can explore this dataset (and many other public datasets) by
       viewing it on [39]floydhub
     * use a cloud gpu with --gpu
     * enable tensorboard with --tensorboard
     * run the job in jupyter notebook mode with --mode jupyter

   okay, let   s run our job:
floyd run --data emilwallner/datasets/cifar-10/1:data --gpu --tensorboard --mode
 jupyter

   once it initiates jupyter in your browser, click on the file named
   start-here.ipnyb.

   start-here.ipnyb is a simple neural network to get to know the syntax
   in tflearn. it learns the logic of the or operator, explained in full
   later on.

   in the menu row, click on kernel > restart & run all. if you see the
   message, it   s working, then you are good to go.

   go to your floydhub project to find the link for tensorboard.

a deep neural network

   deep learning are neural networks with more than one hidden layer.
   there are already plenty of detailed tutorials on how id98s
   (convolutional neural networks) work. you can find them [40]here,
   [41]here, and [42]here.

   so, we   ll focus on the high-level notions that you can apply to most
   neural networks.
   [1*yhzyq-zze2a5yxec8gljrw.png]
   note: the visual is not a deep neural network. it needs more than one
   hidden layer.

   you want to train neural networks to make predictions on data it was
   not trained on. it needs an ability to generalize. it   s a balance
   between learning and forgetting.

   you want it to learn to separate signal from noise. but also forget the
   signals that are only found in the training data.

   if the neural network is not learning enough it   s underfitting. the
   opposite is overfitting. that   s when it has learned too much from the
   training data.

   id173 is the process to reduce overfitting by forgetting
   training specific signals.

   to get an intuition for these concepts, we   ll be working with the
   [43]cifar-10 dataset. it   s a dataset with 60k images in ten different
   categories, such as cars, trucks, and birds. the goal is to predict
   which of the ten categories a new image belongs to.
   [1*wo81biq10n4jyyhpywckng.png]

   to get an intuition for these concepts, we   ll be working with the
   [44]cifar-10 dataset. it   s a dataset with 60k images in ten different
   categories, such as cars, trucks, and birds. the goal is to predict
   which of the ten categories a new image belongs to.
   [1*yo1kzpvnlmix-fsydf19tq.png]
   sample images from cifar

   normally, we have to scrape the data, clean it and apply filters to the
   images. but to narrow it down, we   ll only focus on the neural networks.
   you can run the all the examples from the jupyter notebook that [45]in
   the installation section.

   the input layer takes an image which has been mapped into digits. the
   output layer classifies the images into ten categories. the hidden
   layers are a mix of convolutional, pooling, and connected layers.

choosing the amount of layers

   let   s make a comparison with a neural network with one against three
   sets of layers. each set includes a convolutional, pooling and
   connected layer.

   the first two experiments are called [46]experiment-0-few-layers.ipynb
   and [47]experiment-0-three-layer-sets.ipynb.

   iframe: [48]/media/681b5e417697f0ca9981775afaf04b77?postid=34c4435ae6b

   you can run these notebooks by clicking kernel > restart & run all in
   the menu bar. then take a peek at the training log in tensorboard.
   you   ll see that the one with many layers is ~15% more accurate. the
   layer with few layers is underfitting         it   s not learning enough.

   you can run the same example from the folder you downloaded earlier, as
   well as the all the upcoming experiments.
   [1*sihgmxx9e74wud_fdqh5ha.png]
   experiment_0.ipynb in the repo

   take a look at the accuracy and accuracy/validation. it   s best practice
   in deep learning to split the dataset in two. one for the training the
   neural network and another for validating it. this way you can tell how
   well the neural network makes predictions on new data, or its ability
   to generalize.

   this is how you can tell how well the neural network makes predictions
   on new data, or its ability to generalize.

   as we can see, the accuracy of the training data is higher than the
   accuracy on the validation dataset. the neural network has included
   background noise and details that hinder it from predicting new images.

   to deal with the overfitting you can punish complex functions and
   introduce noise into the neural network. common id173
   techniques to prevent this are dropout layers and punishing complex
   functions.

dropout layers

   we can compare the dropout id173 to the value of a democracy.
   instead of having a few powerful neurons that decide the final outcome,
   they distribute the power.

   the neural network is forced to learn several independent
   representations. when it makes the final prediction it then has several
   distinct patterns to learn from.

   this is an example of a neural network with a dropout layer.

   iframe: [49]/media/6a3a2926026a862b25d0f7f2be89b6f1?postid=34c4435ae6b

   in this comparison, the neural networks are the same except that one
   has a dropout layer and the other one doesn   t.
   [1*-0kzifiyllor2rtbvgk8cq.png]

   in each layer of the neural network, the neurons become dependent on
   each other. some neurons gain more influence than others. the dropout
   layer randomly mutes different neurons. this way each neuron has to
   build a distinct contribution to the final output.

   the second popular method to prevent overfitting is applying an l1 or
   l2 regularizer function on each layer.

l1 and l2 id173

   say you want to describe a horse. if the description is too detailed,
   you exclude too many horses. but, if it   s too general you might include
   other animals. the l1 and l2 id173 helps the network to make
   this distinction.

   iframe: [50]/media/6a3bec74cf140ca20ef48e0025275eea?postid=34c4435ae6b

   if we make a similar comparison as the previous experiment we get a
   similar outcome.
   [1*p3momr5qoudkiq5ppscuta.png]

   the neural network with id173 functions outperforms the one
   without them.

   the id173 function l2 punishes functions that are too complex.
   it measures how much each function contributes to the final output. it
   then punishes the ones with large coefficients.

batch size

   another core hyper parameter is batch size, the amount of data to use
   for each training step. below is a comparison between a large and a
   small batch size.

   iframe: [51]/media/5f4a2972ee12953759d2e44f6c37d60f?postid=34c4435ae6b

   [1*443vq1z0f84weqbq1gvzka.png]

   as we see in the result, a large batch size requires fewer cycles but
   has more accurate training steps. in comparison, a smaller batch size
   is more random but take more steps to compensate for it.

   a large batch size requires fewer learning steps. but, you need more
   memory and time to compute each step.

learning rate

   the final experiment is a comparison between a network with small,
   medium, and large learning rates.

   iframe: [52]/media/66ceb04de985f311c4e69f93a6374616?postid=34c4435ae6b

   [1*wbgnvyxwp06j7-k8piygrq.png]

   the learning rate is often considered one of the most important
   parameters due to its impact. it regulates how to adjust the change in
   prediction for each learning step. if the learning rate is too high or
   too low it might not converge, like the large learning rate above.

   there is no fixed way of designing neural networks. a lot of it has to
   do with experimentation. look at what others have done by adding
   layers, and tuning hyper parameters.

   if you have access to a lot of computing power, you can create programs
   to design and tune the hyper parameters.

   when you   re done running your job, you should spin down your cloud gpu
   instance by clicking cancel in the floydhub web dashboard for your job.

next steps

   in tflearn   s [53]official example repo, you can get a feel for some of
   the best performing id98s. try copying some of the methods and improve
   the validation for the cifar-10 dataset. the best result so far is
   96.53% (graham, 2014).

   it   s also worth learning the python syntax and get familiar with the
   command line. this reduces unnecessary cognitive load so you can focus
   on deep learning notions. start with codecademy   s [54]course on python
   and then do the [55]command line one. it should not take more than
   three days if you do it full-time.

   thanks to [56]ignacio tonoli de maussion, [57]per harald borgen,
   [58]jean-luc wingert, [59]sai soundararaj, and [60]charlie harrington
   for reading drafts of this. and gratitude towards the [61]tflearn
   community for the documentation and sample code.

about emil wallner

   this the first part in a multi-part blog series as i learn deep
   learning. i   ve spent a decade exploring human learning. i working for
   oxford   s business school, invested in education startups, and built an
   education technology business. last year, i enrolled at [62]ecole 42 to
   apply my knowledge of human learning to machine learning.

   you can follow along my learning journey on [63]twitter. if you have
   any questions/suggestions please leave a comment below or ping me on
   [64]medium.

   this was first published as a community post on [65]floydhub   s blog.

     * [66]machine learning
     * [67]artificial intelligence
     * [68]data science
     * [69]programming
     * [70]tech

   (button)
   (button)
   (button) 3.3k claps
   (button) (button) (button) 7 (button) (button)

     (button) blockedunblock (button) followfollowing
   [71]go to the profile of emil wallner

[72]emil wallner

   i study cs at 42 paris, write, and experiment with deep learning.

     (button) follow
   [73]freecodecamp.org

[74]freecodecamp.org

   stories worth reading about programming and technology from our open
   source community.

     * (button)
       (button) 3.3k
     * (button)
     *
     *

   [75]freecodecamp.org
   never miss a story from freecodecamp.org, when you sign up for medium.
   [76]learn more
   never miss a story from freecodecamp.org
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.freecodecamp.org/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/34c4435ae6b
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://medium.freecodecamp.org/deep-learning-for-developers-tools-you-can-use-to-code-neural-networks-on-day-1-34c4435ae6b&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://medium.freecodecamp.org/deep-learning-for-developers-tools-you-can-use-to-code-neural-networks-on-day-1-34c4435ae6b&source=--------------------------nav_reg&operation=register
   8. https://medium.freecodecamp.org/?source=logo-lo_yiknlm3bxsqz---336d898217ee
   9. https://medium.freecodecamp.org/tagged/web-development
  10. https://www.freecodecamp.com/?ref=mn
  11. https://medium.freecodecamp.org/@emilwallner?source=post_header_lockup
  12. https://medium.freecodecamp.org/@emilwallner
  13. https://unsplash.com/photos/y3fkhw1cybe?utm_source=unsplash&utm_medium=referral&utm_content=creditcopytext
  14. https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditcopytext
  15. https://www.codecademy.com/tracks/python
  16. https://www.codecademy.com/learn/learn-the-command-line
  17. https://www.youtube.com/watch?v=hw29067qvwk
  18. https://ml4a.github.io/images/figures/mnist-input.png
  19. http://www.r2d3.us/visual-intro-to-machine-learning-part-1/
  20. http://1.bp.blogspot.com/-me24epzpzim/uqlwtwurfxi/aaaaaaaaanw/w3eetiroa80/s1600/drop_shadows_background.png
  21. https://en.wikipedia.org/wiki/neocortex
  22. https://www.mladdict.com/neural-network-simulator
  23. http://tflearn.org/
  24. https://msdn.microsoft.com/en-us/library/f355wky8.aspx
  25. https://ml4a.github.io/images/figures/mnist-input.png
  26. https://medium.freecodecamp.org/media/3e96e9afeb8eb46deca91b482135f2b4?postid=34c4435ae6b
  27. https://www.tensorflow.org/
  28. http://tflearn.org/layers/core/
  29. http://tflearn.org/layers/estimator/
  30. http://tflearn.org/optimizers/
  31. http://tflearn.org/models/dnn/
  32. https://medium.com/towards-data-science/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9
  33. about:invalid#zsoyz
  34. https://keras.io/
  35. https://www.floydhub.com/
  36. http://docs.floydhub.com/getstarted/quick_start/
  37. https://medium.freecodecamp.org/media/486fde65bfda9f1488f9863f9201e926?postid=34c4435ae6b
  38. https://github.com/emilwallner/deep-learning-101.git
  39. https://www.floydhub.com/emilwallner/datasets/cifar-10/1
  40. https://www.youtube.com/watch?v=fmpdiaimiea&t=1202s
  41. http://cs231n.github.io/convolutional-networks/
  42. https://www.youtube.com/watch?v=lxfughug-iq
  43. https://pgaleone.eu/images/autoencoders/tf/cifar10_io_l2.png
  44. https://pgaleone.eu/images/autoencoders/tf/cifar10_io_l2.png
  45. https://github.com/emilwallner/deep-learning-101
  46. https://github.com/emilwallner/deep-learning-101/blob/master/experiment_0_few_layers.ipynb
  47. https://github.com/emilwallner/deep-learning-101/blob/master/experiment_0_three_layer_sets.ipynb
  48. https://medium.freecodecamp.org/media/681b5e417697f0ca9981775afaf04b77?postid=34c4435ae6b
  49. https://medium.freecodecamp.org/media/6a3a2926026a862b25d0f7f2be89b6f1?postid=34c4435ae6b
  50. https://medium.freecodecamp.org/media/6a3bec74cf140ca20ef48e0025275eea?postid=34c4435ae6b
  51. https://medium.freecodecamp.org/media/5f4a2972ee12953759d2e44f6c37d60f?postid=34c4435ae6b
  52. https://medium.freecodecamp.org/media/66ceb04de985f311c4e69f93a6374616?postid=34c4435ae6b
  53. https://github.com/tflearn/tflearn/tree/master/examples/images
  54. https://www.codecademy.com/tracks/python
  55. https://www.codecademy.com/learn/learn-the-command-line
  56. https://medium.com/@ignaciotonoli
  57. https://medium.com/@perborgen
  58. https://medium.com/@jlwingert
  59. https://twitter.com/sasounda
  60. https://medium.com/@whatrocks
  61. https://github.com/tflearn/tflearn/blob/master/examples/basics/linear_regression.py
  62. https://twitter.com/paulg/status/847844863727087616
  63. https://twitter.com/emilwallner
  64. https://medium.com/@emilwallner
  65. http://blog.floydhub.com/my-first-weekend-of-deep-learning/
  66. https://medium.freecodecamp.org/tagged/machine-learning?source=post
  67. https://medium.freecodecamp.org/tagged/artificial-intelligence?source=post
  68. https://medium.freecodecamp.org/tagged/data-science?source=post
  69. https://medium.freecodecamp.org/tagged/programming?source=post
  70. https://medium.freecodecamp.org/tagged/tech?source=post
  71. https://medium.freecodecamp.org/@emilwallner?source=footer_card
  72. https://medium.freecodecamp.org/@emilwallner
  73. https://medium.freecodecamp.org/?source=footer_card
  74. https://medium.freecodecamp.org/?source=footer_card
  75. https://medium.freecodecamp.org/
  76. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  78. https://medium.com/p/34c4435ae6b/share/twitter
  79. https://medium.com/p/34c4435ae6b/share/facebook
  80. https://medium.com/p/34c4435ae6b/share/twitter
  81. https://medium.com/p/34c4435ae6b/share/facebook
