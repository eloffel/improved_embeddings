   #[1]techcrunch    feed [2]techcrunch    comments feed [3]techcrunch   
   neural networks made easy comments feed [4]alternate [5]alternate

neural networks made easy

   [6]ophir tanz [7]cambron carter 2 years
   [brain-ai-newsletter.jpg?w=640]

   ophir tanz contributor
   [8]ophir tanz is the ceo of [9]gumgum, an artificial intelligence
   company with particular expertise in id161. gumgum applies
   its capabilities to a variety of industries, from advertising to
   professional sports across the globe. ophir holds a b.s. and a m.s.
   from carnegie mellon university and currently lives in los angeles.
   more posts by this contributor
     * [10]how video game tech makes neural networks possible
     * [11]why the future of deep learning depends on finding good data

   cambron carter contributor
   [12]cambron carter leads the image technology team at [13]gumgum, where
   he designs id161 and machine learning solutions for a wide
   variety of applications. cambron holds b.s. degrees in physics and
   electrical engineering and an m.eng. in electrical engineering from the
   university of louisville.
   more posts by this contributor
     * [14]why the future of deep learning depends on finding good data

   if you   ve dug into any articles on artificial intelligence, you   ve
   almost certainly run into the term    neural network.    modeled loosely on
   the human brain, id158s enable computers to learn
   from being fed data.

   the efficacy of this powerful branch of machine learning, more than
   anything else, has been responsible for ushering in a new era of
   artificial intelligence, ending a long-lived    [15]ai winter.    simply
   put, the neural network may well be one of the most fundamentally
   disruptive technologies in existence today.

   this guide to neural networks aims to give you a conversational level
   of understanding of deep learning. to this end, we   ll avoid delving
   into the math and instead rely as much as possible on analogies and
   animations.

thinking by brute force

   one of the early schools of ai taught that if you load up as much
   information as possible into a powerful computer and give it as many
   directions as possible to understand that data, it ought to be able to
      think.    this was the idea behind chess computers like ibm   s famous
   deep blue: by exhaustively programming every possible chess move into a
   computer, as well as known strategies, and then giving it sufficient
   power, ibm programmers created a machine that, in theory, could
   calculate every possible move and outcome into the future and pick the
   sequence of subsequent moves to outplay its opponent. this actually
   works, as[16] chess masters learned in 1997.*

   with this sort of computing, the machine relies on fixed rules that
   have been painstakingly pre-programmed by engineers     if this happens,
   then that happens; if this happens, do this     and so it isn   t
   human-style flexible learning as we know it at all. it   s powerful
   supercomputing, for sure, but not    thinking    per se.

teaching machines to learn

   over the past decade, scientists have resurrected an old concept that
   doesn   t rely on a massive encyclopedic memory bank, but instead on a
   simple and systematic way of analyzing input data that   s loosely
   modeled after human thinking. known as deep learning, or neural
   networks, this technology has been around since the 1940s, but because
   of today   s exponential proliferation of data     images, videos, voice
   searches, browsing habits and more     along with supercharged and
   affordable processors, it is at last able to begin to fulfill its true
   potential.

machines     they   re just like us!

   an artificial (as opposed to human) neural network (ann) is an
   algorithmic construct that enables machines to learn everything from
   voice commands and playlist curation to music composition and image
   recognition.the typical ann consists of thousands of interconnected
   artificial neurons, which are stacked sequentially in rows that are
   known as layers, forming millions of connections. in many cases, layers
   are only interconnected with the layer of neurons before and after them
   via inputs and outputs. (this is quite different from neurons in a
   human brain, which are interconnected every which way.)

   source: gumgum


   this layered ann is one of the main ways to go about machine learning
   today, and feeding it vast amounts of labeled data enables it to learn
   how to interpret that data like (and sometimes better than) a human.

     just as when parents teach their kids to identify apples and oranges
     in real life, for computers too, practice makes perfect.

   take, for example, image recognition, which relies on a particular type
   of neural network known as the convolutional neural network (id98)     so
   called because it uses a mathematical process known as convolution to
   be able to analyze images in non-literal ways, such as identifying a
   partially obscured object or one that is viewable only from certain
   angles. (there are other types of neural networks, including recurrent
   neural networks and feed-forward neural networks, but these are less
   useful for identifying things like images, which is the example we   re
   going to use below.)

all aboard the network training

   so how do neural networks learn? let   s look at a very simple, yet
   effective, procedure called supervised learning. here, we feed the
   neural network vast amounts of training data, labeled by humans so that
   a neural network can essentially fact-check itself as it   s learning.

   let   s say this labeled data consists of pictures of apples and oranges,
   respectively. the pictures are the data;    apple    and    orange    are the
   labels, depending on the picture. as pictures are fed in, the network
   breaks them down into their most basic components, i.e. edges, textures
   and shapes. as the picture propagates through the network, these basic
   components are combined to form more abstract concepts, i.e. curves and
   different colors which, when combined further, start to look like a
   stem, an entire orange, or both green and red apples.

   at the end of this process, the network attempts to make a prediction
   as to what   s in the picture. at first, these predictions will appear as
   random guesses, as no real learning has taken place yet. if the input
   image is an apple, but    orange    is predicted, the network   s inner
   layers will need to be adjusted.

   the adjustments are carried out through a process called
   id26 to increase the likelihood of predicting    apple    for
   that same image the next time around. this happens over and over until
   the predictions are more or less accurate and don   t seem to be
   improving. just as when parents teach their kids to identify apples and
   oranges in real life, for computers too, practice makes perfect. if, in
   your head, you just thought    hey, that sounds like learning,    then you
   may have a career in ai.

so many layers   

   typically, a convolutional neural network has four essential layers of
   neurons besides the input and output layers:
     * convolution
     * activation
     * pooling
     * fully connected

   convolution

   in the initial convolution layer or layers, thousands of neurons act as
   the first set of filters, scouring every part and pixel in the image,
   looking for patterns. as more and more images are processed, each
   neuron gradually learns to filter for specific features, which improves
   accuracy.

   in the case of apples, one filter might be focused on finding the color
   red, while another might be looking for rounded edges and yet another
   might be identifying thin, stick-like stems. if you   ve ever had to
   clean out a cluttered basement to prepare for a garage sale or a big
   move     or worked with a professional organizer     then you know what it
   is to go through everything and sort it into different-themed piles
   (books, toys, electronics, objets d   art, clothes). that   s sort of what
   a convolutional layer does with an image by breaking it down into
   different features.

     one advantage of neural networks is that they are capable of
     learning in a nonlinear way.

   what   s particularly powerful     and one of the neural network   s main
   claims to fame     is that unlike earlier ai methods (deep blue and its
   ilk), these filters aren   t hand designed; they learn and refine
   themselves purely by looking at data.

   the convolution layer essentially creates maps     different, broken-down
   versions of the picture, each dedicated to a different filtered feature
       that indicate where its neurons see an instance (however partial) of
   the color red, stems, curves and the various other elements of, in this
   case, an apple. but because the convolution layer is fairly liberal in
   its identifying of features, it needs an extra set of eyes to make sure
   nothing of value is missed as a picture moves through the network.

   activation

   one advantage of neural networks is that they are capable of learning
   in a nonlinear way, which, in mathless terms, means they are able to
   spot features in images that aren   t quite as obvious     pictures of
   apples on trees, some of them under direct sunlight and others in the
   shade, or piled into a bowl on a kitchen counter. this is all thanks to
   the activation layer, which serves to more or less highlight the
   valuable stuff     both the straightforward and harder-to-spot varieties.

   in the world of our garage-sale organizer or clutter consultant,
   imagine that from each of those separated piles of things we   ve
   cherry-picked a few items     a handful of rare books, some classic
   t-shirts from our college days to wear ironically     that we might want
   to keep. we stick these    maybe    items on top of their respective
   category piles for another consideration later.

   pooling

   all this    convolving    across an entire image generates a lot of
   information, and this can quickly become a computational nightmare.
   enter the pooling layer, which shrinks it all into a more general and
   digestible form. there are many ways to go about this, but one of the
   most popular is    max pooling,    which edits down each feature map into a
   reader   s digest version of itself, so that only the best examples of
   redness, stem-ness or curviness are featured.

   in the garage spring cleaning example, if we were using famed japanese
   clutter consultant marie kondo   s principles, our pack rat would have to
   choose only the things that    spark joy    from the smaller assortment of
   favorites in each category pile, and sell or toss everything else. so
   now we still have all our piles categorized by type of item, but only
   consisting of the items we actually want to keep; everything else gets
   sold. (and this, by the way, ends our de-cluttering analogy to help
   describe the filtering and downsizing that goes on inside a neural
   network.)

   at this point, a neural network designer can stack subsequent layered
   configurations of this sort     convolution, activation, pooling     and
   continue to filter down images to get higher-level information. in the
   case of identifying an apple in pictures, the images get filtered down
   over and over, with initial layers showing just barely discernable
   parts of an edge, a blip of red or just the tip of a stem, while
   subsequent, more filtered layers will show entire apples. either way,
   when it   s time to start getting results, the fully connected layer
   comes into play.

   source: gumgum

   fully connected

   now it   s time to start getting answers. in the fully connected layer,
   each reduced, or    pooled,    feature map is    fully connected    to output
   nodes (neurons) that represent the items the neural network is learning
   to identify. if the network is tasked with learning how to spot cats,
   dogs, guinea pigs and gerbils, then it   ll have four output nodes. in
   the case of the neural network we   ve been describing, it   ll just have
   two output nodes: one for    apples    and one for    oranges.   

   if the picture that has been fed through the network is of an apple,
   and the network has already undergone some training and is getting
   better with its predictions, then it   s likely that a good chunk of the
   feature maps contain quality instances of apple features. this is where
   these final output nodes start to fulfill their destiny, with a reverse
   election of sorts.

     tweaks and adjustments are made to help each neuron better identify
     the data at every level.

   the job (which they   ve learned    on the job   ) of both the apple and
   orange nodes is essentially to    vote    for the feature maps that contain
   their respective fruits. so, the more the    apple    node thinks a
   particular feature map contains    apple    features, the more votes it
   sends to that feature map. both nodes have to vote on every single
   feature map, regardless of what it contains. so in this case, the
      orange    node won   t send many votes to any of the feature maps, because
   they don   t really contain any    orange    features. in the end, the node
   that has sent the most votes out     in this example, the    apple    node    
   can be considered the network   s    answer,    though it   s not quite that
   simple.

   because the same network is looking for two different things     apples
   and oranges     the final output of the network is expressed as
   percentages. in this case, we   re assuming that the network is already a
   bit down the road in its training, so the predictions here might be,
   say, 75 percent    apple    and 25 percent    orange.    or, if it   s earlier in
   the training, it might be more inaccurate and determine that it   s 20
   percent    apple    and 80 percent    orange.    oops.

   source: gumgum

if at first you don   t succeed, try, try, try again

   so, in its early stages, the neural network spits out a bunch of wrong
   answers in the form of percentages. the 20 percent    apple    and 80
   percent    orange    prediction is clearly wrong, but since this is
   supervised learning with labeled training data, the network is able to
   figure out where and how that error occurred through a system of checks
   and balances known as id26.

   now, this is a mathless explanation, so suffice it to say that
   id26 sends feedback to the previous layer   s nodes about just
   how far off the answers were. that layer then sends the feedback to the
   previous layer, and on and on like a game of telephone until it   s back
   at convolution. tweaks and adjustments are made to help each neuron
   better identify the data at every level when subsequent images go
   through the network.

   this process is repeated over and over until the neural network is
   identifying apples and oranges in images with increasing accuracy,
   eventually ending up at 100 percent correct predictions     though many
   engineers consider 85 percent to be acceptable. and when that happens,
   the neural network is ready for prime time and can start identifying
   apples in pictures professionally.

   *this is different than google   s alphago which used a self-learned
   neural net to evaluate board positions and ultimately [17]beat a human
   at go, versus deep blue, which used a hard-coded function written by a
   human.

   ____________________

references

   1. https://techcrunch.com/feed/
   2. https://techcrunch.com/comments/feed/
   3. https://techcrunch.com/2017/04/13/neural-networks-made-easy/feed/
   4. https://techcrunch.com/wp-json/oembed/1.0/embed?url=https://techcrunch.com/2017/04/13/neural-networks-made-easy/
   5. https://techcrunch.com/wp-json/oembed/1.0/embed?url=https://techcrunch.com/2017/04/13/neural-networks-made-easy/&format=xml
   6. https://techcrunch.com/author/
   7. https://techcrunch.com/author/
   8. https://www.linkedin.com/in/ophirtanz/
   9. http://gumgum.com/
  10. https://techcrunch.com/2017/10/27/how-video-game-tech-makes-neural-networks-possible/
  11. https://techcrunch.com/2017/07/21/why-the-future-of-deep-learning-depends-on-finding-good-data/
  12. https://www.linkedin.com/in/cambron-carter-5358a06a/
  13. http://www.gumgum.com/
  14. https://techcrunch.com/2017/07/21/why-the-future-of-deep-learning-depends-on-finding-good-data/
  15. https://en.wikipedia.org/wiki/ai_winter
  16. https://en.wikipedia.org/wiki/deep_blue_(chess_computer)
  17. https://beta.techcrunch.com/2016/03/09/googles-deepmind-chalks-up-ai-landmark-after-beating-go-world-champion-lee-sedol/
