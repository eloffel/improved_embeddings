   #[1]index [2]search [3]using auxiliary variables in mcmc proposals
   [4]numerical evaluation of integrals

navigation

     * [5]index
     * [6]next
     * [7]previous
     * [8]computational statistics in python   

metropolis and id150[9]  

   [10]kruschke   s book begins with a fun example of a politician visiting
   a chain of islands to canvas support - being callow, the politician
   uses a simple rule to determine which island to visit next. each day,
   the politician chooses a neighboring island and compares the
   populations there with the population of the current island. if the
   neighboring island has a larger population, the politician goes over.
   if the neighboring island has a smaller population, then the politician
   visits with id203 \(p = p_\text{neighbor} / p_\text{current}\);
   otherwise the politician stays on the same island. after doing this for
   many days, the politician will end up spending time on each island
   proportional to the population of each island - in other words,
   estimating the distribution of island populations correctly. how a
   simple comparison of only two states at a time can lead to accurate
   estimation of a id203 density is the topic of the next few
   lectures.

island hopping[11]  

in [37]:

def make_islands(n, low=10, high=101):
    islands = np.random.randint(low, high, n+2)
    islands[0] = 0
    islands[-1] = 0
    return islands

in [38]:

def hop(islands, start=1, niter=1000):
    pos = start
    pop = islands[pos]
    thetas = np.zeros(niter+1, dtype='int')
    thetas[0] = pos
    for i in range(niter):
        # generate sample from proposal distribution
        k = np.random.choice([-1, 1], 1)
        next_pos = pos + k
        # evaluate unnormalized target distribution at proposed position
        next_pop = islands[next_pos]
        # calculate acceptance id203
        p = min(1, next_pop/pop)
        # use uniform random to decide accept/reject proposal
        if np.random.random() < p:
            pos = next_pos
            pop = next_pop
        thetas[i+1] = pos
    return thetas

in [39]:

islands = make_islands(10)
thetas = hop(islands, start=1, niter=10000)

true population proportions[12]  

in [40]:

data = islands[1:-1]
data = data/data.sum()
sns.barplot(x=np.arange(len(data)), y=data)
pass

   _images/16a_mcmc_7_0.png

estimated population proportions[13]  

in [41]:

data = np.bincount(thetas)[1:]
data = data/data.sum()
sns.barplot(x=np.arange(len(data)), y=data)
pass

   _images/16a_mcmc_9_0.png

generic metropolis scheme[14]  

in [42]:

def metroplis(start, target, proposal, niter, nburn=0):
    current = start
    post = [current]
    for i in range(niter):
        proposed = proposal(current)
        p = min(target(proposed)/target(current), 1)
        if np.random.random() < p:
            current = proposed
        post.append(current)
    return post[nburn:]

apply to island hooper[15]  

in [43]:

target = lambda x: islands[x]
proposal = lambda x: x + np.random.choice([-1, 1])
post = metroplis(1, target, proposal, 2000)
data = np.bincount(post)[1:]
data = data/data.sum()
sns.barplot(x=np.arange(len(data)), y=data)
pass

   _images/16a_mcmc_13_0.png

bayesian data analysis[16]  

   the fundamental objective of bayesian data analysis is to determine the
   posterior distribution
   p(\theta \ | \ x) = \frac{p(x \ | \ \theta) p(\theta)}{p(x)}

   where the denominator is
   p(x) = \int d\theta^* p(x \ | \ \theta^*) p(\theta^*)

   here,
     * \(p(x \ | \ \theta)\) is the likelihood,
     * \(p(\theta)\) is the prior and
     * \(p(x)\) is a normalizing constant also known as the evidence or
       marginal likelihood

   the computational issue is the difficulty of evaluating the integral in
   the denominator. there are many ways to address this difficulty,
   including:
     * in cases with conjugate priors (with conjugate priors, the
       posterior has the same distribution as the prior), we can get
       closed form solutions
     * we can use numerical integration
     * we can approximate the functions used to calculate the posterior
       with simpler functions and show that the resulting approximate
       posterior is    close    to true posterior (id58)
     * we can use monte carlo methods, of which the most important is
       id115 (mcmc). in simple monte carlo inegration,
       we want to estimate the integral \(f(x) \, p(x) dx\). wtih bayesain
       models, the distribution \(p(x)\) in the integral is the posterior

   \[ \begin{align}\begin{aligned}:nowrap:\\ p(x) = p(\theta \ | \ x) =
   \frac{p(x \ | \ \theta) p(\theta)}{\int d\theta^* p(x \ | \ \theta^*)
   p(\theta^*) }\\- mcmc allows to sample from the posterior distribution
   - the samples\end{aligned}\end{align} \]

   will not be independent unlike simple monte carlo integration, but this
   is ok as we can compensate for the auto-correlation by drawing a larger
   number of samples.

motivating example[17]  

   we will use the toy example of estimating the bias of a coin given a
   sample consisting of \(n\) tosses to illustrate a few of the
   approaches.

analytical solution[18]  

   if we use a beta distribution as the prior, then the posterior
   distribution has a closed form solution. this is shown in the example
   below. some general points:
     * we need to choose a prior distribution family (i.e. the beta here)
       as well as its parameters (here a=10, b=10)
          + the prior distribution may be relatively uninformative (i.e.
            more flat) or informative (i.e. more peaked)
     * the posterior depends on both the prior and the data
          + as the amount of data becomes large, the posterior
            approximates the id113
          + an informative prior takes more data to shift than an
            uninformative one
     * of course, it is also important the model used (i.e. the
       likelihood) is appropriate for the fitting the data
     * the mode of the posterior distribution is known as the maximum a
       posteriori (map) estimate (cf id113 which is the mode of the
       likelihood)

in [44]:

import scipy.stats as stats

in [45]:

n = 100
h = 61
p = h/n
rv = stats.binom(n, p)
mu = rv.mean()

a, b = 10, 10
prior = stats.beta(a, b)
post = stats.beta(h+a, n-h+b)
ci = post.interval(0.95)

thetas = np.linspace(0, 1, 200)
plt.plot(thetas, prior.pdf(thetas), label='prior', c='blue')
plt.plot(thetas, post.pdf(thetas), label='posterior', c='red')
plt.plot(thetas, n*stats.binom(n, thetas).pmf(h), label='likelihood', c='green')
plt.axvline((h+a-1)/(n+a+b-2), c='red', linestyle='dashed', alpha=0.4, label='ma
p')
plt.axvline(mu/n, c='green', linestyle='dashed', alpha=0.4, label='id113')
plt.xlim([0, 1])
plt.axhline(0.3, ci[0], ci[1], c='black', linewidth=2, label='95% ci');
plt.xlabel(r'$\theta$', fontsize=14)
plt.ylabel('density', fontsize=16)
plt.legend(loc='upper left')
pass

   _images/16a_mcmc_18_0.png

numerical integration[19]  

   one simple way of numerical integration is to estimate the values on a
   grid of values for \(\theta\). to calculate the posterior, we find the
   prior and the likelihood for each value of \(\theta\), and for the
   marginal likelihood, we replace the integral with the equivalent sum
   p(x) = \sum_{\theta^*} p(x | \theta^*) p(\theta^*)

   one advantage of this is that the prior does not have to be conjugate
   (although the example below uses the same beta prior for ease of
   comparison), and so we are not restricted in our choice of an
   appropriate prior distribution. for example, the prior can be a mixture
   distribution or estimated empirically from data. the disadvantage, of
   course, is that this is computationally very expensive when we need to
   estimate multiple parameters, since the number of grid points grows as
   \(\mathcal{o}(n^d)\), where \(n\) defines the grid resolution and \(d\)
   is the size of \(\theta\).
in [46]:

thetas = np.linspace(0, 1, 200)
prior = stats.beta(a, b)

post = prior.pdf(thetas) * stats.binom(n, thetas).pmf(h)
# normalzie so volume is 1
post /= (post.sum() / len(thetas))

plt.plot(thetas, prior.pdf(thetas), label='prior', c='blue')
plt.plot(thetas, n*stats.binom(n, thetas).pmf(h), label='likelihood', c='green')
plt.plot(thetas, post, label='posterior', c='red')
plt.xlim([0, 1])
plt.xlabel(r'$\theta$', fontsize=14)
plt.ylabel('density', fontsize=16)
plt.legend()
pass

   _images/16a_mcmc_20_0.png

id115 (mcmc)[20]  

   this lecture will only cover the basic ideas of mcmc and the 3 common
   variants - metroplis, metropolis-hastings and id150. all code
   will be built from the ground up to illustrate what is involved in
   fitting an mcmc model, but only toy examples will be shown since the
   goal is conceptual understanding. more realistic computational examples
   will be shown in coming lectures using the pymc3 and pystan packages.

   in bayesian statistics, we want to estimate the posterior distribution,
   but this is often intractable due to the high-dimensional integral in
   the denominator (marginal likelihood). a few other ideas we have
   encountered that are also relevant here are monte carlo integration
   with independent samples and the use of proposal distributions (e.g.
   rejection and importance sampling). as we have seen from the monte
   carlo integration lectures, we can approximate the posterior \(p(\theta
   | x)\) if we can somehow draw many samples that come from the posterior
   distribution. with vanilla monte carlo integration, we need the samples
   to be independent draws from the posterior distribution, which is a
   problem if we do not actually know what the posterior distribution is
   (because we cannot integrate the marginal likelihood).

   with mcmc, we draw samples from a (simple) proposal distribution so
   that each draw depends only on the state of the previous draw (i.e. the
   samples form a markov chain). under certain conditions, the markov
   chain will have a unique stationary distribution. in addition, not all
   samples are used - instead we set up acceptance criteria for each draw
   based on comparing successive states with respect to a target
   distribution that ensure that the stationary distribution is the
   posterior distribution of interest. the nice thing is that this target
   distribution only needs to be proportional to the posterior
   distribution, which means we don   t need to evaluate the potentially
   intractable marginal likelihood, which is just a normalizing constant.
   we can find such a target distribution easily, since posterior
   \(\propto\) likelihood \(\times\) prior. after some time, the markov
   chain of accepted draws will converge to the stationary distribution,
   and we can use those samples as (correlated) draws from the posterior
   distribution, and find functions of the posterior distribution in the
   same way as for vanilla monte carlo integration.

   there are several flavors of mcmc, but the simplest to understand is
   the metropolis-hastings random walk algorithm, and we will start there.

metropolis-hastings random walk algorithm for estimating the bias of a
coin[21]  

   to carry out the metropolis-hastings algorithm, we need to draw random
   samples from the following distributions
     * the standard uniform distribution
     * a proposal distribution \(p(x)\) that we choose to be
       \(\mathcal{n}(0, \sigma)\)
     * the target distribution \(g(x)\) which is proportional to the
       posterior id203

   given an initial guess for \(\theta\) with positive id203 of
   being drawn, the metropolis-hastings algorithm proceeds as follows
     * choose a new proposed value (\(\theta_p\)) such that \(\theta_p =
       \theta + \delta\theta\) where \(\delta \theta \sim \mathcal{n}(0,
       \sigma)\)
     * caluculate the ratio

   \rho = \frac{g(\theta_p \ | \ x)}{g(\theta \ | \ x)}

   where \(g\) is the posterior id203.
     * if the proposal distribution is not symmetrical, we need to weight
       the acceptance id203 to maintain detailed balance
       (reversibility) of the stationary distribution, and instead
       calculate

   \rho = \frac{g(\theta_p \ | \ x) p(\theta \ | \ \theta_p)}{g(\theta \ |
   \ x) p(\theta_p \ | \ \theta)}

   since we are taking ratios, the denominator cancels any distribution
   proportional to \(g\) will also work - so we can use
   \rho = \frac{p(x | \theta_p ) p(\theta_p)}{p(x | \theta ) p(\theta)}
     * if \(\rho \ge 1\), then set \(\theta = \theta_p\)
     * if \(\rho \lt 1\), then set \(\theta = \theta_p\) with id203
       \(\rho\), otherwise set \(\theta = \theta\) (this is where we use
       the standard uniform distribution)
     * repeat the earlier steps

   after some number of iterations \(k\), the samples \(\theta_{k+1},
   \theta_{k+2}, \dots\) will be samples from the posterior distributions.
   here are initial concepts to help your intuition about why this is so:
     * we accept a proposed move to \(\theta_{k+1}\) whenever the density
       of the (unnormalized) target distribution at \(\theta_{k+1}\) is
       larger than the value of \(\theta_k\) - so \(\theta\) will more
       often be found in places where the target distribution is denser
     * if this was all we accepted, \(\theta\) would get stuck at a local
       mode of the target distribution, so we also accept occasional moves
       to lower density regions - it turns out that the correct
       id203 of doing so is given by the ratio \(\rho\)
     * the acceptance criteria only looks at ratios of the target
       distribution, so the denominator cancels out and does not matter -
       that is why we only need samples from a distribution proportional
       to the posterior distribution
     * so, \(\theta\) will be expected to bounce around in such a way that
       its spends its time in places proportional to the density of the
       posterior distribution - that is, \(\theta\) is a draw from the
       posterior distribution.

   additional notes:

   different proposal distributions can be used for metropolis-hastings:
     * the independence sampler uses a proposal distribution that is
       independent of the current value of \(\theta\). in this case the
       proposal distribution needs to be similar to the posterior
       distribution for efficiency, while ensuring that the acceptance
       ratio is bounded in the tail region of the posterior.
     * the random walk sampler (used in this example) takes a random step
       centered at the current value of \(\theta\) - efficiency is a
       trade-off between small step size with high id203 of
       acceptance and large step sizes with low id203 of acceptance.
       note (picture will be sketched in class) that the random walk may
       take a long time to traverse narrow regions of the id203
       distribution. changing the step size (e.g. scaling \(\sigma\) for a
       multivariate normal proposal distribution) so that a target
       proportion of proposals are accepted is known as tuning.
     * much research is being conducted on different proposal
       distributions for efficient sampling of the posterior distribution.

   we will first see a numerical example and then try to understand why it
   works.
in [47]:

def target(lik, prior, n, h, theta):
    if theta < 0 or theta > 1:
        return 0
    else:
        return lik(n, theta).pmf(h)*prior.pdf(theta)

n = 100
h = 61
a = 10
b = 10
lik = stats.binom
prior = stats.beta(a, b)
sigma = 0.3

naccept = 0
theta = 0.1
niters = 10000
samples = np.zeros(niters+1)
samples[0] = theta
for i in range(niters):
    theta_p = theta + stats.norm(0, sigma).rvs()
    rho = min(1, target(lik, prior, n, h, theta_p)/target(lik, prior, n, h, thet
a ))
    u = np.random.uniform()
    if u < rho:
        naccept += 1
        theta = theta_p
    samples[i+1] = theta
nmcmc = len(samples)//2
print("efficiency = ", naccept/niters)

efficiency =  0.1904

in [48]:

post = stats.beta(h+a, n-h+b)

plt.hist(samples[nmcmc:], 40, histtype='step', normed=true, linewidth=1, label='
prior');
plt.hist(prior.rvs(nmcmc), 40, histtype='step', normed=true, linewidth=1, label=
'posterior');
plt.plot(thetas, post.pdf(thetas), c='red', linestyle='--', alpha=0.5, label='tr
ue posterior')
plt.xlim([0,1]);
plt.legend(loc='upper left')
pass

   _images/16a_mcmc_24_0.png

assessing for convergence[22]  

   trace plots are often used to informally assess for stochastic
   convergence. rigorous demonstration of convergence is an unsolved
   problem, but simple ideas such as running multiple chains and checking
   that they are converging to similar distributions are often employed in
   practice.
in [49]:

def mh_coin(niters, n, h, theta, lik, prior, sigma):
    samples = [theta]
    while len(samples) < niters:
        theta_p = theta + stats.norm(0, sigma).rvs()
        rho = min(1, target(lik, prior, n, h, theta_p)/target(lik, prior, n, h,
theta ))
        u = np.random.uniform()
        if u < rho:
            theta = theta_p
        samples.append(theta)
    return samples

in [50]:

n = 100
h = 61
lik = stats.binom
prior = stats.beta(a, b)
sigma = 0.05
niters = 100

sampless = [mh_coin(niters, n, h, theta, lik, prior, sigma) for theta in np.aran
ge(0.1, 1, 0.2)]

in [51]:

# convergence of multiple chains

for samples in sampless:
    plt.plot(samples, '-o')
plt.xlim([0, niters])
plt.ylim([0, 1]);

   _images/16a_mcmc_28_0.png

why does metropolis-hastings work?[23]  

   there are two main ideas - first that the samples generated by mcmc
   constitute a markov chain, and that this markov chain has a unique
   stationary distribution that is always reached if we generate a very
   large number of samples. the second idea is to show that this
   stationary distribution is exactly the posterior distribution that we
   are looking for. we will only give the intuition here as a refresher.

one: there is a unique stationary state[24]  

   since possible transitions depend only on the current and the proposed
   values of \(\theta\), the successive values of \(\theta\) in a
   metropolis-hastings sample constitute a markov chain. recall that for a
   markov chain with a transition matrix \(t\)
   \pi = \pi t

   means that \(\pi\) is a stationary distribution. if it is possible to
   go from any state to any other state, then the matrix is irreducible.
   if in addition, it is not possible to get stuck in an oscillation, then
   the matrix is also aperiodic or mixing. for finite state spaces,
   irreducibility and aperiodicity guarantee the existence of a unique
   stationary state. for continuous state space, we need an additional
   property of positive recurrence - starting from any state, the expected
   time to come back to the original state must be finite. if we have all
   3 properties of irreducibility, aperiodicity and positive recurrence,
   then there is a unique stationary distribution. the term ergodic is a
   little confusing - most standard definitions take ergodicity to be
   equivalent to irreducibility, but often bayesian texts take ergodicity
   to mean irreducibility, aperiodicity and positive recurrence, and we
   will follow the latter convention. for another intuitive perspective,
   the random walk metropolis-hasting algorithm is analogous to a
   diffusion process. since all states are communicating (by design),
   eventually the system will settle into an equilibrium state. this is
   analogous to converging on the stationary state.

two: the stationary state is the posterior id203 distribution[25]  

   we will consider the simplest possible scenario for an explicit
   calculation. suppose we have a two-state system where the posterior
   probabilities are \(\theta\) and \(1 - \theta\). suppose \(\theta \lt
   0.5\). so we have the following picture with the metropolis-hastings
   algorithm:
   markov chain

   markov chain

   and we find the stationary distribution \(\pi = \left(
   \begin{array}{cc} p & 1-p \end{array} \right)\) by solving
   \begin{align} \left( \begin{array}{cc} p & 1-p \end{array} \right) &=
   \left( \begin{array}{cc} p & 1-p \end{array} \right) \left(
   \begin{array}{cc} 0 & 1 \\ \frac{\theta}{1-\theta} &
   1-\frac{\theta}{1-\theta} \end{array} \right) \end{align}

   to be \(\pi = \left( \begin{array}{cc} \theta & 1-\theta \end{array}
   \right)\), which is the posterior distribution.

   the final point is that a stationary distribution has to follow the
   detailed balance (reversibility) criterion that says that the
   id203 of being in state \(x\) and moving to state \(y\) must be
   the same as the id203 of being in state \(y\) and moving to state
   \(x\). or, more briefly,
   \pi(x)t(x \to y) = \pi(y)t(y \to x)

   and the need to make sure that this condition is true accounts for the
   strange looking acceptance criterion
   \min \left(1, \frac{g(\theta_p \ | \ x) p(\theta \ | \
   \theta_p)}{g(\theta \ | \ x) p(\theta_p \ | \ \theta)} \right)

intuition[26]  

   we want the stationary distribution \(\pi(x)\) to be the posterior
   distribution \(p(x)\). so we set
   p(x)t(x \to y) = p(y)t(y \to x)

   rearranging, we get
   \frac{t(x \to y)}{t(y \to x)} = \frac{p(y)}{p(x)}

   we split the transition id203 into separate proposal \(q\) and
   acceptance \(a\) parts, and after a little algebraic rearrangement get
   \frac{a(x \to y)}{a(y \to x)} = \frac{p(y) \, q(y \to x)}{p(x) \, q(x
   \to y)}

   an acceptance id203 that meets this condition is
   a(x \to y) = \min \left(1, \frac{p(y) \, q(y \to x)}{p(x) \, q(x \to
   y)} \right)

   since \(a\) in the numerator and denominator are both bounded above by
   1.

   see [27]chib and greenberg for algebraic details.

the gibbs sampler[28]  

   suppose we have a vector of parameters \(\theta = (\theta_1, \theta_2,
   \dots, \theta_k)\), and we want to estimate the joint posterior
   distribution \(p(\theta | x)\). suppose we can find and draw random
   samples from all the conditional distributions
   p(\theta_1 | \theta_2, \dots \theta_k, x) \\ p(\theta_2 | \theta_1,
   \dots \theta_k, x) \\ \dots \\ p(\theta_k | \theta_1, \theta_2, \dots,
   x)

   with id150, the markov chain is constructed by sampling from
   the conditional distribution for each parameter \(\theta_i\) in turn,
   treating all other parameters as observed. when we have finished
   iterating over all parameters, we are said to have completed one cycle
   of the gibbs sampler. since id187 are typically set up as
   products of conditional distributions, the gibbs sampler is ubiquitous
   in bayesian modeling. where it is difficult to sample from a
   conditional distribution, we can sample using a metropolis-hastings
   algorithm instead - this is known as metropolis within gibbs.

   id150 is a type of random walk through parameter space, and
   hence can be thought of as a metropolis-hastings algorithm with a
   special proposal distribution. at each iteration in the cycle, we are
   drawing a proposal for a new value of a particular parameter, where the
   proposal distribution is the conditional posterior id203 of that
   parameter. this means that the proposal move is always accepted. hence,
   if we can draw samples from the conditional distributions, gibbs
   sampling can be much more efficient than regular metropolis-hastings.
   more formally, we want to show that
   \frac{p(y) \, q(y \to x)}{p(x) \, q(x \to y)} = 1

   we start by noting that \(p(x_{-i}\) is the same as \(p(y_{-i})\) since
   apart from the component \(i\), the old state and the proposed new
   state are identical in id150. we also recall that
   \[p(x_i \mid x_{-i}) \, p(x_{-i}) = p(x_i, x_{-i} = p(x)\]

   by definition of id155. so we have
   \begin{align} \frac{p(y) \, q(y \to x)}{p(x) \, q(x \to y)} &=
   \frac{p(y_i \mid y_{-1}) \, p(y_{-i})\, p(x_i \mid x_{-i}) }{p(x_i \mid
   x_{-i}) \, p(x_{-i})\, p(y_i \mid y_{-1})} &= 1 \end{align}

   advantages of id150
     * no need to tune proposal distribution
     * proposals are always accepted

   disadvantages of id150
     * need to be able to derive id155 distributions
     * need to be able to (cheaply) draw random samples from conditional
       id203 distributions
     * can be very slow if parameters are correlated because you cannot
       take    diagonal    steps (draw picture to illustrate)

motivating example[29]  

   we will use the toy example, familiar from the em lecture, of
   estimating the bias of two coins given sample pairs \((z_1, n_1)\) and
   \((z_2, n_2)\) where \(z_i\) is the number of heads in \(n_i\) tosses
   for coin \(i\).

setup[30]  

in [52]:

def bern(theta, z, n):
    """bernoulli likelihood with n trials and z successes."""
    return np.clip(theta**z * (1-theta)**(n-z), 0, 1)

in [53]:

def bern2(theta1, theta2, z1, z2, n1, n2):
    """bernoulli likelihood with n trials and z successes."""
    return bern(theta1, z1, n1) * bern(theta2, z2, n2)

in [54]:

def make_thetas(xmin, xmax, n):
    xs = np.linspace(xmin, xmax, n)
    widths =(xs[1:] - xs[:-1])/2.0
    thetas = xs[:-1]+ widths
    return thetas

in [55]:

from mpl_toolkits.mplot3d import axes3d

def make_plots(x, y, prior, likelihood, posterior, projection=none):
    fig, ax = plt.subplots(1,3, subplot_kw=dict(projection=projection, aspect='e
qual'), figsize=(12,3))
    if projection == '3d':
        ax[0].plot_surface(x, y, prior, alpha=0.3, cmap=plt.cm.jet)
        ax[1].plot_surface(x, y, likelihood, alpha=0.3, cmap=plt.cm.jet)
        ax[2].plot_surface(x, y, posterior, alpha=0.3, cmap=plt.cm.jet)
        for ax_ in ax: ax_._axis3don = false
    else:
        ax[0].contour(x, y, prior, cmap=plt.cm.jet)
        ax[1].contour(x, y, likelihood, cmap=plt.cm.jet)
        ax[2].contour(x, y, posterior, cmap=plt.cm.jet)
    ax[0].set_title('prior')
    ax[1].set_title('likelihood')
    ax[2].set_title('posteior')
    plt.tight_layout()

in [56]:

thetas1 = make_thetas(0, 1, 101)
thetas2 = make_thetas(0, 1, 101)
x, y = np.meshgrid(thetas1, thetas2)

analytic solution[31]  

in [57]:

a = 2
b = 3

z1 = 11
n1 = 14
z2 = 7
n2 = 14

prior = stats.beta(a, b).pdf(x) * stats.beta(a, b).pdf(y)
likelihood = bern2(x, y, z1, z2, n1, n2)
posterior = stats.beta(a + z1, b + n1 - z1).pdf(x) * stats.beta(a + z2, b + n2 -
 z2).pdf(y)
make_plots(x, y, prior, likelihood, posterior)
make_plots(x, y, prior, likelihood, posterior, projection='3d')

   _images/16a_mcmc_39_0.png
   _images/16a_mcmc_39_1.png

grid approximation[32]  

in [58]:

def c2d(thetas1, thetas2, pdf):
    width1 = thetas1[1] - thetas1[0]
    width2 = thetas2[1] - thetas2[0]
    area = width1 * width2
    pmf = pdf * area
    pmf /= pmf.sum()
    return pmf

in [59]:

_prior = bern2(x, y, 2, 8, 10, 10) + bern2(x, y, 8, 2, 10, 10)
prior_grid = c2d(thetas1, thetas2, _prior)
_likelihood = bern2(x, y, 1, 1, 2, 3)
posterior_grid = _likelihood * prior_grid
posterior_grid /= posterior_grid.sum()
make_plots(x, y, prior_grid, likelihood, posterior_grid)
make_plots(x, y, prior_grid, likelihood, posterior_grid, projection='3d')

   _images/16a_mcmc_42_0.png
   _images/16a_mcmc_42_1.png

metropolis[33]  

in [60]:

a = 2
b = 3

z1 = 11
n1 = 14
z2 = 7
n2 = 14

prior = lambda theta1, theta2: stats.beta(a, b).pdf(theta1) * stats.beta(a, b).p
df(theta2)
lik = partial(bern2, z1=z1, z2=z2, n1=n1, n2=n2)
target = lambda theta1, theta2: prior(theta1, theta2) * lik(theta1, theta2)

theta = np.array([0.5, 0.5])
niters = 10000
burnin = 500
sigma = np.diag([0.2,0.2])

thetas = np.zeros((niters-burnin, 2), np.float)
for i in range(niters):
    new_theta = stats.multivariate_normal(theta, sigma).rvs()
    p = min(target(*new_theta)/target(*theta), 1)
    if np.random.rand() < p:
        theta = new_theta
    if i >= burnin:
        thetas[i-burnin] = theta

in [61]:

kde = stats.gaussian_kde(thetas.t)
xy = np.vstack([x.ravel(), y.ravel()])
posterior_metroplis = kde(xy).reshape(x.shape)
make_plots(x, y, prior(x, y), lik(x, y), posterior_metroplis)
make_plots(x, y, prior(x, y), lik(x, y), posterior_metroplis, projection='3d')

   _images/16a_mcmc_45_0.png
   _images/16a_mcmc_45_1.png

gibbs[34]  

in [62]:

a = 2
b = 3

z1 = 11
n1 = 14
z2 = 7
n2 = 14

prior = lambda theta1, theta2: stats.beta(a, b).pdf(theta1) * stats.beta(a, b).p
df(theta2)
lik = partial(bern2, z1=z1, z2=z2, n1=n1, n2=n2)
target = lambda theta1, theta2: prior(theta1, theta2) * lik(theta1, theta2)

theta = np.array([0.5, 0.5])
niters = 10000
burnin = 500
sigma = np.diag([0.2,0.2])

thetas = np.zeros((niters-burnin,2), np.float)
for i in range(niters):
    theta = [stats.beta(a + z1, b + n1 - z1).rvs(), theta[1]]
    theta = [theta[0], stats.beta(a + z2, b + n2 - z2).rvs()]

    if i >= burnin:
        thetas[i-burnin] = theta

in [63]:

kde = stats.gaussian_kde(thetas.t)
xy = np.vstack([x.ravel(), y.ravel()])
posterior_gibbs = kde(xy).reshape(x.shape)
make_plots(x, y, prior(x, y), lik(x, y), posterior_gibbs)
make_plots(x, y, prior(x, y), lik(x, y), posterior_gibbs, projection='3d')

   _images/16a_mcmc_48_0.png
   _images/16a_mcmc_48_1.png

id187[35]  

   id187 have the following structure - first we specify
   that the data come from a distribution with parameters \(\theta\)
   x \sim f(x\ | \ \theta)

   and that the parameters themselves come from another distribution with
   hyperparameters \(\lambda\)
   \theta \sim g(\theta \ | \ \lambda)

   and finally that \(\lambda\) comes from a prior distribution
   \lambda \sim h(\lambda)

   more levels of hierarchy are possible - i.e you can specify
   hyper-hyperparameters for the distribution of \(\lambda\) and so on.

   the essential idea of the hierarchical model is because the \(\theta\)s
   are not independent but rather are drawn from a common distribution
   with parameter \(\lambda\), we can share information across the
   \(\theta\)s by also estimating \(\lambda\) at the same time.

   as an example, suppose have data about the proportion of heads after
   some number of tosses from several coins, and we want to estimate the
   bias of each coin. we also know that the coins come from the same mint
   and so might share some common manufacturing defect. there are two
   extreme approaches - we could estimate the bias of each coin from its
   coin toss data independently of all the others, or we could pool the
   results together and estimate the same bias for all coins. hierarchical
   models provide a compromise where we shrink individual estimates
   towards a common estimate.

   note that because of the conditionally independent structure of
   id187, id150 is often a natural choice for the
   mcmc sampling strategy.

   suppose we have data of the number of failures (\(y_i\)) for each of 10
   pumps in a nuclear plant. we also have the times (\(_i\)) at which each
   pump was observed. we want to model the number of failures with a
   poisson likelihood, where the expected number of failure \(\lambda_i\)
   differs for each pump. since the time which we observed each pump is
   different, we need to scale each \(\lambda_i\) by its observed time
   \(t_i\).

   we now specify the hierarchical model - note change of notation from
   the overview above - that \(\theta\) is \(\lambda\) (parameter) and
   \(\lambda\) is \(\beta\) (hyperparameter) simply because \(\lambda\) is
   traditional for the poisson distribution parameter.

   the likelihood \(f\) is
   \prod_{i=1}^{10} \text{poisson}(\lambda_i t_i)

   we let the prior \(g\) for \(\lambda\) be
   \[ \begin{align}\begin{aligned}:nowrap:\\ \lambda \sim
   \text{gamma}(\alpha, \beta)\\with :math:`\alpha = 1.8` (an improper
   prior whose integral does not\end{aligned}\end{align} \]

   sum to 1)

   and let the hyperprior \(h\) for \(\beta\) to be
   \beta \sim \text{gamma}(\gamma, \delta)

   with \(\gamma = 0.01\) and \(\delta = 1\).

   there are 11 unknown parameters (10 \(\lambda\)s and \(\beta\)) in this
   hierarchical model.

   the posterior is
   p(\lambda, \beta \ | \ y, t) = \prod_{i=1}^{10}
   \text{poisson}(\lambda_i t_i) \times \text{gamma}(\alpha, \beta) \times
   \text{gamma}(\gamma, \delta)

   with the conditional distributions needed for id150 given by
   p(\lambda_i \ | \ \lambda_{-i}, \beta, y, t) = \text{gamma}(y_i +
   \alpha, t_i + \beta)

   and
   p(\beta \ | \ \lambda, y, t) = \text{gamma}(10\alpha + \gamma, \delta +
   \sum_{i=1}^10 \lambda_i)
in [66]:

from numpy.random import gamma as rgamma # rename so we can use gamma for parame
ter name

in [67]:

def lambda_update(alpha, beta, y, t):
    return rgamma(size=len(y), shape=y+alpha, scale=1.0/(t+beta))

def beta_update(alpha, gamma, delta, lambd, y):
    return rgamma(size=1, shape=len(y) * alpha + gamma, scale=1.0/(delta + lambd
.sum()))

def gibbs(niter, y, t, alpha, gamma, delta):
    lambdas_ = np.zeros((niter, len(y)), np.float)
    betas_ = np.zeros(niter, np.float)

    lambda_ = y/t

    for i in range(niter):
        beta_ = beta_update(alpha, gamma, delta, lambda_, y)
        lambda_ = lambda_update(alpha, beta_, y, t)

        betas_[i] = beta_
        lambdas_[i,:] = lambda_

    return betas_, lambdas_

in [68]:

alpha = 1.8
gamma = 0.01
delta = 1.0
beta0 = 1
y = np.array([5, 1, 5, 14, 3, 19, 1, 1, 4, 22], np.int)
t = np.array([94.32, 15.72, 62.88, 125.76, 5.24, 31.44, 1.05, 1.05, 2.10, 10.48]
, np.float)
niter = 1000

in [69]:

betas, lambdas = gibbs(niter, y, t, alpha, gamma, delta)
print('%.3f' % betas.mean())
print('%.3f' % betas.std(ddof=1))
print(lambdas.mean(axis=0))
print(lambdas.std(ddof=1, axis=0))

2.517
0.702
[ 0.06868215  0.15056069  0.10317275  0.12202341  0.63105223  0.60574169
  0.82281696  0.80642704  1.28372441  1.83879696]
[ 0.02667919  0.08864888  0.03946587  0.03161263  0.28059977  0.13161654
  0.49599896  0.50922204  0.58418796  0.39279425]

in [70]:

plt.figure(figsize=(8, 16))
for i in range(len(lambdas.t)):
    plt.subplot(5,2,i+1)
    plt.plot(lambdas[::10, i]);
    plt.title('trace for $\lambda$%d' % i)
plt.tight_layout()

   _images/16a_mcmc_57_0.png
in [71]:

%load_ext version_information
%version_information numpy, scipy, matplotlib

the version_information extension is already loaded. to reload it, use:
  %reload_ext version_information

out[71]:

    software                      version
   python     3.5.1 64bit [gcc 4.2.1 (apple inc. build 5577)]
   ipython    4.0.1
   os         darwin 15.3.0 x86_64 i386 64bit
   numpy      1.10.4
   scipy      0.17.0
   matplotlib 1.5.1
   mon feb 29 19:45:30 2016 est
in [ ]:



[36]page contents

     * [37]metropolis and id150
          + [38]island hopping
               o [39]true population proportions
               o [40]estimated population proportions
               o [41]generic metropolis scheme
               o [42]apply to island hooper
          + [43]bayesian data analysis
               o [44]motivating example
                    # [45]analytical solution
                    # [46]numerical integration
               o [47]id115 (mcmc)
                    # [48]metropolis-hastings random walk algorithm for
                      estimating the bias of a coin
                    # [49]assessing for convergence
                    # [50]why does metropolis-hastings work?
                    # [51]one: there is a unique stationary state
                    # [52]two: the stationary state is the posterior
                      id203 distribution
               o [53]intuition
               o [54]the gibbs sampler
               o [55]motivating example
                    # [56]setup
                    # [57]analytic solution
                    # [58]grid approximation
                    # [59]metropolis
                    # [60]gibbs
          + [61]id187

previous page

   [62]    numerical evaluation of integrals

next page

   [63]    using auxiliary variables in mcmc proposals

this page

     * [64]show source

quick search

   ____________________
   go

navigation

     * [65]index
     * [66]next
     * [67]previous
     * [68]computational statistics in python   

      copyright 2016, cliburn chan, janice mccarthy. created using
   [69]sphinx 1.5.

references

   1. http://people.duke.edu/~ccc14/sta-663-2016/genindex.html
   2. http://people.duke.edu/~ccc14/sta-663-2016/search.html
   3. http://people.duke.edu/~ccc14/sta-663-2016/16b_auxiliaryvariablemcmc.html
   4. http://people.duke.edu/~ccc14/sta-663-2016/15c_montecarlointegration.html
   5. http://people.duke.edu/~ccc14/sta-663-2016/genindex.html
   6. http://people.duke.edu/~ccc14/sta-663-2016/16b_auxiliaryvariablemcmc.html
   7. http://people.duke.edu/~ccc14/sta-663-2016/15c_montecarlointegration.html
   8. http://people.duke.edu/~ccc14/sta-663-2016/index.html
   9. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#metropolis-and-gibbs-sampling
  10. https://sites.google.com/site/doingbayesiandataanalysis/
  11. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#island-hopping
  12. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#true-population-proportions
  13. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#estimated-population-proportions
  14. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#generic-metropolis-scheme
  15. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#apply-to-island-hooper
  16. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#bayesian-data-analysis
  17. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#motivating-example
  18. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#analytical-solution
  19. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#numerical-integration
  20. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#markov-chain-monte-carlo-(mcmc)
  21. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#metropolis-hastings-random-walk-algorithm-for-estimating-the-bias-of-a-coin
  22. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#assessing-for-convergence
  23. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#why-does-metropolis-hastings-work?
  24. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#one:-there-is-a-unique-stationary-state
  25. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#two:-the-stationary-state-is-the-posterior-id203-distribution
  26. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#intuition
  27. https://eml.berkeley.edu/reprints/misc/understanding.pdf
  28. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#the-gibbs-sampler
  29. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#motivating-example
  30. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#setup
  31. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#analytic-solution
  32. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#grid-approximation
  33. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#metropolis
  34. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#gibbs
  35. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#hierarchical-models
  36. http://people.duke.edu/~ccc14/sta-663-2016/index.html
  37. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html
  38. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#island-hopping
  39. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#true-population-proportions
  40. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#estimated-population-proportions
  41. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#generic-metropolis-scheme
  42. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#apply-to-island-hooper
  43. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#bayesian-data-analysis
  44. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#motivating-example
  45. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#analytical-solution
  46. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#numerical-integration
  47. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#markov-chain-monte-carlo-(mcmc)
  48. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#metropolis-hastings-random-walk-algorithm-for-estimating-the-bias-of-a-coin
  49. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#assessing-for-convergence
  50. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#why-does-metropolis-hastings-work?
  51. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#one:-there-is-a-unique-stationary-state
  52. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#two:-the-stationary-state-is-the-posterior-id203-distribution
  53. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#intuition
  54. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#the-gibbs-sampler
  55. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#motivating-example
  56. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#setup
  57. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#analytic-solution
  58. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#grid-approximation
  59. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#metropolis
  60. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#gibbs
  61. http://people.duke.edu/~ccc14/sta-663-2016/16a_mcmc.html#hierarchical-models
  62. http://people.duke.edu/~ccc14/sta-663-2016/15c_montecarlointegration.html
  63. http://people.duke.edu/~ccc14/sta-663-2016/16b_auxiliaryvariablemcmc.html
  64. http://people.duke.edu/~ccc14/sta-663-2016/_sources/16a_mcmc.ipynb.txt
  65. http://people.duke.edu/~ccc14/sta-663-2016/genindex.html
  66. http://people.duke.edu/~ccc14/sta-663-2016/16b_auxiliaryvariablemcmc.html
  67. http://people.duke.edu/~ccc14/sta-663-2016/15c_montecarlointegration.html
  68. http://people.duke.edu/~ccc14/sta-663-2016/index.html
  69. http://sphinx-doc.org/
