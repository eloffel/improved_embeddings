   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]hacker noon
     * [9]latest
     * [10]editors' choice
     * [11]terms faq
     * [12]sign up for 2.0
     * [13]future of search
     __________________________________________________________________

     latest deep learning ocr with keras and supervisely in 15 minutes

   [14]go to the profile of supervise.ly
   [15]supervise.ly (button) blockedunblock (button) followfollowing
   nov 2, 2017
   [1*izw3q79nyalmgnyf2jsvjw.png]

   hello world. this tutorial is a gentle introduction to building modern
   text recognition system using deep learning in 15 minutes. it will
   teach you the main ideas of how to use [16]keras and [17]supervisely
   for this problem. this guide is for anyone who is interested in using
   deep learning for text recognition in images but has no idea where to
   start.

   we are going to consider simple real-world example: number plate
   recognition. this is a good start point and you can easily customize it
   for your task. simple tutorial on how to detect number plates you can
   find [18]here.
   [1*ajdyalj2e6sh5f63fwlhjq.jpeg]

   when we dove into this field we faced a lack of materials in the
   internet. through long research and reading many papers we have
   developed an understanding of main principles behind creating effective
   recognition systems. and we have shared our understanding with
   community in two small video lectures ([19]part1 and [20]part2) and
   explain how it works in plain language. we feel that this content is
   extremely valuable, because it is impossible to find nice and simple
   explanation of how to build modern recognition systems. we highly
   recommended to watch them before you start, because they will give you
   a lot of intuition behind this topic.

   to pass this tutorial without problems, you will need ubuntu, gpu and
   docker.

   all sources are available at [21]github. source code is located at a
   [22]single jupyther notebook with comments and useful visualizations.
   [1*bgdbutixewy-ihcliqpw2w.png]

where to get training data?

   for this tutorial we have generated artificial dataset of more than 10k
   images that are very similar to real number plates. the images look
   like this.
   [1*llakc12-c5fe-l9ec-z5fw.png]
   [1*fihytfdk_m3lgdp5f7kvwa.png]
   [1*hws4o_kuqvi45lm7b-nvmq.png]
   [1*q6ows1tqceocshjhhht8jg.png]
   [1*aisu0dv2n7ogfxa8dpr2dg.png]
   [1*znk7hkv2qp2uhkrwcnghvw.png]
   [1*l4f9-laijyywsmnmxf-oyq.png]
   [1*x1xvlranzjc2wyfsproocw.png]
   [1*ud3egyd7cq0idhgq3mtqsa.png]

   you can easily get this dataset from [23]supervisely. let us say a few
   words about it. we at [24]deepsystems do a lot of id161
   developments like [25]self-driving car, receipt recognition system,
   [26]road defect detection and so on. we as data scientists spend a lot
   of time to working with training data: creating custom image
   annotations, merging our data with public datasets, making data
   augmentations and so on. [27]supervisely simplifies the way you work
   with training data and automate many routine tasks. we believe you   ll
   find it useful in your everyday work.

   the first step is to [28]register in [29]supervisely. the next step is
   to go to    import    ->    datasets library    tab and click to    anpr_ocr   
   project.
   [1*1vptjfpxr5bgvxwymxodjg.png]

   after that type name    anpr_ocr    and click    next    button.
   [1*iufop3mn-qfqtewnfzmhmw.png]

   then click    upload    button. that   s all. now the project    anpr_ocr    is
   added to your account.
   [1*do_iukxhsosneagyvb0p9g.png]

   it consists of two datasets:    train    and    test   .
   [1*mbw72dkztjp5dbppctdrrg.png]

   if you want to preview images, just click to dataset and you will
   instantly get into annotation tool. for each image we have a text
   description that will be used as ground truth to train our system. to
   view it just click to small icon opposite the selected image (market in
   red).
   [1*pndhlot6afn29kk0_fcymw.png]

   now we have to download it in a specific format. to do it just click to
      dtl    page and insert this [30]config to text area. it will look like
   this.
   [1*-xnbtqoydcpdildrsx6w1g.png]

   in the screenshot above you can see the scheme illustrating the export
   steps. we will not dig into technical details (you can read the
   [31]documentation if needed) but try to explain this process below. in
   our    anpr_ocr    project we have two datasets.    test    dataset is exported
   as is(all images will be tagged as    test   ).    train    dataset is splitted
   to two sets:    train    and    val   . random 95 percent of images will be
   tagged as    train   , and the rest 5 percent as    val   .

   now you can click    start    button and wait two minutes while the system
   prepare archive to download. click    dtl    ->    task status    ->    three
   vertical dots    ->    download    button to get training data (marked in
   red).
   [1*hk4d-muok6y-qhx8g5kp3q.jpeg]

let   s start our experiment

   we prepared all you need in our [32]git repository. clone it with the
   following commands
git clone [33]https://github.com/deepsystems/supervisely-tutorials.git
cd supervisely-tutorials/anpr_ocr

   directory structure will be the following
.
          data
          docker
                build.sh
                dockerfile
                run.sh
          src
              architecture.png
              export_config.json
              image_ocr.ipynb

   put downloaded zip archive into    data    directory and run the command
   below
unzip <archive name>.zip -d .

   in my case the command was
unzip anpr_ocr.zip -d .

   now lets build and run docker container with prepared working
   environment (tensorflow and keras). just go to    docker    directory and
   run the following commands
./build.sh
./run.sh

   after that you will be inside the container. run next command to start
   jupyther notebook
jupyter notebook

   in terminal you will see something like this
   [1*wesv-tanld1xvapnznh6fq.png]

   you have to copy selected link and paste it into web browser. notice,
   that your link will be slightly different from mine.

   the last step is to run whole    image_ocr.ipynb    notebook. click    cell   
   ->    run all   .

   notebook consists of few main parts: data loading and visualisation,
   model training, model evaluation on test set. on average for this
   dataset training process takes around 30 minutes.

   if everything will be ok, you   ll see the following output
   [1*-jepmeyuhscvcurobns_hw.png]

   as you can see, the predicted string will be the same as ground truth.
   thus we have constructed the modern ocr system in one pretty [34]clear
   jupyther notebook. in the next chapter of this tutorial we will cover
   and explain all main principles of how it works.

how it works

   as for us, the understanding of neural network architecture is the key.
   please, don   t be lazy and take 15 minutes to watch our small and simple
   [35]video lecture about high level overview of nn architecture, that
   was mentioned at the beginning. it will give you general understanding.
   if you have already done         bravo! :-)

   here i will try to give you short explanation. high level overview is
   the following
   [1*sdb9_e5lvsjnxivblcfxeg.png]

   firstly, image is feeded to id98 to extract image features. the next
   step is to apply [36]recurrent neural network to these features
   followed by the special decoding algorithm. this decoding algorithm
   takes lstm outputs from each time step and produces the final labeling.

   detailed architecture will be the following. fc         fully connected
   layer, sm         softmax layer.
   [1*ppxhsm2dkhth6lotlkinfg.png]

   image has the following shape: height equals to 64, width equals to 128
   and num channels equal to three.

   as you have seen before we feed this image tensor to id98 feature
   extractor and it produces tensor with shape 4*8*4. we put image    apple   
   to the feature tensor so you can understand how to interpret it. height
   equals to 4, width equals to 8 (these are spatial dimentions) and num
   channels equals to 4. thus we transform input image with 3 channels to
   4 channel tensor. in practice number of channels should be much larger,
   but we constructed small demo network only because everything fit on
   the slide.

   next we do reshape operation. after that we obtain the sequence of 8
   vectors of 16 elements. after that we feed these 8 vectors to the lstm
   network and get its output         also the vectors of 16 elements. then we
   apply fully connected layer followed by softmax layer and get the
   vector of 6 elements. this vector contains id203 distribution of
   observing alphabet symbols at each lstm step.

   in practice, the number of id98 output vectors can reach 32, 64 or more.
   the choice will depend on the specific task. also in production it is
   better to use multilayered bidirectional lstm. but this simple example
   explains only most important concepts.

   but how does decoding algorithm work? on the above diagram we have
   eight vectors of probabilities at each lstm time step. let   s take most
   probable symbol at each time step. as a result we obtain the string of
   eight characters         one most probable letter at each time step. then we
   have to glue all consecutive repeating characters into one. in our
   example two    e    letters are glued to single one. special blank
   character allows us to split symbols that are repeated in the original
   labeling. we added blank symbol to the alphabet to teach our neural
   network to predict blank between such case symbols. then we remove all
   blank symbols. look at the illustration below
   [1*jommmj4lxy4quhd4qjkd_g.png]

   when we train our network we replace decoding algorithm with ctc loss
   layer. it is explained in our second video lecture. now it is available
   only in russian, sorry about it. but the good news are: we have english
   slides and we will publish english version soon.

   a bit complex nn architecture is used in our implementation. the
   architecture is the following, but the main principles are still the
   same.
   [1*myhddocct2gqrccnxkeqya.png]

   after the model training we apply it on images from test set and get
   really high accuracy. we also visualize id203 distributions from
   each id56 step as a matrix. here is the example.
   [1*drhzxqnlpry5vuyt7rhadw.png]

   the rows of this matrix are correspond to all alphabet symbols plus
      blank   . columns correspond to id56 steps.

conclusion

   we are happy to share our experience with community. we believe that
   video lectures, this tutorial, ready-to-use artificial data and source
   code will help you get basic intuition and that everyone can build
   modern ocr system from scratch.

   feel free to ask any questions! thank you!

     * [37]machine learning
     * [38]ai
     * [39]deep learning
     * [40]tutorial
     * [41]data science

   (button)
   (button)
   (button) 3.1k claps
   (button) (button) (button) 42 (button) (button)

     (button) blockedunblock (button) followfollowing
   [42]go to the profile of supervise.ly

[43]supervise.ly

   first available ide for id161: supervise.ly (made in
   deepsystems.ai)

     (button) follow
   [44]hacker noon

[45]hacker noon

   how hackers start their afternoons.

     * (button)
       (button) 3.1k
     * (button)
     *
     *

   [46]hacker noon
   never miss a story from hacker noon, when you sign up for medium.
   [47]learn more
   never miss a story from hacker noon
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://hackernoon.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/34aecd630ed8
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://hackernoon.com/latest-deep-learning-ocr-with-keras-and-supervisely-in-15-minutes-34aecd630ed8&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://hackernoon.com/latest-deep-learning-ocr-with-keras-and-supervisely-in-15-minutes-34aecd630ed8&source=--------------------------nav_reg&operation=register
   8. https://hackernoon.com/?source=logo-lo_eugdbitnybwp---3a8144eabfe3
   9. https://hackernoon.com/latest-tech-stories/home
  10. https://hackernoon.com/editors-top-tech-stories/home
  11. https://hackernoon.com/your-most-frequently-asked-questions-about-our-terms-of-service-how-to-opt-out-and-more-66abf239a151
  12. https://hackernoon.com/sign-up-for-hacker-noon-2-0-9ff1ea0b60cc
  13. https://community.hackernoon.com/t/what-will-replace-google-search/992/14
  14. https://hackernoon.com/@deepsystems?source=post_header_lockup
  15. https://hackernoon.com/@deepsystems
  16. https://keras.io/
  17. https://supervise.ly/
  18. https://medium.com/towards-data-science/number-plate-detection-with-supervisely-and-tensorflow-part-1-e84c74d4382c
  19. https://medium.com/towards-data-science/lecture-on-how-to-build-a-recognition-system-part-1-best-practices-46208e1ae591
  20. https://goo.gl/kwwr48
  21. https://github.com/deepsystems/supervisely-tutorials
  22. https://github.com/deepsystems/supervisely-tutorials/blob/master/anpr_ocr/src/image_ocr.ipynb
  23. https://supervise.ly/
  24. https://deepsystems.ai/
  25. https://deepsystems.ai/solutions/autonomous-driving
  26. https://deepsystems.ai/solutions/road-defects-detection
  27. https://supervise.ly/
  28. https://app.supervise.ly/signup
  29. https://supervise.ly/
  30. https://github.com/deepsystems/supervisely-tutorials/blob/master/anpr_ocr/src/export_config.json
  31. https://docs.supervise.ly/
  32. https://github.com/deepsystems/supervisely-tutorials
  33. https://github.com/deepsystems/supervisely-tutorials.git
  34. https://github.com/deepsystems/supervisely-tutorials/blob/master/anpr_ocr/src/image_ocr.ipynb
  35. https://youtu.be/uvbockyuemo
  36. https://medium.com/towards-data-science/lecture-evolution-from-vanilla-id56-to-gru-lstms-58688f1da83a
  37. https://hackernoon.com/tagged/machine-learning?source=post
  38. https://hackernoon.com/tagged/ai?source=post
  39. https://hackernoon.com/tagged/deep-learning?source=post
  40. https://hackernoon.com/tagged/tutorial?source=post
  41. https://hackernoon.com/tagged/data-science?source=post
  42. https://hackernoon.com/@deepsystems?source=footer_card
  43. https://hackernoon.com/@deepsystems
  44. https://hackernoon.com/?source=footer_card
  45. https://hackernoon.com/?source=footer_card
  46. https://hackernoon.com/
  47. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  49. https://medium.com/p/34aecd630ed8/share/twitter
  50. https://medium.com/p/34aecd630ed8/share/facebook
  51. https://medium.com/p/34aecd630ed8/share/twitter
  52. https://medium.com/p/34aecd630ed8/share/facebook
