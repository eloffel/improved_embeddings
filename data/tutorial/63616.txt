                                  magic paper

   working notes by [1]michael nielsen, november 2017. followup to (but
   doesn't require) my [2]notes on chalktalk.

     [technology] transforms what can be said and what is said    all major
     advances in consciousness depend on technological transformations in
     implementations of the word.     walter ong, interfaces of the word
     (1977).

   mathematical ideas are conventionally expressed using notation and
   terminology developed using static media. suppose, however, that
   mathematics had been invented after modern computers. this is perhaps
   difficult to imagine     after all, mathematics helped lead to computers
       but let's do the thought experiment anyway. might mathematical
   notation have developed in a different way? would we instead have
   developed a dynamic, interactive notation more powerful than the static
   mathematical and linguistic notations in common use today?

   as part of my exploration of this question, i recently developed a
   simple prototype system, which i call magic paper ([3]code). to get a
   feel for what the system does, below is a video of me using magic paper
   to explain the (very simple!) basic idea underlying the proof of a
   beautiful theorem about id158s: the result that
   neural nets may be used to approximate any continuous function** see
   [4]approximation by superpositions of sigmoidal function, by george
   cybenko (1989), and [5]multilayer feedforward networks are universal
   approximators, by kurt hornik, maxwell stinchcombe, and halbert white
   (1989).. note that you do not need to be deeply familiar with neural
   networks to follow along; an introduction to the basics of neural nets
   may be found [6]here. you may wish to fullscreen the video, for easier
   viewing:

   iframe: [7]https://www.youtube.com/embed/ijqkc7oleni?rel=0&showinfo=0

   the design of magic paper was inspired in part by a system developed by
   ken perlin, known as chalktalk. chalktalk has not been publicly
   released at the time of this writing (november 2017)** update:
   chalktalk has since been released, see [8]here., but you can get some
   understanding of the system by viewing from 32:40 to the end of the
   following video:

   iframe: [9]https://www.youtube.com/embed/xuzrf_82z7u?start=1960

  can a visual medium be used to do serious mathematical exploration?

   i built magic paper to explore two questions not directly addressed by
   chalktalk.

   the first question is whether such a visual medium can be used to do
   serious mathematical exploration, the kind a researcher might do when
   working on a research problem. in other words: can such a system be
   used as a medium for creative thought? while chalktalk is a fun medium
   to explore in, it's not obvious to me that it's suitable for the kind
   of exploration that arises in mathematical work.

   of course, it's too ambitious for such a quickly-built prototype medium
   to be useable across all of mathematics. and so i decided to narrow the
   question, and ask whether such a medium could be used to explore at
   least one non-trivial mathematical question; concretely: can neural
   nets be used to approximate any function?

   while focusing on one problem is much easier than building a
   general-purpose exploratory mathematical medium, it's still an
   extremely demanding and thus informative constraint. furthermore, it
   seems likely that patterns useful in solving one mathematical problem
   will be reuseable in solving others.

   in fact, even this is too demanding. the idea for a proof presented
   above wasn't actually discovered in this medium. it's a proof taken
   from my book on neural networks** michael a. nielsen, [10]neural
   networks and deep learning (chapter 4), determination press (2015). .
   despite this, i believe this context     explaining the idea underlying
   the proof of a relatively recent mathematical result     is a good one
   for understanding what is required for a general-purpose exploratory
   mathematical medium.

   note that while the video of magic paper perhaps makes it appear to be
   explanatory or educational in intent, that is not the case. it is
   intended primarily to be a medium to think and explore in, and only
   secondarily to explain or to educate in. while these goals are
   sometimes congruent, they are also often in tension.

   as an example of this tension, explanatory media are often highly
   polished, presenting a finished product from which distracting elements
   have been eliminated. by contrast, exploration involves distractions,
   wrong paths, and dead ends. one sees this in myriad small ways in the
   video: the frequent readjustment of the position and size of the
   glyphs; the various unnecessary weight and bias parameters that are
   sometimes shown; and so on. in a polished presentation these would have
   been eliminated, showing just what the viewer needs at any given
   moment. but such superfluous elements are inevitable in exploration.

   another example of the tension between education and exploration comes
   from the programming language logo. logo is often touted as an example
   of discovery-based learning, and in many respects it's a good
   exploratory medium for mathematics. however, while logo has had
   considerable success in helping children understand ideas about
   differential geometry, differential geometers do not, as far as i'm
   aware, use it as a medium for research. that's potentially a problem:
   when education and real practice are separated, it can result in busy
   work on poorly-motivated    educational    problems. an interesting project
   would be to create a single environment which can be used for both
   education and research. i am optimistic this is possible; after all,
   beginning chess players use the same board and the same moves as the
   world champion.

  can we reify deep ideas about mathematics inside the magic paper interface?

   the second question motivating magic paper was whether it is possible
   to reify deep ideas about mathematics inside the interface. that sounds
   cryptic, but has a straightforward meaning. to explain that meaning,
   let's briefly switch topic, and recall an idea from elementary physics,
   the principle of conservation of energy:

                            mv^2 + u(x) = constant

   the basic point is that there's some relationship between the mass of a
   particle, m, its velocity v, its position x, and its potential energy
   u(x). the way physics is ordinarily done, we manipulate this expression
   using algebraic operations. but a different approach is possible. in my
   essay    thought as a technology   ** michael nielsen, [11]thought as a
   technology, available at http://cognitivemedium.com/tat/index.html
   (2016). i develop a prototype interface which reifies the principle of
   conservation of energy. in particular, the prototype vividly shows the
   user the relationship between mass, position, velocity and potential
   energy. this makes it possible to directly see and adjust the potential
   energy, see how the trajectories respond, and so on. this gives a
   unique and rich experience, one enabling the user to internalize a
   powerful set of cognitive technologies for thinking about motion.

   chalktalk-like media seem promising for reifying such principles.
   unfortunately, as far as i'm aware there are no general results about
   neural networks as powerful as conservation of energy. however, as a
   step in this direction, directly seeing the relationship between the
   parameters of a network and the output of various neurons does help us
   understand the behaviour of the network. further work could incorporate
   deeper ideas about neural networks, such as learning by gradient
   descent, or id173, or ways of visualizing the network** a nice
   recent example is the paper by jason yosinksi, jeff clune, anh nguyen,
   thomas fuchs, and hod lipson, on [12]understanding neural networks
   through deep visualization icml (2015).. it'd also be interesting to
   develop such an interface in a context where more deep principles are
   available     perhaps using magic paper to explore (say) chaotic
   dynamical systems, using ideas such as conservation of energy,
   conservation of phase space volume, lyapunov exponents, and the kam
   theorem. building such ideas into the interface would make them a
   routine, concrete part of the way the user works and thinks.

  why not just key commands?

   instead of drawing a neuron, why not just hit    n   ? instead of drawing
   axes, why not just hit    g   , for    graph   ? wouldn't such keystrokes be
   faster and easier?

   this question has bothered me ever since first seeing perlin
   demonstrate chalktalk. even as an audience member, i found it much more
   satisfying to see him draw a glyph than to just hit a key and have it
   appear. and this effect was even stronger as a user of magic paper.

   i don't have a satisfactory understanding of why it's satisfying to do
   this. perhaps it's because the act of drawing activates associations in
   my brain that wouldn't have been activated as strongly by issuing a key
   command. in this sense, the act of drawing is far more meaningful     and
   meaning-inducing     than hitting a key. it's a little like the reasons
   we don't name a variable meant to represent someone's name as jnwhg;
   it's more meaningful to use name. or the reasons it's better to use a
   map of a coastline to navigate, rather than a log of latitudes and
   longitudes for points on the coast.

   unfortunately, while such explanations are suggestive they're vague and
   incomplete. and yet my lived experience is that this is a strong
   effect. something similar is true of physical activities, such as
   tennis or dance: there is an enormous difference between a symbolic
   representation     say, reading about tennis     versus actually doing it.
   now, for the most part, we tend to think of these activities as a
   special class of    physical    activities, different from    mental   
   activities such as mathematics. yet i'm not sure the distinction is all
   that sharp.

   more broadly, advocates of embodied cognition often make strong claims
   about its importance. as far as i can see, the evidence they have for
   those claims is weak. and yet while the specific claims may be weak or
   wrong, i believe there is some strong and important underlying effect.
   it really does greatly help my thinking to sketch the glyphs in magic
   paper. i just don't understand why.

  working within the system

   i began the design work for magic paper with paper-and-pen storyboards
   and a text-based script for my video. as i developed the storyboards
   and script i also began to develop the system. very quickly, the system
   was powerful enough that i could do basic sketches. once that point was
   reached, it was more stimulating (and easier) to work within the new
   medium, and to abandon the storyboards and script.

   i initially felt guilty at abandoning the storyboards and script, as
   though that was somehow the    correct    way of working. but working in
   the new medium quickly began to suggest useful ideas that i do not
   believe i would otherwise have anticipated.

   as an example, in the final video we often see multiple graphs showing
   the behaviour of several different neurons in a network. this makes it
   easy for the viewer to understand the behaviours of different parts of
   the network, and to put it all together:

                            [multiple_graphs.png]

   by contrast, my initial storyboards and script had just a single output
   graph. it was only after i began using the medium that i realized it
   was possible to use the graphs in this way. in particular, i didn't
   design the system so it could plot the behavior of intermediate
   neurons. rather, that was a fortuitous happenstance, tried
   spontaneously as i used the medium.

   another point i did not anticipate in storyboarding and scripting was
   how useful it would be to move and resize the neurons and the graphs,
   e.g.:

                            [movement_edited.gif]

   a big benefit of this is object persistence. when possible, it's often
   useful to reuse or repurpose existing objects, since viewers have
   already built strong mental models of their behaviour. this kind of
   dynamic reuse is harder to achieve in static media. perhaps for that
   reason i did not anticipate it in my storyboarding and scripting.

   by contrast, my earlier description of this proof in an online book
   consisted of text interspersed with interactive elements, e.g.:
   [nnadl_4_pt1.png] [nnadl_4_pt2.png]

   many of the interactive elements depict minor variations on the same
   system. but because there is no object persistence, the user must parse
   each one separately, and put in the mental work required to understand
   the relationships. for the most part this is not terribly hard work,
   but it is an additional mental burden.

   all told, while the script and storyboards were useful to bootstrap,
   once the medium was running, it was more generative to work directly
   within that, experimenting and evolving an approach i was comfortable
   with.

  extensions: abstracting glyphs, re-parameterization, glyph design

   here are three extensions that could be added to magic paper with 40 to
   50 hours of additional work.

   first, it should be possible to    lasso    several elements, combining
   them into a single new glyph. for instance, we could lasso the
   two-neuron gadget used to build tower functions, and turn it into a
   single re-usable glyph. that abstracted glyph could then be duplicated,
   moved, its parameters edited, and so on, just as any other glyph. it
   would also be possible to inspect the internal state of the abstracted
   glyph, making it possible to understand multiple layers of abstraction.

   second, it should be possible to re-parameterize the abstracted glyph,
   so it has just three parameters, representing the height of the tower
   function, a starting x value, and a finishing x value. these three
   parameters would then determine the biases and weights of the
   underlying elements. this could be implemented with a simple expression
   parser.

   third, it should be possible to integrate an image editor enabling the
   addition of extra glyphs to magic paper's visual language. amongst
   other things, such an editor could be used to add unique visual
   representations for the abstracted glyphs.

  conclusion

   my research colleagues sometimes express puzzlement at my interest in
   new media forms. they often treat it as fun but not especially serious
   work. to them, advanced research usually means work on esoteric
   subjects. but people working on new media forms have the opportunity to
   rethink absolutely fundamental concepts such as number, equality, and
   so on; such work is about rethinking what mathematics and language is.
   i believe such experiments will eventually affect and perhaps transform
   the way all research is done. but it will take a huge effort, since
   this kind of rethinking is not an individual-sized problem, it is a
   civilization-sized problem, and we're just getting started.

acknowledgements

   thanks to shan carter, nicky case, andy matuschak, robert ochshorn,
   kanjun qiu, grant sanderson, and jack schaedler for helpful
   discussions.

citation

   in academic work, please cite this as: michael nielsen, [13]   magic
   paper   , available at http://cognitivemedium.com/magic_paper/index.html
   (2017).

further reading

   michael nielsen, [14]toward an exploratory medium for mathematics
   (2016).

   michael nielsen, [15]thought as a technology (2016).

   bret victor, [16]kill math (2011). see also my [17]notes on kill math
   (2014).

   bret victor, [18]media for thinking the unthinkable (2013).

   bret victor, [19]magic ink (2006).

   seymour papert, [20]mindstorms: children, computers, and powerful ideas
   (1980).

   jason brennan, scott farrar, natalie fitzgerald, may-li khoe, and andy
   matuschak, [21]playful worlds of creative math: a design exploration
   (2017).

licensing

   this work is licensed under a [22]creative commons
   attribution-noncommercial 3.0 unported license . this means you're free
   to copy, share, and build on it, but not to sell it. if you're
   interested in commercial use, please [23]contact me. [24]creative
   commons licence

references

   1. http://michaelnielsen.org/
   2. http://cognitivemedium.com/interfaces-1/index.html
   3. https://github.com/mnielsen/magic_paper
   4. http://cognitivemedium.com/magic_paper/assets/cybenko.pdf
   5. http://cognitivemedium.com/magic_paper/assets/hornik.pdf
   6. http://neuralnetworksanddeeplearning.com/chap1.html
   7. https://www.youtube.com/embed/ijqkc7oleni?rel=0&showinfo=0
   8. https://github.com/kenperlin/chalktalk
   9. https://www.youtube.com/embed/xuzrf_82z7u?start=1960
  10. http://neuralnetworksanddeeplearning.com/chap4.html
  11. http://cognitivemedium.com/tat/index.html
  12. http://cognitivemedium.com/magic_paper/assets/yosinski2015a.pdf
  13. http://cognitivemedium.com/magic_paper/index.html
  14. http://cognitivemedium.com/emm/emm.html
  15. http://cognitivemedium.com/tat/index.html
  16. http://worrydream.com/killmath/
  17. http://mnielsen.github.io/notes/kill_math/kill_math.html
  18. http://worrydream.com/mediaforthinkingtheunthinkable/
  19. http://worrydream.com/magicink/
  20. https://mindstorms.media.mit.edu/
  21. https://www.khanacademy.org/research/reports/early-math
  22. http://creativecommons.org/licenses/by-nc/3.0/deed.en_gb
  23. mailto:mn@michaelnielsen.org
  24. http://creativecommons.org/licenses/by-nc/3.0/deed.en_gb
