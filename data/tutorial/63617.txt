   #[1]github [2]recent commits to pretrained-models.pytorch:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]167
     * [35]star [36]3,830
     * [37]fork [38]808

[39]cadene/[40]pretrained-models.pytorch

   [41]code [42]issues 35 [43]pull requests 3 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   pretrained convnets for pytorch: nasnet, resnext, resnet, inceptionv4,
   inceptionresnetv2, xception, dpn, etc.
   [47]id163 [48]resnet [49]resnext [50]pretrained [51]pytorch
   [52]inception
     * [53]152 commits
     * [54]4 branches
     * [55]0 releases
     * [56]fetching contributors
     * [57]bsd-3-clause

    1. [58]python 99.7%
    2. [59]lua 0.3%

   (button) python lua
   branch: master (button) new pull request
   [60]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/c
   [61]download zip

downloading...

   want to be notified of new releases in
   cadene/pretrained-models.pytorch?
   [62]sign in [63]sign up

launching github desktop...

   if nothing happens, [64]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [65]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [66]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [67]download the github extension for visual studio
   and try again.

   (button) go back
   [68]@cadene
   [69]cadene [70]update id163_eval.py to torch 1.0.x
   latest commit [71]021d978 apr 4, 2019
   [72]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [73]data [74]remove lena sep 2, 2018
   [75]examples [76]update id163_eval.py to torch 1.0.x apr 3, 2019
   [77]pretrainedmodels [78]merge pull request [79]#122 [80]from
   ekagra-ranjan/patch-1 mar 23, 2019
   [81]tests
   [82].gitignore
   [83].travis.yml
   [84]license.txt
   [85]readme.md
   [86]requirements.txt
   [87]setup.id18
   [88]setup.py

readme.md

pretrained models for pytorch (work in progress)

   the goal of this repo is:
     * to help to reproduce research papers results (id21
       setups for instance),
     * to access pretrained convnets with a unique interface/api inspired
       by torchvision.

   [89][68747470733a2f2f6170692e7472617669732d63692e6f72672f436164656e652f
   707265747261696e65642d6d6f64656c732e7079746f7263682e7376673f6272616e636
   83d6d6173746572]

   news:
     * 27/10/2018: fix compatibility issues, add tests, add travis
     * 04/06/2018: [90]polynet and [91]pnasnet-5-large thanks to [92]alex
       parinov
     * 16/04/2018: [93]se-resnet* and se-resnext* thanks to [94]alex
       parinov
     * 09/04/2018: [95]senet154 thanks to [96]alex parinov
     * 22/03/2018: cafferesnet101 (good for localization with fasterrid98)
     * 21/03/2018: nasnet mobile thanks to [97]veronika yurchuk and
       [98]anastasiia
     * 25/01/2018: dualpathnetworks thanks to [99]ross wightman, xception
       thanks to [100]t standley, improved transformimage api
     * 13/01/2018: pip install pretrainedmodels,
       pretrainedmodels.model_names, pretrainedmodels.pretrained_settings
     * 12/01/2018: python setup.py install
     * 08/12/2017: update data url (/!\ git pull is needed)
     * 30/11/2017: improve api (model.features(input),
       model.logits(features), model.forward(input), model.last_linear)
     * 16/11/2017: nasnet-a-large pretrained model ported by t. durand and
       r. cadene
     * 22/07/2017: torchvision pretrained models
     * 22/07/2017: momentum in inceptionv4 and inceptionresnetv2 to 0.1
     * 17/07/2017: model.input_range attribut
     * 17/07/2017: bninception pretrained on id163

summary

     * [101]installation
     * [102]quick examples
     * [103]few use cases
          + [104]compute id163 logits
          + [105]compute id163 validation metrics
     * [106]evaluation on id163
          + [107]accuracy on valset
          + [108]reproducing results
     * [109]documentation
          + [110]available models
               o [111]alexnet
               o [112]bninception
               o [113]cafferesnet101
               o [114]densenet121
               o [115]densenet161
               o [116]densenet169
               o [117]densenet201
               o [118]densenet201
               o [119]dualpathnet68
               o [120]dualpathnet92
               o [121]dualpathnet98
               o [122]dualpathnet107
               o [123]dualpathnet113
               o [124]fbresnet152
               o [125]inceptionresnetv2
               o [126]inceptionv3
               o [127]inceptionv4
               o [128]nasnet-a-large
               o [129]nasnet-a-mobile
               o [130]pnasnet-5-large
               o [131]polynet
               o [132]resnext101_32x4d
               o [133]resnext101_64x4d
               o [134]resnet101
               o [135]resnet152
               o [136]resnet18
               o [137]resnet34
               o [138]resnet50
               o [139]senet154
               o [140]se-resnet50
               o [141]se-resnet101
               o [142]se-resnet152
               o [143]se-resnext50_32x4d
               o [144]se-resnext101_32x4d
               o [145]squeezenet1_0
               o [146]squeezenet1_1
               o [147]vgg11
               o [148]vgg13
               o [149]vgg16
               o [150]vgg19
               o [151]vgg11_bn
               o [152]vgg13_bn
               o [153]vgg16_bn
               o [154]vgg19_bn
               o [155]xception
          + [156]model api
               o [157]model.input_size
               o [158]model.input_space
               o [159]model.input_range
               o [160]model.mean
               o [161]model.std
               o [162]model.features
               o [163]model.logits
               o [164]model.forward
     * [165]reproducing porting
          + [166]resnet*
          + [167]resnext*
          + [168]inception*

installation

    1. [169]python3 with anaconda
    2. [170]pytorch with/out cuda

install from pip

    3. pip install pretrainedmodels

install from repo

    3. git clone https://github.com/cadene/pretrained-models.pytorch.git
    4. cd pretrained-models.pytorch
    5. python setup.py install

quick examples

     * to import pretrainedmodels:

import pretrainedmodels

     * to print the available pretrained models:

print(pretrainedmodels.model_names)
> ['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'incept
ionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet2
01', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'
, 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13',
 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetalarge', 'nasnetam
obile', 'cafferesnet101', 'senet154',  'se_resnet50', 'se_resnet101', 'se_resnet
152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'polynet',
'pnasnet5large']

     * to print the available pretrained settings for a chosen model:

print(pretrainedmodels.pretrained_settings['nasnetalarge'])
> {'id163': {'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge
-a1897284.pth', 'input_space': 'rgb', 'input_size': [3, 331, 331], 'input_range'
: [0, 1], 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'num_classes': 1000},
 'id163+background': {'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nas
netalarge-a1897284.pth', 'input_space': 'rgb', 'input_size': [3, 331, 331], 'inp
ut_range': [0, 1], 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'num_classes
': 1001}}

     * to load a pretrained models from id163:

model_name = 'nasnetalarge' # could be fbresnet152 or inceptionresnetv2
model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imag
enet')
model.eval()

   note: by default, models will be downloaded to your $home/.torch
   folder. you can modify this behavior using the $torch_model_zoo
   variable as follow: export torch_model_zoo="/local/pretrainedmodels
     * to load an image and do a complete forward pass:

import torch
import pretrainedmodels.utils as utils

load_img = utils.loadimage()

# transformations depending on the model
# rescale, center crop, normalize, and others (ex: tobgr, torange255)
tf_img = utils.transformimage(model)

path_img = 'data/cat.jpg'

input_img = load_img(path_img)
input_tensor = tf_img(input_img)         # 3x400x225 -> 3x299x299 size may diffe
r
input_tensor = input_tensor.unsqueeze(0) # 3x299x299 -> 1x3x299x299
input = torch.autograd.variable(input_tensor,
    requires_grad=false)

output_logits = model(input) # 1x1000

     * to extract features (beware this api is not available for all
       networks):

output_features = model.features(input) # 1x14x14x2048 size may differ
output_logits = model.logits(output_features) # 1x1000

few use cases

compute id163 logits

     * see [171]examples/id163_logits.py to compute logits of classes
       appearance over a single image with a pretrained model on id163.

$ python examples/id163_logits.py -h
> nasnetalarge, resnet152, inceptionresnetv2, inceptionv4, ...

$ python examples/id163_logits.py -a nasnetalarge --path_img data/cat.jpg
> 'nasnetalarge': data/cat.jpg' is a 'tiger cat'

compute id163 id74

     * see [172]examples/id163_eval.py to evaluate pretrained models on
       id163 valset.

$ python examples/id163_eval.py /local/common-data/id163_2012/images -a na
snetalarge -b 20 -e
> * acc@1 92.693, acc@5 96.13

evaluation on id163

accuracy on validation set (single model)

   results were obtained using (center cropped) images of the same size
   than during the training process.
            model               version     acc@1  acc@5
   pnasnet-5-large          [173]tensorflow 82.858 96.182
   [174]pnasnet-5-large     our porting     82.736 95.992
   nasnet-a-large           [175]tensorflow 82.693 96.163
   [176]nasnet-a-large      our porting     82.566 96.086
   senet154                 [177]caffe      81.32  95.53
   [178]senet154            our porting     81.304 95.498
   polynet                  [179]caffe      81.29  95.75
   [180]polynet             our porting     81.002 95.624
   inceptionresnetv2        [181]tensorflow 80.4   95.3
   inceptionv4              [182]tensorflow 80.2   95.3
   [183]se-resnext101_32x4d our porting     80.236 95.028
   se-resnext101_32x4d      [184]caffe      80.19  95.04
   [185]inceptionresnetv2   our porting     80.170 95.234
   [186]inceptionv4         our porting     80.062 94.926
   [187]dualpathnet107_5k   our porting     79.746 94.684
   resnext101_64x4d         [188]torch7     79.6   94.7
   [189]dualpathnet131      our porting     79.432 94.574
   [190]dualpathnet92_5k    our porting     79.400 94.620
   [191]dualpathnet98       our porting     79.224 94.488
   [192]se-resnext50_32x4d  our porting     79.076 94.434
   se-resnext50_32x4d       [193]caffe      79.03  94.46
   [194]xception            [195]keras      79.000 94.500
   [196]resnext101_64x4d    our porting     78.956 94.252
   [197]xception            our porting     78.888 94.292
   resnext101_32x4d         [198]torch7     78.8   94.4
   se-resnet152             [199]caffe      78.66  94.46
   [200]se-resnet152        our porting     78.658 94.374
   resnet152                [201]pytorch    78.428 94.110
   [202]se-resnet101        our porting     78.396 94.258
   se-resnet101             [203]caffe      78.25  94.28
   [204]resnext101_32x4d    our porting     78.188 93.886
   fbresnet152              [205]torch7     77.84  93.84
   se-resnet50              [206]caffe      77.63  93.64
   [207]se-resnet50         our porting     77.636 93.752
   [208]densenet161         [209]pytorch    77.560 93.798
   [210]resnet101           [211]pytorch    77.438 93.672
   [212]fbresnet152         our porting     77.386 93.594
   [213]inceptionv3         [214]pytorch    77.294 93.454
   [215]densenet201         [216]pytorch    77.152 93.548
   [217]dualpathnet68b_5k   our porting     77.034 93.590
   [218]cafferesnet101      [219]caffe      76.400 92.900
   [220]cafferesnet101      our porting     76.200 92.766
   [221]densenet169         [222]pytorch    76.026 92.992
   [223]resnet50            [224]pytorch    76.002 92.980
   [225]dualpathnet68       our porting     75.868 92.774
   [226]densenet121         [227]pytorch    74.646 92.136
   [228]vgg19_bn            [229]pytorch    74.266 92.066
   nasnet-a-mobile          [230]tensorflow 74.0   91.6
   [231]nasnet-a-mobile     our porting     74.080 91.740
   [232]resnet34            [233]pytorch    73.554 91.456
   [234]bninception         our porting     73.524 91.562
   [235]vgg16_bn            [236]pytorch    73.518 91.608
   [237]vgg19               [238]pytorch    72.080 90.822
   [239]vgg16               [240]pytorch    71.636 90.354
   [241]vgg13_bn            [242]pytorch    71.508 90.494
   [243]vgg11_bn            [244]pytorch    70.452 89.818
   [245]resnet18            [246]pytorch    70.142 89.274
   [247]vgg13               [248]pytorch    69.662 89.264
   [249]vgg11               [250]pytorch    68.970 88.746
   [251]squeezenet1_1       [252]pytorch    58.250 80.800
   [253]squeezenet1_0       [254]pytorch    58.108 80.428
   [255]alexnet             [256]pytorch    56.432 79.194

   notes:
     * the pytorch version of resnet152 is not a porting of the torch7 but
       has been retrained by facebook.
     * for the polynet evaluation each image was resized to 378x378
       without preserving the aspect ratio and then the central 331  331
       patch from the resulting image was used.

   beware, the accuracy reported here is not always representative of the
   transferable capacity of the network on other tasks and datasets. you
   must try them all! :p

reproducing results

   please see [257]compute id163 validation metrics

documentation

available models

nasnet*

   source: [258]tensorflow slim repo
     * nasnetalarge(num_classes=1000, pretrained='id163')
     * nasnetalarge(num_classes=1001, pretrained='id163+background')
     * nasnetamobile(num_classes=1000, pretrained='id163')

facebook resnet*

   source: [259]torch7 repo of facebook

   there are a bit different from the resnet* of torchvision. resnet152 is
   currently the only one available.
     * fbresnet152(num_classes=1000, pretrained='id163')

caffe resnet*

   source: [260]caffe repo of kaiminghe
     * cafferesnet101(num_classes=1000, pretrained='id163')

inception*

   source: [261]tensorflow slim repo and [262]pytorch/vision repo for
   inceptionv3
     * inceptionresnetv2(num_classes=1000, pretrained='id163')
     * inceptionresnetv2(num_classes=1001,
       pretrained='id163+background')
     * inceptionv4(num_classes=1000, pretrained='id163')
     * inceptionv4(num_classes=1001, pretrained='id163+background')
     * inceptionv3(num_classes=1000, pretrained='id163')

bninception

   source: [263]trained with caffe by [264]xiong yuanjun
     * bninception(num_classes=1000, pretrained='id163')

resnext*

   source: [265]resnext repo of facebook
     * resnext101_32x4d(num_classes=1000, pretrained='id163')
     * resnext101_62x4d(num_classes=1000, pretrained='id163')

dualpathnetworks

   source: [266]mxnet repo of chen yunpeng

   the porting has been made possible by [267]ross wightman in his
   [268]pytorch repo.

   as you can see [269]here dualpathnetworks allows you to try different
   scales. the default one in this repo is 0.875 meaning that the original
   input size is 256 before croping to 224.
     * dpn68(num_classes=1000, pretrained='id163')
     * dpn98(num_classes=1000, pretrained='id163')
     * dpn131(num_classes=1000, pretrained='id163')
     * dpn68b(num_classes=1000, pretrained='id163+5k')
     * dpn92(num_classes=1000, pretrained='id163+5k')
     * dpn107(num_classes=1000, pretrained='id163+5k')

   'id163+5k' means that the network has been pretrained on id1635k
   before being finetuned on id1631k.

xception

   source: [270]keras repo

   the porting has been made possible by [271]t standley.
     * xception(num_classes=1000, pretrained='id163')

senet*

   source: [272]caffe repo of jie hu
     * senet154(num_classes=1000, pretrained='id163')
     * se_resnet50(num_classes=1000, pretrained='id163')
     * se_resnet101(num_classes=1000, pretrained='id163')
     * se_resnet152(num_classes=1000, pretrained='id163')
     * se_resnext50_32x4d(num_classes=1000, pretrained='id163')
     * se_resnext101_32x4d(num_classes=1000, pretrained='id163')

pnasnet*

   source: [273]tensorflow slim repo
     * pnasnet5large(num_classes=1000, pretrained='id163')
     * pnasnet5large(num_classes=1001, pretrained='id163+background')

polynet

   source: [274]caffe repo of the cuhk multimedia lab
     * polynet(num_classes=1000, pretrained='id163')

torchvision

   source: [275]pytorch/vision repo

   (inceptionv3 included in [276]inception*)
     * resnet18(num_classes=1000, pretrained='id163')
     * resnet34(num_classes=1000, pretrained='id163')
     * resnet50(num_classes=1000, pretrained='id163')
     * resnet101(num_classes=1000, pretrained='id163')
     * resnet152(num_classes=1000, pretrained='id163')
     * densenet121(num_classes=1000, pretrained='id163')
     * densenet161(num_classes=1000, pretrained='id163')
     * densenet169(num_classes=1000, pretrained='id163')
     * densenet201(num_classes=1000, pretrained='id163')
     * squeezenet1_0(num_classes=1000, pretrained='id163')
     * squeezenet1_1(num_classes=1000, pretrained='id163')
     * alexnet(num_classes=1000, pretrained='id163')
     * vgg11(num_classes=1000, pretrained='id163')
     * vgg13(num_classes=1000, pretrained='id163')
     * vgg16(num_classes=1000, pretrained='id163')
     * vgg19(num_classes=1000, pretrained='id163')
     * vgg11_bn(num_classes=1000, pretrained='id163')
     * vgg13_bn(num_classes=1000, pretrained='id163')
     * vgg16_bn(num_classes=1000, pretrained='id163')
     * vgg19_bn(num_classes=1000, pretrained='id163')

model api

   once a pretrained model has been loaded, you can use it that way.

   important note: all image must be loaded using pil which scales the
   pixel values between 0 and 1.

model.input_size

   attribut of type list composed of 3 numbers:
     * number of color channels,
     * height of the input image,
     * width of the input image.

   example:
     * [3, 299, 299] for inception* networks,
     * [3, 224, 224] for resnet* networks.

model.input_space

   attribut of type str representating the color space of the image. can
   be rgb or bgr.

model.input_range

   attribut of type list composed of 2 numbers:
     * min pixel value,
     * max pixel value.

   example:
     * [0, 1] for resnet* and inception* networks,
     * [0, 255] for bninception network.

model.mean

   attribut of type list composed of 3 numbers which are used to normalize
   the input image (substract "color-channel-wise").

   example:
     * [0.5, 0.5, 0.5] for inception* networks,
     * [0.485, 0.456, 0.406] for resnet* networks.

model.std

   attribut of type list composed of 3 numbers which are used to normalize
   the input image (divide "color-channel-wise").

   example:
     * [0.5, 0.5, 0.5] for inception* networks,
     * [0.229, 0.224, 0.225] for resnet* networks.

model.features

   /!\ work in progress (may not be available)

   method which is used to extract the features from the image.

   example when the model is loaded using fbresnet152:
print(input_224.size())            # (1,3,224,224)
output = model.features(input_224)
print(output.size())               # (1,2048,1,1)

# print(input_448.size())          # (1,3,448,448)
output = model.features(input_448)
# print(output.size())             # (1,2048,7,7)

model.logits

   /!\ work in progress (may not be available)

   method which is used to classify the features from the image.

   example when the model is loaded using fbresnet152:
output = model.features(input_224)
print(output.size())               # (1,2048, 1, 1)
output = model.logits(output)
print(output.size())               # (1,1000)

model.forward

   method used to call model.features and model.logits. it can be
   overwritten as desired.

   note: a good practice is to use model.__call__ as your function of
   choice to forward an input to your model. see the example bellow.
# without model.__call__
output = model.forward(input_224)
print(output.size())      # (1,1000)

# with model.__call__
output = model(input_224)
print(output.size())      # (1,1000)

model.last_linear

   attribut of type nn.linear. this module is the last one to be called
   during the forward pass.
     * can be replaced by an adapted nn.linear for fine tuning.
     * can be replaced by pretrained.utils.identity for features
       extraction.

   example when the model is loaded using fbresnet152:
print(input_224.size())            # (1,3,224,224)
output = model.features(input_224)
print(output.size())               # (1,2048,1,1)
output = model.logits(output)
print(output.size())               # (1,1000)

# fine tuning
dim_feats = model.last_linear.in_features # =2048
nb_classes = 4
model.last_linear = nn.linear(dim_feats, nb_classes)
output = model(input_224)
print(output.size())               # (1,4)

# features extraction
model.last_linear = pretrained.utils.identity()
output = model(input_224)
print(output.size())               # (1,2048)

reproducing

hand porting of resnet152

th pretrainedmodels/fbresnet/resnet152_dump.lua
python pretrainedmodels/fbresnet/resnet152_load.py

automatic porting of resnext

   [277]https://github.com/clcarwin/convert_torch_to_pytorch

hand porting of nasnet, inceptionv4 and inceptionresnetv2

   [278]https://github.com/cadene/tensorflow-model-zoo.torch

acknowledgement

   thanks to the deep learning community and especially to the
   contributers of the pytorch ecosystem.

     *    2019 github, inc.
     * [279]terms
     * [280]privacy
     * [281]security
     * [282]status
     * [283]help

     * [284]contact github
     * [285]pricing
     * [286]api
     * [287]training
     * [288]blog
     * [289]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [290]reload to refresh your
   session. you signed out in another tab or window. [291]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/cadene/pretrained-models.pytorch/commits/master.atom
   3. https://github.com/cadene/pretrained-models.pytorch#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/cadene/pretrained-models.pytorch
  32. https://github.com/join
  33. https://github.com/login?return_to=/cadene/pretrained-models.pytorch
  34. https://github.com/cadene/pretrained-models.pytorch/watchers
  35. https://github.com/login?return_to=/cadene/pretrained-models.pytorch
  36. https://github.com/cadene/pretrained-models.pytorch/stargazers
  37. https://github.com/login?return_to=/cadene/pretrained-models.pytorch
  38. https://github.com/cadene/pretrained-models.pytorch/network/members
  39. https://github.com/cadene
  40. https://github.com/cadene/pretrained-models.pytorch
  41. https://github.com/cadene/pretrained-models.pytorch
  42. https://github.com/cadene/pretrained-models.pytorch/issues
  43. https://github.com/cadene/pretrained-models.pytorch/pulls
  44. https://github.com/cadene/pretrained-models.pytorch/projects
  45. https://github.com/cadene/pretrained-models.pytorch/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/id163
  48. https://github.com/topics/resnet
  49. https://github.com/topics/resnext
  50. https://github.com/topics/pretrained
  51. https://github.com/topics/pytorch
  52. https://github.com/topics/inception
  53. https://github.com/cadene/pretrained-models.pytorch/commits/master
  54. https://github.com/cadene/pretrained-models.pytorch/branches
  55. https://github.com/cadene/pretrained-models.pytorch/releases
  56. https://github.com/cadene/pretrained-models.pytorch/graphs/contributors
  57. https://github.com/cadene/pretrained-models.pytorch/blob/master/license.txt
  58. https://github.com/cadene/pretrained-models.pytorch/search?l=python
  59. https://github.com/cadene/pretrained-models.pytorch/search?l=lua
  60. https://github.com/cadene/pretrained-models.pytorch/find/master
  61. https://github.com/cadene/pretrained-models.pytorch/archive/master.zip
  62. https://github.com/login?return_to=https://github.com/cadene/pretrained-models.pytorch
  63. https://github.com/join?return_to=/cadene/pretrained-models.pytorch
  64. https://desktop.github.com/
  65. https://desktop.github.com/
  66. https://developer.apple.com/xcode/
  67. https://visualstudio.github.com/
  68. https://github.com/cadene
  69. https://github.com/cadene/pretrained-models.pytorch/commits?author=cadene
  70. https://github.com/cadene/pretrained-models.pytorch/commit/021d97897c9aa76ec759deff43d341c4fd45d7ba
  71. https://github.com/cadene/pretrained-models.pytorch/commit/021d97897c9aa76ec759deff43d341c4fd45d7ba
  72. https://github.com/cadene/pretrained-models.pytorch/tree/021d97897c9aa76ec759deff43d341c4fd45d7ba
  73. https://github.com/cadene/pretrained-models.pytorch/tree/master/data
  74. https://github.com/cadene/pretrained-models.pytorch/commit/f7848902706e1e742472e763fafd87bca3d83220
  75. https://github.com/cadene/pretrained-models.pytorch/tree/master/examples
  76. https://github.com/cadene/pretrained-models.pytorch/commit/021d97897c9aa76ec759deff43d341c4fd45d7ba
  77. https://github.com/cadene/pretrained-models.pytorch/tree/master/pretrainedmodels
  78. https://github.com/cadene/pretrained-models.pytorch/commit/3fc49a5a64328a0fcdc28dedd14f614d4f3124a2
  79. https://github.com/cadene/pretrained-models.pytorch/pull/122
  80. https://github.com/cadene/pretrained-models.pytorch/commit/3fc49a5a64328a0fcdc28dedd14f614d4f3124a2
  81. https://github.com/cadene/pretrained-models.pytorch/tree/master/tests
  82. https://github.com/cadene/pretrained-models.pytorch/blob/master/.gitignore
  83. https://github.com/cadene/pretrained-models.pytorch/blob/master/.travis.yml
  84. https://github.com/cadene/pretrained-models.pytorch/blob/master/license.txt
  85. https://github.com/cadene/pretrained-models.pytorch/blob/master/readme.md
  86. https://github.com/cadene/pretrained-models.pytorch/blob/master/requirements.txt
  87. https://github.com/cadene/pretrained-models.pytorch/blob/master/setup.id18
  88. https://github.com/cadene/pretrained-models.pytorch/blob/master/setup.py
  89. https://travis-ci.org/cadene/pretrained-models.pytorch
  90. https://github.com/cuhk-mmlab/polynet
  91. https://arxiv.org/abs/1712.00559
  92. https://github.com/creafz
  93. https://github.com/hujie-frank/senet
  94. https://github.com/creafz
  95. https://github.com/hujie-frank/senet
  96. https://github.com/creafz
  97. https://github.com/veronikayurchuk
  98. https://github.com/dagnyt
  99. https://github.com/rwightman/pytorch-dpn-pretrained
 100. https://github.com/tstandley/xception-pytorch
 101. https://github.com/cadene/pretrained-models.pytorch#installation
 102. https://github.com/cadene/pretrained-models.pytorch#quick-examples
 103. https://github.com/cadene/pretrained-models.pytorch#few-use-cases
 104. https://github.com/cadene/pretrained-models.pytorch#compute-id163-logits
 105. https://github.com/cadene/pretrained-models.pytorch#compute-id163-validation-metrics
 106. https://github.com/cadene/pretrained-models.pytorch#evaluation-on-id163
 107. https://github.com/cadene/pretrained-models.pytorch#accuracy-on-validation-set
 108. https://github.com/cadene/pretrained-models.pytorch#reproducing-results
 109. https://github.com/cadene/pretrained-models.pytorch#documentation
 110. https://github.com/cadene/pretrained-models.pytorch#available-models
 111. https://github.com/cadene/pretrained-models.pytorch#torchvision
 112. https://github.com/cadene/pretrained-models.pytorch#bninception
 113. https://github.com/cadene/pretrained-models.pytorch#caffe-resnet
 114. https://github.com/cadene/pretrained-models.pytorch#torchvision
 115. https://github.com/cadene/pretrained-models.pytorch#torchvision
 116. https://github.com/cadene/pretrained-models.pytorch#torchvision
 117. https://github.com/cadene/pretrained-models.pytorch#torchvision
 118. https://github.com/cadene/pretrained-models.pytorch#torchvision
 119. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 120. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 121. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 122. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 123. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 124. https://github.com/cadene/pretrained-models.pytorch#facebook-resnet
 125. https://github.com/cadene/pretrained-models.pytorch#inception
 126. https://github.com/cadene/pretrained-models.pytorch#inception
 127. https://github.com/cadene/pretrained-models.pytorch#inception
 128. https://github.com/cadene/pretrained-models.pytorch#nasnet
 129. https://github.com/cadene/pretrained-models.pytorch#nasnet
 130. https://github.com/cadene/pretrained-models.pytorch#pnasnet
 131. https://github.com/cadene/pretrained-models.pytorch#polynet
 132. https://github.com/cadene/pretrained-models.pytorch#resnext
 133. https://github.com/cadene/pretrained-models.pytorch#resnext
 134. https://github.com/cadene/pretrained-models.pytorch#torchvision
 135. https://github.com/cadene/pretrained-models.pytorch#torchvision
 136. https://github.com/cadene/pretrained-models.pytorch#torchvision
 137. https://github.com/cadene/pretrained-models.pytorch#torchvision
 138. https://github.com/cadene/pretrained-models.pytorch#torchvision
 139. https://github.com/cadene/pretrained-models.pytorch#senet
 140. https://github.com/cadene/pretrained-models.pytorch#senet
 141. https://github.com/cadene/pretrained-models.pytorch#senet
 142. https://github.com/cadene/pretrained-models.pytorch#senet
 143. https://github.com/cadene/pretrained-models.pytorch#senet
 144. https://github.com/cadene/pretrained-models.pytorch#senet
 145. https://github.com/cadene/pretrained-models.pytorch#torchvision
 146. https://github.com/cadene/pretrained-models.pytorch#torchvision
 147. https://github.com/cadene/pretrained-models.pytorch#torchvision
 148. https://github.com/cadene/pretrained-models.pytorch#torchvision
 149. https://github.com/cadene/pretrained-models.pytorch#torchvision
 150. https://github.com/cadene/pretrained-models.pytorch#torchvision
 151. https://github.com/cadene/pretrained-models.pytorch#torchvision
 152. https://github.com/cadene/pretrained-models.pytorch#torchvision
 153. https://github.com/cadene/pretrained-models.pytorch#torchvision
 154. https://github.com/cadene/pretrained-models.pytorch#torchvision
 155. https://github.com/cadene/pretrained-models.pytorch#xception
 156. https://github.com/cadene/pretrained-models.pytorch#model-api
 157. https://github.com/cadene/pretrained-models.pytorch#modelinput_size
 158. https://github.com/cadene/pretrained-models.pytorch#modelinput_space
 159. https://github.com/cadene/pretrained-models.pytorch#modelinput_range
 160. https://github.com/cadene/pretrained-models.pytorch#modelmean
 161. https://github.com/cadene/pretrained-models.pytorch#modelstd
 162. https://github.com/cadene/pretrained-models.pytorch#modelfeatures
 163. https://github.com/cadene/pretrained-models.pytorch#modellogits
 164. https://github.com/cadene/pretrained-models.pytorch#modelforward
 165. https://github.com/cadene/pretrained-models.pytorch#reproducing
 166. https://github.com/cadene/pretrained-models.pytorch#hand-porting-of-resnet152
 167. https://github.com/cadene/pretrained-models.pytorch#automatic-porting-of-resnext
 168. https://github.com/cadene/pretrained-models.pytorch#hand-porting-of-inceptionv4-and-inceptionresnetv2
 169. https://www.continuum.io/downloads
 170. http://pytorch.org/
 171. https://github.com/cadene/pretrained-models.pytorch/blob/master/examples/id163_logits.py
 172. https://github.com/cadene/pretrained-models.pytorch/blob/master/examples/id163_eval.py
 173. https://github.com/tensorflow/models/tree/master/research/slim
 174. https://github.com/cadene/pretrained-models.pytorch#pnasnet
 175. https://github.com/tensorflow/models/tree/master/research/slim
 176. https://github.com/cadene/pretrained-models.pytorch#nasnet
 177. https://github.com/hujie-frank/senet
 178. https://github.com/cadene/pretrained-models.pytorch#senet
 179. https://github.com/cuhk-mmlab/polynet
 180. https://github.com/cadene/pretrained-models.pytorch#polynet
 181. https://github.com/tensorflow/models/tree/master/slim
 182. https://github.com/tensorflow/models/tree/master/slim
 183. https://github.com/cadene/pretrained-models.pytorch#senet
 184. https://github.com/hujie-frank/senet
 185. https://github.com/cadene/pretrained-models.pytorch#inception
 186. https://github.com/cadene/pretrained-models.pytorch#inception
 187. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 188. https://github.com/facebookresearch/resnext
 189. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 190. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 191. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 192. https://github.com/cadene/pretrained-models.pytorch#senet
 193. https://github.com/hujie-frank/senet
 194. https://github.com/cadene/pretrained-models.pytorch#xception
 195. https://github.com/keras-team/keras/blob/master/keras/applications/xception.py
 196. https://github.com/cadene/pretrained-models.pytorch#resnext
 197. https://github.com/cadene/pretrained-models.pytorch#xception
 198. https://github.com/facebookresearch/resnext
 199. https://github.com/hujie-frank/senet
 200. https://github.com/cadene/pretrained-models.pytorch#senet
 201. https://github.com/pytorch/vision#models
 202. https://github.com/cadene/pretrained-models.pytorch#senet
 203. https://github.com/hujie-frank/senet
 204. https://github.com/cadene/pretrained-models.pytorch#resnext
 205. https://github.com/facebook/fb.resnet.torch
 206. https://github.com/hujie-frank/senet
 207. https://github.com/cadene/pretrained-models.pytorch#senet
 208. https://github.com/cadene/pretrained-models.pytorch#torchvision
 209. https://github.com/pytorch/vision#models
 210. https://github.com/cadene/pretrained-models.pytorch#torchvision
 211. https://github.com/pytorch/vision#models
 212. https://github.com/cadene/pretrained-models.pytorch#facebook-resnet
 213. https://github.com/cadene/pretrained-models.pytorch#inception
 214. https://github.com/pytorch/vision#models
 215. https://github.com/cadene/pretrained-models.pytorch#torchvision
 216. https://github.com/pytorch/vision#models
 217. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 218. https://github.com/cadene/pretrained-models.pytorch#caffe-resnet
 219. https://github.com/kaiminghe/deep-residual-networks
 220. https://github.com/cadene/pretrained-models.pytorch#caffe-resnet
 221. https://github.com/cadene/pretrained-models.pytorch#torchvision
 222. https://github.com/pytorch/vision#models
 223. https://github.com/cadene/pretrained-models.pytorch#torchvision
 224. https://github.com/pytorch/vision#models
 225. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 226. https://github.com/cadene/pretrained-models.pytorch#torchvision
 227. https://github.com/pytorch/vision#models
 228. https://github.com/cadene/pretrained-models.pytorch#torchvision
 229. https://github.com/pytorch/vision#models
 230. https://github.com/tensorflow/models/tree/master/research/slim
 231. https://github.com/veronikayurchuk/pretrained-models.pytorch/blob/master/pretrainedmodels/models/nasnet_mobile.py
 232. https://github.com/cadene/pretrained-models.pytorch#torchvision
 233. https://github.com/pytorch/vision#models
 234. https://github.com/cadene/pretrained-models.pytorch#bninception
 235. https://github.com/cadene/pretrained-models.pytorch#torchvision
 236. https://github.com/pytorch/vision#models
 237. https://github.com/cadene/pretrained-models.pytorch#torchvision
 238. https://github.com/pytorch/vision#models
 239. https://github.com/cadene/pretrained-models.pytorch#torchvision
 240. https://github.com/pytorch/vision#models
 241. https://github.com/cadene/pretrained-models.pytorch#torchvision
 242. https://github.com/pytorch/vision#models
 243. https://github.com/cadene/pretrained-models.pytorch#torchvision
 244. https://github.com/pytorch/vision#models
 245. https://github.com/cadene/pretrained-models.pytorch#torchvision
 246. https://github.com/pytorch/vision#models
 247. https://github.com/cadene/pretrained-models.pytorch#torchvision
 248. https://github.com/pytorch/vision#models
 249. https://github.com/cadene/pretrained-models.pytorch#torchvision
 250. https://github.com/pytorch/vision#models
 251. https://github.com/cadene/pretrained-models.pytorch#torchvision
 252. https://github.com/pytorch/vision#models
 253. https://github.com/cadene/pretrained-models.pytorch#torchvision
 254. https://github.com/pytorch/vision#models
 255. https://github.com/cadene/pretrained-models.pytorch#torchvision
 256. https://github.com/pytorch/vision#models
 257. https://github.com/cadene/pretrained-models.pytorch#compute-id163-validation-metrics
 258. https://github.com/tensorflow/models/tree/master/research/slim
 259. https://github.com/facebook/fb.resnet.torch
 260. https://github.com/kaiminghe/deep-residual-networks
 261. https://github.com/tensorflow/models/tree/master/slim
 262. https://github.com/pytorch/vision/tree/master/torchvision
 263. https://github.com/cadene/tensorflow-model-zoo.torch/pull/2
 264. http://yjxiong.me/
 265. https://github.com/facebookresearch/resnext
 266. https://github.com/cypw/dpns
 267. http://rwightman.com/
 268. https://github.com/rwightman/pytorch-dpn-pretrained
 269. https://github.com/rwightman/pytorch-dpn-pretrained
 270. https://github.com/keras-team/keras/blob/master/keras/applications/xception.py
 271. https://github.com/tstandley/xception-pytorch
 272. https://github.com/hujie-frank/senet
 273. https://github.com/tensorflow/models/tree/master/research/slim
 274. https://github.com/cuhk-mmlab/polynet
 275. https://github.com/pytorch/vision/tree/master/torchvision
 276. https://github.com/cadene/pretrained-models.pytorch#inception
 277. https://github.com/clcarwin/convert_torch_to_pytorch
 278. https://github.com/cadene/tensorflow-model-zoo.torch
 279. https://github.com/site/terms
 280. https://github.com/site/privacy
 281. https://github.com/security
 282. https://githubstatus.com/
 283. https://help.github.com/
 284. https://github.com/contact
 285. https://github.com/pricing
 286. https://developer.github.com/
 287. https://training.github.com/
 288. https://github.blog/
 289. https://github.com/about
 290. https://github.com/cadene/pretrained-models.pytorch
 291. https://github.com/cadene/pretrained-models.pytorch

   hidden links:
 293. https://github.com/
 294. https://github.com/cadene/pretrained-models.pytorch
 295. https://github.com/cadene/pretrained-models.pytorch
 296. https://github.com/cadene/pretrained-models.pytorch
 297. https://help.github.com/articles/which-remote-url-should-i-use
 298. https://github.com/cadene/pretrained-models.pytorch#pretrained-models-for-pytorch-work-in-progress
 299. https://github.com/cadene/pretrained-models.pytorch#summary
 300. https://github.com/cadene/pretrained-models.pytorch#installation
 301. https://github.com/cadene/pretrained-models.pytorch#install-from-pip
 302. https://github.com/cadene/pretrained-models.pytorch#install-from-repo
 303. https://github.com/cadene/pretrained-models.pytorch#quick-examples
 304. https://github.com/cadene/pretrained-models.pytorch#few-use-cases
 305. https://github.com/cadene/pretrained-models.pytorch#compute-id163-logits
 306. https://github.com/cadene/pretrained-models.pytorch#compute-id163-evaluation-metrics
 307. https://github.com/cadene/pretrained-models.pytorch#evaluation-on-id163
 308. https://github.com/cadene/pretrained-models.pytorch#accuracy-on-validation-set-single-model
 309. https://github.com/cadene/pretrained-models.pytorch#reproducing-results
 310. https://github.com/cadene/pretrained-models.pytorch#documentation
 311. https://github.com/cadene/pretrained-models.pytorch#available-models
 312. https://github.com/cadene/pretrained-models.pytorch#nasnet
 313. https://github.com/cadene/pretrained-models.pytorch#facebook-resnet
 314. https://github.com/cadene/pretrained-models.pytorch#caffe-resnet
 315. https://github.com/cadene/pretrained-models.pytorch#inception
 316. https://github.com/cadene/pretrained-models.pytorch#bninception
 317. https://github.com/cadene/pretrained-models.pytorch#resnext
 318. https://github.com/cadene/pretrained-models.pytorch#dualpathnetworks
 319. https://github.com/cadene/pretrained-models.pytorch#xception
 320. https://github.com/cadene/pretrained-models.pytorch#senet
 321. https://github.com/cadene/pretrained-models.pytorch#pnasnet
 322. https://github.com/cadene/pretrained-models.pytorch#polynet
 323. https://github.com/cadene/pretrained-models.pytorch#torchvision
 324. https://github.com/cadene/pretrained-models.pytorch#model-api
 325. https://github.com/cadene/pretrained-models.pytorch#modelinput_size
 326. https://github.com/cadene/pretrained-models.pytorch#modelinput_space
 327. https://github.com/cadene/pretrained-models.pytorch#modelinput_range
 328. https://github.com/cadene/pretrained-models.pytorch#modelmean
 329. https://github.com/cadene/pretrained-models.pytorch#modelstd
 330. https://github.com/cadene/pretrained-models.pytorch#modelfeatures
 331. https://github.com/cadene/pretrained-models.pytorch#modellogits
 332. https://github.com/cadene/pretrained-models.pytorch#modelforward
 333. https://github.com/cadene/pretrained-models.pytorch#modellast_linear
 334. https://github.com/cadene/pretrained-models.pytorch#reproducing
 335. https://github.com/cadene/pretrained-models.pytorch#hand-porting-of-resnet152
 336. https://github.com/cadene/pretrained-models.pytorch#automatic-porting-of-resnext
 337. https://github.com/cadene/pretrained-models.pytorch#hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2
 338. https://github.com/cadene/pretrained-models.pytorch#acknowledgement
 339. https://github.com/
