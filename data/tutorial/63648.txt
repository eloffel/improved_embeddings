   #[1]ahmed besbes - data science portfolio atom

   [2]ahmed besbes

[3]ahmed besbes

   data scientist in the making
     *
     *
     *
     *
     *

   [4]home [5]archives [6]categories [7]tags [8]atom

 understanding deep convolutional neural networks with a practical use-case in
                              tensorflow and keras

   posted on lun. 13 novembre 2017 in [9]deep learning

   [10]posted on kdnuggets, 2nd most shared article

   post featured on [11]kddnuggets.com.
     __________________________________________________________________

   deep learning is one of the most exciting artificial intelligence
   topics. it's a family of algorithms loosely based on a biological
   interpretation that have proven astonishing results in many areas:
   id161, natural language processing, id103 and
   more.

   [deep.png]

   over the past five years, deep learning expanded to a broad range of
   industries.

   many recent technological breakthroughs owe their existence to it. to
   name a few: tesla id101, photo tagging systems at facebook,
   virtual assistants such as siri or cortana, chatbots, object
   recognition cameras. in so many areas, deep learning achieved a
   human-performence level on the cognitive tasks of language
   understanding and image analysis.

   here's an example of what deep learning algorithms are capable of
   doing: automatically detecting and labeling different objects in a
   scene.

   [object_recognition.jpg]

   deep learning also became a widely mediatized tech topic.

   [dl_trend.png]

   in this article, i'll go beyond the overall hype you'd encounter in the
   mass media and present a concrete application of deep learning.

   i'll show you how to build a deep neural network that classifies images
   to their categories with an accuracy of a 90%. this seemingly simple
   task is a very hard problem that computer scientists have been working
   on for years before the rose of deep networks and especially
   convolutional neural networks (id98).

     this post is broken into 4 parts where i will:
    1. [12]present the dataset and the use-case and explain the complexity
       of the image classification task
    2. [13]go over the details about convolutional neural nets. i'll
       explain their inner meachanisms and the reason why they are more
       suitable to image classification than ordinary neural netwoks
    3. [14]set up a deep learning dedicated environment on a powerful
       gpu-based ec2 instance from amazon web services (aws)
    4. [15]train two deep learning models: one from scratch in an
       end-to-end pipeline using keras and tensorflow, and another one by
       using a pre-trained network on a large dataset

   these parts are independent. if you're not interested in the theory you
   can skip part 1 and 2.

   deep learning is a challenging topic to handle. as a machine learning
   practitioner, i myself spent a lot of time learning about the subject.
   in the last part, i'll share all the material i used so that you can
   use it yourself and start your deep learning journey.

   this article is an honest attempt to synthesize the knowledge i've
   developed on neural nets. so please don't hesitate to point out any
   mistake you come across while reading. feel free to also discuss any
   point you see unclear or any thought you'd like to share.

   in case you're willing to reproduce my work or send a pull request, the
   code of this article as well as the trained models are available in
   [16]my github account

   let's get started.

1 - a fun use case: how to classify cats and dogs? [17]  

   there are lots of image datasets dedicated to benchmarking deep
   learning models.

   the one i'll be using in this article comes from the [18]cat vs dogs
   kaggle competition . as you've probably guessed it, it's a set of
   labeled images of cats and dogs.

   like in every kaggle competition, we'll have tow folders:
     * a train folder: it contains 25,000 images of dogs and cats. each
       image in this folder has the label as part of the filename. we'll
       use it to train and validate our model.
     * a test folder: it contains 12,500 images, named according to a
       numeric id. for each image in this dataset, one should predict a
       id203 that the image is a dog (1 = dog, 0 = cat). in practice
       it's used to score the model on the kaggle leaderboard.

   as you can see, we have a variety of images. they all are in different
   resolutions. cats and dogs are in different shapes, positions, colors.
   they may be sitting, they may not. they may be happy or sad. cats may
   be sleeping, dogs may be barking. photographs can be taken from
   diffrent angles with a different zoom.

   an infinite number of configurations is possible. for a human,
   recognizing pets in a scene in a set of heterogeneous photographs comes
   naturally with no effort. this is however not a trivial task for a
   machine. in fact, automatic classification assumes to know how to
   robustly describe what makes a cat a cat and makes a dog a dog. this
   assumes to know the intrinsic features that describe each animal.

   what makes deep neural networks very effective at classifying images is
   their ability to automatically learn multiple levels of abstraction
   that simply characterize each class in a given classification task.
   they can recognize patterns with extreme variability, and with
   robustness to distortions and simple geometric transformations.

   let's see how deep neural nets handle this.

2 - fully connected networks vs id98s [19]  

   many people started using fully connected networks to address the image
   classification problem. however, they came to realize that these
   networks are not fully optimal for the task.

   let's understand why.

2 - 1 a fully connected (fc) neural network[20]  

   fully connected neural nets are networks where each neuron is connected
   to every neuron in the adjacent layers. they are the standard and
   typical neural network architectures. to learn more about the theory
   behind neural networks please refer to this [21]link and this [22]one:
   these are andrej karpathy's stanford lectures and they are simply,
   awesome.

   to illustrate, here's a 3-hidden layer fc neural net.

   using fc networks, images are first converted to a one dimensional
   vector before being fed as an input.

   for example, a color image of size 256x256, which is represented by
   object of shape (255, 255, 3) where 3 is the number of color channels,
   is converted to a vector of size 256 x 256 x 3 = 196608. all we did
   here was rolling the image into a long vector. each element of this
   vector is a pixel value.

   using a fc network on a set of 256x256 color images, we would then
   have:
     * an input layer of size 196608 where each neuron encodes a pixel
       value of the image
     * an output layer of size 2 where each neuron indicates the
       prediction for the output class
     * hidden layers and hidden neurons in between.

   fully connected networks can be very good classifiers. in the realm of
   supervised algorithms, they can learn complex non-linear patterns and
   generalize well assuming we design a robust architecture that doesn't
   overfit on the data.

   when it comes to processing images, fully connected networks are
   unfortunately not the right tools.

i see two main reasons:[23]  

    1. let's imagine that we have one hidden layer of 1000 hidden units
       for our case. 1000 is a reasonable value given the size of the
       input layer. with this configuration, the number of parameters (or
       weights) connecting our input layer to the first hidden layer is
       equal to 196608 x 1000 = 196608000! this is not only a huge number
       but the network is also not likely to perform very well given that
       neural networks need in general more than one hidden layer to be
       robust. but fair enough. let's say that our network is very good
       with that one hidden layer and 1000 hidden units. let's do the math
       for the memory cost. a weight is a floating value that is encoded
       in 8 bytes. 196698000 weights would then cost ... 1572864000 bytes
       which is an approximate value of ~ 1,572 gb . so we'll need 1,572
       gb to store the weights of the first hidden layer only. unless you
       have a lot of ram on your laptop, this is clearly not a scalable
       solution.
    2. with fully connected networks, we lose the spatial structure that
       is intrinsic to the image. in fact, after converting the image to a
       long vector, each pixel value is processed by the network pretty
       much the same as the other pixels. there is no assumption of
       spatial correlation between the pixels whatsoever. each pixel has
       the same role. this is unfortunately a huge information loss since
       we lose the dependencies and the similarities between closer
       pixels. this is an infromation that we want to be encoded in our
       model.

   to overcome these two limitations, a lot of work have been invested to
   come up with new neural network architectures that are both scalable
   and suitable to handle the complexity of the image data.

   and that's when we came up with convolutional neural networks (id98s).

2 - 2 convolutional neural networks[24]  

   convolutional neural networks (or id98s) are special kind of neural
   architectures that have been specifically designed to handle image
   data. since their introduction by (lecun et al, 1989) in the early
   1990's, id98s have demonstrated excellent performance at tasks such as
   handwritten digit classification and face detection. in the past few
   years, several papers have shown that they can also deliver outstanding
   results on more challenging visual classification tasks. most notably
   (krizhevsky et al., 2012) show record beating performance on the
   id163 2012 classification benchmark, with their convnet model
   (alexnet) achieving an error rate of 16.4% compared to the second place
   result of 26.1%.

   id98s are not just hype. several factors are responsible for the renewed
   interest people got in them.

    1. the availability of very large training datasets with millions of
       labeled examples. one of the most popular databases is id163
    2. powerful gpu implementations, making the training of very large
       models practical
    3. enhanced model id173 strategies such as [25]dropout

   id98 are powerful at the image classification task. they are, by design,
   a solution to the two previous limitations that are faced by fc
   networks.

   id98s have their own structure and properties. they look different (and
   we will see it) from standard fc networks but they share the same
   mechanisms. in both cases, we talk about hidden layers, weights,
   biases, hidden neurons, id168s, id26 and stochastic
   id119. again, if you're not familiar with these concepts, i
   encourage you to look at andrej karpathy's lectures on neural nets.

   id98s are composed of five basic blocks: understanding them should give
   you a clear intuition about the global mechanism.
    1. [26]an input layer
    2. [27]convolutional layer
    3. [28]relu layer
    4. [29]pooling layer
    5. [30]fully connected layer

   before diving in each block, here's full id98 architecture.

   as you can see, the image is processed throughout the network over many
   layers and the output neurons hold the predictions for each class.

   let's understand what each layer does in details.

the input layer

   in fully connected networks, the inputs are depicted as vertical lines
   of neurons, basically vectors. whether we process images or not, we
   always have to tweak our data to switch to this configuration.

   in a convnet, however, when dealing with images, it helps to think
   about them as squares or neurons where each neuron represents a pixel
   value. basically id98s keep images as they are and don't try to squeeze
   them in a vector.

   the diagram below shows the difference:

   [input_image.png]

the convolution layer

   this layer is the main component of a convnet. before explaining what
   it does, we must first understand the main difference between convnets
   and fc nets in terms of connectivity. this is a crucial idea. let me
   explain:

   we saw it earlier: fully connected networks are literally "fully
   connected". or dense, if you wish. this simply means that every neuron
   in a given layer is connected to all the neurons of the adjacent
   layers. when a multi dimensional data point flows from one layer to
   another, the activation of each neuron in a given layer is determined
   by the weights of all neurons in the previous layers. these guys all
   have a saying.

   however, things are a bit different for id98s. they are not fully
   connected.

   this means that each neuron in a hidden layer is not connected to all
   neurons of the previous layer. it is rather connected to a patch
   (generally a small square region) of neurons in the previous layer.

   here's an example:

   [conv_1.png]

   in this figure, the first neuron of the first hidden layer, which we
   also call a feature map, is connected to a patch of 3x3 pixels in the
   input. this hidden neuron depends only on this small region and will
   ultimately, throughout the learning, capture its characteristics.

   what does the value of this first hidden neuron represent? this is the
   result of a convolution between a weight matrix called the kernel (the
   little gray square) and a small region of same size in the image,
   called the receptive field.

   the operation behind is very simple: it's an element-wise
   multiplication of two matrices: the 3x3 image region and the kernel of
   same size. the multiplications are then summed up into an output value.
   in this example, we have 9 multiplications that are summed into the
   first hidden neuron.

   this neuron basically learns a visual pattern out of the receptive
   field. you can think of its value as a intensity that characterises the
   presence or not of a feature in the image.

   now what about the other hidden neurons? how are they computed?

   to compute the second hidden neuron, the kernel shifts by a unit (or
   one stride) on the input image from left to right and applies the same
   convolution, again with the same filter. here's how it goes.

   ok now let's imagine that the kernel slides over the whole image making
   a convolution at each step and storing the outputs in the feature map.
   in practice, this is how it looks like.

   this is what the convolution layer does: given a filter, it scans the
   input and generates a feature map.

     but what does this convolution operation really represent? how to
     interpret the resulting feature map?

   i started by stating that convolution layers capture visual patterns
   within an image. let me illustrate this to convince you.

   i'm going to load a cat image from the dataset. i'll then apply
   different convolutions on it, changing the kernel each time, and
   visualizing the results.

   in [1]:
%matplotlib inline
from scipy.signal import convolve2d
import numpy as np
import cv2
from matplotlib import pyplot as plt

image = cv2.imread('./data/train/cats/cat.46.jpg')
# converting the image to grayscale
image = cv2.cvtcolor(image, cv2.color_bgr2gray)

   i'll define a function that takes a kenel as an input, performs a
   convolution on the image and then plots the original image and the
   convolved one next to it.

   the kernel is a small square matrix (gray square in the figures above).

   in [2]:
def show_differences(kernel):
    convolved = convolve2d(image, kernel)
    fig = plt.figure(figsize=(15, 15))
    plt.subplot(121)
    plt.title('original image')
    plt.axis('off')
    plt.imshow(image, cmap='gray')

    plt.subplot(122)
    plt.title('convolved image')
    plt.axis('off')
    plt.imshow(convolved, cmap='gray')
    return convolved

   let's start by this filter: $$ \frac{1}{9} \left[ \begin{array}{cccc} 1
   & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \\ \end{array} \right]$$

   it's called box blur. when this filter is applied to a pixel value in
   the input image, it basically takes this pixel and its 8 neighbors
   (that's why we have 1 everywhere) and compute their average pixel value
   (that's why we devide by 9).

   mathematically, this is a simple average. visually, it results in
   smoothing abrupt contrast transitions that appear in the image.

   box blur is highly used in noise removal.

   let's apply it on a cat image and see what it does.

   in [3]:
kernel = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])/9
output = show_differences(kernel)

   [flou1.png]

   if you closely look at the convolved image, you'll notice that it's
   smoother, with less white pixels (noise) sprinkled on it.

   now let's look at a more agressive bluring filter: $$\frac{1}{64}\left[
   \begin{array}{cccc} 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 & 1
   & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 & 1 & 1 &
   1 & 1 \\ 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1
   \\ 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
   \end{array} \right]$$

   in [4]:
kernel = np.ones((8,8), np.float32)/64
dx = show_differences(kernel)

   [flou2.png]

   some filters are used to capture intrinsic image details like edges.

   here is one example that computes an approximation of the vertical
   changes in the image a.
   $$g_x= a * \left[ \begin{array}{cccc} -1 & 0 & 1\\ -2 & 0 & 2 \\ -1 & 0
   & 1 \\ \end{array} \right]$$

   in [5]:
kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)
dx = show_differences(kernel)

   [dx.png]

   the white areas are the ones that better respond to the filter,
   indicating the presence of a vertical edge. look closely at the cat's
   left ear for example and notice how its edge is captured.

   cool, right? here is a second filter that does the same operation but
   for the horizontal changes.
   $$g_y = a * \left[ \begin{array}{cccc} 1 & 2 & 1\\ 0 & 0 & 0 \\ -1 & -2
   & -1 \\ \end{array} \right]$$

   in [6]:
kernel = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)
dy = show_differences(kernel)

   [dy.png]

   notice how the whiskers are detected.

   the two previous filters are gradient operators. they allow, to some
   extent, to reveal an inherent structure in the image with respect to a
   direction.

   however, when g_x and g_y are combined in the following formula:
   $$g = \sqrt{g_x^2 + g_y^2}$$

   they allow an even better edge detection.

   in [7]:
mag = np.hypot(dx, dy)  # magnitude
mag *= 255.0 / np.max(mag)  # normalize (q&d)

fig = plt.figure(figsize=(15, 15))
plt.subplot(121)
plt.title('original image')
plt.axis('off')
plt.imshow(image, cmap='gray')

plt.subplot(122)
plt.title('convoluted image with highlighted edges')
plt.axis('off')
plt.imshow(mag, cmap='gray')

   [edges.png]

   this is called a sobol filter. it's a non-linear combination of two
   simple convolutions. we'll see later that convolution layers are
   capable of aggregating multiple feature maps in a non-linear fashion
   and therefore allowing results such that this edge detection.

   there are more advanced and exotic filters out there. for additional
   information you can refer to this wikipedia [31]link .

   we now understand what a convolution layer does in a convnet: it
   generates a convolved output that responds to a visual element existing
   in the input. the output may be of reduced size, and you can think of
   it as a condensed version of the input regarding a specific feature.

   the kernel determines which feature the convolution is looking for. it
   plays the role of the feature detector. we can think of many filters
   that could detect edges, semi circles, corners, etc.

more than one filter on a convolution layer?[32]  

   in a typical id98 architecture, we won't have one single filter per
   convolution layer. sometimes we'll have 10, 16 or 32. sometimes more.
   in this case we'll be performing as many convolutions per layer as the
   number of filters. the idea is to generate different feature maps, each
   locating a specific simple characteristic in the image. the more
   filters we have, the more intrinsic details we extract.

   keep in mind that these simple characteritics we extract are later
   combined in the network to detect more complex patterns.

what about filter weights? how to choose them?[33]  

   we won't handcraft filter weights based on a domain knowledge we may
   have about the dataset.

   in practice, when training id98s we won't be setting the filter weights
   manually. these values are learnt by the network. automatically. do you
   recall how weights are learnt in a typical fully connected network via
   id26? well, convnets do the same thing.

   instead of large weight matrices per layer, id98s learn filter weights.
   in other words, this means that the network, when adjusting its weights
   (from random values) to decrease the classification errors, comes up
   with the right filters that are suitable for characterising the object
   we're interested in. this is a powerful idea that reverse-engineers the
   vision process.
     __________________________________________________________________

   i find convnets both impressive and mysterious. here's an example of
   the first three features map being learnt in a convnet. (a famous one,
   called alexnet)

   note how complex the features get from simple edges to more bizarre
   shapes.

   [features.png]

weight sharing?[34]  

   a feature map is produced by one and only one filter, i.e. all the
   hidden neurons "share" the same weights because the same filter is
   producing them all. that's what we call weight sharing. it's a property
   that makes id98s faster to train by drastically reducing the number of
   learnt parameters.

   in addition to speeding up training, the concept of weight sharing is
   motivated by the fact that a visual pattern can appear in different
   regions of an image many times and thus having a single filter that
   detect it over the whole image makes sense.

relu layer

   once the feature maps are extracted from the convolution layer, the
   next step is to move them to a relu layer. relu layers are usually
   coupled with conv layers. they usually work together.

   a relu layer applies an elemetwise relu function on the feature map.
   this basically sets all negative pixels to 0. the output of this
   operation is called a rectified feature map.

   [relu.png] [relu.png]

   relu layers have two main advantages:
     * they introduce a non-linearity in the network. in fact, all
       operations seen so far: convolutions, elementwise matrix
       multiplication and summation are linear. if we don't have a non
       linearity, we will end up with a linear model that will fail in the
       classification task.
     * they speed up the training process by preventing the [35]vanishing
       gradient problem.

   here's a visualization of what the relu layer does on an image example:

pooling layer

   the rectified feature maps now go throught a pooling layer. pooling is
   a down-sampling operation that reduces the dimensionality of the
   feature map.

   the most common pooling operation is max-pooling. it involves a small
   window of usally size 2x2 which slides by a stride of 2 over the
   rectified feature map and takes the largest element at each step.

   for example a 10x10 rectified feature map is converted to a 5x5 output.

   max-pooling has many benefits:
     * it reduces the size of the rectified feature maps and the number of
       trainable parameters, thus controlling overfitting
     * it condenses the feature maps by retaining the most important
       features
     * it makes the network invariant to small transformations,
       distortions and translations in the input image (a small distortion
       in input will not change the output of pooling     since we take the
       maximum value in a local neighborhood)

   the intuition behind max-pooling is not straightforward. from my
   understanding, i schematize this as follow:

   if a feature (an edge for instance) is detected, say on small portion
   of an image like the 2x2 red square above, we don't care what exact
   pixels made it appear. instead, we pick from this portion the one with
   the largest value and assume that it's this pixel that summarizes the
   visual feature. this approach seems aggressive since it loses the
   spatial information. but the fact is, it's really efficient and works
   very well in practice. in fact you shouldn't have in mind a 4x4 image
   example like this. when max-pooling is applied to a relatively high
   resolution image, the main spatial information still remains. only
   uninportant details vanish. this is why max pooling prevents
   overfitting. it makes the network concentrate on the most relevant
   information of the image.

fully-connected layer

   id98s also have a fully connected layer. you the one we are used to see
   in typical fc nets. it usually comes at the end of the network where
   the last pooled layer is flattened into a vector that is then fully
   connected to the output layer which is the prediction vector (its size
   is the number of classes).

   if you still have the whole picture in mind (input -> convolution ->
   relu -> max pooling) now add up a fully connected layer to the output
   and you'll have a complete and tiny convnet that assembles the basic
   blocks.

   this may look like this:

   note that the flattened layer is just a vectorized version of the
   pooled layer just before it.

     why do we need a fully connected layer?

   fully connected layer(s) play the role of the classification task,
   whereas the previous layers act as the feature extractors.

   fully connected layers take the condensed and localized results of
   convolutions, recitification and pooling and integrate them, combine
   them and perform the classification.

   apart from classification, adding a fully-connected layer is also a way
   of learning non-linear combinations of these features. most of the
   features from convolution and pooling layers may be good for the
   classification task, but combinations of those features might be even
   better.

   think of the fc layer as an additional level of abstraction that adds
   up to the network.

wrap up[36]  

   let's recap the layers what we've seen so far:

   layer function
   input layer takes an image as input and preserves its spatial structure
   convolution layer extracts feature maps from the input, each responding
   to a specific pattern
   relu layer introduces non-linearities in the network by setting
   negative pixels to 0
   max-pooling layer down-samples the rectified feature maps, thus
   reducing the spatial dimensionality and retaining important features.
   this prevents overfitting
   fully-connected layer learns non-linear combinations of the features
   and performs the classification task

   in a typical id98 architecture, there won't be one layer of each type.

   in fact, if you consider the example of a network that has two
   sucessive convolutional-pooling layers, the idea is that the second
   convolution takes a condensed version of the image which indicates a
   presence or not of a particular feature. so you can think of the second
   conv layer as having as input a version of the original input image.
   that version is abstracted and condensed, but still has a lot of
   spatial structure.

   we usually have 2 or 3 fc layers too. this allows to learn many
   non-linear combinations of features before proceeding to the
   classification task.

   let me quote andrej karpathy on this point:

     the most common form of a convnet architecture stacks a few
     conv-relu layers, follows them with pool layers, and repeats this
     pattern until the image has been merged spatially to a small size.
     at some point, it is common to transition to fully-connected layers.
     the last fully-connected layer holds the output, such as the class
     scores. in other words, the most common convnet architecture follows
     the pattern:</em>

   input -> [[conv -> relu]n -> pool?]m -> [fc -> relu]*k -> fc

   now that we know the basic blocks of a convnet, let's look at a typical
   network.

lenet5[37]  

   below is a popular convnet, designed by lecun et al. in 1998. it's
   called lenet5.

   [lenet5.png]

   let's tell this network architecture. i encourage you to first do this
   exercice by yourself.

     * input layer: a 32x32 grayscale image (1 color channel)
     * convolution layer n  1: it applies 6 different 5x5 filters on the
       image. this results in 6 feature maps of size 28x28 (the activation
       function in applied in this layer on the 6 feature maps, it was not
       relu back then)
     * pooling layer on the 6 28x28 feature maps resulting in 6 14x14
       pooled feature maps (1/4 the size)
     * convolution layer n  2: it applies 16 different 5x5 filters on the 6
       14x14 previous feature maps. this generates 16 feature maps of size
       10x10. each of these 16 feature maps is the sum of the six matrices
       that are the results of convolution between the first filter and
       the six inputs
     * pooling layer on the 16 10x10 feature map resulting in 16 5x5
       pooled maps
     * a first fully connected layer containing 120 neurons. each neurons
       is connected to all the pixels of the 16 5x5 feature maps. this
       layer has 16x5x5x120=48000 learnable weights
     * a second fully connected layer containing 84 neurons. this layer is
       fully connected to the previous one. it has 120x84=10080 learnable
       weights.
     * a fully connected layer to the output layer. 84x10=840 learnable
       weights.

more advanced id98 architectures[38]  

   if you're interested in more complex and state of the art convnets
   architectures, you can read about them in this [39]blog.

   below a popular id98 that won the 2012 id163 competition (alexnet).

   [alexnet.png]

3 - setting up a deep learning environment [40]  

   deep learning is computationally very heavy. you'll figure this out
   when you'll prototype your first model on your laptop.

   however, the training can be drastically sped up when you use graphics
   processing units (gpus). the reason is that gpus are very efficient at
   paralellizing tasks such as matrix mutliplications. and since neural
   nets are all about id127s, the performence in
   incredibly boosted.

   i don't have a powerful gpu on my laptop. so i used a virtual machine
   on amazon web services (aws). it's called p2.xlarge and is part of
   amazon ec2 instances. it has an nvidia gpu with 12gb of video memory,
   61gb of ram, 4vcpu and 2,496 cuda cores. it's a powerful beast and it
   costs $0.9 per hour.

   there are of course more powerful instances but for the given task
   we're tackling, a p2.xlarge is more than enough.

   [vm.png]

   i started this instance on the deep learning ami cuda 8 ubuntu version.
   [41]here to know more about it.

   it's basically a setting of an ubuntu 16.04 server that encapsulates
   all the deep learning frameworks needed (tensorflow, theano, caffe,
   keras) as well as the gpu drivers (which i heard are a nightmare to
   install...)

   [aws.png]

   this is great: aws provides with you with powerful instances and
   ready-to-use deep learning dedicated environments so that you can start
   working on your projects really fast.

   if you're not familiar with aws you can look at these two posts:
     * [42]https://blog.keras.io/running-jupyter-notebooks-on-gpu-on-aws-a
       -starter-guide.html
     * [43]https://hackernoon.com/keras-with-gpu-on-amazon-ec2-a-step-by-s
       tep-instruction-4f90364e49ac

   they should get you started to:
     * set up an ec2 vm and connect to it
     * configure the network security to access jupyter notebook remotely

4 - building a cat/dog classifier using tensorfow and keras [44]  

   the environment is now set up. we're ready to put in practice what
   we've learnt so far and build a convnet that classifies images of cats
   and dogs.

   we're going to use the tensorflow deep learning framework and keras.

     keras is a high-level neural networks api, written in python and
     capable of running on top of tensorflow, cntk, or theano. it was
     developed with a focus on enabling fast experimentation. being able
     to go from idea to result with the least possible delay is key to
     doing good research.

   [keras-tf.jpg]

4 - 1 builiding a convnet from scratch[45]  

   in this first section, we'll setup an end-to-end pipeline to train a
   id98. we'll go through data preparation and augmentation, architecture
   design, training and validation. we'll plot the loss and accuracy
   metrics on both the train and validation set: this will allow us to
   assess the improvement of the model over the training.

data preparation[46]  

   the first thing to do before starting is to download and unzip the
   [47]train dataset from kaggle.

   in [8]:
%matplotlib inline
from matplotlib import pyplot as plt
from pil import image
import numpy as np
import os
import cv2
from tqdm import tqdm_notebook
from random import shuffle
import shutil
import pandas as pd

   we must now organize the data so that it's easily processed by keras.

   we'll create a data folder in which we'll have in two subfolders:
     * train
     * validation

   each of them will have 2 folders:
     * cats
     * dogs

   at the end we'll have the following structure:
     __________________________________________________________________

data/
    train/
        dogs/
            dog001.jpg
            dog002.jpg
            ...
        cats/
            cat001.jpg
            cat002.jpg
            ...
    validation/
        dogs/
            dog001.jpg
            dog002.jpg
            ...
        cats/
            cat001.jpg
            cat002.jpg
     __________________________________________________________________

   this structure will allow our model to know from which folder to fetch
   the images as well as their labels for either training or validation.

   here's a function that allows you to construct this file tree. it has
   two parameters: the total number of images n and the ratio of
   validation set r.

   in [9]:
def organize_datasets(path_to_data, n=4000, ratio=0.2):
    files = os.listdir(path_to_data)
    files = [os.path.join(path_to_data, f) for f in files]
    shuffle(files)
    files = files[:n]

    n = int(len(files) * ratio)
    val, train = files[:n], files[n:]


    shutil.rmtree('./data/')
    print('/data/ removed')

    for c in ['dogs', 'cats']:
        os.makedirs('./data/train/{0}/'.format(c))
        os.makedirs('./data/validation/{0}/'.format(c))

    print('folders created !')

    for t in tqdm_notebook(train):
        if 'cat' in t:
            shutil.copy2(t, os.path.join('.', 'data', 'train', 'cats'))
        else:
            shutil.copy2(t, os.path.join('.', 'data', 'train', 'dogs'))

    for v in tqdm_notebook(val):
        if 'cat' in v:
            shutil.copy2(v, os.path.join('.', 'data', 'validation', 'cats'))
        else:
            shutil.copy2(v, os.path.join('.', 'data', 'validation', 'dogs'))

    print('data copied!')

   i used:
     * n : 25000 (the entire dataset)
     * r : 0.2

   in [10]:
ratio = 0.2
n = 25000
organize_datasets(path_to_data='./train/', n=n, ratio=ratio)

   let's load keras and its dependencies.

   in [11]:
import keras
from keras.preprocessing.image import imagedatagenerator
from keras_tqdm import tqdmnotebookcallback
from keras.models import sequential
from keras.layers import dense
from keras.layers import dropout
from keras.layers import flatten
from keras.constraints import maxnorm
from keras.optimizers import sgd
from keras.layers.convolutional import conv2d
from keras.layers.convolutional import maxpooling2d
from keras.utils import np_utils
from keras.callbacks import callback

using tensorflow backend.

image generators and data augmentation[48]  

   when training a model, we're not going to load the entire dataset in
   memory. this won't be efficient, especially if you use your local
   machine.

   we're going to use the imagedatagenerator class. it allows you to
   indefinitely stream the images by batches from the train and validation
   folders. every batch flows through the network, makes a forward-prop, a
   back-prop then a parameter updates (along with the test on the
   validation data). then comes the next batch and does the same thing,
   etc.

   inside the imagedatagenerator object, we're going to introduce random
   modifications on each batch. it's a process we call data augmentation.
   it allows to generate more data so that our model would never see twice
   the exact same picture. this helps prevent overfitting and makes the
   model generalize better.

   we'll create two imagedatagenerator objects.

   train_datagen for the training set and val_datagen one for the
   validation set. the two of them will apply a rescaling on the image,
   but the train_datagen will introduce more modifications.

   in [12]:
batch_size = 32

   in [13]:
train_datagen = imagedatagenerator(rescale=1/255.,
                                    shear_range=0.2,
                                    zoom_range=0.2,
                                    horizontal_flip=true
                                    )
val_datagen = imagedatagenerator(rescale=1/255.)

   from the two previous objects we're going to create two file
   generators:
     * train_generator
     * validation_generator

   each one generates, from its directory, batches of tensor image data
   with real-time data augmentation. the data will be looped over (in
   batches) indefinitely.

   in [14]:
train_generator = train_datagen.flow_from_directory(
        './data/train/',
        target_size=(150, 150),
        batch_size=batch_size,
        class_mode='categorical')

validation_generator = val_datagen.flow_from_directory(
        './data/validation/',
        target_size=(150, 150),
        batch_size=batch_size,
        class_mode='categorical')

found 20000 images belonging to 2 classes.
found 5000 images belonging to 2 classes.

model architecture[49]  

   i'll use a id98 with three convolution/pooling layers and two fully
   connected layers.

   the three conv layers will use respectively 32, 32 and 64 3x3 filters.

   i used dropout on the two fully connected layers to prevent
   overfitting.

   in [15]:
model = sequential()

model.add(conv2d(32, (3, 3), input_shape=(150, 150, 3), padding='same', activati
on='relu'))
model.add(maxpooling2d(pool_size=(2, 2)))

model.add(conv2d(32, (3, 3), padding='same', activation='relu'))
model.add(maxpooling2d(pool_size=(2, 2)))

model.add(conv2d(64, (3, 3), activation='relu', padding='same'))
model.add(maxpooling2d(pool_size=(2, 2)))

model.add(dropout(0.25))
model.add(flatten())
model.add(dense(64, activation='relu'))
model.add(dropout(0.5))
model.add(dense(2, activation='softmax'))

   i used the stochastic id119 optimizer with a learning rate
   of 0.01 and a momentum of 0.9.

   since we're having a binary classification, i used the binary
   crossid178 id168.

   in [16]:
epochs = 50
lrate = 0.01
decay = lrate/epochs
sgd = sgd(lr=lrate, momentum=0.9, decay=decay, nesterov=false)
model.compile(loss='binary_crossid178', optimizer=sgd, metrics=['accuracy'])

   keras provides a convenient method to display a summary of the model.
   for each layer, this shows up the output shape and the number of
   trainable parameters.

   this a sanity check before starting fitting the model.

   in [17]:
model.summary()

   [summary.png]

   let's look at the network architecture:

visualizing the architecture[50]  

   [model.png]

training the model[51]  

   before training the model, i defined two callback functions that will
   be called while training.
     * one for early stopping the training when the id168 stops
       improving on the validation data
     * one for storing the validation loss and accuracy of each epoch:
       this allows to plot the training error

   in [18]:
## callback for loss logging per epoch
class losshistory(callback):
    def on_train_begin(self, logs={}):
        self.losses = []
        self.val_losses = []

    def on_epoch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
        self.val_losses.append(logs.get('val_loss'))

history = losshistory()

## callback for early stopping the training
early_stopping = keras.callbacks.earlystopping(monitor='val_loss',
                              min_delta=0,
                              patience=2,
                              verbose=0, mode='auto')

   i also used [52]keras-tqdm which is an awesome progress-bar that
   perfectly integrates with keras.

   it allows you to monitor the training of you models very easily.

   what you need to do is simply load the tqdmnotebookcallback class from
   keras_tqdm then pass it as a third callback functions.

   here's what keras-tqdm looks like on simple example:

   [keras-tqdm.png]

   a few words about the training:
     * we'll use the fit_generator method which is a variant (of the
       standard fit method) that takes a generator as input.
     * we'll train the model over 50 epochs: over one epoch 20000 unique
       and augmented images will flow by batch of 32 to the network,
       performing a forward and back propagation and adjusting the weights
       with sgd. the idea of using multiple epochs is to prevent
       overfitting.

   in [19]:
fitted_model = model.fit_generator(
        train_generator,
        steps_per_epoch= int(n * (1-ratio)) // batch_size,
        epochs=50,
        validation_data=validation_generator,
        validation_steps= int(n * ratio) // batch_size,
        callbacks=[tqdmnotebookcallback(leave_inner=true, leave_outer=true), ear
ly_stopping, history],
        verbose=0)

   this is a heavy computation:
     * if you're on your laptop this may take about 15 minutes per epoch
     * if you're using an the p2.xlarge ec2 instance like me, this takes
       about 2 minutes or so per epoch

   tqdm allows you to monitor the validation loss and accuracy on each
   epochs. this is useful to check the quality of your model.

classification results[53]  

   we reached 89.4% accuracy (on the validation data) in 34 epochs
   (training/validation error and accuracy displayed below)

   this is a good result given that i didn't invest too much time
   designing the architecture of the network.

   now let's save the model for later use.

   in [20]:
model.save('./models/model4.h5')

   let's plot the train and validation losses on the same graph:

   in [21]:
losses, val_losses = history.losses, history.val_losses
fig = plt.figure(figsize=(15, 5))
plt.plot(fitted_model.history['loss'], 'g', label="train losses")
plt.plot(fitted_model.history['val_loss'], 'r', label="val losses")
plt.grid(true)
plt.title('training loss vs. validation loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()

   [loss.png]

   we interrupt the training when the validation loss doesn't improve on
   two successive epochs.

   let's now plot the accuracy on both the training set and validation
   set.

   in [22]:
losses, val_losses = history.losses, history.val_losses
fig = plt.figure(figsize=(15, 5))
plt.plot(fitted_model.history['acc'], 'g', label="accuracy on train set")
plt.plot(fitted_model.history['val_acc'], 'r', label="accuracy on validation set
")
plt.grid(true)
plt.title('training accuracy vs. validation accuracy')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()

   [accuracy.png]

   these two metrics keep increasing before reaching a plateau where the
   model eventually starts overfitting (from epoch 34).

4 - 2 loading a pre-trained model[54]  

   so far so good: we designed a custom convnet that performs reasonably
   well on the valiation data with ~ 89% accuracy.

   there is however a way to get a better score: loading the weights of a
   pre-trained convnet on a large dataset that includes images of cats and
   dogs among 1000 classes. such a network would have learnt relevant
   features that are relevant to our classification.

   i'll load the weights of the vgg16 network: more specifically, i'm
   going to load the network weights up to the last conv layer. this
   network part acts as a feature detector to which we're going to add
   fully connected layers for our classification task.

   vgg16 is a very large network in comparison to lenet5. it has 16 layers
   with trainable weights and around 140 millions parameters. to learn
   more about vgg16 please refer to this [55]pdf link.

   we first start by loading the vgg16 weights (trained on id163) by
   specifying that we're not interested in the last three fc layers.

   in [23]:
from keras import applications
# include_top: whether to include the 3 fully-connected layers at the top of the
 network.
model = applications.vgg16(include_top=false, weights='id163')
datagen = imagedatagenerator(rescale=1. / 255)

   now we pass the images through the network to get a feature
   representation that we'll input to a neural network classifier.

   we do this for the training set and the validation set.

   in [24]:
generator = datagen.flow_from_directory('./data/train/',
                                        target_size=(150, 150),
                                        batch_size=batch_size,
                                        class_mode=none,
                                        shuffle=false)

bottleneck_features_train = model.predict_generator(generator, int(n * (1 - rati
o)) // batch_size)
np.save(open('./features/bottleneck_features_train.npy', 'wb'), bottleneck_featu
res_train)

found 20000 images belonging to 2 classes.

   in [25]:
generator = datagen.flow_from_directory('./data/validation/',
                                        target_size=(150, 150),
                                        batch_size=batch_size,
                                        class_mode=none,
                                        shuffle=false)

bottleneck_features_validation = model.predict_generator(generator, int(n * rati
o) // batch_size,)
np.save('./features/bottleneck_features_validation.npy', bottleneck_features_val
idation)

found 5000 images belonging to 2 classes.

   when the images are passed to the network, they are in the right
   orders. so we associate the labels to them easily.

   in [26]:
train_data = np.load('./features/bottleneck_features_train.npy')
train_labels = np.array([0] * (int((1-ratio) * n) // 2) + [1] * (int((1 - ratio)
 * n) // 2))

validation_data = np.load('./features/bottleneck_features_validation.npy')
validation_labels = np.array([0] * (int(ratio * n) // 2) + [1] * (int(ratio * n)
 // 2))

   now we design a small fully connected network that plugs in to the
   features extracted from the vgg16 and acts as the classification part
   of a id98.

   in [27]:
model = sequential()
model.add(flatten(input_shape=train_data.shape[1:]))
model.add(dense(512, activation='relu'))
model.add(dropout(0.5))
model.add(dense(256, activation='relu'))
model.add(dropout(0.2))
model.add(dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop',
              loss='binary_crossid178', metrics=['accuracy'])

   in [28]:
fitted_model = model.fit(train_data, train_labels,
          epochs=15,
          batch_size=batch_size,
          validation_data=(validation_data, validation_labels[:validation_data.s
hape[0]]),
          verbose=0,
          callbacks=[tqdmnotebookcallback(leave_inner=true, leave_outer=false),
history])

   we reached 90.7% accuracy on 15 epochs only. quite not bad.

   note that each epoch takes around 1 minute on my personal laptop.

   in [29]:
fig = plt.figure(figsize=(15, 5))
plt.plot(fitted_model.history['loss'], 'g', label="train losses")
plt.plot(fitted_model.history['val_loss'], 'r', label="val losses")
plt.grid(true)
plt.title('training loss vs. validation loss - vgg16')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()

   [vgg16_loss.png]

   in [30]:
fig = plt.figure(figsize=(15, 5))
plt.plot(fitted_model.history['acc'], 'g', label="accuracy on train set")
plt.plot(fitted_model.history['val_acc'], 'r', label="accuracy on validation set
e")
plt.grid(true)
plt.title('training accuracy vs. validation accuracy - vgg16')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()

   [vgg16_acc.png]

   many deep learning pioneers encourage to use pre-trained networks for
   classification tasks. in fact, this usually leverages the training of a
   very large network on a very large dataset.

   keras allows you easliy to download pretrained networks like vgg16,
   googlenet and resnet. more about this [56]here.

   the general motto is:

     don't be a hero. don't reinvent the wheel. use pre-trained networks!

where to go from here ?[57]  

if you're interested in improving a custom id98:[58]  

     * on the dataset level, introduce more data augmentation
     * play with the network hyperparameters: number of conv layers,
       number of filters, size of the filters. have a validation dataset
       to test each combination.
     * change the optimizer or tweak it
     * try different cost functions
     * use more fc layers
     * introduce more aggressive dropout

if you're interested in having better results with pretrained networks:[59]  

     * use different network architectures
     * use more fc layers with more hidden units

if you want to do discover what the id98 model has learnt:[60]  

     * visualize feature maps. i haven't done that yet, but there's an
       interesting [61]paper on the subject

if you want to use the trained model:[62]  

     * ship it in a web app and use it on new cat/dog images. this is a
       good exercise to see if the model generalizes well.

conclusion[63]  

   this article was an opportunity to go through the theory behind
   convolutional neural networks and explain each of their principal
   components in more details.

   this was also a hands-on guide to setup a deep learning dedicated
   environment on aws and develop an end-to-end model from scratch as well
   as an enhanced model based on a pre-trained one.

   using python for deep learning is extermely fun. keras made it easier
   for preprocessing the data and building up the layers. keep in mind
   that if you want someday to build custom neural net components, you'll
   have to switch to another framework.

   i hope this gave you a practical intuition about the convnets
   mechanisms and a strong appetite to learn more.

   convnets are amazingly powerful. anyone working on id161
   believes in their robustness and efficiency.

   their applications are getting a larger scope. nlp practictioners are
   now the ones who are switching to convnets. here are some of their
   applications:
     * text classification using id98s : [64]link
     * automated image captioning (image + text): [65]link
     * text classification at character level: [66]link

references[67]  

   here's a list of some references i used to learn about neural nets and
   convnets:
    1. [68]neuralnetworksanddeeplearning.com : by far the best notes on
       neural networks and deep learning. i highly recommend this website
       to anyone who want to start learning about neural nets.
    2. [69]cs231n convolutional neural networks for visual recognition :
       andrej karpathy's lectures at stanford. great mathematical focus.
    3. a beginner guide to understanding neural networks: a three-part
       post explaining id98s, from the basic high level inuition to the
       architecture details. very interesting read. learnt a lot from it.
          + [70]part 1
          + [71]part 2
          + [72]part 3
    4. [73]running jupyter notebooks on gpu on aws
    5. [74]building powerful image classification models using very little
       data
    6. [75]catdognet - keras convnet starter
    7. [76]a quick introduction to neural networks
    8. [77]an intuitive explanation of convolutional neural networks
    9. [78]visualizing parts of convolutional neural networks using keras
       and cats

   [79]deep learning [80]convolutional neural networks [81]image
   classification [82]keras [83]tensorflow [84]aws [85]gpu [86]python
   [87]kaggle

   like this article? share it with your friends!

related posts:

     * [88]how to score 0.8134 in titanic kaggle challenge
     * [89]id31 on twitter using id97 and keras
     * [90]how to mine newsfeed data and extract interactive insights in
       python

   please enable javascript to view the [91]comments powered by disqus.

      ahmed besbes 2016 - this work is licensed under a [92]creative
   commons attribution-sharealike 1.0 international license

   built using [93]pelican - [94]flex theme by [95]alexandre vicenzi

   [96]creative commons license

references

   visible links
   1. https://ahmedbesbes.com/feeds/all.atom.xml
   2. https://ahmedbesbes.com/
   3. https://ahmedbesbes.com/
   4. https://ahmedbesbes.com/
   5. https://ahmedbesbes.com/archives.html
   6. https://ahmedbesbes.com/categories.html
   7. https://ahmedbesbes.com/tags.html
   8. https://ahmedbesbes.com/feeds/all.atom.xml
   9. https://ahmedbesbes.com/category/deep-learning.html
  10. https://www.kdnuggets.com/2017/11/understanding-deep-convolutional-neural-networks-tensorflow-keras.html
  11. https://www.kdnuggets.com/2017/11/understanding-deep-convolutional-neural-networks-tensorflow-keras.html
  12. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#intro
  13. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#id98
  14. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#setup
  15. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#code
  16. https://github.com/ahmedbesbes/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras
  17. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#-1---a-fun-use-case:-how-to-classify-cats-and-dogs?-
  18. https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition
  19. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#-2---fully-connected-networks-vs-id98s-
  20. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#2---1-a-fully-connected-(fc)-neural-network
  21. http://cs231n.github.io/neural-networks-1/
  22. http://cs231n.github.io/neural-networks-2/
  23. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#i-see-two-main-reasons:
  24. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#2---2-convolutional-neural-networks
  25. https://www.youtube.com/watch?v=uckpdam8cni
  26. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#input
  27. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#conv
  28. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#relu
  29. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#maxpool
  30. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#fc
  31. https://en.wikipedia.org/wiki/kernel_(image_processing)
  32. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#more-than-one-filter-on-a-convolution-layer?
  33. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#what-about-filter-weights?-how-to-choose-them?
  34. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#weight-sharing?
  35. https://www.quora.com/how-does-the-relu-solve-the-vanishing-gradient-problem
  36. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#wrap-up
  37. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#lenet5
  38. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#more-advanced-id98-architectures
  39. https://adeshpande3.github.io/adeshpande3.github.io/the-9-deep-learning-papers-you-need-to-know-about.html
  40. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#-3---setting-up-a-deep-learning-environment-
  41. https://aws.amazon.com/marketplace/pp/b06vspxkdx
  42. https://blog.keras.io/running-jupyter-notebooks-on-gpu-on-aws-a-starter-guide.html
  43. https://hackernoon.com/keras-with-gpu-on-amazon-ec2-a-step-by-step-instruction-4f90364e49ac
  44. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#-4---building-a-cat/dog-classifier-using-tensorfow-and-keras-
  45. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#4---1-builiding-a-convnet-from-scratch
  46. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#data-preparation
  47. https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/train.zip
  48. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#image-generators-and-data-augmentation
  49. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#model-architecture
  50. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#visualizing-the-architecture
  51. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#training-the-model
  52. https://github.com/bstriner/keras-tqdm
  53. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#classification-results
  54. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#4---2-loading-a-pre-trained-model
  55. https://arxiv.org/pdf/1409.1556.pdf
  56. https://keras.io/applications/
  57. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#where-to-go-from-here-?
  58. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#if-you're-interested-in-improving-a-custom-id98:
  59. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#if-you're-interested-in-having-better-results-with-pretrained-networks:
  60. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#if-you-want-to-do-discover-what-the-id98-model-has-learnt:
  61. https://arxiv.org/pdf/1311.2901.pdf
  62. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#if-you-want-to-use-the-trained-model:
  63. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#conclusion
  64. https://chara.cs.illinois.edu/sites/sp16-cs591txt/files/0226-presentation.pdf
  65. https://cs.stanford.edu/people/karpathy/sfmltalk.pdf
  66. https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf
  67. https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html#references
  68. http://neuralnetworksanddeeplearning.com/
  69. http://cs231n.github.io/convolutional-networks/
  70. https://adeshpande3.github.io/adeshpande3.github.io/a-beginner's-guide-to-understanding-convolutional-neural-networks/
  71. https://adeshpande3.github.io/adeshpande3.github.io/a-beginner's-guide-to-understanding-convolutional-neural-networks-part-2/
  72. https://adeshpande3.github.io/adeshpande3.github.io/the-9-deep-learning-papers-you-need-to-know-about.html
  73. https://blog.keras.io/running-jupyter-notebooks-on-gpu-on-aws-a-starter-guide.html
  74. https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html
  75. https://www.kaggle.com/jeffd23/catdognet-keras-convnet-starter
  76. https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/
  77. https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/
  78. https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59
  79. https://ahmedbesbes.com/tag/deep-learning.html
  80. https://ahmedbesbes.com/tag/convolutional-neural-networks.html
  81. https://ahmedbesbes.com/tag/image-classification.html
  82. https://ahmedbesbes.com/tag/keras.html
  83. https://ahmedbesbes.com/tag/tensorflow.html
  84. https://ahmedbesbes.com/tag/aws.html
  85. https://ahmedbesbes.com/tag/gpu.html
  86. https://ahmedbesbes.com/tag/python.html
  87. https://ahmedbesbes.com/tag/kaggle.html
  88. https://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html
  89. https://ahmedbesbes.com/sentiment-analysis-on-twitter-using-id97-and-keras.html
  90. https://ahmedbesbes.com/how-to-mine-newsfeed-data-and-extract-interactive-insights-in-python.html
  91. https://disqus.com/?ref_noscript
  92. http://creativecommons.org/licenses/by-sa/1.0/
  93. http://getpelican.com/
  94. https://github.com/alexandrevicenzi/flex
  95. http://alexandrevicenzi.com/
  96. http://creativecommons.org/licenses/by-sa/1.0/

   hidden links:
  98. https://fr.linkedin.com/in/ahmed-besbes-99a91661
  99. https://github.com/ahmedbesbes
 100. https://twitter.com/ahmed_besbes_?lang=fr
 101. https://www.quora.com/profile/ahmed-besbes
 102. https://stackoverflow.com/users/4583959/ahmed-besbes
