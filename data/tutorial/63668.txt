   #[1]probably approximately a scientific blog - atom [2]probably
   approximately a scientific blog - rss [3]probably approximately a
   scientific blog - atom

[4]probably approximately a scientific blog

   human-interpretable computer science and other ramblings

monday, october 30, 2017

ambiguity

   [5][slow_children.jpg]
   one of the problems with teaching computers to understand natural
   language, is that much of the meaning in what people say is actually
   hidden in what they don't say. as humans, we trivially interpret the
   meaning of ambiguous words, written or spoken, according to their
   context. for example, this blog post is published in a blog that
   largely discusses natural language processing, so if i write "nlp",
   you'd know i refer to natural language processing rather
   than to [6]neuro-linguistic programming. if i told you that the blog
   post doesn't fit into a tweet because it's too long, you'd know that
   the blog post is too long and not that the tweet is too long. you would
   infer that even without having any knowledge about [7]twitter's
   character limit, because it just doesn't make sense otherwise.
   unfortunately, common-sense and world knowledge that come so easily for
   us are not trivial to teach to machines. in this post, i will present a
   few cases in which ambiguity is a challenge in nlp, along with common
   ways in which we try to overcome it.
     __________________________________________________________________

   polysemous words, providing material for dad jokes since... ever.
   lexical ambiguity
   lexical ambiguity can occur when a word is polysemous, i.e. has more
   than one meaning, and the sentence in which it is contained can be
   interpreted differently depending on its correct sense.
   for example, the word bank has two meanings - either a financial
   institute or the land alongside the river. when we read a sentence with
   the word bank, we understand which sense of bank the text refers to
   according to the context:
   (1) police seek person who robbed bank in downtown reading.
   (2) the faster-moving surface water travels along the concave bank.
   in these example sentences, "robbed" indicates the first sense while
   "water" and "concave" indicate the second.
   existing solutions for lexical ambiguity
   id27s are great, but they conflate all the different senses
   of a word into one vector. since id27s [8]are learned from
   the occurrences of a word in a text corpus, the id27
   for bank is learned from its occurrences in both senses, and will be
   affected from neighbors related to the first sense (money, atm, union)
   and of the second (river, west, water, etc.). the resulting vector is
   very likely to tend towards the more common sense of bank, as can be
   seen in this [9]demo: see how all the nearest words to bank are related
   to its financial sense.
   id51 (wsd) is an nlp task aimed
   at disambiguating a word in context. given a list of potential word
   senses for each word, the correct sense of the word in the given
   context is determined. similar to the way humans disambiguate words,
   wsd systems also rely on the surrounding context. a simple way to do
   so, in a machine-learning based solution (i.e. learning from examples),
   is to represent a word-in-context as the average of its context word
   vectors ("bag-of-words"). in the example above, we get for the first
   occurrence of bank: feature_vector(bank) = 1/8( (vector(police)
   + vector(seek) + vector(person) + vector(who) + vector(robbed)
   + vector(in) + vector(downtown) + vector(reading)), and for the
   second: feature_vector(bank) = 1/9(vector(the) + vector(faster) +
   vector(moving) + vector(surface) + vector(water) + vector(travels) +
   vector(along) + vector(the) + vector(concave)).
     __________________________________________________________________

                               [10][acl.png]
            can google expand the acronym "acl" correctly for me?

   acronyms
   while many words in english are polysemous, things turn absolutely
   chaotic with acronyms. acronyms are highly polysemous, some having
   dozens of different expansions. to make things even more complicated,
   as opposed to regular words, whose various senses are recorded in
   dictionaries and taxonomies like [11]id138, acronyms are often
   domain-specific and not commonly known.
   take for example a google search for "acl 2017". i get results both for
   the annual meeting of the association for computational linguistics
   (which is what i was searching for) and for the austin city limits
   festival. i have no idea whether this happens because (a) these are the
   two most relevant/popular expansions of "acl" lately or the only ones
   that go with "2017"; or (b) google successfully disambiguated my query,
   showing the nlp conference first, and leaving also the musical festival
   ranked lower in the search results, since it knows i also like music
   festivals. probably (a) :)
   existing solutions for acronym expansion
   expanding acronyms is considered a different task from wsd, in which
   there is no inventory of potential expansions for each acronym. given
   enough context (e.g. "2017" is a context word for the acronym acl), it
   is possible to find texts that contain the expansion. this can either
   be by searching for a pattern (e.g. "association for computational
   linguistics (acl)") or considering all the word sequences that start
   with these initials, and deciding on the correct one using rules or a
   machine-learning based solution.
     __________________________________________________________________

   syntactic ambiguity
   no beginner nlp class is complete without at least one of the following
   example sentences:
    1. they ate pizza with anchovies
    2. [12]i shot an elephant wearing my pajamas
    3. time flies like an arrow

   common to all these examples is that each can be interpreted as
   multiple different meanings, where the different meanings differ in the
   underlying syntax of the sentence. let's go over the examples.
   the first sentence "they ate pizza with anchovies", can be interpreted
   as (i) "they ate pizza and the pizza had anchovies on it", which is the
   more likely interpretation, illustrated on the left side of the image
   below. this sentence has at least two more crazy interpretations: (ii)
   they ate pizza using anchovies (instead of using utensils, or eating
   with their hands), as in the right side of the image below, and (iii)
   they ate pizza and their anchovy friends ate pizza with them.

                    [13][pizza_with_anchovies_small.jpg]
    visual illustration of the interpretations of the sentence "they ate
                           pizza with anchovies".
    image taken from [14]https://explosion.ai/blog/syntaxnet-in-context.

   the first interpretation considers "with anchovies" as describing the
   pizza, while the other two consider it as describing the eating action.
   in the output of a [15]syntactic parser, the interpretations will
   differ by the tree structure, as illustrated below.

                                          [16][trees.png]
       possible syntactic trees for the sentence "they ate pizza with
                       anchovies", using [17]displacy.

   although this is a classic example, both the [18]spacy and the
   [19]stanford core nlp demos got it wrong. the difficulty is that
   syntactically speaking, both trees are likely. humans know to prefer
   the first one based on the semantics of the words, and using their
   knowledge that anchovy is something that you eat rather than eat with.
   machines don't come with this knowledge.
   a similar parser decision is crucial in the second sentence, and just
   in case you haven't managed to find the funny interpretations yet: "i
   shot an elephant wearing my pajamas" has two ambiguities: first, does
   shoot mean taking a photo of, or pointing a gun to? (a lexical
   ambiguity). but more importantly, who's wearing the pajamas? depending
   on whether wearing is attached to shot (meaning that i wore the pajamas
   while shooting) or to elephant (meaning that the elephant miraculously
   managed to squeeze into my pajamas). this entire scene, regardless of
   the interpretation, is very unlikely, and please don't kill elephants,
   even if they're stretching your pajamas.
   the third sentence is just plain weird, but it also has multiple
   interpretations, of which you can read about [20]here.
   existing solutions for syntactic ambiguity
   in the past, parsers were based on deterministic grammar rules (e.g. a
   noun and a modifier create a noun-phrase) rather than on machine
   learning. a possible solution to the ambiguity issue was to add
   different rules for different words. for more details, you can read
   my [21]answer to [22]natural language processing: what does it mean to
   lexicalize pid18s? on [23]quora.
   today, similarly to other nlp tasks, parsers are mostly based on neural
   networks. in addition to other information, the id27s of the
   words in the sentence are used for deciding on the correct output. so
   potentially, such a parser may learn that "eat * with [y]" yields the
   output in the left of the image if y is edible (similar to word
   embeddings of other edible things), otherwise the right one.
     __________________________________________________________________

   coreference ambiguity
   very often a text mentions an entity (someone/something), and then
   refers to it again, possibly in a different sentence, using another
   word. take these two paragraphs from a news article as an example:

                                            [24][coref.png]
   from [25]https://www.theguardian.com/sport/2017/sep/22/donald-trump-nfl
                         -national-anthem-protests.
      the various entities participating in the article were marked in
                              different colors.

   i marked various entities that participate in the article in different
   colors. i grouped together different mentions of the same entities,
   including pronouns ("he" as referring to "that son of a bitch"; excuse
   my language, i'm just quoting trump) and different descriptions
   ("donald trump", "the president"). to do that, i had to use my common
   sense (the he must refer to that son of a bitch who disrespected the
   flag, definitely not to the president or the nfl owners, right?) and my
   world knowledge (trump is the president). again, any task that requires
   world knowledge and reasoning is difficult for machines.
   existing solutions for coreference resolution
   coreference resolution systems group mentions that refer to the same
   entity in the text. they go over each mention (e.g. the president), and
   either link it to an existing group containing previous mentions of the
   same entity ([donald trump, the president]), or start a new entity
   cluster ([the president]). systems differ from each other, but in
   general, given a pair of mentions (e.g. donald trump, the president),
   they extract features referring either to each single mention (e.g.
   part-of-speech, word vector) or to the pair (e.g. gender/number
   agreement, etc.), and decide whether these mentions refer to the same
   entity.
   note that mentions can be proper-names (donald trump), common nouns
   (the president) and pronouns (he); identifying coreference between
   pairs of mentions from each type requires different abilities and
   knowledge. for example, proper-name + common noun may require world
   knowledge (donald trump is the president), while pairs of common nouns
   can sometimes be solved with semantic similarity (e.g. synonyms like
   owner and holder). pronouns can sometimes be matched to their
   antecedent (original mention) based on proximity and linguistic cues
   such as gender and number agreement, but very often there is more than
   one possible option for matching.
   a nice example of solving coreference ambiguity is the [26]winograd
   schema challenge, of which i've first heard from this [27]post in
   the [28]artificial detective blog. in this contest, computer programs
   are given a sentence with two nouns and an ambiguous pronoun, and they
   need to answer which noun the pronoun refers to, as in the following
   example:
   the trophy would not fit in the brown suitcase because it was too big.
   what was too big?
   answer 0: the trophy
   answer 1: the suitcase
   answering such questions requires, yes, you guessed correctly -
   commonsense and world knowledge. in the given example, the computer
   must reason that for the first object to fit into the second, the first
   object must be smaller than the second, so if the trophy could not fit
   into the suitcase, the trophy must be too big. conversely, if instead
   of big, the question would have read small, the answer would have been
   "the suitcase".
     __________________________________________________________________

   noun compounds
   words are usually considered as the basic unit of a language, and many
   nlp applications use [29]id27s to represent the words in the
   text. id27s do a pretty decent job in capturing the semantics
   of a single word, and sometimes also its syntactic and morphological
   properties. the problem starts when we want to capture the semantics of
   a multi-word expression (or a sentence, or a document). the embedding
   of a word, for example dog, is learned from its occurrences in a large
   text corpus; the more common a word is, the more occurrences there are,
   and the higher the quality of the learned id27 would be (it
   would be located "correctly" in the vector space near things that are
   similar to dog). a bigram like hot dog is already much less frequent,
   even less frequent is hot dog bun, and so on. the conclusion is clear -
   we can't learn embeddings for multi-word expressions the same way we do
   for single words.
   the alternative is to try to somehow combine the id27s of the
   single words in the expression into a meaningful representation.
   although there are many approaches for this task, there is no
   one-size-fits-all solution for this problem; a multi-word expression is
   not simply the sum of its single word meanings (hot dog is an extreme
   counter-example!).
   one example out of many would be noun-compounds. a noun-compound is a
   noun that is made up of two or more words, which usually consists of
   the head (main) noun and its modifiers, e.g. video conference, pumpkin
   spice latte, and paper clip. the use of noun-compounds in english is
   very common, but most noun-compounds don't appear frequently in text
   corpora. as humans, we can usually interpret the meaning of a new
   noun-compound if we know the words it is composed of; for example, even
   though i've never heard of watermelon soup, i can easily infer that it
   is a soup made of watermelon.
   similarly, if i want my software to have a nice vector representation
   of watermelon soup, there is no way i can base it on the corpus
   occurrences of watermelon soup -- it would be too rare. however, i used
   my commonsense to build a representation of watermelon soup in my head
   -- how would my software know that there is a made of relation between
   watermelon and soup? this relation can be one out of many, for example:
   video conference (means), paper clip (purpose), etc. note that the
   relation is implicit, so there is no immediate way for the machine to
   know what's the correct relation between the head and the
   modifier.^[30]1  to complicate things a bit further, many
   noun-compounds are non-compositional, i.e. the meaning of the compound
   is not a straightforward combination of the meaning of its words, as in
   [31]hot dog, [32]baby sitting, and [33]banana hammock.
   existing solutions for noun-compound interpretation
   automatic methods for interpreting the relation between the head and
   the modifier of noun-compounds have largely been divided into two
   approaches:
   (1) machine-learning methods, i.e. hand-labeling a bunch of
   noun-compounds to a set of pre-defined relations (e.g. part of, made
   of, means, purpose...), and learning to predict the relation for unseen
   noun-compounds. the features are either related to each single word
   (head/modifier), such as their word vectors or lexical properties from
   [34]id138, or to the noun-compound itself and its corpus occurrences.
   some methods also try to learn a vector representation for a
   noun-compound in the form of applying a function to the id27s
   of its single words (e.g. vector(olive oil) = function(vector(olive),
   vector(oil))).
   (2) finding joint occurrences of the nouns in a text corpus, some of
   which would explicitly describe the relation between the head and the
   modifier. for example "oil made of olives".
   while there has been a lot of work in this area, success on this task
   is still mediocre. a recent [35]paper suggested that current methods
   succeed mostly due to predicting the relation based solely on the head
   or on the modifier - for example, most noun-compounds with the head
   "oil" hold the made of relation (olive oil, coconut oil, avocado oil,
   ...). while this guess can be pretty accurate most of the times, it may
   cause funny mistakes as in the meme below.

                            [36][baby_oil.jpg]
               from [37]http://www.quickmeme.com/meme/3r9thy.

   for the sake of simplicity, i focused on two-word noun-compounds, but
   noun-compounds with more than two words have an additional ambiguity -
   a syntactic ambiguity - what are the head-modifier relations in the
   compound? it is often referred to as bracketing. without getting into
   too many details, consider the example of hot dog bun from before. it
   should be interpreted as [[hot dog][bun]] rather than [hot [[38]dog
   bun]].
     __________________________________________________________________

   more to read?
   yeah, i know it was a long post, but there is so much more ambiguity in
   language that i haven't discussed. here is another selected topic, in
   case you're looking for more to read. we all speak a second language
   called emoji, which is full of ambiguity. here are some interesting
   articles about it: [39]emoji could cause confusion, trouble in the
   workplace, [40]the real meaning of all those emoji in twitter handles,
   [41]learning the language of emoji, and [42]why emojis may be the best
   thing to happen to language in the digital age. for the older people
   among us (and in the context of emoji, i consider myself old too, so no
   offence anyone), if you're not sure about the meaning of an emoji, why
   don't you check [43]emojipedia first, just to make sure you're not
   accidentally using [44]phallic symbols in your grocery list?
     __________________________________________________________________

   [45]1 in this very interesting [46]paper by preslav nakov there is a
   nice observation: a noun-compound is a "compression device" that allows
   saying more with less words. ^[47]   
   posted by [48]vered shwartz at [49]9:11 pm
   [50]email this[51]blogthis![52]share to twitter[53]share to
   facebook[54]share to pinterest
   labels: [55]natural language processing

5 comments:

    1. [56]achyuta[57]november 6, 2017 at 6:53 pm
       nice article. thanks a lot. looking forward to get a lot knowledge
       from you in future.
       reply[58]delete
       replies
            reply
    2. [59]achyuta[60]november 6, 2017 at 6:56 pm
       can you help me in building a id13 from a raw text ?
       reply[61]delete
       replies
         1. [62]vered shwartz[63]november 6, 2017 at 9:31 pm
            thanks for the feedback!
            what kind of help do you mean? i can refer you to papers about
            knowledge base completion if it helps:
            for a start, there is the universal schema
            (http://www.aclweb.org/anthology/n13-1008) and the line of
            work that continued it. there is the patty algorithm
            (http://www.aclweb.org/anthology/d12-1104), and the nell
            project (http://rtw.ml.cmu.edu/rtw/). all are from a few years
            back, so you might want to also search for some more recent
            work.
            [64]delete
            replies
                 reply
            reply
    3. [65]geetha devi[66]september 18, 2018 at 8:33 am
       this comment has been removed by a blog administrator.
       reply[67]delete
       replies
            reply
    4. [68]boc sciences[69]october 15, 2018 at 5:28 pm
       this comment has been removed by a blog administrator.
       reply[70]delete
       replies
            reply

   add comment
   load more...

   [71]newer post [72]older post [73]home
   subscribe to: [74]post comments (atom)

   feel free to use the content published in this blog, but if you
   re-distribute it, please provide a link to the original post.

about me

   [75]my photo

   [76]vered shwartz

   [77]view my complete profile
   [78]follow @veredshwartz

posts by topic

     * [79]general (3)
     * [80]machine learning (4)
     * [81]machine translation (3)
     * [82]math (1)
     * [83]natural language processing (17)

blog archive

     * [84]     [85]2018 (4)
          + [86]     [87]september (1)
          + [88]     [89]august (1)
          + [90]     [91]april (1)
          + [92]     [93]january (1)

     * [94]     [95]2017 (3)
          + [96]     [97]october (1)
               o [98]ambiguity
          + [99]     [100]august (1)
          + [101]     [102]march (1)

     * [103]     [104]2016 (7)
          + [105]     [106]november (2)
          + [107]     [108]august (1)
          + [109]     [110]june (1)
          + [111]     [112]may (1)
          + [113]     [114]march (1)
          + [115]     [116]january (1)

     * [117]     [118]2015 (10)
          + [119]     [120]november (1)
          + [121]     [122]october (1)
          + [123]     [124]september (2)
          + [125]     [126]august (3)
          + [127]     [128]july (3)

follow by email

   ____________________ submit

subscribe to

   [arrow_dropdown.gif] posts
   [129][subscribe-netvibes.png] [130][subscribe-yahoo.png]
   [131][icon_feed12.png] atom
   [arrow_dropdown.gif] posts
   [arrow_dropdown.gif] comments
   [132][subscribe-netvibes.png] [133][subscribe-yahoo.png]
   [134][icon_feed12.png] atom
   [arrow_dropdown.gif] comments

recommended blogs

     * [icon18_wrench_allbkg.png]
       [135]elvis on medium
     * [icon18_wrench_allbkg.png]
       [136]                                  
     * [icon18_wrench_allbkg.png]
       [137]lifesimulator |                               .                                        
                     .
     * [icon18_wrench_allbkg.png]
       [138]                       
     * [icon18_wrench_allbkg.png]
       [139]artificial detective
     * [icon18_wrench_allbkg.png]
       [140]natural language processing blog
     * [icon18_wrench_allbkg.png]
       [141]ben frederickson
     * [icon18_wrench_allbkg.png]
       [142]language processing
     * [icon18_wrench_allbkg.png]
       [143]colah's blog
     * [icon18_wrench_allbkg.png]
       [144]resources for machine learning | gengo ai
     * [icon18_wrench_allbkg.png]
       [145]dirk hovy's blog
     * [icon18_wrench_allbkg.png]
       [146]andrej karpathy blog

   copyright (2015-2019) vered shwartz. all rights reserved.. simple
   theme. powered by [147]blogger.

references

   visible links
   1. http://veredshwartz.blogspot.com/feeds/posts/default
   2. http://veredshwartz.blogspot.com/feeds/posts/default?alt=rss
   3. http://veredshwartz.blogspot.com/feeds/8556945456906008663/comments/default
   4. http://veredshwartz.blogspot.com/
   5. https://4.bp.blogspot.com/-dsoxcpfuifu/wdp416ftksi/aaaaaaaaucs/rq3wkrgmxpstm_pzcp1iwzixx_wtsdboqclcbgas/s1600/slow_children.jpg
   6. https://en.wikipedia.org/wiki/neuro-linguistic_programming
   7. https://www.recode.net/2017/9/26/16364002/twitter-longer-tweets-character-limit-140-280
   8. http://veredshwartz.blogspot.co.il/2016/01/representing-words.html
   9. http://bionlp-www.utu.fi/wv_demo/
  10. https://3.bp.blogspot.com/-hd1b6bu7pqm/wdqa6wqtjai/aaaaaaaauda/wb1qxokltc0mhkizaitscbvcpzawu_h4gclcbgas/s1600/acl.png
  11. http://id138.princeton.edu/
  12. https://youtu.be/nfn_gcjgojo
  13. https://2.bp.blogspot.com/-nmgjipklrnq/wc_k7kpsmei/aaaaaaaauwg/3k2rqwvif5mrfxunymhnykxwoy7pa6cswclcbgas/s1600/pizza_with_anchovies_small.jpg
  14. https://explosion.ai/blog/syntaxnet-in-context
  15. https://veredshwartz.blogspot.co.il/2016/06/linguistic-analysis-of-texts.html
  16. https://3.bp.blogspot.com/-vc6v2zetmi4/wc_rrxiqski/aaaaaaaauw4/2-wdo7g4i60jqhofy5_jp33zh5owjzixgclcbgas/s1600/trees.png
  17. https://demos.explosion.ai/displacy/
  18. https://demos.explosion.ai/displacy/
  19. http://nlp.stanford.edu:8080/corenlp/process
  20. https://en.wikipedia.org/wiki/time_flies_like_an_arrow;_fruit_flies_like_a_banana
  21. https://www.quora.com/natural-language-processing-what-does-it-mean-to-lexicalize-pid18s/answer/vered-shwartz?srid=8j1c
  22. https://www.quora.com/natural-language-processing-what-does-it-mean-to-lexicalize-pid18s
  23. https://www.quora.com/
  24. https://2.bp.blogspot.com/-qnignu9j3ww/wdvkhp2s3_i/aaaaaaaauem/9rawzh49qd0m--2jlmefo2xydx4exf5swclcbgas/s1600/coref.png
  25. https://www.theguardian.com/sport/2017/sep/22/donald-trump-nfl-national-anthem-protests
  26. http://commonsensereasoning.org/winograd.html
  27. https://artistdetective.wordpress.com/2015/12/31/winograd-schema-challenge/
  28. https://artistdetective.wordpress.com/
  29. https://veredshwartz.blogspot.co.il/2016/01/representing-words.html
  30. http://veredshwartz.blogspot.co.il/2017/10/ambiguity.html#1
  31. https://en.wikipedia.org/wiki/hot_dog#etymology
  32. https://en.wikipedia.org/wiki/babysitting#etymology
  33. https://youtu.be/eutbda4lzw0?t=2m
  34. https://id138.princeton.edu/
  35. http://aclweb.org/anthology/w16-1604
  36. https://3.bp.blogspot.com/-z4fkcahkfye/wc1gmbackyi/aaaaaaaauvo/cdvi5bntln4wvteceoab1pchq-rfvsazaclcbgas/s1600/baby_oil.jpg
  37. http://www.quickmeme.com/meme/3r9thy
  38. https://www.google.co.il/search?q="dog+bun"+-hot&source=lnms&tbm=isch&sa=x&ved=0ahukewjy58rygpnxahulb1akhstwbwqq_auicigb&biw=1280&bih=600
  39. https://www.thestar.com/business/tech_news/2017/08/04/emoji-could-cause-confusion-trouble-in-the-workplace.html
  40. http://mashable.com/2017/06/03/emoji-twitter-handles-meanings/#jqeeyckgbkq3
  41. http://www.jellyfish.net/en-us/news-and-views/learning-the-language-of-emoji-0
  42. https://www.usatoday.com/story/tech/2017/07/16/emoji-celebrate-all-emojis-worldemojiday/466053001/
  43. https://emojipedia.org/
  44. https://emojipedia.org/aubergine/
  45. https://www.blogger.com/null
  46. http://people.ischool.berkeley.edu/~nakov/selected_papers_list/jnle2013.pdf
  47. http://veredshwartz.blogspot.co.il/2017/10/ambiguity.html#top1
  48. https://www.blogger.com/profile/17531957962535846245
  49. http://veredshwartz.blogspot.com/2017/10/ambiguity.html
  50. https://www.blogger.com/share-post.g?blogid=9145120678290195131&postid=8556945456906008663&target=email
  51. https://www.blogger.com/share-post.g?blogid=9145120678290195131&postid=8556945456906008663&target=blog
  52. https://www.blogger.com/share-post.g?blogid=9145120678290195131&postid=8556945456906008663&target=twitter
  53. https://www.blogger.com/share-post.g?blogid=9145120678290195131&postid=8556945456906008663&target=facebook
  54. https://www.blogger.com/share-post.g?blogid=9145120678290195131&postid=8556945456906008663&target=pinterest
  55. http://veredshwartz.blogspot.com/search/label/natural language processing
  56. https://www.blogger.com/profile/07280990107022263738
  57. http://veredshwartz.blogspot.com/2017/10/ambiguity.html?showcomment=1509987229981#c6131998194682936937
  58. https://www.blogger.com/delete-comment.g?blogid=9145120678290195131&postid=6131998194682936937
  59. https://www.blogger.com/profile/07280990107022263738
  60. http://veredshwartz.blogspot.com/2017/10/ambiguity.html?showcomment=1509987398846#c7045200602799367164
  61. https://www.blogger.com/delete-comment.g?blogid=9145120678290195131&postid=7045200602799367164
  62. https://www.blogger.com/profile/17531957962535846245
  63. http://veredshwartz.blogspot.com/2017/10/ambiguity.html?showcomment=1509996710687#c1567647381124073717
  64. https://www.blogger.com/delete-comment.g?blogid=9145120678290195131&postid=1567647381124073717
  65. https://www.blogger.com/profile/13662377101256298223
  66. http://veredshwartz.blogspot.com/2017/10/ambiguity.html?showcomment=1537248805332#c184283893805788591
  67. https://www.blogger.com/delete-comment.g?blogid=9145120678290195131&postid=184283893805788591
  68. https://www.blogger.com/profile/12128271861530734257
  69. http://veredshwartz.blogspot.com/2017/10/ambiguity.html?showcomment=1539613720197#c1881218739373583544
  70. https://www.blogger.com/delete-comment.g?blogid=9145120678290195131&postid=1881218739373583544
  71. http://veredshwartz.blogspot.com/2018/01/fun-with-lyrics.html
  72. http://veredshwartz.blogspot.com/2017/08/id141.html
  73. http://veredshwartz.blogspot.com/
  74. http://veredshwartz.blogspot.com/feeds/8556945456906008663/comments/default
  75. https://www.blogger.com/profile/17531957962535846245
  76. https://www.blogger.com/profile/17531957962535846245
  77. https://www.blogger.com/profile/17531957962535846245
  78. https://twitter.com/veredshwartz?ref_src=twsrc^tfw
  79. http://veredshwartz.blogspot.com/search/label/general
  80. http://veredshwartz.blogspot.com/search/label/machine learning
  81. http://veredshwartz.blogspot.com/search/label/machine translation
  82. http://veredshwartz.blogspot.com/search/label/math
  83. http://veredshwartz.blogspot.com/search/label/natural language processing
  84. javascript:void(0)
  85. http://veredshwartz.blogspot.com/2018/
  86. javascript:void(0)
  87. http://veredshwartz.blogspot.com/2018/09/
  88. javascript:void(0)
  89. http://veredshwartz.blogspot.com/2018/08/
  90. javascript:void(0)
  91. http://veredshwartz.blogspot.com/2018/04/
  92. javascript:void(0)
  93. http://veredshwartz.blogspot.com/2018/01/
  94. javascript:void(0)
  95. http://veredshwartz.blogspot.com/2017/
  96. javascript:void(0)
  97. http://veredshwartz.blogspot.com/2017/10/
  98. http://veredshwartz.blogspot.com/2017/10/ambiguity.html
  99. javascript:void(0)
 100. http://veredshwartz.blogspot.com/2017/08/
 101. javascript:void(0)
 102. http://veredshwartz.blogspot.com/2017/03/
 103. javascript:void(0)
 104. http://veredshwartz.blogspot.com/2016/
 105. javascript:void(0)
 106. http://veredshwartz.blogspot.com/2016/11/
 107. javascript:void(0)
 108. http://veredshwartz.blogspot.com/2016/08/
 109. javascript:void(0)
 110. http://veredshwartz.blogspot.com/2016/06/
 111. javascript:void(0)
 112. http://veredshwartz.blogspot.com/2016/05/
 113. javascript:void(0)
 114. http://veredshwartz.blogspot.com/2016/03/
 115. javascript:void(0)
 116. http://veredshwartz.blogspot.com/2016/01/
 117. javascript:void(0)
 118. http://veredshwartz.blogspot.com/2015/
 119. javascript:void(0)
 120. http://veredshwartz.blogspot.com/2015/11/
 121. javascript:void(0)
 122. http://veredshwartz.blogspot.com/2015/10/
 123. javascript:void(0)
 124. http://veredshwartz.blogspot.com/2015/09/
 125. javascript:void(0)
 126. http://veredshwartz.blogspot.com/2015/08/
 127. javascript:void(0)
 128. http://veredshwartz.blogspot.com/2015/07/
 129. https://www.netvibes.com/subscribe.php?url=http://veredshwartz.blogspot.com/feeds/posts/default
 130. https://add.my.yahoo.com/content?url=http://veredshwartz.blogspot.com/feeds/posts/default
 131. http://veredshwartz.blogspot.com/feeds/posts/default
 132. https://www.netvibes.com/subscribe.php?url=http://veredshwartz.blogspot.com/feeds/8556945456906008663/comments/default
 133. https://add.my.yahoo.com/content?url=http://veredshwartz.blogspot.com/feeds/8556945456906008663/comments/default
 134. http://veredshwartz.blogspot.com/feeds/8556945456906008663/comments/default
 135. https://medium.com/@ibelmopan?source=rss-41338000425f------2
 136. https://ai-blog.co.il/
 137. https://lifesimulator.wordpress.com/
 138. https://blazinghyphens.wordpress.com/
 139. https://artistdetective.wordpress.com/
 140. https://nlpers.blogspot.com/
 141. http://www.benfrederickson.com/`
 142. http://trimc-nlp.blogspot.com/
 143. http://colah.github.io/
 144. https://gengo.ai/resources/
 145. http://www.dirkhovy.com/blog
 146. http://karpathy.github.io/
 147. https://www.blogger.com/

   hidden links:
 149. https://memeguy.com/photo/108837/dad-jokes-
 150. https://www.blogger.com/post-edit.g?blogid=9145120678290195131&postid=8556945456906008663&from=pencil
 151. https://www.blogger.com/comment-iframe.g?blogid=9145120678290195131&postid=8556945456906008663
 152. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=text&widgetid=text1&action=editwidget&sectionid=sidebar-right-1
 153. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=html&widgetid=html1&action=editwidget&sectionid=sidebar-right-1
 154. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=profile&widgetid=profile1&action=editwidget&sectionid=sidebar-right-1
 155. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=html&widgetid=html2&action=editwidget&sectionid=sidebar-right-1
 156. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=label&widgetid=label1&action=editwidget&sectionid=sidebar-right-1
 157. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=blogarchive&widgetid=blogarchive1&action=editwidget&sectionid=sidebar-right-1
 158. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=followbyemail&widgetid=followbyemail1&action=editwidget&sectionid=sidebar-right-1
 159. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=subscribe&widgetid=subscribe1&action=editwidget&sectionid=sidebar-right-1
 160. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=bloglist&widgetid=bloglist1&action=editwidget&sectionid=sidebar-right-1
 161. http://www.blogger.com/rearrange?blogid=9145120678290195131&widgettype=attribution&widgetid=attribution1&action=editwidget&sectionid=footer-3
