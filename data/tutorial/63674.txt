   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

audio processing in tensorflow

   [16]go to the profile of dario cazzani
   [17]dario cazzani (button) blockedunblock (button) followfollowing
   jun 30, 2017
   [1*ysfmnumszv4axbp-ouolia.png]

an implementation of the short time fourier transform

i found audio processing in tensorflow hard, here is my fix

   there are countless ways to perform audio processing. the usual flow
   for running experiments with id158s in tensorflow
   with audio inputs is to first preprocess the audio, then feed it to the
   neural net.

   what happens though when one wants to perform audio processing
   somewhere in the middle of the computation graph?
   tensorflow comes with an implementation of the [18]fast fourier
   transform, but it is not enough.

   in this post i will explain how we implemented it and provide the code
   so that the short time fourier transform can be used anywhere in the
   computation graph.

the code

   all the code is available on my github: [19]audio processing in
   tensorflow.
   feel free to add your contribution there.

audio preprocessing: the usual approach

   when developing a id103 engine using deep neural networks
   we need to feed the audio to our neural network, but    what is the right
   way to preprocess this input?

   there are 2 common ways to represent sound:
     * time domain: each sample represents the variation in air pressure.
     * frequency domain: at each time stamp we indicate the amplitude for
       each frequency.

   despite the fact that deep neural networks are extremely good at
   learning features automagically, it is always a good idea to rely on
   known features that carry the information needed for the task that we
   are trying to solve.

   for most application, a id103 engine included, the
   features we are interested in are encoded in the frequency domain
   representation of the sound.

the spectrogram and the short time fourier transform

   a [20]spectrogram shows how the frequency content of a signal changes
   over time and can be calculated from the time domain signal.
   the operation, or transformation, used to do that is known as the
   [21]short time fourier transform.

   i could let the neural network figure out how to learn this operation,
   but it turns out to be quite complex to learn with 1 hidden layer.
   (refer to the [22]universal approximation theorem)

   i could add more layers, but i want to keep the complexity of the
   neural networks as small as possible and learn features only where it
   is most needed.

   i have used the example of developing an automatic id103
   engine, but the use of the spectrogram as input to deep neural nets is
   common also for similar tasks involving non-speech audio like noise
   reduction, music genre classification, whale call detection, etc.

   a particular project that i want to mention is [23]magenta, from the
   [24]google brain team, who   s aim is to advance the state of the art in
   machine intelligence for music and art generation.

why tensorflow?

   i mainly use tensorflow when implementing id158s
   and, because i haven   t found an implementation of the short time
   fourier transform in tf, i decided to implement our own.
   [edit: june 4th 2018]         since tensorflow 1.3 they added some useful
   [25]dsp functionalities.

   there can also be multiple reasons why a deep learning practitioner
   might want to include the short time fourier transform (stft for my
   friends) in the computation graph, and not just as a separate
   preprocessing step.

   keep in mind that i haven   t focused on making this efficient. it should
   (and will) be improved before being used in production.

what you need to know

   in order to understand how the stft is calculated, you need to
   understand how to compute the discrete fourier transform.

discrete fourier transform         dft

   this part can appear quite technical for those who are not familiar
   with these concepts, but i think it is important to go through some
   maths in order give a complete understanding of the code.

   theory
   fourier analysis is fundamentally a method for expressing a function as
   a sum of periodic components, and for recovering the function from
   those components. when both the function and its fourier transform are
   replaced with discretized counterparts, it is called the discrete
   fourier transform (dft).

   given a vector x of n input amplitudes such as:
{x[0], x[1], x[2], x[3],    , x[n-1]}

   the discrete fourier transform yields a set of n frequency magnitudes.

   the dft is defined by this equation:
   [1*pkevkpcpgv2kwu84qt17xq.png]
   dft equation
     * k is used to denote the frequency domain ordinal
     * n is used to represent the time-domain ordinal
     * n is the length of the sequence to be transformed.

   fast fourier transform
   the [26]fast fourier transform is an efficient implementation of the
   dft equation. the signal must be restricted to be of size of a power of
   2.

   this explains why n (the size of the signal in input to the dft
   function) has to be power of 2 and why it must be zero-padded
   otherwise.

   one can detect whether x is a power of 2 very simply in python:

   iframe: [27]/media/669bff009bc3591533d0ac2f448a2c38?postid=208f1a4103aa

   we only need half of it
   real sine waves can be expressed as the sum of complex sine waves using
   [28]euler   s identity
   [1*eu5f-wzzgifx9ov26e3ivw.png]

   because the dft is a linear function, the dft of a sum of sine waves is
   the sum of the dft of each sine wave. so for the spectral case you get
   2 dfts, one for the positive frequencies and one for the negative
   frequencies, which are symmetric.
   this symmetry occurs for real signals that can be viewed as an infinite
   (or finite in our case) sum of sine waves.

   windowing
   truncating a signal in the time domain will lead to ripples appearing
   in the frequency domain.
   this can be understood if you think of truncating the signal as if you
   applied a rectangular window. applying a window in the time domain
   results in a convolution in the frequency domain.
   the ripples are caused when we convolve the 2 frequency domain
   representations together.

   find out more about [29]spectral_leakage if you   re interested.

   here is an example of an implementation of windowing in python:

   iframe: [30]/media/d98b2ed9221ba19520f627e9e3aa695f?postid=208f1a4103aa

   zero-phase padding

   in order to use the fft, the input signal has to have a power of 2
   length. if the input signal does not have the right length, zeros can
   be appended to the signal itself both at the beginning and at the end.
   because the zero sample is originally at the center of the input
   signal, i split the padded signal through the middle and swap the order
   of these 2 parts.

   the next code snippet shows how to do this in tensorflow for a batch of
   inputs:

   iframe: [31]/media/2515cb32a756fc0add5f9d91160c6f63?postid=208f1a4103aa

   fft, magnitude and phase
   you now have everything you need to calculate the magnitude of the
   spectrogram in decibels and the phase of the signal:

   iframe: [32]/media/a54a364b9a1d49c9beed98c5c121d14f?postid=208f1a4103aa

short time fourier transform

   you now know how to compute the dft to evaluate the frequency content
   of a signal.
   the stft is used to analyze the frequency content of signals when that
   frequency content varies with time.
   you can do this by:
    1. taking segments of the signal.
    2. windowing those out from the rest of the signal, and applying a dft
       to each segment.
    3. sliding this window along each segment.

   you get dft coefficients as a function of both time and frequency.

   the complete code is divided in 2 parts: helpers.py and stft.py.

   iframe: [33]/media/27dff25b9aba500e6b9eeb04e4895a5f?postid=208f1a4103aa

conclusion

   the possibility of doing the stft in tensorflow allows machine learning
   practitioners to perform the transformation of a signal, from
   time-domain to frequency domain, anywhere in the computation graph.
   new tools always bring new ideas and we hope this post will be the
   source of new ideas for developing new deep learning solutions.

   thanks to [34]matt norris, [35]joshua frattarola, and [36]andy payne.
     * [37]machine learning
     * [38]tensorflow
     * [39]id103
     * [40]audio processing
     * [41]towards data science

   (button)
   (button)
   (button) 706 claps
   (button) (button) (button) 2 (button) (button)

     (button) blockedunblock (button) followfollowing
   [42]go to the profile of dario cazzani

[43]dario cazzani

   violinist, machine learning engineer and i also make good pasta

     (button) follow
   [44]towards data science

[45]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 706
     * (button)
     *
     *

   [46]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [47]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/208f1a4103aa
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/audio-processing-in-tensorflow-208f1a4103aa&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/audio-processing-in-tensorflow-208f1a4103aa&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_d53uycgevqrb---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@dariocazzani?source=post_header_lockup
  17. https://towardsdatascience.com/@dariocazzani
  18. https://www.tensorflow.org/api_docs/python/tf/fft
  19. https://github.com/dariocazzani/tensorflow-audio-processing
  20. https://en.wikipedia.org/wiki/spectrogram
  21. https://en.wikipedia.org/wiki/short-time_fourier_transform
  22. https://en.wikipedia.org/wiki/universal_approximation_theorem
  23. https://magenta.tensorflow.org/welcome-to-magenta
  24. https://research.google.com/teams/brain/
  25. https://www.tensorflow.org/api_docs/python/tf/contrib/signal
  26. https://en.wikipedia.org/wiki/fast_fourier_transform
  27. https://towardsdatascience.com/media/669bff009bc3591533d0ac2f448a2c38?postid=208f1a4103aa
  28. https://en.wikipedia.org/wiki/euler's_formula
  29. https://mil.ufl.edu/nechyba/www/__eel3135.s2003/lectures/lecture19/spectral_leakage.pdf
  30. https://towardsdatascience.com/media/d98b2ed9221ba19520f627e9e3aa695f?postid=208f1a4103aa
  31. https://towardsdatascience.com/media/2515cb32a756fc0add5f9d91160c6f63?postid=208f1a4103aa
  32. https://towardsdatascience.com/media/a54a364b9a1d49c9beed98c5c121d14f?postid=208f1a4103aa
  33. https://towardsdatascience.com/media/27dff25b9aba500e6b9eeb04e4895a5f?postid=208f1a4103aa
  34. https://medium.com/@mattnorrisme?source=post_page
  35. https://medium.com/@jfrattarola?source=post_page
  36. https://medium.com/@andy_payne?source=post_page
  37. https://towardsdatascience.com/tagged/machine-learning?source=post
  38. https://towardsdatascience.com/tagged/tensorflow?source=post
  39. https://towardsdatascience.com/tagged/speech-recognition?source=post
  40. https://towardsdatascience.com/tagged/audio-processing?source=post
  41. https://towardsdatascience.com/tagged/towards-data-science?source=post
  42. https://towardsdatascience.com/@dariocazzani?source=footer_card
  43. https://towardsdatascience.com/@dariocazzani
  44. https://towardsdatascience.com/?source=footer_card
  45. https://towardsdatascience.com/?source=footer_card
  46. https://towardsdatascience.com/
  47. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  49. https://medium.com/p/208f1a4103aa/share/twitter
  50. https://medium.com/p/208f1a4103aa/share/facebook
  51. https://medium.com/p/208f1a4103aa/share/twitter
  52. https://medium.com/p/208f1a4103aa/share/facebook
