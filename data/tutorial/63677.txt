   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]ai   | theory, practice, business
     * [9]theory
     * [10]practice
     * [11]business
     __________________________________________________________________

understanding hinton   s id22. part ii: how capsules work.

   [12]go to the profile of max pechyonkin
   [13]max pechyonkin (button) blockedunblock (button) followfollowing
   nov 15, 2017

part of understanding hinton   s id22 series:

   part i: [14]intuition
   part ii: [15]how capsules work (you are reading it now)
   part iii: [16]dynamic routing between capsules
   part iv: [17]capsnet architecture
     __________________________________________________________________

   quick announcement about our new publication [18]ai  . we are getting
   the best writers together to talk about the theory, practice, and
   business of ai and machine learning. follow it to stay up to date on
   the latest trends.
     __________________________________________________________________

introduction

   in [19]part i of this series on id22, i talked about the
   basic intuition and motivation behind the novel architecture. in this
   part, i will describe, what capsule is and how it works internally as
   well as intuition behind it. in the next part i will focus mostly on
   the dynamic routing algorithm.

what is a capsule?

   in order to answer this question, i think it is a good idea to refer to
   the first paper where capsules were introduced            [20]transforming
   autoencoders    by hinton et al. the part that is important to
   understanding of capsules is provided below:

        instead of aiming for viewpoint invariance in the activities of
        neurons    that use a single scalar output to summarize the
     activities of a local pool of replicated feature detectors,
     id158s should use local    capsules    that perform
     some quite complicated internal computations on their inputs and
     then encapsulate the results of these computations into a small
     vector of highly informative outputs. each capsule learns to
     recognize an implicitly defined visual entity over a limited domain
     of viewing conditions and deformations and it outputs both the
     id203 that the entity is present within its limited domain and
     a set of    instantiation parameters    that may include the precise
     pose, lighting and deformation of the visual entity relative to an
     implicitly defined canonical version of that entity. when the
     capsule is working properly, the id203 of the visual entity
     being present is locally invariant         it does not change as the
     entity moves over the manifold of possible appearances within the
     limited domain covered by the capsule. the instantiation parameters,
     however, are    equivariant            as the viewing conditions change and
     the entity moves over the appearance manifold, the instantiation
     parameters change by a corresponding amount because they are
     representing the intrinsic coordinates of the entity on the
     appearance manifold.   

   the paragraph above is very dense, and it took me a while to figure out
   what it means, sentence by sentence. below is my version of the above
   paragraph, as i understand it:

   artificial neurons output a single scalar. in addition, id98s use
   convolutional layers that, for each kernel, replicate that same
   kernel   s weights across the entire input volume and then output a 2d
   matrix, where each number is the output of that kernel   s convolution
   with a portion of the input volume. so we can look at that 2d matrix as
   output of replicated feature detector. then all kernel   s 2d matrices
   are stacked on top of each other to produce output of a convolutional
   layer.
   [1*wslt0p0qyxkw9daf6paysq.png]
   not only can the capsnet recognize digits, it can also generate them
   from internal representations. [21]source.

   then, we try to achieve viewpoint invariance in the activities of
   neurons. we do this by the means of max pooling that consecutively
   looks at regions in the above described 2d matrix and selects the
   largest number in each region. as result, we get what we
   wanted         invariance of activities. invariance means that by changing
   the input a little, the output still stays the same. and activity is
   just the output signal of a neuron. in other words, when in the input
   image we shift the object that we want to detect by a little bit,
   networks activities (outputs of neurons) will not change because of max
   pooling and the network will still detect the object.

   the above described mechanism is not very good, because max pooling
   loses valuable information and also does not encode relative spatial
   relationships between features. we should use capsules instead, because
   they will encapsulate all important information about the state of the
   features they are detecting in a form of a vector (as opposed to a
   scalar that a neuron outputs).

     capsules encapsulate all important information about the state of
     the feature they are detecting in vector form.

   capsules encode id203 of detection of a feature as the length of
   their output vector. and the state of the detected feature is encoded
   as the direction in which that vector points to (   instantiation
   parameters   ). so when detected feature moves around the image or its
   state somehow changes, the id203 still stays the same (length of
   vector does not change), but its orientation changes.

   imagine that a capsule detects a face in the image and outputs a 3d
   vector of length 0.99. then we start moving the face across the image.
   the vector will rotate in its space, representing the changing state of
   the detected face, but its length will remain fixed, because the
   capsule is still sure it has detected a face. this is what hinton
   refers to as activities equivariance: neuronal activities will change
   when an object    moves over the manifold of possible appearances    in the
   picture. at the same time, the probabilities of detection remain
   constant, which is the form of invariance that we should aim at, and
   not the type offered by id98s with max pooling.

how does a capsule work?

   let us compare capsules with artificial neurons. table below summarizes
   the differences between the capsule and the neuron:
   [1*prleiwkme0vx0v75emh1lw.png]
   important differences between capsules and neurons. source: author,
   inspired by the talk on capsnets given by [22]naturomics.

   recall, that a neuron receives input scalars from other neurons, then
   multiplies them by scalar weights and sums. this sum is then passed to
   one of the many possible nonlinear id180, that take the
   input scalar and output a scalar according to the function. that scalar
   will be the output of the neuron that will go as input to other
   neurons. the summary of this process can be seen on the table and
   diagram below on the right side. in essence, artificial neuron can be
   described by 3 steps:
    1. scalar weighting of input scalars
    2. sum of weighted input scalars
    3. scalar-to-scalar nonlinearity

   [1*gkrl9_6lk9zqnf0ttv2kfa.jpeg]
   left: capsule diagram; right: artificial neuron. source: author,
   inspired by the talk on capsnets given by [23]naturomics.

   on the other hand, the capsule has vector forms of the above 3 steps in
   addition to the new step, affine transform of input:
    1. id127 of input vectors
    2. scalar weighting of input vectors
    3. sum of weighted input vectors
    4. vector-to-vector nonlinearity

   let   s have a better look at the 4 computational steps happening inside
   the capsule.

1. id127 of input vectors

   input vectors that our capsule receives (u1, u2 and u3 in the diagram)
   come from 3 other capsules in the layer below. lengths of these vectors
   encode probabilities that lower-level capsules detected their
   corresponding objects and directions of the vectors encode some
   internal state of the detected objects. let us assume that lower level
   capsules detect eyes, mouth and nose respectively and out capsule
   detects face.

   these vectors then are multiplied by corresponding weight matrices w
   that encode important spatial and other relationships between lower
   level features (eyes, mouth and nose) and higher level feature (face).
   for example, matrix w2j may encode relationship between nose and face:
   face is centered around its nose, its size is 10 times the size of the
   nose and its orientation in space corresponds to orientation of the
   nose, because they all lie on the same plane. similar intuitions can be
   drawn for matrices w1j and w3j. after multiplication by these matrices,
   what we get is the predicted position of the higher level feature. in
   other words, u1hat represents where the face should be according to the
   detected position of the eyes, u2hat represents where the face should
   be according to the detected position of the mouth and u3hat represents
   where the face should be according to the detected position of the
   nose.

   at this point your intuition should go as follows: if these 3
   predictions of lower level features point at the same position and
   state of the face, then it must be a face there.
   [1*vtuuncdu9cdu5j0juercaq.jpeg]
   predictions for face location of nose, mouth and eyes capsules closely
   match: there must be a face there. source: author, based on
   [24]original image.

2. scalar weighting of input vectors

   at the first glance, this step seems very familiar to the one where
   artificial neuron weights its inputs before adding them up. in the
   neuron case, these weights are learned during id26, but in
   the case of the capsule, they are determined using    dynamic routing   ,
   which is a novel way to determine where each capsule   s output goes. i
   will dedicate a separate post to this algorithm and only offer some
   intuition here.
   [1*i0i5nlfe9pd1lq5vmoohyq.png]
   lower level capsule will send its input to the higher level capsule
   that    agrees    with its input. this is the essence of the dynamic
   routing algorithm. [25]source.

   in the image above, we have one lower level capsule that needs to
      decide    to which higher level capsule it will send its output. it will
   make its decision by adjusting the weights c that will multiply this
   capsule   s output before sending it to either left or right higher-level
   capsules j and k.

   now, the higher level capsules already received many input vectors from
   other lower-level capsules. all these inputs are represented by red and
   blue points. where these points cluster together, this means that
   predictions of lower level capsules are close to each other. this is
   why, for the sake of example, there is a cluster of red points in both
   capsules j and k.

   so, where should our lower-level capsule send its output: to capsule j
   or to capsule k? the answer to this question is the essence of the
   dynamic routing algorithm. the output of the lower capsule, when
   multiplied by corresponding matrix w, lands far from the red cluster of
      correct    predictions in capsule j. on the other hand, it will land
   very close to    true    predictions red cluster in the right capsule k.
   lower level capsule has a mechanism of measuring which upper level
   capsule better accommodates its results and will automatically adjust
   its weight in such a way that weight c corresponding to capsule k will
   be high, and weight c corresponding to capsule j will be low.

3. sum of weighted input vectors

   this step is similar to the regular artificial neuron and represents
   combination of inputs. i don   t think there is anything special about
   this step (except it is sum of vectors and not sum of scalars). we
   therefore can move on to the next step.

4.    squash   : novel vector-to-vector nonlinearity

   another innovation that capsnet introduce is the novel nonlinear
   activation function that takes a vector, and then    squashes    it to have
   length of no more than 1, but does not change its direction.
   [1*rb03q9minvgrpk_vbcbnsg.png]
   squashing nonlinearity scales input vector without changing its
   direction.

   the right side of equation (blue rectangle) scales the input vector so
   that it will have unit length and the left side (red rectangle)
   performs additional scaling. remember that the output vector length can
   be interpreted as id203 of a given feature being detected by the
   capsule.
   [1*f4m5csjzal47fcn_fez-nq.png]
   graph of the novel nonlinearity in its scalar form. in real application
   the function operates on vectors. source: author.

   on the left is the squashing function applied to a 1d vector, which is
   a scalar. i included it to demonstrate the interesting nonlinear shape
   of the function.

   it only makes sense to visualize one dimensional case; in real
   application it will take vector and output a vector, which would be
   hard to visualize.

conclusion

   in this part we talked about what the capsule is, what kind of
   computation it performs as well as intuition behind it. we see that the
   design of the capsule builds up upon the design of artificial neuron,
   but expands it to the vector form to allow for more powerful
   representational capabilities. it also introduces matrix weights to
   encode important hierarchical relationships between features of
   different layers. the result succeeds to achieve the goal of the
   designer: neuronal activity equivariance with respect to changes in
   inputs and invariance in probabilities of feature detection.
   [1*gbmq2x9nqoguj1m-eod67g.png]
   summary of the internal workings of the capsule. note that there is no
   bias because it is already included in the w matrix that can
   accommodate it and other, more complex transforms and relationships.
   source: author.

   the only parts that remain to conclude the series on the capsnet are
   the dynamic routing between capsules algorithm as well as the detailed
   walkthrough of the architecture of this novel network. these will be
   discussed in the following posts.
     __________________________________________________________________

thanks for reading! if you enjoyed it, hit that clap button below and
[26]subscribe to updates on [27]my website! it would mean a lot to me and
encourage me to write more stories like this.

   you can [28]follow me on twitter. let   s also connect on [29]linkedin.

     * [30]machine learning
     * [31]deep learning
     * [32]geoffrey hinton
     * [33]artificial intelligence
     * [34]theory

   (button)
   (button)
   (button) 15.5k claps
   (button) (button) (button) 40 (button) (button)

     (button) blockedunblock (button) followfollowing
   [35]go to the profile of max pechyonkin

[36]max pechyonkin

   [37]https://pechyonkin.me/

     (button) follow
   [38]ai   | theory, practice, business

[39]ai   | theory, practice, business

   the ai revolution is here! navigate the ever changing industry with our
   thoughtfully written articles whether your a researcher, engineer, or
   entrepreneur

     * (button)
       (button) 15.5k
     * (button)
     *
     *

   [40]ai   | theory, practice, business
   never miss a story from ai   | theory, practice, business, when you sign
   up for medium. [41]learn more
   never miss a story from ai   | theory, practice, business
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/153b6ade9f66
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://medium.com/ai%c2%b3-theory-practice-business/understanding-hintons-capsule-networks-part-ii-how-capsules-work-153b6ade9f66&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://medium.com/ai%c2%b3-theory-practice-business/understanding-hintons-capsule-networks-part-ii-how-capsules-work-153b6ade9f66&source=--------------------------nav_reg&operation=register
   8. https://medium.com/ai  -theory-practice-business?source=logo-lo_mggvx6xrojpk---ab837e78463f
   9. https://medium.com/ai  -theory-practice-business/tagged/theory
  10. https://medium.com/ai  -theory-practice-business/tagged/practice
  11. https://medium.com/ai  -theory-practice-business/tagged/business
  12. https://medium.com/@pechyonkin?source=post_header_lockup
  13. https://medium.com/@pechyonkin
  14. https://pechyonkin.me/capsules-1/
  15. https://pechyonkin.me/capsules-2/
  16. https://pechyonkin.me/capsules-3/
  17. https://pechyonkin.me/capsules-4/
  18. https://medium.com/ai  -theory-practice-business?source=logo-bc670b9a1aca---ab837e78463f
  19. https://medium.com/@pechyonkin/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b
  20. http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf
  21. https://arxiv.org/abs/1710.09829
  22. https://github.com/naturomics/capsnet-tensorflow
  23. https://github.com/naturomics/capsnet-tensorflow
  24. http://sharenoesis.com/wp-content/uploads/2010/05/7shapefaceremoveguides.jpg
  25. https://youtu.be/rtawfwuvnle?t=36m39s
  26. https://pechyonkin.me/subscribe/
  27. https://pechyonkin.me/
  28. https://twitter.com/max_pechyonkin
  29. https://www.linkedin.com/in/maxim-pechyonkin-phd/
  30. https://medium.com/tag/machine-learning?source=post
  31. https://medium.com/tag/deep-learning?source=post
  32. https://medium.com/tag/geoffrey-hinton?source=post
  33. https://medium.com/tag/artificial-intelligence?source=post
  34. https://medium.com/tag/theory?source=post
  35. https://medium.com/@pechyonkin?source=footer_card
  36. https://medium.com/@pechyonkin
  37. https://pechyonkin.me/
  38. https://medium.com/ai  -theory-practice-business?source=footer_card
  39. https://medium.com/ai  -theory-practice-business?source=footer_card
  40. https://medium.com/ai  -theory-practice-business
  41. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  43. https://medium.com/p/153b6ade9f66/share/twitter
  44. https://medium.com/p/153b6ade9f66/share/facebook
  45. https://medium.com/p/153b6ade9f66/share/twitter
  46. https://medium.com/p/153b6ade9f66/share/facebook
