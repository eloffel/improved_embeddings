   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

having fun with deep convolutional gans

   go to the profile of naoki shibuya
   [16]naoki shibuya (button) blockedunblock (button) followfollowing
   nov 13, 2017
   [1*xjsok9gwwdwgs1vnktevlg.png]

   this article show deep convolutional generative adversarial
   networks         a.k.a dcgan examples using different image data sets such as
   [17]mnist, [18]svhn, and [19]celeba.

dcgan with mnist

   [1*stzgk0n4m2sgu_9t4fvfnq.png]
   images from mnist

   in [20]understanding id3, i used a simple
   gan to generate images, and the results were merely good enough to
   prove the concept.
   [1*epq3lnboh8nl_tgylywrgq.png]
   generated by a simple gan

   below, i used dcgan to generate the images. there are much less noises,
   and the shapes are better.
   [1*3ovr8fiay3wu12spnfwwnq.png]
   generated by dcgan

the difference between the simple gan and the dcgan

   the generator of the simple gan is a simple fully connected network.
generator = sequential([
        dense(128, input_shape=(100,)),
        leakyrelu(alpha=0.01),
        dense(784),
        activation('tanh')
    ], name='generator')

   the generator of the dcgan uses [21]the transposed convolution
   technique to perform up-sampling of 2d image size.
generator = sequential([
    # layer 1
    dense(784, input_shape=(100,)),
    reshape(target_shape=(7, 7, 16)),
    batchid172(),
    leakyrelu(alpha=0.01),
    # layer 2
    conv2dtranspose(32, kernel_size=5, strides=2, padding='same'),
    batchid172(),
    leakyrelu(alpha=0.01),
    # layer 3
    conv2dtranspose(1, kernel_size=5, strides=2, padding='same'),
    activation('tanh')
])

   [22]notebook on github

   we can roughly consider the transposed convolution as a reverse
   operation of normal convolution. the generator network summary below
   shows that the multiple transposed convolutions increase the image
   size.
layer (type)                 output shape              param #
=================================================================
dense_7 (dense)              (none, 784)               79184
_________________________________________________________________
reshape_5 (reshape)          (none, 7, 7, 16)          0
_________________________________________________________________
batch_id172_7 (batch (none, 7, 7, 16)          64
_________________________________________________________________
leaky_re_lu_5 (leakyrelu)    (none, 7, 7, 16)          0
_________________________________________________________________
conv2d_transpose_4 (conv2dtr (none, 14, 14, 32)        12832
_________________________________________________________________
batch_id172_8 (batch (none, 14, 14, 32)        128
_________________________________________________________________
leaky_re_lu_6 (leakyrelu)    (none, 14, 14, 32)        0
_________________________________________________________________
conv2d_transpose_5 (conv2dtr (none, 28, 28, 1)         801
_________________________________________________________________
activation_3 (activation)    (none, 28, 28, 1)         0
=================================================================
total params: 93,009
trainable params: 92,913
non-trainable params: 96
_________________________________________________________________

   the final image shape is 28x28 with 1 channel which is the same as the
   original mnist digit image size.

   fyi         my article [23]up-sampling with transposed convolution has more
   details on the concept of transposed convolution.

dcgan with svhn

   [1*rze1vh8hu7mezn68fo3wmq.png]
   images from svhn

   this dcgan example uses [24]the street view house numbers (svhn)
   dataset.

   the generated images look pretty descent. if these images are mixed
   with the real svhn images, i would not be able to tell which ones are
   which (i am not a good discriminator   ).
   [1*c2jczaqm6l2iyt7javrrva.png]
   generated by dcgan

   the generator has 3 transposed convolution layers.
generator = sequential([
    # layer 1
    dense(4*4*512, input_shape=(100,)),
    reshape(target_shape=(4, 4, 512)),
    batchid172(),
    leakyrelu(alpha=0.2),

    # layer 2
    conv2dtranspose(256, kernel_size=5, strides=2, padding='same'),
    batchid172(),
    leakyrelu(alpha=0.2),

    # layer 3
    conv2dtranspose(128, kernel_size=5, strides=2, padding='same'),
    batchid172(),
    leakyrelu(alpha=0.2),

    # layer 4
    conv2dtranspose(3, kernel_size=5, strides=2, padding='same'),
    activation('tanh')
])

   this network was much more difficult to train. no wonder why gans are
   notorious for very hard to train.

   [25]my notebook on github contains a few training scenarios with
   various hyper parameters. i experimented with the learning rate, the
   leaky relu   s alpha and the adam optimizer   s momentum coefficient (beta
   1). adding / removing the batch id172, and e.t.c.

   i learned some hyper parameter tuning ideas from [26]how to train a
   gan? tips and tricks to make gans work. there is a presentation by the
   author on youtube which i recommend watching before reading [27]the
   paper.

   iframe: [28]/media/1aa1fc5b16d8ba7143708a918e9b1091?postid=f4f8393686ed

dcgan with celeba

   [1*z2lw4qjhlzpha-hoilqfow.png]
   images from celeba (full size)

   the last (but not least) example uses the [29]large-scale celeb faces
   attributes (celeba) dataset.

   i decided to resize the images into 32x32 as it was taking too long to
   train the network.
   [1*wzt8ihalgd4doigbay8auw.png]
   images from celeba (resized: 32x32)

   the generated images look a bit frankenstein-ish. but look, it   s
   generating faces from random noises. isn   t that something?
   [1*x9ud6wlt9fj7ps4dd5qsma.png]
   generated by dcgan

   this generator network has the similar capacity with the svhn example.

   one thing i did differently was that i used a different kernel weight
   initializer as suggested in [30]how to train a gan? tips and tricks to
   make gans work. it seems to have improved the quality of images but it
   is not clear by how much. in any case, the result was good enough to
   prove that it works. if you play with gans, you may also experiment
   with the initializers.
from keras.initializers import randomnormal
generator = sequential([
    # layer 1
    dense(4*4*512, input_shape=(100,),
          kernel_initializer=randomnormal(stddev=0.02)),
    reshape(target_shape=(4, 4, 512)),
    batchid172(),
    leakyrelu(alpha=0.2),

    # layer 2
    conv2dtranspose(256, kernel_size=5, strides=2, padding='same',
                    kernel_initializer=randomnormal(stddev=0.02)),
    batchid172(),
    leakyrelu(alpha=0.2),

    # layer 3
    conv2dtranspose(128, kernel_size=5, strides=2, padding='same',
                    kernel_initializer=randomnormal(stddev=0.02)),
    batchid172(),
    leakyrelu(alpha=0.2),

    # layer 4
    conv2dtranspose(3, kernel_size=5, strides=2, padding='same',
                    kernel_initializer=randomnormal(stddev=0.02)),
    activation('tanh')
])

   [31]notebook on github

conclusion

   the concept of gans is not that hard to understand (i.e.,
   [32]understanding id3). but implementing
   them to produce quality images can be tricky. so i recommend anybody
   who wants to have better insights into gans to make their hands dirty
   and tweak parameters.

   having said that, it takes a long time to train deep networks with tons
   of images. so, i hope this article and [33]my notebooks in github can
   provide you with some insights without sweat and tears.

references

   [1] id3

   ian j. goodfellow, jean pouget-abadie, mehdi mirza, bing xu, david
   warde-farley, sherjil ozair, aaron courville, yoshua bengio

   [34]https://arxiv.org/abs/1406.2661

   [2] unsupervised representation learning with deep convolutional
   id3

   alec radford & luke metz (indico research), soumith chintala (facebook
   ai research)

   [35]https://arxiv.org/pdf/1511.06434.pdf

   [3] how to train a gan? tips and tricks to make gans work

   facebook ai research: soumith chintala, emily denton, martin arjovsky,
   michael mathieu

   [36]https://github.com/soumith/ganhacks

   [37]https://www.youtube.com/watch?v=x1mun6dd8ue

   [4] udacity deep learning nanodegree github

   udacity

   [38]https://github.com/udacity/deep-learning

   [5] mnist dataset

   yann lecun

   [39]http://yann.lecun.com/exdb/mnist/

   [6] the street view house numbers (svhn) dataset

   stanford

   [40]http://ufldl.stanford.edu/housenumbers/

   [7] large-scale celebfaces attributes (celeba) dataset

   ziwei liu, ping luo, xiaogang wang, xiaoou tang multimedia laboratory,
   the chinese university of hong kong

   [41]http://mmlab.ie.cuhk.edu.hk/projects/celeba.html

     * [42]machine learning
     * [43]deep learning
     * [44]gan
     * [45]convolutional
     * [46]dcgan

   (button)
   (button)
   (button) 238 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of naoki shibuya

[47]naoki shibuya

   medium member since mar 2017

   senior research engineer @ ascent robotics

     (button) follow
   [48]towards data science

[49]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 238
     * (button)
     *
     *

   [50]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [51]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/f4f8393686ed
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/having-fun-with-deep-convolutional-gans-f4f8393686ed&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/having-fun-with-deep-convolutional-gans-f4f8393686ed&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_juighaajyymd---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@naokishibuya
  17. http://yann.lecun.com/exdb/mnist/
  18. http://ufldl.stanford.edu/housenumbers/
  19. http://mmlab.ie.cuhk.edu.hk/projects/celeba.html
  20. https://medium.com/@naokishibuya/understanding-generative-adversarial-networks-4dafc963f2ef
  21. https://medium.com/@naokishibuya/up-sampling-with-transposed-convolution-9ae4f2df52d0
  22. https://github.com/naokishibuya/deep-learning/blob/master/python/dcgan_mnist.ipynb
  23. https://medium.com/@naokishibuya/up-sampling-with-transposed-convolution-9ae4f2df52d0
  24. http://ufldl.stanford.edu/housenumbers/
  25. https://github.com/naokishibuya/deep-learning/blob/master/python/dcgan_svhn.ipynb
  26. https://github.com/soumith/ganhacks
  27. https://github.com/soumith/ganhacks
  28. https://towardsdatascience.com/media/1aa1fc5b16d8ba7143708a918e9b1091?postid=f4f8393686ed
  29. http://mmlab.ie.cuhk.edu.hk/projects/celeba.html
  30. https://github.com/soumith/ganhacks
  31. https://github.com/naokishibuya/deep-learning/blob/master/python/dcgan_celeba.ipynb
  32. https://medium.com/@naokishibuya/understanding-generative-adversarial-networks-4dafc963f2ef
  33. https://github.com/udacity/deep-learning
  34. https://arxiv.org/abs/1406.2661
  35. https://arxiv.org/pdf/1511.06434.pdf
  36. https://github.com/soumith/ganhacks
  37. https://www.youtube.com/watch?v=x1mun6dd8ue
  38. https://github.com/udacity/deep-learning
  39. http://yann.lecun.com/exdb/mnist/
  40. http://ufldl.stanford.edu/housenumbers/
  41. http://mmlab.ie.cuhk.edu.hk/projects/celeba.html
  42. https://towardsdatascience.com/tagged/machine-learning?source=post
  43. https://towardsdatascience.com/tagged/deep-learning?source=post
  44. https://towardsdatascience.com/tagged/gans?source=post
  45. https://towardsdatascience.com/tagged/convolutional?source=post
  46. https://towardsdatascience.com/tagged/dcgan?source=post
  47. https://towardsdatascience.com/@naokishibuya
  48. https://towardsdatascience.com/?source=footer_card
  49. https://towardsdatascience.com/?source=footer_card
  50. https://towardsdatascience.com/
  51. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  53. https://towardsdatascience.com/@naokishibuya?source=post_header_lockup
  54. https://medium.com/p/f4f8393686ed/share/twitter
  55. https://medium.com/p/f4f8393686ed/share/facebook
  56. https://towardsdatascience.com/@naokishibuya?source=footer_card
  57. https://medium.com/p/f4f8393686ed/share/twitter
  58. https://medium.com/p/f4f8393686ed/share/facebook
