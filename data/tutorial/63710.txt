   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

coreml: a quick walkthrough

   go to the profile of nick bourdakos
   [9]nick bourdakos (button) blockedunblock (button) followfollowing
   jun 24, 2017 unlisted
   [1*cvn6qajuzsskh6w2c0tqzg.png]

   for those of you that haven   t heard, coreml was announced at wwdc a
   little less than a month ago. coreml is one of apple   s newest
   frameworks available for ios 11. it brings the capability of easily
   adding and using machine learning models on your phone.

   i want to emphasize how easy it is. by the end of this article you
   should be able to build an app with id161, with no machine
   learning prerequisites required!

   core ml is optimized to run fast and efficiently on your phone. this
   means you don   t have to worry about whether to run on gpu or cpu. apple
   actively switches between the two based on how computation and memory
   heavy the task.

   and! since it runs on your phone, this ensures the privacy of user data
   and guarantees that your app remains functional and responsive even
   when a network connection is unavailable!

   when coreml was announced i was super excited and couldn   t wait to get
   my hands on it. normally, i wait until ios is out of beta before
   upgrading, but! i have waited long enough   

what we   re building

   i decided to test out the vision framework because i   m kind of obsessed
   with id161. i   ve used [10]inception before so i thought it
   would be a good idea to try out the inceptionv3 model that apple has so
   kindly provided [11]here.

   apple provides several models on the [12]developer website, but they
   also provide a [13]conversion tool. you don   t have to learn a new way
   to build your model. if you   re model is built caffe, keras or
   scikit-learn, you can easily convert them to coreml models.

   we   ll be building a simple camera snapper that pops up a list of
   results when you take a picture. i spent a little bit of time to make
   it look pretty, but hopefully that doesn   t overcomplicate things     

jumping in

   in order to use coreml and run the demo app, you   ll need to install
   [14]xcode 9 beta             .

   then go ahead and clone [15]this repo.

   and    download one of these [16]models. i ended up trying out both
   inception and vgg16, they function pretty similarly, but inception   s
   file size is waayyyy smaller at 94.7 mb.
   [1*rvtkachl63ayqmtpvpuxew.png]

   copy the .mlmodel file you just downloaded into your project.

   note: it seems that there are a few bugs with automatically adding
   files to compiled sources so just make sure it looks something like
   this (make sure the .mlmodel file is there):
   [1*ovr4anajmypepbj4peqdwq.png]

how it works

   most of the code is just boilerplate for the camera and making the app
   look pretty. the part dealing with our coreml model can be found in the
   classify function in cameraviewcontroller.

   since, we are using an image as the input of our model we can take
   advantage of the vision framework!

   we start off by initializing the vision model and use it to build our
   vision request.

   we then need a vision request handler to actually perform our request.

   the only thing you probably need to change is inceptionv3().model to
   whatever model you are using, and you can change 0.01 to whatever
   confidence level you want to show up in your results table.

   iframe: [17]/media/1fc57d0bcf8aa9892685da36b6147848?postid=c836561d18f1

   note: we are using both coreml and vision so make sure you import both
   of them.

results

   i promised myself i wouldn   t talk about watson, but i was really
   curious and wanted to compare the results, because i wasn   t too
   impressed with inceptionv3   s performance   

   note: i also ended up testing out vgg16.

bookshelf

   [1*3xvyeemfnmloily4gldqqa.png]

coffee maker

   [1*gy9kobu5yfk_a9arspwk_w.png]

toothbrush

   [1*l2nubor89bd41qql2f7xuw.png]

fox

   [1*zvpyvs5b6m1qys9xl651tg.png]

final thoughts

   i personally feel watson totally kicked butt, except, you need wifi to
   use watson and watson doesn   t use coreml! i was suprized by how poorly
   the provided models performed, but i only tested things that were
   around the house.

   coreml itself is awesome and i want to try out building my own model
   with caffe and definitely try out coreml   s id164. i have
   some pretty exciting ideas going forward, let me know if you have any
   suggestions for things to try out      have fun, be creative and keep on
   hacking!
     __________________________________________________________________

   thanks for reading! if you have any questions, feel free to reach out
   at [18]bourdakos1@gmail.com, connect with me on [19]linkedin, or
   [20]follow me here on medium.

   if you found this article helpful, it would mean a lot if you click the
        and share with friends.

   unlisted
     * [21]machine learning
     * [22]ios
     * [23]swift
     * [24]apple
     * [25]tutorial

   (button)
   (button)
   (button) 9 claps
   (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of nick bourdakos

[26]nick bourdakos

   medium member since sep 2017

   id161 addict at ibm watson

     * (button)
       (button) 9
     * (button)

   [27]ibm watson
   never miss a story from ibm watson, when you sign up for medium.
   [28]learn more
   never miss a story from ibm watson
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/c836561d18f1
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@bourdakos1/a-deep-dive-into-coreml-c836561d18f1&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@bourdakos1/a-deep-dive-into-coreml-c836561d18f1&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@bourdakos1
  10. https://medium.com/@nickbourdakos/visual-recognition-378dd49ee272
  11. https://medium.com/r/?url=https://developer.apple.com/machine-learning/
  12. https://medium.com/r/?url=https://developer.apple.com/machine-learning/
  13. https://medium.com/r/?url=https://developer.apple.com/documentation/coreml/converting_trained_models_to_core_ml
  14. https://medium.com/r/?url=https://developer.apple.com/download/
  15. https://medium.com/r/?url=https://github.com/bourdakos1/core-ml-demo
  16. https://medium.com/r/?url=https://developer.apple.com/machine-learning/
  17. https://medium.com/media/1fc57d0bcf8aa9892685da36b6147848?postid=c836561d18f1
  18. https://medium.com/r/?url=http://bourdakos1@gmail.com
  19. https://medium.com/r/?url=https://www.linkedin.com/in/nicholasbourdakos
  20. https://medium.com/@nickbourdakos
  21. https://medium.com/tag/machine-learning?source=post
  22. https://medium.com/tag/ios?source=post
  23. https://medium.com/tag/swift?source=post
  24. https://medium.com/tag/apple?source=post
  25. https://medium.com/tag/tutorial?source=post
  26. https://medium.com/@bourdakos1
  27. https://medium.com/ibm-watson
  28. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  30. https://medium.com/@bourdakos1?source=post_header_lockup
  31. https://medium.com/@bourdakos1?source=footer_card
