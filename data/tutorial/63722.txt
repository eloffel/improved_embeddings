   #[1]sitewide atom feed [2]sitewide rss feed

   [3]omar u. florez

one lego at a time: explaining the math of how neural networks learn

     a neural network is a clever arrangement of linear and non-linear
     modules. when we choose and connect them wisely, we have a powerful
     tool to approximate any mathematical function. for example one that
     separates classes with a non-linear decision boundary.

   a topic that is not always explained in depth, despite of its intuitive
   and modular nature, is the id26 technique responsible for
   updating trainable parameters. let   s build a neural network from
   scratch to see the internal functioning of a neural network using lego
   pieces as a modular analogy, one brick at a time.

   code implementing this can be found in this repository:
   [4]https://github.com/omar-florez/scratch_mlp

neural networks as a composition of pieces

   alt text

   the above figure depicts some of the math used for training a neural
   network. we will make sense of this during this article. the reader may
   find interesting that a neural network is a stack of modules with
   different purposes:
     * input x feeds a neural network with raw data, which is stored in a
       matrix in which observations are rows and dimensions are columns
     * weights w1 maps input x to the first hidden layer h1. weights w1
       works then as a linear kernel
     * a sigmoid function prevents numbers in the hidden layer from
       falling out of range by scaling them to 0-1. the result is an array
       of neural activations h1 = sigmoid(wx)

   at this point these operations only compute a general linear system,
   which doesn   t have the capacity to model non-linear interactions. this
   changes when we stack one more layer, adding depth to this modular
   structure. the deeper the network, the more subtle non-linear
   interactions we can learn and more complex problems we can solve, which
   may explain in part the rise of deep neural models.

why should i read this?

     if you understand the internal parts of a neural network, you will
     quickly know what to change first when things don   t work and define
     an strategy to test invariants and expected behaviors that you know
     are part the algorithm. this will also be helpful when you want to
     create new capabilities that are not currently implemented in the ml
     library you are using.

   because debugging machine learning models is a complex task. by
   experience, mathematical models don   t work as expected the first try.
   they may give you low accuracy for new data, spend long training time
   or too much memory, return a large number of false negatives or nan
   predictions, etc. let me show some cases when knowing how the algorithm
   works can become handy:
     * if it takes so much time to train, it is maybe a good idea to
       increase the size of a minibatch to reduce the variance in the
       observations and thus to help the algorithm to converge
     * if you observe nan predictions, the algorithm may have received
       large gradients producing memory overflow. think of this as
       consecutive id127s that exploit after many
       iterations. decreasing the learning rate will have the effect of
       scaling down these values. reducing the number of layers will
       decrease the number of multiplications. and clipping gradients will
       control this problem explicitly

concrete example: learning the xor function

     let   s open the blackbox. we will build now a neural network from
     scratch that learns the xor function. the choice of this non-linear
     function is by no means random chance. without id26 it
     would be hard to learn to separate classes with a straight line.

   to illustrate this important concept, note below how a straight line
   cannot separate 0s and 1s, the outputs of the xor function. real life
   problems are also non-linearly separable.

   alt text

   the topology of the network is simple:
     * input x is a two dimensional vector
     * weights w1 is a 2x3 matrix with randomly initialized values
     * hidden layer h1 consists of three neurons. each neuron receives as
       input a weighted sum of observations, this is the inner product
       highlighted in green in the below figure: z1 = [x1, x2][w1, w2]
     * weights w2 is a 3x2 matrix with randomly initialized values and
     * output layer h2 consists of two neurons since the xor function
       returns either 0 (y1=[0,1]) or 1 (y2 = [1,0])

   more visually:

   alt text

   let   s now train the model. in our simple example the trainable
   parameters are weights, but be aware that current research is exploring
   more types of parameters to be optimized. for example shortcuts between
   layers, regularized distributions, topologies, residual, learning
   rates, etc.

   id26 is a method to update the weights towards the direction
   (gradient) that minimizes a predefined error metric known as loss
   function given a batch of labeled observations. this algorithm has been
   repeatedly rediscovered and is a special case of a more general
   technique called [5]automatic differentiation in reverse accumulation
   mode.

network initialization

     let   s initialize the network weights with random numbers.

   alt text

forward step:

     this goal of this step is to forward propagate the input x to each
     layer of the network until computing a vector in the output layer
     h2.

   this is how it happens:
     * linearly map input data x using weights w1 as a kernel:

   alt text
     * scale this weighted sum z1 with a sigmoid function to get values of
       the first hidden layer h1. note that the original 2d vector is now
       mapped to a 3d space.

   alt text
     * a similar process takes place for the second layer h2. let   s
       compute first the weighted sum z2 of the first hidden layer, which
       is now input data.

   alt text
     * and then compute their sigmoid activation function. this vector
       [0.37166596 0.45414264] represents the log id203 or predicted
       vector computed by the network given input x.

   alt text

computing the total loss

     also known as    actual minus predicted   , the goal of the loss
     function is to quantify the distance between the predicted vector h2
     and the actual label provided by humans y.

   note that the id168 contains a id173 component that
   penalizes large weight values as in a ridge regression. in other words,
   large squared weights values will increase the id168, an error
   metric we indeed want to minimize.

   alt text

backward step:

     the goal of this step is to update the weights of the neural network
     in a direction that minimizes its id168. as we will see,
     this is a recursive algorithm, which can reuse gradients previously
     computed and heavily relies on differentiable functions. since these
     updates reduce the id168, a network    learns    to approximate
     the label of observations with known classes. a property called
     generalization.

   this step goes in backward order than the forward step. it computes
   first the partial derivative of the id168 with respect to the
   weights of the output layer (dloss/dw2) and then the hidden layer
   (dloss/dw1). let   s explain in detail each one.

dloss/dw2:

   the chain rule says that we can decompose the computation of gradients
   of a neural network into differentiable pieces:

   alt text

   as a memory helper, these are the function definitions used above and
   their first derivatives:
       function      first derivative
   loss = (y-h2)^2  dloss/dw2 = -(y-h2)
   h2 = sigmoid(z2) dh2/dz2 = h2(1-h2)
   z2 = h1w2        dz2/dw2 = h1
   z2 = h1w2        dz2/dh1 = w2

   more visually, we aim to update the weights w2 (in blue) in the below
   figure. in order to that, we need to compute three partial derivatives
   along the chain.

   alt text

   plugging in values into these partial derivatives allow us to compute
   gradients with respect to weights w2 as follows.

   alt text

   the result is a 3x2 matrix dloss/dw2, which will update the original w2
   values in a direction that minimizes the id168.

   alt text

dloss/dw1:

   computing the chain rule for updating the weights of the first hidden
   layer w1 exhibits the possibility of reusing existing computations.

   alt text

   more visually, the path from the output layer to the weights w1 touches
   partial derivatives already computed in latter layers.

   alt text

   for example, partial derivatives dloss/dh2 and dh2/dz2 have been
   already computed as a dependency for learning weights of the output
   layer dloss/dw2 in the previous section.

   alt text

   placing all derivatives together, we can execute the chain rule again
   to update the weights of the hidden layer w1:

   alt text

   finally, we assign the new values of the weights and have completed an
   iteration on the training of network.

   alt text

implementation

   let   s translate the above mathematical equations to code only using
   [6]numpy as our id202 engine. neural networks are trained in a
   loop in which each iteration present already calibrated input data to
   the network. in this small example, let   s just consider the entire
   dataset in each iteration. the computations of forward step, loss, and
   backwards step lead to good generalization since we update the
   trainable parameters (matrices w1 and w2 in the code) with their
   corresponding gradients (matrices dl_dw1 and dl_dw2) in every cycle.
   code is stored in this repository:
   [7]https://github.com/omar-florez/scratch_mlp

   alt text

let   s run this!

   see below some neural networks trained to approximate the xor function
   over many iterations.

   left plot: accuracy. central plot: learned decision boundary. right
   plot: id168.

   first let   s see how a neural network with 3 neurons in the hidden layer
   has small capacity. this model learns to separate 2 classes with a
   simple decision boundary that starts being a straight line but then
   shows a non-linear behavior. the id168 in the right plot nicely
   gets low as training continues.

   alt text

   having 50 neurons in the hidden layer notably increases model   s power
   to learn more complex decision boundaries. this could not only produce
   more accurate results, but also exploiting gradients, a notable problem
   when training neural networks. this happens when very large gradients
   multiply weights during id26 and thus generate large updated
   weights. this is reason why the loss value suddenly increases during
   the last steps of the training (step > 90). the id173
   component of the id168 computes the squared values of weights
   that are already very large (sum(w^2)/2n).

   alt text

   this problem can be avoided by reducing the learning rate as you can
   see below. or by implementing a policy that reduces the learning rate
   over time. or by enforcing a stronger id173, maybe l1 instead
   of l2. exploiding and vanishing gradients are interesting phenomenons
   and we will devote an entire analysis later.

   alt text
     __________________________________________________________________

   [8]cc0   [9]omar u. florez

references

   1. https://omar-florez.github.io/scratch_mlpnil
   2. https://omar-florez.github.io/scratch_mlpnil
   3. https://omar-florez.github.io/scratch_mlp
   4. https://github.com/omar-florez/scratch_mlp
   5. https://en.wikipedia.org/wiki/automatic_differentiation
   6. http://www.numpy.org/
   7. https://github.com/omar-florez/scratch_mlp
   8. https://creativecommons.org/publicdomain/zero/1.0/
   9. https://www.linkedin.com/in/omar-u-florez-35338015
