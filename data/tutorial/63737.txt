   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

id161 by andrew ng         11 lessons learned

   [16]go to the profile of ryan shrott
   [17]ryan shrott (button) blockedunblock (button) followfollowing
   nov 19, 2017
   [1*og9pstljov1amc7v7vmhrq.jpeg]
   created in week 4 of the course. combined ng   s face with the style of
   rain princess by leonid afremov.

   i recently completed andrew ng   s id161 course on coursera. ng
   does an excellent job at explaining many of the complex ideas required
   to optimize any id161 task. my favourite component of the
   course was the neural style transfer section (see lesson 11), which
   allows you to create artwork which combines the style of claud monet
   with the content of whichever image you would like. this is an example
   of what you can do:
   [1*amew4j3o4dwvzjjkgnitvg.png]

   in this article, i will discuss 11 key lessons that i learned in the
   course. note that this is the fourth course in the deep learning
   specialization released by deeplearning.ai. if you would like to learn
   about the previous 3 courses, i recommend you check out [18]this blog.

lesson 1: why id161 is taking off?

   big data and algorithmic developments will cause the testing error of
   intelligent systems to converge to bayes optimal error. this will lead
   to ai surpassing human level performance in all areas, including
   natural perception tasks. open source software from tensorflow allows
   you to use id21 to implement an id164 system
   for any object very rapidly. with id21, you only need
   about 100   500 examples for the system to work relatively well. manually
   labeling 100 examples isn   t too much work, so you   ll have a minimum
   viable product very quickly.

lesson 2: how convolution works?

   ng explains how to implement the convolution operator and shows how it
   can detect edges in an image. he also explains other filters, such as
   the sobel filter, which put more weight on central pixels of the edge.
   ng then explains that the weights of the filter should not be
   hand-designed but rather should be learned using a hill climbing
   algorithm such as id119.

lesson 3: why convolutions?

   ng gives several philosophical reasons for why convolutions work so
   well in image recognition tasks. he outlines 2 concrete reasons. the
   first is known as parameter sharing. it is the idea that a feature
   detector that   s useful in one part of an image is probably useful in
   another part of the image. for example, an edge detector is probably
   useful is many parts of the image. the sharing of parameters allows the
   number of parameters to be small and also allows for robust translation
   invariance. translation invariance is the notion that a cat shifted and
   rotated is still a picture of a cat.

   the second idea he outlines is known as sparsity of connections. this
   is the idea that each output layer is only a function of a small number
   of inputs (particularly, the filter size squared). this greatly reduces
   the number of parameters in the network and allows for faster training.

lesson 3: why padding?

   padding is usually used to preserve the input size (i.e. the dimension
   of the input and output are the same). it is also used so that frames
   near the edges of image contribute as much to the output as frames near
   near the centre.

lesson 4: why max pooling?

   through empirical research, max pooling has proven to be extremely
   effective in id98   s. by downsampling the image, we reduce the number of
   parameters which makes the features invariant to scale or orientation
   changes.

lesson 5: classical network architectures

   ng shows 3 classical network architectures including lenet-5, alexnet
   and vgg-16. the main idea he presents is that effective networks often
   have layers with an increasing channel size and decreasing width and
   height.

lesson 6: why resnets works?

   for a plain network, the training error does not monotonically decrease
   as the number of layers increases due to vanishing and exploding
   gradients. these networks have feed forward skipped connections which
   allow you train extremely large networks without a drop in performance.
   [1*sp6ksrdom6hu4kuxpdxgiq.png]

lesson 7: use id21!

   training large networks, such as inception, from scratch can take weeks
   on a gpu. you should download the weights from a pretrained network and
   just retrain the last softmax layer (or the last few layers). this will
   greatly reduce training time. the reason this works is that earlier
   layers tend to be associated with concepts in all images such as edges
   and curvy lines.

lesson 8: how to win id161 competitions

   ng explains that you should train several networks independently and
   average their outputs to get better performance. data augmentation
   techniques such as randomly cropping images, flipping images about the
   horizontal and vertical axes may also help with performance. finally,
   you should use an open source implementation and pretrained model to
   start and then fine-tune the parameters for your particular
   application.

lesson 9: how to implement id164

   ng starts by explaining the idea of landmark detection in an image.
   basically, these landmarks become apart of your training output
   examples. with some clever convolution manipulations, you get an output
   volume that tells you the id203 that the object is in a certain
   region and the location of the object. he also explains how to evaluate
   the effectiveness of your id164 algorithm using the
   intersection over union formula. finally, ng puts all these components
   together to explain the famous yolo algorithm.

lesson 10: how to implement face recognition

   facial recognition is a id62 problem since you may only
   have one example image to identify the person. the solution is to learn
   a similarity function which gives the degree of difference between two
   images. so if the images are of the same person, you want the function
   to output a small number, and vice versa for different people.

   the first solution ng gives is known as a siamese network. the idea is
   to input two persons into the same network separately and then compare
   their outputs. if the outputs are similar, then the persons are
   probably the same. the network is trained so that if two input images
   are of the same person, then the distance between their encodings is
   relatively small.

   the second solution he gives uses a triplet loss method. the idea is
   that you have a triplet of images (anchor (a), positive (p) and
   negative (n)) and you train the network so that the output distance
   between a and p is much smaller than the distance between a and n.
   [1*6fxfzxduat9gpx4vzae8qg.png]
   [1*0gccwv08pup-ptpcvsrhxw.png]

lesson 11: how to create artwork using neural style transfer

   ng explains how to generate an image with a combining content and
   style. see the examples below.
   [1*ekjidfldoust0qwmziluag.png]

   the key to neural style transfer is to understand the visual
   representations for what each layer in a convolutional network is
   learning. it turns out that earlier layers learn simple features like
   edges and later features learn complex objects like faces, feet and
   cars.

   to build a neural style transfer image, you simply define a cost
   function which is a convex combination of the similarity in content and
   style. in particular, the cost function would be:
j(g) = alpha * j_content(c,g) + beta * j_style(s,g)

   where g is the generated image, c is the content image and s is the
   style image. the learning algorithm simply uses id119 to
   minimize the cost function with respect to the generated image, g.

   the steps are as follows:
    1. generate g randomly.
    2. use id119 to minimize j(g), i.e. write g := g-dg(j(g)).
    3. repeat step 2.

conclusion

   by completing this course, you will gain an intuitive understanding of
   a large chunk of the id161 literature. the homework
   assignments also give you practice implementing these ideas yourself.
   you will not become an expert in id161 after completing this
   course, but this course may kickstart a potential idea/career you may
   have in id161.

   if you have any interesting applications of id161 you would
   like to share, let me know in the comments below. i would be happy to
   discuss potential collaboration on new projects.

   that   s all folks         if you   ve made it this far, please comment below and
   add me on [19]linkedin.

   my github is [20]here.

     * [21]machine learning
     * [22]artificial intelligence
     * [23]id161
     * [24]deep learning
     * [25]towards data science

   (button)
   (button)
   (button) 2.2k claps
   (button) (button) (button) 11 (button) (button)

     (button) blockedunblock (button) followfollowing
   [26]go to the profile of ryan shrott

[27]ryan shrott

   equity desk quant at bmo capital markets
   [28]https://github.com/ryanshrott

     (button) follow
   [29]towards data science

[30]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 2.2k
     * (button)
     *
     *

   [31]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [32]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/7d05c18a6999
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/computer-vision-by-andrew-ng-11-lessons-learned-7d05c18a6999&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/computer-vision-by-andrew-ng-11-lessons-learned-7d05c18a6999&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_m6b3mazlcsfq---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@ryanshrott?source=post_header_lockup
  17. https://towardsdatascience.com/@ryanshrott
  18. https://towardsdatascience.com/deep-learning-specialization-by-andrew-ng-21-lessons-learned-15ffaaef627c
  19. https://www.linkedin.com/in/ryanshrott/
  20. https://github.com/ryanshrott
  21. https://towardsdatascience.com/tagged/machine-learning?source=post
  22. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  23. https://towardsdatascience.com/tagged/computer-vision?source=post
  24. https://towardsdatascience.com/tagged/deep-learning?source=post
  25. https://towardsdatascience.com/tagged/towards-data-science?source=post
  26. https://towardsdatascience.com/@ryanshrott?source=footer_card
  27. https://towardsdatascience.com/@ryanshrott
  28. https://github.com/ryanshrott
  29. https://towardsdatascience.com/?source=footer_card
  30. https://towardsdatascience.com/?source=footer_card
  31. https://towardsdatascience.com/
  32. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  34. https://medium.com/p/7d05c18a6999/share/twitter
  35. https://medium.com/p/7d05c18a6999/share/facebook
  36. https://medium.com/p/7d05c18a6999/share/twitter
  37. https://medium.com/p/7d05c18a6999/share/facebook
