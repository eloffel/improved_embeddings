   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    introductory guide to information retrieval using
   knn and kdtree comments feed [4]alternate [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]machine learning [94]introductory guide to information
   retrieval using knn and kdtree

   [95]machine learning[96]python

introductory guide to information retrieval using knn and kdtree

   [97]gurchetan singh, november 28, 2017

introduction

   i love cricket as much as i love data science. a few years back (on 16
   november 2013 to be precise), my favorite cricketer     sachin tendulkar
   retired from international cricket. i spent that entire day reading
   articles and blogs about him on the web.

   by the end of the day, i had read close to 50 articles about him.
   interestingly, while i was reading these articles     none of the
   websites suggested me articles outside of sachin or cricket. was it a
   co-incidence? surely not.

   i was being suggested the next article based on what i was currently
   reading. the technique behind this process is known as    information
   retrieval   .

   in this article, i would take you through the basics of information
   retrieval and two common algorithms used to implement it, knn and kd
   tree. by end of this article, you will be able to create your own
   information retrieval systems, which can be implemented in any digital
   library / search.

   let   s get going!


table of contents

     * what is information retrieval?
     * where is information retrieval used?
     * knn for information retrieval
     * improvement over knn: kd trees for information retrieval
     * explanation of kd trees
     * implementation of kd trees
     * advantages and disadvantages of kd trees


what is information retrieval?

   in the past few decades, the availability of cheap and effective
   storage devices and information systems has prompted the rapid growth
   of graphical and textual databases. information collection and storage
   efforts have become easier, but the effort required to retrieve
   relevant information has become significantly greater, especially in
   large-scale databases. this situation is critical for textual
   databases, with so much of textual information around us     for
   instance business applications (e.g., manuals, newsletters, and
   electronic data interchanges), scientific applications (e.g.,
   electronic community systems and scientific databases) etc.

   [98]source

   to aid the users to access these databases and extract the relevant
   knowledge or documents, information retrieval is used.

   information retrieval (ir) is the process by which a collection of data
   is represented, stored, and searched for the purpose of knowledge
   discovery as a response to a user request (query). this process
   involves various stages initiating with representing data and ending
   with returning relevant information to the user. the intermediate stage
   includes filtering, searching, matching and ranking operations. the
   main goal of information retrieval system (irs) is to    find the
   relevant information or a document that satisfies user   s information
   needs   


where is information retrieval used?

use case 1: digital library

   a digital library is a library in which collection of data are stored
   in digital formats and accessible by computers. the digital content may
   be stored locally, or accessed remotely via computer networks. a
   digital library is a type of information retrieval system.

use case 2: search engine

   a search engine is one of the most the practical applications of
   information retrieval techniques to large scale text collections.

use case 3: id162

   an id162 system is a computer system for browsing, searching
   and retrieving images from a large database of digital images.

   very famous example of id162 system is
   [99]https://reverse.photos/ which uses image as the search query and
   returns similar images.

   [100]source


knn for information retrieval

   one of the most common algorithms that most of the data scientists use
   for retrieval of information is knn. k nearest neighbour (knn) is one
   of the simplest algorithms that calculates the distance between the
   query observation and each data point in the train dataset and finds
   the k closest observations.

   when we use nearest neighbour search algorithm, it compares all the
   data points with the mentioned query point and finds the closest
   points.

   there are many ways in which we can find the distance between two data
   points. most commonly used distance metrics are    euclidean distance   
   and    hamming distance   .

   [101]this research paper focuses on them.

   imagine a situation where you have thousands of queries, and every time
   the algorithm compares the query point with all the data points. isn   t
   it very computationally intensive?

   also, greater the data points, higher will be the amount of computation
   needed. obviously!

   [102]source

   so, knn  search has o(n) time complexity for each query where n= number
   of data points. for knn with k neighbor search, the time complexity
   will be o(log(k)*n) only if we maintain a priority queue to return the
   closest k observations. you can read more about knn [103]here.

   so, for a dataset with millions of rows and thousands of queries, knn
   seems to be computationally very demanding. so is there any alternative
   to knn which uses similar approach but can be time efficient also?

   kd tree is one such algorithm which uses a mixture of id90
   and knn to calculate the nearest neighbour(s).


improvement over knn: kd trees for information retrieval

   kd-trees are a specific data structure for efficiently representing our
   data. in particular, kd-trees helps organize and partition the data
   points based on specific conditions.

   let   s say we have a data set with 2 input features. we can represent
   our data as-


   now, we   re going to be making some axis aligned cuts, and maintaining
   lists of points that fall into each one of these different bins.


   [104]source

   and what this structure allows us to do as we   re going to show, is
   efficiently prune our search space so that we don   t have to visit every
   single data point.

   now the question arises of how to draw these cuts?
    1. one option is to split at the median value of the observations that
       are contained in the box.
    2. you could also split at the centre point of the box, ignoring the
       spread of data within the box

   then a question is when do you stop?

   there are a couple of choices that we have.
    1. one is you can stop if there are fewer than a given number of
       points in the box. let   s say m data points left.
    2. or if a minimum width to the box has been achieved.

   so again, this second criteria would ignore the actual data in the box
   whereas the first one uses facts about the data to drive the stocking
   criterion. we can use the same distance metrics(   euclidean distance   
   and    hamming distance   ) that we used while implementing knn.

intuitive explanation of kd trees

   suppose we have a data set with only two features.
                x    y
   data point 0 0.54 0.93
   data point 1 0.96 0.86
   data point 2 0.42 0.67
   data point 3 0.11 0.53
   data point 4 0.64 0.29
   data point 5 0.27 0.75
   data point 6 0.81 0.63

   let   s split data into two groups.

   we do it by comparing x with mean of max and min value.

   value = (max + min)/2

   = (0.96 + 0.11)/2

   = 0.53






   at each node we will save 3 things.
     * dimension we split on
     * value we split on
     * tightest bounding box which contains all the points within that
       node.

   tight bounds x                 y
   node 1       0.11 <= x <= 0.42 0.53 <= y <= 0.75
   node 2       0.54 <= x <= 0.96 0.29 <= y <= 0.93

   similarly dividing the structure into more parts on the basis of
   alternate dimensions until we get maximum 2 data points in a node.


   so now we plotted the points and divided them into various groups.

   let   s say now we have a query point    q    to which we have to find the
   nearest neighbor.


   using the tree we made earlier, we traverse through it to find the
   correct node.


   when using node 3 to find the nearest neighbor.

   but we can easily see, that it is in fact not the nearest neighbor to
   the query point.

   we now traverse one level up, to node 1. we do this because the nearest
   neighbor may not necessarily fall into the same node as the query
   point.

   do we need to inspect all remaining data points in node 1 ?

   we can check this by checking if the tightest box containing all the
   points of node 4 is closer than the current near point or not.

   this time, the bounding box for node 4 lies within the circle,
   indicating that node 4 may contain a point that   s closer to the query.

   when we calculate the distance of the points within the node 4 and
   previous closest point with the query point, we find that point lying
   above the query point is actually the nearest neighbor within the given
   points.

   we now traverse one level up, to root.

   do we need to inspect all remaining data points in node 2 ?

   we can check this by checking if the tightest box containing all the
   points of node 2 is closer than the current near point or not.

   we can see that the tightest box is far from the current nearest point.
   hence, we can prune that part of the tree.


   since we   ve traversed the whole tree, we are done: data point marked is
   indeed the true nearest neighbour of the query.


implementation of kd trees

   for the implementation of kd tree, we will use the most common form of
   ir ie document retrieval. based on the current document, document
   retrieval returns the most similar document(s) to the user.

   we will use the dataset which consists of articles on famous
   personalities. we would implement kd tree to help us retrieve articles
   most similar to that of the    barack obama   .

   you can download the dataset in the form of csv from [105]here.

   [106]source


in [1]:

#importing libraries

import pandas as pd

import numpy as np

import nltk



in [2]:

#reading first 2000 rows of the dataset

people = pd.read_csv('people_data.csv',nrows =2000)



in [4]:

#using countvectoriser to count the freq of occurence of each word

from sklearn.feature_extraction.text import countvectorizer

count_vect = countvectorizer()

x_train_counts = count_vect.fit_transform(people.text)

   

in [5]:

#using tf-idf to reduce the effect of common words

from sklearn.feature_extraction.text import tfidftransformer

tfidf_transformer = tfidftransformer()

x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)



in [6]:

#using tfidf as a feature

people['tfidf']=list(x_train_tfidf.toarray())



in [8]:

#importing kdtree

from sklearn.neighbors import kdtree

kdt = kdtree(people['tfidf'].tolist(), leaf_size=3)



in [9]:

#using kdtree to find 3 articles similar to that of barack obama

dist, idx = kdt.query(people['tfidf'][people['name']=='barack obama'].tolist(),
k=3)



in [10]:

#indices of 3 nearest articles

idx[0]



out[10]:

array([  32,    0, 1177])



in [11]:

#nearest neighbour 1

people['name'][32]



out[11]:

'barack obama'



in [12]:

#nearest neighbour 2

people['name'][0]



out[12]:

'bill clinton'



in [13]:

#nearest neighbour 3

people['name'][1177]



out[13]:

'donald fowler'


   hence we can see that articles of bill clinton and donald flower who
   share the same field of politics as barack obama are similar.

advantages and disadvantages of kd trees

advantages of kd trees

   so now we look at the advantages of kd tree :
     * so to begin with, the first thing we have to do when we have a
       query point, is that we traverse all the way down to a leaf node.
       so we   re going to go all the way down to the depth of the tree. in
       the worst case, we would have to traverse n nodes, the worst case
       being when, because of the structure of the problem we   re not able
       to prune anything at all.
     * the complexity range is anywhere from on the order of log n, if we
       can do lots of pruning, everything gets pruned, all the way to on
       the order of n, if we can   t do any pruning.
     * remember that order n was the same complexity as our knn search.
       so, if we   re just going to do a single nearest neighbour query and
       if we got really unlucky about the structure of the data, we might
       take a penalty over a knn search. but in many cases, we can
       actually have significant gains in efficiency and time.


disadvantages of kd tree

   well, kd-trees are really cool. they   re a very intuitive way to think
   about storing data, and as we saw, they could lead to help us find
   relevant information way sooner.

   but there are few issues.
     * kd-trees are not the simplest things to implement. you have to
       structure out this tree, and it can be pretty challenging to do
       that.

   [107]source
     * as the features of our data, i.e. dimensionality increases, we
       might get a poor performance in terms of efficiency of nearest
       neighbor search using kd-trees. this is because we won   t be able to
       prune many partitions as in high dimension, the radius of our
       nearest neighbour would intersect many different partitions, which
       would force us to look for a better nearest neighbour among the
       points stored in them. so we won   t be able to prune many of these
       partitions, and what ends up happening is that we would have to
       search many partitions which completely defeats the purpose of
       using kd-trees. as displayed in the above image, no of inspections
       would increase exponentially as the dimensionality of the dataset
       increase.


end notes

   kd tree can prove to be a better retrieval algorithm on a specific
   dataset that matches its condition. though there are more models such
   as locality sensitive hashing which can overcome its limitations. we
   shall explore them as well in the upcoming articles.

   did you find the article useful? do you plan to use kd tree or lsh in
   near future in python or r? if yes, share with us how you plan to go
   about it.
   you can also read this article on analytics vidhya's android app
   [108]get it on google play

share this:

     * [109]click to share on linkedin (opens in new window)
     * [110]click to share on facebook (opens in new window)
     * [111]click to share on twitter (opens in new window)
     * [112]click to share on pocket (opens in new window)
     * [113]click to share on reddit (opens in new window)
     *

like this:

   like loading...

related articles

   [ins: :ins]

   tags : [114]information retrieval, [115]kdtree, [116]knn, [117]machine
   learning
   next article

heart sound segmentation using deep learning     a doctor in making?

   previous article

flashtext     a library faster than id157 for nlp tasks

[118]gurchetan singh

   budding data scientist from mait who loves implementing data analytical
   and statistical machine learning models in python. i also understand
   big data technology like hadoop and alteryx.
     *
     *
     *

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [119]discussion portal to get your queries resolved

12 comments

     * james chibole says:
       [120]november 28, 2017 at 10:54 am
       powerful article. where can i study this?
       [121]reply
          + gurchetan singh says:
            [122]november 28, 2017 at 1:33 pm
            hey james
            glad that you liked the article !!
            you can refer to    intro to statistical learning   , a book by
            trevor hastie for more insights. coursera also offers a course
            on id91 and retrieval by univ of washington. you can
            watch it   s videos for detailed explanation.
            [123]reply
     * gitesh narula says:
       [124]november 28, 2017 at 11:24 am
       nice and easy explanation !
       [125]reply
     * shubham ganguly says:
       [126]november 28, 2017 at 11:34 am
       excellent article worth reading and it is very informative
       [127]reply
     * james says:
       [128]november 28, 2017 at 6:36 pm
       r methods of writing available ?
       [129]reply
          + gurchetan singh says:
            [130]november 29, 2017 at 3:35 pm
            hey james
            i only use python for implementing ml. hence i have no idea
            regarding the r code. if you manage to implement it in future,
            do share with us.
            [131]reply
     * jarad says:
       [132]november 28, 2017 at 11:16 pm
       why value = (max + min)/2 instead of value = (max     min)/2 ? is
       there some advantage to adding max and min over max     min?
       [133]reply
          + gurchetan singh says:
            [134]november 29, 2017 at 12:35 am
            hey jarad
            the idea is to take the average value which can equally divide
            the datasets into equal parts. instead of taking the average
            of all datapoints, we consider only the extremes for
            calculating the average. so max+min/2 sounds intuitively more
            correct as it will give some value in between while max-min/2
            might not.
            [135]reply
               o jarad says:
                 [136]november 29, 2017 at 7:15 am
                 you   re right. thank you for the explanation. i don   t know
                 why that wasn   t obvious to me.
                 [137]reply
     * [138]divp says:
       [139]november 29, 2017 at 3:21 pm
       nice one thanks for sharing
       [140]reply
     * hassan says:
       [141]november 30, 2017 at 10:11 am
       awesome article
       [142]reply
     * prasoon says:
       [143]december 21, 2017 at 3:32 am
       have you guys explored k-d-b tree, hb-tree or bkd tree? i think bkd
       takes care of some of the limitations of kd tree.
       [144]reply

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-06] [145]srk       3924
   2    [2.jpg?date=2019-04-06] [146]mark12    3510
   3    [3.jpg?date=2019-04-06] [147]nilabha   3261
   4    [4.jpg?date=2019-04-06] [148]nitish007 3237
   5    [5.jpg?date=2019-04-06] [149]tezdhar   3082
   [150]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [151]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [152]understanding support vector machine algorithm from examples
       (along with code)
     * [153]essentials of machine learning algorithms (with python and r
       codes)
     * [154]a complete tutorial to learn data science with python from
       scratch
     * [155]7 types of regression techniques you should know!
     * [156]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [157]a simple introduction to anova (with applications in excel)
     * [158]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [159]top 5 machine learning github repositories and reddit discussions
   from march 2019

[160]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [161]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[162]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [163]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[164]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [165]16 opencv functions to start your id161 journey (with
   python code)

[166]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [167][ds-finhack.jpg]

   [168][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [169]about us
     * [170]our team
     * [171]career
     * [172]contact us
     * [173]write for us

   [174]about us
   [175]   
   [176]our team
   [177]   
   [178]careers
   [179]   
   [180]contact us

data scientists

     * [181]blog
     * [182]hackathon
     * [183]discussions
     * [184]apply jobs
     * [185]leaderboard

companies

     * [186]post jobs
     * [187]trainings
     * [188]hiring hackathons
     * [189]advertising
     * [190]reach us

   don't have an account? [191]sign up here.

join our community :

   [192]46336 [193]followers
   [194]20224 [195]followers
   [196]followers
   [197]7513 [198]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [199]privacy policy
     * [200]terms of use
     * [201]refund policy

   don't have an account? [202]sign up here

   iframe: [203]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [204](button) join now

   subscribe!

   iframe: [205]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [206](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/machine-learning/
  94. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/
  95. https://www.analyticsvidhya.com/blog/category/machine-learning/
  96. https://www.analyticsvidhya.com/blog/category/python-2/
  97. https://www.analyticsvidhya.com/blog/author/gurchetan1000/
  98. https://3.bp.blogspot.com/-w96avpmy198/wfgqtqkmi7i/aaaaaaaagaq/zd3izfvh0_e5yy2d_1wss5n8rb8rpjrbwck4bgayycw/s320/information+retrieval_1.png?width=320
  99. https://reverse.photos/
 100. http://slideplayer.com/slide/3415344/12/images/6/content-based+image+retrieval.jpg
 101. https://www2.ia-engineers.org/iciae/index.php/iciae/iciae2015/paper/viewfile/572/423
 102. https://camo.githubusercontent.com/7e03ab32b5e89f2631b5a5dbb40a367350bb25bc/68747470733a2f2f706c6f742e6c792f2537456b6361726c73736f6e38392f3339372e706e67
 103. https://www.analyticsvidhya.com/blog/2014/10/introduction-k-neighbours-algorithm-id91/
 104. http://graphics.stanford.edu/courses/cs368-00-spring/ta/manuals/cgal/ref-manual2/searchstructures/kdtree.gif
 105. https://drive.google.com/file/d/1quivjqthndzcxft6xgjqhknpj48rz-49/view?usp=sharing
 106. https://github.com/learnml/machine-learning-specialization
 107. https://www.coursera.org/learn/ml-id91-and-retrieval/lecture/2i4c7/visualizing-scaling-behavior-of-kd-trees
 108. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 109. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/?share=linkedin
 110. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/?share=facebook
 111. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/?share=twitter
 112. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/?share=pocket
 113. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/?share=reddit
 114. https://www.analyticsvidhya.com/blog/tag/information-retrieval/
 115. https://www.analyticsvidhya.com/blog/tag/kdtree/
 116. https://www.analyticsvidhya.com/blog/tag/knn/
 117. https://www.analyticsvidhya.com/blog/tag/machine-learning/
 118. https://www.analyticsvidhya.com/blog/author/gurchetan1000/
 119. https://discuss.analyticsvidhya.com/
 120. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145261
 121. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145261
 122. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145288
 123. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145288
 124. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145264
 125. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145264
 126. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145268
 127. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145268
 128. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145366
 129. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145366
 130. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145523
 131. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145523
 132. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145409
 133. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145409
 134. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145414
 135. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145414
 136. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145467
 137. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145467
 138. http://www.cygnet-infotech.com/
 139. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145520
 140. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145520
 141. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145623
 142. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-145623
 143. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-148891
 144. https://www.analyticsvidhya.com/blog/2017/11/information-retrieval-using-kdtree/#comment-148891
 145. https://datahack.analyticsvidhya.com/user/profile/srk
 146. https://datahack.analyticsvidhya.com/user/profile/mark12
 147. https://datahack.analyticsvidhya.com/user/profile/nilabha
 148. https://datahack.analyticsvidhya.com/user/profile/nitish007
 149. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 150. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 151. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 152. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 153. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 154. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 155. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 156. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 157. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 158. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 159. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 160. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 161. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 162. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 163. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 164. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 165. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 166. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 167. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 168. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 169. http://www.analyticsvidhya.com/about-me/
 170. https://www.analyticsvidhya.com/about-me/team/
 171. https://www.analyticsvidhya.com/career-analytics-vidhya/
 172. https://www.analyticsvidhya.com/contact/
 173. https://www.analyticsvidhya.com/about-me/write/
 174. http://www.analyticsvidhya.com/about-me/
 175. https://www.analyticsvidhya.com/about-me/team/
 176. https://www.analyticsvidhya.com/about-me/team/
 177. https://www.analyticsvidhya.com/about-me/team/
 178. https://www.analyticsvidhya.com/career-analytics-vidhya/
 179. https://www.analyticsvidhya.com/about-me/team/
 180. https://www.analyticsvidhya.com/contact/
 181. https://www.analyticsvidhya.com/blog
 182. https://datahack.analyticsvidhya.com/
 183. https://discuss.analyticsvidhya.com/
 184. https://www.analyticsvidhya.com/jobs/
 185. https://datahack.analyticsvidhya.com/users/
 186. https://www.analyticsvidhya.com/corporate/
 187. https://trainings.analyticsvidhya.com/
 188. https://datahack.analyticsvidhya.com/
 189. https://www.analyticsvidhya.com/contact/
 190. https://www.analyticsvidhya.com/contact/
 191. https://datahack.analyticsvidhya.com/signup/
 192. https://www.facebook.com/analyticsvidhya/
 193. https://www.facebook.com/analyticsvidhya/
 194. https://twitter.com/analyticsvidhya
 195. https://twitter.com/analyticsvidhya
 196. https://plus.google.com/+analyticsvidhya
 197. https://in.linkedin.com/company/analytics-vidhya
 198. https://in.linkedin.com/company/analytics-vidhya
 199. https://www.analyticsvidhya.com/privacy-policy/
 200. https://www.analyticsvidhya.com/terms/
 201. https://www.analyticsvidhya.com/refund-policy/
 202. https://id.analyticsvidhya.com/accounts/signup/
 203. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 204. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 205. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 206. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 208. https://www.facebook.com/analyticsvidhya
 209. https://twitter.com/analyticsvidhya
 210. https://plus.google.com/+analyticsvidhya/posts
 211. https://in.linkedin.com/company/analytics-vidhya
 212. https://www.analyticsvidhya.com/blog/2017/11/heart-sound-segmentation-deep-learning/
 213. https://www.analyticsvidhya.com/blog/2017/11/flashtext-a-library-faster-than-regular-expressions/
 214. https://www.analyticsvidhya.com/blog/author/gurchetan1000/
 215. https://www.analyticsvidhya.com/cdn-cgi/l/email-protection#3b5c4e4958535e4f5a550a0b0b0b7b5c565a525715585456
 216. https://www.linkedin.com/in/gurchetan-singh-b257ba110/
 217. https://github.com/gurchetan1000
 218. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 219. https://www.facebook.com/analyticsvidhya/
 220. https://twitter.com/analyticsvidhya
 221. https://plus.google.com/+analyticsvidhya
 222. https://plus.google.com/+analyticsvidhya
 223. https://in.linkedin.com/company/analytics-vidhya
 224. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 225. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 226. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 227. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 228. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 229. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 230. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 231. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 232. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 233. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 234. javascript:void(0);
 235. javascript:void(0);
 236. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 237. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 238. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 239. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 240. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 241. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 242. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 243. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 244. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 245. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f11%2finformation-retrieval-using-kdtree%2f&linkname=introductory%20guide%20to%20information%20retrieval%20using%20knn%20and%20kdtree
 246. javascript:void(0);
 247. javascript:void(0);
