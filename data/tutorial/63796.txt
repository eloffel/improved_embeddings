   #[1]github [2]recent commits to deepspeech:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]554
     * [35]star [36]9,842
     * [37]fork [38]1,773

[39]mozilla/[40]deepspeech

   [41]code [42]issues 109 [43]pull requests 3 [44]projects 2 [45]wiki
   [46]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [47]sign up
   a tensorflow implementation of baidu's deepspeech architecture
   [48]deep-learning [49]machine-learning [50]neural-networks
   [51]tensorflow [52]speech-recognition [53]speech-to-text
     * [54]1,618 commits
     * [55]43 branches
     * [56]30 releases
     * [57]67 contributors
     * [58]mpl-2.0

    1. [59]c++ 62.3%
    2. [60]c 15.4%
    3. [61]python 13.4%
    4. [62]shell 5.2%
    5. [63]cmake 1.3%
    6. [64]java 0.8%
    7. other 1.6%

   (button) c++ c python shell cmake java other
   branch: master (button) new pull request
   [65]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/m
   [66]download zip

downloading...

   want to be notified of new releases in mozilla/deepspeech?
   [67]sign in [68]sign up

launching github desktop...

   if nothing happens, [69]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [70]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [71]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [72]download the github extension for visual studio
   and try again.

   (button) go back
   [73]@reuben
   [74]reuben [75]merge branch 'more-metadata'
   latest commit [76]5779d29 apr 5, 2019
   [77]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [78].github [79]add lock bot config dec 28, 2018
   [80]bin [81]rename epoch flag to epochs apr 5, 2019
   [82]data [83]capitalize mar 18, 2019
   [84]doc [85]adding streaming api support to the gui tool nov 16, 2018
   [86]examples [87]improved nodejs streaming id136 with vad and
   ffmpeg mar 18, 2019
   [88]images [89]compressed gif nov 28, 2017
   [90]native_client [91]embed more metadata in exported model and read it
   in native client apr 5, 2019
   [92]taskcluster [93]update to new tensorflow r1.13 artifacts apr 3,
   2019
   [94]util [95]merge branch 'more-metadata' apr 5, 2019
   [96].compute [97]fix [98]#1986 [99]- remove distributed training
   support apr 1, 2019
   [100].gitattributes [101]remove old versions of decoder binary files
   nov 8, 2018
   [102].gitignore [103]fix [104]#1986 [105]- remove distributed training
   support apr 1, 2019
   [106].taskcluster.yml
   [107]code_of_conduct.md [108]add mozilla code of conduct file mar 29,
   2019
   [109]deepspeech.py [110]merge branch 'more-metadata' apr 5, 2019
   [111]dockerfile [112]update to tensorflow 1.13 mar 19, 2019
   [113]graph_version [114]add version info to exported graphs apr 3, 2019
   [115]issue_template.md [116]create an issue template nov 27, 2017
   [117]license [118]added license sep 20, 2016
   [119]readme.md [120]rename epoch flag to epochs apr 5, 2019
   [121]release.md
   [122]version [123]bump version to v0.5.0-alpha.4 mar 20, 2019
   [124]bazel.patch [125]proper re-use of bazel cache jan 31, 2018
   [126]evaluate.py [127]rewrite input pipeline to use tf.data api apr 2,
   2019
   [128]evaluate_tflite.py [129]add --define=runtime=tflite config_setting
   feb 14, 2019
   [130]requirements.txt [131]rewrite input pipeline to use tf.data api
   apr 2, 2019
   [132]requirements_eval_tflite.txt [133]add tflite accuracy estimation
   tool feb 12, 2019
   [134]tc-android-apk-tests.sh [135]move to libdeepspeech jan 22, 2019
   [136]tc-android-ds-tests.sh [137]extract tensorflow version ourselves
   jan 23, 2019
   [138]tc-benchmark-tests.sh [139]remove aot sep 20, 2018
   [140]tc-brew-tests.sh [141]force homebrew_no_auto_update=1 to avoid
   magic autoupdate of brew oct 25, 2018
   [142]tc-cpp-ds-tests-prod.sh
   [143]tc-cpp-ds-tests.sh [144]remove aot sep 20, 2018
   [145]tc-cppwin-ds-tests.sh [146]building on windows mar 12, 2019
   [147]tc-lite_benchmark_model-ds-tests.sh [148]add benchmark_model tests
   nov 5, 2018
   [149]tc-netframework-ds-tests.sh [150]building on windows mar 12, 2019
   [151]tc-node-tests-prod.sh [152]unify version definition apr 27, 2018
   [153]tc-node-tests.sh [154]add nodejs windows tests mar 20, 2019
   [155]tc-python-tests-prod.sh [156]add python 3.7.0b5 jun 5, 2018
   [157]tc-python-tests.sh [158]remove aot sep 20, 2018
   [159]tc-schedule.sh [160]avoid duplicated tag name for routes apr 28,
   2018
   [161]tc-single-shot-id136.sh [162]don't overwrite exported graph
   from training task with the tflite ver    apr 2, 2019
   [163]tc-tests-utils.sh [164]use taskcluster_tmp_dir instead of
   hardcoding /tmp apr 5, 2019
   [165]tc-train-tests.sh [166]speed up training tests and make sure they
   fully converge apr 2, 2019

readme.md

project deepspeech

   [167]task status

   deepspeech is an open source speech-to-text engine, using a model
   trained by machine learning techniques based on [168]baidu's deep
   speech research paper. project deepspeech uses google's [169]tensorflow
   to make the implementation easier.

   [170]usage

   pre-built binaries for performing id136 with a trained model can be
   installed with pip3. proper setup using a virtual environment is
   recommended, and you can find that documentation [171]below.

   a pre-trained english model is available for use and can be downloaded
   using [172]the instructions below. currently, only 16-bit, 16 khz,
   mono-channel wave audio files are supported in the python client.

   once everything is installed, you can then use the deepspeech binary to
   do speech-to-text on short (approximately 5-second long) audio files as
   such:
pip3 install deepspeech
deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm
models/lm.binary --trie models/trie --audio my_audio_file.wav

   alternatively, quicker id136 can be performed using a supported
   nvidia gpu on linux. see the [173]release notes to find which gpus are
   supported. to run deepspeech on a gpu, install the gpu specific
   package:
pip3 install deepspeech-gpu
deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm
models/lm.binary --trie models/trie --audio my_audio_file.wav

   please ensure you have the required [174]cuda dependency.

   see the output of deepspeech -h for more information on the use of
   deepspeech. (if you experience problems running deepspeech, please
   check [175]required runtime dependencies).

   table of contents
     * [176]prerequisites
     * [177]getting the code
     * [178]getting the pre-trained model
     * [179]using the model
          + [180]cuda dependency
          + [181]model compatibility
          + [182]using the python package
          + [183]using the command-line client
          + [184]using the node.js package
          + [185]installing bindings from source
          + [186]third party bindings
     * [187]training
          + [188]installing prerequisites for training
          + [189]recommendations
          + [190]common voice training data
          + [191]training a model
          + [192]checkpointing
          + [193]exporting a model for id136
          + [194]exporting a model for tflite
          + [195]making a mmap-able model for id136
          + [196]continuing training from a release model
     * [197]contact/getting help

prerequisites

     * [198]python 3.6
     * [199]git large file storage
     * mac or linux environment
     * go to [200]build readme to start building deepspeech for windows
       from source.

getting the code

   install [201]git large file storage either manually or through a
   package-manager if available on your system. then clone the deepspeech
   repository normally:
git clone https://github.com/mozilla/deepspeech

getting the pre-trained model

   if you want to use the pre-trained english model for performing
   speech-to-text, you can download it (along with other important
   id136 material) from the deepspeech [202]releases page.
   alternatively, you can run the following command to download and unzip
   the model files in your current directory:
wget https://github.com/mozilla/deepspeech/releases/download/v0.4.1/deepspeech-0
.4.1-models.tar.gz
tar xvfz deepspeech-0.4.1-models.tar.gz

using the model

   there are three ways to use deepspeech id136:
     * [203]the python package
     * [204]the command-line client
     * [205]the node.js package

cuda dependency

   the gpu capable builds (python, nodejs, c++ etc) depend on the same
   cuda runtime as upstream tensorflow. currently with tensorflow r1.12 it
   depends on cuda 9.0 and cudnn v7.2.

model compatibility

   deepspeech models are versioned to keep you from trying to use an
   incompatible graph with a newer client after a breaking change was made
   to the code. if you get an error saying your model file version is too
   old for the client, you should either upgrade to a newer model release,
   re-export your model from the checkpoint using a newer version of the
   code, or downgrade your client if you need to use the old model and
   can't re-export it.

using the python package

   pre-built binaries which can be used for performing id136 with a
   trained model can be installed with pip3. you can then use the
   deepspeech binary to do speech-to-text on an audio file:

   for the python bindings, it is highly recommended that you perform the
   installation within a python 3.5 or later virtual environment. you can
   find more information about those in [206]this documentation.

   we will continue under the assumption that you already have your system
   properly setup to create new virtual environments.

create a deepspeech virtual environment

   in creating a virtual environment you will create a directory
   containing a python3 binary and everything needed to run deepspeech.
   you can use whatever directory you want. for the purpose of the
   documentation, we will rely on $home/tmp/deepspeech-venv. you can
   create it using this command:
$ virtualenv -p python3 $home/tmp/deepspeech-venv/

   once this command completes successfully, the environment will be ready
   to be activated.

activating the environment

   each time you need to work with deepspeech, you have to activate this
   virtual environment. this is done with this simple command:
$ source $home/tmp/deepspeech-venv/bin/activate

installing deepspeech python bindings

   once your environment has been set-up and loaded, you can use pip3 to
   manage packages locally. on a fresh setup of the virtualenv, you will
   have to install the deepspeech wheel. you can check if deepspeech is
   already installed with pip3 list.

   to perform the installation, just use pip3 as such:
$ pip3 install deepspeech

   if deepspeech is already installed, you can update it as such:
$ pip3 install --upgrade deepspeech

   alternatively, if you have a supported nvidia gpu on linux, you can
   install the gpu specific package as follows:
$ pip3 install deepspeech-gpu

   see the [207]release notes to find which gpus are supported. please
   ensure you have the required [208]cuda dependency.

   you can update deepspeech-gpu as follows:
$ pip3 install --upgrade deepspeech-gpu

   in both cases, pip3 should take care of installing all the required
   dependencies. after installation has finished, you should be able to
   call deepspeech from the command-line.

   note: the following command assumes you [209]downloaded the pre-trained
   model.
deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm
models/lm.binary --trie models/trie --audio my_audio_file.wav

   the arguments --lm and --trie are optional, and represent a language
   model.

   see [210]client.py for an example of how to use the package
   programatically.

using the command-line client

   to download the pre-built binaries for the deepspeech command-line
   client, use util/taskcluster.py:
python3 util/taskcluster.py --target .

   or if you're on macos:
python3 util/taskcluster.py --arch osx --target .

   also, if you need some binaries different than current master, like
   v0.2.0-alpha.6, you can use --branch:
python3 util/taskcluster.py --branch "v0.2.0-alpha.6" --target "."

   the script taskcluster.py will download native_client.tar.xz (which
   includes the deepspeech binary and associated libraries) and extract it
   into the current folder. also, taskcluster.py will download binaries
   for linux/x86_64 by default, but you can override that behavior with
   the --arch parameter. see the help info with python util/taskcluster.py
   -h for more details. specific branches of deepspeech or tensorflow can
   be specified as well.

   note: the following command assumes you [211]downloaded the pre-trained
   model.
./deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --l
m models/lm.binary --trie models/trie --audio audio_input.wav

   see the help output with ./deepspeech -h and the [212]native client
   readme for more details.

using the node.js package

   you can download the node.js bindings using npm:
npm install deepspeech

   alternatively, if you're using linux and have a supported nvidia gpu,
   you can install the gpu specific package as follows:
npm install deepspeech-gpu

   see the [213]release notes to find which gpus are supported. please
   ensure you have the required [214]cuda dependency.

   see [215]client.js for an example of how to use the bindings. or
   download the [216]wav example.

installing bindings from source

   if pre-built binaries aren't available for your system, you'll need to
   install them from scratch. follow these [217]native_client installation
   instructions.

third party bindings

   in addition to the bindings above, third party developers have started
   to provide bindings to other languages:
     * [218]asticode provides [219]golang bindings in its
       [220]go-astideepspeech repo.
     * [221]rustaudio provide a [222]rust binding, the installation and
       use of which is described in their [223]deepspeech-rs repo.
     * [224]stes provides preliminary [225]pkgbuilds to install the client
       and python bindings on [226]arch linux in the [227]arch-deepspeech
       repo.
     * [228]gst-deepspeech provides a [229]gstreamer plugin which can be
       used from any language with gstreamer bindings.

training

installing prerequisites for training

   install the required dependencies using pip3:
cd deepspeech
pip3 install -r requirements.txt

   you'll also need to install the ds_ctcdecoder python package.
   ds_ctcdecoder is required for decoding the outputs of the deepspeech
   acoustic model into text. you can use util/taskcluster.py with the
   --decoder flag to get a url to a binary of the decoder package
   appropriate for your platform and python version:
pip3 install $(python3 util/taskcluster.py --decoder)

   this command will download and install the ds_ctcdecoder package. if
   you prefer building the binaries from source, see the
   [230]native_client readme file. you can override the platform with
   --arch if you want the package for arm7 (--arch arm) or arm64 (--arch
   arm64).

recommendations

   if you have a capable (nvidia, at least 8gb of vram) gpu, it is highly
   recommended to install tensorflow with gpu support. training will be
   significantly faster than using the cpu. to enable gpu support, you can
   do:
pip3 uninstall tensorflow
pip3 install 'tensorflow-gpu==1.13.1'

   please ensure you have the required [231]cuda dependency.

common voice training data

   the common voice corpus consists of voice samples that were donated
   through mozilla's [232]common voice initiative. you can download
   individual commonvoice v2.0 language data sets from [233]here. after
   extraction of such a data set, you'll find the following contents:
     * the *.tsv files output by corporacreator for the downloaded
       language
     * the mp3 audio files they reference in a clips sub-directory.

   for bringing this data into a form that deepspeech understands, you
   have to run the commonvoice v2.0 importer (bin/import_cv2.py):
bin/import_cv2.py --filter_alphabet path/to/some/alphabet.txt /path/to/extracted
/language/archive

   providing a filter alphabet is optional. it will exclude all samples
   whose transcripts contain characters not in the specified alphabet.
   running the importer with -h will show you some additional options.

   once the import is done, the clips sub-directory will contain for each
   required .mp3 an additional .wav file. it will also add the following
   .csv files:
     * clips/train.csv
     * clips/dev.csv
     * clips/test.csv

   all entries in these csv files refer to their samples by absolute
   paths. so moving this sub-directory would require another import or
   tweaking the csv files accordingly.

   to use common voice data during training, validation and testing, you
   pass (comma separated combinations of) their filenames into
   --train_files, --dev_files, --test_files parameters of deepspeech.py.

   if, for example, common voice language en was extracted to
   ../data/cv/en/, deepspeech.py could be called like this:
./deepspeech.py --train_files ../data/cv/en/clips/train.csv --dev_files ../data/
cv/en/clips/dev.csv --test_files ../data/cv/en/clips/test.csv

training a model

   the central (python) script is deepspeech.py in the project's root
   directory. for its list of command line options, you can call:
./deepspeech.py --helpfull

   to get the output of this in a slightly better-formatted way, you can
   also look up the option definitions top deepspeech.py.

   for executing pre-configured training scenarios, there is a collection
   of convenience scripts in the bin folder. most of them are named after
   the corpora they are configured for. keep in mind that the other speech
   corpora are very large, on the order of tens of gigabytes, and some
   aren't free. downloading and preprocessing them can take a very long
   time, and training on them without a fast gpu (gtx 10 series
   recommended) takes even longer.

   if you experience gpu oom errors while training, try reducing the batch
   size with the --train_batch_size, --dev_batch_size and
   --test_batch_size parameters.

   as a simple first example you can open a terminal, change to the
   directory of the deepspeech checkout and run:
./bin/run-ldc93s1.sh

   this script will train on a small sample dataset called ldc93s1, which
   can be overfitted on a gpu in a few minutes for demonstration purposes.
   from here, you can alter any variables with regards to what dataset is
   used, how many training iterations are run and the default values of
   the network parameters.

   feel also free to pass additional (or overriding) deepspeech.py
   parameters to these scripts. then, just run the script to train the
   modified network.

   each dataset has a corresponding importer script in bin/ that can be
   used to download (if it's freely available) and preprocess the dataset.
   see bin/import_librivox.py for an example of how to import and
   preprocess a large dataset for training with deepspeech.

   if you've run the old importers (in util/importers/), they could have
   removed source files that are needed for the new importers to run. in
   that case, simply remove the extracted folders and let the importer
   extract and process the dataset from scratch, and things should work.

checkpointing

   during training of a model so-called checkpoints will get stored on
   disk. this takes place at a configurable time interval. the purpose of
   checkpoints is to allow interruption (also in the case of some
   unexpected failure) and later continuation of training without losing
   hours of training time. resuming from checkpoints happens automatically
   by just (re)starting training with the same --checkpoint_dir of the
   former run.

   be aware however that checkpoints are only valid for the same model
   geometry they had been generated from. in other words: if there are
   error messages of certain tensors having incompatible dimensions, this
   is most likely due to an incompatible model change. one usual way out
   would be to wipe all checkpoint files in the checkpoint directory or
   changing it before starting the training.

exporting a model for id136

   if the --export_dir parameter is provided, a model will have been
   exported to this directory during training. refer to the corresponding
   [234]readme.md for information on building and running a client that
   can use the exported model.

exporting a model for tflite

   if you want to experiment with the tf lite engine, you need to export a
   model that is compatible with it, then use the --nouse_seq_length
   --export_tflite flags. if you already have a trained model, you can
   re-export it for tflite by running deepspeech.py again and specifying
   the same checkpoint_dir that you used for training, as well as passing
   --nouse_seq_length --export_tflite --export_dir
   /model/export/destination.

making a mmap-able model for id136

   the output_graph.pb model file generated in the above step will be
   loaded in memory to be dealt with when running id136. this will
   result in extra loading time and memory consumption. one way to avoid
   this is to directly read data from the disk.

   tensorflow has tooling to achieve this: it requires building the target
   //tensorflow/contrib/util:convert_graphdef_memmapped_format (binaries
   are produced by our taskcluster for some systems including linux/amd64
   and macos/amd64), use util/taskcluster.py tool to download, specifying
   tensorflow as a source and convert_graphdef_memmapped_format as
   artifact.

   producing a mmap-able model is as simple as:
$ convert_graphdef_memmapped_format --in_graph=output_graph.pb --out_graph=outpu
t_graph.pbmm

   upon sucessfull run, it should report about conversion of a non-zero
   number of nodes. if it reports converting 0 nodes, something is wrong:
   make sure your model is a frozen one, and that you have not applied any
   incompatible changes (this includes quantize_weights).

continuing training from a release model

   if you'd like to use one of the pre-trained models released by mozilla
   to bootstrap your training process (id21, fine tuning),
   you can do so by using the --checkpoint_dir flag in deepspeech.py.
   specify the path where you downloaded the checkpoint from the release,
   and training will resume from the pre-trained model.

   for example, if you want to fine tune the entire graph using your own
   data in my-train.csv, my-dev.csv and my-test.csv, for three epochs, you
   can something like the following, tuning the hyperparameters as needed:
mkdir fine_tuning_checkpoints
python3 deepspeech.py --n_hidden 2048 --checkpoint_dir path/to/checkpoint/folder
 --epochs 3 --train_files my-train.csv --dev_files my-dev.csv --test_files my_de
v.csv --learning_rate 0.0001

   note: the released models were trained with --n_hidden 2048, so you
   need to use that same value when initializing from the release models.

contact/getting help

   there are several ways to contact us or to get help:
    1. [235]faq - we have a list of common questions, and their answers,
       in our [236]faq. when just getting started, it's best to first
       check the [237]faq to see if your question is addressed.
    2. [238]discourse forums - if your question is not addressed in the
       [239]faq, the [240]discourse forums is the next place to look. they
       contain conversations on [241]general topics, [242]using deep
       speech, and [243]deep speech development.
    3. [244]irc - if your question is not addressed by either the [245]faq
       or [246]discourse forums, you can contact us on the
       #machinelearning channel on [247]mozilla irc; people there can try
       to answer/help
    4. [248]issues - finally, if all else fails, you can open an issue in
       our repo.

     *    2019 github, inc.
     * [249]terms
     * [250]privacy
     * [251]security
     * [252]status
     * [253]help

     * [254]contact github
     * [255]pricing
     * [256]api
     * [257]training
     * [258]blog
     * [259]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [260]reload to refresh your
   session. you signed out in another tab or window. [261]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/mozilla/deepspeech/commits/master.atom
   3. https://github.com/mozilla/deepspeech#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/mozilla/deepspeech
  32. https://github.com/join
  33. https://github.com/login?return_to=/mozilla/deepspeech
  34. https://github.com/mozilla/deepspeech/watchers
  35. https://github.com/login?return_to=/mozilla/deepspeech
  36. https://github.com/mozilla/deepspeech/stargazers
  37. https://github.com/login?return_to=/mozilla/deepspeech
  38. https://github.com/mozilla/deepspeech/network/members
  39. https://github.com/mozilla
  40. https://github.com/mozilla/deepspeech
  41. https://github.com/mozilla/deepspeech
  42. https://github.com/mozilla/deepspeech/issues
  43. https://github.com/mozilla/deepspeech/pulls
  44. https://github.com/mozilla/deepspeech/projects
  45. https://github.com/mozilla/deepspeech/wiki
  46. https://github.com/mozilla/deepspeech/pulse
  47. https://github.com/join?source=prompt-code
  48. https://github.com/topics/deep-learning
  49. https://github.com/topics/machine-learning
  50. https://github.com/topics/neural-networks
  51. https://github.com/topics/tensorflow
  52. https://github.com/topics/speech-recognition
  53. https://github.com/topics/speech-to-text
  54. https://github.com/mozilla/deepspeech/commits/master
  55. https://github.com/mozilla/deepspeech/branches
  56. https://github.com/mozilla/deepspeech/releases
  57. https://github.com/mozilla/deepspeech/graphs/contributors
  58. https://github.com/mozilla/deepspeech/blob/master/license
  59. https://github.com/mozilla/deepspeech/search?l=c++
  60. https://github.com/mozilla/deepspeech/search?l=c
  61. https://github.com/mozilla/deepspeech/search?l=python
  62. https://github.com/mozilla/deepspeech/search?l=shell
  63. https://github.com/mozilla/deepspeech/search?l=cmake
  64. https://github.com/mozilla/deepspeech/search?l=java
  65. https://github.com/mozilla/deepspeech/find/master
  66. https://github.com/mozilla/deepspeech/archive/master.zip
  67. https://github.com/login?return_to=https://github.com/mozilla/deepspeech
  68. https://github.com/join?return_to=/mozilla/deepspeech
  69. https://desktop.github.com/
  70. https://desktop.github.com/
  71. https://developer.apple.com/xcode/
  72. https://visualstudio.github.com/
  73. https://github.com/reuben
  74. https://github.com/mozilla/deepspeech/commits?author=reuben
  75. https://github.com/mozilla/deepspeech/commit/5779d298e14f1acea8aab8c090b1aab8320c48a7
  76. https://github.com/mozilla/deepspeech/commit/5779d298e14f1acea8aab8c090b1aab8320c48a7
  77. https://github.com/mozilla/deepspeech/tree/5779d298e14f1acea8aab8c090b1aab8320c48a7
  78. https://github.com/mozilla/deepspeech/tree/master/.github
  79. https://github.com/mozilla/deepspeech/commit/39efa24d7dca8ffd42556211aa885b0795e1151e
  80. https://github.com/mozilla/deepspeech/tree/master/bin
  81. https://github.com/mozilla/deepspeech/commit/97c36291af5e22847f3f5f84de1d011c8fb78f32
  82. https://github.com/mozilla/deepspeech/tree/master/data
  83. https://github.com/mozilla/deepspeech/commit/73ebc5027770dec80837f495f44a82fa4adf6434
  84. https://github.com/mozilla/deepspeech/tree/master/doc
  85. https://github.com/mozilla/deepspeech/commit/851fb4ea900b17fc2993a83b606879a210ced86e
  86. https://github.com/mozilla/deepspeech/tree/master/examples
  87. https://github.com/mozilla/deepspeech/commit/e8169160b6a05f9a5cec4540e5372d340fb290b8
  88. https://github.com/mozilla/deepspeech/tree/master/images
  89. https://github.com/mozilla/deepspeech/commit/afb67aed98b34da993fd30790c1b3004d8a98b71
  90. https://github.com/mozilla/deepspeech/tree/master/native_client
  91. https://github.com/mozilla/deepspeech/commit/7f6fd8b48bef935c5adcb1bf09dce45893fab5f2
  92. https://github.com/mozilla/deepspeech/tree/master/taskcluster
  93. https://github.com/mozilla/deepspeech/commit/3aa286f6157ff24d0254bdaef9f0f837fc5d468a
  94. https://github.com/mozilla/deepspeech/tree/master/util
  95. https://github.com/mozilla/deepspeech/commit/5779d298e14f1acea8aab8c090b1aab8320c48a7
  96. https://github.com/mozilla/deepspeech/blob/master/.compute
  97. https://github.com/mozilla/deepspeech/commit/a179a2389fa304352db2e7dfabe893d56f5a4d09
  98. https://github.com/mozilla/deepspeech/issues/1986
  99. https://github.com/mozilla/deepspeech/commit/a179a2389fa304352db2e7dfabe893d56f5a4d09
 100. https://github.com/mozilla/deepspeech/blob/master/.gitattributes
 101. https://github.com/mozilla/deepspeech/commit/60fb5ad04c8a070c8db4c03313a089921ffb566f
 102. https://github.com/mozilla/deepspeech/blob/master/.gitignore
 103. https://github.com/mozilla/deepspeech/commit/a179a2389fa304352db2e7dfabe893d56f5a4d09
 104. https://github.com/mozilla/deepspeech/issues/1986
 105. https://github.com/mozilla/deepspeech/commit/a179a2389fa304352db2e7dfabe893d56f5a4d09
 106. https://github.com/mozilla/deepspeech/blob/master/.taskcluster.yml
 107. https://github.com/mozilla/deepspeech/blob/master/code_of_conduct.md
 108. https://github.com/mozilla/deepspeech/commit/1f7babda1a33354ca9a07a33a6ce4baa124b1e24
 109. https://github.com/mozilla/deepspeech/blob/master/deepspeech.py
 110. https://github.com/mozilla/deepspeech/commit/5779d298e14f1acea8aab8c090b1aab8320c48a7
 111. https://github.com/mozilla/deepspeech/blob/master/dockerfile
 112. https://github.com/mozilla/deepspeech/commit/91fa181b7406fe5f0010348ef71d26b7000666c6
 113. https://github.com/mozilla/deepspeech/blob/master/graph_version
 114. https://github.com/mozilla/deepspeech/commit/a7cda8e761a8f3446730cd19a8e019c4873a6573
 115. https://github.com/mozilla/deepspeech/blob/master/issue_template.md
 116. https://github.com/mozilla/deepspeech/commit/f1bb852a5ee524c705366ba841c0de77c7fbdb9a
 117. https://github.com/mozilla/deepspeech/blob/master/license
 118. https://github.com/mozilla/deepspeech/commit/ea38c6834410f891810a89ef8acedadd594967a9
 119. https://github.com/mozilla/deepspeech/blob/master/readme.md
 120. https://github.com/mozilla/deepspeech/commit/97c36291af5e22847f3f5f84de1d011c8fb78f32
 121. https://github.com/mozilla/deepspeech/blob/master/release.md
 122. https://github.com/mozilla/deepspeech/blob/master/version
 123. https://github.com/mozilla/deepspeech/commit/4f261b7d825eefa49a64babd14849bb363c70ca5
 124. https://github.com/mozilla/deepspeech/blob/master/bazel.patch
 125. https://github.com/mozilla/deepspeech/commit/11fcae4bc74cd367b846b3b4fb342c4db3ecf9a9
 126. https://github.com/mozilla/deepspeech/blob/master/evaluate.py
 127. https://github.com/mozilla/deepspeech/commit/1cea2b0fe88b888ae8bbbb4cbe2743c1a6087552
 128. https://github.com/mozilla/deepspeech/blob/master/evaluate_tflite.py
 129. https://github.com/mozilla/deepspeech/commit/f7a82c9608e1c31fd5a725aaf6ff299f8dfeee88
 130. https://github.com/mozilla/deepspeech/blob/master/requirements.txt
 131. https://github.com/mozilla/deepspeech/commit/1cea2b0fe88b888ae8bbbb4cbe2743c1a6087552
 132. https://github.com/mozilla/deepspeech/blob/master/requirements_eval_tflite.txt
 133. https://github.com/mozilla/deepspeech/commit/c0cd36554439c43e3ec6582607203eaf0e67f7f7
 134. https://github.com/mozilla/deepspeech/blob/master/tc-android-apk-tests.sh
 135. https://github.com/mozilla/deepspeech/commit/b396d3a7d41ea335213583d28ab8a7435a52d590
 136. https://github.com/mozilla/deepspeech/blob/master/tc-android-ds-tests.sh
 137. https://github.com/mozilla/deepspeech/commit/5d842c284b037b45a1c40ec9b32998256ebc7a46
 138. https://github.com/mozilla/deepspeech/blob/master/tc-benchmark-tests.sh
 139. https://github.com/mozilla/deepspeech/commit/3dad37eb05153cb935183f26e796a1437812d9af
 140. https://github.com/mozilla/deepspeech/blob/master/tc-brew-tests.sh
 141. https://github.com/mozilla/deepspeech/commit/4be9364c364ce6bbe83847530da4d2e0265d88a1
 142. https://github.com/mozilla/deepspeech/blob/master/tc-cpp-ds-tests-prod.sh
 143. https://github.com/mozilla/deepspeech/blob/master/tc-cpp-ds-tests.sh
 144. https://github.com/mozilla/deepspeech/commit/3dad37eb05153cb935183f26e796a1437812d9af
 145. https://github.com/mozilla/deepspeech/blob/master/tc-cppwin-ds-tests.sh
 146. https://github.com/mozilla/deepspeech/commit/75149f33df620ef40d5f642c550e3b6e22513d27
 147. https://github.com/mozilla/deepspeech/blob/master/tc-lite_benchmark_model-ds-tests.sh
 148. https://github.com/mozilla/deepspeech/commit/740e8584bde902c3f8c14eacd1064df6ba169e28
 149. https://github.com/mozilla/deepspeech/blob/master/tc-netframework-ds-tests.sh
 150. https://github.com/mozilla/deepspeech/commit/75149f33df620ef40d5f642c550e3b6e22513d27
 151. https://github.com/mozilla/deepspeech/blob/master/tc-node-tests-prod.sh
 152. https://github.com/mozilla/deepspeech/commit/e01784894ed6f7ce21d5c389f8725fc474a08ef7
 153. https://github.com/mozilla/deepspeech/blob/master/tc-node-tests.sh
 154. https://github.com/mozilla/deepspeech/commit/d421daa2ca18265684d7e722e87c0d8f20f0cf47
 155. https://github.com/mozilla/deepspeech/blob/master/tc-python-tests-prod.sh
 156. https://github.com/mozilla/deepspeech/commit/d08ef842bc1b372ac2cbf77afeacddf671c7a5a7
 157. https://github.com/mozilla/deepspeech/blob/master/tc-python-tests.sh
 158. https://github.com/mozilla/deepspeech/commit/3dad37eb05153cb935183f26e796a1437812d9af
 159. https://github.com/mozilla/deepspeech/blob/master/tc-schedule.sh
 160. https://github.com/mozilla/deepspeech/commit/10ac90473006ce65ec93283b0f8c17f061b47e2e
 161. https://github.com/mozilla/deepspeech/blob/master/tc-single-shot-id136.sh
 162. https://github.com/mozilla/deepspeech/commit/6632504ad164fe02c37bb9222121dd48ee510245
 163. https://github.com/mozilla/deepspeech/blob/master/tc-tests-utils.sh
 164. https://github.com/mozilla/deepspeech/commit/d70753cc0fd781b2f79f0deafe9db1d717823eca
 165. https://github.com/mozilla/deepspeech/blob/master/tc-train-tests.sh
 166. https://github.com/mozilla/deepspeech/commit/d6babfb8f3dc707473345664eb145128c6587272
 167. https://github.taskcluster.net/v1/repository/mozilla/deepspeech/master/latest
 168. https://arxiv.org/abs/1412.5567
 169. https://www.tensorflow.org/
 170. https://github.com/mozilla/deepspeech/blob/master/images/usage.gif
 171. https://github.com/mozilla/deepspeech#using-the-python-package
 172. https://github.com/mozilla/deepspeech#getting-the-pre-trained-model
 173. https://github.com/mozilla/deepspeech/releases
 174. https://github.com/mozilla/deepspeech#cuda-dependency
 175. https://github.com/mozilla/deepspeech/blob/master/native_client/readme.md#required-dependencies
 176. https://github.com/mozilla/deepspeech#prerequisites
 177. https://github.com/mozilla/deepspeech#getting-the-code
 178. https://github.com/mozilla/deepspeech#getting-the-pre-trained-model
 179. https://github.com/mozilla/deepspeech#using-the-model
 180. https://github.com/mozilla/deepspeech#cuda-dependency
 181. https://github.com/mozilla/deepspeech#model-compatibility
 182. https://github.com/mozilla/deepspeech#using-the-python-package
 183. https://github.com/mozilla/deepspeech#using-the-command-line-client
 184. https://github.com/mozilla/deepspeech#using-the-nodejs-package
 185. https://github.com/mozilla/deepspeech#installing-bindings-from-source
 186. https://github.com/mozilla/deepspeech#third-party-bindings
 187. https://github.com/mozilla/deepspeech#training
 188. https://github.com/mozilla/deepspeech#installing-prerequisites-for-training
 189. https://github.com/mozilla/deepspeech#recommendations
 190. https://github.com/mozilla/deepspeech#common-voice-training-data
 191. https://github.com/mozilla/deepspeech#training-a-model
 192. https://github.com/mozilla/deepspeech#checkpointing
 193. https://github.com/mozilla/deepspeech#exporting-a-model-for-id136
 194. https://github.com/mozilla/deepspeech#exporting-a-model-for-tflite
 195. https://github.com/mozilla/deepspeech#making-a-mmap-able-model-for-id136
 196. https://github.com/mozilla/deepspeech#continuing-training-from-a-release-model
 197. https://github.com/mozilla/deepspeech#contactgetting-help
 198. https://www.python.org/
 199. https://git-lfs.github.com/
 200. https://github.com/mozilla/deepspeech/blob/master/examples/net_framework/readme.md
 201. https://git-lfs.github.com/
 202. https://github.com/mozilla/deepspeech/releases
 203. https://github.com/mozilla/deepspeech#using-the-python-package
 204. https://github.com/mozilla/deepspeech#using-the-command-line-client
 205. https://github.com/mozilla/deepspeech#using-the-nodejs-package
 206. http://docs.python-guide.org/en/latest/dev/virtualenvs/
 207. https://github.com/mozilla/deepspeech/releases
 208. https://github.com/mozilla/deepspeech#cuda-dependency
 209. https://github.com/mozilla/deepspeech#getting-the-pre-trained-model
 210. https://github.com/mozilla/deepspeech/blob/master/native_client/python/client.py
 211. https://github.com/mozilla/deepspeech#getting-the-pre-trained-model
 212. https://github.com/mozilla/deepspeech/blob/master/native_client/readme.md
 213. https://github.com/mozilla/deepspeech/releases
 214. https://github.com/mozilla/deepspeech#cuda-dependency
 215. https://github.com/mozilla/deepspeech/blob/master/native_client/javascript/client.js
 216. https://github.com/mozilla/deepspeech/blob/master/examples/nodejs_wav
 217. https://github.com/mozilla/deepspeech/blob/master/native_client/readme.md
 218. https://github.com/asticode
 219. https://golang.org/
 220. https://github.com/asticode/go-astideepspeech
 221. https://github.com/rustaudio
 222. https://www.rust-lang.org/
 223. https://github.com/rustaudio/deepspeech-rs
 224. https://github.com/stes
 225. https://wiki.archlinux.org/index.php/pkgbuild
 226. https://www.archlinux.org/
 227. https://github.com/stes/arch-deepspeech
 228. https://github.com/elleo/gst-deepspeech
 229. https://gstreamer.freedesktop.org/
 230. https://github.com/mozilla/deepspeech/blob/master/native_client/readme.md
 231. https://github.com/mozilla/deepspeech#cuda-dependency
 232. https://voice.mozilla.org/
 233. https://voice.mozilla.org/data
 234. https://github.com/mozilla/deepspeech/blob/master/native_client/readme.md
 235. https://github.com/mozilla/deepspeech/wiki#frequently-asked-questions
 236. https://github.com/mozilla/deepspeech/wiki#frequently-asked-questions
 237. https://github.com/mozilla/deepspeech/wiki#frequently-asked-questions
 238. https://discourse.mozilla.org/c/deep-speech
 239. https://github.com/mozilla/deepspeech/wiki#frequently-asked-questions
 240. https://discourse.mozilla.org/c/deep-speech
 241. https://discourse.mozilla.org/t/general-topics/21075
 242. https://discourse.mozilla.org/t/using-deep-speech/21076/4
 243. https://discourse.mozilla.org/t/deep-speech-development/21077
 244. https://wiki.mozilla.org/irc
 245. https://github.com/mozilla/deepspeech/wiki#frequently-asked-questions
 246. https://discourse.mozilla.org/c/deep-speech
 247. https://wiki.mozilla.org/irc
 248. https://github.com/mozilla/deepspeech/issues
 249. https://github.com/site/terms
 250. https://github.com/site/privacy
 251. https://github.com/security
 252. https://githubstatus.com/
 253. https://help.github.com/
 254. https://github.com/contact
 255. https://github.com/pricing
 256. https://developer.github.com/
 257. https://training.github.com/
 258. https://github.blog/
 259. https://github.com/about
 260. https://github.com/mozilla/deepspeech
 261. https://github.com/mozilla/deepspeech

   hidden links:
 263. https://github.com/
 264. https://github.com/mozilla/deepspeech
 265. https://github.com/mozilla/deepspeech
 266. https://github.com/mozilla/deepspeech
 267. https://help.github.com/articles/which-remote-url-should-i-use
 268. https://github.com/mozilla/deepspeech#project-deepspeech
 269. https://github.com/mozilla/deepspeech#prerequisites
 270. https://github.com/mozilla/deepspeech#getting-the-code
 271. https://github.com/mozilla/deepspeech#getting-the-pre-trained-model
 272. https://github.com/mozilla/deepspeech#using-the-model
 273. https://github.com/mozilla/deepspeech#cuda-dependency
 274. https://github.com/mozilla/deepspeech#model-compatibility
 275. https://github.com/mozilla/deepspeech#using-the-python-package
 276. https://github.com/mozilla/deepspeech#create-a-deepspeech-virtual-environment
 277. https://github.com/mozilla/deepspeech#activating-the-environment
 278. https://github.com/mozilla/deepspeech#installing-deepspeech-python-bindings
 279. https://github.com/mozilla/deepspeech#using-the-command-line-client
 280. https://github.com/mozilla/deepspeech#using-the-nodejs-package
 281. https://github.com/mozilla/deepspeech#installing-bindings-from-source
 282. https://github.com/mozilla/deepspeech#third-party-bindings
 283. https://github.com/mozilla/deepspeech#training
 284. https://github.com/mozilla/deepspeech#installing-prerequisites-for-training
 285. https://github.com/mozilla/deepspeech#recommendations
 286. https://github.com/mozilla/deepspeech#common-voice-training-data
 287. https://github.com/mozilla/deepspeech#training-a-model
 288. https://github.com/mozilla/deepspeech#checkpointing
 289. https://github.com/mozilla/deepspeech#exporting-a-model-for-id136
 290. https://github.com/mozilla/deepspeech#exporting-a-model-for-tflite
 291. https://github.com/mozilla/deepspeech#making-a-mmap-able-model-for-id136
 292. https://github.com/mozilla/deepspeech#continuing-training-from-a-release-model
 293. https://github.com/mozilla/deepspeech#contactgetting-help
 294. https://github.com/
