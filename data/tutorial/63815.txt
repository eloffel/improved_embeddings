   #[1]rss feed

   [tr?id=1853843318208763&ev=pageview&noscript=1]

     * [2]home
     * [3]blog
     * [4]research
     * [5]cv
     * [6]photography
          + [7]arches
          + [8]berlin
          + [9]lindau
          + [10]munich
          + [11]people taking pictures

     * menu

[12]brian dolhansky

   ml     code     photography

     * [13]home
     * [14]blog
     * [15]research
     * [16]cv
     * photography
          + [17]arches
          + [18]berlin
          + [19]lindau
          + [20]munich
          + [21]people taking pictures

[22]id158s: mathematics of id26 (part 4)

   [23]october 28, 2014 in [24]ml primers, [25]neural networks

   up until now, we haven't utilized any of the expressive non-linear
   power of neural networks - all of our simple one layer models
   corresponded to a linear model such as multinomial id28.
   these one-layer models had a simple derivative. we only had one set of
   weights the fed directly to our output, and it was easy to compute the
   derivative with respect to these weights. however, what happens when we
   want to use a deeper model? what happens when we start stacking
   layers?

   no longer is there a linear relation in between a change in the weights
   and a change of the target. any perturbation at a particular layer will
   be further transformed in successive layers. so, then, how do we
   compute the gradient for all weights in our network? this is  where we
   use the id26 algorithm.

   id26, at its core, simply consists of repeatedly applying
   the chain rule through all of the possible paths in our network.
   however, there are an exponential number of directed paths from the
   input to the output. id26's real power arises in the form of
   a id145 algorithm, where we reuse intermediate results to
   calculate the gradient. we transmit intermediate errors backwards
   through a network, thus leading to the name id26. in fact,
   id26 is closely related to forward propagation, but instead
   of propagating the inputs forward through the network, we propagate the
   error backwards.

   most explanations of id26 start directly with a general
   theoretical derivation, but i   ve found that computing the gradients by
   hand naturally leads to the id26 algorithm itself, and
   that   s what i   ll be doing in this blog post. this is a lengthy section,
   but i feel that this is the best way to learn how id26
   works.

   i   ll start with a simple one-path network, and then move on to a
   network with multiple units per layer. finally, i   ll derive the general
   id26 algorithm. code for the id26 algorithm will
   be included in my next installment, where i derive the matrix form of
   the algorithm.

examples: deriving the base rules of id26

   remember that our ultimate goal in training a neural network is to find
   the gradient of each weight with respect to the output: $$\begin{align}
   \frac{\partial e}{\partial w_{i\rightarrow j}} \end{align}$$ we do this
   so that we can update the weights incrementally using stochastic
   id119: $$\begin{align*} w_{i\rightarrow j} =&
   w_{i\rightarrow j} -\eta \frac{\partial e}{\partial w_{i\rightarrow j}}
   \end{align*}$$

   for a single unit in a general network, we can have several cases: the
   unit may have only one input and one output (case 1), the unit may have
   multiple inputs (case 2), or the unit may have multiple outputs (case
   3). technically there is a fourth case: a unit may have multiple inputs
   and outputs. but as we will see, the multiple input case and the
   multiple output case are independent, and we can simply combine the
   rules we learn for case 2 and case 3 for this case.

   i will go over each of this cases in turn with relatively simple
   multilayer networks, and along the way will derive some general rules
   for id26.  at the end, we can combine all of these rules
   into a single grand unified id26 algorithm for arbitrary
   networks.

case 1: single input and single output

   suppose we have the following network:
   a simple "one path" network. a simple "one path" network.

   a simple "one path" network.
   we can explicitly write out the values of each of variable in this
   network: $$ \begin{align} s_j =&\ w_1\cdot x_i\\ z_j =&\ \sigma(in_j) =
   \sigma(w_1\cdot x_i)\\ s_k =&\ w_2\cdot z_j\\ z_k =&\ \sigma(in_k) =
   \sigma(w_2\cdot\sigma(w_1\cdot x_i))\\ s_o =&\ w_3\cdot z_k\\ \hat{y}_i
   =&\ in_o = w_3\cdot\sigma(w_2\cdot\sigma(w_1\cdot x_i))\\ e =&\
   \frac{1}{2}(\hat{y}_i - y_i)^2 =
   \frac{1}{2}(w_3\cdot\sigma(w_2\cdot\sigma(w_1\cdot x_i)) - y_i)^2
   \end{align} $$ for this simple example, it's easy to find all of the
   derivatives by hand. in fact, let's do that now. i am going to color
   code certain parts of the derivation, and see if you can deduce a
   pattern that we might exploit in an iterative algorithm. first, let's
   find the derivative for $w_{k\rightarrow o}$ (remember that $\hat{y} =
   w_{k\rightarrow o}z_k$, as our output is a linear unit): $$
   \begin{align} \frac{\partial e}{\partial w_{k\rightarrow o}} =&\
   \frac{\partial}{\partial w_{k\rightarrow o}} \frac{1}{2}(\hat{y}_i -
   y_i)^2\\ =&\ \frac{\partial}{\partial w_{k\rightarrow o}}
   \frac{1}{2}(w_{k\rightarrow o}\cdot z_k - y_i)^2\\ =&\ (w_{k\rightarrow
   o}\cdot z_k - y_i)\frac{\partial}{\partial w_{k\rightarrow
   o}}(w_{k\rightarrow o}\cdot z_k - y_i)\\ =&\ \color{blue}{(\hat{y_i} -
   y_i)}(z_k) \end{align} $$ finding the weight update for
   $w_{i\rightarrow k}$ is also relatively simple: $$ \begin{align}
   \frac{\partial e}{\partial w_{j\rightarrow k}} =&\
   \frac{\partial}{\partial w_{j\rightarrow k}} \frac{1}{2}(\hat{y}_i -
   y_i)^2\\ =&\ (\hat{y}_i-y_i)\left( \frac{\partial}{\partial
   w_{j\rightarrow k}} (w_{k\rightarrow o}\cdot\sigma(w_{j\rightarrow
   k}\cdot z_j) - y_i) \right)\\ =&\ (\hat{y}_i-y_i)(w_{k\rightarrow
   o})\left( \frac{\partial}{\partial w_{j\rightarrow k}}
   \sigma(w_{j\rightarrow k}\cdot z_j) \right)\\ =&\
   (\hat{y}_i-y_i)(w_{k\rightarrow o})\left( \sigma(s_k)(1-\sigma(s_k))
   \frac{\partial }{\partial w_{j\rightarrow k}}(w_{j\rightarrow k}\cdot
   z_j) \right)\\ =&\
   \color{blue}{(\hat{y}_i-y_i)}\color{red}{(w_{k\rightarrow o})\left(
   \sigma(s_k)(1-\sigma(s_k)\right)}(z_j) \end{align} $$ again, finding
   the weight update for $w_{i\rightarrow j}$ consists of some
   straightforward calculus: $$ \begin{align} \frac{\partial e}{\partial
   w_{i\rightarrow j}} =&\ \frac{\partial}{\partial w_{i\rightarrow j}}
   \frac{1}{2}(\hat{y}_i-y_i)^2\\ =&\ (\hat{y}_i-y_i)\left(
   \frac{\partial}{\partial w_{i\rightarrow j}} (\hat{y}_i-y_i) \right)\\
   =&\ (\hat{y}_i-y_i)(w_{k\rightarrow o})\left( \frac{\partial}{\partial
   w_{i\rightarrow j}}\cdot\sigma(w_{j\rightarrow
   k}\cdot\sigma(w_{i\rightarrow j}\cdot x_i))\right)\\ =&\
   (\hat{y}_i-y_i)(w_{k\rightarrow
   o})(\sigma(s_k)(1-\sigma(s_k)))(w_{j\rightarrow k})\left(
   \frac{\partial}{\partial w_{i\rightarrow j}}\sigma(w_{i\rightarrow
   j}\cdot x_i) \right)\\ =&\
   \color{blue}{(\hat{y}_i-y_i)}\color{red}{(w_{k\rightarrow
   o})(\sigma(s_k)(1-\sigma(s_k)))}\color{olivegreen}{(w_{j\rightarrow
   k})(\sigma(s_j)(1-\sigma(s_j)))}(x_i) \end{align} $$
   by now, you should be seeing a pattern emerging, a pattern that
   hopefully we could encode with id26. we are reusing multiple
   values as we compute the updates for weights that appear earlier and
   earlier in the network. specifically, we see the derivative of the
   network error, the weighted derivative of unit $k$'s output with
   respect to $s_k$, and the weighted derivative of unit $j$'s output with
   respect to $s_j$.
   so, in summary, for this simple network, we have: $$ \begin{align}
   \delta w_{i\rightarrow j} =&\ -\eta\left[
   \color{blue}{(\hat{y}_i-y_i)}\color{red}{(w_{k\rightarrow
   o})(\sigma(s_k)(1-\sigma(s_k)))}\color{olivegreen}{(w_{j\rightarrow
   k})(\sigma(s_j)(1-\sigma(s_j)))}(x_i) \right]\\ \delta w_{j\rightarrow
   k} =&\ -\eta\left[
   \color{blue}{(\hat{y}_i-y_i)}\color{red}{(w_{k\rightarrow o})\left(
   \sigma(s_k)(1-\sigma(s_k)\right)}(z_j)\right]\\ \delta w_{k\rightarrow
   o} =&\ -\eta\left[ \color{blue}{(\hat{y_i} - y_i)}(z_k)\right]
   \end{align} $$

   case 2: handling multiple inputs

   consider the more complicated network, where a unit may have more than
   one input:
   what happens to a weight when it leads to a unit that has multiple
   inputs? is $w_{i\rightarrow k}$'s update rule affected by
   $w_{j\rightarrow k}$'s update rule? to see, let's derive the update for
   $w_{i\rightarrow k}$ by hand: $$ \begin{align} \frac{\partial
   e}{w_{i\rightarrow k}} =& \frac{\partial}{w_{i\rightarrow
   k}}\frac{1}{2}(\hat{y}_i - y_i)^2\\ =&\ (\hat{y}_i - y_i)\left(
   \frac{\partial}{w_{i\rightarrow k}}z_k w_{k\rightarrow o} \right)\\ =&\
   (\hat{y}_i - y_i)(w_{k\rightarrow o})\left(
   \frac{\partial}{w_{i\rightarrow k}}\sigma\left( s_k \right) \right)\\
   =&\ (\hat{y}_i - y_i)(\sigma(s_k)(1-\sigma(s_k)) w_{k\rightarrow
   o})\left( \frac{\partial}{w_{i\rightarrow k}}\left( z_iw_{i\rightarrow
   k} + z_jw_{j\rightarrow k} \right) \right)\\ =&\ (\hat{y}_i -
   y_i)(\sigma(s_k)(1-\sigma(s_k)) w_{k\rightarrow o})z_i \end{align} $$
   here we see that the update for $w_{i\rightarrow k}$ does not depend on
   $w_{j\rightarrow k}$'s derivative, leading to our first rule: the
   derivative for a weight is not dependent on the derivatives of any of
   the other weights in the same layer. thus we can update weights in the
   same layer in isolation. there is a natural ordering of the updates -
   they only depend on the values of other weights in the same layer, and
   (as we shall see), the derivatives of weights further in the network.
   this ordering is good news for the id26 algorithm.

   case 3: handling multiple outputs

   now let's examine the case where a hidden unit has more than one
   output.
   based on the previous sections, the only "new" type of weight update is
   the derivative of $w_{in\rightarrow j}$. the difference in the multiple
   output case is that unit $i$ has more than one immediate successor, so
   (spoiler!) we must sum the error accumulated along all paths that are
   rooted at unit $i$. let's explicitly derive the weight update for
   $w_{in\rightarrow i}$ (to keep track of what's going on, we define
   $\sigma_i(\cdot)$ as the activation function for unit $i$): $$
   \begin{align} \frac{\partial e}{w_{in\rightarrow i}} =&
   \frac{\partial}{w_{in\rightarrow i}}\frac{1}{2}(\hat{y}_i - y_i)^2\\
   =&\ (\hat{y}_i - y_i)\left( \frac{\partial}{w_{in\rightarrow i}}(z_j
   w_{j\rightarrow o} + z_k w_{k\rightarrow o}) \right)\\ =&\ (\hat{y}_i -
   y_i)\left( \frac{\partial}{w_{in\rightarrow i}}(\sigma_j(s_j)
   w_{j\rightarrow o} + \sigma_k(s_k)w_{k\rightarrow o}) \right)\\ =&\
   (\hat{y}_i - y_i)\left( w_{j\rightarrow o}\sigma_j'(s_j)
   \frac{\partial}{w_{in\rightarrow i}}s_j + w_{k\rightarrow
   o}\sigma_k'(s_k) \frac{\partial}{w_{in\rightarrow i}}s_k \right)\\ =&\
   (\hat{y}_i - y_i)\left( w_{j\rightarrow o}\sigma_j'(s_j)
   \frac{\partial}{w_{in\rightarrow i}}z_iw_{i\rightarrow j} +
   w_{k\rightarrow o}\sigma_k'(s_k) \frac{\partial}{w_{in\rightarrow
   i}}z_iw_{i\rightarrow k} \right)\\ =&\ (\hat{y}_i - y_i)\left(
   w_{j\rightarrow o}\sigma_j'(s_j) \frac{\partial}{w_{in\rightarrow
   i}}\sigma_i(s_i)w_{i\rightarrow j} + w_{k\rightarrow o}\sigma_k'(s_k)
   \frac{\partial}{w_{in\rightarrow i}}\sigma_i(s_i)w_{i\rightarrow k}
   \right)\\ =&\ (\hat{y}_i - y_i)\left( w_{j\rightarrow o}\sigma_j'(s_j)
   w_{i\rightarrow j}\sigma'_i(s_i)\frac{\partial}{w_{in\rightarrow i}}s_i
   + w_{k\rightarrow o}\sigma_k'(s_k) w_{i\rightarrow k}\sigma'_i(s_i)
   \frac{\partial}{w_{in\rightarrow i}}s_i \right)\\ =&\ (\hat{y}_i -
   y_i)\left( w_{j\rightarrow o}\sigma_j'(s_j) w_{i\rightarrow
   j}\sigma'_i(s_i) + w_{k\rightarrow o}\sigma_k'(s_k) w_{i\rightarrow
   k}\sigma'_i(s_i) \right)x_i \end{align} $$
   there are two things to note here. the first, and most relevant, is our
   second derived rule: the weight update for a weight leading to a unit
   with multiple outputs is dependent on derivatives that reside on both
   paths.
   but more generally, and more importantly, we begin to see the relation
   between id26 and forward propagation. during
   id26, we compute the error of the output. we then pass the
   error backward and weight it along each edge. when we come to a unit,
   we multiply the weighted backpropagated error by the unit's derivative.
   we then continue backpropagating this error in the same fashion, all
   the way to the input. id26, much like forward propagation,
   is a recursive algorithm. in the next section, i introduce the notion
   of an error signal, which allows us to rewrite our weight updates in a
   compact form.

error signals

   deriving all of the weight updates by hand is intractable, especially
   if we have hundreds of units and many layers. but we saw a pattern
   emerge in the last few sections - the error is propagated backwards
   through the network. in this section, we define the error signal, which
   is simply the accumulated error at each unit. for now, let's just
   consider the contribution of a single training instance (so we use
   $\hat{y}$ instead of $\hat{y}_i$).
   we define the recursive error signal at unit $j$ as: $$ \begin{align}
   \delta_j =&\ \frac{\partial e}{\partial s_j} \end{align} $$ in layman's
   terms, it is a measure of how much the network error varies with the
   input to unit $j$. using the error signal has some nice properties -
   namely, we can rewrite id26 in a more compact form. to see
   this, let's expand $\delta_j$: $$ \begin{align} \delta_j =&\
   \frac{\partial e}{\partial s_j}\\ =&\ \frac{\partial}{\partial
   s_j}\frac{1}{2}(\hat{y} - y)^2\\ =&\ (\hat{y} - y)\frac{\partial
   \hat{y}}{\partial s_j} \end{align} $$ consider the case where unit $j$
   is an output node. this means that $\hat{y} = f_j(s_j)$ (if unit $j$'s
   activation function is $f_j(\cdot)$), so $\frac{\partial
   \hat{y}}{\partial s_j}$ is simply $f_j'(s_j)$, giving us $\delta_j =
   (\hat{y} - y)f'_j(s_j)$.
   otherwise, unit $j$ is a hidden node that leads to another layer of
   nodes $k\in \text{outs}(j)$. we can expand $\frac{\partial
   \hat{y}}{\partial s_j}$ further, using the chain rule: $$ \begin{align}
   \frac{\partial \hat{y}}{\partial s_j} =&\ \frac{\partial
   \hat{y}}{\partial z_j}\frac{\partial z_j}{\partial s_j}\\ =&\
   \frac{\partial \hat{y}}{\partial z_j}f_j'(s_j) \end{align} $$ take note
   of the term $\frac{\partial \hat{y}}{\partial z_j}$. multiple units
   depend on $z_j$, specifically, all of the units $k\in\text{outs}(j)$.
   we saw in the section on multiple outputs that a weight that leads to a
   unit with multiple outputs does have an effect on those output units.
   but for each unit $k$, we have $s_k = z_jw_{j\rightarrow k}$, with each
   $s_k$ not depending on any other $s_k$. therefore, we can use the chain
   rule again and sum over the output nodes $k\in\text{outs}(j)$: $$
   \begin{align} \frac{\partial \hat{y}}{\partial s_j} =&\
   f_j'(s_j)\sum_{k\in\text{outs}(j)} \frac{\partial \hat{y}}{\partial
   s_k}\frac{\partial s_k}{\partial z_j}\\ =&\
   f_j'(s_j)\sum_{k\in\text{outs}(j)} \frac{\partial \hat{y}}{\partial
   s_k}w_{j\rightarrow k} \end{align} $$ plugging this equation back into
   the function $\delta_j = (\hat{y} - y) \frac{\partial \hat{y}}{\partial
   s_j}$, we get: $$ \begin{align} \delta_j =& (\hat{y} -
   y)f_j'(s_j)\sum_{k\in\text{outs}(j)} \frac{\partial \hat{y}}{\partial
   s_k}w_{j\rightarrow k} \end{align} $$ based on our definition of the
   error signal, we know that $\delta_k = (\hat{y} - y) \frac{\partial
   \hat{y}}{\partial s_k}$, so if we push $(\hat{y} - y)$ into the
   summation, we get the following recursive relation: $$ \begin{align}
   \delta_j =& f_j'(s_j)\sum_{k\in\text{outs}(j)} \delta_k w_{j\rightarrow
   k} \end{align} $$ we now have a compact representation of the
   backpropagated error. the last thing to do is tie everything together
   with a general algorithm.

the general form of id26

   recall the simple network from the first section:
   we can use the definition of $\delta_i$ to derive the values of all the
   error signals in the network: $$ \begin{align} \delta_o =&\ (\hat{y} -
   y) \text{ (the derivative of a linear function is 1)}\\ \delta_k =&\
   \delta_o w_{k\rightarrow o}\sigma(s_k)(1 - \sigma(s_k))\\ \delta_j =&\
   \delta_k w_{j\rightarrow k}\sigma(s_j)(1 - \sigma(s_j)) \end{align} $$
   also remember that the explicit weight updates for this network were of
   the form: $$ \begin{align} \delta w_{i\rightarrow j} =&\ -\eta\left[
   \color{blue}{(\hat{y}_i-y_i)}\color{red}{(w_{k\rightarrow
   o})(\sigma(s_k)(1-\sigma(s_k)))}\color{olivegreen}{(w_{j\rightarrow
   k})(\sigma(s_j)(1-\sigma(s_j)))}(x_i) \right]\\ \delta w_{j\rightarrow
   k} =&\ -\eta\left[
   \color{blue}{(\hat{y}_i-y_i)}\color{red}{(w_{k\rightarrow o})\left(
   \sigma(s_k)(1-\sigma(s_k)\right)}(z_j)\right]\\ \delta w_{k\rightarrow
   o} =&\ -\eta\left[ \color{blue}{(\hat{y_i} - y_i)}(z_k)\right]
   \end{align} $$ by substituting each of the error signals, we get: $$
   \begin{align} \delta w_{k\rightarrow o} =&\ -\eta \delta_o z_k\\ \delta
   w_{j\rightarrow k} =&\ -\eta \delta_kz_j\\ \delta w_{i\rightarrow j}
   =&\ -\eta \delta_jx_i \end{align} $$ as another example, let's look at
   the more complicated network from the section on handling multiple
   outputs:
   we can again derive all of the error signals: $$ \begin{align} \delta_o
   =&\ (\hat{y} - y)\\ \delta_k =&\ \delta_o w_{k\rightarrow
   o}\sigma(s_k)(1 - \sigma(s_k))\\ \delta_j =&\ \delta_o w_{j\rightarrow
   o}\sigma(s_j)(1 - \sigma(s_j))\\ \delta_i =&\ \sigma(s_i)(1 -
   \sigma(s_i))\sum_{k\in\text{outs}(i)}\delta_k w_{i\rightarrow k}
   \end{align} $$ although we did not derive all of these weight updates
   by hand, by using the error signals, the weight updates become (and you
   can check this by hand, if you'd like): $$ \begin{align} \delta
   w_{k\rightarrow o} =&\ -\eta \delta_o z_k\\ \delta w_{j\rightarrow o}
   =&\ -\eta \delta_o z_j\\ \delta w_{i\rightarrow k} =&\ -\eta \delta_k
   z_i\\ \delta w_{i\rightarrow j} =&\ -\eta \delta_j z_i\\ \delta
   w_{in\rightarrow i} =&\ -\eta \delta_i x_i \end{align} $$ it should be
   clear by now that we've derived a general form of the weight updates,
   which is simply $\delta w_{i\rightarrow j} = -\eta \delta_j z_i$.
   the last thing to consider is the case where we use a minibatch of
   instances to compute the gradient. because we treat each $y_i$ as
   independent, we sum over all training instances to compute the full
   update for a weight (we typically scale by the minibatch size $n$ so
   that steps are not sensitive to the magnitude of $n$). for each
   separate training instance $y_i$, we add a superscript $(y_i)$ to the
   values that change for each training example: $$ \begin{align} \delta
   w_{i\rightarrow j} =&\ -\frac{\eta}{n} \sum_{y_i}
   \delta_j^{(y_i)}z_i^{(y_i)} \end{align} $$ thus, the general form of
   the id26 algorithm for updating the weights consists the
   following steps:
    1. feed the training instances forward through the network, and record
       each $s_j^{(y_i)}$ and $z_{j}^{(y_i)}$.
    2. calculate the error signal $\delta_j^{(y_i)}$ for all units $j$ and
       each training example $y_{i}$. if $j$ is an output node, then
       $\delta_j^{(y_i)} = f'_j(s_j^{(y_i)})(\hat{y}_i - y_i)$. if $j$ is
       not an output node, then $\delta_j^{(y_i)} =
       f'_j(s_j^{(y_i)})\sum_{k\in\text{outs}(j)}\delta_k^{(y_i)}
       w_{j\rightarrow k}$.
    3. update the weights with the rule $\delta w_{i\rightarrow j}
       =-\frac{\eta}{n} \sum_{y_i} \delta_j^{(y_i)}z_i^{(y_i)}$.

conclusions

   hopefully you've gained a full understanding of the id26
   algorithm with this derivation. although we've fully derived the
   general id26 algorithm in this chapter, it's still not in a
   form amenable to programming or scaling up. in the next post, i will go
   over the matrix form of id26, along with a working example
   that trains a basic neural network on mnist.


   tags: [26]id26, [27]machine learning, [28]tutorial

   [29]prev / [30]next

references

   1. http://www.briandolhansky.com/blog?format=rss
   2. http://www.briandolhansky.com/
   3. http://www.briandolhansky.com/blog
   4. http://www.briandolhansky.com/research
   5. http://www.briandolhansky.com/cv-online
   6. http://www.briandolhansky.com/photography
   7. http://www.briandolhansky.com/arches
   8. http://www.briandolhansky.com/berlin
   9. http://www.briandolhansky.com/lindau
  10. http://www.briandolhansky.com/munich
  11. http://www.briandolhansky.com/people-taking-pictures
  12. http://www.briandolhansky.com/
  13. http://www.briandolhansky.com/
  14. http://www.briandolhansky.com/blog
  15. http://www.briandolhansky.com/research
  16. http://www.briandolhansky.com/cv-online
  17. http://www.briandolhansky.com/arches
  18. http://www.briandolhansky.com/berlin
  19. http://www.briandolhansky.com/lindau
  20. http://www.briandolhansky.com/munich
  21. http://www.briandolhansky.com/people-taking-pictures
  22. http://www.briandolhansky.com/blog/2013/9/27/artificial-neural-networks-id26-part-4
  23. http://www.briandolhansky.com/blog/2013/9/27/artificial-neural-networks-id26-part-4
  24. http://www.briandolhansky.com/blog?category=ml primers
  25. http://www.briandolhansky.com/blog?category=neural networks
  26. http://www.briandolhansky.com/blog?tag=id26#show-archive
  27. http://www.briandolhansky.com/blog?tag=machine+learning#show-archive
  28. http://www.briandolhansky.com/blog?tag=tutorial#show-archive
  29. http://www.briandolhansky.com/blog/2014/10/30/artificial-neural-networks-matrix-form-part-5
  30. http://www.briandolhansky.com/blog/2014/9/16/linux-snippets-sorting-a-file-ignoring-the-header
