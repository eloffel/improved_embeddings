   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

   [1*q_gynfvmn1xaprmpvrltra.jpeg]

how do we    train    neural networks ?

   [16]go to the profile of vitaly bushaev
   [17]vitaly bushaev (button) blockedunblock (button) followfollowing
   nov 27, 2017

i. introduction

   this is part 1 of my planned series on optimization algorithms used for
      training    in machine learning and neural networks in particular. in
   this post i cover id119(gd) and its small variations. in the
   future i plan to write about some other popular algorithms such as:
    1. [18]sgd with momentum.
    2. [19]rmsprop.
    3. [20]adam.
    4. genetic algorithm.

   i   ll put links above as finish writing about them.

   today i   ll start off with very brief introduction of neural networks
   just enough to understand concepts i will be talking about. i   ll
   explain what a id168 is and what it means to    train    neural
   network or any other machine learning model. i do not claim my
   explanation to be full, deep introduction to neural networks and, in
   fact, hope that you   re already familiar with these concepts. if you
   want a better understanding of what is going on in neural networks i
   provide a list of resources to learn at the end of my post.

   i will be explaining everything on the example of dogs vs. cats
   competition which ran several years ago on [21]kaggle. in the
   competition we   re faced with a task of recognizing whether a dog or a
   cat is appearing on a given image.

ii. let   s define a neural network

   id158s(ann) were inspired by what is actually going
   on in your brain. and while these analogies are pretty loose, anns have
   several similarities with their biological    parent   . they consist of
   some number of neurons. so let   s take a look at a single neuron.
   [1*_ee6hqf_6xtpmld9jkorww.png]
   single id88.

   we   re going to consider a little bit modified version of the simplest
   model of a neuron proposed by frank rosenblatt in 1957 called
      id88   . all modifications i make are for the sake of simplicity,
   because i   m not going for a deep explanation of a neural nets. i   m only
   trying to give you an intuition of what is going on.

   so what is a neuron ? it is a mathematical function. it takes several
   numbers as inputs(as many as you want). the neuron i drew above takes
   two numbers as input. each input number we   re going to denote as x   
   where k stands for index of input. for each input x    neuron assigns
   another number w   . a vector consisting of these numbers w    is called
   weights vector. these weights are what makes each neuron unique. they
   are fixed during testing, but during training these are the numbers
   we   re going to change in order to    tune    our network. i   ll talk about
   it later in the post. as i said above, a neuron is a function. but what
   kind of function is that ? it   s a linear combination of weights and
   inputs with some kind of non-linear function on top of it. let me
   explain further. let   s look at the first part         linear part.
   [1*itywcnax8bs_voakxp-lzw.png]
   linear combination of weight and inputs.

   the formula above is what i mean by linear combination. we   re going to
   take inputs, multiply them by corresponding weights and sum everything
   together. the result of that is a number. the last part         is to apply
   some kind non-linear function on top of it. the most popular
   non-linearity that is used today is actually even easier than linear
   function called rectified linear unit (relu). the formula is the
   following:
   [1*qt26gc55ksvy_verjgu2jw.png]
   rectified linear unit formula.

   if our number is greater than zeros then we   re going to take that
   number as is, if it   s less than zero then we   ll take zero instead. this
   non-linear function applied on top linear in neuron is called
   activation function. the reason we have to have some kind of non-linear
   function will be apparent later. to sum up, the neuron is a function
   that takes some fixed number of inputs and outputs a single
   number         its activation. our final formula for the neuron that is drown
   above is:
   [1*wtukasusyyzfw6gbchhc4g.png]
   neuron that takes two numbers as input.

   getting a little bit ahead of myself, if we take dogs vs. cats as an
   example, we   re going to passing our images as inputs to neurons. you
   might be wondering how can we pass an image when i defined a neuron to
   be a function. you should remember, that the way we store images in a
   computer is by representing it as an array of numbers, each number
   indicating the brightness of a given pixel. so, the way to pass it to a
   neuron is to take that 2d array(or 3d in case of colored images),
   flatten it in a row to get a 1d vector and pass all those number to a
   neuron. unfortunately, it makes our network dependent on image size in
   a way that we   re only going to be able to process images of a given
   size defined by the network. modern neural networks have found the to
   deal with this problem, but for now we   re going to have that
   restriction.

   it   s time to define a neural network. a neural network is also a
   mathematical function. it is defined by a bunch of neurons connected to
   each other. and when i say connected, i mean that the output from one
   neuron is used as an input to other neurons. let   s take a look at a
   very simple neural network and hope it will make it clearer.
   [1*xa9zspisrkcjn7px_gcknq.png]
   simple neural network.

   the network, defined above, has 5 neuron. as you can see these neurons
   are stacked in 3 fully connected layers, that is each neuron from one
   layer is connected to each neuron from the following layer. how many
   layers you have in a network, how many neuron in each layer and how
   they are connected         all these choices define an architecture of the
   network. first layer, consisting of 2 neurons, is called an input
   layer. the neuron in this layer are not in fact neurons as i described
   them earlier, in a sense that they don   t perform any computations. they
   are only there to denote for the input of the network. the need for
   non-linearity comes from the fact, that we connect neurons together and
   the fact the linear function on top of linear function is itself a
   linear function. so, if didn   t have non-linear function applied in each
   neuron, the neural network would be a linear function, thus not more
   powerful than a single neuron. the last thing to note, is that we
   usually want a number between 0 and 1 as an output from out neural
   network so that we treat is as a id203. for example, in
   dogs-vs-cats we could treat a number close to zero as a cat, and a
   number close to one as a dog. to accomplish that we   re going to apply a
   different activation function to our last neuron. we   re going to be
   using a [22]sigmoid activation. the only thing you need to know about
   this function is that it returns a number from 0 to 1, exactly what we
   want. having said all that, we   re ready to define a function
   corresponding to the network i drew above:
   [1*kgeb8wz6tppsktbgdykbjq.png]
   function, defining out neural network. superscript of w denoted to the
   index of the neuron. subscript of w denotes the index of input.

   as a result, we have some kind of function, that takes some numbers and
   outputs another number between 0 and 1. it is actually not so important
   what formula this function has, what important is that we have complex
   non-linear function parametrized by some weights in a sense that we can
   change that function by changing the weights.

iii. id168

   the only thing left to define before i start talking about training is
   a id168. id168 is a function that tells us, how good
   our neural network for a certain task. the intuitive way to do it is,
   take each training example, pass through the network to get the number,
   subtract it from the actual number we wanted to get and square it
   (because negative numbers are just as bad as positives).
   [1*7-5e7fstfzukidjhpykzrw.png]

   where y stands for the number we want to get from the network, y with a
   hat         the number we actually got by passing our example through the
   network, i         index of a training example. let   s take again dogs-vs-cats
   for example. we have a dataset of pictures of dogs and cats labeled one
   if it is a dog, or zero if it is a cat. this label corresponds to
   y         it   s the number we want to get from network, when passing our image
   to it. to compute the id168 we would go over each training
   example in our dataset, compute y for that example, and then compute
   the function defined above. if the id168 is big then our
   network doesn   t perform very well, we want as small number as possible.
   we can rewrite this formula, changing y to the actual function of our
   network to see deeper the connection of the id168 and the
   neural network.

iv. training

   when we start off with our neural network we initialize our weights
   randomly. obviously, it won   t give you very good results. in the
   process of training, we want to start with a bad performing neural
   network and wind up with network with high accuracy. in terms of loss
   function, we want our id168 to much lower in the end of
   training. improving the network is possible, because we can change its
   function by adjusting weights. we want to find another function that
   performs better than the initial one.

   the problem of training is equivalent to the problem of minimizing the
   id168. why minimize loss instead of maximizing? turns out loss
   is much easier function to optimize.

   there are a lot of algorithms that optimize functions. these algorithms
   can gradient-based or not, in sense that they are not only using the
   information provided by the function, but also by its gradient. one of
   the simplest gradient-based algorithms         the one i   ll be covering in
   this post         is called stochastic id119. let   s see how it
   works.

   first, we need to remember what a derivative is with respect to some
   variable. let   s take some easy function f(x) = x. if we remember the
   rules of calculus from high school we know, that the derivative of that
   is one at every value of x. what does it tell us ? the derivative is
   the rate of how fast our function is changing when we take infinitely
   small step in the positive direction. mathematically it can be written
   as the following:
   [1*min73xthqsqqtnh-o9rpwg.png]

   which means: how much our function changes(left term) approximately
   equals to derivative of that function with respect to some variable x
   multiplied with how much we changed that variable. that approximation
   is going to be exact when we step we take is infinitely small and this
   is very important concept of the derivative. going back to our simple
   function f(x) = x, we said that our derivative is 1, which means, that
   if take some step epsilon in the positive direction, the function
   outputs will change by 1 multiplied by our step epsilon which is just
   epsilon. it   s really easy to check that that   s rule. that   s actually
   not even an approximation, that   s exact. why ? because our derivative
   is the same for every value of x. that is not true for most functions.
   let   s look at a slightly more complex function f(x) = x  .
   [1*y3m-afnebxe-yods5pcmxq.png]
   y = x  

   from rules of calculus we know, that the derivative of that functions
   is 2x. it   s easy to check that now if we start at some value of x and
   make some step epsilon, then how much our function changed is not going
   to be exactly equal to the formula given above.

   now, gradient is vector of partial derivatives, whose elements contains
   derivatives with respect to some variable on which function is
   dependent. with simple functions we   ve considering so far, this vector
   only contains one element, because we   ve only been using function which
   take one input. with more complex functions(like our id168),
   the gradient will contain derivatives with respect to each variable we
   want.

   how can we use this information, provided for us by derivatives, in
   order to minimize some function ? let   s go back to our function f(x) =
   x  . obviously, the minimum of that function is at point x = 0, but how
   would a computer know it ? suppose, we start off with some random value
   of x and this value is 2. the derivative of the function in that in x =
   2 equals 4. which means that is we take a step in positive direction
   our function will change proportionally to 4. so it will increase.
   instead, we want to minimize our function, so we can take a step in
   opposite direction, negative, to be sure that our function will
   decrease, at least a little bit. how big of a step we can take ? well,
   that   s the bad news. our derivative only guarantees that the function
   will decrease if take infinitely small step. we can   t do that.
   generally, you want to control how big of step you make with some kind
   of hyper-parameter. this hyper-parameter is called learning rate and
   i   ll talk about it later. let   s now see what happens if we start at a
   point x = -2. the derivative is now equals -4, which means, that if
   take a small step in positive direction our function will change
   proportionally to -4, thus it will decrease. that   s exactly what we
   want.

   have noticed a pattern here ? when x > 0, our derivative greater than
   zero and we need to go in negative direction, when x < 0, the
   derivative less than zero, we need to go in positive direction. we
   always need to take a step in the direction which is opposite of
   derivative. let   s apply the same idea to gradient. gradient is vector
   which points to some direction in space. it actually point to the
   direction of the steepest increase of the function. since we want
   minimize our function, we   ll take a step in the opposite direction of
   gradient. let   s apply our idea. in neural network we think of inputs x,
   and outputs y as fixed numbers. the variable with respect to which
   we   re going to be taking our derivatives are weights w, since these are
   the values we want to change to improve our network. if we compute the
   gradient of the id168 w.r.t our weights and take small steps in
   the opposite direction of gradient our loss will gradually decrease
   until it converges to some local minima. this algorithms is called
   id119. the rule for updating weights on each iteration of
   id119 is the following:
   [1*y5w2jikkl-vltb_k3gxm3g.png]
   for each weight subtract the derivative with respect to it, multiplied
   by learning rate.

   lr in the notation above means learning rate. it   s there to control how
   big of a step we   re taking each iteration. it is the most important
   hyper-parameter to tune when training neural networks. if you choose
   learning that is too big, then you   ll make steps that are too large and
   will    jump over    the minimum. which means that your algorithms will
   diverge. if you choose learning rate that is too small, it might take
   too much time to converge to some local minima. people have developed
   some very good techniques for finding an optimal learning rate, but
   this goes beyond the scope of this post. some of them are described in
   my other post [23]   improving the way we work with learning rate   .

   unfortunately, we can   t really apply this algorithm for training neural
   networks and the reason lies in our formula for the id168.

   as you can see from what we defined above, our formula is the average
   over the sum. from calculus we know, that derivative of the sum is the
   sum of the derivatives. therefore, in order to compute the derivatives
   of the loss, we need to go through each example of our dataset. it
   would be very inefficient to do it every iteration of the gradient
   descent, because each iteration of the algorithm only improves our loss
   by some small step. to solve this problem, there   s another algorithm,
   called mini-batch id119. the rule for updating the weights
   stays the same, but we   re not going to be calculating the exact
   derivative. instead, we   ll approximate the derivate on some small
   mini-batch of the dataset and use that derivative to update the
   weights. mini-batch isn   t guaranteed to take steps in optimal
   direction. in fact, it usually won   t. with id119, if choose
   small enough learning rate, your loss is guaranteed to decrease every
   iteration. with mini-batch that   s not true. your loss will decrease
   over time, but it will fluctuate and be much more    noisy   .

   the size of the batch to use for estimating the derivatives is another
   hyper-parameter that you   ll have to choose. usually, you want as big
   batch size as your memory can handle. but i   ve rarely seen people use
   batch size much larger than around 100.

   extreme version of mini-batch id119 with batch size equals
   to 1 is called stochastic id119. in moder literature and
   very commonly, when people say stochastic id119(sgd) they
   actually refer to mini-batch id119. most deep learning
   frameworks will let you choose batch size for sgd.

   that   s it on id119 and its variations. recently, more and
   more people have been using more advanced algorithms. most of them are
   gradient-based and actually based on sgd with slight modifications. i   m
   planning on writing about those as well.

vii. id26

   the only thing left to say about gradient-based algorithms is how we
   compute gradient. the most fast method for calculating would be
   analytically find the derivative for each neural network architecture.
   i guess, i shouldn   t event say that this is an insane idea, when it
   comes to neural networks. the formula we defined above for a very
   simple neural network was hard enough to get stuck trying to find all
   the derivatives and we only had 6 parameters. modern architectures have
   millions of them.

   the second way to go about it, and, in fact, the easiest to implement,
   is to approximate the derivative with the following formula we know
   from calculus:
   [1*uicbjo_c_fkh3nsj4zxrha.png]

   while it is super easy to implement, it   s way too much computationally
   expensive to do so.

   the final way to calculate the derivatives, which gives a good balance
   on how hard it is and how computationally expensive it is, is called
   id26. discussing this algorithm goes beyond the scope of
   this post, but if you want to learn more about it, go to last section
   of this post where i list number of recourses to learn more about
   neural networks.

vi. why will it work ?

   when i first learned about neural networks and how they worked, i
   understood all the equations, but i wasn   t quite sure why they worked.
   the idea that we can take some function, then take some derivatives and
   end up with algorithm that can tell a dog from a cat on an image seemed
   a bit surreal to me. why i can   t give you a really good intuition on
   why neural nets work so well, there are some aspects you should note.
    1. any problem we solve with neural networks has to be expressed in
       some mathematical way. for dogs and cats it   s the following: we
       need to find a functions, which takes all the numbers from an image
       and outputs a id203 of it being a dog. you can actually
       define any classification problem this way.
    2. it might not be clear, why there is such a function that can tell a
       dog from a cat on a given image. and the idea here is that, as long
       as you have some dataset with inputs and labels, there   s always
       going to be a function that works really well on a given dataset.
       the problem is that function is going to be incredibly complex. and
       neural networks come to help. there   s a    universal approximation
       theorem   , which says that neural network with just one hidden layer
       can approximate any function as good as you want. now, it   s not
       clear, why, even if we find approximation of that function, it   s
       going to be working just as good on a new dataset, the one neural
       network didn   t see during training. this is called a generalization
       problem and it   s an open research problem. the research showed that
       sgd has a    self-generalization    effect. but we still don   t
       understand that problem really well.

vii. where to learn more

   some of the resources i found really useful when learning about neural
   networks:
    1. [24]fast.ai courses provide two excellent courses on practical deep
       learning for coders and a fantastic course on computational linear
       algebra. it   s a great place to start coding neural networks as
       quick as possible while learning more on theory of neural networks
       as you go deeper in the courses.
    2. [25]neuralnetworksanddeeplearning.com book is a great online book
       about basic. theory behind neural networks. the author explains the
       math you need to know in a very good way. he also provides and
       explain the code to implement the neural network from scratch
       without using any deep learning frameworks.
    3. [26]andrew ng   s courses on deep learning course on coursera is
       excellent as well to learn more about neural networks, starting
       with very simple networks and going further to convolutional
       networks and more!
    4. [27]3blue1brown youtube channel has some great videos to help you
       with understanding deep learning and id202. they provide
       great visualizations and a very intuitive way to think about the
       math and neural networks.
    5. [28]stanford cs231n class on convolutional neural networks for
       visual recognition is a great place to learn more about deep
       learning and id98s in particular.

     * [29]machine learning
     * [30]deep learning
     * [31]neural networks
     * [32]optimization
     * [33]towards data science

   (button)
   (button)
   (button) 2.1k claps
   (button) (button) (button) 6 (button) (button)

     (button) blockedunblock (button) followfollowing
   [34]go to the profile of vitaly bushaev

[35]vitaly bushaev

   c++, python developer

     (button) follow
   [36]towards data science

[37]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 2.1k
     * (button)
     *
     *

   [38]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [39]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/edd985562b73
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/how-do-we-train-neural-networks-edd985562b73&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/how-do-we-train-neural-networks-edd985562b73&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_2roxk4yghfyy---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@bushaev?source=post_header_lockup
  17. https://towardsdatascience.com/@bushaev
  18. https://medium.com/@bushaev/stochastic-gradient-descent-with-momentum-a84097641a5d
  19. https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a
  20. https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c
  21. https://www.kaggle.com/c/dogs-vs-cats
  22. https://en.wikipedia.org/wiki/sigmoid_function
  23. https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b
  24. http://fast.ai/
  25. http://neuralnetworksanddeeplearning.com/chap1.html
  26. https://www.coursera.org/specializations/deep-learning
  27. https://www.youtube.com/channel/ucyo_jab_esufrv4b17ajtaw
  28. http://cs231n.stanford.edu/
  29. https://towardsdatascience.com/tagged/machine-learning?source=post
  30. https://towardsdatascience.com/tagged/deep-learning?source=post
  31. https://towardsdatascience.com/tagged/neural-networks?source=post
  32. https://towardsdatascience.com/tagged/optimization?source=post
  33. https://towardsdatascience.com/tagged/towards-data-science?source=post
  34. https://towardsdatascience.com/@bushaev?source=footer_card
  35. https://towardsdatascience.com/@bushaev
  36. https://towardsdatascience.com/?source=footer_card
  37. https://towardsdatascience.com/?source=footer_card
  38. https://towardsdatascience.com/
  39. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  41. https://medium.com/p/edd985562b73/share/twitter
  42. https://medium.com/p/edd985562b73/share/facebook
  43. https://medium.com/p/edd985562b73/share/twitter
  44. https://medium.com/p/edd985562b73/share/facebook
