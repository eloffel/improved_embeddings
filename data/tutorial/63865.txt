   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

the 4 deep learning breakthroughs you should know about

the first in a series on deep learning for non-experts

   [16]go to the profile of seth weidman
   [17]seth weidman (button) blockedunblock (button) followfollowing
   dec 4, 2017

why read this?

   to get started applying deep learning, either as an individual
   practitioner or as a organization, you need two things:
    1. the    what   : an idea of what the latest developments in deep
       learning are capable of.
    2. the    how   : the technical capability to either train a new model or
       take your existing model and get it working in production.

   thanks to the strength of the open source community, the second part is
   getting easier every day. there are many great tutorials on the
   specifics of how to train and use deep learning models using libraries
   such as tensorflow         many of which publications like towards data
   science publish on a weekly basis.

   the implication of this is that once you have an idea for how you   d
   like to use deep learning, implementing your idea, while not easy,
   involves standard    dev    work: following tutorials like the ones linked
   throughout this article, modifying them for your specific purpose
   and/or data, troubleshooting via reading posts on stackoverflow, and so
   on. they don   t, for example, require being (or hiring) a unicorn with
   ph.d who can code original neural net architectures from scratch and is
   an experienced software engineer.

   this series of essays will attempt to fill a gap on the first part:
   covering, at a high level, what deep learning is capable of, while
   giving resources for those of you who want to learn more and/or dive
   into the code and tackle the second part. more specifically, i   ll
   cover:
    1. what the latest achievements using open source architectures and
       datasets have been.
    2. what the key architectures or other insights were that led to those
       achievements
    3. what the best resources to get started with using similar
       techniques on your own projects.

what these breakthroughs have in common

   the breakthroughs, while they involve many new architectures and ideas,
   were all achieved using the usual    supervised learning    process from
   machine learning. specifically the steps are:
    1. collect a large set of appropriate training data
    2. set up a neural net architecture         that is, a complicated system of
       equations, loosely modeled on the brain         that often has of
       millions of parameters called    weights   .
    3. repeatedly feed the data through the neural net; at each iteration
       comparing the result of the neural net   s prediction to the correct
       result, and adjusting each of the neural net   s weights based on how
       much and in what direction it misses.

   [1*fbmyomrfr_mr8tnofi0_jw.jpeg]
   this is how neural nets are trained: this process is repeated many,
   many times. [18]source.

   this process has been applied to many different domains, and has
   resulted in neural nets that appear to have    learned   . in each domain,
   we   ll cover:
    1. the data needed to train these models
    2. the model architecture used
    3. the results

1. image classification

   neural networks can be trained to figure out what object or objects an
   image contains.

data required

   to train an image classifier, you need labeled images, where each image
   belongs to one of a number of finite classes. for example, one of the
   standard datasets used to train image classifiers is the [19]cifar 10
   data, which has correctly labelled images of 10 classes:
   [1*6woxnue8n4m9swzx67djpa.png]
   illustration of images of cifar-10 data. [20]source

deep learning architecture

   all the neural net architectures we   ll cover were motivated by thinking
   about how people would actually have to learn to solve the problem. how
   do we do this for image detection? when humans determine what is in an
   image we first would look for high-level visual features, like
   branches, noses, or wheels. in order to detect these, however, we would
   subconsciously need to determine lower level features like colors,
   lines, and other shapes. indeed, to go from raw pixels to complex
   features that humans would recognize, like eyes, we would require
   detecting features of pixels, and then features of features of pixels,
   etc.

   prior to deep learning, researchers would manually try to extract these
   features and use them for prediction. just before the advent of deep
   learning, researchers were starting to use techniques (mainly [21]id166s)
   that tried to find complex, nonlinear relationships between these
   manually-extracted features and whether an image was of a cat or dog,
   for example.
   [1*2swb6cmxzbpzijmevfbe-g.jpeg]
   convolutional neural network extracting features at each
   layer. [22]source

   now, researchers have developed neural net architectures that learn
   these features of the original pixels themselves; specifically, deep
   convolutional neural net architectures. these networks extract features
   of pixels, then features of features of pixels and so on, and then
   ultimately feed these through a regular neural net layer (similar to a
   id28) to make the final prediction.
   [1*u7s9w6r0ms2skp49aw7xjw.png]
   samples of the predictions a leading id98 architecture made on images
   from the id163 dataset.

   we   ll dive deeper into how convolutional neural nets are being used for
   image classification in a future post.

breakthroughs

   the consequence of this is that on the central task these architectures
   were designed to solve         image classification    algorithms can now
   achieve better results than humans. on the famous [23]id163 dataset,
   which is most commonly used as a benchmark for convolutional
   architectures, trained neural nets now achieve better-than-human
   performance on image classification:
   [1*zz0iymi4ph1qrr2q8tfjza.png]
   as of 2015, computers can be trained to classify objects in images
   better than humans. [24]source

   in addition, researchers have figured out how to take images not
   immediately curated for image classification, segment out rectangles of
   the image most likely to represent objects of specific classes, feed
   each of these rectangles through a id98 architecture, and end up with
   classifications of the individual objects in the image along with boxes
   bounding their location (these are called    bounding boxes   ):
   [1*rettdms6thkbk7wrrxk7rq.png]
   id164 using    mask r-id98   . [25]source

   this entire multi-step process is technically known as    [26]object
   detection   , though it uses    image classification    for the most
   challenging step.

resources

   theoretical: for a deeper look at the theory of why id98s work, read the
   tutorial from andrej karpathy   s stanford course [27]here. for a
   slightly more mathematical version, check out chris olah   s post on
   convolutions [28]here.

   code: to get started quickly building an image classifier, check out
   [29]this introductory example from the tensorflow documentation.

2. text generation

   neural networks can be trained to generate text that mimics text of a
   given type.

data required

   simply text of a given class. this could be all the works of
   shakespeare, for example.

deep learning architecture

   neural nets can model the next element in a sequence of elements. it
   can look at the past sequence of characters and, for a given set of
   past sequences, determine which character is most likely to appear
   next.

   the architecture used for this problem is different than the
   architecture used for image classification. with different
   architectures, we are asking the net to learn different things. before,
   we were asking it to learn what features of images matter. here, we are
   asking it to pay attention to a sequence of characters to predict the
   next character in a sequence. to do this, unlike with image
   classification, the net needs a way of keeping track of its    state   .
   for example, if the prior characters it has seen are    c-h-a-r-a-c-t-e   ,
   the network should    store    that information and predict that the next
   character should be    r   .

   a recurrent neural network architecture is capable of this: it feeds
   the state of each neuron back into the network during its next
   iteration, allowing it to learn sequences (there   s a lot more to it
   than this, but we   ll get into that later).
   [1*psfywcdghtueb7arpexpbg.png]
   image of a recurrent neural net architecture. [30]source.

   to really excel at text generation, however, the nets must also decide
   how far back to look in the sequence. sometimes, as in the middle of
   words, the net simply has to look at the last few characters to
   determine which character comes next, and other times it may have to
   look back many characters to determine, for example, if we are at the
   end of a sentence.

   there is a special type of cell called an    lstm    (long short term
   memory) cell that does this particularly well. each cell decides
   whether to    remember    or    forget    based on weights internal to the cell
   itself that are updated with each new character that the net sees.
   [1*egqzn0yoqfzvlmiodlar7a.png]
   the inner workings of an lstm cell. [31]source.

breakthroughs

   in short: we can generate text that looks sort of like a characature of
   the text we are trying to generate, minus a few mispelled words and
   mistakes that prevent it from being proper english. this [32]andrej
   karpathy post has some fun examples, from generating shakespeare plays
   to generating paul graham essays.

   the same architecture has been used to generate handwriting by
   sequentially generating the x and y coordinates, just as language is
   generated character by character. check out [33]this demo here.
   [1*3ylpbzvvxuutevabf4bxyg.png]
   written by a neural net. can we still call it *hand*writing? [34]source

   we   ll dive further into how recurrent neural nets and lstms work in a
   future post.

resources

   theoretical: [35]this chris olah post on lstms is a classic, as is
   [36]this post from andrej karpathy on id56s generally, what they can
   accomplish, and how they work.

   code: [37]this is a great walkthrough on how to get started building an
   end-to-end text generation model, including the preprocessing of the
   data. [38]this github repo makes it easy to generate handwriting using
   a pretrained id56-lstm model.

3. language translation

   machine translation         the ability to translate language         has long been
   a dream of ai researchers. deep learning has brought that dream much
   closer to reality.

data required

   pairs of sentences between different languages. for example, the pair
      i am a student    and    je suis   tudiant    would be one pair of sentences
   in a dataset training a neural net to translate between english and
   french.

deep learning architecture

   as with other deep learning architectures, researchers have
      hypothesized    how computers might ideally learn to translate
   languages, set up an architecture that attempts to mimic this. with
   language translation, fundamentally, a sentence (encoded as a sequence
   of words) should be translated into its underlying    meaning   . that
   meaning should then be translated into a sequence of words in the new
   language.

   the way sentences are    transformed    from words into meaning should be
   an architecture that is good at dealing with sequences         this turns out
   to be the    recurrent neural network    architecture described above.
   [1*nrcynkpg2wjltfa08w_0ig.jpeg]
   encoder-decoder architecture diagram. [39]source

   this architecture was first discovered to work well on language
   translation in [40]2014 and has since been extended in many directions,
   in particular with    attention    an idea that we   ll explore in a future
   blog post.

breakthroughs

   [41]this google blog post shows that this architecture does indeed
   accomplish what it set out to accomplish, blowing other language
   translation techniques out of the water. of course, it doesn   t hurt
   that google has access to such great training data for this task!
   [1*-h9o3jbsidxjfkico07_1w.png]
   google sequence-to-sequence based model performance. [42]source

resources

   code & theoretical: google, to their credit, has published a fantastic
   tutorial on sequence to sequence architectures [43]here. this tutorial
   both gives an overview of the goals and theory of sequence to sequence
   models and walks you through how to actually code them up in
   tensorflow. it also covers    attention   , an extension to the basic
   sequence-to-sequence architecture that i   ll cover when i discuss
   sequence-to-sequence in detail.

4. id3

   neural networks can be trained to generate images that look like images
   of a given class         images of faces, for example, that are not actual
   faces.

data required

   images of a particular class         for example, a bunch of images of faces.

deep learning architecture

   gans are a surprising and important result         [44]yann lecun, one of the
   leading ai researchers in the world, said that they are    [45]the most
   interesting idea in the last 10 years in ml, in my opinion.    it turns
   out we can generate images that look like a set of training images but
   are not actually images from that training set: images that look like
   faces but are not actually real faces, for example. this is
   accomplished via training two neural networks simultaneously: one that
   tries to generate fake images that look real and one that tries to
   detect whether the images are real or not. if you train both of these
   networks so that they learn    at the same speed            this is the hard part
   of building gans         the network that is trying to generate the fake
   images actually can generate images that look quite real.

   to go into just a bit of detail: the main network that we want to train
   with gans is called the generator: it will learn to take in a vector of
   random noise and transform it into a realistic looking image. this
   network has an    inverse    structure from a convolutional neural network,
   aptly named a    deconvolutional    architecture. the other network, that
   tries to distinguish real from fake images, is a convolutional network
   just like those used for image classification, and is called the
      discriminator   .
   [1*ntu9lt7ts3vkstehvoqaoq.png]
   deconvolutional architecture of a    generator   . [46]source
   [1*aerzoe54sbgpvf-8ihbczq.png]
   convolutional architecture of the    discriminator   . [47]source

   both neural nets in the case of gans are convolutional neural nets,
   since these neural nets are especially good at extracting features from
   images.

breakthroughs & resources

   [1*45kebpoou-mjtpnhmymb5a.png]
   images generated by a gan from a dataset of faces of celebrities.
   [48]source

   code: [49]this github repo is both a great tutorial on training gans
   using tensorflow and contains some striking images generated by gans,
   such as the one above.

   theoretical: [50]this talk by irmak sirer is a fun introduction to
   gans, as well as covering many supervised learning concepts that will
   help you understand the findings above as well.

   finally, the excellent [51]arthur juliani has another fun, visual
   explanation of gans here, along with code to implement one in
   tensorflow.

summary

   this was a high level overview of the areas where deep learning has
   generated the biggest breakthroughs over the last five years. any of
   these models we discussed has many open source implementations. that
   means that you can almost always download a    pre-trained    model and
   apply it to your data         for example, you can download pre-trained image
   classifiers that you can feed your data through to either classify new
   images or draw boxes around the objects in images. because much of this
   work has been done for you, the work necessary to use these cutting
   edge techniques is not in    doing the deep learning    itself         the
   researchers have largely figured that part out for you         but rather in
   doing the    dev    work to get the models others have developed to work
   for your problem.

   hopefully now you have a bit of a better understanding of what the
   capabilities of deep learning models are, and are a bit closer to
   actually using them!

     * [52]artificial intelligence
     * [53]deep learning
     * [54]machine learning
     * [55]data science
     * [56]towards data science

   (button)
   (button)
   (button) 1.8k claps
   (button) (button) (button) 2 (button) (button)

     (button) blockedunblock (button) followfollowing
   [57]go to the profile of seth weidman

[58]seth weidman

   senior data scientist at [59]@thisismetis. i write about the
   intersection of data science, business, education, and society.

     (button) follow
   [60]towards data science

[61]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 1.8k
     * (button)
     *
     *

   [62]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [63]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/df27674ccdf2
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/the-5-deep-learning-breakthroughs-you-should-know-about-df27674ccdf2&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/the-5-deep-learning-breakthroughs-you-should-know-about-df27674ccdf2&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_huw8kvc2v64w---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@sethweidman?source=post_header_lockup
  17. https://towardsdatascience.com/@sethweidman
  18. https://www.embedded-vision.com/platinum-members/cadence/embedded-vision-training/documents/pages/neuralnetworksimagerecognition
  19. https://www.cs.toronto.edu/~kriz/cifar.html
  20. https://becominghuman.ai/training-mxnet-part-2-cifar-10-c7b0b729c33c'
  21. https://crypto.stanford.edu/~pgolle/papers/dogcat.pdf
  22. https://www.strong.io/blog/deep-neural-networks-go-to-the-movies
  23. http://www.image-net.org/challenges/lsvrc/
  24. https://devblogs.nvidia.com/parallelforall/mocha-jl-deep-learning-julia/
  25. https://arxiv.org/pdf/1703.06870.pdf
  26. https://en.wikipedia.org/wiki/object_detection
  27. http://cs231n.github.io/convolutional-networks/
  28. http://colah.github.io/posts/2014-07-conv-nets-modular/
  29. https://www.tensorflow.org/tutorials/layers
  30. https://medium.com/@erikhallstrm/hello-world-id56-83cd7105b767
  31. http://harinisuresh.com/2016/10/09/lstms/
  32. http://karpathy.github.io/2015/05/21/id56-effectiveness/
  33. https://www.cs.toronto.edu/~graves/handwriting.cgi
  34. https://www.cs.toronto.edu/~graves/handwriting.cgi?text=handwriting&style=&bias=0.15&samples=3
  35. http://colah.github.io/posts/2015-08-understanding-lstms/
  36. http://karpathy.github.io/2015/05/21/id56-effectiveness/
  37. https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/
  38. https://github.com/snowkylin/id56-handwriting-generation
  39. https://github.com/tensorflow/id4/tree/tf-1.2
  40. https://arxiv.org/pdf/1406.1078.pdf
  41. https://research.googleblog.com/2016/09/a-neural-network-for-machine.html
  42. https://research.googleblog.com/2016/09/a-neural-network-for-machine.html
  43. https://github.com/tensorflow/id4/tree/tf-1.2
  44. https://en.wikipedia.org/wiki/yann_lecun
  45. https://www.quora.com/session/yann-lecun/1
  46. https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39
  47. https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39
  48. https://github.com/carpedm20/dcgan-tensorflow
  49. https://github.com/carpedm20/dcgan-tensorflow
  50. https://www.youtube.com/watch?v=bzrgiphrzoe
  51. https://medium.com/@awjuliani
  52. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  53. https://towardsdatascience.com/tagged/deep-learning?source=post
  54. https://towardsdatascience.com/tagged/machine-learning?source=post
  55. https://towardsdatascience.com/tagged/data-science?source=post
  56. https://towardsdatascience.com/tagged/towards-data-science?source=post
  57. https://towardsdatascience.com/@sethweidman?source=footer_card
  58. https://towardsdatascience.com/@sethweidman
  59. http://twitter.com/thisismetis
  60. https://towardsdatascience.com/?source=footer_card
  61. https://towardsdatascience.com/?source=footer_card
  62. https://towardsdatascience.com/
  63. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  65. https://medium.com/p/df27674ccdf2/share/twitter
  66. https://medium.com/p/df27674ccdf2/share/facebook
  67. https://medium.com/p/df27674ccdf2/share/twitter
  68. https://medium.com/p/df27674ccdf2/share/facebook
