   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

introduction to bayesian thinking: from id47 to bayes networks

   [16]go to the profile of felipe sanchez
   [17]felipe sanchez (button) blockedunblock (button) followfollowing
   nov 2, 2017
   [0*q6brqrnjffant36y.png]

suppose that in the world exist a very rare disease. there is only 1 in 1000
chance that you have the disease. you want to know whether you are infected
or not, so you make a 99% accurate test    the test result to be positive ! how
sure are you that you are really infected?

   how can a second test affect the belief that you are infected indeed?

   i am using here the example from the veritasium channel. in this post i
   want to show the logic under id110s. for more details in
   [18]id47 i suggest to see the video.

   iframe: [19]/media/c75836a3a44b7a2410200a6005fd45e3?postid=3da371f5134

   the first test
   [0*vvpcuhclu60sxpzy.jpg]

   since it is a very rare disease (1 in 1000 is affected) the id203
   of having the virus in your body is given by next table (called a
   id155 table):
   [1*avfele01zlvn5q5cmso-ra.png]
   virus cpt (id155 table)

   this table shows that only 1 in 1000 of people have the virus. that   s
   the same to say: 999 in 1000 are free from the virus.

   now we do a similar table for making test: this second table shows the
   accuracy of the test. that is the capacity of the test on telling the
   true. so, if you are infected the test will be true with 99% chance,
   and if you are not infected the test will show false (99% accurate too)
   in both cases the error rate is 1%
   [1*hsmcnzdjilok3h9f1zkdng.png]
   test1 cpt (id155 table)

   the next graph shows that the virus presence given the result of the
   test depends on the test (like in the the table above):
   [1*en_ebqjhqorvdtljpxboda.png]
   a simple and empty simple id110

   then, when i give the evidence that the test is true. the network shows
   me that the presence of the virus on your body, given that one test is
   positive, is only 9% !
   [1*iy5kcgt780deupfx15o_6a.png]
   the same id110 with the evidence loaded of one positive test

   why is that? this number comes from id47:
   [1*fubyopk794akrphjtfwhng.png]

   in this problem:

       (h|e) =     (h)        (e|h) /     (e)

       (h|e) =     (h)    p(e|h) / (    (e|h)        (h) +     (e|hc)        (ec) )

       (h|e) = 0,99*0,001 / (0,001*0,99 + 0,999*0,01) = 0,9 = 9%

so, even if you take a 99% accurate test, the chance of having the disease is
only 9%

   this calculations seems complicated, but once represented in graphs, we
   get a better intuition on how bayesian thinking works.
   [0*dqrhequugxprsfcj.]

   for two tests:

   what happen if you take a second test? let   s say that this new test
   also have 99% accuracy, we have the same table as the first test:
   [1*s0faqqccxxzxsdq55likag.png]
   test2 cpt (id155 table)

   the corresponding id110 will be the next one:
   [1*-gtsjq9khye9cp4yyez23g.png]
   id110 for two positive test

   that means: for two positive test the chance of having the disease
   increase to 91%. the prior experience is uploaded. this is coherent,
   the chance of having the disease jums from 9% to 91%. but it is not
   100%!

   in an another case, if the second test is negative, there is 100%
   chance of not having the disease.
   [1*fcyb0jwbpvdxw8i7xi35tw.png]
   id110 for one positive test and one negative test

   for three tests

   in the case of three tests, all with the same accuracy, we see some
   interesting results. if you have evidence that 3 test are true, now it
   is 100% certain that you are infected with the virus.
   [1*b-oed0hh01yfhi6rg8izzw.png]
   bayes network for three positive test

   but since one test is false, the result turns again, and it is only 91%
   chance of virus presence in your body:
   [1*uhrgzha84hi5m98jd5roiw.png]

   in conclusion, id110 helps us to represent the bayesian
   thinking, it can be use in data science when the amount of data to
   model is moderate, incomplete and/or uncertain. they also can use
   expert judgment to build or refine the network. they allow to
      simulate    different scenarios. they represent how input values (in
   this example virus presence and accuracy of the test) are linked to
   certain level of id203 of the output (id203 of actually
   having the disease)

   in this post i explained in how to build a id110, starting
   from the id47. i am currently working on id110s to
   predict cost and risk of projects. i want to share the basics of the
   construction of such powerful [20]ai tool.

   if you want to know a bit more about id110s:

   concerning the horizontal division between theory and data on the model
   source axis, id110s have a special characteristic. bayesian
   networks can be built from human knowledge, i.e. from theory, or they
   can be machine-learned from data. thus, they can use the entire
   spectrum as model source. also, due to their graphical structure,
   machine-learned id110s are visually interpretable, therefore
   promoting human learning and theory building.
   [1*mphf9sjq0_-v5b_7jihtzw.jpeg]

   id110s allow human learning and machine learning to work in
   tandem, i.e. id110s can be developed from a combination of
   human and artificial intelligence. beyond crossing the boundaries
   between theory and data, id110s also have special qualities
   concerning causality.

   under certain conditions and with specific theory-driven assumptions,
   id110s facilitate causal id136. in fact, bayesian
   network models can cover the entire range from association/correlation
   to causation.

   in practice, this means that we can add causal assumptions to an
   existing non-causal network and, thus, create a causal bayesian
   network. this is of particular importance when we try to simulate an
   intervention in a domain, such as estimating the effects of a
   treatment. in this context, it is imperative to work with a causal
   model, and id110s help us make that transition. source:
   [21]bayesia book

     * [22]artificial intelligence
     * [23]bayesian statistics
     * [24]bayesian machine learning
     * [25]data science
     * [26]machine learning

   (button)
   (button)
   (button) 976 claps
   (button) (button) (button) 7 (button) (button)

     (button) blockedunblock (button) followfollowing
   [27]go to the profile of felipe sanchez

[28]felipe sanchez

   engineering consultant. now working on project management and ai
   research. [29]https://www.linkedin.com/in/ingsanchezgarzon/

     (button) follow
   [30]towards data science

[31]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 976
     * (button)
     *
     *

   [32]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [33]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/3da371f5134
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/will-you-become-a-zombie-if-a-99-accuracy-test-result-positive-3da371f5134&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/will-you-become-a-zombie-if-a-99-accuracy-test-result-positive-3da371f5134&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_c3qaujmw76wm---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@fesan818181?source=post_header_lockup
  17. https://towardsdatascience.com/@fesan818181
  18. https://en.wikipedia.org/wiki/bayes'_theorem
  19. https://towardsdatascience.com/media/c75836a3a44b7a2410200a6005fd45e3?postid=3da371f5134
  20. https://medium.com/@fesan818181/from-classic-ai-techniques-to-deep-learning-753d20cf8578
  21. http://www.bayesia.com/book
  22. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  23. https://towardsdatascience.com/tagged/bayesian-statistics?source=post
  24. https://towardsdatascience.com/tagged/bayesian-machine-learning?source=post
  25. https://towardsdatascience.com/tagged/data-science?source=post
  26. https://towardsdatascience.com/tagged/machine-learning?source=post
  27. https://towardsdatascience.com/@fesan818181?source=footer_card
  28. https://towardsdatascience.com/@fesan818181
  29. https://www.linkedin.com/in/ingsanchezgarzon/
  30. https://towardsdatascience.com/?source=footer_card
  31. https://towardsdatascience.com/?source=footer_card
  32. https://towardsdatascience.com/
  33. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  35. https://medium.com/p/3da371f5134/share/twitter
  36. https://medium.com/p/3da371f5134/share/facebook
  37. https://medium.com/p/3da371f5134/share/twitter
  38. https://medium.com/p/3da371f5134/share/facebook
