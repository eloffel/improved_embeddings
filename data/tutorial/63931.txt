   #[1]accelerating convolutional neural networks on raspberry pi [2]image
   segmentation using deconvolution layer in tensorflow

   ____________________

   [3]cv-tricks.com learn machine learning, ai & id161
   [4]login

     * [5]home
     * [6]tensorflow tutorials
     * [7]about

   [8]search

   keras tensorflow tutorial

keras tutorial: practical guide from getting started to developing complex
deep neural network

   by ankit sachan
   keras is a high-level python api which can be used to quickly build and
   train neural networks using either tensorflow or theano as back-end.
   this tutorial assumes that you are slightly familiar convolutional
   neural networks. you can follow the first part of [9]convolutional
   neural network tutorial to learn more about them.
   in this quick tutorial, we shall learn following things:
   1. why keras? why is it considered to be the future of deep learning?
   2. installing keras on ubuntu: step by step installation on ubuntu
   3. keras tensorflow tutorial: fundamentals of keras
   4. understanding keras sequential model
            4.1) solve a id75 problem with example
   5. saving and restoring pre-trained models using keras
   6. keras functional api
            6.1) develop vgg convolutional neural network using functional
   api
            6.2) build and run squeezenet convolutional neural network
   using functional api

 1. why keras?

   [10]fran  ois chollet, who works at google developed keras as a wrapper
   on top of theano for quick prototyping. later this was expanded for
   tensorflow as back-end. recently, tensorflow has decided to adopt it
   and provide it as part of contrib folder in the tensorflow code.
   [11]keras is being hailed as the future of building neural networks.
   here are some of the reasons for its popularity:
    1. light-weight and quick: keras is designed to remove boilerplate
       code. few lines of keras code will achieve so much more than native
       tensorflow code. you can easily design both id98 and id56s and can
       run them on either gpu or cpu.
    2. emerging possible winner: keras is an api which runs on top of a
       back-end. this back-end could be either tensorflow or theano.
       microsoft is also working to provide cntk as a back-end to keras.
       currently, the world of neural network is very fragmented and
       evolving very fast. look at this tweet by karpathy:

   imagine the pain all of us have been enduring, of learning a new
   framework every year. as of now, it appears that tensorflow is here to
   stay and as more and more frameworks provide support to keras, it will
   become the standard.
   currently, keras is one of the fastest growing libraries for deep
   learning.
   the power of being able to run the same code with different back-end is
   a great reason for choosing keras. imagine, you read a paper which
   seems to be doing something so interesting that you want to try with
   your own dataset. let   s say you work with tensorflow and don   t know
   much about theano, then you will have to implement the paper in
   tensorflow, which obviously will take longer. now, if the code is
   written in keras all you have to do is change the back-end to
   tensorflow. this will turbo charge collaborations for the whole
   community.

2. how to install keras with tensorflow:

a) dependency:

   install h5py for saving and restoring models:
   python

   pip install h5py____________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   pip install h5py

   other python dependencies need to be installed.
   python

   pip install numpy scipy_____________________________________
   pip install pillow__________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2
   3

   pip install numpy scipy
   pip install pillow

   if you don   t have tensorflow installed, please follow this
   [12]tensorflow tutorial to install tensorflow. once, you have
   tensorflow installed, you can simply install keras using pypi:
   python

   sudo pip install keras______________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   sudo pip install keras
   checking the keras version.
   python

   >>python -c "import keras; print(keras.__version__)"________
   using tensorflow backend.___________________________________
   2.0.1_______________________________________________________
   ____________________________________________________________
   1
   2
   3
   4

   >>python -c "import keras; print(keras.__version__)"
   using tensorflow backend.
   2.0.1
   once, keras is installed, you need to specify which backend it should
   run on i.e. tensorflow or theano. this is done in a config file which
   is located at ~/.keras/keras.json. this is how it looks like:

   python

   {___________________________________________________________
       "epsilon": 1e-07,_______________________________________
       "floatx": "float32",____________________________________
       "image_data_format": "channels_last",___________________
       "backend": "tensorflow"_________________________________
   }___________________________________________________________
   1
   2
   3
   4
   5
   6
   7

   {
       "epsilon": 1e-07,
       "floatx": "float32",
       "image_data_format": "channels_last",
       "backend": "tensorflow"
   }

   note that, the value of image_data_format is    channels_last   , which is
   the correct value for tensorflow. in tensorflow, images are stored as
   tensors/arrays of shape [height, width, channels] while in theano the
   order is different [channels, height, width]. so, if you don   t have
   this parameter set correctly, your intermediate results will be very
   strange. for theano, this value will be    channels_first   .

   so, now you are ready to use keras with tensorflow.

3. keras tensorflow tutorial: fundamentals of keras

   the main data structure in keras is the model which provides a way to
   define the complete graph. you can add layers to the existing
   model/graph to build the network you want.
   python

   import keras________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   import keras
   keras has two distinct ways of building models:
    1. sequential models: this is used to implement simple models. you
       simply keep adding layers to the existing model.
    2. functional api: keras functional api is very powerful and you can
       build more complex models using it, models with multiple output,
       directed acyclic graph etc.

                                       in the next sections of this blog,
       you would understand the theory and examples of keras sequential
       model and functional api.

4. keras sequential model

   in this section, i shall cover the theory of keras sequential model. i
   shall quickly explain how it works by also showing you the code. later,
   we shall solve a id75 problem where you can run the code
   while reading.
   this is how we start by importing and building a sequential model.
   python

   from keras.models import sequential_________________________
   model = sequential()________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2
   3

   from keras.models import sequential
   model = sequential()
   we can add layers like dense(fully connected layer), activation,
   conv2d, maxpooling2d etc by calling add function.
   python

   from keras.layers import dense, activation,conv2d,maxpooling
   model.add(conv2d(64, (3, 3), activation='relu'))____________
   // this adds a convolutional layer with 64 filters of size 3
   ____________________________________________________________
   1
   2
   3
   4

   from keras.layers import dense,
   activation,conv2d,maxpooling2d,flatten,dropout
   model.add(conv2d(64, (3, 3), activation='relu'))
   // this adds a convolutional layer with 64 filters of size 3 * 3 to the
   graph
   here is how you can add some of the most popular layers to the network.
   i have already written about most of these layers in this
   [13]convolutional network tutorial:

   1. convolutional layer: here, we shall add a layer with 64 filters of
   size 3*3 and use relu activations after that.
   python

   model.add(conv2d(64, (3, 3), activation='relu'))____________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.add(conv2d(64, (3, 3), activation='relu'))
   2. maxpooling layer:  specify the type of layer and specify the pool
   size and you are done. how cool is that!
   python

   model.add(maxpooling2d(pool_size=(2, 2)))___________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.add(maxpooling2d(pool_size=(2, 2)))

   3. fully connected layer: it   s called dense in keras. just specify the
   number of outputs and you are done.
   python

   model.add(dense(256, activation='relu'))____________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.add(dense(256, activation='relu'))

   4. drop out:
   python

   model.add(dropout(0.5))_____________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.add(dropout(0.5))

   5. flattening layer:
   python

   model.add(flatten())________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.add(flatten())

taking input:

   the first layer of a network reads the training data. so, we need to
   specify the size of images/training data that we are feeding the
   network. so, the input_shape parameter is used to specify the shape of
   input data:

   python

   model.add(conv2d(32, (3, 3), activation='relu', input_shape=
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.add(conv2d(32, (3, 3), activation='relu', input_shape=(224, 224,
   3)))

   in this case, the input layer is a convolutional layer which takes
   input images of 224 * 224 * 3.
   this will help you build neural networks using sequential model. let   s
   come to the most important part. once you have specified the
   architecture of the network, you need to specify the method for
   back-propagation by choosing an optimizer( like rmsprop or adagrad) and
   specify the loss(like categorical_crossid178 ). we use compile
   function to do that in keras. for example, in this line below we are
   asking the network to use the    rmsprop    optimizer to change weights in
   such a way that the loss    binary_crossid178    is minimized at each
   iteration.
   python

   model.compile(loss='binary_crossid178',___________________
                        optimizer='rmsprop')__________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2
   3

   model.compile(loss='binary_crossid178',
                 optimizer='rmsprop')
   if you want to specify stochastic id119 and you want to
   choose proper initialization and other hyperparameters:
   python

   from keras.optimizers import sgd____________________________
   ......._____________________________________________________
   ......______________________________________________________
   sgd = sgd(lr=0.01, decay=1e-6, momentum=0.9, nesterov=true)_
   model.compile(loss='categorical_crossid178', optimizer=sgd
   1
   2
   3
   4
   5
   6

   from keras.optimizers import sgd
   .......
   ......
   sgd = sgd(lr=0.01, decay=1e-6, momentum=0.9, nesterov=true)
   model.compile(loss='categorical_crossid178', optimizer=sgd)
   now that we have created the model; let   s feed the data to the model
   via the fit function. you can also specify the batch_size and the
   maximum number of epochs you want training to go on.
   python

   model.fit(x_train, y_train, batch_size=32, epochs=10,validat
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.fit(x_train, y_train, batch_size=32,
   epochs=10,validation_data=(x_val, y_val))
   finally, let   s use the evaluate function to test the model
   python

   score = model.evaluate(x_test, y_test, batch_size=32)_______
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   score = model.evaluate(x_test, y_test, batch_size=32)
   these are the basic building blocks to use the sequential model in
   keras.  now, let   s build a simple example to implement linear
   regression using keras sequential model.

4.1 solve a id75 problem with an example

problem statement:

   in id75, you get a lot of data points and try to fit them
   on a straight line. for this example, we will create 100 data points
   and try to fit them into a line.

 a) creating training data:

   trainx has values between    1 and 1, and trainy has 3 times the trainx
   and some randomness.
   python

   import keras________________________________________________
   from keras.models import sequential_________________________
   from keras.layers import dense______________________________
   import numpy as np__________________________________________
     ___________________________________________________________
   trx = np.linspace(-1, 1, 101)_______________________________
   try = 3 * trx + np.random.randn(*trx.shape) * 0.33__________
   1
   2
   3
   4
   5
   6
   7
   8

   import keras
   from keras.models import sequential
   from keras.layers import dense
   import numpy as np

   trx = np.linspace(-1, 1, 101)
   try = 3 * trx + np.random.randn(*trx.shape) * 0.33

 b) create model:

   we shall create a sequential model. all we need is a single connection
   so we use a dense layer with linear activation.
   python

   model = sequential()________________________________________
   model.add(dense(input_dim=1, output_dim=1, init='uniform', a
   ____________________________________________________________
   ____________________________________________________________
   1
   2
   3

   model = sequential()
   model.add(dense(input_dim=1, output_dim=1, init='uniform',
   activation='linear'))
   this will take input x and apply weight, w, and bias, b followed by a
   linear activation to produce output.
   let   s look at values that the weights are initialized with:
   python

   weights = model.layers[0].get_weights()_____________________
   w_init = weights[0][0][0]___________________________________
   b_init = weights[1][0]______________________________________
   print('id75 model is initialized with weights w
   ## id75 model is initialized with weight w: -0.
   1
   2
   3
   4
   5
   6

   weights = model.layers[0].get_weights()
   w_init = weights[0][0][0]
   b_init = weights[1][0]
   print('id75 model is initialized with weights w: %.2f, b:
   %.2f' % (w_init, b_init))
   ## id75 model is initialized with weight w: -0.03, b: 0.00
   now, we shall train this linear model with our training data of trx and
   try,  where try is 3 times of trx, so this value of weights should
   become 3.
   we shall define mean squared error(mse) as the loss with simple
   id119(sgd) as the optimizer
   python

   model.compile(optimizer='sgd', loss='mse')__________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.compile(optimizer='sgd', loss='mse')
   finally, we feed the data using fit function
   python

   model.fit(trx, try, nb_epoch=200, verbose=1)________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.fit(trx, try, nb_epoch=200, verbose=1)
   now, we print the weight after training:
   python

   weights = model.layers[0].get_weights()_____________________
   w_final = weights[0][0][0]__________________________________
   b_final = weights[1][0]_____________________________________
   print('id75 model is trained to have weight w: 
           _______________________________________________________
   ##id75 model is trained to have weight w: 2.94,
   1
   2
   3
   4
   5
   6
   7

   weights = model.layers[0].get_weights()
   w_final = weights[0][0][0]
   b_final = weights[1][0]
   print('id75 model is trained to have weight w: %.2f, b:
   %.2f' % (w_final, b_final))

   ##id75 model is trained to have weight w: 2.94, b: 0.08

   as you can see, the weights are very close to 3 now. this ran for 200
   epochs. feel free to change the number of epochs to 100 or 300 to see
   how this affects the output. we are now able to build a linear
   classifier using keras with very few lines of code while we had to deal
   with sessions and placeholders to do the same using native
   [14]tensorflow in this tutorial.

5. saving and restoring pre-trained weights using keras:

hdf5 binary format:

   once you are done with training using keras, you can save your network
   weights in hdf5 binary data format. in order to use this, you must have
   the h5py package installed, which we did during installation. the hdf5
   format is great to store huge amount of numerical data and manipulate
   this data from numpy. for example, it   s easily possible to slice
   multi-terabyte datasets stored on disk as if they were real numpy
   arrays. you can also store multiple datasets in a single file, iterate
   over them or check out the .shape and .dtype attributes.
   if it gives you a kick, even nasa stores data using[15] hdf format.
   h5py rests on an object-oriented python wrapping of the hdf5 c api.
   almost anything you can do from c in hdf5, you can do from h5py.

saving weights:

   to save the weights of the network that you have just trained, just use
   the save_weights function:
   python

   model.save_weights("my_model.h5")___________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.save_weights("my_model.h5")

restoring pre-trained weights:

   if you want to load saved weights and start training on top of previous
   work, use the load_weights function:
   python

   model.load_weights('my_model_weights.h5')___________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   model.load_weights('my_model_weights.h5')

6. functional api:

   sequential models are good for simpler networks and problems, but to
   build real-world complex networks you need to understand functional
   api. in most of the popular neural networks, we have a mini-network(a
   few layers arranged in a certain way like inception module in
   googlenet, fire module in squeezenet) and this mini-network is repeated
   multiple times. functional api allows you to call models like a
   function as we do for a layer. so, you can build a small model which
   can be repeated multiple times to build the complete network with even
   fewer lines of code. by calling a model on a tensor, you can reuse the
   model as well as weights.

   let   s see how it works. first, you need to import differently.
   python

   from keras.models import model______________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   from keras.models import model
   now, you start by specifying the input, as opposed to mentioning the
   input at the end of the fit function, as done in sequential models.
   this is one of the notable difference between sequential models and
   functional api. let   s declare a tensor of shape 28 * 28 * 1  by using
   input().
   python

   from keras.layers import input______________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   from keras.layers import input
   python

   digit_input = input(shape=(28, 28,1))_______________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   digit_input = input(shape=(28, 28,1))
   now, let   s say we apply a convolutional layer using the functional api,
   we shall have to specify the variable on which we want to apply the
   layer. this looks like this(see, how we specify the input to the
   layer):
   python

   x = conv2d(64, (3, 3))(digit_input)_________________________
   x = conv2d(64, (3, 3))(x)___________________________________
   x = maxpooling2d((2, 2))(x)_________________________________
   out = flatten()(x)__________________________________________
   1
   2
   3
   4
   5

   x = conv2d(64, (3, 3))(digit_input)
   x = conv2d(64, (3, 3))(x)
   x = maxpooling2d((2, 2))(x)
   out = flatten()(x)
   finally, we create a model by specifying the input and output.
   python

   vision_model = model(digit_input, out)______________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   2

   vision_model = model(digit_input, out)
   of course, one will also need to specify the loss, optimizer etc. using
   fit and compile methods, same as we did for the sequential models.

   let   s just use what we have just learned and build a vgg-16 neural
   network. it   s a rather old and large network but is great for learning
   things due to its simplicity.

 6.1 develop vgg convolutional neural network using functional api:

vgg:

   vgg convolutional neural network was proposed by a research group at
   oxford in 2014. this network was once very popular due to its
   simplicity and some nice properties like it worked well on both image
   classification as well as detection tasks. vgg achieved 92.3% top-5
   accuracy in ilsvrc 2014 but was not the winner. it has a few variants,
   one of the most popular ones is vgg-16 which has 16 layers. as you can
   see that it takes an input of 224 * 224 * 3.

   vgg 16 architecture
   let   s write an independent function that will build the complete
   network.
   python

   img_input = input(shape=input_shape)________________________
   # block 1___________________________________________________
   x = conv2d(64, (3, 3), activation='relu', padding='same', na
   x = conv2d(64, (3, 3), activation='relu', padding='same', na
   x = maxpooling2d((2, 2), strides=(2, 2), name='block1_pool')
   ____________________________________________________________
   # block 2___________________________________________________
   x = conv2d(128, (3, 3), activation='relu', padding='same', n
   x = conv2d(128, (3, 3), activation='relu', padding='same', n
   x = maxpooling2d((2, 2), strides=(2, 2), name='block2_pool')
   ____________________________________________________________
   # block 3___________________________________________________
   x = conv2d(256, (3, 3), activation='relu', padding='same', n
   x = conv2d(256, (3, 3), activation='relu', padding='same', n
   x = conv2d(256, (3, 3), activation='relu', padding='same', n
   x = maxpooling2d((2, 2), strides=(2, 2), name='block3_pool')
   ____________________________________________________________
   # block 4___________________________________________________
   x = conv2d(512, (3, 3), activation='relu', padding='same', n
   x = conv2d(512, (3, 3), activation='relu', padding='same', n
   x = conv2d(512, (3, 3), activation='relu', padding='same', n
   x = maxpooling2d((2, 2), strides=(2, 2), name='block4_pool')
   ____________________________________________________________
   # block 5___________________________________________________
   x = conv2d(512, (3, 3), activation='relu', padding='same', n
   x = conv2d(512, (3, 3), activation='relu', padding='same', n
   x = conv2d(512, (3, 3), activation='relu', padding='same', n
   x = maxpooling2d((2, 2), strides=(2, 2), name='block5_pool')
   ____________________________________________________________
   x = flatten(name='flatten')(x)______________________________
   x = dense(4096, activation='relu', name='fc1')(x)___________
   x = dense(4096, activation='relu', name='fc2')(x)___________
   x = dense(classes, activation='softmax', name='predictions')
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34

   img_input = input(shape=input_shape)
   # block 1
   x = conv2d(64, (3, 3), activation='relu', padding='same',
   name='block1_conv1')(img_input)
   x = conv2d(64, (3, 3), activation='relu', padding='same',
   name='block1_conv2')(x)
   x = maxpooling2d((2, 2), strides=(2, 2), name='block1_pool')(x)

   # block 2
   x = conv2d(128, (3, 3), activation='relu', padding='same',
   name='block2_conv1')(x)
   x = conv2d(128, (3, 3), activation='relu', padding='same',
   name='block2_conv2')(x)
   x = maxpooling2d((2, 2), strides=(2, 2), name='block2_pool')(x)

   # block 3
   x = conv2d(256, (3, 3), activation='relu', padding='same',
   name='block3_conv1')(x)
   x = conv2d(256, (3, 3), activation='relu', padding='same',
   name='block3_conv2')(x)
   x = conv2d(256, (3, 3), activation='relu', padding='same',
   name='block3_conv3')(x)
   x = maxpooling2d((2, 2), strides=(2, 2), name='block3_pool')(x)

   # block 4
   x = conv2d(512, (3, 3), activation='relu', padding='same',
   name='block4_conv1')(x)
   x = conv2d(512, (3, 3), activation='relu', padding='same',
   name='block4_conv2')(x)
   x = conv2d(512, (3, 3), activation='relu', padding='same',
   name='block4_conv3')(x)
   x = maxpooling2d((2, 2), strides=(2, 2), name='block4_pool')(x)

   # block 5
   x = conv2d(512, (3, 3), activation='relu', padding='same',
   name='block5_conv1')(x)
   x = conv2d(512, (3, 3), activation='relu', padding='same',
   name='block5_conv2')(x)
   x = conv2d(512, (3, 3), activation='relu', padding='same',
   name='block5_conv3')(x)
   x = maxpooling2d((2, 2), strides=(2, 2), name='block5_pool')(x)

   x = flatten(name='flatten')(x)
   x = dense(4096, activation='relu', name='fc1')(x)
   x = dense(4096, activation='relu', name='fc2')(x)
   x = dense(classes, activation='softmax', name='predictions')(x)
   the complete code is provided in vgg16.py.

   in this example, let   s run id163 predictions on some images. let   s
   write the code for the same:

   python

   model = applications.vgg16(weights='id163')______________
   img = image.load_img('cat.jpeg', target_size=(224, 224))____
   x = image.img_to_array(img)_________________________________
   x = np.expand_dims(x, axis=0)_______________________________
   x = preprocess_input(x)_____________________________________
   preds = model.predict(x)____________________________________
   for results in decode_predictions(preds):___________________
       for result in results:__________________________________
           print('id203 %0.2f%% => [%s]' % (100*result[2]
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10

   model = applications.vgg16(weights='id163')
   img = image.load_img('cat.jpeg', target_size=(224, 224))
   x = image.img_to_array(img)
   x = np.expand_dims(x, axis=0)
   x = preprocess_input(x)
   preds = model.predict(x)
   for results in decode_predictions(preds):
       for result in results:
           print('id203 %0.2f%% => [%s]' % (100*result[2],
   result[1]))

   prediction in keras tensorflow tutorial
   this will take the input image and generate predictions. as you can see
   that it   s able to accurately predict the correct class.
   vgg is a simple network which demonstrates the use of functional api.
   however, it doesn   t really harness the power of functional api. in the
   next section, we shall build squeezenet which shall truly demonstrate
   the power of functional api.

6.2 build and run squeezenet convolutional neural network using functional
api:

squeezenet:

   squeezenet is a network architecture which is remarkable not for its
   accuracy but for how less computation it needs. squeezenet has accuracy
   levels close to that of alexnet however, the pre-trained model on
   id163 has a size less than 5 mb which is great for using id98s in a
   real world application. squeezenet introduced a fire module which is
   made of alternate squeeze and expand modules.
   squeezenet fire module

   squeezenet fire module

   now, this fire module is repeated used to build the complete network
   which looks like this:
   in order to build this network, we shall harness the power of
   functional api to first build an individual fire module:
   python

   # squeeze part of fire module with 1 * 1 convolutions, follo
   x = convolution2d(squeeze, (1, 1), padding='valid', name='fi
   x = activation('relu', name='fire2/relu_squeeze1x1')(x)_____
   &nbsp;______________________________________________________
   #expand part has two portions, left uses 1 * 1 convolutions 
   left = convolution2d(expand, (1, 1), padding='valid', name='
   left = activation('relu', name='fire2/relu_expand1x1')(left)
   &nbsp;______________________________________________________
   #right part uses 3 * 3 convolutions and is called expand3x3,
   right = convolution2d(expand, (3, 3), padding='same', name='
   right = activation('relu', name='fire2/relu_expand3x3')(righ
   &nbsp;______________________________________________________
   # final output of fire module is concatenation of left and r
   x = concatenate([left, right], axis=3, name='fire2/concat')_
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15

   # squeeze part of fire module with 1 * 1 convolutions, followed by relu
   x = convolution2d(squeeze, (1, 1), padding='valid',
   name='fire2/squeeze1x1')(x)
   x = activation('relu', name='fire2/relu_squeeze1x1')(x)
   &nbsp;
   #expand part has two portions, left uses 1 * 1 convolutions and is
   called expand1x1&nbsp;
   left = convolution2d(expand, (1, 1), padding='valid',
   name='fire2/expand1x1')(x)
   left = activation('relu', name='fire2/relu_expand1x1')(left)
   &nbsp;
   #right part uses 3 * 3 convolutions and is called expand3x3, both of
   these are follow#ed by relu layer, note that both receive x as input as
   designed.&nbsp;
   right = convolution2d(expand, (3, 3), padding='same',
   name='fire2/expand3x3')(x)
   right = activation('relu', name='fire2/relu_expand3x3')(right)
   &nbsp;
   # final output of fire module is concatenation of left and right.&nbsp;
   x = concatenate([left, right], axis=3, name='fire2/concat')
   we can easily convert this code into a function for reuse:
   python

   sq1x1 = "squeeze1x1"________________________________________
   exp1x1 = "expand1x1"________________________________________
   exp3x3 = "expand3x3"________________________________________
   relu = "relu_"______________________________________________
   weights_path = "https://github.com/rcmalli/keras-squeezenet/
   1
   2
   3
   4
   5
   6

   sq1x1 = "squeeze1x1"
   exp1x1 = "expand1x1"
   exp3x3 = "expand3x3"
   relu = "relu_"
   weights_path =
   "https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squ
   eezenet_weights_tf_dim_ordering_tf_kernels.h5"

modular function for fire node

   python

   sq1x1 = "squeeze1x1"________________________________________
   exp1x1 = "expand1x1"________________________________________
   exp3x3 = "expand3x3"________________________________________
   relu = "relu_"______________________________________________
   ____________________________________________________________
   def fire_module(x, fire_id, squeeze=16, expand=64):_________
      s_id = 'fire' + str(fire_id) + '/'_______________________
      x = convolution2d(squeeze, (1, 1), padding='valid', name=
      x = activation('relu', name=s_id + relu + sq1x1)(x)______
   ____________________________________________________________
      left = convolution2d(expand, (1, 1), padding='valid', nam
      left = activation('relu', name=s_id + relu + exp1x1)(left
   ____________________________________________________________
      right = convolution2d(expand, (3, 3), padding='same', nam
      right = activation('relu', name=s_id + relu + exp3x3)(rig
   ____________________________________________________________
      x = concatenate([left, right], axis=3, name=s_id + 'conca
   return x____________________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19

   sq1x1 = "squeeze1x1"
   exp1x1 = "expand1x1"
   exp3x3 = "expand3x3"
   relu = "relu_"

   def fire_module(x, fire_id, squeeze=16, expand=64):
      s_id = 'fire' + str(fire_id) + '/'
      x = convolution2d(squeeze, (1, 1), padding='valid', name=s_id +
   sq1x1)(x)
      x = activation('relu', name=s_id + relu + sq1x1)(x)

      left = convolution2d(expand, (1, 1), padding='valid', name=s_id +
   exp1x1)(x)
      left = activation('relu', name=s_id + relu + exp1x1)(left)

      right = convolution2d(expand, (3, 3), padding='same', name=s_id +
   exp3x3)(x)
      right = activation('relu', name=s_id + relu + exp3x3)(right)

      x = concatenate([left, right], axis=3, name=s_id + 'concat')
   return x
   now, we can build the complete network by extensively reusing the
   fire_module function which we just defined.
   python

   x = convolution2d(64, (3, 3), strides=(2, 2), padding='valid
   x = activation('relu', name='relu_conv1')(x)________________
   x = maxpooling2d(pool_size=(3, 3), strides=(2, 2), name='poo
   ____________________________________________________________
   x = fire_module(x, fire_id=2, squeeze=16, expand=64)________
   x = fire_module(x, fire_id=3, squeeze=16, expand=64)________
   x = maxpooling2d(pool_size=(3, 3), strides=(2, 2), name='poo
   ____________________________________________________________
   x = fire_module(x, fire_id=4, squeeze=32, expand=128)_______
   x = fire_module(x, fire_id=5, squeeze=32, expand=128)_______
   x = maxpooling2d(pool_size=(3, 3), strides=(2, 2), name='poo
   ____________________________________________________________
   x = fire_module(x, fire_id=6, squeeze=48, expand=192)_______
   x = fire_module(x, fire_id=7, squeeze=48, expand=192)_______
   x = fire_module(x, fire_id=8, squeeze=64, expand=256)_______
   x = fire_module(x, fire_id=9, squeeze=64, expand=256)_______
   x = dropout(0.5, name='drop9')(x)___________________________
   ____________________________________________________________
   x = convolution2d(classes, (1, 1), padding='valid', name='co
   x = activation('relu', name='relu_conv10')(x)_______________
   x = globalaveragepooling2d()(x)_____________________________
   out = activation('softmax', name='loss')(x)_________________
   ____________________________________________________________
   model = model(inputs, out, name='squeezenet')_______________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25

   x = convolution2d(64, (3, 3), strides=(2, 2), padding='valid',
   name='conv1')(img_input)
   x = activation('relu', name='relu_conv1')(x)
   x = maxpooling2d(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)

   x = fire_module(x, fire_id=2, squeeze=16, expand=64)
   x = fire_module(x, fire_id=3, squeeze=16, expand=64)
   x = maxpooling2d(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)

   x = fire_module(x, fire_id=4, squeeze=32, expand=128)
   x = fire_module(x, fire_id=5, squeeze=32, expand=128)
   x = maxpooling2d(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)

   x = fire_module(x, fire_id=6, squeeze=48, expand=192)
   x = fire_module(x, fire_id=7, squeeze=48, expand=192)
   x = fire_module(x, fire_id=8, squeeze=64, expand=256)
   x = fire_module(x, fire_id=9, squeeze=64, expand=256)
   x = dropout(0.5, name='drop9')(x)

   x = convolution2d(classes, (1, 1), padding='valid', name='conv10')(x)
   x = activation('relu', name='relu_conv10')(x)
   x = globalaveragepooling2d()(x)
   out = activation('softmax', name='loss')(x)

   model = model(inputs, out, name='squeezenet')
   the complete network architecture is defined in squeezenet.py file. we
   shall download id163 pre-trained model and run prediction using this
   model on our own image. let   s quickly write some code to run this
   network:
   python

   import numpy as np__________________________________________
   from keras_squeezenet import squeezenet_____________________
   from keras.applications.id163_utils import preprocess_inp
   from keras.preprocessing import image_______________________
   ____________________________________________________________
   model = squeezenet()________________________________________
   ____________________________________________________________
   img = image.load_img('pexels-photo-280207.jpeg', target_size
   x = image.img_to_array(img)_________________________________
   x = np.expand_dims(x, axis=0)_______________________________
   x = preprocess_input(x)_____________________________________
   ____________________________________________________________
   preds = model.predict(x)____________________________________
   all_results = decode_predictions(preds)_____________________
   for results in all_results:_________________________________
   for result in results:______________________________________
   print('id203 %0.2f%% => [%s]' % (100*result[2], result
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18

   import numpy as np
   from keras_squeezenet import squeezenet
   from keras.applications.id163_utils import preprocess_input,
   decode_predictions
   from keras.preprocessing import image

   model = squeezenet()

   img = image.load_img('pexels-photo-280207.jpeg', target_size=(227,
   227))
   x = image.img_to_array(img)
   x = np.expand_dims(x, axis=0)
   x = preprocess_input(x)

   preds = model.predict(x)
   all_results = decode_predictions(preds)
   for results in all_results:
   for result in results:
   print('id203 %0.2f%% => [%s]' % (100*result[2], result[1]))

   this will result in the t in p-5 predictions and their probabilities
   for the image    pixels-photo-280207.jpeg    which is an image of french
   loaf.
   hopefully, this keras tensorflow tutorial gave you a good introduction
   to keras. we have learnt:
   1. setting up and installing keras with tensorflow backend.
   2. keras sequential models
   3. keras functional api
   4. saving and loading saved weights in keras
   5. how to solve id75 using keras with example code.
   as usual, the complete code can be downloaded from our github[16] repo.
   you can run all 3 examples by running these 3 files:
   python

   #id75__________________________________________
   python 1_keras_linear_regression.py_________________________
   ____________________________________________________________
   # vgg prediction, this downloads 500 mb sized weights_______
   # so, it will take a while to run and predict.______________
   python 2_run_vgg.py_________________________________________
   ____________________________________________________________
   # squeezenet prediction. the size of pretrained model is 5 m
   python 3_run_squeezenet.py__________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10

   #id75
   python 1_keras_linear_regression.py

   # vgg prediction, this downloads 500 mb sized weights
   # so, it will take a while to run and predict.
   python 2_run_vgg.py

   # squeezenet prediction. the size of pretrained model is 5 mb. wow!
   python 3_run_squeezenet.py
   hopefully, this tutorial helps you in learning keras with tensorflow.
   do me a favour, if you find this useful, please share with your friends
   and colleagues who are looking to learn deep learning and computer
   vision. happy learning!
   [17]deep learning, [18]install keras, [19]keras functional api,
   [20]sqeezenet, [21]tensorflow tutorial, [22]vgg

most popular
     __________________________________________________________________

     * [23]tensorflow tutorial 2: image classifier using convolutional
       neural network
     * [24]tensorflow tutorials [25]a quick complete tutorial to save and
       restore tensorflow models
     * [26]resnet, alexnet, vggnet, inception: understanding various
       architectures of convolutional networks
     * [27]zero to hero: guide to id164 using deep learning:
       ...
     * keras tensorflow tutorial keras tutorial: practical guide from
       getting started to developing complex ...

[28]rss [29]cv-tricks rss feed
     __________________________________________________________________

     * [30]human pose estimation using deep learning in opencv
     * [31]deep learning based image colorization with opencv
     * [32]deep learning based edge detection in opencv
     __________________________________________________________________

share this article

   [33]share on facebook [34]share on twitter [35]share on pinterest

   copyright    2017 cv-tricks.com

references

   visible links
   1. https://cv-tricks.com/artificial-intelligence/deep-learning/accelerating-convolutional-neural-networks-on-raspberry-pi/
   2. https://cv-tricks.com/image-segmentation/transpose-convolution-in-tensorflow/
   3. https://cv-tricks.com/
   4. https://cv-tricks.com/tensorflow-tutorial/keras/
   5. https://cv-tricks.com/
   6. https://cv-tricks.com/category/tensorflow-tutorial
   7. https://cv-tricks.com/about-us/
   8. https://cv-tricks.com/tensorflow-tutorial/keras/
   9. https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/
  10. https://twitter.com/fchollet
  11. http://keras.io/
  12. https://cv-tricks.com/artificial-intelligence/deep-learning/deep-learning-frameworks/install-tensorflow-1-0-gpu-ubuntu-14-04-aws-p2-xlarge/
  13. https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/
  14. https://cv-tricks.com/artificial-intelligence/deep-learning/deep-learning-frameworks/tensorflow-tutorial/
  15. https://earthobservatory.nasa.gov/features/hdfeos/
  16. https://github.com/sankit1/cv-tricks.com/tree/master/tensorflow-tutorials/keras-tensorflow-tutorial
  17. https://cv-tricks.com/tag/deep-learning/
  18. https://cv-tricks.com/tag/install-keras/
  19. https://cv-tricks.com/tag/keras-functional-api/
  20. https://cv-tricks.com/tag/sqeezenet/
  21. https://cv-tricks.com/tag/tensorflow-tutorial/
  22. https://cv-tricks.com/tag/vgg/
  23. https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/
  24. https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/
  25. https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/
  26. https://cv-tricks.com/id98/understand-resnet-alexnet-vgg-inception/
  27. https://cv-tricks.com/object-detection/faster-r-id98-yolo-ssd/
  28. https://cv-tricks.com/feed/
  29. https://cv-tricks.com/
  30. https://cv-tricks.com/pose-estimation/using-deep-learning-in-opencv/
  31. https://cv-tricks.com/opencv/deep-learning-image-colorization/
  32. https://cv-tricks.com/opencv-dnn/edge-detection-hed/
  33. http://www.facebook.com/share.php?u=https://cv-tricks.com/tensorflow-tutorial/keras/
  34. https://twitter.com/share?url=https://cv-tricks.com/tensorflow-tutorial/keras/
  35. http://pinterest.com/pin/create/button/?url=https://cv-tricks.com/tensorflow-tutorial/keras/

   hidden links:
  37. https://cv-tricks.com/tensorflow-tutorial/keras/
  38. https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/
  39. https://cv-tricks.com/id98/understand-resnet-alexnet-vgg-inception/
  40. https://cv-tricks.com/object-detection/faster-r-id98-yolo-ssd/
  41. https://cv-tricks.com/tensorflow-tutorial/keras/#top
