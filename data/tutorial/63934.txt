   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

id119 vs. neuroevolution

   [16]go to the profile of lars hulstaert
   [17]lars hulstaert (button) blockedunblock (button) followfollowing
   dec 20, 2017

   in march 2017, openai released a [18]blog post on evolution strategies,
   an optimisation technique that has been around for several decades. the
   novelty of their paper was that they managed to apply the technique to
   deep neural networks in the context of id23 (rl)
   problems. before this, the optimisation of deep learning rl models
   (with typically millions of parameters) was typically achieved with
   id26. using evolution strategies for deep neural network
   (dnn) optimisation seemingly unlocked an exciting new toolbox for deep
   learning researchers to play with.

   this week, uber ai research released a set of five papers which are all
   focussed on 'neuroevolution'. the term neuroevolution refer to the
   optimisation of neural networks through evolutionary algorithms. the
   researchers posit that id107 are an effective method to
   train deep neural networks for id23 problems and that
   they outperform traditional rl approaches in some domains.
   [0*lozs9o9wdj5tolac.jpg]
   neuroevolution relates to natural evolution as an airplane relates to a
   bird. neuroevolution has borrowed some fundamental concepts from
   nature, similarly as neural networks, planes, etc.

overview

   so what does this mean? will all dnn's, ranging from supervised, to
   unsupervised as well as rl applications, be optimised using
   neuroevolution in the near future? is neuroevolution the future of deep
   learning? what exactly is neuroevolution? in this blog post i will
   attempt to provide an introduction to neuroevolution, and compare it to
   the traditional id26 algorithm. i will also attempt to
   answer the aforementioned questions and situate neuroevolution
   techniques in the bigger dl picture.

   first i will start by framing the optimisation problem, which is the
   core problem that id26 and neuroevolution try to solve. i
   will also attempt to make a clear distinction between the difference
   between supervised learning and id23.

   next, i will discuss id26 and explain how it relates to
   neuroevolution. given that both openai and uber ai research just
   released papers on this technique, i have plenty of topics to tackle.
   fortunately, as deep learning neuroevolution is in the early stages of
   research, the mechanics of neuroevolution still remain fairly
   comprehensible.

the optimisation problem

   as discussed in [19]my previous blog post, machine learning models are
   in essence function approximators. whether it is classification,
   regression or id23, the end goal is almost always to
   find a function that maps input data to output data. you use the
   training data to infer the parameters and hyperparameters and verify
   with the test data whether the approximated function performs well on
   unseen data.

   the inputs can be manually defined features or raw data (images, text,
   etc.) and the outputs are either classes or labels in classification,
   real values in regression and actions in id23. for
   this blog post we will limit the type of function approximators to deep
   learning networks, yet the same discussion applies to other models. the
   parameters that need to be inferred thus correspond to the weights and
   biases in the network. 'performing well on train and test data' is
   expressed through objective measures, such as the log loss for
   classification, the mean squared error (mse) for regression and the
   reward for id23.

   the core problem is thus finding the parameter settings that results in
   the lowest loss or the highest reward. simple! given an optimisation
   objective, i.e. the loss or the reward, that needs to be optimised as a
   function of the networks parameters the goal is thus to tweak the
   parameters in such a way that the optimisation objective is minimised
   or maximised.

   in order to make this visual, let's use two examples. in both cases, we
   have plotted an optimisation objective. in the image of the parabola,
   the x-axis represents the single parameter of the model, and the y-axis
   represents the optimisation objective (e.g. on test data).
   [1*qugilaeqzdumgkscrubelq.png]

   in the image below, the x and y axis represent the two parameters of
   the model and the z axis represents the optimisation objective (e.g. on
   the test data).
   [1*cjgkqklenw2dspcoirexca.png]

   in reality, it is not possible to plot the 'optimisation surfaces', due
   to the sheer number of parameters and how they are non-linearly
   combined in deep learning networks. nevertheless, the same ideas apply
   and the optimisation surface is typically high dimensional and complex,
   with many hills, cradles, valleys, etc.

   the goal is now to find an optimisation technique that allows us to
   crawl in the optimisation surface and find the minimum or maximum. note
   that the size and shape of these surfaces is related to the number of
   parameters, and it is infeasible to explore all options, regardless if
   we are working with continous or discrete parameters. the problem now
   has become the following: given a random starting point in the
   optimisation surface, find the absolute minimum or maximum.

   deep neural networks are great function approximators (universal
   function approximators even to a certain extent), but they are also
   hard to optimise. hard to optimise in this context means that it is
   very hard to find the global maximum or minimum on the    optimisation
   surface   . in the next sections i will discuss how id119 and
   neuroevolution can be used to find good solutions.

id119

   the general idea of id119 (id26) has been around
   for several decades. due to the abundance of data, compute power, and
   novel innovations, it has become the main technique to optimise the
   parameters of deep learning models.

   the general idea of id119 is the following:
   -assume you are in paris, france, and you need to get berlin, germany.
   europe in this case is the optimisation surface, paris is the random
   starting point and berlin is the absolute minimum or maximum.
   -as you don't have a map, you ask random strangers the direction to
   berlin. some of the random strangers know where berlin is but others
   don't, so while most of the times, you walk in the correct direction,
   it is possible that you also are going into wrong directions. as long
   as the strangers are more correct than false, it should work out (e.g.
   stochastic id119, or id119 with minibatches).
   -you walk 5 miles (the stepsize or learning rate) in the direction the
   stranger has pointed you to. this process is repeated until you believe
   you are close enough to germany. it might turn out you just entered
   germany, and you are nowhere close to berlin (local optima). there is
   no way to verify whether you reached your end goal and you can only
   estimate based on your surroundings (the test loss or the reward).
   [1*oz218oh_eypsccloeb2w0w.png]
   id119: walking around in europe without a map.

   going back to the two visual examples, you can imagine how gradient
   descent works in the case of the parabola and the more complex surface.
   essentially, with id119 you are walking down the
   optimisation surface. in the case of the parabola, it is
   straightforward, as you just have to walk down the slope. if the
   learning rate is too high though, you might never be able to get to the
   absolute minimum.
   [1*kqzluifr8a_9wmvjddx6lg.png]
   the importance of a proper stepsize (image taken from the
   cornell course)

   in the second example the situation is more complex. there are several
   hills and valleys you have to overcome in order to get to the absolute
   minimum. several id119 variants that attempt to mimic
   physical behaviour such as a ball rolling down the surface with
   momentum (e.g. adam) in order to avoid getting stuck in local optima.
   [1*su7d1-ec375mpt746wzwyw.png]
   an example path that id119 might take. notice that depending
   on the hyperparameters you might get stuck in the initial local minima.

   i highly recommend this [20]blog post on id119 variants. it
   clearly explains and illustrates the differences between the different
   variants and how they solve the different problems that gradient
   descent faces. there are often several local optima, obstacles and
   different paths in this optimisation problem, and different variants of
   id119 typically try to tackle some (or all of these)
   problems. nowadays, the adam optimiser seems to be the most influential
   one.

   essential to id119 is the computation of proper gradients
   that propel you towards a good solution. in supervised learning, it is
   possible to obtain 'high quality gradients' with relative ease through
   the labeled datasets. in id23 however, you are only
   given a sparse reward, as the random initial behaviour will not lead to
   a high reward. in addition this reward only occurs after a couple of
   actions. while the loss in classification and regression is a
   relatively good proxy for the function you are trying to approximate,
   the reward in id23 is typically not a very good proxy
   of the behaviour or function you want to learn.

   given that the gradients in id23 are not always of
   good quality, evolution algorithms have recently been used by uber and
   openai to improve learning.

neuroevolution

   neuroevolution, id107, evolution strategies all revolve
   around the concept of genetic evolution.

   when you are doing genetic optimisation in the context of dnn
   optimisation, you start from an initial population of models.
   typically, a model is randomly initialised, and several offspring are
   derived based on this initial model. in the case of dnn   s, you
   initialise a model (as you normally do), and you add small random
   vectors, sampled from a simple gaussian distribution, to the
   parameters. this results in a cloud of models, which all reside
   somewhere on the optimisation surface. note that this is the first
   important distinction with id119. you start (and continue to
   work) with a population of models, instead of a single (point) model.

   starting from this original population, the genetic optimisation cycles
   start. in what follows i will describe genetic optimisation in the
   context of evolution strategies (es). evolution strategies, genetic
   algorithms, etc. all have slightly different approaches as to how
   genetic optimisation is performed.
   [1*kqigkizokjudef9x_sw5kw.png]
   overview of genetic optimisation.

   first, a fitness evaluation is performed. fitness evaluation
   corresponds with checking where the models are in the optimisation
   surface and determining which of the models perform best (e.g. are the
   most fit). some models will perform better than others, just because of
   the way they have been initialised.
   next, a selection is performed based on the fitness evaluation. in
   evolution strategies, the (pseudo) offspring is reduced to a single
   model, weighted by the fitness evaluation. for dnn's the fitness is
   defined as the loss or the reward. essentially, you are thus moving
   around the optimisation surface and using the offspring to get in the
   right direction. notice that this is a second major difference with
   id119. instead of computing the gradients, you are setting
   out multiple 'antenna's' and moving in the direction that looks best.
   in a way, this is similar to a 'structured random' search. the end
   result of the selection phase is that you have a single model.
   next, reproduction and combination is performed. concretely, the same
   process as in the initial phase is repeated. based on the newly
   selected 'prime' model, a new set of offspring is derived. the process
   then continues with this offspring.
   typically, in genetic optimisation, mutation is also performed in order
   to improve the variety of the offspring. one example of mutation is to
   change how the different offspring is created (i.e. different noise
   levels for the different parameters).

   one of the advantages of es is that the fitness evaluation of the
   different models in the population can be computed on different cores
   (out-of-core computation). the only information that needs to be shared
   after fitness evaluation is their performance (a scalar value) as well
   as the random seed value that was used to generate the model. as a
   result, it is not necessary anymore to share the full network with all
   machines. both openai and uber used literally hundreds and thousands of
   machines in order to do their experiments. with the rise of cloud
   computing, running these experiments becomes very scalable and is only
   limited by compute power.

   the image below represent two of the main differences between es and
   id119. multiple models are used to move around, and
   gradients are not calculated, rather the different models are averaged
   based on their performance. optimising over a population instead of
   over a single model results in higher robustness properties, as shown
   in the uber research, and shows similarities to bayesian approaches to
   dnn optimisation.
   [1*6a6xog-xmjoxe48mb7wwhq.png]
   neuroevolution: walking around europe in a group.

   i highly recommend having a look at the great illustrations in the
   [21]uber blog post. these illustrate how es can be used to circumvent
   some of the problems that id119 faces (e.g. getting stuck in
   local optima). in essence, the evolution strategy performs a gradient
   approximation. while using the true gradients is better when they are
   available, this method does show promise when only relatively bad
   approximations are available for the true gradient and when exploration
   of the optimisation surface is required, such as in reinforcement
   learning scenario's.

conclusion

   the researchers at openai and uber are able to show that the 'gradient
   approximation' of evolution strategies leads to satisfying (but not
   necessarily new state-of-the-art) solutions in supervised learning
   scenario's. on the other hand they are able to show high performance of
   their methods in id23 scenario's (comparable to
   state-of-the-art in some domains).

   will neuroevolution be the future of deep learning? probably not, but i
   do believe it shows great promises for hard optimisation problems, such
   as in id23 scenario's. in addition, i believe a
   combination of neuroevolution and id119 methods will lead to
   a significant improvement in rl performance. one downside of
   neuroevolution is the massive amounts of compute power that are
   required in order to train these systems, which might limit the
   democratisation of these techniques.

   given that prominent research groups are focussing on these problems, i
   am still excited to see what the future holds!

     * [22]machine learning
     * [23]deep learning
     * [24]data science
     * [25]neural networks
     * [26]towards data science

   (button)
   (button)
   (button) 1k claps
   (button) (button) (button) 4 (button) (button)

     (button) blockedunblock (button) followfollowing
   [27]go to the profile of lars hulstaert

[28]lars hulstaert

   data scientist at microsoft. previously masters student at cambridge,
   engineering student in ghent. i like connecting the dots.

     (button) follow
   [29]towards data science

[30]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 1k
     * (button)
     *
     *

   [31]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [32]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/f907dace010f
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/gradient-descent-vs-neuroevolution-f907dace010f&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/gradient-descent-vs-neuroevolution-f907dace010f&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_vupuseo3el5s---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@lars.hulstaert?source=post_header_lockup
  17. https://towardsdatascience.com/@lars.hulstaert
  18. https://blog.openai.com/evolution-strategies/
  19. https://towardsdatascience.com/understanding-objective-functions-in-neural-networks-d217cb068138
  20. http://ruder.io/optimizing-gradient-descent/index.html#fn:15
  21. https://eng.uber.com/deep-neuroevolution/
  22. https://towardsdatascience.com/tagged/machine-learning?source=post
  23. https://towardsdatascience.com/tagged/deep-learning?source=post
  24. https://towardsdatascience.com/tagged/data-science?source=post
  25. https://towardsdatascience.com/tagged/neural-networks?source=post
  26. https://towardsdatascience.com/tagged/towards-data-science?source=post
  27. https://towardsdatascience.com/@lars.hulstaert?source=footer_card
  28. https://towardsdatascience.com/@lars.hulstaert
  29. https://towardsdatascience.com/?source=footer_card
  30. https://towardsdatascience.com/?source=footer_card
  31. https://towardsdatascience.com/
  32. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  34. https://medium.com/p/f907dace010f/share/twitter
  35. https://medium.com/p/f907dace010f/share/facebook
  36. https://medium.com/p/f907dace010f/share/twitter
  37. https://medium.com/p/f907dace010f/share/facebook
