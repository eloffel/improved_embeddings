   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]good audience
     * [9]     what is good audience?
     * [10]    signup for our newsletter
     * [11]       submit a story
     * [12]     get 100 free raven tokens
     __________________________________________________________________

ai in 2018 for researchers

   go to the profile of alexandr honchar
   [13]alexandr honchar (button) blockedunblock (button) followfollowing
   dec 21, 2017

   ciao everyone! 2017 was one of the most productive and full of cool
   ideas and developments year in machine learning world. i think you
   already can see a lot of blog posts or even official reports with
   summaries of research and industry breakthroughs. i would like to share
   my vision about slightly different thing         what will happen in the next
   year in ai from three different points of view in two articles:
     * as an ai researcher, who is moving the field forward (this article)
     * [14]as a developer, who is applying machine learning in industry

   my forecasts in this, first article, are based on the evolution of
   research ideas in both academia and tech giants labs which i am
   following since 2012. i have selected areas that, from my point of
   view, are in more or less early development stage, but ready enough to
   be studied and show good results in the 2018 and be applied in the real
   world in 2019   2020. enjoy!

   iframe: [15]/media/748a06e9019942f2677bba917ef55804?postid=8955df0caaf9

open science

   academia people from other sciences are asking themselves:

     how these ai guys are doing their research so fast?

   first of all, in machine learning most of articles aren   t going to the
   journals, but to conference, with immediate arxiv preprint, so people
   can see latest development not in several months after paper sending,
   but much earlier. secondly, we don   t publish    homeopathic    articles: to
   be published you almost surely or have to show new state of the art or
   to show new method that performs the same or nearly the same as current
   state of the art. moreover, new method has to show improvement in
   different metrics         speed, accuracy, parallel execution, quality of
   mathematical proofs, handling different dataset sizes etc         it improves
   the general quality greatly. last, but not least, all main articles are
   open-sourcing implementations, so the results can be double checked and
   even improved by other people launching your code.

   one of the coolest thing in modern ai research is new format of
   publications in sort of    blog    format         that   s what we can see in[16]
   deepmind blog, [17]openai blog, [18]salesforce blog, [19]ibm research
   blog. results are shown in nice and clear way, so even people far from
   research can see that this is    cool   . personally i like a lot the
   distill pub:
   [20]distill - latest articles about machine learning
   articles about machine learningdistill.pub

   this is a real scientific journal, but articles look much more like
   blog posts with nice illustrations. of course, it requires a lot of
   work, but for now only this format of research can attract more
   people         basically you show results simultaneously to 1) researchers,
   that can value your maths 2) developers, that can understand your ideas
   through visualizations 3) investors, who can understand your research
   and how it can be applied. i believe that in next couple of years best
   researches will be delivered in this way. if giants are doing
   this         you should try too!

language models without parallel corpus

   let   s consider a simple problem:

     take 50 books in arabic, 16 books in german and 7 books in ukrainian
     and learn now to translate from arabic to ukrainian and from
     ukrainian to german.

   can you do it? i bet you can   t. but machines already can! in 2017 two
   breakthrough papers were published: [21]click, [22]clack. basically the
   idea is to train some general human language representation space,
   where similar sentences are sticking together. idea is not new, but now
   it   s done without having explicit pairs of german-arabic sentences:
   [0*u2tvnyi-y4tmqdpc.png]
   illustration of such a multilingual representation space

   authors of these articles say that with small supervision the quality
   of translation rises drastically. i expect this research to be done
   till summer and be in production till the end of 2018. and the general
   idea of this kind of supervised, but not really supervised learning can
   be and must be extended to other domains.

time to understand video better

   we already could make id161 system see better than a human
   being, thanks to different deep, wide and densely connected nets:
   [1*2y4hdh2zghor_8fdpiawaa.png]
   from [23]http://aiindex.org/2017-report.pdf

   but for now we benchmarked performance only on still images, which is
   cool, but we used to see sequences of images, videos or just real world
   changes with our eyes         so we need to transform these id161
   results to videos and make it work the same fast as for still pictures.

     and let   s be honest, detecting 1000 objects on still images became
     totally boring and not sexy at all

   there are some interesting results published on last nips 2017 about
   next [24]frame prediction (we can see a connection with id56s for text
   generation, where trained to predict next word neural network could
   become a sort of language model) and [25]representation learning from a
   video. here are several datasets you can start working with: improve
   id12, add optical flow concept to videos, work on recurrent
   architectures to make them more efficient with large videos:
   [26]moments in time
   homepagemoments.csail.mit.edu
   [27]youtube-8m: a large and diverse labeled video dataset for video
   understanding research
   feb 15, 2017: updated youtub-8m with new labels (twice as many
   labels/video, on average), newly added audio
   features   research.google.com

multitask/multimodal learning

   when i am observing world around me, i see much more than moving
   pictures: i hear sounds, feel temperature outside, feel some emotions.
   it means that i    see    the world around me from different sources, that
   i would like to call modalities. moreover, even when i    see    just one
   modality, for example hear someone   s voice         i don   t just translate it
   into words, like sound recognition systems do, i also understand gender
   and age, emotions of the person who i am talking to         i understand
   different things same time. we would like machines to have the same
   abilities.

     humans can make hundreds of conclusions from a single image, why
     machines don   t?

   there are not very much datasets on solving multitask problems, usually
   before the additional tasks were created additionally to use them as
   regularizers, but recently really cool dataset and challenge was
   published in oxford on multimodal image recognition. i expect more
   datasets and results to appear next year in voice applications (age,
   emotions):
   [28]visual decathlon challenge
   the goal of this challenge is to solve simultaneously ten image
   classification problems representative of very   www.robots.ox.ac.uk

     humans are processing more than 10 modalities, why machines don   t?

   i wanted to write about financial applications of multimodal learning,
   but after release of this dataset trading has no chances anymore. this
   is amazing environment where you can teach your robot to see, to feel
   and to hear everything inside an almost real house!
   [29]home: a household multimodal environment
   home integrates over 45,000 diverse 3d house layouts based on the suncg
   dataset, a scale which may facilitate
   learning   home-platform.github.io

     can we do it all together?

   if you   re curious, if we can build crazy multimodal-multitask models,
   that can solve different tasks based on totally different
   inputs         [30]google research did it. they have built an architecture
   that can take images and text as input and solving image recognition,
   segmentation, text translation, parsing and other problems with a
   single neural network. i think it was not the smartest way to solve
   this kind of tasks, but it   s a good start though!
   [0*237gksopvdnntxhu.png]
   [31]https://research.googleblog.com/2017/06/multimodel-multi-task-machi
   ne-learning.html

id23: still playing

   id23 is one of the most exciting and doubtful areas
   for me         we can play and win complex games like [32]go, chess and
   [33]poker just from self-play without knowing any rules, but the same
   time we barely see real world applications, just some 3d toy figure
   climbing in a artificial environment or moving robotic arms. that   s why
   i think that next year will be still in research. i see two main
   breakthroughs that will happen:
   [34]dota 2
   we've created a bot which beats the world's top professionals at 1v1
   matches of dota 2 under standard tournament rules   blog.openai.com
   [35]deepmind and blizzard open starcraft ii as an ai research
   environment | deepmind
   along with our partner blizzard entertainment, we are excited to
   announce the release of the starcraft ii learning   deepmind.com

   yes, i am pretty sure that dota and starcraft 2 champions will be
   beaten by openai and deepmind bots. you can try to play sc2 already by
   yourself using [36]openai gym environment.

   iframe: [37]/media/530eb2f9533e53c155e61d960a940711?postid=8955df0caaf9

   in case if you haven   t seen how openai bot plays dota

   for real researchers who aren   t so much into playing games, there are
   interesting results by openai you might like to improve:[38]
   competitive self-play, [39]learning from other models, [40]learning to
   communicate and cooperate and, of course, facebook   s [41]learning to
   negotiate. i hope to see results above in chatbots in 1   2 years, but
   now they need more research to be done.
   [0*_r7crwlbhnbwsvka.]
   facebook bots trying to negotiate, image from the link above

ai has to be able to explain itself

   using deep neural networks is cool. you can brag with number of layers,
   density of connections and 0.05 improvements on id163, or even apply
   it to [42]medical radiology, but can we seriously rely on them if they
   can   t even explain themselves?

     i would like to know, why exactly this my net thinks that this is a
     dog on the image, why it thinks that person is smiling or why it
     says i have some disease.

   deep neural networks unfortunately can   t give us these answers, even
   they can give very accurate results:
   [1*74hby44amx3nedvwyfklxg.png]
   picture from    darpa explainable ai         performance vs. explainability   
   presentation

   this problem is still considered as open, even we had some successful
   applications of [43]extraction of tree-based rules from deep networks,
   [44]visualization of convolutional neural network layers and more
   difficult ideas like [45]latent concepts, [46]and-or graphs training or
   generating [47]visual explanations:
   [1*qheisgg7k4-8-96qfy5rbq.png]
   image from [48]https://arxiv.org/pdf/1603.08507.pdf

   and [49]latest state of the art interpretnet:
   [1*hhjw6nugdg7-f2nfh1ir5g.png]
   image from [50]https://arxiv.org/pdf/1710.09511.pdf

   let   s also keep in mind bayesian methods that allow to track certainty
   of predictions. for neural networks we have this must be very hot topic
   for machine learning next year.

ai safety: it   s not a toy problem anymore

   after ai interpretability, second very important task to solve is
   vulnerability of modern machine learning algorithms         they can be
   easily fooled by a lot of things from adversarial attacks to stealing
   from api:
   [51]hype or reality? stealing machine learning models via prediction
   apis
   wired magazine just published an article with the interesting title how
   to steal an ai, where the author explores the   blog.bigml.com
   [52]attacking machine learning with adversarial examples
   adversarial examples are inputs to machine learning models that an
   attacker has intentionally designed to cause the   blog.openai.com

   for these things there is amazing initiative from ian goodfellow called
   [53]cleverhans. you think this is all? what about privacy of the data
   and training on encrypted data? check [54]amazing post from oxford phd
   student, where he shows example of building simple homomorphically
   encrypted neural network.

     we have to protect inputs for ai (private data), inner structure
     (from attacks) and what it learns (safety of it   s actions)

   and this is still not all problems of today   s ai. from mathematics
   point of view (especially in rl), algorithms still can   t explore
   environments safely, which means that if we are getting physical robots
   freedom to explore the world right now, they wouldn   t be able to avoid
   totally wrong or unsafe actions in training phase; we still can   t
   totally adapt our models to new distributions and situations         it may
   be difficult to recognize for example drawn objects with a neural net
   that was trained on real world objects; and lot of other problems that
   you can check in the following articles:
   [55]concrete ai safety problems
   we (along with researchers from berkeley and stanford) are co-authors
   on today's paper led by google brain researchers   blog.openai.com
   [56]specifying ai safety problems in simple environments | deepmind
   as ai systems become more general and more useful in the real world,
   ensuring they behave safely will become even more   deepmind.com

optimization: what is beyond gradients?

   i am a big fan of optimization theory and i think that one of the best
   reviews on optimization methods advances in 2017 was written by
   [57]sebastian ruder. here i want to recap what ways to improve general
   sgd + id26 pipeline we have:
     * [58]synthetic gradients and other ways to avoid expensive chain
       rule through deep networks
     * [59]evolutionary algorithms for id23,
       non-differentiable id168, for probable avoiding local
       minimums
     * [60]sgd improvements, learning rate and batch size scheduling
     * [61]learning to optimize         treating optimization problem as a
       learning problem itself
     * different spaces optimization         what if we train our network in
       [62]sobolev space?

   [0*zjntkkv6frjwgtjd.png]
   image from
   [63]http://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-
   rl/

   i believe that moving forward to solve non-differentiable functions
   optimization using evolutionary methods, id23 and
   learning optimization techniques will help us a lot to train ai models
   more efficiently.

geometrical deep learning for 3d and graphs

   i wasn   t really aware of this topic before a [64]speech on nips. of
   course i understood that real world data is laying in some more
   difficult space than r^d, and actually data and information really have
   their own geometry and topology. 3d objects can considered just as
   point clouds, but in fact it is a surface (manifold), a shape that has
   it   s own local and global math (differential geometry) especially in
   motion. or think about graphs, of course you can describe them in forms
   of some adjacency matrices, but you loose some local structure or some
   graphs you really would like to treat as graphs (molecules for
   example). other multidimensional objects like images, sounds, texts
   also can be and must be considered from geometrical point of view as
   well. i believe that we will have many interesting insights from
   research in this area, let   s just stick for now with a fact that

     all data has local and global geometry that we can   t avoid

   check the following link for some further details:
   [65]geometric deep learning
   in the last decade, deep learning approaches (e.g. convolutional neural
   networks and recurrent neural networks)
   allowed   geometricdeeplearning.com

conclusions

   i could talk about id99, id21, one
   shot learning, bayesian learning, differentiable computing and other
   things, but let   s be honest, these fields are not ready enough to
   evolve in something big in 2018. in bayesian learning we still are in
   stuck with math of sampling, differentiable computing is cool, but for
   what? id63s, differentiable neural computer by
   deepmind         where they are now? representation learning is already a
   core of any deep learning algorithm, it   s not even worth to write about
   it. one- and few-shot learning is also not really developed area and
   there are no well defined metrics or datasets. i expect topics i
   mentioned in this article to evolve in something hot and mature and
   have a lot of real-world applications in 2019   2020.

   in addition i would like to share main labs i suggest you to follow to
   know latest research news:
     * [66]openai
     * [67]deepmind
     * [68]ibm ai research
     * [69]berkley ai
     * [70]stanford ml group
     * [71]facebook research
     * [72]google research

   next article of the series will be for developers, i want to tell, what
   technologies, tools are already good and stable enough to be deployed
   in real world applications. thank you for attention and stay tuned!

   p.s.
   follow me also in [73]facebook for ai articles that are too short for
   medium, [74]instagram for personal stuff and [75]linkedin!

     * [76]machine learning
     * [77]artificial intelligence
     * [78]future
     * [79]research
     * [80]technology

   (button)
   (button)
   (button) 854 claps
   (button) (button) (button) 4 (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of alexandr honchar

[81]alexandr honchar

   medium member since oct 2018

                     developing ai for biosignal analysis and finance, consulting,
   giving public speeches and blogging. contact me to collaborate
   [82]rachnogstyle@gmail.com

     (button) follow
   [83]good audience

[84]good audience

   the front page of deep tech. don't miss the latest advancements in
   artificial intelligence, machine learning, and blockchain. straight
   from practitioners.

     * (button)
       (button) 854
     * (button)
     *
     *

   [85]good audience
   never miss a story from good audience, when you sign up for medium.
   [86]learn more
   never miss a story from good audience
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://blog.goodaudience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/8955df0caaf9
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://blog.goodaudience.com/ai-in-2018-for-researchers-8955df0caaf9&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://blog.goodaudience.com/ai-in-2018-for-researchers-8955df0caaf9&source=--------------------------nav_reg&operation=register
   8. https://blog.goodaudience.com/?source=logo-lo_0gmyb4v5mrkt---cb942d4b5d89
   9. https://blog.goodaudience.com/10-reasons-every-early-stage-company-needs-a-social-media-manager-995a96780204
  10. https://blog.goodaudience.com/dont-miss-the-latest-advancements-in-blockchain-crypto-and-artificial-intelligence-bbbf9d34b4a1
  11. https://blog.goodaudience.com/write-for-the-front-page-of-deep-tech-d63e2bc4fc63
  12. http://t.me/ravenprotocol
  13. https://blog.goodaudience.com/@alexrachnog
  14. https://medium.com/swlh/ai-in-2018-for-developers-2f01250d17c
  15. https://blog.goodaudience.com/media/748a06e9019942f2677bba917ef55804?postid=8955df0caaf9
  16. https://deepmind.com/blog/
  17. http://blog.openai.com/
  18. https://www.salesforce.com/products/einstein/ai-research/
  19. http://www.research.ibm.com/ai/
  20. https://distill.pub/
  21. https://arxiv.org/abs/1711.00043
  22. https://arxiv.org/abs/1710.11041
  23. http://aiindex.org/2017-report.pdf
  24. http://papers.nips.cc/paper/7014-temporal-coherency-based-criteria-for-predicting-video-frames-using-deep-multi-stage-generative-adversarial-networks
  25. http://papers.nips.cc/paper/7028-unsupervised-learning-of-disentangled-representations-from-video
  26. http://moments.csail.mit.edu/
  27. https://research.google.com/youtube8m/
  28. http://www.robots.ox.ac.uk/~vgg/decathlon/
  29. https://home-platform.github.io/
  30. https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html
  31. https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html
  32. https://deepmind.com/blog/alphago-zero-learning-scratch/
  33. https://www.deepstack.ai/
  34. https://blog.openai.com/dota-2/
  35. https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/
  36. https://github.com/alibaba/gym-starcraft
  37. https://blog.goodaudience.com/media/530eb2f9533e53c155e61d960a940711?postid=8955df0caaf9
  38. https://blog.openai.com/competitive-self-play/
  39. https://blog.openai.com/learning-to-model-other-minds/
  40. https://blog.openai.com/learning-to-cooperate-compete-and-communicate/
  41. https://code.facebook.com/posts/1686672014972296/deal-or-no-deal-training-ai-bots-to-negotiate/
  42. https://stanfordmlgroup.github.io/projects/chexnet/
  43. https://www.ke.tu-darmstadt.de/lehre/arbeiten/master/2015/zilke_jan.pdf
  44. http://cs231n.github.io/understanding-id98/
  45. http://www-nlpir.nist.gov/projects/tvpubs/tv14.papers/sri_aurora.pdf
  46. http://www.cnbc.cmu.edu/~tai/microns_papers/zhu_aotpami.pdf
  47. https://arxiv.org/pdf/1603.08507.pdf
  48. https://arxiv.org/pdf/1603.08507.pdf
  49. https://arxiv.org/pdf/1710.09511.pdf
  50. https://arxiv.org/pdf/1710.09511.pdf
  51. https://blog.bigml.com/2016/09/30/hype-or-reality-stealing-machine-learning-models-via-prediction-apis/
  52. https://blog.openai.com/adversarial-example-research/
  53. http://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html
  54. https://iamtrask.github.io/2017/03/17/safe-ai/
  55. https://blog.openai.com/concrete-ai-safety-problems/
  56. https://deepmind.com/blog/specifying-ai-safety-problems/
  57. http://ruder.io/deep-learning-optimization-2017
  58. https://deepmind.com/research/publications/understanding-synthetic-gradients-and-decoupled-neural-interfaces/
  59. https://blog.openai.com/evolution-strategies/
  60. http://ruder.io/deep-learning-optimization-2017/
  61. http://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/
  62. https://papers.nips.cc/paper/7015-sobolev-training-for-neural-networks.pdf
  63. http://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/
  64. https://www.youtube.com/watch?v=lvmjbxzyop0
  65. http://geometricdeeplearning.com/
  66. http://openai.com/
  67. https://deepmind.com/
  68. http://www.research.ibm.com/ai/
  69. http://bair.berkeley.edu/
  70. https://stanfordmlgroup.github.io/
  71. https://research.fb.com/
  72. https://research.googleblog.com/
  73. https://www.facebook.com/rachnogstyle.blog
  74. http://instagram.com/rachnogstyle
  75. https://www.linkedin.com/in/alexandr-honchar-4423b962/
  76. https://blog.goodaudience.com/tagged/machine-learning?source=post
  77. https://blog.goodaudience.com/tagged/artificial-intelligence?source=post
  78. https://blog.goodaudience.com/tagged/future?source=post
  79. https://blog.goodaudience.com/tagged/research?source=post
  80. https://blog.goodaudience.com/tagged/technology?source=post
  81. https://blog.goodaudience.com/@alexrachnog
  82. mailto:rachnogstyle@gmail.com
  83. https://blog.goodaudience.com/?source=footer_card
  84. https://blog.goodaudience.com/?source=footer_card
  85. https://blog.goodaudience.com/
  86. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  88. https://blog.goodaudience.com/@alexrachnog?source=post_header_lockup
  89. https://distill.pub/
  90. http://moments.csail.mit.edu/
  91. https://research.google.com/youtube8m/
  92. http://www.robots.ox.ac.uk/~vgg/decathlon/
  93. https://home-platform.github.io/
  94. https://blog.openai.com/dota-2/
  95. https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/
  96. https://blog.bigml.com/2016/09/30/hype-or-reality-stealing-machine-learning-models-via-prediction-apis/
  97. https://blog.openai.com/adversarial-example-research/
  98. https://blog.openai.com/concrete-ai-safety-problems/
  99. https://deepmind.com/blog/specifying-ai-safety-problems/
 100. http://geometricdeeplearning.com/
 101. https://medium.com/p/8955df0caaf9/share/twitter
 102. https://medium.com/p/8955df0caaf9/share/facebook
 103. https://blog.goodaudience.com/@alexrachnog?source=footer_card
 104. https://medium.com/p/8955df0caaf9/share/twitter
 105. https://medium.com/p/8955df0caaf9/share/facebook
