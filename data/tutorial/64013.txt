   #[1]github [2]recent commits to coral:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]6
     * [35]star [36]76
     * [37]fork [38]23

[39]visionlearninggroup/[40]coral

   [41]code [42]issues 3 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   correlation alignment for id20
     * [47]26 commits
     * [48]2 branches
     * [49]0 releases
     * [50]fetching contributors

   branch: master (button) new pull request
   [51]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/v
   [52]download zip

downloading...

   want to be notified of new releases in visionlearninggroup/coral?
   [53]sign in [54]sign up

launching github desktop...

   if nothing happens, [55]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [56]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [57]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [58]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [59]permalink
   type      name     latest commit message commit time
        failed to load latest commit information.
        [60]code
        [61]dataset
        [62]readme.md

readme.md

correlation alignment for id20

   welcome to the website of [63]coral framework. correlation alignment or
   coral in short is a simple yet effective method for unsupervised domain
   adaptation. coral minimizes domain shift by aligning the second-order
   statistics of source and target distributions, without requiring any
   target labels. there are mainly three parts of the coral framework. in
   the [64]coral paper (reference 1 in the citation section below), we
   describe a solution that applies a linear transformation to source
   features to align them with target features before classifier training.
   for linear classifiers, we propose to equivalently apply coral to the
   classifier weights, leading to added efficiency when the number of
   classifiers is small but the number and dimensionality of target
   examples are very high. the resulting [65]coral linear discriminant
   analysis (coral-lda) (reference 2 in the citation section below)
   outperforms lda by a large margin on standard id20
   benchmarks. finally, we extend coral to learn a nonlinear
   transformation that aligns correlations of layer activations in deep
   neural networks (dnns). the resulting [66]deep coral (reference 3 in
   the citation section below) approach works seaid113ssly with dnns and
   achieves state-of-the-art performance on standard benchmark datasets.

source code and data

    1. coral: the source code is in code/coral_source_code.zip, the data
       used in reference 1 is included in /dataset folder
    2. coral-lda: the code and data can be found [67]here. as can be seen
       from the title of the paper (from virtual to reality: fast
       adaptation of virtual object detectors to real domains), another
       major contribution is ''from virtual to reality''. in this paper,
       we ''(1) we show that freely available non-photorealistic 3d models
       can be used to train 2d object detectors, in a first such study
       that evaluates across a large variety of categories; (2) we
       eliminate the need to generate images that match real-image
       statistics by utilizing domain-specific image statistics; (3) we
       present a supervised adaptation approach, and show improved results
       on a multi-domain dataset.'' please refer to [68]this webpage for
       more detailed information.
    3. deep-coral: the source code is in code/d-coral.zip, sample
       protofiles and parameters can be found in
       code/d-coral_office31.zip, the data used is the standard office31
       dataset

tips for (visual) id20

   the following tips are based on my personal experience and discussions
   (in person or via email) with others (special thanks to prof. mingsheng
   long). i found them to be useful to design/apply id20
   algorithms yet seldom mentioned/explained in the literature. i put them
   here and hope it helps :-)
    1. data processing for id20
     __________________________________________________________________

   data processing is very importrant for id20 applications
   even though it is seldom mentioned (or not emphasised enough) in the
   literature. it is extremely true for ''shallow'' approaches as many of
   them (i.e., coral) are doing asymmetric transformation (applying
   transformation to source/target only). for example, suppose we
   normalize both the source and target to have the same distribution
   (i.e., zero mean and unit variance). then after the asymmetric
   transformation, the distribution/id172 of the transformed
   source might be different to the target. to achieve good performance on
   the target data, the distribution/id172 on which the
   classifier/detector is trained on need to be as close to the target as
   possible. we used the same trick (please refer to the id166_accuracy
   function in ex_coral.m) as sa to ensure this. the most commonly used
   data pre-processing approach for visual id20 is l1
   id172 and zscore (the one used in the source code of coral, sa,
   gfk, etc.). l2 id172 also works pretty well (or even better
   than l1/zscore) on deep features (for the ''shallow'' methods). for
   deep methods, as the raw image is feeded into the network and
   same/similar transformations are applied to both source and target
   data, there is little need of extra data processing.
    2. id20 equilibrium
     __________________________________________________________________

   as explicitly mentioned in [69]deep coral, there is an equilibrium
   between aligning the distributions (between the source and target) and
   keeping the discriminative power of the features (i.e., high
   classification accuracy). ''minimizing the classification loss itself
   is likely to lead to overfitting to the source domain, causing reduced
   performance on the target domain. on the other hand, minimizing the
   coral loss alone might lead to degenerated features. for example, the
   network could project all of the source and target data to a single
   point, making the coral loss trivially zero.'' this equilibrium is also
   implicitly used in many ''shallow'' methods in a different way. for
   example, constraining the transformation to be linear can be think of
   an implicit way of id173.
    3. parameter/hyper-parameter tuning
     __________________________________________________________________

   for the most common unsupervised id20 scenario where there
   is no labeled target data during training, traditional cross-validation
   based paramter/hyper-paremeter tuning approaches are impossible. in
   practice, the parameters/hyper-paramters are usually set to certain
   number empricially. for coral, there is only one papameter --
   id173 parameter (  ) which was set to 1 empricically. for deep
   coral, the main parameter/hyper-parameter (other parameters like the
   learning rate, weight decay were set in the same way as classical
   fine-tuning procedures) is the weight of coral loss. as mentioned in
   the deep coral paper, this parameter is set in this way: ''the weight
   of the coral loss (  ) is set in such way that at the end of training
   the classification loss and coral loss are roughly the same. it seems
   be a reasonable choice as we want to have a feature representation that
   is both discriminative and also minimizes the distance between the
   source and target domains.''

citation

   i highly recommend you to read the [70]book chapter for a compresensive
   introduction of the coral framework. each individual paper listed in
   this section talks about one part of the framework only.

   if you find this project is useful in your research, please consider
   citing:

   reference 1: [71]coral
@inproceedings{coral,
  author={baochen sun and jiashi feng and kate saenko},
  title={return of frustratingly easy id20},
  booktitle={aaai},
  year={2016}
}

   reference 2: [72]coral-lda
@inproceedings{coral-lda,
    author={baochen sun and kate saenko},
    title={from virtual to reality: fast adaptation of virtual object detectors
to real domains},
    booktitle={bmvc},
    year={2014}
}

   reference 3: [73]deep coral
@inproceedings{dcoral,
  author={baochen sun and kate saenko},
  title={deep coral: correlation alignment for deep id20},
  booktitle={eccv 2016 workshops},
  year={2016}
}

faq

   please send your further questions to baochens at gmail dot com

     *    2019 github, inc.
     * [74]terms
     * [75]privacy
     * [76]security
     * [77]status
     * [78]help

     * [79]contact github
     * [80]pricing
     * [81]api
     * [82]training
     * [83]blog
     * [84]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [85]reload to refresh your
   session. you signed out in another tab or window. [86]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/visionlearninggroup/coral/commits/master.atom
   3. https://github.com/visionlearninggroup/coral#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/visionlearninggroup/coral
  32. https://github.com/join
  33. https://github.com/login?return_to=/visionlearninggroup/coral
  34. https://github.com/visionlearninggroup/coral/watchers
  35. https://github.com/login?return_to=/visionlearninggroup/coral
  36. https://github.com/visionlearninggroup/coral/stargazers
  37. https://github.com/login?return_to=/visionlearninggroup/coral
  38. https://github.com/visionlearninggroup/coral/network/members
  39. https://github.com/visionlearninggroup
  40. https://github.com/visionlearninggroup/coral
  41. https://github.com/visionlearninggroup/coral
  42. https://github.com/visionlearninggroup/coral/issues
  43. https://github.com/visionlearninggroup/coral/pulls
  44. https://github.com/visionlearninggroup/coral/projects
  45. https://github.com/visionlearninggroup/coral/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/visionlearninggroup/coral/commits/master
  48. https://github.com/visionlearninggroup/coral/branches
  49. https://github.com/visionlearninggroup/coral/releases
  50. https://github.com/visionlearninggroup/coral/graphs/contributors
  51. https://github.com/visionlearninggroup/coral/find/master
  52. https://github.com/visionlearninggroup/coral/archive/master.zip
  53. https://github.com/login?return_to=https://github.com/visionlearninggroup/coral
  54. https://github.com/join?return_to=/visionlearninggroup/coral
  55. https://desktop.github.com/
  56. https://desktop.github.com/
  57. https://developer.apple.com/xcode/
  58. https://visualstudio.github.com/
  59. https://github.com/visionlearninggroup/coral/tree/339844fa3336b74a51a170b6c2848056931c0311
  60. https://github.com/visionlearninggroup/coral/tree/master/code
  61. https://github.com/visionlearninggroup/coral/tree/master/dataset
  62. https://github.com/visionlearninggroup/coral/blob/master/readme.md
  63. https://arxiv.org/abs/1612.01939
  64. http://www.aaai.org/ocs/index.php/aaai/aaai16/paper/download/12443/11842
  65. https://github.com/umasslowell-vision-group/bmvc2014/raw/master/bmvc14_paper.pdf
  66. https://arxiv.org/abs/1607.01719
  67. https://github.com/umasslowell-vision-group/from-virtual-to-reality
  68. https://github.com/umasslowell-vision-group/from-virtual-to-reality
  69. https://arxiv.org/abs/1607.01719
  70. https://arxiv.org/abs/1612.01939
  71. http://www.aaai.org/ocs/index.php/aaai/aaai16/paper/download/12443/11842
  72. https://github.com/umasslowell-vision-group/bmvc2014/raw/master/bmvc14_paper.pdf
  73. https://arxiv.org/abs/1607.01719
  74. https://github.com/site/terms
  75. https://github.com/site/privacy
  76. https://github.com/security
  77. https://githubstatus.com/
  78. https://help.github.com/
  79. https://github.com/contact
  80. https://github.com/pricing
  81. https://developer.github.com/
  82. https://training.github.com/
  83. https://github.blog/
  84. https://github.com/about
  85. https://github.com/visionlearninggroup/coral
  86. https://github.com/visionlearninggroup/coral

   hidden links:
  88. https://github.com/
  89. https://github.com/visionlearninggroup/coral
  90. https://github.com/visionlearninggroup/coral
  91. https://github.com/visionlearninggroup/coral
  92. https://help.github.com/articles/which-remote-url-should-i-use
  93. https://github.com/visionlearninggroup/coral#correlation-alignment-for-domain-adaptation
  94. https://github.com/visionlearninggroup/coral#source-code-and-data
  95. https://github.com/visionlearninggroup/coral#tips-for-visual-domain-adaptation
  96. https://github.com/visionlearninggroup/coral#citation
  97. https://github.com/visionlearninggroup/coral#faq
  98. https://github.com/
