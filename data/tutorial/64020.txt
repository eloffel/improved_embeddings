   #[1]manning    feed [2]ride the phoenix [3]getting started with ethereum
   blockchain: a first look at decentralized applications [4]alternate
   [5]alternate

   ____________________ search
   [6]manning

     * [7]home
     * [8]free ebooks
     * [9]articles
     * [10]media
          + [11]slideshares
          + [12]animated gifs
          + [13]videos
     * [14]all content by topic
          + [15]data science
          + [16]game development
          + [17]java
          + [18]microsoft / .net
          + [19]mobile technology
          + [20]programming
          + [21]software engineering
          + [22]web development
     * [23]manning.com

     * [24]home
     * [25]free ebooks
     * [26]articles
     * [27]media
          + [28]slideshares
          + [29]animated gifs
          + [30]videos
     * [31]all content by topic
          + [32]data science
          + [33]game development
          + [34]java
          + [35]microsoft / .net
          + [36]mobile technology
          + [37]programming
          + [38]software engineering
          + [39]web development
     * [40]manning.com

[41]what does deep learning contribute to search

   from [42]deep learning for search by tommaso teofili

   if you   ve ever worked on designing, implementing or configuring a
   search engine, you   ve faced the problem of having a solution that
   adapts to your data; deep learning helps provide solutions to these
   problems which are accurately based on the data, not on fixed rules or
   algorithms.
     __________________________________________________________________

   save 37% on [43]deep learning for search. just enter code fccteofili
   into the discount code box at checkout at [44]manning.com.
     __________________________________________________________________

   what deep learning can do for search

   with the help of deep learning (or dl) algorithms, the search engine
   can:
     * provide more relevant results to its end users, satisfying users
       with the results    quality
     * search through binary contents like images the same way we search
       over text; think of this as being able to search for an image with
       the phrase    picture of a leopard hunting an impala    (and you   re not
       google)
     * serve content to users speaking in different languages, allowing
       more users to access the data in the search system
     * become more sensitive to the data it serves, which means less
       chance to have queries which give no results

   the quality of search results is crucial for end users. one thing a
   search engine should do well is finding out which of the possibly
   matching search results is most useful for a specific user   s
   information need. well-ranked search results allow users to find the
   important results easier and faster, which is why we put a lot of
   emphasis on the topic of relevant results. in real life this can make a
   huge difference, in fact, according to an article published in forbes
   magazine    [b]y providing better search results, netflix estimates that
   it is avoiding canceled subscriptions that would reduce its revenue by
   $1b annually.   
   ([45]www.forbes.com/sites/louiscolumbus/2017/07/09/mckinseys-state-of-m
   achine-learning-and-ai-2017/#27fe02c375b6)

   deep neural networks can help by automatically tweaking the end user
   query under the hood based on past user queries or based on the search
   engine contents. people are used to working with web search engines to
   retrieve images. if you search for    pictures of angry lions    on google,
   for instance, you   ll get strongly relevant images. before the advent of
   deep learning, such images had to be decorated with metadata (data
   about data) describing their contents before being put into the search
   engine. and that metadata was usually typed by a human. deep neural
   networks can abstract a representation of an image which captures
   what   s in there to prevent the need for human intervention to put an
   image description in the search engine.

   for scenarios like web search (searching all websites over the
   internet) users are global, and it   s best if they can search in their
   own native languages. additionally, the search engine could pick user
   profiles and return them results in their language, even if they search
   in english; this is a common scenario for tech queries, because lots of
   content is produced in english. an interesting application of deep
   neural networks is called id4   a set of
   techniques that use deep neural networks to translate a piece of text
   from a source language into another target language.

   another exciting prospect is the possibility of using deep neural
   networks to let the search engine generate information instead of
      just    retrieving search results (deep learning relevance: creating
   relevant information   as opposed to retrieving it   see
   arxiv.org/pdf/1606.07660.pdf). you could even aggregate all the above
   ideas and build a search engine serving both text and images seaid113ssly
   to users globally which, instead of returning search results, returns
   one single piece of text or image.

   the above applications are examples of what we call neural search, and,
   as you can imagine, they have the potential to revolutionize the way we
   work and use search engines. to take advantage of the potential of deep
   neural networks, people interested in computer science, particularly in
   the fields of natural language processing, id161, and
   informational retrieval, need to know how such artificial neural
   networks work in practice.

   the goal of this article is to show you how you might use deep learning
   in the context of search engines by teaching some deep learning
   algorithms applied to search problems, even if you   re not going to
   build the next google search, you should see how the potential of dl
   techniques within small / medium sized search engines could provide a
   better experience to your users.

   i run my neural search examples on top of open source software written
   in java with the help of apache lucene (lucene.apache.org), an
   information retrieval library, and deeplearning4j (deeplearning4j.org),
   a deep learning library. at the time of writing, deeplearning4j is a
   widely used framework for deep learning in the enterprise communities,
   and it   s part of the eclipse foundation. it also has a good adoption
   because of integrations with popular big data frameworks like apache
   spark. other deep learning frameworks exist, such as tensorflow (from
   google), which is popular among the python and research communities.
   new tools are invented almost daily, and i decided to focus on a
   relatively easy-to-use dl framework that can be easily integrated with
   lucene, which is one of the most widely adopted search libraries for
   the jvm.

   now let   s have a look at the problems search engines try to solve and,
   correspondingly, the most common techniques used. this allows you to
   learn the basics of how text is analyzed, ingested, and retrieved
   within a search engine, to familiarize you with how queries hit search
   results as well as some fundamentals on solving the problem of
   returning the relevant results first. we   ll also uncover the weaknesses
   inherent to common search techniques. this sets up the basis for the
   discussion on what deep learning can be used for in the context of
   search. we   ll look at which tasks deep learning can help to solve and
   define the practical implications of its applications in the search
   field, to understand what we can expect and also what we can   t expect
   from neural search in real life scenarios.

   deep learning to the rescue

   let   s start learning about deep learning which can help us create
   smarter search engines.

   in the past, a key difficulty in id161 (a field in computer
   science that deals with processing and understanding visual data like
   pictures or videos), when working with images, was that it was hardly
   possible to come up with an image representation containing information
   about the enclosed objects and visual structures. deep learning helped
   to fix this difficulty with the creation of a special type of deep
   neural network that could learn image representation incrementally, one
   abstraction at a time, as shown in the figure below.
     __________________________________________________________________

   figure 1 learning image abstractions incrementally
     __________________________________________________________________

   deep learning is a subfield of machine learning which focuses on
   learning deep representations of text, images, or data by learning
   successive abstractions of increasingly meaningful representations. it
   does this by using deep neural networks (see a deep neural network with
   three hidden layers in the picture below).
     __________________________________________________________________

   figure 2 a deep feed forward neural network with three hidden layers
     __________________________________________________________________

   at each step (or layer of the network), such deep neural networks are
   able to capture increasingly more complex structures in the data. it
   isn   t chance that id161 is one of the fields that fostered
   the development and research of representation-learning algorithms for
   images.

   researchers discovered that it makes sense to use such deep networks
   such as those with highly compositional data (see:
   cbmm.mit.edu/publications/when-and-why-are-deep-networks-better-shallow
   -ones), which means that they can help immensely things that are formed
   by smaller parts of similar constituents. images and text are excellent
   examples of compositional data, as one can divide them into smaller
   units incrementally (e.g. text paragraphs sentences words).

   though there are many different ways a neural network can be
   architected, neural networks are commonly composed by:
     * a set of neurons
     * a set of connections between all or some neurons
     * a weight (a real number) for each directed connection between two
       neurons
     * one or more functions that map how each neuron receives and
       propagates signals towards its outgoing connections
     * optionally, a set of layers that group sets of neurons having
       similar connectivity in the neural network

   in the above figure we can identify twenty neurons organized in a set
   of five layers. each neuron within each layer   s connected with all the
   neurons in the layers nearby (both the previous and the following
   layers), except for the first (blue) and last (green) layers.
   conventionally, information starts flowing within the network from left
   to right, and the first layer which receives the inputs is called the
   input layer, as opposed to the last layer, called the output layer,
   which outputs the results of the neural network. the (red) layers in
   between are called hidden layers.

   imagine that we could apply the same approach on text to learn
   representations of documents that capture increasingly higher
   abstractions within a document. deep learning-based techniques exist
   for such tasks, and over time these algorithms are becoming smarter. we
   can use them to extract word, sentence, paragraph, and document
   representations that can capture surprisingly interesting semantics. in
   fact, when using a neural network algorithm to learn word
   representations within a certain set of text documents, you   ll be able
   to see that closely related words lie near each other in the vector
   space. think about creating a point on a two-dimensional plot for each
   word contained in a piece of text and see how similar or closely
   related words lie close to one another, it   s achieved by using a neural
   network algorithm for learning word representations called id97.
     __________________________________________________________________

   figure 3 word vectors derived from papers on id97
     __________________________________________________________________

   notice that the words information and retrieval lie close, similarly
   id97 and skip-gram, terms that both relate to (shallow) neural
   network algorithms used to extract word vectors, are near each other
   too.

   one of the key ideas of neural search is to use such representations in
   order to improve the effectiveness of search engines. it   d be nice if
   we had a retrieval model that relies on word and document vectors (also
   called embeddings) with the above capabilities, to calculate and use
   document and word similarities efficiently by looking at the    nearest
   neighbors.   
     __________________________________________________________________

   figure 4 a neural search application: using word representations
   generated by a deep neural network to provide more relevant results
     __________________________________________________________________

   in this picture we can see that we use a deep neural network to create
   word representations of the words contained in the indexed documents
   and we put them back into the search engine as we   ll use them to adjust
   the search results. it   s important to remember the importance of the
   context when compared to the complexity of expressing and understanding
   information needs via text queries. deep representations of text are
   often built by using the context in which a certain word / sentence /
   document appears in order to infer an appropriate representation.

   let   s look at the above example to briefly explain how deep learning
   algorithms can help get better results with relevance. considering the
   table comparing queries and corresponding search results from the
   previous section and taking the two queries latest breakthroughs in
   artificial intelligence and latest breakthroughs in ai, let   s assume
   we   re using the vector space model. in such models the similarity
   between queries and documents can vary a lot based on the text analysis
   chain. this problem doesn   t affect vector representations of text
   generated with some recent neural network based algorithm. although we
   could place artificial intelligence and ai far apart in a vector space
   model, they   ll likely be placed close when plotted using word
   representations generated by neural nets. with such simple change, we
   added some relevance boost to the search engine via more semantically
   grounded representations of words.

   sidebar: deep learning vs deep neural networks

   an important distinction has to be made: deep learning is mostly about
   learning representation of word, text, documents, images in a deep
   fashion. deep neural networks have a wider usage and are used, for
   example, in language modelling, machine translation, etc. besides
   learning representations, there are a number of information retrieval
   tasks that deep neural networks can help to solve.

   let   s look at some practical implications of making search engines and
   neural networks work together.

   index please meet neuron

   an id158 can learn to predict outputs based on a
   training set (supervised learning) or perform unsupervised learning (no
   information about correct outputs is given) in order to extract
   patterns and / or learn representations. a search engines    typical
   workflow involves indexing and searching content; notably, such tasks
   that can happen in parallel. although this may sound like a
   technicality at this point, the way we integrate a search engine with a
   machine learning algorithm and output model is important in principle
   because it impacts neural search design effectiveness and performance.
   we can have a super accurate system, but if it   s slow no one will use
   it!

   neural network training

   in order to use its powerful capabilities of learning we need to train
   a neural net. training a network like the one shown in the previous
   section via supervised learning means providing some inputs to the
   network input layer, comparing the network (predicted) outputs with the
   known (target) outputs and letting the network learn from the
   discrepancies between predicted and target outputs. neural networks can
   easily represent many interesting mathematical functions; it   s one of
   the reasons why they can be highly accurate. such mathematical
   functions are governed by the connections    weights and neurons   
   id180. a neural network learning algorithm takes the
   discrepancies between desired and actual outputs and adjusts each
   layer   s weights in order to reduce the output error in the future. if
   you feed enough data to the network it can reach a tiny error rate and
   perform extremely well. id180 have an impact on the
   neural network capability to perform predictions and on how quickly
   they learn.

   the most famous neural network learning algorithm is called
   id26. given desired and actual outputs, the algorithm
   backpropagates each neuron   s error contribution and consequently
   adjusts its internal state on each neuron connections, one layer at a
   time, from output to input. this is a high-level description of how
   id26 algorithm works.

   the states for each layer together with its id180 define
   a machine learning model for neural networks. now that we have a
   primary understanding of how neural nets learn, we need to decide how
   to plug into the search engine. although design decisions can vary
   depending on the purpose neural networks are used for, training usually
   needs:
     * a non-trivial amount of time
     * a lot of data

   for these reasons we can identify a few high-level solutions. search
   engines can receive data to be indexed continuously; because new
   content is added, existing content is updated or even deleted. although
   it   s relatively easy and quick to support this within the search
   engine, sometimes machine learning algorithms create models that can   t
   be adapted quickly as data changes. therefore, it may be required to
   perform training again from scratch for the model to stay consistent
   with the new data in the search engine.

   a good choice in such scenarios is to look for online learning
   algorithms that can cope with data that changes without requiring
   training from scratch. when this isn   t possible we can mitigate the
   inconsistency between indexed data and the neural network model if we:
     *    unplug    the model from the prediction phase
     *    discount    the outputs of the neural network prediction by a
       certain rate, depending on how much data we expect to be
       inconsistent

   model storage

   search engine central data structures are inverted indexes; they
   contain: posting lists, term dictionaries, information about term
   positions and other such data. a neural network model can be composed
   by a matrix of hundreds of thousands of rows/columns. if we don   t store
   such a model within the index or somewhere on a disk we   ll need to
   retrain it upon restart of the system; given the high cost of training
   this is usually discouraged.

   in some cases, like in the previous example of using a neural network
   for learning to rank, it   s hard to find a correlation between any
   entity stored in the inverted index and the learned model. on the other
   hand, for example, when learning representation of words, the neural
   network model   s usually composed of multiple sets of weights, and one
   of these sets outlines a matrix where each row can be mapped to a word.
   it makes sense to relate word vectors to terms in the inverted index.
   that means we may decide to    split    the machine learning model to store
   the id27 together with its term within the index.

   table 1 inverted index table with id27s

   such    tricks    allow for efficient storage and retrieval of portions of
   the model on demand and don   t require additional infrastructures to
   maintain it.

   the promises of neural search

   neural search is about integrating deep learning and deep neural
   networks into search at different stages. deep learning   s capability of
   capturing deep semantics within the generated representations allows us
   to obtain relevance models and ranking functions that adapt well to
   underlying data. we   ll be able to learn image representations which
   give us surprising results in image search. simple similarity measures
   like cosine distance can be applied to learned representations to
   capture semantically similar words, sentences, paragraphs, etc.; this
   has a number of applications like in the text analysis phase or in
   recommending similar documents. at the same time, deep neural networks
   can do more than    just    learning representations; they can learn to
   generate or translate text or learn how to optimize search engine
   performance.

   all the above sounds awesome, but beware that you can   t throw neural
   networks at your search engine and expect it to be automatically
   perfect. every decision has to be taken in context and neural networks
   have some limitations, including the cost of training, upgrading
   models, and more. but applying neural search to your search engine is a
   great way to make it better for your users. it also makes for a
   fascinating journey for the search engineers, who get to explore the
   beauty of neural networks.
     __________________________________________________________________

   if you want to learn more about the book, check it out on livebook
   [46]here and see this [47]slide deck.
     __________________________________________________________________

manning publications

   manning's focus is on computing titles at professional levels. we care
   about the quality of our books. we work with our authors to coax out of
   them the best writing they can produce. we consult with technical
   experts on book proposals and manuscripts, and we may use as many as
   two dozen reviewers in various stages of preparing a manuscript. the
   abilities of each author are nurtured to encourage him or her to write
   a first-rate book.
   [48]author archive [49]author website [50]support@manning.com
   [51]@manningbooks on twitter

   january 29, 2018

   [52]articles, [53]data

   [54]deep-learning, [55]deep-learning-for-search, [56]search, [57]search
   engines
   [58]previous post [59]next post

deal of the day

   enter in the promotional code box when you check out.
   ____________________ search

tags

   [60].net [61]algorithms [62]amazon [63]amazon web services [64]api
   [65]aws [66]aws-lambda [67]big data [68]c-sharp [69]cloud
   [70]cloud-computing [71]concurrency [72]containers [73]css [74]data
   [75]data science [76]deep-learning [77]docker [78]functional
   programming [79]game development [80]go [81]ios [82]java [83]javascript
   [84]jvm [85]kubernetes [86]machine learning [87]microservice
   [88]microservices [89]mobile development [90]node.js
   [91]powered-by-javascript [92]powered-by-javascript-2015
   [93]programming [94]python [95]react [96]reactive [97]scala [98]search
   [99]serverless [100]spark [101]spring [102]swift [103]testing [104]web
   development

search form

   ____________________ search

subjects

     * [105]animation
     * [106]art
     * [107]articles
     * [108]big data
     * [109]business
     * [110]cloud computing
     * [111]data
     * [112]data science
     * [113]databases
     * [114]design
     * [115]development
     * [116]devices
     * [117]devops
     * [118]engineering
     * [119]free ebooks
     * [120]game development
     * [121]general
     * [122]graphics
     * [123]internet
     * [124]interview
     * [125]iphone
     * [126]java
     * [127]java/jvm
     * [128]javascript
     * [129]linux
     * [130]mac
     * [131]mental model graphic
     * [132]microsoft / .net
     * [133]mobile technology
     * [134]next generation databases
     * [135]operations & cloud
     * [136]powered by javascript
     * [137]programming
     * [138]programming languages
     * [139]python
     * [140]r
     * [141]slideshare
     * [142]software
     * [143]software development
     * [144]software engineering
     * [145]technology
     * [146]video
     * [147]web
     * [148]web development

recent content

     * [149]modern data solutions with python
     * [150]models as a tool for deeper insight
     * [151]armoring lambda for production
     * [152]the inner workings of spark
     * [153]the magic of graphs and machine learning

featured content

   [154]animated gifs

      2019 [155]manning     design [156]credits
     * [157]subscribe to the manningnewsletter
     * [158]manning onfacebook
     * [159]manning ontwitter

   [160]up    

references

   visible links
   1. https://freecontent.manning.com/feed/
   2. https://freecontent.manning.com/ride-the-phoenix/
   3. https://freecontent.manning.com/a-first-look-at-decentralized-applications/
   4. https://freecontent.manning.com/wp-json/oembed/1.0/embed?url=https://freecontent.manning.com/what-does-deep-learning-contribute-to-search/
   5. https://freecontent.manning.com/wp-json/oembed/1.0/embed?url=https://freecontent.manning.com/what-does-deep-learning-contribute-to-search/&format=xml
   6. https://freecontent.manning.com/
   7. https://freecontent.manning.com/
   8. https://freecontent.manning.com/free-ebooks/
   9. https://freecontent.manning.com/articles/
  10. https://freecontent.manning.com/animated-gifs/
  11. https://freecontent.manning.com/slideshare/
  12. https://freecontent.manning.com/animated-gifs/
  13. https://freecontent.manning.com/video/
  14. https://freecontent.manning.com/what-does-deep-learning-contribute-to-search/
  15. https://freecontent.manning.com/data-science/
  16. https://freecontent.manning.com/game-development/
  17. https://freecontent.manning.com/java/
  18. https://freecontent.manning.com/microsoft-dotnet/
  19. https://freecontent.manning.com/mobile-technology/
  20. https://freecontent.manning.com/programming/
  21. https://freecontent.manning.com/software-engineering/
  22. https://freecontent.manning.com/web-development/
  23. http://manning.com/
  24. https://freecontent.manning.com/
  25. https://freecontent.manning.com/free-ebooks/
  26. https://freecontent.manning.com/articles/
  27. https://freecontent.manning.com/animated-gifs/
  28. https://freecontent.manning.com/slideshare/
  29. https://freecontent.manning.com/animated-gifs/
  30. https://freecontent.manning.com/video/
  31. https://freecontent.manning.com/what-does-deep-learning-contribute-to-search/
  32. https://freecontent.manning.com/data-science/
  33. https://freecontent.manning.com/game-development/
  34. https://freecontent.manning.com/java/
  35. https://freecontent.manning.com/microsoft-dotnet/
  36. https://freecontent.manning.com/mobile-technology/
  37. https://freecontent.manning.com/programming/
  38. https://freecontent.manning.com/software-engineering/
  39. https://freecontent.manning.com/web-development/
  40. http://manning.com/
  41. https://freecontent.manning.com/what-does-deep-learning-contribute-to-search/
  42. https://www.manning.com/books/deep-learning-for-search
  43. https://livebook.manning.com/#!/book/deep-learning-for-search/chapter-1/
  44. https://www.manning.com/
  45. http://www.forbes.com/sites/louiscolumbus/2017/07/09/mckinseys-state-of-machine-learning-and-ai-2017/#27fe02c375b6
  46. https://livebook.manning.com/#!/book/deep-learning-for-search/chapter-1/
  47. https://www.slideshare.net/manningbooks/deep-learning-for-search
  48. https://freecontent.manning.com/author/manning/
  49. http://manning.com/
  50. mailto:support@manning.com
  51. http://www.twitter.com/manningbooks
  52. https://freecontent.manning.com/articles/
  53. https://freecontent.manning.com/data/
  54. https://freecontent.manning.com/tag/deep-learning/
  55. https://freecontent.manning.com/tag/deep-learning-for-search/
  56. https://freecontent.manning.com/tag/search/
  57. https://freecontent.manning.com/tag/search-engines/
  58. https://freecontent.manning.com/ride-the-phoenix/
  59. https://freecontent.manning.com/a-first-look-at-decentralized-applications/
  60. https://freecontent.manning.com/tag/net/
  61. https://freecontent.manning.com/tag/algorithms/
  62. https://freecontent.manning.com/tag/amazon/
  63. https://freecontent.manning.com/tag/amazon-web-services/
  64. https://freecontent.manning.com/tag/api/
  65. https://freecontent.manning.com/tag/aws/
  66. https://freecontent.manning.com/tag/aws-lambda/
  67. https://freecontent.manning.com/tag/big-data/
  68. https://freecontent.manning.com/tag/c-sharp/
  69. https://freecontent.manning.com/tag/cloud/
  70. https://freecontent.manning.com/tag/cloud-computing/
  71. https://freecontent.manning.com/tag/concurrency/
  72. https://freecontent.manning.com/tag/containers/
  73. https://freecontent.manning.com/tag/css/
  74. https://freecontent.manning.com/tag/data/
  75. https://freecontent.manning.com/tag/data-science/
  76. https://freecontent.manning.com/tag/deep-learning/
  77. https://freecontent.manning.com/tag/docker/
  78. https://freecontent.manning.com/tag/functional-programming/
  79. https://freecontent.manning.com/tag/game-development/
  80. https://freecontent.manning.com/tag/go/
  81. https://freecontent.manning.com/tag/ios/
  82. https://freecontent.manning.com/tag/java/
  83. https://freecontent.manning.com/tag/javascript/
  84. https://freecontent.manning.com/tag/jvm/
  85. https://freecontent.manning.com/tag/kubernetes/
  86. https://freecontent.manning.com/tag/machine-learning/
  87. https://freecontent.manning.com/tag/microservice/
  88. https://freecontent.manning.com/tag/microservices/
  89. https://freecontent.manning.com/tag/mobile-development/
  90. https://freecontent.manning.com/tag/node-js/
  91. https://freecontent.manning.com/tag/powered-by-javascript/
  92. https://freecontent.manning.com/tag/powered-by-javascript-2015/
  93. https://freecontent.manning.com/tag/programming/
  94. https://freecontent.manning.com/tag/python/
  95. https://freecontent.manning.com/tag/react/
  96. https://freecontent.manning.com/tag/reactive/
  97. https://freecontent.manning.com/tag/scala/
  98. https://freecontent.manning.com/tag/search/
  99. https://freecontent.manning.com/tag/serverless/
 100. https://freecontent.manning.com/tag/spark/
 101. https://freecontent.manning.com/tag/spring/
 102. https://freecontent.manning.com/tag/swift/
 103. https://freecontent.manning.com/tag/testing/
 104. https://freecontent.manning.com/tag/web-development/
 105. https://freecontent.manning.com/animation/
 106. https://freecontent.manning.com/art/
 107. https://freecontent.manning.com/articles/
 108. https://freecontent.manning.com/big-data/
 109. https://freecontent.manning.com/business/
 110. https://freecontent.manning.com/cloud-computing/
 111. https://freecontent.manning.com/data/
 112. https://freecontent.manning.com/data-science/
 113. https://freecontent.manning.com/databases/
 114. https://freecontent.manning.com/design/
 115. https://freecontent.manning.com/development/
 116. https://freecontent.manning.com/devices/
 117. https://freecontent.manning.com/devops/
 118. https://freecontent.manning.com/engineering/
 119. https://freecontent.manning.com/free-ebooks/
 120. https://freecontent.manning.com/game-development/
 121. https://freecontent.manning.com/general/
 122. https://freecontent.manning.com/graphics/
 123. https://freecontent.manning.com/internet/
 124. https://freecontent.manning.com/interview/
 125. https://freecontent.manning.com/iphone/
 126. https://freecontent.manning.com/java/
 127. https://freecontent.manning.com/javajvm/
 128. https://freecontent.manning.com/javascript/
 129. https://freecontent.manning.com/linux/
 130. https://freecontent.manning.com/mac/
 131. https://freecontent.manning.com/mental-model-graphic/
 132. https://freecontent.manning.com/microsoft-dotnet/
 133. https://freecontent.manning.com/mobile-technology/
 134. https://freecontent.manning.com/next-generation-databases/
 135. https://freecontent.manning.com/operations-cloud/
 136. https://freecontent.manning.com/powered-by-javascript/
 137. https://freecontent.manning.com/programming/
 138. https://freecontent.manning.com/programming-languages/
 139. https://freecontent.manning.com/python/
 140. https://freecontent.manning.com/r/
 141. https://freecontent.manning.com/slideshare/
 142. https://freecontent.manning.com/software/
 143. https://freecontent.manning.com/software-development/
 144. https://freecontent.manning.com/software-engineering/
 145. https://freecontent.manning.com/technology/
 146. https://freecontent.manning.com/video/
 147. https://freecontent.manning.com/web/
 148. https://freecontent.manning.com/web-development/
 149. https://freecontent.manning.com/slideshare-modern-data-solutions-with-python/
 150. https://freecontent.manning.com/models-as-a-tool-for-deeper-insight/
 151. https://freecontent.manning.com/mental-model-graphic-production-ready-serverless/
 152. https://freecontent.manning.com/mental-model-graphic-spark-in-action-2e/
 153. https://freecontent.manning.com/mental-model-graphic-graph-powered-machine-learning/
 154. https://freecontent.manning.com/animated-gifs
 155. https://freecontent.manning.com/
 156. https://freecontent.manning.com/credits
 157. https://manning.com/mail-preferences
 158. https://www.facebook.com/manningbooks?ref=nf
 159. https://twitter.com/manningbooks
 160. https://freecontent.manning.com/what-does-deep-learning-contribute-to-search/

   hidden links:
 162. https://freecontent.manning.com/what-does-deep-learning-contribute-to-search/
 163. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2ffreecontent.manning.com%2fwhat-does-deep-learning-contribute-to-search%2f&linkname=what%20does%20deep%20learning%20contribute%20to%20search
 164. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2ffreecontent.manning.com%2fwhat-does-deep-learning-contribute-to-search%2f&linkname=what%20does%20deep%20learning%20contribute%20to%20search
 165. https://www.addtoany.com/add_to/google_plus?linkurl=https%3a%2f%2ffreecontent.manning.com%2fwhat-does-deep-learning-contribute-to-search%2f&linkname=what%20does%20deep%20learning%20contribute%20to%20search
 166. https://www.manning.com/dotd
