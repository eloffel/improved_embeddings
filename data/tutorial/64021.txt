   #[1]github [2]recent commits to shap:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]145
     * [35]star [36]4,314
     * [37]fork [38]541

[39]slundberg/[40]shap

   [41]code [42]issues 209 [43]pull requests 12 [44]projects 0
   [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   a unified approach to explain the output of any machine learning model.
   [47]interpretability [48]machine-learning [49]deep-learning
   [50]gradient-boosting [51]shap
     * [52]763 commits
     * [53]2 branches
     * [54]28 releases
     * [55]41 contributors
     * [56]mit

    1. [57]jupyter notebook 98.6%
    2. [58]python 1.1%
    3. [59]c++ 0.2%
    4. [60]javascript 0.1%
    5. [61]powershell 0.0%
    6. [62]batchfile 0.0%

   (button) jupyter notebook python c++ javascript powershell batchfile
   branch: master (button) new pull request
   [63]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/s
   [64]download zip

downloading...

   want to be notified of new releases in slundberg/shap?
   [65]sign in [66]sign up

launching github desktop...

   if nothing happens, [67]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [68]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [69]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [70]download the github extension for visual studio
   and try again.

   (button) go back
   [71]@slundberg
   [72]slundberg [73]fix [74]#518 (button)    
sklearn treats multiple regression different than multiple class clssifications.
 this fixes the code to correctly explain all outputs of a multiple regression p
roblem.

   latest commit [75]dc936d0 apr 5, 2019
   [76]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [77]appveyor [78]add appveyor apr 19, 2018
   [79]data
   [80]docs [81]update keras lstm for imdb sentiment classification.html
   mar 12, 2019
   [82]javascript
   [83]notebooks [84]address [85]#427 mar 12, 2019
   [86]shap
   [87]tests
   [88].gitignore
   [89].travis.yml
   [90]license
   [91]manifest.in [92]fix pip dist apr 11, 2018
   [93]readme.md [94]update readme.md mar 11, 2019
   [95]appveyor.yml [96]added keras to travis and appveyor. mar 1, 2019
   [97]setup.py

readme.md

                           [98][shap_diagram.png]
     __________________________________________________________________

   [99][68747470733a2f2f7472617669732d63692e6f72672f736c756e64626572672f73
   6861702e7376673f6272616e63683d6d6173746572]

   shap (shapley additive explanations) is a unified approach to explain
   the output of any machine learning model. shap connects game theory
   with local explanations, uniting several previous methods [1-7] and
   representing the only possible consistent and locally accurate additive
   feature attribution method based on expectations (see the [100]shap
   nips paper for details).

install

   shap can be installed from either [101]pypi or [102]conda-forge:
pip install shap
or
conda install -c conda-forge shap

tree ensemble example with treeexplainer
(xgboost/lightgbm/catboost/scikit-learn models)

   while shap values can explain the output of any machine learning model,
   we have developed a high-speed exact algorithm for tree ensemble
   methods ([103]tree shap arxiv paper). fast c++ implementations are
   supported for xgboost, lightgbm, catboost, and scikit-learn tree
   models:
import xgboost
import shap

# load js visualization code to notebook
shap.initjs()

# train xgboost model
x,y = shap.datasets.boston()
model = xgboost.train({"learning_rate": 0.01}, xgboost.dmatrix(x, label=y), 100)

# explain the model's predictions using shap values
# (same syntax works for lightgbm, catboost, and scikit-learn models)
explainer = shap.treeexplainer(model)
shap_values = explainer.shap_values(x)

# visualize the first prediction's explanation (use matplotlib=true to avoid jav
ascript)
shap.force_plot(explainer.expected_value, shap_values[0,:], x.iloc[0,:])

                         [104][boston_instance.png]

   the above explanation shows features each contributing to push the
   model output from the base value (the average model output over the
   training dataset we passed) to the model output. features pushing the
   prediction higher are shown in red, those pushing the prediction lower
   are in blue (these force plots are introduced in our [105]nature bme
   paper).

   if we take many explanations such as the one shown above, rotate them
   90 degrees, and then stack them horizontally, we can see explanations
   for an entire dataset (in the notebook this plot is interactive):
# visualize the training set predictions
shap.force_plot(explainer.expected_value, shap_values, x)

                          [106][boston_dataset.png]

   to understand how a single feature effects the output of the model we
   can plot the shap value of that feature vs. the value of the feature
   for all the examples in a dataset. since shap values represent a
   feature's responsibility for a change in the model output, the plot
   below represents the change in predicted house price as rm (the average
   number of rooms per house in an area) changes. vertical dispersion at a
   single value of rm represents interaction effects with other features.
   to help reveal these interactions dependence_plot automatically selects
   another feature for coloring. in this case coloring by rad (index of
   accessibility to radial highways) highlights that the average number of
   rooms per house has less impact on home price for areas with a high rad
   value.
# create a shap dependence plot to show the effect of a single feature across th
e whole dataset
shap.dependence_plot("rm", shap_values, x)

                      [107][boston_dependence_plot.png]

   to get an overview of which features are most important for a model we
   can plot the shap values of every feature for every sample. the plot
   below sorts features by the sum of shap value magnitudes over all
   samples, and uses shap values to show the distribution of the impacts
   each feature has on the model output. the color represents the feature
   value (red high, blue low). this reveals for example that a high lstat
   (% lower status of the population) lowers the predicted home price.
# summarize the effects of all the features
shap.summary_plot(shap_values, x)

                       [108][boston_summary_plot.png]

   we can also just take the mean absolute value of the shap values for
   each feature to get a standard bar plot (produces stacked bars for
   multi-class outputs):
shap.summary_plot(shap_values, x, plot_type="bar")

                     [109][boston_summary_plot_bar.png]

deep learning example with deepexplainer (tensorflow/keras models)

   deep shap is a high-speed approximation algorithm for shap values in
   deep learning models that builds on a connection with [110]deeplift
   described in the shap nips paper. the implementation here differs from
   the original deeplift by using a distribution of background samples
   instead of a single reference value, and using shapley equations to
   linearize components such as max, softmax, products, divisions, etc.
   note that some of these enhancements have also been since integrated
   into deeplift. tensorflow models and keras models using the tensorflow
   backend are supported (there is also preliminary support for pytorch):
# ...include code from https://github.com/keras-team/keras/blob/master/examples/
mnist_id98.py

import shap
import numpy as np

# select a set of background examples to take an expectation over
background = x_train[np.random.choice(x_train.shape[0], 100, replace=false)]

# explain predictions of the model on four images
e = shap.deepexplainer(model, background)
# ...or pass tensors directly
# e = shap.deepexplainer((model.layers[0].input, model.layers[-1].output), backg
round)
shap_values = e.shap_values(x_test[1:5])

# plot the feature attributions
shap.image_plot(shap_values, -x_test[1:5])

                         [111][mnist_image_plot.png]

   the plot above explains ten outputs (digits 0-9) for four different
   images. red pixels increase the model's output while blue pixels
   decrease the output. the input images are shown on the left, and as
   nearly transparent grayscale backings behind each of the explanations.
   the sum of the shap values equals the difference between the expected
   model output (averaged over the background dataset) and the current
   model output. note that for the 'zero' image the blank middle is
   important, while for the 'four' image the lack of a connection on top
   makes it a four instead of a nine.

deep learning example with gradientexplainer (tensorflow/keras/pytorch
models)

   expected gradients combines ideas from [112]integrated gradients, shap,
   and [113]smoothgrad into a single expected value equation. this allows
   an entire dataset to be used as the background distribution (as opposed
   to a single reference value) and allows local smoothing. if we
   approximate the model with a linear function between each background
   data sample and the current input to be explained, and we assume the
   input features are independent then expected gradients will compute
   approximate shap values. in the example below we have explained how the
   7th intermediate layer of the vgg16 id163 model impacts the output
   probabilities.
from keras.applications.vgg16 import vgg16
from keras.applications.vgg16 import preprocess_input
import keras.backend as k
import numpy as np
import json
import shap

# load pre-trained model and choose two images to explain
model = vgg16(weights='id163', include_top=true)
x,y = shap.datasets.id16350()
to_explain = x[[39,41]]

# load the id163 class names
url = "https://s3.amazonaws.com/deep-learning-models/image-models/id163_class
_index.json"
fname = shap.datasets.cache(url)
with open(fname) as f:
    class_names = json.load(f)

# explain how the input to the 7th layer of the model explains the top two class
es
def map2layer(x, layer):
    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))
    return k.get_session().run(model.layers[layer].input, feed_dict)
e = shap.gradientexplainer(
    (model.layers[7].input, model.layers[-1].output),
    map2layer(x, 7),
    local_smoothing=0 # std dev of smoothing noise
)
shap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)

# get the names for the classes
index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)

# plot the explanations
shap.image_plot(shap_values, to_explain, index_names)

                      [114][gradient_id163_plot.png]

   predictions for two input images are explained in the plot above. red
   pixels represent positive shap values that increase the id203 of
   the class, while blue pixels represent negative shap values the reduce
   the id203 of the class. by using ranked_outputs=2 we explain only
   the two most likely classes for each input (this spares us from
   explaining all 1,000 classes).

model agnostic example with kernelexplainer (explains any function)

   kernel shap uses a specially-weighted local id75 to
   estimate shap values for any model. below is a simple example for
   explaining a multi-class id166 on the classic iris dataset.
import sklearn
import shap
from sklearn.model_selection import train_test_split

# print the js visualization code to the notebook
shap.initjs()

# train a id166 classifier
x_train,x_test,y_train,y_test = train_test_split(*shap.datasets.iris(), test_siz
e=0.2, random_state=0)
id166 = sklearn.id166.svc(kernel='rbf', id203=true)
id166.fit(x_train, y_train)

# use kernel shap to explain test set predictions
explainer = shap.kernelexplainer(id166.predict_proba, x_train, link="logit")
shap_values = explainer.shap_values(x_test, nsamples=100)

# plot the shap values for the setosa output of the first instance
shap.force_plot(explainer.expected_value[0], shap_values[0][0,:], x_test.iloc[0,
:], link="logit")

                          [115][iris_instance.png]

   the above explanation shows four features each contributing to push the
   model output from the base value (the average model output over the
   training dataset we passed) towards zero. if there were any features
   pushing the class label higher they would be shown in red.

   if we take many explanations such as the one shown above, rotate them
   90 degrees, and then stack them horizontally, we can see explanations
   for an entire dataset. this is exactly what we do below for all the
   examples in the iris test set:
# plot the shap values for the setosa output of all instances
shap.force_plot(explainer.expected_value[0], shap_values[0], x_test, link="logit
")

                           [116][iris_dataset.png]

shap interaction values

   shap interaction values are a generalization of shap values to higher
   order interactions. fast exact computation of pairwise interactions are
   implemented for tree models with
   shap.treeexplainer(model).shap_interaction_values(x). this returns a
   matrix for every prediction, where the main effects are on the diagonal
   and the interaction effects are off-diagonal. these values often reveal
   interesting hidden relationships, such as how the increased risk of
   death peaks for men at age 60 (see the nhanes notebook for details):

                    [117][nhanes_age_sex_interaction.png]

sample notebooks

   the notebooks below demonstrate different use cases for shap. look
   inside the notebooks directory of the repository if you want to try
   playing with the original notebooks yourself.

treeexplainer

   an implementation of tree shap, a fast and exact algorithm to compute
   shap values for trees and ensembles of trees.
     * [118]nhanes survival model with xgboost and shap interaction values
       - using mortality data from 20 years of followup this notebook
       demonstrates how to use xgboost and shap to uncover complex risk
       factor relationships.
     * [119]census income classification with lightgbm - using the
       standard adult census income dataset, this notebook trains a
       gradient boosting tree model with lightgbm and then explains
       predictions using shap.
     * [120]league of legends win prediction with xgboost - using a kaggle
       dataset of 180,000 ranked matches from league of legends we train
       and explain a gradient boosting tree model with xgboost to predict
       if a player will win their match.

deepexplainer

   an implementation of deep shap, a faster (but only approximate)
   algorithm to compute shap values for deep learning models that is based
   on connections between shap and the deeplift algorithm.
     * [121]mnist digit classification with keras - using the mnist
       handwriting recognition dataset, this notebook trains a neural
       network with keras and then explains predictions using shap.
     * [122]keras lstm for imdb sentiment classification - this notebook
       trains an lstm with keras on the imdb text id31
       dataset and then explains predictions using shap.

gradientexplainer

   an implementation of expected gradients to approximate shap values for
   deep learning models. it is based on connections between shap and the
   integrated gradients algorithm. gradientexplainer is slower than
   deepexplainer and makes different approximation assumptions.
     * [123]explain an intermediate layer of vgg16 on id163 - this
       notebook demonstrates how to explain the output of a pre-trained
       vgg16 id163 model using an internal convolutional layer.

linearexplainer

   for a linear model with independent features we can analytically
   compute the exact shap values. we can also account for feature
   correlation if we are willing to estimate the feature covaraince
   matrix. linearexplainer supports both of these options.
     * [124]id31 with id28 - this notebook
       demonstrates how to explain a linear id28 sentiment
       analysis model.

kernelexplainer

   an implementation of kernel shap, a model agnostic method to estimate
   shap values for any model. because it makes not assumptions about the
   model type, kernelexplainer is slower than the other model type
   specific algorithms.
     * [125]census income classification with scikit-learn - using the
       standard adult census income dataset, this notebook trains a
       k-nearest neighbors classifier using scikit-learn and then explains
       predictions using shap.
     * [126]id163 vgg16 model with keras - explain the classic vgg16
       convolutional nerual network's predictions for an image. this works
       by applying the model agnostic kernel shap method to a super-pixel
       segmented image.
     * [127]iris classification - a basic demonstration using the popular
       iris species dataset. it explains predictions from six different
       models in scikit-learn using shap.

methods unified by shap

    1. lime: ribeiro, marco tulio, sameer singh, and carlos guestrin. "why
       should i trust you?: explaining the predictions of any classifier."
       proceedings of the 22nd acm sigkdd international conference on
       knowledge discovery and data mining. acm, 2016.
    2. shapley sampling values: strumbelj, erik, and igor kononenko.
       "explaining prediction models and individual predictions with
       feature contributions." knowledge and information systems 41.3
       (2014): 647-665.
    3. deeplift: shrikumar, avanti, peyton greenside, and anshul kundaje.
       "learning important features through propagating activation
       differences." arxiv preprint arxiv:1704.02685 (2017).
    4. qii: datta, anupam, shayak sen, and yair zick. "algorithmic
       transparency via quantitative input influence: theory and
       experiments with learning systems." security and privacy (sp), 2016
       ieee symposium on. ieee, 2016.
    5. layer-wise relevance propagation: bach, sebastian, et al. "on
       pixel-wise explanations for non-linear classifier decisions by
       layer-wise relevance propagation." plos one 10.7 (2015): e0130140.
    6. shapley regression values: lipovetsky, stan, and michael conklin.
       "analysis of regression in game theory approach." applied
       stochastic models in business and industry 17.4 (2001): 319-330.
    7. tree interpreter: saabas, ando. interpreting id79s.
       [128]http://blog.datadive.net/interpreting-random-forests/

   [129][68747470733a2f2f7777772e66616365626f6f6b2e636f6d2f74723f69643d313
   8393134373039313835353939312665763d5061676556696577266e6f7363726970743d
   31]

     *    2019 github, inc.
     * [130]terms
     * [131]privacy
     * [132]security
     * [133]status
     * [134]help

     * [135]contact github
     * [136]pricing
     * [137]api
     * [138]training
     * [139]blog
     * [140]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [141]reload to refresh your
   session. you signed out in another tab or window. [142]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/slundberg/shap/commits/master.atom
   3. https://github.com/slundberg/shap#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/slundberg/shap
  32. https://github.com/join
  33. https://github.com/login?return_to=/slundberg/shap
  34. https://github.com/slundberg/shap/watchers
  35. https://github.com/login?return_to=/slundberg/shap
  36. https://github.com/slundberg/shap/stargazers
  37. https://github.com/login?return_to=/slundberg/shap
  38. https://github.com/slundberg/shap/network/members
  39. https://github.com/slundberg
  40. https://github.com/slundberg/shap
  41. https://github.com/slundberg/shap
  42. https://github.com/slundberg/shap/issues
  43. https://github.com/slundberg/shap/pulls
  44. https://github.com/slundberg/shap/projects
  45. https://github.com/slundberg/shap/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/interpretability
  48. https://github.com/topics/machine-learning
  49. https://github.com/topics/deep-learning
  50. https://github.com/topics/gradient-boosting
  51. https://github.com/topics/shap
  52. https://github.com/slundberg/shap/commits/master
  53. https://github.com/slundberg/shap/branches
  54. https://github.com/slundberg/shap/releases
  55. https://github.com/slundberg/shap/graphs/contributors
  56. https://github.com/slundberg/shap/blob/master/license
  57. https://github.com/slundberg/shap/search?l=jupyter-notebook
  58. https://github.com/slundberg/shap/search?l=python
  59. https://github.com/slundberg/shap/search?l=c++
  60. https://github.com/slundberg/shap/search?l=javascript
  61. https://github.com/slundberg/shap/search?l=powershell
  62. https://github.com/slundberg/shap/search?l=batchfile
  63. https://github.com/slundberg/shap/find/master
  64. https://github.com/slundberg/shap/archive/master.zip
  65. https://github.com/login?return_to=https://github.com/slundberg/shap
  66. https://github.com/join?return_to=/slundberg/shap
  67. https://desktop.github.com/
  68. https://desktop.github.com/
  69. https://developer.apple.com/xcode/
  70. https://visualstudio.github.com/
  71. https://github.com/slundberg
  72. https://github.com/slundberg/shap/commits?author=slundberg
  73. https://github.com/slundberg/shap/commit/dc936d0497ae37ae223e8b4287c786eb10959cd4
  74. https://github.com/slundberg/shap/issues/518
  75. https://github.com/slundberg/shap/commit/dc936d0497ae37ae223e8b4287c786eb10959cd4
  76. https://github.com/slundberg/shap/tree/dc936d0497ae37ae223e8b4287c786eb10959cd4
  77. https://github.com/slundberg/shap/tree/master/appveyor
  78. https://github.com/slundberg/shap/commit/564b0b4de5f8b0c2605a6568b8ac7c61d1a8c0e6
  79. https://github.com/slundberg/shap/tree/master/data
  80. https://github.com/slundberg/shap/tree/master/docs
  81. https://github.com/slundberg/shap/commit/8ffa62ea286330492031102a83dacdebf620d500
  82. https://github.com/slundberg/shap/tree/master/javascript
  83. https://github.com/slundberg/shap/tree/master/notebooks
  84. https://github.com/slundberg/shap/commit/c48ecff8534accff7cb83828c5bd22492084cc97
  85. https://github.com/slundberg/shap/issues/427
  86. https://github.com/slundberg/shap/tree/master/shap
  87. https://github.com/slundberg/shap/tree/master/tests
  88. https://github.com/slundberg/shap/blob/master/.gitignore
  89. https://github.com/slundberg/shap/blob/master/.travis.yml
  90. https://github.com/slundberg/shap/blob/master/license
  91. https://github.com/slundberg/shap/blob/master/manifest.in
  92. https://github.com/slundberg/shap/commit/15ecb69cc7d9b70e94b2cd49bd2afd166bf86674
  93. https://github.com/slundberg/shap/blob/master/readme.md
  94. https://github.com/slundberg/shap/commit/9ceb3c792a0226be79e869bbf2da5cbbd138370c
  95. https://github.com/slundberg/shap/blob/master/appveyor.yml
  96. https://github.com/slundberg/shap/commit/36b8b83633061dcb2a7c75d2e38b63142b964467
  97. https://github.com/slundberg/shap/blob/master/setup.py
  98. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_diagram.png
  99. https://travis-ci.org/slundberg/shap
 100. http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions
 101. https://pypi.org/project/shap
 102. https://anaconda.org/conda-forge/shap
 103. https://arxiv.org/abs/1802.03888
 104. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png
 105. https://www.nature.com/articles/s41551-018-0304-0
 106. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dataset.png
 107. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dependence_plot.png
 108. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot.png
 109. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot_bar.png
 110. https://arxiv.org/abs/1704.02685
 111. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/mnist_image_plot.png
 112. https://arxiv.org/abs/1703.01365
 113. https://arxiv.org/abs/1706.03825
 114. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/gradient_id163_plot.png
 115. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_instance.png
 116. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_dataset.png
 117. https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/nhanes_age_sex_interaction.png
 118. https://slundberg.github.io/shap/notebooks/nhanes i survival model.html
 119. https://slundberg.github.io/shap/notebooks/census income classification with lightgbm.html
 120. https://slundberg.github.io/shap/notebooks/league of legends win prediction with xgboost.html
 121. https://slundberg.github.io/shap/notebooks/deep_explainer/front page deepexplainer mnist example.html
 122. https://slundberg.github.io/shap/notebooks/deep_explainer/keras lstm for imdb sentiment classification.html
 123. https://slundberg.github.io/shap/notebooks/gradient_explainer/explain an intermediate layer of vgg16 on id163.html
 124. https://slundberg.github.io/shap/notebooks/linear_explainer/id31 with id28.html
 125. https://slundberg.github.io/shap/notebooks/census income classification with scikit-learn.html
 126. https://slundberg.github.io/shap/notebooks/id163 vgg16 model with keras.html
 127. https://slundberg.github.io/shap/notebooks/iris classification with scikit-learn.html
 128. http://blog.datadive.net/interpreting-random-forests/
 129. https://camo.githubusercontent.com/db8c6ffa9af4cf6d17c411a9f7ad56cc1b508c35/68747470733a2f2f7777772e66616365626f6f6b2e636f6d2f74723f69643d3138393134373039313835353939312665763d5061676556696577266e6f7363726970743d31
 130. https://github.com/site/terms
 131. https://github.com/site/privacy
 132. https://github.com/security
 133. https://githubstatus.com/
 134. https://help.github.com/
 135. https://github.com/contact
 136. https://github.com/pricing
 137. https://developer.github.com/
 138. https://training.github.com/
 139. https://github.blog/
 140. https://github.com/about
 141. https://github.com/slundberg/shap
 142. https://github.com/slundberg/shap

   hidden links:
 144. https://github.com/
 145. https://github.com/slundberg/shap
 146. https://github.com/slundberg/shap
 147. https://github.com/slundberg/shap
 148. https://help.github.com/articles/which-remote-url-should-i-use
 149. https://github.com/slundberg/shap#install
 150. https://github.com/slundberg/shap#tree-ensemble-example-with-treeexplainer-xgboostlightgbmcatboostscikit-learn-models
 151. https://github.com/slundberg/shap#deep-learning-example-with-deepexplainer-tensorflowkeras-models
 152. https://github.com/slundberg/shap#deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models
 153. https://github.com/slundberg/shap#model-agnostic-example-with-kernelexplainer-explains-any-function
 154. https://github.com/slundberg/shap#shap-interaction-values
 155. https://github.com/slundberg/shap#sample-notebooks
 156. https://github.com/slundberg/shap#treeexplainer
 157. https://github.com/slundberg/shap#deepexplainer
 158. https://github.com/slundberg/shap#gradientexplainer
 159. https://github.com/slundberg/shap#linearexplainer
 160. https://github.com/slundberg/shap#kernelexplainer
 161. https://github.com/slundberg/shap#methods-unified-by-shap
 162. https://github.com/
