   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

another twitter id31 with python         part 9 (neural networks with
tfidf vectors using keras)

   [16]go to the profile of ricky kim
   [17]ricky kim (button) blockedunblock (button) followfollowing
   jan 31, 2018
   [1*c4jpigks57ttbxclvymqda.jpeg]

   this is the 9th part of my ongoing twitter id31 project.
   you can find the previous posts from the below links.
     * [18]part 1: data cleaning
     * [19]part 2: eda, data visualisation
     * [20]part 3: zipf   s law, data visualisation
     * [21]part 4: feature extraction (count vectorizer), id165,
       confusion matrix
     * [22]part 5: feature extraction (tfidf vectorizer), machine learning
       model comparison, lexical approach
     * [23]part 6: doc2vec
     * [24]part 7: phrase modeling + doc2vec
     * [25]part 8: id84 (chi2, pca)

   in the previous post, i took a detour of implementing dimensionality
   reduction before i try neural network modelling. in this post, i will
   implement neural network first with the tfidf vectors of 100,000
   features including up to trigram.

   *in addition to short code blocks i will attach, you can find the link
   for the whole jupyter notebook at the end of this post.

id158

   my first idea was, if id28 is the best performing
   classifier, then this idea can be extended to neural networks. in terms
   of its structure, id28 can be thought as a neural
   network with no hidden layer, and just one output node. you can see
   this relationship more clearly from the pictures below.
   [1*e6xgg8p4f1b2tix5tuhyma.png]

   i will not go through the details of how neural networks work, but if
   you want to know more in detail, you can take a look at the post i
   wrote previously on [26]implementing a neural network from scratch with
   python. but for this post, i won   t implement it from scratch but use a
   library called keras. keras is more of a wrapper, which can be run on
   top of other libraries such as theano or tensorflow. it is one of the
   most easy-to-use libraries with intuitive syntax yet powerful. if you
   are a newbie to neural network modelling as myself, i think keras is a
   good place to start.

ann with tfidf vectorizer

   the best performing tfidf vectors i got is with 100,000 features
   including up to trigram with id28. validation accuracy
   is 82.91%, while train set accuracy is 84.19%. i would want to see if
   the neural network can boost the performance of my existing tfidf
   vectors.

   i will first start by loading required dependencies. in order to run
   keras with tensorflow backend, you need to install both tensorflow and
   keras.

   iframe: [27]/media/91ce09bec05e8bbecc1f6f12eccbf8ee?postid=d0b4af6be6d7

   the structure of below nn model has 100,000 nodes in the input layer,
   then 64 nodes in a hidden layer with relu activation function applied,
   then finally one output layer with sigmoid activation function applied.
   there are different types of optimizing techniques for neural networks,
   and different id168 you can define with the model. below model
   uses adam optimizing, and binary cross id178 loss.

   adam is an optimisation algorithm for updating the parameters and
   minimising the cost of the neural network, which is proved to be very
   effective. it combines two methods of optimisation: rmsprop, momentum.
   again, i will focus on sharing the result i got from my implementation,
   but if you want to understand properly how adam works, i strongly
   recommend the    [28]deeplearning.ai    course by andrew ng. he explains
   the complex concept of neural network in a very intuitive way. if you
   want more in-depth material on the topic, you can also take a look at
   the research paper    [29]adam: a method for stochastic optimization    by
   kingma & ba (2014).

   before i feed the data and train the model, i need to deal with one
   more thing. keras nn model cannot handle sparse matrix directly. the
   data has to be dense array or matrix, but transforming the whole
   training data tfidf vectors of 1.5 million to dense array won   t fit
   into my ram. so i had to define a function, which generates iterable
   generator object, so that it can be fed to nn model. note that the
   output should be a generator class object rather than directly
   returning arrays, this can be achieved by using    yield    instead of
      return   .

   iframe: [30]/media/7d0bea1faabc5e30e3afef448ac0cdef?postid=d0b4af6be6d7

   [1*afvktq3s_pb1h9i7_ugwng.png]

   it looks like the model had the best validation accuracy after 2
   epochs, and after that, it fails to generalise so validation accuracy
   slowly decreases, while training accuracy increases. but if you
   remember the result i got from id28 (train accuracy:
   84.19%, validation accuracy: 82.91%), you can see that the above neural
   network failed to outperform id28 in terms of
   validation.

   let   s see if normalising inputs have any effect on the performance.

   iframe: [31]/media/71341b8b65632d326520d351393cfa1d?postid=d0b4af6be6d7

   then i redefined the model and refit the model with
      x_train_tfidf_norm    i got from the above normaliser.

   and the result comes out almost as same as without normalisation. and
   it is at this point i realised that tfidf is already normalised by the
   way it is calculated. tf (term frequency) in tfidf is not absolute
   frequency but relative frequency, and by multiplying idf (inverse
   document frequency) to the relative term frequency value, it further
   normalises the value in a cross-document manner.

dropout

   if the problem of the model is a poor generalisation, then there is
   another thing i can add to the model. even though the neural network is
   a very powerful model, sometimes overfitting to the training data can
   be a problem. dropout is a technique that addresses this problem. if
   you are familiar with the concept of ensemble model in machine
   learning, dropout can also be seen in the same vein. according to the
   research paper    [32]improving neural networks by preventing
   co-adaptation of feature detectors    by hinton et al. (2012),    a good
   way to reduce the error on the test set is to average the predictions
   produced by a very large number of different networks. the standard way
   to do this is to train many separate networks and then to apply each of
   these networks to the test data, but this is computationally expensive
   during both training and testing. random dropout makes it possible to
   train a huge number of different networks in a reasonable time.   

   dropout is simulating as if we train many different networks and
   averaging them by randomly omitting hidden nodes with a certain
   id203 throughout the training process. with keras, this can be
   easily implemented just by adding one line to your model architecture.
   let   s see how the model performance changes with 20% dropout rate. (*i
   will gather all the results and present them with a table at the end.)

   iframe: [33]/media/235815171c43050166cd4e9f98a7f1da?postid=d0b4af6be6d7

   [1*dy2uji9foqhkmmml4prfaw.png]

   through 5 epochs, the train set accuracy didn   t get as high as the
   model without dropout, but validation accuracy didn   t drop as low as
   the previous model. even though the dropout added some generalisation
   to the model, but still the validation accuracy is still
   underperforming compared to id28 result.

shuffling

   there is another method i can try to prevent overfitting. by presenting
   the data in the same order for every epoch, there   s a possibility that
   the model learns the parameters which also includes the noise of the
   training data, which eventually leads to overfitting. this can be
   improved by shuffling the order of the data we feed the model. below i
   added shuffling to the batch generator function and tried with the same
   model structure and compared the result.

   iframe: [34]/media/8b73465955b3bb3e8f640a089e88f2cd?postid=d0b4af6be6d7

   [1*vvbk6izmcgi7snlurqx6xg.png]

   the same model with non-shuffled training data had training accuracy of
   87.36%, and validation accuracy of 79.78%. with shuffling, training
   accuracy decreased to 84.80% but the validation accuracy after 5 epochs
   has increased to 82.61%. it seems like the shuffling did improve the
   model   s performance on the validation set. and another thing i noticed
   is that with or without shuffling also for both with or without
   dropout, validation accuracy tends to peak after 2 epochs, and
   gradually decrease afterwards.

   i also tried the same model with 20% dropout with shuffled data, this
   time only 2 epochs that i will share the result at the end.

learning rate

   as i was going through the    [35]deeplearning.ai    course by andrew ng,
   he states that the first thing he would try to improve a neural network
   model is tweaking the learning rate. i decided to follow his advice and
   try different learning rates with the model. please note that except
   for the learning rate, the parameter for    beta_1   ,    beta_2   , and
      epsilon    are set to the default values presented by the original paper
      [36]adam: a method for stochastic optimization    by kingma and ba
   (2015).

   iframe: [37]/media/c5b33bfc2c4059e66934aaddc79c8bcf?postid=d0b4af6be6d7

   having tried four different learning rates (0.0005, 0.005, 0.01, 0.1),
   none of them outperformed the default learning rate of 0.001.

increasing number of nodes

   maybe i can try to increase the number of hidden nodes, and see how it
   affects the performance. below model has 128 nodes in the hidden layer.

   iframe: [38]/media/f0fcfb1e79db50a99f041d3ac85b733f?postid=d0b4af6be6d7

   with 128 hidden nodes, validation accuracy got close to the performance
   of id28. i could experiment further with increasing the
   number of hidden layers, but for the above 2 epochs to run, it took 5
   hours. considering that id28 took less than a minute to
   fit, even if the neural network can be improved further, this doesn   t
   look like an efficient way.

   below is a table with all the results i got from trying different
   models above. please note that i have compared performance at 2 epochs
   since some of the models only ran for 2 epochs.
   [1*pygxcbimrfvw0govt39u9a.png]

   except for ann_8 (with the learning rate of 0.1), the model performance
   only varies in the decimal place, and the best model is ann_9 (with one
   hidden layer of 128 nodes) at 82.84% validation accuracy.

   as a result, in this particular case, neural network models failed to
   outperform id28. this might be due to the high
   dimensionality and sparse characteristics of the textual data. i have
   also found a research paper, which compared model performance with high
   dimension data. according to    [39]an empirical evaluation of supervised
   learning in high dimensions    by caruana et al.(2008), logistic
   regression showed as good performance as neural networks, in some cases
   outperforms neural networks.

   through all the trials above i learned some valuable lessons.
   implementing and tuning neural networks is a highly iterative process
   and includes many trials and errors. even though neural network is a
   more complex version of id28, it doesn   t always
   outperform id28, and sometimes with high dimension
   sparse data, id28 can deliver good performance with much
   less computation time than neural network.

   in the next post, i will implement a neural network with doc2vec
   vectors i got from the previous post. hopefully with dense vectors such
   as doc2vec, the neural network might show some boost. fingers crossed.

   as always, thank you for reading. you can find the whole jupyter
   notebook from the link below.

   [40]https://github.com/tthustla/twitter_sentiment_analysis_part9/blob/m
   aster/capstone_part4-copy7.ipynb

     * [41]machine learning
     * [42]data science
     * [43]neural networks
     * [44]nlp
     * [45]python

   (button)
   (button)
   (button) 309 claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   [46]go to the profile of ricky kim

[47]ricky kim

   the rickest ricky. love data, beer, coffee, and good memes in no
   particular order.

     (button) follow
   [48]towards data science

[49]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 309
     * (button)
     *
     *

   [50]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [51]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/d0b4af6be6d7
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-9-neural-networks-with-tfidf-vectors-using-d0b4af6be6d7&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-9-neural-networks-with-tfidf-vectors-using-d0b4af6be6d7&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_yjag1zd8dpal---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@rickykim78?source=post_header_lockup
  17. https://towardsdatascience.com/@rickykim78
  18. https://towardsdatascience.com/another-twitter-sentiment-analysis-bb5b01ebad90
  19. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-2-333514854913
  20. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-3-zipfs-law-data-visualisation-fc9eadda71e7
  21. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-4-count-vectorizer-b3f4944e51b5
  22. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-5-50b4e87d9bdd
  23. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-6-doc2vec-603f11832504
  24. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-7-phrase-modeling-doc2vec-592a8a996867
  25. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-8-dimensionality-reduction-chi2-pca-c6d06fb3fcf3
  26. https://towardsdatascience.com/shallow-neural-network-from-scratch-deeplearning-ai-assignment-320f57c581cd
  27. https://towardsdatascience.com/media/91ce09bec05e8bbecc1f6f12eccbf8ee?postid=d0b4af6be6d7
  28. https://www.coursera.org/specializations/deep-learning
  29. https://arxiv.org/pdf/1412.6980.pdf
  30. https://towardsdatascience.com/media/7d0bea1faabc5e30e3afef448ac0cdef?postid=d0b4af6be6d7
  31. https://towardsdatascience.com/media/71341b8b65632d326520d351393cfa1d?postid=d0b4af6be6d7
  32. https://arxiv.org/pdf/1207.0580.pdf
  33. https://towardsdatascience.com/media/235815171c43050166cd4e9f98a7f1da?postid=d0b4af6be6d7
  34. https://towardsdatascience.com/media/8b73465955b3bb3e8f640a089e88f2cd?postid=d0b4af6be6d7
  35. https://www.coursera.org/specializations/deep-learning
  36. https://arxiv.org/pdf/1412.6980.pdf
  37. https://towardsdatascience.com/media/c5b33bfc2c4059e66934aaddc79c8bcf?postid=d0b4af6be6d7
  38. https://towardsdatascience.com/media/f0fcfb1e79db50a99f041d3ac85b733f?postid=d0b4af6be6d7
  39. http://icml2008.cs.helsinki.fi/papers/632.pdf
  40. https://github.com/tthustla/twitter_sentiment_analysis_part9/blob/master/capstone_part4-copy7.ipynb
  41. https://towardsdatascience.com/tagged/machine-learning?source=post
  42. https://towardsdatascience.com/tagged/data-science?source=post
  43. https://towardsdatascience.com/tagged/neural-networks?source=post
  44. https://towardsdatascience.com/tagged/nlp?source=post
  45. https://towardsdatascience.com/tagged/python?source=post
  46. https://towardsdatascience.com/@rickykim78?source=footer_card
  47. https://towardsdatascience.com/@rickykim78
  48. https://towardsdatascience.com/?source=footer_card
  49. https://towardsdatascience.com/?source=footer_card
  50. https://towardsdatascience.com/
  51. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  53. https://medium.com/p/d0b4af6be6d7/share/twitter
  54. https://medium.com/p/d0b4af6be6d7/share/facebook
  55. https://medium.com/p/d0b4af6be6d7/share/twitter
  56. https://medium.com/p/d0b4af6be6d7/share/facebook
