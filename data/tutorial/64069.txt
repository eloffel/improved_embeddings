   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]technology@nineleaps
   [7]technology@nineleaps
   [8]sign in[9]get started
     __________________________________________________________________

expectation maximization

   [10]go to the profile of joydeep bhattacharjee
   [11]joydeep bhattacharjee (button) blockedunblock (button)
   followfollowing
   feb 22, 2018

   a peek into generative algorithms
   [1*9l0o2uvbupqdhiik-bugaw.jpeg]
   [12]source

   id116 id91 is one of the most simple algorithms out there and
   has been quite robust as well. if you are looking to perform machine
   learning on some unlabeled data, you should consider id116 id91
   as your first algorithm of choice. having said that, there are some
   fundamental problems with id116 id91. to start with, id116
   id91 does not have any mathematical base as is the norm in
   general machine learning algorithms. also, in the real world, it is
   seen that id116 tends to cluster to local minima. hence, we will take
   a look at expectation maximization which is kind of a generalization of
   id116 id91.

   expectation maximization comes under [13]gaussian models which are more
   of a way of thinking and modeling rather than a particular algorithm.
   clusters are modeled as gaussian distributions and not by their means.
   what happens in such cases is that there is a correspondence between
   all data points and all clusters rather than correspondence between
   each data point to its own cluster, as is the case in id116
   id91. thus, we also cover cases where there is overlapping
   between different clusters.
   [1*wyhqzwmiylxtpxx13vwcrq.png]

   expectation maximization works the same way as id116 except that the
   data is assigned to each cluster with the weights being soft
   probabilities instead of distances. the advantage is that the model
   becomes generative as we define the id203 distribution for each
   model.
   [14]generative models
   this post describes four projects that share a common theme of
   enhancing or using generative models, a branch of   blog.openai.com

   typically, we encounter a lot of dimensions in our features and hence,
   we will use a multivariate gaussian, which is shown in the below form
   [0*vafa_jden8wwoatr.]
   is the covariance matrix
   is the mean vector

   now, to get the values of nu and sigma, you just need to get the
   maximum likelihood estimates which can be easily computed below
   [0*khh_g4cvdpyfxnsh.]

   the algorithm for em-learning consists of the below steps.
    1. e-step: an initial guess is made for the parameters of the model
       and a id203 distribution is created.
    2. newly observed data is fed into the model.
    3. m-step: the id203 distribution of the e-step is changed and
       modified to include the new data.
    4. the above process is repeated till there is no change between the
       e-step and the m-step.

   this algorithm is proven to converge.

applications

   [0*gmifyagtul7qtyoy.jpg]
   [15]source
    1. since the resultant id203 distribution can be considered to
       be the joined id203 distribution of multiple gaussians hence,
       this can be used to disentangle mixed signals.
    2. em algorithm is an algorithm for id113 and
       hence, can be used for estimating id48 and many
       other uses.

   [16]maximum-likelihood estimation for id48 -
   sciencedirect
   id48 assume a sequence of random variables to be
   conditionally independent given a sequence of
   state   www.sciencedirect.com

   on a final note, as em algorithm is used for finding a id203
   distribution, it can be very slow even on the fastest computer. in such
   cases, depending on the task it may make sense to use a simpler
   algorithm.

   in case you found this post useful then please click on the claps
   button. also, follow me [17]here or on [18]@alt227joydeep for more of
   my articles. you can also tweet me in case you want to discuss. i would
   be more than happy to help.

     * [19]machine learning
     * [20]algorithms
     * [21]id116
     * [22]tech
     * [23]data

   (button)
   (button)
   (button) 125 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [24]go to the profile of joydeep bhattacharjee

[25]joydeep bhattacharjee

   machine learning engineer and avid reader

     (button) follow
   [26]technology@nineleaps

[27]technology@nineleaps

   technology insights, selection & implementation

     * (button)
       (button) 125
     * (button)
     *
     *

   [28]technology@nineleaps
   never miss a story from technology@nineleaps, when you sign up for
   medium. [29]learn more
   never miss a story from technology@nineleaps
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/4bb203841757
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/technology-nineleaps?source=avatar-lo_6cc4t2iv1gs0-479df42c7b8e
   7. https://medium.com/technology-nineleaps?source=logo-lo_6cc4t2iv1gs0---479df42c7b8e
   8. https://medium.com/m/signin?redirect=https://medium.com/technology-nineleaps/expectation-maximization-4bb203841757&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/technology-nineleaps/expectation-maximization-4bb203841757&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@joydeepubuntu?source=post_header_lockup
  11. https://medium.com/@joydeepubuntu
  12. https://unsplash.com/@robertaguillen?utm_medium=referral&utm_campaign=photographer-credit&utm_content=creditbadge
  13. http://www.cs.cmu.edu/~./awm/tutorials/gmm.html
  14. https://blog.openai.com/generative-models/
  15. https://www.originlab.com/forum/topic.asp?topic_id=19129
  16. https://www.sciencedirect.com/science/article/pii/030441499290141c
  17. https://medium.com/@joydeepubuntu/latest
  18. https://twitter.com/alt227joydeep
  19. https://medium.com/tag/machine-learning?source=post
  20. https://medium.com/tag/algorithms?source=post
  21. https://medium.com/tag/id116?source=post
  22. https://medium.com/tag/tech?source=post
  23. https://medium.com/tag/data?source=post
  24. https://medium.com/@joydeepubuntu?source=footer_card
  25. https://medium.com/@joydeepubuntu
  26. https://medium.com/technology-nineleaps?source=footer_card
  27. https://medium.com/technology-nineleaps?source=footer_card
  28. https://medium.com/technology-nineleaps
  29. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  31. https://blog.openai.com/generative-models/
  32. https://www.sciencedirect.com/science/article/pii/030441499290141c
  33. https://medium.com/p/4bb203841757/share/twitter
  34. https://medium.com/p/4bb203841757/share/facebook
  35. https://medium.com/p/4bb203841757/share/twitter
  36. https://medium.com/p/4bb203841757/share/facebook
