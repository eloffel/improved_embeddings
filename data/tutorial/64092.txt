   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

id90         understanding explainable ai

   [16]go to the profile of grant holtes
   [17]grant holtes (button) blockedunblock (button) followfollowing
   mar 1, 2018
   [1*14cem2ezajs_npgjsvjhzg.jpeg]

   explainable ai or xai is a sub-category of ai where the decisions made
   by the model can be interpreted by humans, as opposed to    black box   
   models. as ai moves from correcting our spelling and targeting ads to
   driving our cars and diagnosing patients, the need to verify and
   justify the conclusions being reached is beginning to be prioritised.

   to begin to delve into the field, lets look at one simple xai model:
   the decision tree. id90 can be easily read and even mimic a
   human approach to decision making by breaking the choice into many
   small sub-choices. a simple example is how one may evaluate local
   universities when the leave high school. given the student has a course
   in mind a simple decision making process could be:
   [1*1_xpfn_nnib31ds0euy_qg.png]

   how the student reached their conclusion can be easily justified if a
   third party has access to the    model    and the required variables.

   this same structure can be applied with supervised learning, with the
   goal of creating a decision tree which best describes the training
   data. this model can then be used to understand the relationship
   between the variables or in a predictive application.

the algorithm

   the construction of the decision tree is done as a recusive process.
    1. estimate which variable gives the largest information gain.
       information gain is the reduction in id178 of the dependant
       variable when the state of the independent variable is known.
       lot of big words there.
       essentially this measures how much more organised the independant
       variable is when we split it into groups according to the dependant
       variable   s value.
    2. the dependant variable which provides the greatest increase in
       organisation is selected and the dataset is split according to this
       variable.
    3. at this point one of three things must be true:
       - the dependant variable now takes only one value. in this case
       this branch of the tree is complete, and we have reached our
          decision   .
       - the dependant variable takes >1 values. here we simply go back to
       step one and try to narrow it down further.
       -the dependant variable takes >1 values but we have no more
       independent variables to split the data by. here we simply say what
       values the decision could take and estimate a id203 for each
       according to the relative proportions of each option.

calculating information gain

   first, we need a formula for organisation or id178. to calculate the
   id178 of our dependant variable we use:
   [1*hllk3rogtf9l56thba-uwa.png]

   the following chart shows how the id178 of y (where y has two states)
   changes with the id203 of each state. as the id203 of one
   state is 0 the id178 is also 0, as this is when y is most organised,
   while when y is evenly split between the two states the id178 is at
   its maximum.
   [1*7uoib5bmb7wzneoqda1omw.png]

   expanding this to add the effect on id178 of knowing an independent
   variable, x:
   [1*lkx0iqy370ceut0tw_blsa.png]

   information gain is now given as the difference between the id178
   when we know x and when we don   t.
   [1*wcsnkik_nzdtax8d_qxkhg.png]

give me the code!

   some functions to calculate id178 and create the graphics have not
   been included here.
def decide(y, x_dict, previous_node):
    #calc info gain for each x
    max_ig = 0
    var_to_split = none
#calculate information gain to find out which variable to split on
    for x in x_dict.keys():
        ig = infogain(y, x_dict[x])
        if ig > max_ig:
            max_ig = ig
            var_to_split = x
#see if all variables have been used and none are left.
    if var_to_split == none:
        y_options = list(set(y))
        tot = float(len(y))
        count = [0 for _ in range(len(y_options))]
for op in range(len(y_options)):
            for i in range(len(y)):
                if y[i] == op:
                    count[op] += 1
        #format node label
        prob = ""
        for op in range(len(y_options) - 1):
            prob += "p("
            prob += str(y_options[op]) + ")-> "
            p = float(count[op]) / tot
            prob += "{0:.2f}".format(p)
        #make a new node
        nodename = node(prob, color = "orange")
        edge(previous_node, nodename)
    else:
        print("splitting on {0}".format(var_to_split))
        x_options = list(set(x_dict[var_to_split]))
        #make decision variable node
        var_nodename = node(var_to_split, color = "red")
        edge(previous_node, var_nodename)
        #init new data for each new branch of the tree
        for x_option in x_options:
            x_nodename = node(str(x_option))
            edge(var_nodename, x_nodename)
            new_x_dict = {}
            #get remaining variables
            for key in x_dict.keys():
                if key != var_to_split:
                    new_x_dict[key] = []
            new_y = []
            #populate
            for i in range(len(y)):
                if x_dict[var_to_split][i] == x_option:
                    new_y.append(y[i])
                    for key in new_x_dict.keys():
                        new_x_dict[key].append(x_dict[key][i])
#check if this is a terminal node:
            if len(set(new_y)) == 1:
                nodename = node(str(new_y[0]), color = "green")
                edge(x_nodename, nodename)
            else:
                #no terminal node, so try again
                decide(new_y, new_x_dict, x_nodename)
y, x_dict =  import_golf('golf.csv') #import data
root_node = node("root", color = "blue") #create the first node
decide(y, x_dict, root_node) #start the tree

   for the[18] golf dataset the following tree is output, which is an easy
   way to interpret the decision making process.
   [1*2rrboduhsiapiufcrild5g.png]

     * [19]machine learning
     * [20]ai
     * [21]decision making

   (button)
   (button)
   (button) 182 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [22]go to the profile of grant holtes

[23]grant holtes

   ai and analytics consultant in melbourne. 90% ml / economics / cv. 10%
   photography / cooking / cycling. [24]www.grantholtes.com

     (button) follow
   [25]towards data science

[26]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 182
     * (button)
     *
     *

   [27]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [28]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/620fc37e598d
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/decision-trees-understanding-explainable-ai-620fc37e598d&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/decision-trees-understanding-explainable-ai-620fc37e598d&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_srth2744qp2g---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@grantholtes?source=post_header_lockup
  17. https://towardsdatascience.com/@grantholtes
  18. https://gerardnico.com/data_mining/weather
  19. https://towardsdatascience.com/tagged/machine-learning?source=post
  20. https://towardsdatascience.com/tagged/ai?source=post
  21. https://towardsdatascience.com/tagged/decision-making?source=post
  22. https://towardsdatascience.com/@grantholtes?source=footer_card
  23. https://towardsdatascience.com/@grantholtes
  24. http://www.grantholtes.com/
  25. https://towardsdatascience.com/?source=footer_card
  26. https://towardsdatascience.com/?source=footer_card
  27. https://towardsdatascience.com/
  28. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  30. https://medium.com/p/620fc37e598d/share/twitter
  31. https://medium.com/p/620fc37e598d/share/facebook
  32. https://medium.com/p/620fc37e598d/share/twitter
  33. https://medium.com/p/620fc37e598d/share/facebook
