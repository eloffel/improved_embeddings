   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    how to handle imbalanced classification problems
   in machine learning? comments feed [4]alternate [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]machine learning [94]how to handle imbalanced
   classification problems in machine learning?

   [95]machine learning[96]r

how to handle imbalanced classification problems in machine learning?

   [97]guest blog, march 17, 2017

introduction

   if you have spent some time in machine learning and data science, you
   would have definitely come across imbalanced class distribution. this
   is a scenario where the number of observations belonging to one class
   is significantly lower than those belonging to the other classes.

   this problem is predominant in scenarios where anomaly detection is
   crucial like electricity pilferage, fraudulent transactions in banks,
   identification of rare diseases, etc. in this situation, the predictive
   model developed using conventional machine learning algorithms could be
   biased and inaccurate.

   this happens because machine learning algorithms are usually designed
   to improve accuracy by reducing the error. thus, they do not take into
   account the class distribution / proportion or balance of classes.

   this guide describes various approaches for solving such class
   imbalance problems using various sampling techniques. we also weigh
   each technique for its pros and cons. finally, i reveal an approach
   using which you can create a balanced class distribution and apply
   id108 technique designed especially for this purpose.


table of content

    1. challenges faced with imbalanced datasets
    2. approach to handling imbalanced datasets
    3. illustrative example
    4. conclusion

1. challenges faced with imbalanced datasets

   one of the main challenges faced by the utility industry today is
   electricity theft. electricity theft is the third largest form of theft
   worldwide. utility companies are increasingly turning towards advanced
   analytics and machine learning algorithms to identify consumption
   patterns that indicate theft.

   however, one of the biggest stumbling blocks is the humongous data and
   its distribution. fraudulent transactions are significantly lower than
   normal healthy transactions i.e. accounting it to around 1-2 % of the
   total number of observations. the ask is to improve identification of
   the rare minority class as opposed to achieving higher overall
   accuracy.

   machine learning algorithms tend to produce unsatisfactory classifiers
   when faced with imbalanced datasets. for any imbalanced data set, if
   the event to be predicted belongs to the minority class and the event
   rate is less than 5%, it is usually referred to as a rare event.

example of imbalanced classes

   let   s understand this with the help of an example.

   ex: in an utilities fraud detection data set you have the following
   data:

   total observations = 1000

   fraudulent  observations = 20

   non fraudulent observations = 980

   event rate= 2 %

   the main question faced during data analysis is     how to get a balanced
   dataset by getting a decent number of samples for these anomalies given
   the rare occurrence for some them?

challenges with standard machine learning techniques

   the conventional model evaluation methods do not accurately measure
   model performance when faced with imbalanced datasets.

   standard classifier algorithms like decision tree and logistic
   regression have a bias towards classes which have number of instances.
   they tend to only predict the majority class data. the features of the
   minority class are treated as noise and are often ignored. thus, there
   is a high id203 of misclassification of the minority class as
   compared to the majority class.

   evaluation of a classification algorithm performance is measured by the
   confusion matrix which contains information about the actual and the
   predicted class.

   accuracy of a model = (tp+tn) / (tp+fn+fp+tn)

   however, while working in an imbalanced domain accuracy is not an
   appropriate measure to evaluate model performance. for eg: a classifier
   which achieves an accuracy of 98 % with an event rate of 2 % is not
   accurate, if it classifies all instances as the majority class. and
   eliminates the 2 % minority class observations as noise.

examples of imbalanced classes

   thus, to sum it up, while trying to resolve specific business
   challenges with imbalanced data sets, the classifiers produced by
   standard machine learning algorithms might not give accurate results.
   apart from fraudulent transactions, other examples of a common business
   problem with imbalanced dataset are:
     * datasets to identify customer churn where a vast majority of
       customers will continue using the service. specifically,
       telecommunication companies where churn rate is lower than 2 %.
     * data sets to identify rare diseases in medical diagnostics etc.
     * natural disaster like earthquakes

dataset used

   in this article, we will illustrate the various techniques to train a
   model to perform well against highly imbalanced datasets. and
   accurately predict rare events using the following fraud detection
   dataset:

   total observations = 1000

   fraudulent   observations =20

   non-fraudulent observations = 980

   event rate= 2 %

   fraud indicator = 0 for non-fraud instances

   fraud indicator = 1 for fraud


2. approach to handling imbalanced datasets

2.1 data level approach: resampling techniques

   dealing with imbalanced datasets entails strategies such as improving
   classification algorithms or balancing classes in the training data
   (id174) before providing the data as input to the machine
   learning algorithm. the later technique is preferred as it has wider
   application.

   the main objective of balancing classes is to either increasing the
   frequency of the minority class or decreasing the frequency of the
   majority class. this is done in order to obtain approximately the same
   number of instances for both the classes. let us look at a few
   resampling techniques:


2.1.1  random under-sampling

   random undersampling aims to balance class distribution by randomly
   eliminating majority class examples.  this is done until the majority
   and minority class instances are balanced out.

   total observations = 1000

   fraudulent   observations =20

   non fraudulent observations = 980

   event rate= 2 %

   in this case we are taking 10 % samples without replacement from non
   fraud instances.  and combining them with fraud instances.

   non fraudulent observations after random under sampling = 10 % of 980
   =98

   total observations after combining them with fraudulent observations =
   20+98=118

   event rate for the new dataset after under sampling = 20/118 = 17%


     * advantages
          + it can help improve run time and storage problems by reducing
            the number of training data samples when the training data set
            is huge.

     * disadvantages
          + it can discard potentially useful information which could be
            important for building rule classifiers.
          + the sample chosen by random under sampling may be a biased
            sample. and it will not be an accurate representative of the
            population. thereby, resulting in inaccurate results with the
            actual test data set.


2.1.2  random over-sampling

   over-sampling increases the number of instances in the minority class
   by randomly replicating them in order to present a higher
   representation of the minority class in the sample.

   total observations = 1000

   fraudulent   observations =20

   non fraudulent observations = 980

   event rate= 2 %

   in this case we are replicating 20 fraud observations   20 times.

   non fraudulent observations =980

   fraudulent observations after replicating the minority class
   observations= 400

   total observations in the new data set after oversampling=1380

   event rate for the new data set after under sampling= 400/1380 = 29 %
     * advantages
          + unlike under sampling this method leads to no information
            loss.
          + outperforms under sampling

     * disadvantages
          + it increases the likelihood of overfitting since it replicates
            the minority class events.


2.1.3  cluster-based over sampling

   in this case, the id116 id91 algorithm is independently applied
   to minority and majority class instances. this is to identify clusters
   in the dataset. subsequently, each cluster is oversampled such that all
   clusters of the same class have an equal number of instances and all
   classes have the same size.

   total observations = 1000

   fraudulent   observations =20

   non fraudulent observations = 980

   event rate= 2 %
     * majority class clusters
         1. cluster 1: 150 observations
         2. cluster 2: 120 observations
         3. cluster 3: 230 observations
         4. cluster 4: 200 observations
         5. cluster 5: 150 observations
         6. cluster 6: 130 observations

     * minority  class clusters
         1. cluster 1: 8 observations
         2. cluster 2: 12 observations


   after oversampling of each cluster, all clusters of the same class
   contain the same number of observations.
     * majority class clusters
         1. cluster 1: 170 observations
         2. cluster 2: 170 observations
         3. cluster 3: 170 observations
         4. cluster 4: 170   observations
         5. cluster 5: 170   observations
         6. cluster 6: 170   observations

     * minority   class clusters
         1. cluster 1: 250 observations
         2. cluster 2: 250 observations

   event rate post cluster based oversampling sampling = 500/ (1020+500) =
   33 %
     * advantages
          + this id91 technique helps overcome the challenge between
            class imbalance. where the number of examples representing
            positive class differs from the number of examples
            representing a negative class.
          + also, overcome challenges within class imbalance, where a
            class is composed of different sub clusters. and each sub
            cluster does not contain the same number of examples.

     * disadvantages
          + the main drawback of this algorithm, like most oversampling
            techniques is the possibility of over-fitting the training
            data.


2.1.4  informed over sampling: synthetic minority over-sampling technique

   this technique is followed to avoid overfitting which occurs when exact
   replicas of minority instances are added to the main dataset. a subset
   of data is taken from the minority class as an example and then new
   synthetic similar instances are created. these synthetic instances are
   then added to the original dataset. the new dataset is used as a sample
   to train the classification models.

   total observations = 1000

   fraudulent  observations = 20

   non fraudulent observations = 980

   event rate = 2 %

   a sample of 15 instances is taken from the minority class and similar
   synthetic instances are generated 20 times

   post generation of synthetic instances, the following data set is
   created

   minority class (fraudulent observations) = 300

   majority class (non-fraudulent observations) = 980

   event rate= 300/1280 = 23.4 %


     * advantages
          + mitigates the problem of overfitting caused by random
            oversampling as synthetic examples are generated rather than
            replication of instances
          + no loss of useful information

     * disadvantages
          + while generating synthetic examples smote does not take into
            consideration neighboring examples from other classes. this
            can result in increase in overlapping of classes and can
            introduce additional noise
          + smote is not very effective for high dimensional data



   **n is the number of attributes

   figure 1:  synthetic minority oversampling algorithm


    figure 2: generation of synthetic instances with the help of smote


2.1.5  modified synthetic minority oversampling technique (msmote)

   it is a modified version of smote. smote does not consider the
   underlying distribution of the minority class and latent noises in the
   dataset. to improve the performance of smote a modified method msmote
   is used.

   this algorithm classifies the samples of minority classes into 3
   distinct groups     security/safe samples, border samples, and latent
   nose samples. this is done by calculating the distances among samples
   of the minority class and samples of the training data.

   security samples are those data points which can improve the
   performance of a classifier. while on the other hand, noise are the
   data points which can reduce the performance of the classifier.  the
   ones which are difficult to categorize into any of the two are
   classified as border samples.

   while the basic flow of msomte is the same as that of smote (discussed
   in the previous section).  in msmote the strategy of selecting nearest
   neighbors is different from smote. the algorithm randomly selects a
   data point from the k nearest neighbors for the security sample,
   selects the nearest neighbor from the border samples and does nothing
   for latent noise.


2.2 algorithmic ensemble techniques

   the above section, deals with handling imbalanced data by resampling
   original data to provide balanced classes. in this section, we are
   going to look at an alternate approach i.e.  modifying existing
   classification algorithms to make them appropriate for imbalanced data
   sets.

   the main objective of ensemble methodology is to improve the
   performance of single classifiers. the approach involves constructing
   several two stage classifiers from the original data and then aggregate
   their predictions.

                                            figure 3: approach to ensemble
   based methodologies


2.2.1. id112 based

   id112 is an abbreviation of bootstrap aggregating. the conventional
   id112 algorithm involves generating    n    different bootstrap training
   samples with replacement. and training the algorithm on each
   bootstrapped algorithm separately and then aggregating the predictions
   at the end.

   id112 is used for reducing overfitting in order to create strong
   learners for generating accurate predictions. unlike boosting, id112
   allows replacement in the bootstrapped sample.


                                        figure 4:  approach to id112
   methodology

   total observations = 1000

   fraudulent   observations =20

   non fraudulent observations = 980

   event rate= 2 %

   there are 10 bootstrapped samples chosen from the population with
   replacement. each sample contains 200 observations. and each sample is
   different from the original dataset but resembles the dataset in
   distribution & variability.

   the machine learning algorithms like id28, neural
   networks, decision tree  are fitted to each bootstrapped sample of 200
   observations. and the classifiers c1, c2   c10 are aggregated to produce
   a compound classifier.  this ensemble methodology produces a stronger
   compound classifier since it combines the results of individual
   classifiers to come up with an improved one.


     * advantages
          + improves stability & accuracy of machine learning algorithms
          + reduces variance
          + overcomes overfitting
          + improved misclassification rate of the bagged classifier
          + in noisy data environments id112 outperforms boosting


     * disadvantages
          + id112 works only if the base classifiers are not bad to
            begin with. id112 bad classifiers can further degrade
            performance


2.2.2. boosting-based

   boosting is an ensemble technique to combine weak learners to create a
   strong learner that can make accurate predictions. boosting starts out
   with a base classifier / weak classifier that is prepared on the
   training data.

   what are base learners / weak classifiers?

   the base learners / classifiers are weak learners i.e. the prediction
   accuracy is only slightly better than average. a classifier learning
   algorithm is said to be weak when small changes in data induce big
   changes in the classification model.

   in the next iteration, the new classifier focuses on or places more
   weight to those cases which were incorrectly classified in the last
   round.


   figure 5: approach to boosting methodologies


2.2.2.1. adaptive boosting- ada boost

   ada boost is the first original boosting technique which creates a
   highly accurate prediction rule by combining many weak and inaccurate
   rules.  each classifier is serially trained with the goal of correctly
   classifying examples in every round that were incorrectly classified in
   the previous round.

   for a learned classifier to make strong predictions it should follow
   the following three conditions:
     * the rules should be simple
     * classifier should have been trained on sufficient number of
       training examples
     * the classifier should have low training error for the training
       instances

   each of the weak hypothesis has an accuracy slightly better than random
   guessing i.e. error term     (t) should be slightly more than   -   where   
   >0. this is the fundamental assumption of this boosting algorithm which
   can produce a final hypothesis with a small error

   after each round, it gives more focus to examples that are harder to
   classify.  the quantity of focus is measured by a weight, which
   initially is equal for all instances. after each iteration, the weights
   of misclassified instances are increased and the weights of correctly
   classified instances are decreased.



   figure 6:  approach to adaptive boosting

   for example in a data set containing 1000 observations out of which 20
   are labelled fraudulent. equal weights w1 are assigned to all
   observations and the base classifier accurately classifies 400
   observations.

   weight of each of the 600 misclassified observations is increased to w2
   and weight of each of the correctly classified observations is reduced
   to w3.

   in each iteration, these updated weighted observations are fed to the
   weak classifier to improve its performance. this process continues till
   the misclassification rate significantly decreases thereby resulting in
   a strong classifier.


     * advantages
         1. very simple to implement
         2. good generalization- suited for any kind of classification
            problem    not prone to overfitting


     * disadvantages
         1. sensitive to noisy data and outliers


2.2.2.2  gradient tree boosting

   in gradient boosting many models are trained sequentially. it is a
   numerical optimization algorithm where each model minimizes the loss
   function, y = ax+b+e, using the id119 method.

   id90 are used as weak learners in gradient boosting.

   while both adaboost and gradient boosting work on weak learners /
   classifiers. and try to boost them into a strong learner, there are
   some fundamental differences in the two methodologies. adaboost either
   requires the users to specify a set of weak learners  or randomly
   generates the weak learners before the actual learning process. the
   weight of each learner is adjusted at every step depending on whether
   it predicts a sample correctly.

   on the other hand, gradient boosting builds the first learner on the
   training dataset to predict the samples, calculates the loss
   (difference between real value and output of the first learner). and
   use this loss to build an improved learner in the second stage.

   at every step, the residual of the id168 is calculated using
   the id119 method and the new residual becomes a target
   variable for the subsequent iteration.

   gradient boosting can be done using the gradient boosting node in sas
   miner and gbm package in r


          figure 7:  approach to gradient boosting

   for example: in a training data set containing 1000 observations out of
   which 20 are labelled fraudulent an initial base classifier. target
   variable fraud =1 for fraudulent transactions and fraud=0 for not fraud
   transactions.

   for eg: decision tree is fitted which accurately classifying only 5
   observations as fraudulent observations. a differentiable id168
   is calculated based on the difference between the actual output and the
   predicted output of this step.  the residual of the id168 is
   the target variable (f1) for the next iteration.

   similarly, this algorithm internally calculates the id168,
   updates the target at every stage and comes up with an improved
   classifier as compared to the initial classifier.


     * disadvantages
          + gradient boosted trees are harder to fit than id79s
          + gradient boosting algorithms generally have 3 parameters which
            can be fine-tuned, shrinkage parameter, depth of the tree, the
            number of trees. proper training of each of these parameters
            is needed for a good fit. if parameters are not tuned
            correctly it may result in over-fitting.


   2.2.2.3 xg boost

   xgboost (extreme gradient boosting) is an advanced and more efficient
   implementation of gradient boosting algorithm discussed in the previous
   section.

   advantages over other boosting techniques
     * it is 10 times faster than the normal gradient boosting as it
       implements parallel processing. it is highly flexible as users can
       define custom optimization objectives and evaluation criteria, has
       an inbuilt mechanism to handle missing values.
     * unlike gradient boosting which stops splitting a node as soon as it
       encounters a negative loss, xg boost splits up to the maximum depth
       specified and prunes the tree backward and removes splits beyond
       which there is an only negative loss.

   extreme gradient boosting can be done using the xgboost package in r
   and python


3. illustrative example

3.1. data description

   the illustrative telecom churn dataset has  47241 client records with
   each record containing information about 27 key predictor variables.

     [ga9.png]

   the data structure  of the rare event data set is shown below post
   missing value removal, outlier treatment and dimension reduction.

   [ga10.png]

   download the dataset from here: [98]sample dataset


3.2 description of methodologies

   the unbalanced dataset is balanced using synthetic minority
   oversampling technique (smote) which attempts to balance the data set
   by creating synthetic instances. and train the balanced data set using
   gradient boosting algorithm as illustrated by the r codes in the next
   section


   r codes

   #load data
rareevent_boost <- read.table("d:/upasana/rareevent/churn.txt",sep="|", header=t
rue)
dmy<-dummyvars("~.",data=rareevent_boost)
rareeventtrsf<-data.frame(predict(dmy,newdata= rareevent_boost))
set.seed(10)
sub <- sample(nrow(rareeventtrsf), floor(nrow(rareeventtrsf) * 0.9))
sub1 <- sample(nrow(rareeventtrsf), floor(nrow(rareeventtrsf) * 0.1))
training <- rareeventtrsf [sub, ]
testing <- rareeventtrsf [-sub, ]
training_sub<- rareeventtrsf [sub1, ]
tables(training_sub)
head(training_sub)


#for unbalanced data set#
install.packages("unbalanced")
library(unbalanced)
data(ubionosphere)
n<-ncol(rareevent_boost)
output<- rareevent_boost $churn_flag
output<-as.factor(output)
input<- rareevent_boost [ ,-n]
view(input)


#balance the dataset using ubsmote#
data<-ubbalance(x= input, y=output, type="ubsmote", percover=300, percunder=150,
 verbose=true
view(data)
#balanced data#
balanceddata<-cbind(data$x,data$y)
view(balanceddata)
table(balanceddata$churn_flag)


#write the balanced data to be used to train the model#
write.table(balanceddata,"d:/ upasana/rareevent /balanceddata.txt", sep="\t", ro
w.names=false)


#build boosting tree model#
repalcenaswithmean <- function(x) {replace(x, is.na(x), mean(x[!is.na(x)]))}
training <- repalcenaswithmean(training)
testing <- repalcenaswithmean(testing)


#resampling technique#
view(train_set)
fitcontrol<-traincontrol(method="repeatedcv",number=10,repeats=1,verbose=false)
gbmfit<-train(churn_flag~.,data=balanceddata,method="gbm",verbose=false)


#score test data#
testing$score_y=predict(gbmfit,newdata=testing,type="prob")[,2]
testing$score_y=ifelse(testing$score_y>0.5,1,0)
head(testing,n=10)
write.table(testing,"d:/ upasana/rareevent /testing.txt", sep="\t", row.names=fa
lse)
pred_gbm<-prediction(testing$score_y,testing$churn_flag)


#model performance#
model_perf_gbm <- performance(pred_gbm, "tpr", "fpr")
model_perf_gbm1 <- performance(pred_gbm, "tpr", "fpr")
model_perf_gbm
pred_gbm1<-as.data.frame(model_perf_gbm)
auc.tmp_gbm <- performance(pred_gbm,"auc")
auc_gbm <- as.numeric([99][email protected])
auc.tmp_gbm


   results

   this approach of balancing the data set with smote and training a
   gradient boosting algorithm on the balanced set significantly impacts
   the accuracy of the predictive model. by increasing its lift by around
   20% and precision/hit ratio by 3-4 times as compared to normal
   analytical modeling techniques like id28 and decision
   trees.


4. conclusion

   when faced with imbalanced data sets there is no one stop solution to
   improve the accuracy of the prediction model.  one may need to try out
   multiple methods to figure out the best-suited sampling techniques for
   the dataset. in most cases, synthetic techniques like smote and msmote
   will outperform the conventional oversampling and undersampling
   methods.

   for better results, one can use synthetic sampling methods like smote
   and msmote along with advanced boosting methods like gradient boosting
   and xg boost.

   one of the advanced id112 techniques commonly used to counter the
   imbalanced dataset problem is smote id112. it follows an entirely
   different approach from conventional id112 to create each
   bag/bootstrap. it generates the positive instances by the smote
   algorithm by setting a smote resampling rate in each iteration. the set
   of negative instances is bootstrapped in each iteration.

   depending on the characteristics of the imbalanced data set, the most
   effective techniques will vary. relevant evaluation parameters should
   be considered during the model comparison.

   while comparing multiple prediction models built through an exhaustive
   combination of the above-mentioned techniques lift & area under the roc
   curve will be instrumental in determining which model is superior to
   the others.

   if you have any questions or doubts, feel free to drop them in the
   comments below.

   references
    1. dmitry pavlov, alexey gorodilov, cliff brunk    bagboo: a scalable
       hybrid id112-theboosting model   .2010
    2. fithria siti hanifah , hari wijayanto , anang kurnia    smote id112
       algorithm for imbalanced data set in id28 analysis   .
       applied mathematical sciences, vol. 9, 2015
    3. lina guzman, directv    data sampling improvement by developing smote
       technique in sas    .paper 3483-2015
    4. mikel galar, alberto fern  andez, edurne barrenechea, humberto
       bustince and francisco herrera     a review on ensembles for the
       class imbalance problem: id112-, boosting-, and hybrid-based
       approaches     .2011 ieee

about the author

   [upasana.jpg] upasana holds a post graduate diploma in management from
   indian institute of management, indore. she is currently working as a
   consultant in the data & analytics practice of kpmg. she has around 3.5
   + years of work experience and has worked in multiple advanced
   analytics and data science engagements spanning industries like
   telecom, utilities, banking , manufacturing. she has worked extensively
   on sas, data management & advanced analytics, r, tableau, oracle and
   sql.

got expertise in business intelligence  / machine learning / big data / data
science? showcase your knowledge and help analytics vidhya community
by [100]posting your blog.

   you can also read this article on analytics vidhya's android app
   [101]get it on google play

share this:

     * [102]click to share on linkedin (opens in new window)
     * [103]click to share on facebook (opens in new window)
     * [104]click to share on twitter (opens in new window)
     * [105]click to share on pocket (opens in new window)
     * [106]click to share on reddit (opens in new window)
     *

like this:

   like loading...

related articles

   [ins: :ins]

   tags : [107]accuracy, [108]gradient boosting, [109]imbalanced
   classification, [110]r
   next article

backend developer- gurgaon, india (3-7 years of experience)

   previous article

bi architect- us (8 years of experience)

[111]guest blog

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [112]discussion portal to get your queries resolved

21 comments

     * gerard meester says:
       [113]march 17, 2017 at 6:36 am
       thanks for this article. very relevant for me, in the area of fraud
       detection. i have always less fraudulent companies compared to the
       rest.
       what is not clear to me is if sampling techniques are really
       necessary when using xgboost. first you present ensemble techniques
       as an alternative to sampling techniques to solve the unbalanced
       classes problem, later on you state that even when you use
       algorithms like boosting, sampling can be useful. could you comment
       on this?
       [114]reply
          + upasana says:
            [115]march 17, 2017 at 2:04 pm
            thanks for your feedback gerard. x g boost is generally a more
            advanced form of boosting and takes care of imbalanced data
            set by balancing it in itself- so use of sampling techniques
            is really not necessary. ensemble based methods are not an
            alternative to sampling techniques per se     you can use them
            separately or combine them to get better results e.g. smote+
            gradient boosting. however i would suggest you try xg boosting
            on the imbalanced data directly set to get better results.
            [116]reply
     * arun says:
       [117]march 17, 2017 at 6:42 am
       nice article explaining re sampling !! well written
       [118]reply
     * mahesh says:
       [119]march 17, 2017 at 7:40 am
       very nice article, very helpful..
       [120]reply
     * carlos says:
       [121]march 17, 2017 at 8:46 am
       excelent post upasana, this is a very important issue but many
       times it has not enough attention. one question: if you train your
       model on the balanced dataset, do you need to make any adjustment
       in the scores when you apply the model to the original unbalanced
       dataset, or you can use directly the model trained with balanced
       data on the unbalanced data without any problem and use the scores
       without any transformation?
       thanks!
       [122]reply
          + upasana says:
            [123]march 17, 2017 at 3:04 pm
            thank you for your feedback carlos. adjustment in score can be
            done if you want to keep the same cut-off for the unbalanced
            data set. however, if the selection is based on the top n
            deciles then adjustment is not required. the setting of cut
            off will depend on the business use case you are trying to
            solve     this will vary according to the industry and the
            specific use case.
            [124]reply
     * [125]shaul says:
       [126]march 17, 2017 at 10:38 am
       very informative and well written, thanks!
       [127]reply
     * naresh s says:
       [128]march 17, 2017 at 11:19 am
       excellent explanation. thanks for the article
       [129]reply
     * somnath de says:
       [130]march 17, 2017 at 12:52 pm
       very well written upasana. keep it up.
       [131]reply
     * saurabh bhagvatula says:
       [132]march 17, 2017 at 1:29 pm
       awesome post. very knowledgeful.
       [133]reply
     * [134]tom brander says:
       [135]march 17, 2017 at 7:12 pm
       very nicely written and comprehensive. however i wonder whether the
       newer ehancements to neural network approaches offer hope in this
       area without class rebalancing? anyone have thoughts on this? it
       seems that the nn   s often generalize well on sparse features but
       i   m still just getting my feet wet here..
       [136]reply
     * abhay pandilwar says:
       [137]march 18, 2017 at 12:51 pm
       really good article upasana. this relates to my work closely,
       lately i   ve been working on classification problems for imbalanced
       data sets and i tend to use the under sampling method to overcome
       accuracy paradox. but i face one problem in particular that when i
       apply the trained model on application set, the number of
       predictions in minority class are huge. is there a specific way to
       predict minimum number of accurate records? or do we have to rely
       on top n deciles all the time?
       [138]reply
     * [139]prof ravi vadlamani says:
       [140]march 19, 2017 at 12:41 am
       very well written post ms. upasana.
       you pretty much covered most of the methods for unbalanced
       classification, where both classes of data are considered.
       i just add that one-class classification using either support
       vector data description (svdd), or its variant one-class id166 too is
       a very good approach for this case, as we experienced in various
       banking and insurance datasets. unlike the other methods, they
       consider only majority class for training and the minority class is
       used for testing. as some one asked, we did design and try out auto
       associative nn trained by particle swarm optimization technqiue too
       with excellent success. here too, the aann is trained by the
       majority class and tested by the minority class.
       [141]reply
     * surya1987 says:
       [142]march 19, 2017 at 4:48 am
       hi upasana, it   s a very nice article. however i just need to
       confirm whether this can be used when there is imbalance in
       categories of a categorical variable. because i have seen if we use
       caret package in such imbalance scenario the model does not get
       trained untill i remove the categories with less frequency. how to
       deal with those scenarios?
       [143]reply
     * surya1987 says:
       [144]march 19, 2017 at 4:57 am
       sorry i missed to mention that when there is a imbalance in
       categorical variable which is predictor.
       [145]reply
          + tirthankar ghosh says:
            [146]may 12, 2017 at 7:11 am
            i usually combine the categories with less frequency to
            something like others.
            idea is to keep the number of levels in a class variable not
            very high    less than 20 (usually).
            [147]reply
     * [148]kabir ali says:
       [149]march 31, 2017 at 2:53 pm
       upasana i am getting error at
       gbmfit<-train(churn_flag~.,data=balanceddata,method="gbm",verbose=f
       alse)
       i have changed the churn_flag to churn.flag as it is churn,flag in
       the data frame but still it says error in train and unused
       arguments (data = balanceddata, method = "gbm", verbose = false)
       [150]reply
     * cherry says:
       [151]april 9, 2017 at 9:21 pm
       i really like this article! these days i am dealing with an
       imbalanced dataset with small number of data records, so i want to
       try msmote, because when i was suing smote, it didn   t work well. it
       seems that msmote is published in paper in 2009, however i didn   t
       find it in r or python. is there any built in library i can use to
       try msmote?
       [152]reply
     * gigi says:
       [153]october 1, 2017 at 1:01 pm
       this is a really good article . the explanation is to the point and
       covers the topic well .great work!
       [154]reply
     * abhay krishnan says:
       [155]april 12, 2018 at 4:11 pm
       imbalance data sets are always worrisome during any analysis. this
       article has nicely explained various approaches we can use for such
       situations.
       [156]reply
          + aishwarya singh says:
            [157]april 13, 2018 at 1:13 pm
            hi abhay,
            thank you for sharing your views.
            [158]reply

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-06] [159]srk       3924
   2    [2.jpg?date=2019-04-06] [160]mark12    3510
   3    [3.jpg?date=2019-04-06] [161]nilabha   3261
   4    [4.jpg?date=2019-04-06] [162]nitish007 3237
   5    [5.jpg?date=2019-04-06] [163]tezdhar   3082
   [164]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [165]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [166]understanding support vector machine algorithm from examples
       (along with code)
     * [167]essentials of machine learning algorithms (with python and r
       codes)
     * [168]a complete tutorial to learn data science with python from
       scratch
     * [169]7 types of regression techniques you should know!
     * [170]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [171]a simple introduction to anova (with applications in excel)
     * [172]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [173]top 5 machine learning github repositories and reddit discussions
   from march 2019

[174]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [175]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[176]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [177]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[178]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [179]16 opencv functions to start your id161 journey (with
   python code)

[180]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [181][ds-finhack.jpg]

   [182][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [183]about us
     * [184]our team
     * [185]career
     * [186]contact us
     * [187]write for us

   [188]about us
   [189]   
   [190]our team
   [191]   
   [192]careers
   [193]   
   [194]contact us

data scientists

     * [195]blog
     * [196]hackathon
     * [197]discussions
     * [198]apply jobs
     * [199]leaderboard

companies

     * [200]post jobs
     * [201]trainings
     * [202]hiring hackathons
     * [203]advertising
     * [204]reach us

   don't have an account? [205]sign up here.

join our community :

   [206]46336 [207]followers
   [208]20224 [209]followers
   [210]followers
   [211]7513 [212]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [213]privacy policy
     * [214]terms of use
     * [215]refund policy

   don't have an account? [216]sign up here

   iframe: [217]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [218](button) join now

   subscribe!

   iframe: [219]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [220](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/machine-learning/
  94. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
  95. https://www.analyticsvidhya.com/blog/category/machine-learning/
  96. https://www.analyticsvidhya.com/blog/category/r/
  97. https://www.analyticsvidhya.com/blog/author/guest-blog/
  98. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/17063705/sampledata_imc.csv
  99. https://www.analyticsvidhya.com/cdn-cgi/l/email-protection
 100. https://www.analyticsvidhya.com/about-me/write/
 101. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 102. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/?share=linkedin
 103. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/?share=facebook
 104. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/?share=twitter
 105. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/?share=pocket
 106. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/?share=reddit
 107. https://www.analyticsvidhya.com/blog/tag/accuracy/
 108. https://www.analyticsvidhya.com/blog/tag/gradient-boosting/
 109. https://www.analyticsvidhya.com/blog/tag/imbalanced-classification/
 110. https://www.analyticsvidhya.com/blog/tag/r/
 111. https://www.analyticsvidhya.com/blog/author/guest-blog/
 112. https://discuss.analyticsvidhya.com/
 113. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124914
 114. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124914
 115. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124951
 116. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124951
 117. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124915
 118. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124915
 119. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124918
 120. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124918
 121. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124923
 122. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124923
 123. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124953
 124. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124953
 125. http://www.datascience.co.il/
 126. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124932
 127. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124932
 128. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124935
 129. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124935
 130. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124942
 131. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124942
 132. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124948
 133. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124948
 134. http://oswco.com/
 135. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124972
 136. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-124972
 137. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125059
 138. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125059
 139. http://www.idrbt.ac.in/vravi.html
 140. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125100
 141. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125100
 142. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125121
 143. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125121
 144. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125122
 145. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125122
 146. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-128485
 147. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-128485
 148. http://none/
 149. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125935
 150. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-125935
 151. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-126470
 152. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-126470
 153. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-138408
 154. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-138408
 155. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-152531
 156. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-152531
 157. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-152547
 158. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/#comment-152547
 159. https://datahack.analyticsvidhya.com/user/profile/srk
 160. https://datahack.analyticsvidhya.com/user/profile/mark12
 161. https://datahack.analyticsvidhya.com/user/profile/nilabha
 162. https://datahack.analyticsvidhya.com/user/profile/nitish007
 163. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 164. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 165. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 166. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 167. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 168. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 169. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 170. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 171. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 172. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 173. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 174. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 175. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 176. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 177. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 178. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 179. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 180. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 181. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 182. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 183. http://www.analyticsvidhya.com/about-me/
 184. https://www.analyticsvidhya.com/about-me/team/
 185. https://www.analyticsvidhya.com/career-analytics-vidhya/
 186. https://www.analyticsvidhya.com/contact/
 187. https://www.analyticsvidhya.com/about-me/write/
 188. http://www.analyticsvidhya.com/about-me/
 189. https://www.analyticsvidhya.com/about-me/team/
 190. https://www.analyticsvidhya.com/about-me/team/
 191. https://www.analyticsvidhya.com/about-me/team/
 192. https://www.analyticsvidhya.com/career-analytics-vidhya/
 193. https://www.analyticsvidhya.com/about-me/team/
 194. https://www.analyticsvidhya.com/contact/
 195. https://www.analyticsvidhya.com/blog
 196. https://datahack.analyticsvidhya.com/
 197. https://discuss.analyticsvidhya.com/
 198. https://www.analyticsvidhya.com/jobs/
 199. https://datahack.analyticsvidhya.com/users/
 200. https://www.analyticsvidhya.com/corporate/
 201. https://trainings.analyticsvidhya.com/
 202. https://datahack.analyticsvidhya.com/
 203. https://www.analyticsvidhya.com/contact/
 204. https://www.analyticsvidhya.com/contact/
 205. https://datahack.analyticsvidhya.com/signup/
 206. https://www.facebook.com/analyticsvidhya/
 207. https://www.facebook.com/analyticsvidhya/
 208. https://twitter.com/analyticsvidhya
 209. https://twitter.com/analyticsvidhya
 210. https://plus.google.com/+analyticsvidhya
 211. https://in.linkedin.com/company/analytics-vidhya
 212. https://in.linkedin.com/company/analytics-vidhya
 213. https://www.analyticsvidhya.com/privacy-policy/
 214. https://www.analyticsvidhya.com/terms/
 215. https://www.analyticsvidhya.com/refund-policy/
 216. https://id.analyticsvidhya.com/accounts/signup/
 217. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 218. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 219. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 220. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 222. https://www.facebook.com/analyticsvidhya
 223. https://twitter.com/analyticsvidhya
 224. https://plus.google.com/+analyticsvidhya/posts
 225. https://in.linkedin.com/company/analytics-vidhya
 226. https://www.analyticsvidhya.com/datafest-2017/
 227. https://www.analyticsvidhya.com/blog/2017/03/backend-developer-gurgaon-india-3-7-years-of-experience/
 228. https://www.analyticsvidhya.com/blog/2017/03/bi-architect-us-8-years-of-experience/
 229. https://www.analyticsvidhya.com/blog/author/guest-blog/
 230. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 231. https://www.facebook.com/analyticsvidhya/
 232. https://twitter.com/analyticsvidhya
 233. https://plus.google.com/+analyticsvidhya
 234. https://plus.google.com/+analyticsvidhya
 235. https://in.linkedin.com/company/analytics-vidhya
 236. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 237. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 238. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 239. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 240. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 241. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 242. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 243. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 244. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 245. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 246. javascript:void(0);
 247. javascript:void(0);
 248. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 249. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 250. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 251. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 252. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 253. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 254. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 255. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 256. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 257. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fimbalanced-classification-problem%2f&linkname=how%20to%20handle%20imbalanced%20classification%20problems%20in%20machine%20learning%3f
 258. javascript:void(0);
 259. javascript:void(0);
