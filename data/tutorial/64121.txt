   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

machine learning from scratch: part 2

collections and data

   [16]go to the profile of sebastian kwiatkowski
   [17]sebastian kwiatkowski (button) blockedunblock (button)
   followfollowing
   feb 25, 2018

table of contents

     * [18]part 1: attributes and patterns
     * part 2: collections and data
     * [19]part 3: arrays and representations
     * [20]part 4: functions and classifiers
     __________________________________________________________________

   thanks so much for your interest and positive feedback! i am delighted
   to see that many of you find the material useful. this series is
   gradually developing into a comprehensive and self-contained tutorial
   on the most important topics in applied machine learning.

   [21]last time, we focused on attributes and patterns. the first part of
   this article expands our conceptual toolbox through a discussion of
   data sets and collections. the second part then takes a look at natural
   language processing and applies the new concepts.
     __________________________________________________________________

data

data points

   some of the first associations that should come to mind when you hear
   the term    data    are collecting, counting, evaluating, logging,
   measuring, quantifying, rating, surveying, tracking and weighing. these
   are the activities that provide the precious raw material for machine
   learning.

   data is any collection of measured attribute values. biomarkers,
   financial numbers, sales figures, network connections, survey
   responses, user activity, video recordings, word counts and the number
   of available flavors in your favorite ice cream parlor all fall under
   the rubric of data.

   a datum is a single measurement of an attribute value. one datum is the
   number of words in this article (2,268).

   suppose we are interested in a particular set of attributes and measure
   their values on several occasions         perhaps at different times, at
   different locations or for different objects. a collection of such
   measurements taken on any one of these occasions is a data point.

   fitness trackers, for example, take measurements of cardiovascular
   performance, activity levels and sleep quality. the data collected for
   a particular person at a particular time constitutes one data point.

examples

   an example is a data point that has been collected in an effort to
   solve a machine learning problem.

   if we wanted to predict the performance of online advertisements, each
   example would characterize a particular display of an advertisement
   that occurred in the past. this includes features with regard to the
   position, format and design of the advertisement as well as the
   presence or absence of certain words and demographic data about the
   user it was presented to.

   an example is labeled when it includes a target value and is unlabeled
   when the target value is absent.

   in the advertising example, an example is labeled when it includes a
   performance measure, such as a yes/no value that indicates whether the
   ad was clicked on.

data sets

   a data set is a collection of examples.

   supervised learning uses data sets with labeled examples. unsupervised
   learning, a type of learning that will be covered in later chapters, is
   an attempt to recognize patterns in unlabeled examples.
   [0*5qufd6_rovdxbrbb.]
   fig. 1

   during development, data sets are used as sources for pattern
   recognition and to evaluate the performance of a machine learning
   system.

   in production, the system is shown new data points. these data points
   are often similar but rarely identical to the examples that were
   available during development.

collections

   data is arranged in collections.

   the following tree shows the types of collections that will be used
   throughout this series:
   [0*wpkxteghrzebjyuz.]
   fig. 2

   the two basic collection types are sets and lists.

sets

   a set is a collection of distinct objects. in other words, no object
   can occur more than once. the objects that belong to a set are called
   members or elements. the number of elements in a set is known as its
   cardinality or the size of the set.

   specific sets are denoted with capital letters. members of sets are
   written in lowercase letters.

   curly brackets indicate a collection of a objects form a set. a set of
   basic ice cream flavors could look like this: s = { vanilla, chocolate,
   strawberry }.

   the fact that an element x belongs to a set s is written x     s. the
   size of a set s is denoted with vertical bars: |s|.

   in the previous example, we have vanilla     s and |s|=3.

lists

   a list, by contrast, is a collection in which objects can occur more
   than once. the objects that belong to a list are referred to as items
   or elements. the number of items that a list contains is known as the
   size or the length of the list.

   i will use square brackets to denote lists. a customer order of two
   scoops of strawberry ice cream and one scoop of vanilla at our basic
   ice cream parlor can be represented through the following list: [
   strawberry, strawberry, vanilla ].

   note that a list is the right choice in this case. a business that used
   sets to represent orders would be unable to serve the correct number of
   requested scoops of ice cream.

tuples and lists of variable length

   lists can be further divided into two sub-types:
     * tuples (lists of fixed length)
     * lists of variable length

   a tuple is a list of a fixed length. in other words, you can neither
   add additional items nor remove any of the existing items.

   tuples of length 2 and 3 are called pairs and triples, respectively.
   tuples of length 1 are unlikely to be used anytime soon in this series.
   (for the sake of completeness, i will note that they are referred to as
   singletons.) two different naming schemes are used for tuples with a
   length of 4 or greater. some people prefer latin prefixes and refer to
   these lists as quadruples, quintuples, sextuples, etc. others prefer to
   call them 4-tuples, 5-tuples, 6-tuples, and so forth.

   a tuple is denoted by parentheses and can be used to represent a datum.

   suppose you are running an e-commerce site that offers a single product
   and allows customers to post a rating. in this case, a basic
   representation of a rating takes the form of a pair: (customer id,
   rating). as soon as you add a second product to the site, the format
   needs to extended from a pair to a triple: (customer id, product id,
   rating). a fourth item becomes necessary when you offer multiple
   products and allow customers to change their ratings over time:
   (customer id, product id, date and time, rating).

   in other words, the length of a tuple often depends on how much
   contextual information you would like to encode.

   a variable-length list is used when the number of items changes or
   cannot be predicted in advance. new items can be added and existing
   items can removed. unless stated otherwise, the term list will always
   refer to lists of a variable length.

   to conclude our discussion of basic collections, i   m providing an
   overview of the three types that we have covered:
   [0*l0i2snsinl7ammg0.]
   fig. 3

higher-order collections

   before i forget, one last thing on this topic: collections can be
   organized in collections.

   in other words, we can have sets of sets, sets of lists, sets of
   tuples, lists of sets, list of lists, list of tuples, tuples of sets,
   tuples of lists and tuples of tuples. i will refer to these objects as
   higher-order collections.

   an image, for example, can be represented through the red/green/blue
   pixel intensities. for each of these three color channels, we have one
   list of intensities. the image as a whole can be regarded as a list of
   three lists. several images, in turn, form a list of lists of three
   lists.

   it was mentioned that a datum can be thought of as a tuple and that a
   data point is a collection of attribute values (measured for a
   particular purpose and on a particular occasion). equipped with the
   concept of higher-order collections, we can now understand a data point
   as a set of tuples. finally, a data set in supervised learning can be
   described as a list of labeled examples, which, in turn, are pairs,
   consisting of a set of tuples (the data point) and a target value.

   as you can see, we can easily build increasingly complex higher-order
   collections from basic collections.
     __________________________________________________________________

big text data

   now that we have discussed data sets and collections, we can take a
   first look at one of the most fruitful applications of machine learning
   in recent times: the analysis of natural language.

   throughout this series, we will explore methods that can be applied to
   text data and images. this is motivated by two facts:
    1. most state-of-the-art results in id161 and natural
       language processing have been achieved through machine learning.[1,
       2]
    2. a large fraction of the output of our civilization is encoded in
       text or image form.

   [0*slfkzkx5axaw6jj0.jpg]
   fig. 4: the long room of the old library at trinity college dublin
   (photo by [22]david iliff / cc by-sa 4.0)

   in 2010, the google books search project reported a count of close to
   130 million distinct books[3], while the number of scientific articles
   has been estimated to have passed 50 million by 2009[4].

   the number of patents issued by the united states patent and trademark
   office alone has reached 8 millions in 2011.[5] to be awarded a patent,
   an inventor must disclose technical information. whatever the economic
   impact of patents may be, they clearly contain valuable insights and
   are subject to machine learning analysis.

   id103 translates speech into text and, thus, further
   broadens the scope of text analysis. on average, humans speak about
   16,000[6] words per day. globally, this amounts to more than one
   hundred trillion words spoken over the course of twenty-four hours.
   furthermore, it has been reported that 400 hours of video content are
   uploaded to youtube every minute.[7]

   the existence of overwhelmingly large amounts of text data, combined
   with the ability of machines to learn, has given rise to machine
   reading. the answers provided to us every day by search engines and
   virtual assistants are, in large parts, obtained through systems that
   have read through millions of text documents.

   we expect that our artificially intelligent assistants cover a broad
   range of topics and provide accurate answers. all other things being
   equal, a greater availability of data helps with both requirements: it
   increases the coverage and leads to a boost in the ability to recognize
   patterns.

lexical variety

   we can use the difference between lists and sets to compute our first
   natural language processing feature.

   the vocabulary is the set of words in a text document. in other words,
   this is the collection of words that occur at least once in the
   document. the actual text, on the other hand, can be thought of as a
   list of words (and some other symbols).

   suppose your objective is to determine the suitability of a book for
   entry-level language learners. one of the features you can use for this
   task is the ratio between the size of vocabulary (set size) and the
   length of the text (list size). this is known as one of several
   measures of lexical variety.

   the value of this feature is relatively low for children books and text
   books for foreign language learners. in these cases, the size of the
   vocabulary is small and the length of the text is (relatively) large to
   provide ample learning opportunities.

   on the other end of the spectrum, we have herman melville   s novel
   moby-dick. forty-four percent of the words in the moby-dick vocabulary
   occur only once and 75% occur no more than four times[8]. roughly
   speaking, a new word is introduced on every line of the book and the
   book is, thus, more suitable for advanced students and avid readers.

word counts

   the term word count is the epitome of self-descriptiveness. it denotes
   a pair that consists of a word and a count.

   an example is the fact that there are two occurrences of the word
   dexterity in melville   s novel.

   a single word count doesn   t really tell us anything. to start
   performing text analysis, we have to obtain the count for every word in
   the vocabulary.
   [0*rlci28z3z5kgmpyl.gif]
   fig. 5: word counts in melville   s    moby-dick   : each circle represents a
   word. words that occur once (hapax logemena) are shown in red. words
   that occur twice (dis legomena) are shown in blue.

   articles, prepositions and pronouns tend to be at the top of frequency
   rankings. the most frequently occurring word in moby-dick is the
   definite article the.[8]

   more interestingly, the words his and whale are ranked #9 and #21,
   respectively. even if we didn   t know anything else about the content,
   just by looking at these two statistics, it would seem likely that the
   book has something to do with a man and a whale.

   obtaining word counts is one of the very first steps in natural
   language processing workflows. counts may be processed and enriched
   with other features in sophisticated ways, but they always play at
   least some role.

   over the course of this series, we will expand upon word counts and
   systematically use them as the basis for effective text analysis.
     __________________________________________________________________

   the next part of this series will discuss how to precisely formulate a
   problem you are confronted with in terms of machine learning. it will
   combine all concepts that have been covered so far to introduce
   functions and to explore the notion of a model.

thank you for reading! if you   ve enjoyed this article, hit the clap button
and follow me to get the next articles in this series.
     __________________________________________________________________

references

   [1] lecun, y., bengio, y. and hinton, g., 2015. deep learning. nature,
   521(7553), p.436.

   [2] cambria, e. and white, b., 2014. jumping nlp curves: a review of
   natural language processing research. ieee computational intelligence
   magazine, 9(2), pp.48   57.

   [3]
   [23]http://booksearch.blogspot.de/2010/08/books-of-world-stand-up-and-b
   e-counted.html

   [4] jinha, a.e., 2010. article 50 million: an estimate of the number of
   scholarly articles in existence. learned publishing, 23(3), pp.258   263.

   [5]
   [24]https://www.uspto.gov/learning-and-resources/ip-motion/millions-pat
   ents

   [6] mehl, m.r., vazire, s., ram  rez-esparza, n., slatcher, r.b. and
   pennebaker, j.w., 2007. are women really more talkative than men?.
   science, 317(5834), pp.82   82.

   [7]
   [25]https://www.forbes.com/sites/stevenrosenbaum/2015/07/24/fans-selfie
   s-and-the-future-of-tv/#757de7435ffd

   [8] see, for example, li, w., miramontes, p. and cocho, g., 2010.
   fitting ranked linguistic data with two-parameter functions. id178,
   12(7), pp.1743   1764.

     * [26]artificial intelligence
     * [27]business
     * [28]machine learning
     * [29]data science
     * [30]towards data science

   (button)
   (button)
   (button) 1.4k claps
   (button) (button) (button) 2 (button) (button)

     (button) blockedunblock (button) followfollowing
   [31]go to the profile of sebastian kwiatkowski

[32]sebastian kwiatkowski

     (button) follow
   [33]towards data science

[34]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 1.4k
     * (button)
     *
     *

   [35]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [36]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/99ce4c78a3cc
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/machine-learning-from-scratch-part-2-99ce4c78a3cc&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/machine-learning-from-scratch-part-2-99ce4c78a3cc&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_ignbcojlw5gm---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@sekwiatkowski?source=post_header_lockup
  17. https://towardsdatascience.com/@sekwiatkowski
  18. https://towardsdatascience.com/machine-learning-from-scratch-part-1-76603dececa6
  19. https://towardsdatascience.com/machine-learning-from-scratch-part-3-ed572330367d
  20. https://towardsdatascience.com/machine-learning-from-scratch-part-4-10117c005a28
  21. https://towardsdatascience.com/machine-learning-from-scratch-part-1-76603dececa6
  22. https://en.wikipedia.org/wiki/trinity_college_library#/media/file:long_room_interior,_trinity_college_dublin,_ireland_-_diliff.jpg
  23. http://booksearch.blogspot.de/2010/08/books-of-world-stand-up-and-be-counted.html
  24. https://www.uspto.gov/learning-and-resources/ip-motion/millions-patents
  25. https://www.forbes.com/sites/stevenrosenbaum/2015/07/24/fans-selfies-and-the-future-of-tv/#757de7435ffd
  26. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  27. https://towardsdatascience.com/tagged/business?source=post
  28. https://towardsdatascience.com/tagged/machine-learning?source=post
  29. https://towardsdatascience.com/tagged/data-science?source=post
  30. https://towardsdatascience.com/tagged/towards-data-science?source=post
  31. https://towardsdatascience.com/@sekwiatkowski?source=footer_card
  32. https://towardsdatascience.com/@sekwiatkowski
  33. https://towardsdatascience.com/?source=footer_card
  34. https://towardsdatascience.com/?source=footer_card
  35. https://towardsdatascience.com/
  36. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  38. https://medium.com/p/99ce4c78a3cc/share/twitter
  39. https://medium.com/p/99ce4c78a3cc/share/facebook
  40. https://medium.com/p/99ce4c78a3cc/share/twitter
  41. https://medium.com/p/99ce4c78a3cc/share/facebook
