   [1]

linkedin

     * [2]sign in
     * [3]join now

   introduction to optimization with genetic algorithm

              introduction to optimization with genetic algorithm

   published on march 2, 2018march 2, 2018     85 likes     0 comments

   [4]ahmed gad

[5]ahmed gad[6]follow

job seeker. fritz/kdnuggets/tds contributor, t.a. & deep learning | machine
learning | id161 researcher

     * (button) like85
     * (button) comment0
     * [ ] share
          + (button) linkedin
          + (button) facebook
          + (button) twitter
       10

   selection of the optimal parameters values for machine learning tasks
   is challenging. some results may be bad not because the data is noisy
   or the used learning algorithm is weak, but due to the bad selection of
   the parameters values. this article gives a brief introduction about
   evolutionary algorithms (eas) and describes genetic algorithm (ga)
   which is one of the simplest random-based eas.

   introduction

   suppose that a data scientist has an image dataset divided into a
   number of classes and an image classifier is to be created. after the
   data scientist investigated the dataset, the k-nearest neighbor (knn)
   seems to be a good option. to use the knn algorithm, there is an
   important parameter to use which is k. suppose that an initial value of
   3 is selected. the scientist starts the learning process of the knn
   algorithm with the selected k=3. the trained model generated reached a
   classification accuracy of 85%. is that percent acceptable? in another
   way, can we get a better classification accuracy than what we currently
   reached? we cannot say that 85% is the best accuracy to reach until
   conducting different experiments. but to do another experiment, we
   definitely must change something in the experiment such as changing the
   k value used in the knn algorithm. we cannot definitely say 3 is the
   best value to use in this experiment unless trying to apply different
   values for k and noticing how the classification accuracy varies. the
   question is    how to find the best value for k that maximizes the
   classification performance?    this is what is called optimization.

   in optimization, we start with some kind of initial values for the
   variables used in the experiment. because these values may not be the
   best ones to use, we should change them until getting the best ones. in
   some cases, these values are generated by complex functions that we
   cannot solve manually easily. but it is very important to do
   optimization because a classifier may produce a bad classification
   accuracy not because, for example, the data is noisy or the used
   learning algorithm is weak but due to the bad selection of the learning
   parameters initial values. as a result, there are different
   optimization techniques suggested by operation research (or)
   researchers to do such work of optimization. according to [1],
   optimization techniques are categorized into four main categories:

   1.      constrained optimization

   2.      multimodal optimization

   3.      multiobjective optimization

   4.      combinatorial optimization

   looking at various natural species, we can note how they evolve and
   adapt to their environments. we can benefit from such already existing
   natural systems and their natural evolution to create our artificial
   systems doing the same job. this is called bionics. for example, the
   plane is based on how the birds fly, radar comes from bats, submarine
   invented based on fish, and so on. as a result, principles of some
   optimization algorithms comes from nature. for example, genetic
   algorithm (ga) has its core idea from charles darwin   s theory of
   natural evolution    survival of the fittest   . before getting into the
   details of how ga works, we can get an overall idea about evolutionary
   algorithms (eas).

   evolutionary algorithms (eas)

   we can say that optimization is performed using evolutionary algorithms
   (eas). the difference between traditional algorithms and eas is that
   eas are not static but dynamic as they can evolve over time.

   evolutionary algorithms have three main characteristics:

   1.      population-based: evolutionary algorithms are to optimize a
   process in which current solutions are bad to generate new better
   solutions. the set of current solutions from which new solutions are to
   be generated is called the population.

   2.      fitness-oriented: if there are some several solutions, how to
   say that one solution is better than another? there is a fitness value
   associated with each individual solution calculated from a fitness
   function. such fitness value reflects how good the solution is.

   3.      variation-driven: if there is no acceptable solution in the
   current population according to the fitness function calculated from
   each individual, we should make something to generate new better
   solutions. as a result, individual solutions will undergo a number of
   variations to generate new solutions.

   we will move to ga and apply these terms.

genetic algorithm (ga)

   the genetic algorithm is a random-based classical evolutionary
   algorithm. by random here we mean that in order to find a solution
   using the ga, random changes applied to the current solutions to
   generate new ones. note that ga may be called simple ga (sga) due to
   its simplicity compared to other eas.

   ga is based on darwin   s theory of evolution. it is a slow gradual
   process that works by making changes to the making slight and slow
   changes. also, ga makes slight changes to its solutions slowly until
   getting the best solution.

   here is the description of how the ga works:

   ga works on a population consisting of some solutions where the
   population size (popsize) is the number of solutions. each solution is
   called individual. each individual solution has a chromosome. the
   chromosome is represented as a set of parameters (features) that
   defines the individual. each chromosome has a set of genes. each gene
   is represented by somehow such as being represented as a string of 0s
   and 1s as in the next diagram.

   [:0]

   also, each individual has a fitness value. to select the best
   individuals, a fitness function is used. the result of the fitness
   function is the fitness value representing the quality of the solution.
   the higher the fitness value the higher the quality the solution.
   selection of the best individuals based on their quality is applied to
   generate what is called a mating pool where the higher quality
   individual has higher id203 of being selected in the mating pool.

   the individuals in the mating pool are called parents. every two
   parents selected from the mating pool will generate two offspring
   (children). by just mating high-quality individuals, it is expected to
   get a better quality offspring than its parents. this will kill the bad
   individuals from generating more bad individuals. by keeping selecting
   and mating high-quality individuals, there will be higher chances to
   just keep good properties of the individuals and leave out bad ones.
   finally, this will end up with the desired optimal or acceptable
   solution.

   but the offspring currently generated using the selected parents just
   have the characteristics of its parents and no more without changes.
   there is no new added to it and thus the same drawbacks in its parents
   will actually exist in the new offspring. to overcome such problem,
   some changes will be applied to each offspring to create new
   individuals. the set of all newly generated individuals will be the new
   population that replaces the previously used old population. each
   population created is called a generation. the process of replacing the
   old population by the new one is called replacement. the following
   diagram summarizes the steps of ga.

   [:0]

   there are two questions to be answered to get the full idea about ga:

   1.      how the two offspring are generated from the two parents?

   2.      how each offspring gets slightly changed to be an individual?

   we will answer these questions later.

   chromosome representation and evaluation

   there are different representations available for the chromosome and
   the selection of the proper representation is problem specific. the
   good representation is what makes the search space smaller and thus
   easier search.

   the representations available for the chromosome including:

             binary: each chromosome is represented as a string of zeros
   and ones.

             permutation: useful for ordering problems such as travelling
   salesman problem.

             value: the actual value is encoded as it is.

   for example, if we are to encode the number 7 in binary, it might look
   as follows:

   [:0]

   each part of the above chromosome is called gene. each gene has two
   properties. the first one is its value (allele) and the second one is
   the location (locus) within the chromosome which is the number above
   its value.

   each chromosome has two representations.

   1.      genotype: the set of genes representing the chromosome.

   2.      phenotype: the actual physical representation of the
   chromosome.

   in the above example, binary of 0111 is the genotype and 7 is the
   phenotype representation.

   after representing each chromosome the right way to serve to search the
   space, next is to calculate the fitness value of each individual.
   assume that the fitness function used in our example is:

   f(x) = 2x+2 where x is the chromosome value

   then the fitness value of the previous chromosome is:

   f(7) = 2(7)+2=16

   the process of calculating the fitness value of a chromosome is called
   evaluation.

   initialization

   after getting how to represent each individual, next is to initialize
   the population by selecting the proper number of individuals within it.

   selection

   next is to select a number of individuals from the population in the
   mating pool. based on the previously calculated fitness value, the best
   individuals based on a threshold are selected. after that step, we will
   end selecting a subset of the population in the mating pool.

   variation operators

   based on the selected individuals in the mating pool, parents are
   selected for mating. the selection of each two parents may be by
   selecting parents sequentially (1-2, 3-4, and so on). another way is
   random selection of the parents.

   for every two parents selected, there are a number of variation
   operators to get applied such as:

   1.      crossover (recombination)

   2.      mutation

   the next diagram gives an example for these operators.

   [:0]

   crossover

   crossover in ga generates new generation the same as natural mutation.
   by mutating the old generation parents, the new generation offspring
   comes by carrying genes from both parents. the amount of genes carried
   from each parent is random. remember that ga is random-based ea.
   sometimes the offspring takes half of its genes from one parent and the
   other half from the other parent and sometimes such percent changes.
   for every two parents, crossover takes place by selecting a random
   point in the chromosome and exchanging genes before and after such
   point from its parents. the resulting chromosomes are offspring. thus
   operator is called single-point crossover.

   note that crossover is important and without it, the offspring will be
   identical to its parent.

   mutation

   next variation operator is mutation. for each offspring, select some
   genes and change its value. mutation varies based on the chromosome
   representation but it is up to you to decide how to apply mutation. if
   the encoding is binary (i.e. the value space of each gene have just two
   values 0 and 1), then flip the bit value of one or more genes.

   but if the gene value comes from a space of more than two values such
   as 1,2,3,4, and 5, then the binary mutation will not be applicable and
   we should find another way. one way is by selecting a random value from
   such set of values as in the next diagram.

   [:0]

   note that without mutation the offspring will have all of its
   properties from its parents. to add new features to such offspring,
   mutation took place. but because mutation occurs randomly, it is not
   recommended to increase the number of genes to be applied to mutation.

   the individual after mutation is called mutant.

   [1] eiben, agoston e., and james e. smith. introduction to evolutionary
   computing. vol. 53. heidelberg: springer, 2003.

   [7]ahmed gad

[8]ahmed gad

job seeker. fritz/kdnuggets/tds contributor, t.a. & deep learning | machine
learning | id161 researcher

   [9]follow

   0 comments
   article-comment__guest-image
   [10]sign in to leave your comment
     __________________________________________________________________

more from ahmed gad

   [11]27 articles
   from y=x to building a complete id158

[12]from y=x to building a complete artificial   

   march 29, 2019

   feature reduction using genetic algorithm with python

[13]feature reduction using genetic algorithm   

   january 29, 2019

   id158s optimization using genetic algorithm with
   python

[14]id158s optimization   

   january 24, 2019

     *    2019
     * [15]about
     * [16]user agreement
     * [17]privacy policy
     * [18]cookie policy
     * [19]copyright policy
     * [20]brand policy
     * [21]manage subscription
     * [22]community guidelines
     * [ ]
          + (button) bahasa indonesia
          + (button) bahasa malaysia
          + (button)   e  tina
          + (button) dansk
          + (button) deutsch
          + (button) english
          + (button) espa  ol
          + (button)             
          + (button) fran  ais
          + (button)          
          + (button) italiano
          + (button)             
          + (button) nederlands
          + (button)          
          + (button) norsk
          + (button) polski
          + (button) portugu  s
          + (button) rom  n  
          + (button)               
          + (button) svenska
          + (button) tagalog
          + (button)                      
          + (button) t  rk  e
          + (button)               
       languagelanguage

references

   1. https://www.linkedin.com/?trk=header_logo
   2. https://www.linkedin.com/uas/login?trk=header_signin
   3. https://www.linkedin.com/start/join?trk=header_join
   4. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_image
   5. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_title
   6. https://www.linkedin.com/uas/login?session_redirect=https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad&trk=author-info__follow-button
   7. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_image
   8. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_title
   9. https://www.linkedin.com/uas/login?session_redirect=https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad&trk=author-info__follow-button-bottom
  10. https://www.linkedin.com/uas/login?session_redirect=https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad&trk=article-reader_leave-comment
  11. https://www.linkedin.com/today/author/ahmedfgad
  12. https://www.linkedin.com/pulse/from-yx-building-complete-artificial-neural-network-ahmed-gad?trk=related_artice_from y=x to building a complete id158_article-card_title
  13. https://www.linkedin.com/pulse/feature-reduction-using-genetic-algorithm-ahmed-gad?trk=related_artice_feature reduction using genetic algorithm with python_article-card_title
  14. https://www.linkedin.com/pulse/artificial-neural-networks-optimization-using-genetic-ahmed-gad?trk=related_artice_id158s optimization using genetic algorithm with python_article-card_title
  15. https://press.linkedin.com/about-linkedin?trk=article_reader_footer_footer-about
  16. https://www.linkedin.com/legal/user-agreement?trk=article_reader_footer_footer-user-agreement
  17. https://www.linkedin.com/legal/privacy-policy?trk=article_reader_footer_footer-privacy-policy
  18. https://www.linkedin.com/legal/cookie-policy?trk=article_reader_footer_footer-cookie-policy
  19. https://www.linkedin.com/legal/copyright-policy?trk=article_reader_footer_footer-copyright-policy
  20. https://brand.linkedin.com/policies?trk=article_reader_footer_footer-brand-policy
  21. https://www.linkedin.com/psettings/guest-controls?trk=article_reader_footer_footer-manage-sub
  22. https://www.linkedin.com/help/linkedin/answer/34593?lang=en&trk=article_reader_footer_footer-community-guide
