   #[1]kdnuggets: analytics, big data, data mining and data science feed
   [2]kdnuggets    feed [3]kdnuggets    comments feed [4]kdnuggets    a
   general approach to preprocessing text data comments feed [5]mega-paw:
   largest predictive analytics world, las vegas, june 2018     super early
   bird discount until dec 22 [6]exploring recurrent neural networks

kdnuggets

     [7]subscribe to kdnuggets news  | [8]twitter    [9]facebook
   [10]linkedin  |  [11]contact
   ____________________ search
   [menu-30.png]
   [search-icon.png]
     * [12]software
     * [13]news/blog
     * [14]top stories
     * [15]opinions
     * [16]tutorials
     * [17]jobs
     * [18]companies
     * [19]courses
     * [20]datasets
     * [21]education
     * [22]certificates
     * [23]meetings
     * [24]webinars


   [25]kdnuggets home    [26]news    [27]2017    [28]dec    [29]tutorials,
   overviews    a general approach to preprocessing text data
   ( [30]17:n46 )

a general approach to preprocessing text data

   [31][prv.gif] previous post
   [32]next post [nxt.gif]


   tags: [33]data preparation, [34]id174, [35]nlp, [36]text
   analytics, [37]id111

   recently we had a look at a framework for textual data science tasks in
   their totality. now we focus on putting together a generalized approach
   to attacking text id174, regardless of the specific
   textual data science task you have in mind.
     __________________________________________________________________

   by [38]matthew mayo, kdnuggets.

                                                            c [39]comments

   recently we looked at a [40]framework for approaching textual data
   science tasks. we kept said framework sufficiently general such that it
   could be useful and applicable to any id111 and/or natural
   language processing task.

   the high-level steps for the framework were as follows:
    1. data collection or assembly
    2. id174
    3. data exploration & visualization
    4. model building
    5. model evaluation

   though such a framework would, by nature, be iterative, we originally
   demonstrated it visually as a rather linear process. this update should
   put its true nature in perspective (with an obvious nod to the [41]kdd
   process):

                   a revised textual data task framework.
          a revised (but still simple) textual data task framework.

   clearly, any framework focused on the preprocessing of textual data
   would have to be synonymous with step number 2. expanding upon this
   step, specifically, we had the following to say about what this step
   would likely entail:

     * perform the preparation tasks on the raw text corpus in
       anticipation of id111 or nlp task
     * id174 consists of a number of steps, any number of
       which may or not apply to a given task, but generally fall under
       the broad categories of id121, id172, and
       substitution

   more generally, we are interested in taking some predetermined body of
   text and performing upon it some basic analysis and transformations, in
   order to be left with artefacts which will be much more useful for
   performing some further, more meaningful analytic task afterward. this
   further task would be our core id111 or natural language
   processing work.

   so, as mentioned above, it seems as though there are 3 main components
   of text preprocessing:
     * id121
     * id172
     * subsitution

   as we lay out a framework for approaching preprocessing, we should keep
   these high-level concepts in mind.


text preprocessing framework


   we will introduce this framework conceptually, independent of tools. we
   will then followup with a practical implementation of these steps next
   time, in order to see how they would be carried out in the python
   ecosystem.

                           preprocessing framework
                   the text id174 framework.

   1 - id121

   id121 is a step which splits longer strings of text into smaller
   pieces, or tokens. larger chunks of text can be tokenized into
   sentences, sentences can be tokenized into words, etc. further
   processing is generally performed after a piece of text has been
   appropriately tokenized. id121 is also referred to as text
   segmentation or lexical analysis. sometimes segmentation is used to
   refer to the breakdown of a large chunk of text into pieces larger than
   words (e.g. paragraphs or sentences), while id121 is reserved
   for the breakdown process which results exclusively in words.

   this may sound like a straightforward process, but it is anything but.
   how are sentences identified within larger bodies of text? off the top
   of your head you probably say "sentence-ending punctuation," and may
   even, just for a second, think that such a statement is unambiguous.

   sure, this sentence is easily identified with some basic segmentation
   rules:

     the quick brown fox jumps over the lazy dog.

   but what about this one:

     dr. ford did not ask col. mustard the name of mr. smith's dog.

   or this one:

     "what is all the fuss about?" asked mr. peters.

   and that's just sentences. what about words? easy, right? right?

     this full-time student isn't living in on-campus housing, and she's
     not wanting to visit hawai'i.

   it should be intuitive that there are varying strategies not only for
   identifying segment boundaries, but also what to do when boundaries are
   reached. for example, we might employ a segmentation strategy which
   (correctly) identifies a particular boundary between word tokens as the
   apostrophe in the word she's (a strategy tokenizing on whitespace alone
   would not be sufficient to recognize this). but we could then choose
   between competing strategies such as keeping the punctuation with one
   part of the word, or discarding it altogether. one of these approaches
   just seems correct, and does not seem to pose a real problem. but just
   think of all the other special cases in just the english language we
   would have to take into account.

   consideration: when we segment text chunks into sentences, should we
   preserve sentence-ending delimiters? are we interested in remembering
   where sentences ended?


   2 - id172

   before further processing, text needs to be normalized. id172
   generally refers to a series of related tasks meant to put all text on
   a level playing field: converting all text to the same case (upper or
   lower), removing punctuation, converting numbers to their word
   equivalents, and so on. id172 puts all words on equal footing,
   and allows processing to proceed uniformly.

   normalizing text can mean performing a number of tasks, but for our
   framework we will approach id172 in 3 distinct steps: (1)
   id30, (2) lemmatization, and (3) everything else.

   id30

   id30 is the process of eliminating affixes (suffixed, prefixes,
   infixes, circumfixes) from a word in order to obtain a word stem.

                               running     run

   lemmatization

   lemmatization is related to id30, differing in that lemmatization
   is able to capture canonical forms based on a word's lemma.

   for example, id30 the word "better" would fail to return its
   citation form (another word for lemma); however, lemmatization would
   result in the following:

                               better     good

   it should be easy to see why the implementation of a stemmer would be
   the less difficult feat of the two.

   everything else

   a clever catch-all, right? id30 and lemmatization are major parts
   of a text preprocessing endeavor, and as such they need to be treated
   with the respect they deserve. these aren't simple text manipulation;
   they rely on detailed and nuanced understanding of grammatical rules
   and norms.

   there are, however, numerous other steps that can be taken to help put
   all text on equal footing, many of which involve the comparatively
   simple ideas of substitution or removal. they are, however, no less
   important to the overall process. these include:
     * set all characters to lowercase
     * remove numbers (or convert numbers to textual representations)
     * remove punctuation (generally part of id121, but still worth
       keeping in mind at this stage, even as confirmation)
     * strip white space (also generally part of id121)
     * remove default stop words (general english stop words)

   stop words are those words which are filtered out before further
   processing of text, since these words contribute little to overall
   meaning, given that they are generally the most common words in a
   language. for instance, "the," "and," and "a," while all required words
   in a particular passage, don't generally contribute greatly to one's
   understanding of content. as a simple example, the following panagram
   is just as legible if the stop words are removed:

    [del: the :del] quick brown fox jumps over [del: the :del] lazy dog.

     * remove given (task-specific) stop words
     * remove sparse terms (not always necessary or helpful, though!)

   a this point, it should be clear that text preprocessing relies heavily
   on pre-built dictionaries, databases, and rules. you will be relieved
   to find that when we undertake a practical text preprocessing task in
   the python ecosystem in our next article that these pre-built support
   tools are readily available for our use; there is no need to be
   inventing our own wheels.


   3 - noise removal

   noise removal continues the substitution tasks of the framework. while
   the first 2 major steps of our framework (id121 and
   id172) were generally applicable as-is to nearly any text chunk
   or project (barring the decision of which exact implementation was to
   be employed, or skipping certain optional steps, such as sparse term
   removal, which simply does not apply to every project), noise removal
   is a much more task-specific section of the framework.

   keep in mind again that we are not dealing with a linear process, the
   steps of which must exclusively be applied in a specified order. noise
   removal, therefore, can occur before or after the previously-outlined
   sections, or at some point between).

   how about something more concrete. let's assume we obtained a corpus
   from the world wide web, and that it is housed in a raw web format. we
   can, then, assume that there is a high chance our text could be wrapped
   in html or xml tags. while this accounting for metadata can take place
   as part of the text collection or assembly process (step 1 of our
   textual data task framework), it depends on how the data was acquired
   and assembled. [42]this previous post outlines a simple process for
   obtaining raw wikipedia data and building a corpus from it. as we have
   control of this data collection and assembly process, dealing with this
   noise (in a reproducible manner) at this time makes sense.

   but this is not always the case. if the corpus you happen to be using
   is noisy, you have to deal with it. recall that analytics tasks are
   often talked about as being 80% data preparation!

   the good thing is that pattern matching can be your friend here, as can
   existing software tools built to deal with just such pattern matching
   tasks.
     * remove text file headers, footers
     * remove html, xml, etc. markup and metadata
     * extract valuable data from other formats, such as json, or from
       within databases
     * if you fear id157, this could potentially be the part
       of text preprocessing in which your worst fears are realized

   as you can imagine, the boundary between noise removal and data
   collection and assembly is a fuzzy one, and as such some noise removal
   must take place before other preprocessing steps. for example, any text
   required from a json structure would obviously need to be removed prior
   to id121.

   in our next post, we will undertake a practical hands-on text
   preprocessing task, and the presence of task-specific noise will become
   evident... and will be dealt with.


   related:
     * [43]a framework for approaching textual data science tasks
     * [44]building a wikipedia text corpus for natural language
       processing
     * [45]natural language processing key terms, explained
     __________________________________________________________________

   [46][prv.gif] previous post
   [47]next post [nxt.gif]
     __________________________________________________________________

top stories past 30 days

                                              most popular
    1. [48]another 10 free must-read books for machine learning and data
       science
    2. [49]9 must-have skills you need to become a data scientist, updated
    3. [50]who is a typical data scientist in 2019?
    4. [51]the pareto principle for data scientists
    5. [52]what no one will tell you about data science job applications
    6. [53]19 inspiring women in ai, big data, data science, machine
       learning
    7. [54]my favorite mind-blowing machine learning/ai breakthroughs

                                                most shared
    1. [55]id158s optimization using genetic algorithm
       with python
    2. [56]who is a typical data scientist in 2019?
    3. [57]8 reasons why you should get a microsoft azure certification
    4. [58]the pareto principle for data scientists
    5. [59]r vs python for data visualization
    6. [60]how to work in data science, ai, big data
    7. [61]the deep learning toolset     an overview

[62]latest news

     * [63]download your datax guide to ai in marketing
     * [64]kdnuggets offer: save 20% on strata in london
     * [65]training a champion: building deep neural nets for big ...
     * [66]building a recommender system
     * [67]predict age and gender using convolutional neural netwo...
     * [68]top tweets, mar 27     apr 02: here is a great ex...

more recent stories

     * [69]top tweets, mar 27     apr 02: here is a great explanat...
     * [70]odsc east is selling out; odsc india announced
     * [71]accelerate ai and data science career expo, may 4, 2019
     * [72]grow your data career at datasciencego, san diego, sep 27-29
     * [73]getting started with nlp using the pytorch framework
     * [74]how to diy your data science education
     * [75]top 8 data science use cases in gaming
     * [76]kdnuggets 19:n13, apr 3: top 10 data scientist coding mista...
     * [77]make better data-driven business decisions
     * [78]top stories, mar 25-31: r vs python for data visualization;
       th...
     * [79]two predictive analytics world events in europe this fall
     * [80]7 qualities your big data visualization tools absolutely must
       ...
     * [81]yeshiva university: tenure-track faculty in ai and machine
       lea...
     * [82]which face is real?
     * [83]yeshiva university: program director / tenure track faculty
       me...
     * [84]top 10 coding mistakes made by data scientists
     * [85]uber   s case study at paw industry 4.0: machine learning ...
     * [86]xai     a data scientist   s mouthpiece
     * [87]what does gpt-2 think about the ai arms race?
     * [88]openclassrooms: data freelance online course creator
       [telecomm...

   [89]kdnuggets home    [90]news    [91]2017    [92]dec    [93]tutorials,
   overviews    a general approach to preprocessing text data
   ( [94]17:n46 )
      2019 kdnuggets. [95]about kdnuggets.  [96]privacy policy. [97]terms
   of service

   [98]subscribe to kdnuggets news
   [99][tw_c48.png] [100]facebook [101]linkedin
   x
   [envelope.png] [102]get kdnuggets, a leading newsletter on ai, data
   science, and machine learning
   email: ______________________________
   sign up
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://www.kdnuggets.com/feed/
   2. https://www.kdnuggets.com/feed
   3. https://www.kdnuggets.com/comments/feed
   4. https://www.kdnuggets.com/2017/12/general-approach-preprocessing-text-data.html/feed
   5. https://www.kdnuggets.com/2017/11/paw-mega-predictive-analytics-world-las-vegas-june-2018.html
   6. https://www.kdnuggets.com/2017/12/exploring-recurrent-neural-networks.html
   7. https://www.kdnuggets.com/news/subscribe.html
   8. https://twitter.com/kdnuggets
   9. https://www.facebook.com/kdnuggets
  10. https://www.linkedin.com/groups/54257/
  11. https://www.kdnuggets.com/contact.html
  12. https://www.kdnuggets.com/software/index.html
  13. https://www.kdnuggets.com/news/index.html
  14. https://www.kdnuggets.com/news/top-stories.html
  15. https://www.kdnuggets.com/opinions/index.html
  16. https://www.kdnuggets.com/tutorials/index.html
  17. https://www.kdnuggets.com/jobs/index.html
  18. https://www.kdnuggets.com/companies/index.html
  19. https://www.kdnuggets.com/courses/index.html
  20. https://www.kdnuggets.com/datasets/index.html
  21. https://www.kdnuggets.com/education/index.html
  22. https://www.kdnuggets.com/education/analytics-data-mining-certificates.html
  23. https://www.kdnuggets.com/meetings/index.html
  24. https://www.kdnuggets.com/webcasts/index.html
  25. https://www.kdnuggets.com/
  26. https://www.kdnuggets.com/news/index.html
  27. https://www.kdnuggets.com/2017/index.html
  28. https://www.kdnuggets.com/2017/12/index.html
  29. https://www.kdnuggets.com/2017/12/tutorials.html
  30. https://www.kdnuggets.com/2017/n46.html
  31. https://www.kdnuggets.com/2017/11/paw-mega-predictive-analytics-world-las-vegas-june-2018.html
  32. https://www.kdnuggets.com/2017/12/exploring-recurrent-neural-networks.html
  33. https://www.kdnuggets.com/tag/data-preparation
  34. https://www.kdnuggets.com/tag/data-preprocessing
  35. https://www.kdnuggets.com/tag/nlp
  36. https://www.kdnuggets.com/tag/text-analytics
  37. https://www.kdnuggets.com/tag/text-mining
  38. https://www.kdnuggets.com/author/matt-mayo
  39. https://www.kdnuggets.com/2017/12/general-approach-preprocessing-text-data.html#comments
  40. https://www.kdnuggets.com/2017/11/framework-approaching-textual-data-tasks.html
  41. https://www.kdnuggets.com/2016/03/data-science-process-rediscovered.html/2
  42. https://www.kdnuggets.com/2017/11/building-wikipedia-text-corpus-nlp.html
  43. https://www.kdnuggets.com/2017/11/framework-approaching-textual-data-tasks.html
  44. https://www.kdnuggets.com/2017/11/building-wikipedia-text-corpus-nlp.html
  45. https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html
  46. https://www.kdnuggets.com/2017/11/paw-mega-predictive-analytics-world-las-vegas-june-2018.html
  47. https://www.kdnuggets.com/2017/12/exploring-recurrent-neural-networks.html
  48. https://www.kdnuggets.com/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html
  49. https://www.kdnuggets.com/2018/05/simplilearn-9-must-have-skills-data-scientist.html
  50. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  51. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  52. https://www.kdnuggets.com/2019/03/data-science-job-applications.html
  53. https://www.kdnuggets.com/2019/03/women-ai-big-data-science-machine-learning.html
  54. https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html
  55. https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html
  56. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  57. https://www.kdnuggets.com/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html
  58. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  59. https://www.kdnuggets.com/2019/03/r-vs-python-data-visualization.html
  60. https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html
  61. https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html
  62. https://www.kdnuggets.com/news/index.html
  63. https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html
  64. https://www.kdnuggets.com/2019/04/strata-kdnuggets-offer-save-london.html
  65. https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html
  66. https://www.kdnuggets.com/2019/04/building-recommender-system.html
  67. https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html
  68. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  69. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  70. https://www.kdnuggets.com/2019/04/odsc-east-selling-out-india-announced.html
  71. https://www.kdnuggets.com/jobs/19/04-03-accelerate-ai-data-science-career-expo-2019.html
  72. https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html
  73. https://www.kdnuggets.com/2019/04/nlp-pytorch.html
  74. https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html
  75. https://www.kdnuggets.com/2019/04/top-8-data-science-use-cases-gaming.html
  76. https://www.kdnuggets.com/2019/n13.html
  77. https://www.kdnuggets.com/2019/04/psu-make-better-data-driven-business-decisions.html
  78. https://www.kdnuggets.com/2019/04/top-news-week-0325-0331.html
  79. https://www.kdnuggets.com/2019/04/paw-two-predictive-analytics-world-events-europe-fall.html
  80. https://www.kdnuggets.com/2019/04/7-qualities-big-data-visualization-tools.html
  81. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-faculty-ai-machine-learning.html
  82. https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html
  83. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-program-director-faculty-artificial-intelligence-machine-learning.html
  84. https://www.kdnuggets.com/2019/04/top-10-coding-mistakes-data-scientists.html
  85. https://www.kdnuggets.com/2019/04/paw-uber-case-study-machine-learning-enforce-mobile-performance.html
  86. https://www.kdnuggets.com/2019/04/xai-data-scientist.html
  87. https://www.kdnuggets.com/2019/04/gpt-2-think-about-ai-arms-race.html
  88. https://www.kdnuggets.com/jobs/19/04-01-openclassrooms-data-freelance-online-course-creator-b.html
  89. https://www.kdnuggets.com/
  90. https://www.kdnuggets.com/news/index.html
  91. https://www.kdnuggets.com/2017/index.html
  92. https://www.kdnuggets.com/2017/12/index.html
  93. https://www.kdnuggets.com/2017/12/tutorials.html
  94. https://www.kdnuggets.com/2017/n46.html
  95. https://www.kdnuggets.com/about/index.html
  96. https://www.kdnuggets.com/news/privacy-policy.html
  97. https://www.kdnuggets.com/terms-of-service.html
  98. https://www.kdnuggets.com/news/subscribe.html
  99. https://twitter.com/kdnuggets
 100. https://facebook.com/kdnuggets
 101. https://www.linkedin.com/groups/54257
 102. https://www.kdnuggets.com/news/subscribe.html

   hidden links:
 104. https://www.kdnuggets.com/
 105. https://www.kdnuggets.com/
