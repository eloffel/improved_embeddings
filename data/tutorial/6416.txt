   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]chatbots life
     * [9]     start a project
     * [10]     tools
     * [11]    business
     * [12]     voice
     * [13]     tutorials
     * [14]     design
     * [15]            ai & nlp
     * [16]     ai for shopify
     __________________________________________________________________

tensorflow demystified

   [17]go to the profile of gk_
   [18]gk_ (button) blockedunblock (button) followfollowing
   mar 28, 2017

   to understand a new framework, google   s tensorflow is a framework for
   machine-learning calculations, it is often useful to see a    toy   
   example and learn from it.
   [1*kxcdbcu7gjkjfvktip-nta.png]

   here is google   s description of the framework: tensorflow    is an open
   source software library for numerical computation using data flow
   graphs. nodes in the graph represent mathematical operations, while the
   graph edges represent the multidimensional data arrays (tensors)
   communicated between them.

     what goes on within machine learning code is math, it helps to
     organize this in a way that simplifies and keeps the computative
     flow organized.

tensors

   first of all: what is a    tensor    and how does it have    flow   ?

   a    vector    is a list of values, a    matrix    is a table (or list of
   lists)    then there is a list of tables (or list of lists of lists),
   then a table of tables (or list of lists of tables   ). and so on. all of
   these are    tensors    and they appear everywhere in machine learning
   equations.

   let   s take a multi-layer neural network as an example [19]we   re already
   explored.

   in this example we see input data features (   x1   ,    x2   ,    ) going
   through 2 hidden layers, each with nodes (   neurons   ), each with weights
   (   w   ) and bias (   b   ), the output is y.
   [1*mf-zdrborrug-ki20tjkzg.png]
   credit: [20]sebastian raschka

   this becomes a series (a    flow   ) of numerical computation (   math   )
   going from input (   x   ) to output (   y   ). the math involves
   multi-dimensional matrices (   tensors   ), constants and variables (eg.
   bias    b1   ). the definition and execution of this mathematical flow
   across tensors is what the tensorflow framework is about.
   [1*ymtjakz0pd8z2gtyadpk4a.png]

   as a result of repeating this    flow    the weights and biases adjust to
      fit    the expected output and a model is built. the framework can have
   some of the math performed on faster    gpu    processors, which is very
   useful when working [21]with large quantities of data. but besides
   this, a framework for doing a lot of math across a series of equations
   is useful to organize and simplify the code. that   s what any framework
   strives to do.

   most tutorials on tensorflow (or other machine learning frameworks)
   jump straight to [22]recognizing hand-written digits or [23]classifying
   iris flowers. of course having substantive data is useful, but this
   isn   t really    toy    data from the perspective of a machine-learning
   newbie.

     for training data to achieve    toy    status the data itself should be
     intuitive and easily grasped.

toy data

   let   s imagine an array of 5 bits, this is our input. the output is
   [0,1] or [1,0] depending on: the 1st and last bit both being on or not.

     [0, 1, 1, 1, 1], [0,1]
     [1, 1, 1, 1, 0], [0,1]
     [1, 1, 1, 0, 0], [0,1]
     [1, 1, 0, 0, 0], [0,1]
     [1, 0, 0, 0, 1], [1,0]
     [1, 1, 0, 0, 1], [1,0]
     [1, 1, 1, 0, 1], [1,0]
     [1, 0, 0, 1, 1], [1,0]

   the entire dataset and its output makes intuitive sense, you (or any
   reasonably sentient person) could find the pattern instinctively just
   by looking at the data.

   what if we trained a machine-learning model on several of these
   patterns, then asked it to predict a 5-bit pattern it hadn   t been
   trained on? would it predict the correct result? that   s a good    toy   
   problem to work through, and it is    machine learning   , by definition:
   the software learns the patterns.

code

   we   re going to define some simple data, build a model in tensorflow and
   then use it to make predictions. the code is [24]here, using [25]python
   notebook.

   as always we begin with our imports, all common besides the framework.

   iframe: [26]/media/e085dd24d636176f3641301299f84567?postid=80987184faf7

   next we create the data:

   iframe: [27]/media/5e8c717843632126601ffdea0fe0de5a?postid=80987184faf7

   notice in the above setup we are shuffling the data (   features   ) and
   using 2/3 of it for training, 1/3 of it for testing. the ratio is the
   parameter    test_size   . each time we run this we   ll get a different set
   of training and testing data. experiment with this and introspect the
   resulting data lists.

   now we are ready to begin scaffolding our tensorflow model:

   iframe: [28]/media/6eb9f502b5a06681d53e37bde90ff0e4?postid=80987184faf7

   our data is loaded, we   ll use 20 nodes in 2 hidden layers and
   initialize weights and biases with random values. we also define our
   output layer.

   we are now ready to define the mathematical equations for our model:

   iframe: [29]/media/5f0812d0562a5f01e968f13666befec2?postid=80987184faf7

   look at the computations carefully and compare them to the earlier
   diagrams. we are multiplying (tf.matmul) data, matrices (   tensors   ),
   weights, biases, and we are using id180 such as
   tf.sigmoid. the framework has built-in functions that are commonly used
   in machine learning.

     # hidden layer 1: (data * w) + b

     l1 = tf.add(tf.matmul(data,hidden_1_layer[   weight   ]),
     hidden_1_layer[   bias   ]) l1 = tf.sigmoid(l1)

   all of this is the same as when we [30]worked through the code for a
   2-layer neural network, but now we   re using a framework to simplify the
   task         less code, the computations themselves are abstracted. read
   carefully through the diagrams, the earlier code and this new
   tensorflow code and you should see that it is all equivalent.
   [31]id127 is simple.

     there   s no black-magic here: math is math.

   we are now ready to train our model:

   iframe: [32]/media/162a4dbca4968fa451e4d6deb70ed428?postid=80987184faf7

   again if you compare this with the 2-layer neural network example
   [33]without using any framework, the training process is the same. we
   are iterating through cycles    epochs    to get our error (   cost   ) rate
   low and then our model is ready.

   let   s look at the output and then review the training code in more
   detail.
epoch   0 completed out of 1000 cost: 1.06944
epoch 200 completed out of 1000 cost: 0.000669607
epoch 400 completed out of 1000 cost: 0.00030982
epoch 600 completed out of 1000 cost: 0.00019792
epoch 800 completed out of 1000 cost: 0.00014411
accuracy: 1.0
prediction for: [1, 1, 1, 1, 1]
0.998426 0.392255
prediction for: [1, 0, 1, 1, 1]
0.99867 0.364066
prediction for: [0, 0, 1, 1, 1]
0.028218 0.997783
prediction for: [0, 1, 0, 1, 1]
0.0528865 0.997093
prediction for: [1, 0, 0, 0, 1]
0.999507 0.413642
prediction for: [1, 0, 0, 1, 0]
0.0507428 0.998406

   notice the iterative reduction in error (   cost   ) over 1,000 cycles. the
   accuracy calculation is processed by iteratively applying the model to
   our test data (which was not used in training the model).

   we can then see a prediction for each entry in our test data. an output
   of [1,0] means a pattern of[1, _, _, _, 1], an output of [0,1] means
   some other pattern. each value in the output is a id203, so:
prediction for: [1, 0, 0, 1, 0]
0.0507428 0.998406

   means our model strongly believes the [1, _, _, _, 1] pattern does not
   apply.

   as with any    toy    example all of the data is easily grasped so you can
   focus on the code. this 2-layer ann is no different than one you could
   use to classify iris flowers or stock market trends.

more about the training code

   back to the training code, we assign a variable named    prediction    to
   our model, very simply:

     # use the model definition
      prediction = neural_network_model(x)

   then we tell the framework how to optimize for error:

     c =
     tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(prediction,y)
     )
      optimizer = tf.train.gradientdescentoptimizer(1).minimize(c)

   we can use [34]other optimization methods built into the framework.

   then we loop through our epochs to fit our model:

     with tf.session() as sess:
      sess.run(tf.global_variables_initializer())

     for epoch in range(hm_epochs):
      _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y:
     batch_y})

   with each batch of training data, the model improves (lowers the error
   for) its weights and biases.

   the accuracy of the model is a calculation across our test data:

     correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))
     accuracy = tf.reduce_mean(tf.cast(correct,    float   ))
     print(   accuracy:   ,accuracy.eval({x:test_x, y:test_y}))

   and making a prediction on some new data is relatively simple, we use
   the activation function again to normalize output values between 0 and
   1.

     print (   prediction for:   , test_x)
     output = prediction.eval(feed_dict = {x: [test_x]})
     print(tf.sigmoid(output[0][0]).eval(),
     tf.sigmoid(output[0][1]).eval())

what happened?

   we    taught    a machine learning algorithm about a 5-bit pattern, and it
   learned by looking at training data:

   [1, _, _, _, 1] and not. it    learned    this by looking at example, not
   by being told what the rules of the pattern are. that would have been
   trivial, and idiotic, as follows:

   iframe: [35]/media/51a49980cb2ff0b3a20034f705fa3855?postid=80987184faf7

   of course this wouldn   t be    machine learning   , it   s just a reduction of
   the problem using code. if we have to reduce something like image
   recognition in code we are in trouble. that   s where these predictive
   models come in         forged by numerics created as data flows through
   equations.

   you should now be better equipped to work through some    real    problems,
   such as [36]recognizing hand-written digits.
   [1*wn3k1ggs1spjukg2pl0cew.png]

   enjoy.

   iframe: [37]/media/47a0a8491046a6d8bdbb86880dd8fc1e?postid=80987184faf7

   [1*bqlrszfhjemf4q7pyrlgng.gif]
   [38][1*6xuspt9josq0w0fi35hiaa.png]
   [39][1*c1ldmh5vbniz9rmaka8hwg.png]
   [40][1*d0jf3di6zthtqcfwdyy7mg.png]

     * [41]machine learning
     * [42]neural networks
     * [43]tensorflow
     * [44]artificial intelligence
     * [45]how to

   (button)
   (button)
   (button) 600 claps
   (button) (button) (button) 5 (button) (button)

     (button) blockedunblock (button) followfollowing
   [46]go to the profile of gk_

[47]gk_

   philosopher, entrepreneur, investor

     (button) follow
   [48]chatbots life

[49]chatbots life

   best place to learn about chatbots. we share the latest bot news, info,
   ai & nlp, tools, tutorials & more.

     * (button)
       (button) 600
     * (button)
     *
     *

   [50]chatbots life
   never miss a story from chatbots life, when you sign up for medium.
   [51]learn more
   never miss a story from chatbots life
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://chatbotslife.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/80987184faf7
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://chatbotslife.com/tensorflow-demystified-80987184faf7&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://chatbotslife.com/tensorflow-demystified-80987184faf7&source=--------------------------nav_reg&operation=register
   8. https://chatbotslife.com/?source=logo-lo_g2ayrdw63d2t---a49517e4c30b
   9. https://chatbotslife.com/chatbot-development-hire-top-ai-chatbot-developers-c8b45ef7f207
  10. https://chatbotslife.com/chatbot-tools-62dfc60d2b8a
  11. https://chatbotslife.com/bots-for-business/home
  12. https://chatbotslife.com/tagged/voice-assistant
  13. https://chatbotslife.com/tagged/how-to
  14. https://chatbotslife.com/tagged/user-experience
  15. https://chatbotslife.com/tagged/artificial-intelligence
  16. https://www.gobeyond.ai/
  17. https://chatbotslife.com/@gk_?source=post_header_lockup
  18. https://chatbotslife.com/@gk_
  19. https://medium.com/@gk_/how-neural-networks-work-ff4c7ad371f7
  20. http://sebastianraschka.com/
  21. https://medium.com/p/image-recognition-demystified-fc9c89b894ce
  22. https://www.tensorflow.org/get_started/mnist/beginners
  23. https://en.wikipedia.org/wiki/iris_flower_data_set
  24. https://github.com/ugik/notebooks/blob/master/tensorflow ann.ipynb
  25. https://ipython.org/ipython-doc/3/notebook/
  26. https://chatbotslife.com/media/e085dd24d636176f3641301299f84567?postid=80987184faf7
  27. https://chatbotslife.com/media/5e8c717843632126601ffdea0fe0de5a?postid=80987184faf7
  28. https://chatbotslife.com/media/6eb9f502b5a06681d53e37bde90ff0e4?postid=80987184faf7
  29. https://chatbotslife.com/media/5f0812d0562a5f01e968f13666befec2?postid=80987184faf7
  30. https://medium.com/p/how-neural-networks-work-ff4c7ad371f7
  31. https://en.wikipedia.org/wiki/matrix_multiplication
  32. https://chatbotslife.com/media/162a4dbca4968fa451e4d6deb70ed428?postid=80987184faf7
  33. https://medium.com/p/how-neural-networks-work-ff4c7ad371f7
  34. https://www.tensorflow.org/api_guides/python/train
  35. https://chatbotslife.com/media/51a49980cb2ff0b3a20034f705fa3855?postid=80987184faf7
  36. https://www.tensorflow.org/get_started/mnist/beginners
  37. https://chatbotslife.com/media/47a0a8491046a6d8bdbb86880dd8fc1e?postid=80987184faf7
  38. https://chatbotslife.com/bot-communities-mastermind-group-d2dae9876709#.53x0py6ou
  39. https://m.me/chatbotslife
  40. https://chatbotslife.com/how-to-get-a-free-chatbot-b1fb9dfe109#.z9dtp2sy0
  41. https://chatbotslife.com/tagged/machine-learning?source=post
  42. https://chatbotslife.com/tagged/neural-networks?source=post
  43. https://chatbotslife.com/tagged/tensorflow?source=post
  44. https://chatbotslife.com/tagged/artificial-intelligence?source=post
  45. https://chatbotslife.com/tagged/how-to?source=post
  46. https://chatbotslife.com/@gk_?source=footer_card
  47. https://chatbotslife.com/@gk_
  48. https://chatbotslife.com/?source=footer_card
  49. https://chatbotslife.com/?source=footer_card
  50. https://chatbotslife.com/
  51. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  53. https://medium.com/p/80987184faf7/share/twitter
  54. https://medium.com/p/80987184faf7/share/facebook
  55. https://medium.com/p/80987184faf7/share/twitter
  56. https://medium.com/p/80987184faf7/share/facebook
