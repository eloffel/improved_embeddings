   [1]ideas [2]learning platform [3]conferences [4]shop
   search ____________________ submit
   [5]sign in

on our radar

   [6]ai
   [7]data
   [8]economy
   [9]operations
   [10]software architecture
   [11]software engineering
   [12]web programming
   [13]see all

   [14]ideas [15]learning platform [16]conferences [17]shop search
   ____________________ submit

on our radar

   [18]ai
   [19]data
   [20]economy
   [21]operations
   [22]software architecture
   [23]software engineering
   [24]web programming
   [25]see all

   [26]data science

comparing production-grade nlp libraries: accuracy, performance, and scalability

   a comparison of the accuracy and performance of spark-nlp vs. spacy,
   and some use case recommendations.

   by [27]saif addin ellafi

   february 28, 2018

   fractal complexity fractal complexity (source: [28]pixabay)

   [29]check out the "natural language understanding at scale with spacy
   and spark nlp" tutorial session at the strata data conference in
   london, may 21-24, 2018.

   this is the third and final installment in [30]this blog series
   comparing two leading open source natural language processing software
   libraries: [31]john snow labs    nlp for apache spark and [32]explosion
   ai   s spacy. in the previous two parts, we walked through the code for
   training id121 and part-of-speech models, running them on a
   benchmark data set, and evaluating the results. in this part, we
   compare the accuracy and performance of both libraries on this and
   additional benchmarks, and provide recommendations on which use cases
   fit each library best.

accuracy

   here are the accuracy comparisons from the models training in [33]part
   1 of this blog series:
   model accuracy comparison figure 1. model accuracy comparison. image
   courtesy of saif addin ellafi.

   spacy   s pre-trained model does a great job predicting part-of-speech
   tags in english text. if your text is standard, news- or article-based
   text (i.e., not domain-specific text like legal documents, financial
   statements, or medical records), and in one of the [34]seven languages
   supported by spacy, this is a great way to go. note that pretrained
   results here include our custom tokenizer, otherwise accuracy (and
   particularly the ratio of matched tokens) would go down (see figure 2).

   spacy   s self-trained model and spark-nlp perform similarly when trained
   using the same training data, at about 84% accuracy.

   a major impact of spacy   s accuracy seems to come not from trained data
   but from the english vocab content, where spark-nlp assumes nothing on
   language   it is fully language agnostic   and only learns from whatever
   the annotators on the pipeline get to know. this means that the same
   code and algorithms, on training data from another language, should
   work without change.
   id121 accuracy comparison figure 2. id121 accuracy
   comparison. image courtesy of saif addin ellafi.

   we see here that our modified spacy tokenizer makes significant impact
   to better match our target anc corpus tokens. using    out-of-the-box   
   spacy for this benchmark would deliver inferior results. this is very
   common in natural language understanding: domain-specific models must
   be trained to learn the nuances, context, jargon, and grammar of the
   input text.

performance

   although things looks happy when we train and predict about 77 kb of
   .txt files (resulting in 21,000 words to predict and compare), when we
   train against twice the number of files, and predict 9,225 files as
   opposed to 14, things don   t look so happy anymore. of course, this
   isn   t    big data    by any measure, but more realistic than a
   toy/debugging scenario. here are the facts:
spark-nlp 75mb prediction
time to train: 4.798381899 seconds
time to predict + collect: 311.773622473 seconds
total words: 13,441,891

   training on spacy was a little bit more troublesome because i faced
   several issues on weird characters and text format in training
   data   even though i'd already cleaned it in the training algorithm we
   saw before. after working it around, i got an exponential increase in
   the amount of time to train, so i had to estimate the amount of time it
   would take, based on how it scaled as i increased the number of files
   in the training folder, which returned about two hours or more.
spacy 75mb prediction
time to train: 386.05810475349426 seconds
time to predict + collect: 498.60224294662476 seconds
total words: 14,340,283

   training scalability figure 3. training scalability. image courtesy of
   saif addin ellafi.

   figure 3 shows that for this 75mb benchmark:
     * spark-nlp was more than 38 times faster to train 100 kb of data and
       about 80 times faster to train 2.6 mb. scalability difference is
       significant.
     * spark-nlp   s training itself did not grow significantly when data
       grew from 100 kb to 2.6 mb
     * spacy   s training time grows exponentially as we increase the data
       size

   figure 4 shows the runtime performance comparison of running the
   spark-nlp pipeline   i.e., using the models after the training phase is
   done. spacy is fast on small data sets, but it does not scale as well
   as spark-nlp does. for these benchmarks:
     * spacy was faster on 140 kb data sets (both libraries finished in
       less than a second)
     * spark-nlp was 1.4 times faster on a 15 mb data set (roughly 40
       versus 70 seconds)
     * spark-nlp was 1.6 times faster on a 75 mb data set, taking about
       half the time to complete (roughly five versus nine minutes)

   spacy is highly optimized for single-machine execution. it   s written
   from the ground up in cython, and was validated in 2015 (two years
   before spark-nlp became available) as having the fastest syntactic
   parser when compared to other libraries written in python, java, and
   c++. spacy does not have the overhead of the jvm and spark that
   spark-nlp has, which gives it an advantage for small data sets.

   on the other hand, the heavy optimization that was done on spark over
   the years   especially for single-machine, standalone mode   shines here by
   taking the lead in data sets as small as a few megabytes. naturally,
   this advantage becomes more substantial as the data size grows, or as
   the complexity of the pipeline (more naturl language processing (nlp)
   stages, adding machine learning (ml) or deep learning (dl) stages)
   grows.
   runtime performance comparison figure 4. runtime performance
   comparison. image courtesy of saif addin ellafi.

scalability

   outside of these benchmarks, spark scales as spark does. how well
   depends on how you partition your data, whether you have wide or tall
   tables (the latter are better in spark), and most importantly, whether
   you use a cluster. here, for example, everything is on my local
   machine, and i am running a groupby filename operation, which means my
   table is wider than taller, since for every filename there is a large
   number of words. if i could, i would probably also avoid calling a
   collect(), which hits hard on my driver memory, as opposed to storing
   the result in distributed storage.

   in this case, for example, if i performed the groupby operation after
   the transform() step   basically merging the pos and tokens after the
   prediction   i   d be transforming a much taller table than the previous
   one (960,302 lines instead of 9,225, which was the number of files). i
   also have control over whether i oversubscribe my cpu cores into spark
   (e.g., local[6]) and the number of partitions i inject into the
   transform operation. there is usually a bell shape in performance when
   tuning spark performance; in my case, the optimum was about six
   subscribed cores and 24 partitions.

   on spacy, the parallel algorithm i showed in the previous sections
   doesn   t seem to significantly impact performance, while only gaining a
   few seconds out of the total prediction time.
   parallel algorithm impact figure 5. the impact of the parallel
   algorithm wasn't significant. image courtesy of saif addin ellafi.

   for an amazon emr cluster, in a simple comparison of the same
   algorithms, we notice a 2.5x speedup in the time for pos prediction
   when utilizing a distributed yarn cluster against a local-only
   counterpart on the same node. data sets in this scenario have been put
   in hdfs datanodes. in practice, this means you can achieve different
   cost/performance tradeoffs, using configuration only, with linear
   scaling. this is a core benefit of spark, spark ml, and spark-nlp.
   amazon emr cluster comparision figure 6. amazon emr cluster
   comparision. image courtesy of saif addin ellafi.

conclusion

   the use cases for the two libraries are quite different. if your needs
   are toward plugging in a small data set and getting output quickly,
   then spacy is a winner: you download your model per language, process
   the data, and pass it line by line to the nlp object. it contains a
   large vocabulary set of strategies on the language plus a bunch of
   state-of-the-art trained models that will respond back with highly
   optimized c++ (cython) performance. if you want to parallelize your
   task, customize a component (like we did for the tokenizer), or train
   models to fit your domain-specific data, then spacy makes you go
   through its api and write more code.

   on the other hand, if you have a large task ahead, then spark-nlp will
   be far faster, and from a certain scale, the only choice. it
   automatically scales as you plug in larger data sets or grow your spark
   cluster. it is between one and two orders of magnitude faster for
   training nlp models, holding for the same level of accuracy.

   spacy comes with a set of superbly tuned models for a variety of common
   nlp tasks. spark-nlp does not (at the time of writing this post) come
   with pre-trained models. spacy models are    black box    and are usually
   within 1% of the state of the art, if your text is similar to what the
   models were trained on. when training domain-specific models with
   spark-nlp, pipelines are language agnostic, and their result is
   strictly the sum of their parts. every annotator works on the knowledge
   provided to it, and each one of them will communicate with other
   annotators to achieve a final result. you can inject a spell checker, a
   sentence detector, or a normalizer, and it will affect your outcome
   without having to write additional code or custom scripts.

   we hope you have enjoyed this [35]overview of both libraries, and that
   it will help you deliver your next nlp project faster and better. if
   you are interested in learning more, there will be hands-on, half-day
   tutorials on "natural language understanding at scale with spacy and
   spark ml" at the upcoming [36]strata data san jose in march and
   [37]strata data london in may.

   [38]check out the "natural language understanding at scale with spacy
   and spark nlp" tutorial session at the strata data conference in
   london, may 21-24, 2018.
   article image: fractal complexity (source: [39]pixabay).
   tags: [40]nlp libraries

   share
    1. [41]tweet
    2.
    3.
     __________________________________________________________________

   [42]saif addin ellafi

[43]saif addin ellafi

   saif addin ellafi is a software developer, analyst, data scientist, and
   forever a student while being an extreme sports and gaming enthusiast.
   having wide experience in problem solving and quality assurance in the
   data fields in banking and finance industry, he is now the main
   contributor in spark-nlp at john snow labs.
   [44]more
     __________________________________________________________________

   video
   [45]logstash ui

   [46]data science

[47]revealing the uncommonly common with elasticsearch

   by [48]mark harwood

   this webcast looks at how elasticsearch is taking search engine
   technology and branching it out to provide insightful analysis of large
   datasets.

   [49]marina bay and the skyline of the central business district of
   singapore at dusk, by william cho.

   [50]data science

[51]how intelligent data platforms are powering smart cities

   by [52]ben lorica

   smart cities and smart nations run on data.

   [53]a woman posed with a hollerith pantograph: the keyboard is for the
   1920 population card, and a 1940 census form.

   [54]data science

[55]beyond algorithms: optimizing the search experience

   by [56]daniel tunkelang

   making search smarter through better human-computer interaction.

   runnable code
   [57]pandas table

   [58]data science

[59]introducing pandas objects

   by [60]jake vanderplas

   python data science handbook: early release

about us

     * [61]our company
     * [62]teach/speak/write
     * [63]careers
     * [64]customer service
     * [65]contact us

site map

     * [66]ideas
     * [67]learning
     * [68]topics
     * [69]all

     *
     *
     *
     *
     *

      2019 o'reilly media, inc. all trademarks and registered trademarks
   appearing on oreilly.com are the property of their respective owners.
   [70]terms of service     [71]privacy policy     [72]editorial independence

   animal

   iframe: [73]https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

references

   visible links
   1. https://www.oreilly.com/ideas
   2. https://learning.oreilly.com/
   3. http://www.oreilly.com/conferences/
   4. http://shop.oreilly.com/
   5. https://www.oreilly.com/sign-in.html
   6. https://www.oreilly.com/topics/ai
   7. https://www.oreilly.com/topics/data
   8. https://www.oreilly.com/topics/economy
   9. https://www.oreilly.com/topics/operations
  10. https://www.oreilly.com/topics/software-architecture
  11. https://www.oreilly.com/topics/software-engineering
  12. https://www.oreilly.com/topics/web-programming
  13. https://www.oreilly.com/topics
  14. https://www.oreilly.com/ideas
  15. https://learning.oreilly.com/
  16. http://www.oreilly.com/conferences/
  17. http://shop.oreilly.com/
  18. https://www.oreilly.com/topics/ai
  19. https://www.oreilly.com/topics/data
  20. https://www.oreilly.com/topics/economy
  21. https://www.oreilly.com/topics/operations
  22. https://www.oreilly.com/topics/software-architecture
  23. https://www.oreilly.com/topics/software-engineering
  24. https://www.oreilly.com/topics/web-programming
  25. https://www.oreilly.com/topics
  26. https://www.oreilly.com/topics/data-science
  27. https://www.oreilly.com/people/saif-addin-ellafi
  28. https://pixabay.com/en/fractal-complexity-geometry-1758543/
  29. https://conferences.oreilly.com/strata/strata-eu/public/schedule/detail/64514?intcmp=il-data-confreg-lp-steu18_new_site_saif_ellafi_blog_series_part_three_training_pipelines_top_cta
  30. https://www.oreilly.com/tags/nlp-libraries
  31. http://nlp.johnsnowlabs.com/
  32. https://spacy.io/
  33. https://www.oreilly.com/ideas/comparing-production-grade-nlp-libraries-training-spark-nlp-and-spacy-pipelines
  34. https://spacy.io/usage/models
  35. https://www.oreilly.com/tags/nlp-libraries
  36. https://conferences.oreilly.com/strata/strata-ca/public/schedule/detail/63661?intcmp=il-data-confreg-lp-stca18_20180226_new_site_saif_ellafi_blog_series_part_three_nlp_libraries_accuracy_performance_text_body_san_jose_tutorial_link_end
  37. https://conferences.oreilly.com/strata/strata-eu/public/schedule/detail/64514?intcmp=il-data-confreg-lp-steu18_20180226_new_site_saif_ellafi_blog_series_part_three_nlp_libraries_accuracy_performance_text_body_london_tutorial_link_end
  38. https://conferences.oreilly.com/strata/strata-eu/public/schedule/detail/64514?intcmp=il-data-confreg-lp-steu18_new_site_saif_ellafi_blog_series_part_three_training_pipelines_end_cta
  39. https://pixabay.com/en/fractal-complexity-geometry-1758543/
  40. https://www.oreilly.com/tags/nlp-libraries
  41. https://twitter.com/share
  42. https://www.oreilly.com/people/saif-addin-ellafi
  43. https://www.oreilly.com/people/saif-addin-ellafi
  44. https://www.oreilly.com/people/saif-addin-ellafi
  45. https://www.oreilly.com/learning/revealing-the-uncommonly-common-with-elasticsearch
  46. https://www.oreilly.com/topics/data-science
  47. https://www.oreilly.com/learning/revealing-the-uncommonly-common-with-elasticsearch
  48. https://www.oreilly.com/people/d9f55-mark-harwood
  49. https://www.oreilly.com/ideas/how-intelligent-data-platforms-are-powering-smart-cities
  50. https://www.oreilly.com/topics/data-science
  51. https://www.oreilly.com/ideas/how-intelligent-data-platforms-are-powering-smart-cities
  52. https://www.oreilly.com/people/4e7ad-ben-lorica
  53. https://www.oreilly.com/ideas/beyond-algorithms-optimizing-the-search-experience
  54. https://www.oreilly.com/topics/data-science
  55. https://www.oreilly.com/ideas/beyond-algorithms-optimizing-the-search-experience
  56. https://www.oreilly.com/people/e9a1c-daniel-tunkelang
  57. https://www.oreilly.com/learning/introducing-pandas-objects
  58. https://www.oreilly.com/topics/data-science
  59. https://www.oreilly.com/learning/introducing-pandas-objects
  60. https://www.oreilly.com/people/89c9c-jake-vanderplas
  61. http://oreilly.com/about/
  62. http://oreilly.com/work-with-us.html
  63. http://oreilly.com/careers/
  64. http://shop.oreilly.com/category/customer-service.do
  65. http://shop.oreilly.com/category/customer-service.do
  66. https://www.oreilly.com/ideas
  67. https://www.oreilly.com/topics/oreilly-learning
  68. https://www.oreilly.com/topics
  69. https://www.oreilly.com/all
  70. http://oreilly.com/terms/
  71. http://oreilly.com/privacy.html
  72. http://www.oreilly.com/about/editorial_independence.html
  73. https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

   hidden links:
  75. https://www.oreilly.com/
  76. https://www.facebook.com/oreilly/
  77. https://twitter.com/oreillymedia
  78. https://www.youtube.com/user/oreillymedia
  79. https://plus.google.com/+oreillymedia
  80. https://www.linkedin.com/company/oreilly-media
  81. https://www.oreilly.com/
