   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

machine learning basics         part 2         concept of neural networks and how to
debug a learning algorithm

   [16]go to the profile of daniel deutsch
   [17]daniel deutsch (button) blockedunblock (button) followfollowing
   mar 2, 2018
   [0*mt_wvdhrluqrymbp.]
   photo by matteo catanese on
   unsplash         [18]https://unsplash.com/photos/pi8hk-3zccu

   in this article i revisit the learned material from the amazing
   [19]machine learning course by andre ng on coursera and create an
   overview about the concepts. all quotes refer to the material from the
   course if not explicitly stated otherwise.

table of contents

     * [20]-neural networks model representation
     * [21]-cost function in neural networks
     * [22]id26
     * [23]unrolling parameters
     * [24]gradient checking
     * [25]random initialization
     * [26]-checklist on training a neural network
     * [27]-debugging a learning algorithm
     * [28]evaluate the hypothesis
     * [29]model selection
     * [30]bias and variance
     * [31]learning curves and the size of a set
     * [32]summary
     * [33]-designing a machine learning system
     * [34]skewed classes and classification
     * [35]high accuracy

neural networks model representation

   for neural networks we take the findings from exploring the statistical
   regression and try to put it in brain-like architecture.

   the used terms change a little as the logistic function is often
   referred to as the sigmoid activation function and the theta parameters
   as weights. the underlying concept stays the same. instead of the
   [36]bias term theta 0, now a bias unit with the value of 1 is used.

   the neural network architecture is made of at least 3 layers. that is
     * input,
     * hidden,
     * output

   layer. (many neural networks have more than 1 hidden layer though)

   in an activation unit, the weighted input of each unit in the previous
   layer is re-calculated and re-measured. you can say that neural
   networks can basically implement the concept of a statistical
   regression multiple times with more and more advanced input.
   [0*kgpyyg03yvkhjq2s.png]

   of course this concept can also be applied using vectorization.
   therefore we use a new variable, that encompasses the weight parameters
   inside our g function as an activation unit. here it is really
   important to track and visualize the dimensions of your matrices, since
   it can get quickly very complex (depending on your neural network
   architecture).

   check out [37]this incredible article, that explains the concept very
   good with nice graphics.

   a great introduction example is the xor problem. [38]this article
   explains it well.

cost function in neural networks

   for a id28 to be used in a neural network, the cost
   function has to be extend to hold the output units k and the
   id173 part needs the number of layers, the number of nodes in
   the current layer (plus the bias term) and the number of nodes in the
   next layers to localized the theta value correctly.

   cost function for id28:
   [0*8-qsjdbnkmmoarqm.png]

   cost function for id28 in a neural network:
   [0*xibatgyan4srqd_l.png]

id26

        id26    is neural-network terminology for minimizing our
     cost function, just like what we were doing with id119 in
     logistic and id75.

   whereas forward propagation (activation of nodes) takes in the theta
   parameters of each node in the previous layer, id26 does
   basically the opposite. an error for each node is calculated by
   comparing the activation node   s output with the calculated output of
   the node. afterwards this error is minimized gradually by adapting the
   used parameter theta.

   the formula for calculating the error is:
   [0*hr6rrum3stcxbacf.png]

unrolling parameters

   since some, more advanced, algorithms need vectorized versions for
   computation. unrolling matrices into vectors is a great way for
   calculating the cost function and getting the vector of the calculated
   parameters and reshaping the result back into matrices.

gradient checking

   to ensure that your id26 works as intended you should check
   your gradient. this is done calculating an approximation in respect to
   theta with the following formula:
   [0*zchcj4eohmgwmibj.png]

   if the result is similar to the gradient vector the implementation
   works correct.

random initialization

   to use id119 in a neural network the initial values for
   theta cannot be symmetrical and must be initialized randomly. using
   symmetrical initialization always lead to the same learning result,
   since the is no variety provided.

checklist on training a neural network

    1. randomly initialize weights
    2. implement forward propagation to get the hypothesis
    3. compute the cost function to get the errors
    4. implement id26 to compute partial derivatives
       (optimizing the parameters through errors)
    5. apply gradient checking (comparing id26 with numerical
       estimate)
    6. disable gradient checking
    7. use an optimization method to minimize the cost function with it   s
       corresponding parameters

debugging a learning algorithm

   sometimes the learned algorithm produces large errors. the following
   strategies help you debugging.

evaluate the hypothesis

   the first steps you can always take is to get more test data, increase
   or decrease features or your regularizing lambda.

   after that split the data into a training set (~70%) and a test set
   (~30%). this technique give you immediate feedback on how well your
   hypothesis is performing.

model selection

     just because a learning algorithm fits a training set well, that
     does not mean it is a good hypothesis. it could over fit and as a
     result your predictions on the test set would be poor. the error of
     your hypothesis as measured on the data set with which you trained
     the parameters will be lower than the error on any other data set.

     given many models with different polynomial degrees, we can use a
     systematic approach to identify the    best    function. in order to
     choose the model of your hypothesis, you can test each degree of
     polynomial and look at the error result.

   therefore the data can be split into 3 sets:
    1. training set
    2. cross validation set
    3. test set

   this allows us to 1. calculate the optimal parameters, 2. apply it to
   different polynomial models and find the one with the smallest error
   and 3. estimate the general error of the best model.

bias and variance

   the bias vs. variance problem describes the issue of the hypothesis
   under-, or overfitting a data set. whereas a high bias underfits the
   data, a high variance overfits it.

   for diagnostics, the errors of the sets can be compared. if the errors
   of the cross-validation and the test set are high the hypothesis is
   suffering from high bias. if the cross validation sets shows a much
   higher error than the training set the problem is most likely a
   variance problem.

   these problems can be addressed using different regularizing lambda
   parameter.
   [0*395anftgmttmgci0.png]

   remember that, a lambda of the value 1 equals a completely biased
   hypothesis (underfitting), whereas a lambda of 0 is essentially high
   variance one (overfitting).

   to apply this in practice it is useful to create a list of lambdas (eg.
   0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24) and supply
   them when working on the different polynomial models in the trainings
   set and pick the one with the smallest error. it   s important to note,
   that when computing the errors of the cross-validation set to not use
   id173 again, since it would distort the result.

learning curves and the size of a set

   with increasing size of a set the errors will increase until a certain
   point where it plateaus.

   if the algorithm is suffering from high bias, getting more data won   t
   help as it is already underfitting. however if the problem is a
   overfitting one with high variance, getting more data is likely to
   improve the algorithm.

summary

   high bias can be addressed by
     * adding features
     * adding polynomial features
     * decreasing the id173 parameter lambda

   high variance can be addressed by
     * getting more training data
     * reducing features
     * increasing the id173 parameter lambda

     in reality, we would want to choose a model somewhere in between,
     that can generalize well but also fits the data reasonably well.

designing a machine learning system

   important questions one have to ask themselves:
     * how mach data should be collected?
     * how can sophisticated features be developed. what feature actually
       works for the goal?
     * how can algorithms be developed that help reduce misinterpretation?

   a recommended approach to design a machine learning system is to
    1. start with a simple algorithm and test it on cross-validation data
    2. plot learning curves to make the right decisions on what to improve
       next
    3. examine errors manually and see what type of error it is and what
       could be improved to avoid those errors

skewed classes and classification

   skewed classes appear when one class is over-represented in the data
   set.

   to test if your data is suffering from this problem implement precision
   and recall tests. you are essentially testing the true positives of all
   predicted positives (precision) and compare it top all true positives
   of all actual positives.
   [0*soqrz1ievyrygkwe.png]

   depending on the goal of your classification problem, the way of
   weighting precision and recall varies. as the hypothesis returns the
   id203 between 0 or 1, the set boundary threshold decides whether
   to classify an outcome as positive or negativ.

   often the starting point is 0.5, ie. everything under 0.5 is classified
   as negative. depending whether you want to predict very confidently or
   rather avoid missing many cases, it makes sense to test different
   values for 0 and 1 (eg 0.3, 0.5, 0.7, 0.9) and compare the resulting
   algorithms. as you will have 2 values (one for precision, one for
   recall), the desired threshold can afterwards be calculated with the
   f-score formula:
   [0*ip6gkoamgggt7hpe.png]

high accuracy

   to achieve the highest possible accuracy it is best to have as much
   useful(!) data as possible (low variance), but also to have an
   algorithm with many features or parameters (low bias).
     __________________________________________________________________

   this wraps up the second part. in the next one, support vector machines
   and unsupervised learning will be described. stay tuned!
     __________________________________________________________________

   thanks for reading my article! feel free to leave any feedback!
     __________________________________________________________________

   daniel is a ll.m. student in business law, working as a software
   engineer and organizer of tech-related events in vienna. his current
   personal learning efforts focus on machine learning.

   connect on:
     * [39]linkedin
     * [40]github
     * [41]medium
     * [42]twitter
     * [43]steemit
     * [44]hashnode

     * [45]machine learning
     * [46]neural networks
     * [47]deep learning
     * [48]statistics
     * [49]big data

   (button)
   (button)
   (button) 259 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [50]go to the profile of daniel deutsch

[51]daniel deutsch

   aspiring web developer with business law background. pushing the limits
   to make the world a better place. open for projects of any kind.

     (button) follow
   [52]towards data science

[53]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 259
     * (button)
     *
     *

   [54]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [55]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/8a5af671d535
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/machine-learning-basics-part-2-concept-of-neural-networks-and-how-to-debug-a-learning-algorithm-8a5af671d535&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/machine-learning-basics-part-2-concept-of-neural-networks-and-how-to-debug-a-learning-algorithm-8a5af671d535&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_t2b7qkrhhx7x---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@ddcreationstudi?source=post_header_lockup
  17. https://towardsdatascience.com/@ddcreationstudi
  18. https://unsplash.com/photos/pi8hk-3zccu
  19. https://www.coursera.org/learn/machine-learning
  20. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#neural-networks-model-representation
  21. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#cost-function-in-neural-networks
  22. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#id26
  23. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#unrolling-parameters
  24. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#gradient-checking
  25. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#random-initialization
  26. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#checklist-on-training-a-neural-network
  27. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#debugging-a-learning-algorithm
  28. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#evaluate-the-hypothesis
  29. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#model-selection
  30. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#bias-and-variance
  31. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#learning-curves-and-the-size-of-a-set
  32. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#summary
  33. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#designing-a-machine-learning-system
  34. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#skewed-classes-and-classification
  35. https://github.com/ddcreationstudios/writing/blob/master/2018/articles/mlintrop2.md#high-accuracy
  36. https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks
  37. http://www.ebc.cat/2017/01/08/understanding-neural-networks-part-2-vectorized-forward-propagation/
  38. https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b
  39. https://www.linkedin.com/in/createdd
  40. https://github.com/createdd
  41. https://medium.com/@ddcreationstudi
  42. https://twitter.com/ddcreationstudi
  43. https://steemit.com/@createdd
  44. https://hashnode.com/@ddcreationstudio
  45. https://towardsdatascience.com/tagged/machine-learning?source=post
  46. https://towardsdatascience.com/tagged/neural-networks?source=post
  47. https://towardsdatascience.com/tagged/deep-learning?source=post
  48. https://towardsdatascience.com/tagged/statistics?source=post
  49. https://towardsdatascience.com/tagged/big-data?source=post
  50. https://towardsdatascience.com/@ddcreationstudi?source=footer_card
  51. https://towardsdatascience.com/@ddcreationstudi
  52. https://towardsdatascience.com/?source=footer_card
  53. https://towardsdatascience.com/?source=footer_card
  54. https://towardsdatascience.com/
  55. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  57. https://medium.com/p/8a5af671d535/share/twitter
  58. https://medium.com/p/8a5af671d535/share/facebook
  59. https://medium.com/p/8a5af671d535/share/twitter
  60. https://medium.com/p/8a5af671d535/share/facebook
