[1] logo

     * [2]learn python
     * [3]gui
     * [4]pyqt
     * [5]machine learning
     * [6]web development
     * [7]django
     * [8]oop

kmeans text id91

   [ins: :ins]

   given text documents, we can group them automatically: text id91.
   we   ll use kmeans which is an unsupervised machine learning algorithm.

   i   ve collected some articles about cats and google. you   ve guessed it:
   the algorithm will create clusters. the articles can be about anything,
   the id91 algorithm will create clusters automatically. even
   cooler: prediction.

   related course:
     * [9]machine learning a-z   : hands-on python & r in data science
       icon

the data

   we create the documents using a python list. in our example, documents
   are simply text strings that fit on the screen. in a real world
   situation, they may be big files.

documents = ["this little kitty came to play when i was eating at a restaurant."
,
             "merley has the best squooshy kitten belly.",
             "google translate app is incredible.",
             "if you open 100 tab in google you get a smiley face.",
             "best cat photo i've ever taken.",
             "climbing ninja cat.",
             "impressed with google map feedback.",
             "key promoter extension for google chrome."]


feature extraction

   kmeans normally works with numbers only: we need to have numbers. to
   get numbers, we do a common step known as feature extraction.

   the feature we   ll use is tf-idf, a numerical statistic. this statistic
   uses term frequency and inverse document frequency. in short: we use
   statistics to get to numerical features. because i   m lazy, we   ll use
   the existing implementation of the tf-idf algorithm in sklearn.

   the method tfidfvectorizer() implements the tf-idf algorithm. briefly,
   the method tfidfvectorizer converts a collection of raw documents to a
   matrix of [10]tf-idf features.

   [11]algorithm joke

text id91

   after we have numerical features, we initialize the kmeans algorithm
   with k=2. if you want to determine k automatically, see the previous
   article. we   ll then print the top words per cluster.

   then we get to the cool part: we give a new document to the id91
   algorithm and let it predict its class. in the code below i   ve done
   that twice.

from sklearn.feature_extraction.text import tfidfvectorizer
from sklearn.cluster import kmeans
from sklearn.metrics import adjusted_rand_score
documents = ["this little kitty came to play when i was eating at a restaurant."
,
             "merley has the best squooshy kitten belly.",
             "google translate app is incredible.",
             "if you open 100 tab in google you get a smiley face.",
             "best cat photo i've ever taken.",
             "climbing ninja cat.",
             "impressed with google map feedback.",
             "key promoter extension for google chrome."]
vectorizer = tfidfvectorizer(stop_words='english')
x = vectorizer.fit_transform(documents)
true_k = 2
model = kmeans(n_clusters=true_k, init='id116++', max_iter=100, n_init=1)
model.fit(x)
print("top terms per cluster:")
order_centroids = model.cluster_centers_.argsort()[:, ::-1]
terms = vectorizer.get_feature_names()
for i in range(true_k):
    print("cluster %d:" % i),
    for ind in order_centroids[i, :10]:
        print(' %s' % terms[ind]),
    print
print("\n")
print("prediction")
y = vectorizer.transform(["chrome browser to open."])
prediction = model.predict(y)
print(prediction)
y = vectorizer.transform(["my cat is hungry."])
prediction = model.predict(y)
print(prediction)


   [12]download examples
   [ins: :ins]
   [13]previous post [14]next post

      2007 - 2019 [15]pythonprogramminglanguage.com.
   [16]cookie policy & [17]privacy policy.

references

   visible links
   1. https://pythonprogramminglanguage.com/
   2. https://pythonprogramminglanguage.com/
   3. https://pythonprogramminglanguage.com/python-gui
   4. https://pythonprogramminglanguage.com/category/pyqt
   5. https://pythonprogramminglanguage.com/category/machine-learning
   6. https://pythonprogramminglanguage.com/web-application
   7. https://pythonprogramminglanguage.com/django
   8. https://pythonprogramminglanguage.com/category/oop
   9. https://click.linksynergy.com/deeplink?id=ke*2f3hl/pw&mid=39197&murl=https://www.udemy.com/machinelearning/
  10. https://en.wikipedia.org/wiki/tf   idf
  11. https://pythonprogramminglanguage.com/wp-content/uploads/2017/07/algorithm.jpg
  12. https://share.pythonprogramminglanguage.com/download-machine-learning-examples/
  13. https://pythonprogramminglanguage.com/kmeans-elbow-method/
  14. https://pythonprogramminglanguage.com/neural-network/
  15. https://pythonprogramminglanguage.com/
  16. https://pythonprogramminglanguage.com/cookie-policy/
  17. https://pythonprogramminglanguage.com/privacy-policy/

   hidden links:
  19. https://pythonprogramminglanguage.com/kmeans-text-id91/#the-data
  20. https://pythonprogramminglanguage.com/kmeans-text-id91/#feature-extraction
  21. https://pythonprogramminglanguage.com/kmeans-text-id91/#text-id91
