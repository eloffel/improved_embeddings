   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]shravan   s blog
   [7]shravan   s blog
   [8]sign in[9]get started
     __________________________________________________________________

[10]gans, a modern perspective

   [11]go to the profile of shravan murali
   [12]shravan murali (button) blockedunblock (button) followfollowing
   oct 7, 2017
   [1*dtmuafmq6o2bikxidvxzfq.png]

   in today   s world, gan (id3) is an insanely
   active topic of research and it has already attracted a lot of creative
   applications like [13]this one
   [1*pnwmk6niqre4rljqdz7liw.jpeg]
   check out pix2pix [14]here

a brief introduction

what   s wrong with today   s deep neural nets ?

   [1*ldsu9fb0hxms91pgxzsn3w.png]
   adding some amount of noise to the correctly classified panda image
   makes a dnn model misclassify it as a gibbon !

   it all started in the year 2014 when [15]christian szegedy and a couple
   of others at google, noticed that neural nets can be fooled easily by
   adding just a small amount of noise. they used gradient ascent to make
   their deep neural network classify a given image as something else
   other than its ground truth class. surprisingly, they only required a
   small amount of distortion to convert images of one class to another.

   mathematically, this change of class can be implemented using fast
   gradient sign method (fgsm just iteratively adds a small amount noise
   in the direction of the gradient of the objective function with respect
   to the input values)
   [1*0cr6vk65z-uzhbtond-kvw.jpeg]
   the pictures on the left are correctly classified and those on the
   right (after adding the distort) are misclassified as an ostrich

   the most interesting part is that, the model after adding noise has
   much more confidence in the wrong prediction than that when it
   predicted right !

what are the reasons for such adversaries ?

     * since every machine learning model learns from only a limited
       number of images for each class, it is prone to overfit.
     * another important reason is that, the mapping between the input to
       the network and the output is close to being linear. although we
       believe that the boundaries of separation between various classes
       are non-linear, they are composed of linearities and even a small
       change in a point in the feature space could cause it to cross
       class boundaries. the id180 that we use are all
       mostly piecewise linear too. for example.,relu and its variations
       are all linear after the    0    point.

   these are just some of the reasons in layman   s terms. for a clearer
   understanding about such adversaries, i   d highly recommend this
   [16]tutorial by ian goodfellow.

how do we rectify these deep neural nets ?

   well, there   s still a lot of research happening on this and there isn   t
   a clear cut answer yet. one of the solutions proposed for this was to
   train the net on adversarial examples as well. and these adversarial
   examples could be generated using [17]deep generative models. there
   were multiple generative models proposed as well, some of the notable
   ones being [18]pixelid98, [19]variational auto-encoders and
   [20]id3 (or gans). in this article, we are
   particularly gonna explore gans.

what exactly are these    id3    ?

   id3 consist of a generator and a
   discriminator neural network. the purpose of the generator is to take
   in noise vectors and produce images that resembles the input data
   distribution closely and try to fool the discriminator into classifying
   a fake image as a real image. the function of the discriminator is to
   classify a generated image as real or fake. what   s going on between the
   generator and the discriminator here is a [21]2 player zero sum game.
   in other words, in every move, the generator is trying to maximize the
   chance of the discriminator misclassifying the image and the
   discriminator is in turn trying to maximize its chances of correctly
   classifying the incoming image.
   [1*cxnqsjxyp-lx-3afysuxxq.png]
   a simple flowchart of a gan

   for more information on adversarial examples, do watch [22]this talk by
   ian goodfellow

basic math behind gans

   [1*361b0uv35vg7tc8dbuq5kw.png]

   obscure isn   t that ? no worries ! it   s easy to understand !

   let   s analyze both the terms in the objective function.

   [ note :   g and   d are just weights of the generator and discriminator
   networks. you can ignore them while trying to interpret the equations ]

term i

   [1*wovwcth92vj-oec4zwdula.png]
   expected log likelihood of discriminator output when the samples from
   original data distribution are passed as input
   [1*6ki7us19pnw1e-vkylgzcw.png]

   this term represents the log id203 of the discriminator output
   with input data from real data distribution. now, look at this term
   from the discriminator   s perspective. according to the discriminator,
   it should maximize its id203 of classifying an image correctly as
   real or fake. here, the images are sampled from the original data
   distribution, which is the real data itself. also, remember that d(x)
   represents the id203 that the input image is real. hence, the
   discriminator will have to maximize d(x) (i.e., it has to be close to
      1.0   ) and log(d(x)) . and hence, term i has to be maximized.

term ii

   [1*-vakkgig1rpiwoihak2loa.png]
   expected log likelihood of discriminator output when the image(s) from
   generator   s output are passed onto discriminator
   [1*ej4ymutfxclqxz7il5_mag.png]
   [1*yr1ywtt_s9fiuddeoydmra.png]

   the explanation for this term is quite similar. but you should view
   this equation from the generator   s perspective. here, images from the
   generator   s output are passed in to the discriminator. so, according to
   the generator, it has to maximize the chances of the discriminator
   getting fooled by the generated images. which means, the generator
   should want to maximize d(g(z)) . which means, it should look to
   minimize 1         d(g(z)) and hence log( 1         d(g(z)).

types of gans and their architectures

   gans are one of the hottest research topics today and there are a good
   number of proposals for gan implementations in the past couple of
   years. here, i   ll discuss only a few of them, although i   ll make sure
   to list all of the types.

vanilla gan

   this is the simplest type of gan and in this case the generator and the
   discriminator are just simple multi-layer id88s. vanilla gans
   simply just seek to optimize the mathematical equation using stochastic
   id119. let   s take a look at the algorithm.
   [1*0s19-abz5ovql0tiaozytw.png]
   this is the algorithm for the very first gan. it was taken from its
   [23]paper written in 2014

   in layman   s terms, the generator here takes in a noise vector (   z   ,
   usually 100-dimensional) and produce an image (g(z), which is just a
   flattened vector of all the pixels in the image). this image is used in
   the equations we saw previously to simply update the weights of the
   generator and the discriminator by computing gradients through
   id26.

dcgan (deep convolutional gan)

   this is one of the most popular types of gans today. in this case,
   convnets are used in place of the multi-layer id88s. the
   objective function remains the same here. let   s now take a look at the
   architecture.
   [1*wm4iddmoigftexnxjfkubw.png]
   architecture of the generator in the first dcgan as in its [24]paper

   the architecture of the discriminator is mostly just the opposite of
   that of the generator, i.e., it takes in an image and produces 2
   numbers (which are just the probabilities of the image being fake or
   not). one more thing to note here is that, in the discriminator, the
   forward process consists of the conv transpose or deconv operation at
   every layer. let   s take an example. let   s say that you wanna map a     4
   x 4 x 1024     layer to a     8 x 8 x 512     layer and let   s say that we   re
   using 512 filters of size    3 x 3   , then you   ll just have to pad the
   existing layer   s cross-section with zeroes and add zeroes between each
   element in the cross-section and do the regular convolution operation
   with strides. take a look at the below gif for a clearer understanding.
   [1*oq-okrezfdehfwhzdos1rq.gif]
   a layer with 3 x 3 cross-section is being mapped to a layer with 5 x 5
   cross-section

   ok, let   s now take a look at the results that dcgans have produced.
   [1*87x18sbyvbxx0vf7vv44dq.png]
   this image was taken from the dcgan paper. this is after 5 epochs
   of training

cgan (conditional gan)

   this type of gan conditions the output data distribution based on a
   condition layer. so, in the objective function, log( 1         d(g(z)) and
   d(x) will be replaced by log( 1         d(g(z|y)) and d(x|y) . rest of it
   would be the would be taken care of by the respective networks, i.e.,
   creating latent representations and managing weights. you can think of
   this as more like an additional input of    y    always exists in the
   networks. and of course, the objective remains same here.
   [1*zqvliatxotghhn5bo8780q.png]

lapgan (laplacian pyramid gan)

   this type of gan is known to produce very high quality image samples.
   this uses multiple generator-discriminator networks at various levels
   of a [25]laplacian pyramid. precisely, the image is first downsampled
   to half its size at each layer of the pyramid. then, in a backward pass
   through the pyramid, at each layer, the image acquires a noise
   generated by a conditional gan at that layer and then upsampled to
   twice its size. this way the image is reconstructed back to its own
   size.
   [1*8tjgvza68sexjpwqwndw9w.png]
   laplacian pyramid

other types of gans

     * srgan : photo-realistic single image super-resolution gan;
       [26]https://arxiv.org/abs/1609.04802
     * discogan : cross-domain gan; [27]https://arxiv.org/abs/1703.05192
     * infogan : information maximizing gan;
       [28]https://arxiv.org/abs/1606.03657

   you can find most types of gans here :

   [29]https://deephunt.in/the-gan-zoo-79597dc8c347

problems with gans and scope for research

     * instability and non-convergence of the objective function in gans
     * mode collapse (this happens when generator doesn   t produce diverse
       images ). here   s a very good article on mode collapse :
       [30]http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/
     * the possibility that either the generator or the discriminator
       becomes too strong as compared to the other during training

possible improvements to gans

     * normalizing the image
     * feature matching : changing the objective function of generator to
       mse w.r.t real data
     * minibatch discrimination : let the generator classify multiple
       images in a    minibatch    instead of just one
     * virtual batch id172 : each example is normalized based on a
       reference batch of samples

   this paper here has a lot of information on improving gans :
   [31]https://arxiv.org/pdf/1606.03498.pdf

popular applications

     * pix2pix : [32]https://affinelayer.com/pixsrv/
     * text-to-image synthesis :[33]https://arxiv.org/abs/1605.05396
     * high resolution image blending :
       [34]https://arxiv.org/abs/1703.07195
     * image inpainting : [35]https://arxiv.org/pdf/1607.07539.pdf
     * video generation :
       [36]https://github.com/dyelax/adversarial_video_generation

popular gan implementations/libraries

     * [37]https://github.com/goodfeli/adversarial
     * [38]https://github.com/bstriner/keras-adversarial
     * [39]https://github.com/carpedm20/dcgan-tensorflow
     * [40]https://github.com/newmu/dcgan_code
     * [41]https://github.com/martinarjovsky/wassersteingan

other notable github repos on gans

     * [42]https://github.com/gkalliatakis/delving-deep-into-gans
     * [43]https://github.com/nightrome/really-awesome-gan
     * [44]https://github.com/soumith/ganhacks

gan tutorials

     * ian goodfellow   s [45]talk at stanford about adversarial examples
     * ian goodfellow   s [46]tutorial, nips 2016
     * oreilly   s tutorial :
       [47]https://www.oreilly.com/learning/generative-adversarial-network
       s-for-beginners

   phew !

     * [48]machine learning
     * [49]generative model
     * [50]deep learning
     * [51]neural networks

   (button)
   (button)
   (button) 535 claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   [52]go to the profile of shravan murali

[53]shravan murali

   shravanmurali.com

     (button) follow
   [54]shravan   s blog

[55]shravan   s blog

   my tech blog mainly focussed on computer science domains like a.i. and
   distributed systems. check shravanmurali.com if you wanna know more
   about me !

     * (button)
       (button) 535
     * (button)
     *
     *

   [56]shravan   s blog
   never miss a story from shravan   s blog, when you sign up for medium.
   [57]learn more
   never miss a story from shravan   s blog
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/83ed64b42f5c
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/deep-dimension?source=avatar-lo_u9caazylfudk-b0e2bccdd35c
   7. https://medium.com/deep-dimension?source=logo-lo_u9caazylfudk---b0e2bccdd35c
   8. https://medium.com/m/signin?redirect=https://medium.com/deep-dimension/gans-a-modern-perspective-83ed64b42f5c&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/deep-dimension/gans-a-modern-perspective-83ed64b42f5c&source=--------------------------nav_reg&operation=register
  10. https://en.wikipedia.org/wiki/generative_adversarial_network
  11. https://medium.com/@shravanmurali?source=post_header_lockup
  12. https://medium.com/@shravanmurali
  13. https://affinelayer.com/pixsrv/
  14. https://affinelayer.com/pixsrv/
  15. https://research.google.com/pubs/christianszegedy.html
  16. https://arxiv.org/abs/1412.6572
  17. https://blog.openai.com/generative-models/
  18. https://arxiv.org/abs/1606.05328
  19. https://arxiv.org/abs/1312.6114
  20. https://arxiv.org/abs/1406.2661
  21. https://en.wikipedia.org/wiki/zero-sum_game
  22. https://www.youtube.com/watch?v=cifsb_eysvi
  23. https://arxiv.org/abs/1406.2661
  24. https://arxiv.org/pdf/1511.06434.pdf
  25. https://en.wikipedia.org/wiki/pyramid_(image_processing)
  26. https://arxiv.org/abs/1609.04802
  27. https://arxiv.org/abs/1703.05192
  28. https://arxiv.org/abs/1606.03657
  29. https://deephunt.in/the-gan-zoo-79597dc8c347
  30. http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/
  31. https://arxiv.org/pdf/1606.03498.pdf
  32. https://affinelayer.com/pixsrv/
  33. https://arxiv.org/abs/1605.05396
  34. https://arxiv.org/abs/1703.07195
  35. https://arxiv.org/pdf/1607.07539.pdf
  36. https://github.com/dyelax/adversarial_video_generation
  37. https://github.com/goodfeli/adversarial
  38. https://github.com/bstriner/keras-adversarial
  39. https://github.com/carpedm20/dcgan-tensorflow
  40. https://github.com/newmu/dcgan_code
  41. https://github.com/martinarjovsky/wassersteingan
  42. https://github.com/gkalliatakis/delving-deep-into-gans
  43. https://github.com/nightrome/really-awesome-gan
  44. https://github.com/soumith/ganhacks
  45. https://www.youtube.com/watch?v=cifsb_eysvi
  46. https://arxiv.org/pdf/1701.00160.pdf
  47. https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners
  48. https://medium.com/tag/machine-learning?source=post
  49. https://medium.com/tag/generative-model?source=post
  50. https://medium.com/tag/deep-learning?source=post
  51. https://medium.com/tag/neural-networks?source=post
  52. https://medium.com/@shravanmurali?source=footer_card
  53. https://medium.com/@shravanmurali
  54. https://medium.com/deep-dimension?source=footer_card
  55. https://medium.com/deep-dimension?source=footer_card
  56. https://medium.com/deep-dimension
  57. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  59. https://medium.com/p/83ed64b42f5c/share/twitter
  60. https://medium.com/p/83ed64b42f5c/share/facebook
  61. https://medium.com/p/83ed64b42f5c/share/twitter
  62. https://medium.com/p/83ed64b42f5c/share/facebook
