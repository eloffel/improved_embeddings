   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

a    weird    introduction to deep learning

there are amazing introductions, courses and blog posts on deep learning. but
this is a different kind of introduction. spanish version [16]here.

   go to the profile of favio v  zquez
   [17]favio v  zquez (button) blockedunblock (button) followfollowing
   mar 23, 2018
   [1*ojguoqb7liom_0ficrkqaw.jpeg]

   there are amazing introductions, courses and blog posts on deep
   learning. i will name some of them in the resources sections, but this
   is a different kind of introduction.
   [1*-5xrcvybfboi-ab6zj1o9q.jpeg]

   but why weird? maybe because it won   t follow the    normal    structure of
   a deep learning post, where you start with the math, then go into the
   papers, the implementation and then to applications.

   it will be more close to the post i did before about [18]   my journey
   into deep learning   , i think telling a story can be much more helpful
   than just throwing information and formulas everywhere. so let   s begin.

   note: there   s a companion webinar to this article. find it here:
   [19]webinars - deepcognition.ai
   about favio: physicist and computer engineer. holds a master's degree
   in physical sciences from unam. he works on big   deepcognition.ai

why am i making this introduction?

   [1*neg5llgc-sz3_deot5-fdg.jpeg]

   sometimes is important to have a written backup of your thoughts. i
   tend to talk a lot, and be present in several presentations and
   conference, and this is my way of contributing with a little knowledge
   to everyone.

   deep learning (dl)is such an important field for data science, ai,
   technology and our lives right now, and it deserves all of the
   attention is getting. please don   t say that deep learning is just
   adding a layer to a neural net, and that   s it, magic! nope. i   m hoping
   that after reading this you have a different perspective of what dl is.

deep learning timeline

   [1*z_dncykt18rm0accrfzaiq.png]

   i just created this timeline based on several papers and other
   timelines with the purpose of everyone seeing that deep learning is
   much more than just neural networks. there has been really theoretical
   advances, software and hardware improvements that were necessary for us
   to get to this day. if you want it just ping me and i   ll send it to
   you. (find my contact in the end of the article).

what is weird about deep learning?

   [1*anf4qcqsznugohtw7o6c2w.jpeg]

   deep learning has been around for quite a while now. so why it became
   so relevant so fast the last 5   7 years?

   as i said before, until the late 2000s, we were still missing a
   reliable way to train very deep neural networks. nowadays, with the
   development of several simple but important theoretical and algorithmic
   improvements, the advances in hardware (mostly gpus, now tpus), and the
   exponential generation and accumulation of data, dl came naturally to
   fit this missing spot to transform the way we do machine learning.

   deep learning is an active field of research too, nothing is settle or
   closed, we are still searching for the best models, topology of the
   networks, best ways to optimize their hyperparameters and more. is very
   hard, as any other active field on science, to keep up to date with the
   investigation, but it   s not impossible.

   a side note on topology and machine learning ([20]deep learning with
   topological signatures by hofer et al.):

     methods from algebraic topology have only recently emerged in the
     machine learning community, most prominently under the term
     topological data analysis (tda). since tda enables us to infer
     relevant topological and geometrical information from data, it can
     offer a novel and potentially beneficial perspective on various
     machine learning problems.

   luckily for us, there are lots of people helping understand and digest
   all of this information through courses like the [21]andrew ng one,
   blog posts and much more.

   this for me is weird, or uncommon because normally you have to wait for
   sometime (sometime years) to be able to digest difficult and advance
   information in papers or research journals. of course, most areas of
   science are now really fast too to get from a paper to a blog post that
   tells you what yo need to know, but in my opinion dl has a different
   feel.

breakthroughs of deep learning and representation learning

   [1*dn4gdyxpflhzbdcnaqlioa.jpeg]

   we are working with something that is very exciting, most people in the
   field are saying that the last ideas in the papers of deep learning
   (specifically new topologies and configurations for nn or algorithms to
   improve their usage) are the best ideas in machine learning in decades
   (remember that dl is inside of ml).

   i   ve used the word learning a lot in this article so far. but what is
   learning?

   in the context of machine learning, the word    learning    describes an
   automatic search process for better representations of the data you are
   analyzing and studying (please have this in mind, is not making a
   computer learn).

   this is a very important word for this field, rep-re-sen-ta-tion. don   t
   forget about it. what is a representation? it   s a way to look at data.

   let me give you an example, let   s say i tell you i want you to drive a
   line that separates the blue circles from the green triangles for this
   plot:
   [1*8zqwoornwtwriwd2aa_e7g.png]
   ian goodfellow et al. (deep learning, 2016)

     this example is from the [22]book of deep learning by ian
     goodfellow, et al. (2016).

   so, if you want to use a line this is what the author says:

            we represent some data using cartesian coordinates, and the task
     is impossible.   

   this is impossible if we remember the concept of a line:

     a line is a straight one-dimensional figure having no thickness and
     extending infinitely in both directions. from [23]wolfram mathworld.

   so is the case lost? actually no. if we find a way of representing this
   data in a different way, in a way we can draw a straight line to
   separate the types of data. this is something that math taught us
   hundreds of years ago. in this case what we need is a coordinate
   transformation, so we can plot or represent this data in a way we can
   draw this line. if we look the [24]polar coordinate transformation, we
   have the solution:
   [1*obm9epoyhu3gvuipdt-s4a.png]
   ian goodfellow et al. (deep learning, 2016)

   and that   s it now we can draw a line:
   [1*gpnmetn4gmlx0vkkah_ffq.png]

   so, in this simple example we found and chose the transformation to get
   a better representation by hand. but if we create a system, a program
   that can search for different representations (in this case a
   coordinate change), and then find a way of calculating the percentage
   of categories being classified correctly with this new approach, in
   that moment we are doing machine learning.

   this is something very important to have in mind, deep learning is
   representation learning using different kinds of neural networks and
   optimize the hyperparameters of the net to get (learn)the best
   representation for our data.

   this wouldn   t be possible without the amazing breakthroughs that led us
   to the current state of deep learning. here i name some of them:
    1. idea: back propagation.

   [25]learning representations by back-propagating errors by david e.
   rumelhart, geoffrey e. hinton & ronald j. williams.

   [26]a theoretical framework for back-propagation by yann lecun.

   2. idea: better initialization of the parameters of the nets. something
   to remember: the initialization strategy should be selected according
   to the activation function used (next).
   [27]weight initialization for deep networks - practical aspects of deep
   learning | coursera
   this course will teach you the "magic" of getting deep learning to work
   well. rather than the deep learning process   www.coursera.org
   [28]how to train your deep neural network
   there are certain practices in deep learning that are highly
   recommended, in order to efficiently train deep
   neural   rishy.github.io
   [29]cs231n convolutional neural networks for visual recognition
   course materials and notes for stanford class cs231n: convolutional
   neural networks for visual recognition.cs231n.github.io

   3. idea: better id180. this mean, better ways of
   approximating the functions faster leading to faster training process.
   [30]understanding id180 in neural networks
   recently, a colleague of mine asked me a few questions like    why do we
   have so many id180?   ,    why is   medium.com
   [31]id180: neural networks
   sigmoid, tanh, softmax, relu, leaky relu
   explained !!!towardsdatascience.com

   4. idea: dropout. better ways of preventing overfitting and more.
   [32]learning less to learn better         dropout in (deep) machine learning
   in this post, i will primarily discuss the concept of dropout in neural
   networks, specifically deep nets, followed by   medium.com

   [33]dropout: a simple way to prevent neural networks from overfitting,
   a great paper by srivastava, hinton and others.

   5. idea: convolutional neural nets (id98s).

   [34]gradient based learning applied to document recognition by lecun
   and others

   [35]id163 classification with deep convolutional neural networks by
   krizhevsky and others.

   6. idea: residual nets (resnets).
   [36][1512.03385v1] deep residual learning for image recognition
   abstract: deeper neural networks are more difficult to train. we
   present a residual learning framework to ease the   arxiv.org
   [37][1608.02908] residual networks of residual networks: multilevel
   residual networks
   abstract: a residual-networks family with hundreds or even thousands of
   layers dominates major image recognition tasks   arxiv.org

   7. idea: region based id98s. used for id164 and more.
   [38][1311.2524v5] rich feature hierarchies for accurate object
   detection and semantic segmentation
   abstract: id164 performance, as measured on the canonical
   pascal voc dataset, has plateaued in the last few   arxiv.org
   [39][1703.06870] mask r-id98
   abstract: we present a conceptually simple, flexible, and general
   framework for object instance segmentation. our   arxiv.org
   [40]facebookresearch/detectron
   detectron - fair's research platform for id164 research,
   implementing popular algorithms like mask r-id98 and   github.com

   8. idea: recurrent neural networks (id56s) and lstms.
   [41]a beginner's guide to recurrent networks and lstms
   contents the purpose of this post is to give students of neural
   networks an intuition about the functioning of   deeplearning4j.org
   [42]understanding id137 -- colah's blog
   these loops make recurrent neural networks seem kind of mysterious.
   however, if you think a bit more, it turns out that   colah.github.io
   [43]recurrent layers - keras documentation
   input_length: length of input sequences, to be specified when it is
   constant. this argument is required if you are   keras.io

   btw: it was shown by liao and poggio (2016) that resnets == id56s,
   arxiv:1604.03640v1.

   9. idea: id3 (gans).
   [44][1406.2661v1] id3
   abstract: we propose a new framework for estimating generative models
   via an adversarial process, in which we   arxiv.org
   [45]nashory/gans-awesome-applications
   gans-awesome-applications - curated list of awesome gan applications
   and demogithub.com

   10. idea: id22.
   [46]what is a capsnet or capsule network?
   what is a capsule network? what is capsule? is capsnet better than
   convolutional neural network (id98)? this article is   hackernoon.com
   [47]understanding hinton   s id22. part i: intuition.
   part of understanding hinton   s id22 series:medium.com
   [48]gram-ai/capsule-networks
   capsule-networks - a pytorch implementation of the nips 2017 paper
   "dynamic routing between capsules".github.com
     __________________________________________________________________

   and there are many others but i think those are really important
   theoretical and algorithmic breakthroughs that are changing the world,
   and that gave momentum for the dl revolution.

how to get started with deep learning?

   [1*t2y-ewi1z2sm44t_jev5sq.jpeg]

   it   s not easy to get started but i   ll try my best to guide you through
   this process. check out this resources, but remember, this is not only
   watching videos and reading papers, it   s about understanding,
   programming, coding, failing and then making it happen.

   -1. learn python and r ;)

   0. [49]andrew ng and [50]coursera (you know, he doesn   t need an intro):
   [51]deep learning | coursera
   deep learning from deeplearning.ai. if you want to break into ai, this
   specialization will help you do so. deep   www.coursera.org

   [52]siraj raval: he   s amazing. he has the power to explain hard
   concepts in a fun and easy way. follow him on his youtube channel.
   specifically this playlists:

       the math of intelligence:

   iframe: [53]/media/0d76653cbb784e3f0c0e88720db74c47?postid=7828803693b0

       intro to deep learning:

   iframe: [54]/media/218a91cc9009c842f1409618f6dd647d?postid=7828803693b0

   3. [55]fran  ois chollet   s book: deep learning with python (and r):
   [56]deep learning with python
   the clearest explanation of deep learning i have come across...it was a
   joy to read.www.manning.com
   [57]deep learning with r
   the clearest explanation of deep learning i have come across...it was a
   joy to read.www.manning.com

   3. [58]ibm cognitive class:
   [59]deep learning fundamentals
   about this course get a crash course on the what there is to learn and
   how to go about learning more. deep learning   cognitiveclass.ai
   [60]deep learning with tensorflow
   this deep learning with tensorflow course focuses on tensorflow. if you
   are new to the subject of deep learning   cognitiveclass.ai

   5. [61]datacamp:
   [62]deep learning in python
   deep learning is the machine learning technique behind the most
   exciting capabilities in diverse areas like
   robotics   www.datacamp.com
   [63]keras: deep learning in r
   as you know by now, machine learning is a subfield in computer science
   (cs). deep learning, then, is a subfield of   www.datacamp.com

distributed deep learning

   [1*xpxew5fwuuyfkpwkvvr1nw.png]

   deep learning is one of the most important tools and theories a data
   scientist should learn. we are so lucky to see amazing people creating
   both research, software, tools and hardware specific for dl tasks.

   dl is computationally expensive, and even though there   s been advances
   in theory, software and hardware, we need the developments in big data
   and distributed machine learning to improve performance and efficiency.
   great people and companies are making amazing efforts to join the
   distributed frameworks (spark) and dl libraries (tf and keras).

   here   s an overview:
    1. [64]databricks: deep learning pipelines (soon will be merge to
       spark)

   [65]overview - deep learning pipelines 0.2.0 documentation
   deep learning pipelines 0.2.0 documentation
   homepagedatabricks.github.io

   2. elephas: distributed dl with keras & pyspark:
   [66]maxpumperla/elephas
   elephas - distributed deep learning with keras & sparkgithub.com

   [67]3. yahoo! inc.: tensorflowonspark:
   [68]yahoo/tensorflowonspark
   tensorflowonspark brings tensorflow programs onto apache spark
   clustersgithub.com

   [69]4. cern distributed keras (keras + spark) :
   [70]cerndb/dist-keras
   dist-keras - distributed deep learning, with a focus on distributed
   training, using keras and apache spark.github.com

   [71]5. qubole (tutorial keras + spark):
   [72]distributed deep learning with keras on apache spark | qubole
   deep learning has been shown to produce highly effective machine
   learning models in a diverse group of fields. some
   of   www.qubole.com

   [73]6. intel corporation: bigdl (distributed deep learning library for
   apache spark)
   [74]intel-analytics/bigdl
   bigdl: distributed deep learning library for apache sparkgithub.com

   7. tensorflow and spark on [75]google cloud:
   [76]using apache spark with tensorflow on google cloud platform |
   google cloud big data and machine   
   apache spark and tensorflow are both open-source projects that have
   made significant impact in the world of enterprise   cloud.google.com

getting stuff done with deep learning

   [1*yel4otke_oxev9gr9uejxq.jpeg]

   as i   ve said before one of the most important moments for this field
   was the creation and open sourced of [77]tensorflow.

   tensorflow is an open source software library for numerical computation
   using data flow graphs. nodes in the graph represent mathematical
   operations, while the graph edges represent the multidimensional data
   arrays (tensors) communicated between them.
   [1*d36yiqgzt4xanrcz25kg7w.jpeg]

   the things you are seeing in the image above are tensor manipulations
   working with the [78]riemann tensor in general relativity.

   tensors, defined mathematically, are simply arrays of numbers, or
   functions, that transform according to certain rules under a change of
   coordinates.

   but in the scope of machine learning and deep learning a tensor is a
   generalization of vectors and matrices to potentially higher
   dimensions. internally, tensorflow represents tensors as n-dimensional
   arrays of base datatypes.

   we use heavily tensors all the time in dl, but you don   t need to be an
   expert in them to use it. you may need to understand a little bit about
   them so here i list some good resources:
   [79]deep learning 101: demystifying tensors
   tensors and new machine learning tools such as tensorflow are hot
   topics these days, especially among people
   looking   www.kdnuggets.com
   [80]learning ai if you suck at math         p4         tensors illustrated (with
   cats!)
   welcome to part four of learning ai if you suck at math. if you missed
   parts 1, 2, 3, 5, 6 and 7 be sure to check them   hackernoon.com

   after you check that out, the breakthroughs i mentioned before and the
   programming frameworks like tensorflow or keras (for more on keras go
   [81]here), now i think you have an idea of what you need to understand
   and work with deep learning.

   but what have we achieved so far with dl? to name a few (from fran  ois
   chollet book on dl):
     * near-human level image classification.
     * near-human level id103.
     * near-human level handwriting transcription.
     * improved machine translation.
     * improved text-to-speech conversion.
     * digital assistants such as google now or amazon alexa.
     * near-human level autonomous driving.
     * improved ad targeting, as used by google, baidu, and bing.
     * improved search results on the web.
     * answering natural language questions.
     * superhuman go playing.

   and much more. here   s a list of 30 great and funny applications of dl:
   [82]30 amazing applications of deep learning
   over the last few years deep learning was applied to hundreds of
   problems, ranging from id161 to
   natural   www.yaronhadad.com

   thinking about the future of deep learning (for programming or building
   applications), i   ll repeat what i said in other posts.

   i really think guis and automl are the near future of getting things
   done with deep learning. don   t get me wrong, i love coding, but i think
   the amount of code we will be writing next years will decay.

   we cannot spend so many hours worldwide programming the same stuff over
   and over again, so i think these two features (guis and automl) will
   help data scientist on getting more productive and solving more
   problems.

   on of the best free platforms for doing these tasks in a simple gui is
   [83]deep cognition. their simple drag & drop interface helps you design
   deep learning models with ease. deep learning studio can automatically
   design a deep learning model for your custom dataset thanks to their
   advance automl feature with nearly one click.

   here you can learn more about them:
   [84]deepcognition - become an ai-powered organization today
   design, train, and deploy deep learning models without coding. deep
   learning studio simplifies and accelerates the   deepcognition.ai

   take a look at the prices :o, it   s freeeee :)
   [1*282i3qilb2op2yt72ydbmg.png]

   i mean, it   s amazing how fast the development in the area is right now,
   that we can have simple guis to interact with all the hard and
   interesting concepts i talked about in this post.

   one of the things i like about that platform is that you can still
   code, interact with tensorflow, keras, caffe, mxnet an much more with
   the command line or their notebook without installing anything. you
   have both the notebook and the cli!

   i take my hat off to them and their contribution to society.

   iframe: [85]/media/6d70e9e4b0c14b852fae793dfc34f909?postid=7828803693b0

   other interesting applications of deep learning that you can try for
   free or for little cost are (some of them are on private betas):
   [86]skejul - simplify the future...
   if it's in the future, it's on skejul... using skejul's context aware
   predictive computingtm platform set your meetings   skejul.com
   [87]seeing ai | talking camera app for those with a visual impairment
   a free app that narrates the world around you. designed for the low
   vision community, this research project harnesses   www.microsoft.com
   [88]dialogflow
   a conversational user experience platform.dialogflow.com

   iframe: [89]/media/08c2a3d0c5e63c6d814317adca6ff100?postid=7828803693b0

   iframe: [90]/media/b0b19511f96f859e676414ae479408dc?postid=7828803693b0
     __________________________________________________________________

   thanks for reading this weird introduction to deep learning. i hope it
   helped you getting started in this amazing area, or maybe just discover
   something new.

   if you have questions just add me on linkedin and we   ll chat there:
   [91]favio v  zquez - data scientist / tools manager mx - bbva data &amp;
   analytics | linkedin
   view favio v  zquez's profile on linkedin, the world's largest
   professional community. favio has 12 jobs listed on
   their   www.linkedin.com

   thanks to [92]argenis leon and [93]jared romero.
     * [94]machine learning
     * [95]deep learning
     * [96]data science
     * [97]neural networks
     * [98]towards data science

   (button)
   (button)
   (button) 4.8k claps
   (button) (button) (button) 14 (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of favio v  zquez

[99]favio v  zquez

   medium member since nov 2018

   data scientist, physicist and computer engineer. love sharing ideas,
   thoughts and contributing to open source in machine learning and deep
   learning ;).

     (button) follow
   [100]towards data science

[101]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 4.8k
     * (button)
     *
     *

   [102]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [103]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/7828803693b0
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_ovylrhsmhedw---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://medium.com/datos-y-ciencia/una-introducci  n-extra  a-al-deep-learning-3407e05e0483
  17. https://towardsdatascience.com/@faviovazquez
  18. https://towardsdatascience.com/my-journey-into-deep-learning-c66e6ef2a317
  19. http://deepcognition.ai/resources/webinars/#intro-deep-learning
  20. https://arxiv.org/pdf/1707.04041.pdf
  21. https://www.deeplearning.ai/
  22. http://www.deeplearningbook.org/
  23. http://mathworld.wolfram.com/line.html
  24. http://mathworld.wolfram.com/polarcoordinates.html
  25. https://www.nature.com/articles/323533a0
  26. http://yann.lecun.com/exdb/publis/pdf/lecun-88.pdf
  27. https://www.coursera.org/learn/deep-neural-network/lecture/rwqye/weight-initialization-for-deep-networks
  28. http://rishy.github.io/ml/2017/01/05/how-to-train-your-dnn/
  29. http://cs231n.github.io/neural-networks-2/#init
  30. https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0
  31. https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6
  32. https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5
  33. http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer
  34. http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf
  35. https://papers.nips.cc/paper/4824-id163-classification-with-deep-convolutional-neural-networks.pdf
  36. https://arxiv.org/abs/1512.03385v1
  37. https://arxiv.org/abs/1608.02908
  38. https://arxiv.org/abs/1311.2524v5
  39. https://arxiv.org/abs/1703.06870
  40. https://github.com/facebookresearch/detectron
  41. https://deeplearning4j.org/lstm.html
  42. http://colah.github.io/posts/2015-08-understanding-lstms/
  43. https://keras.io/layers/recurrent/
  44. https://arxiv.org/abs/1406.2661v1
  45. https://github.com/nashory/gans-awesome-applications
  46. https://hackernoon.com/what-is-a-capsnet-or-capsule-network-2bfbe48769cc
  47. https://medium.com/ai  -theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b
  48. https://github.com/gram-ai/capsule-networks
  49. https://www.linkedin.com/in/andrewyng/
  50. https://www.linkedin.com/company/2453129/
  51. https://www.coursera.org/specializations/deep-learning
  52. https://www.linkedin.com/in/sirajraval/
  53. https://towardsdatascience.com/media/0d76653cbb784e3f0c0e88720db74c47?postid=7828803693b0
  54. https://towardsdatascience.com/media/218a91cc9009c842f1409618f6dd647d?postid=7828803693b0
  55. https://www.linkedin.com/in/fchollet/
  56. https://www.manning.com/books/deep-learning-with-python
  57. https://www.manning.com/books/deep-learning-with-r
  58. https://www.linkedin.com/school/3153548/?legacyschoolid=3153548
  59. https://cognitiveclass.ai/courses/introduction-deep-learning/
  60. https://cognitiveclass.ai/courses/deep-learning-tensorflow/
  61. https://www.linkedin.com/company/3227175/
  62. https://www.datacamp.com/courses/deep-learning-in-python
  63. https://www.datacamp.com/community/tutorials/keras-r-deep-learning
  64. https://www.linkedin.com/company/3477522/
  65. https://databricks.github.io/spark-deep-learning/site/index.html
  66. https://github.com/maxpumperla/elephas
  67. https://www.linkedin.com/company/1288/
  68. https://github.com/yahoo/tensorflowonspark
  69. https://www.linkedin.com/company/157302/
  70. https://github.com/cerndb/dist-keras
  71. https://www.linkedin.com/company/2531735/
  72. https://www.qubole.com/blog/distributed-deep-learning-keras-apache-spark/
  73. https://www.linkedin.com/company/1053/
  74. https://github.com/intel-analytics/bigdl
  75. https://www.linkedin.com/company/1441/
  76. https://cloud.google.com/blog/big-data/2017/11/using-apache-spark-with-tensorflow-on-google-cloud-platform
  77. https://www.tensorflow.org/
  78. http://mathworld.wolfram.com/riemanntensor.html
  79. https://www.kdnuggets.com/2017/06/deep-learning-demystifying-tensors.html
  80. https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32
  81. https://becominghuman.ai/deep-learning-made-easy-with-deep-cognition-403fbe445351
  82. http://www.yaronhadad.com/deep-learning-most-amazing-applications/
  83. http://deepcognition.ai/
  84. http://deepcognition.ai/
  85. https://towardsdatascience.com/media/6d70e9e4b0c14b852fae793dfc34f909?postid=7828803693b0
  86. http://skejul.com/
  87. https://www.microsoft.com/en-us/seeing-ai/
  88. https://dialogflow.com/
  89. https://towardsdatascience.com/media/08c2a3d0c5e63c6d814317adca6ff100?postid=7828803693b0
  90. https://towardsdatascience.com/media/b0b19511f96f859e676414ae479408dc?postid=7828803693b0
  91. https://www.linkedin.com/in/faviovazquez/
  92. https://medium.com/@argenisleon?source=post_page
  93. https://medium.com/@rocajare?source=post_page
  94. https://towardsdatascience.com/tagged/machine-learning?source=post
  95. https://towardsdatascience.com/tagged/deep-learning?source=post
  96. https://towardsdatascience.com/tagged/data-science?source=post
  97. https://towardsdatascience.com/tagged/neural-networks?source=post
  98. https://towardsdatascience.com/tagged/towards-data-science?source=post
  99. https://towardsdatascience.com/@faviovazquez
 100. https://towardsdatascience.com/?source=footer_card
 101. https://towardsdatascience.com/?source=footer_card
 102. https://towardsdatascience.com/
 103. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
 105. https://towardsdatascience.com/@faviovazquez?source=post_header_lockup
 106. http://deepcognition.ai/resources/webinars/#intro-deep-learning
 107. https://www.coursera.org/learn/deep-neural-network/lecture/rwqye/weight-initialization-for-deep-networks
 108. http://rishy.github.io/ml/2017/01/05/how-to-train-your-dnn/
 109. http://cs231n.github.io/neural-networks-2/#init
 110. https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0
 111. https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6
 112. https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5
 113. https://arxiv.org/abs/1512.03385v1
 114. https://arxiv.org/abs/1608.02908
 115. https://arxiv.org/abs/1311.2524v5
 116. https://arxiv.org/abs/1703.06870
 117. https://github.com/facebookresearch/detectron
 118. https://deeplearning4j.org/lstm.html
 119. http://colah.github.io/posts/2015-08-understanding-lstms/
 120. https://keras.io/layers/recurrent/
 121. https://arxiv.org/abs/1406.2661v1
 122. https://github.com/nashory/gans-awesome-applications
 123. https://hackernoon.com/what-is-a-capsnet-or-capsule-network-2bfbe48769cc
 124. https://medium.com/ai%c2%b3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b
 125. https://github.com/gram-ai/capsule-networks
 126. https://www.coursera.org/specializations/deep-learning
 127. https://www.manning.com/books/deep-learning-with-python
 128. https://www.manning.com/books/deep-learning-with-r
 129. https://cognitiveclass.ai/courses/introduction-deep-learning/
 130. https://cognitiveclass.ai/courses/deep-learning-tensorflow/
 131. https://www.datacamp.com/courses/deep-learning-in-python
 132. https://www.datacamp.com/community/tutorials/keras-r-deep-learning
 133. https://databricks.github.io/spark-deep-learning/site/index.html
 134. https://github.com/maxpumperla/elephas
 135. https://github.com/yahoo/tensorflowonspark
 136. https://github.com/cerndb/dist-keras
 137. https://www.qubole.com/blog/distributed-deep-learning-keras-apache-spark/
 138. https://github.com/intel-analytics/bigdl
 139. https://cloud.google.com/blog/big-data/2017/11/using-apache-spark-with-tensorflow-on-google-cloud-platform
 140. https://www.kdnuggets.com/2017/06/deep-learning-demystifying-tensors.html
 141. https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32
 142. http://www.yaronhadad.com/deep-learning-most-amazing-applications/
 143. http://deepcognition.ai/
 144. http://skejul.com/
 145. https://www.microsoft.com/en-us/seeing-ai/
 146. https://dialogflow.com/
 147. https://www.linkedin.com/in/faviovazquez/
 148. https://medium.com/p/7828803693b0/share/twitter
 149. https://medium.com/p/7828803693b0/share/facebook
 150. https://towardsdatascience.com/@faviovazquez?source=footer_card
 151. https://medium.com/p/7828803693b0/share/twitter
 152. https://medium.com/p/7828803693b0/share/facebook
