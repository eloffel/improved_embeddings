   #[1]paralleldots    feed [2]paralleldots    comments feed [3]paralleldots
      ten machine learning algorithms you should know to become a data
   scientist comments feed [4]alternate [5]alternate

   [6]skip to content
   search for: ____________________ (button)     search

     * [7]log in
     * [8]sign up
     * [9]support
       [10]faqs [11]api docs [12]api wrappers [13]ms excel add-in docs
       [14]google sheets add-in docs
     * [15]pricing
     * [16]company
       [17]about us [18]blog [19]careers
     * [20]plugins
       [21]ms excel add-in [22]google sheets add-in
     * [23]apis

text analysis apis
       [24]id31 [25]emotion analysis [26]keyword
       extractor(english) [27]keyword extractor(other) [28]named entity
       recognition [29]text classification [30]semantic analysis
       [31]intent analysis [32]abusive analysis

visual analysis apis
       [33]image recognition [34]facial emotion detection
     * [35]products
       [36]smartreader [37]text analysis apis [38]visual intelligence apis
       [39]video analysis platform
     * [40][white.png]

[41]paralleldots

   world class ai solutions at your fingertips
     * [42]facebook
     * [43]twitter
     * [44]linkedin

     * [45]home
     * [46]news
     * [47]product
     * [48]data science
     * [49]research

   search for: ____________________ (button)     search

   [50]data science, [51]data scientist, [52]featured, [53]machine
   learning

ten machine learning algorithms you should know to become a data scientist

   posted on [54]march 13, 2018october 30, 2018 author [55]muktabh mayank

   machine learning algorithms
   [56]
   silver blog

   machine learning practitioners have different personalities. while some
   of them are    i am an expert in x and x can train on any type of data   ,
   where x = some algorithm, some others are    right tool for the right job
   people   . a lot of them also subscribe to    jack of all trades. master of
   one    strategy, where they have one area of deep expertise and know
   slightly about different fields of machine learning. that said, no one
   can deny the fact that as practicing data scientists, we will have to
   know basics of some common machine learning algorithms, which would
   help us engage with a new-domain problem we come across. this is a
   whirlwind tour of common machine learning algorithms and quick
   resources about them which can help you get started on them.

1. principal component analysis(pca)/svd

   pca is an unsupervised method to understand global properties of a
   dataset consisting of vectors. covariance matrix of data points is
   analyzed here to understand what dimensions(mostly)/ data points
   (sometimes) are more important (ie have high variance amongst
   themselves, but low covariance with others). one way to think of top
   pcs of a matrix is to think of its eigenvectors with highest
   eigenvalues. svd is essentially a way to calculate ordered components
   too, but you don   t need to get the covariance matrix of points to get
   it.

   machine learning algorithms

   this algorithm helps one fight curse of dimensionality by getting
   datapoints with reduced dimensions.

libraries:

   [57]https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.s
   vd.html

   [58]http://scikit-learn.org/stable/modules/generated/sklearn.decomposit
   ion.pca.html

introductory tutorial:

   [59]https://arxiv.org/pdf/1404.1100.pdf

2a. least squares and polynomial fitting

   remember your numerical analysis code in college, where you used to fit
   lines and curves to points to get an equation. you can use them to fit
   curves in machine learning for very small datasets with low dimensions.
   (for large data or datasets with many dimensions, you might just end up
   terribly overfitting, so don   t bother). ols has a closed form solution,
   so you don   t need to use complex optimization techniques.

   machine learning algorithms

   as is obvious, use this algorithm to fit simple curves / regression

libraries:

   [60]https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.l
   stsq.html
   [61]https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.p
   olyfit.html

introductory tutorial:

   [62]https://lagunita.stanford.edu/c4x/humanitiesscience/statlearning/as
   set/linear_regression.pdf

2b. constrained id75

   least squares can get confused with outliers, spurious fields and noise
   in data. we thus need constraints to decrease the variance of the line
   we fit on a dataset. the right method to do it is to fit a linear
   regression model which will ensure that the weights do not misbehave.
   models can have l1 norm (lasso) or l2 (ridge regression) or both
   (elastic regression). mean squared loss is optimized.

   machine learning algorithms
   use these algorithms to fit regression lines with constraints, avoiding
   overfitting and masking noise dimensions from model.

libraries:

   [63]http://scikit-learn.org/stable/modules/linear_model.html

introductory tutorial(s):

   [64]https://www.youtube.com/watch?v=5asl5eq2x0a

   [65]https://www.youtube.com/watch?v=jbwscwot51m

3. id116 id91

   everyone   s favorite unsupervised id91 algorithm. given a set of
   data points in form of vectors, we can make clusters of points based on
   distances between them. it   s an expectation maximization algorithm that
   iteratively moves the centers of clusters and then clubs points with
   each cluster centers. the input the algorithm has taken is the number
   of clusters which are to be generated and the number of iterations in
   which it will try to converge clusters.
   machine learning algorithms

   as is obvious from the name, you can use this algorithm to create k
   clusters in dataset

library:

   [66]http://scikit-learn.org/stable/modules/generated/sklearn.cluster.km
   eans.html

introductory tutorial(s):

   [67]https://www.youtube.com/watch?v=hdmnf9jg3lo

   [68]https://www.datascience.com/blog/id116-id91

4. id28

   id28 is constrained id75 with a
   nonlinearity (sigmoid function is used mostly or you can use tanh too)
   application after weights are applied, hence restricting the outputs
   close to +/- classes (which is 1 and 0 in case of sigmoid).
   cross-id178 id168s are optimized using id119. a
   note to beginners: id28 is used for classification, not
   regression. you can also think of id28 as a one layered
   neural network. id28 is trained using optimization
   methods like id119 or l-bfgs. nlp people will often use it
   with the name of maximum id178 classifier.

   this is what a sigmoid looks like:

   machine learning algorithms

   use lr to train simple, but very robust classifiers.

library:

   [69]http://scikit-learn.org/stable/modules/generated/sklearn.linear_mod
   el.logisticregression.html

introductory tutorial(s):

   [70]https://www.youtube.com/watch?v=-la3q9d7akq

5. id166 (support vector machines)

   id166s are linear models like linear/ id28, the difference
   is that they have different margin-based id168 (the derivation
   of support vectors is one of the most beautiful mathematical results i
   have seen along with eigenvalue calculation). you can optimize the loss
   function using optimization methods like l-bfgs or even sgd.

   machine learning algorithms

   another innovation in id166s is the usage of kernels on data to feature
   engineer. if you have good domain insight, you can replace the good-old
   rbf kernel with smarter ones and profit.

   one unique thing that id166s can do is learn one class classifiers.

   id166s can used to train a classifier (even regressors)

library:

   [71]http://scikit-learn.org/stable/modules/generated/sklearn.id166.svc.ht
   ml

introductory tutorial(s):

   [72]https://www.youtube.com/watch?v=ehserlpjwuu

   note: sgd based training of both id28 and id166s are found
   in sklearn   s
   [73]http://scikit-learn.org/stable/modules/generated/sklearn.linear_mod
   el.sgdclassifier.html , which i often use as it lets me check both lr
   and id166 with a common interface. you can also train it on >ram sized
   datasets using mini batches.

6. feedforward neural networks

   these are basically multilayered id28 classifiers. many
   layers of weights separated by non-linearities (sigmoid, tanh, relu +
   softmax and the cool new selu). another popular name for them is
   multi-layered id88s. ffnns can be used for classification and
   unsupervised id171 as autoencoders.
   machine learning algorithms multi-layered id88

   machine learning algorithms ffnn as an autoencoder

   ffnns can be used to train a classifier or extract features as
   autoencoders

libraries:

   [74]http://scikit-learn.org/stable/modules/generated/sklearn.neural_net
   work.mlpclassifier.html#sklearn.neural_network.mlpclassifier

   [75]http://scikit-learn.org/stable/modules/generated/sklearn.neural_net
   work.mlpregressor.html

   [76]https://github.com/keras-team/keras/blob/master/examples/reuters_ml
   p_relu_vs_selu.py

introductory tutorial(s):

   [77]http://www.deeplearningbook.org/contents/mlp.html

   [78]http://www.deeplearningbook.org/contents/autoencoders.html

   [79]http://www.deeplearningbook.org/contents/representation.html

7. convolutional neural networks (convnets)

   almost any state of the art vision based machine learning result in the
   world today has been achieved using convolutional neural networks. they
   can be used for image classification, id164 or even
   segmentation of images. invented by yann lecun in late 80s-early 90s,
   convnets feature convolutional layers which act as hierarchical feature
   extractors. you can use them in text too (and even graphs).

   use convnets for state of the art image and text classification, object
   detection, image segmentation.

libraries:

   [80]https://developer.nvidia.com/digits

   [81]https://github.com/kuangliu/torchcv

   [82]https://github.com/chainer/chainercv

   [83]https://keras.io/applications/

introductory tutorial(s):

   [84]http://cs231n.github.io/

   [85]https://adeshpande3.github.io/a-beginner%27s-guide-to-understanding
   -convolutional-neural-networks/

8. recurrent neural networks (id56s):

   id56s model sequences by applying the same set of weights recursively on
   the aggregator state at a time t and input at a time t (given a
   sequence has inputs at times 0..t..t, and have a hidden state at each
   time t which is output from t-1 step of id56). pure id56s are rarely used
   now but its counterparts like lstms and grus are state of the art in
   most sequence modeling tasks.

   machine learning algorithms

   id56 (if here is a densely connected unit and a nonlinearity, nowadays f
   is generally lstms or grus ). lstm unit which is used instead of a
   plain dense layer in a pure id56.

   machine learning algorithms

   use id56s for any sequence modelling task specially text classification,
   machine translation, language modelling

library:

   [86]https://github.com/tensorflow/models (many cool nlp research papers
   from google are here)

   [87]https://github.com/wabyking/textclassificationbenchmark

   [88]http://openid4.net/

introductory tutorial(s):

   [89]http://cs224d.stanford.edu/

   [90]http://www.wildml.com/category/neural-networks/recurrent-neural-net
   works/

   [91]http://colah.github.io/posts/2015-08-understanding-lstms/

9. id49 (crfs)

   crfs are probably the most frequently used models from the family of
   probabilitic id114 (pgms). they are used for sequence
   modeling like id56s and can be used in combination with id56s too. before
   id4 systems came in crfs were the state of the
   art and in many sequence tagging tasks with small datasets, they will
   still learn better than id56s which require a larger amount of data to
   generalize. they can also be used in other id170 tasks
   like image segmentation etc. crf models each element of the sequence
   (say a sentence) such that neighbors affect a label of a component in a
   sequence instead of all labels being independent of each other.

   use crfs to tag sequences (in text, image, time series, dna etc.)

library:

   [92]https://sklearn-crfsuite.readthedocs.io/en/latest/

introductory tutorial(s):

   [93]http://blog.echen.me/2012/01/03/introduction-to-conditional-random-
   fields/

   7 part lecture series by hugo larochelle on youtube:
   [94]https://www.youtube.com/watch?v=gf3isjkgpba

10. id90

   let   s say i am given an excel sheet with data about various fruits and
   i have to tell which look like apples. what i will do is ask a question
      which fruits are red and round ?    and divide all fruits which answer
   yes and no to the question. now, all red and round fruits might not be
   apples and all apples won   t be red and round. so i will ask a question
      which fruits have red or yellow color hints on them?     on red and
   round fruits and will ask    which fruits are green and round ?    on not
   red and round fruits. based on these questions i can tell with
   considerable accuracy which are apples. this cascade of questions is
   what a decision tree is. however, this is a decision tree based on my
   intuition. intuition cannot work on high dimensional and complex data.
   we have to come up with the cascade of questions automatically by
   looking at tagged data. that is what machine learning based decision
   trees do. earlier versions like cart trees were once used for simple
   data, but with bigger and larger dataset, the id160
   needs to solved with better algorithms. the two common id90
   algorithms used nowadays are id79s (which build different
   classifiers on a random subset of attributes and combine them for
   output) and boosting trees (which train a cascade of trees one on top
   of others, correcting the mistakes of ones below them).

   id90 can be used to classify datapoints (and even regression)

libraries

   [95]http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.r
   andomforestclassifier.html

   [96]http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.g
   radientboostingclassifier.html

   [97]http://xgboost.readthedocs.io/en/latest/

   [98]https://catboost.yandex/

introductory tutorial:

   [99]http://xgboost.readthedocs.io/en/latest/model.html

   [100]https://arxiv.org/abs/1511.05741

   [101]https://arxiv.org/abs/1407.7502

   [102]http://education.parrotprediction.teachable.com/p/practical-xgboos
   t-in-python

td algorithms (good to have)

   if you are still wondering how can any of the above methods solve tasks
   like defeating go world champion like deepmind did, they cannot. all
   the 10 type of algorithms we talked about before this was pattern
   recognition, not strategy learners. to learn strategy to solve a
   multi-step problem like winning a game of chess or playing atari
   console, we need to let an agent-free in the world and learn from the
   rewards/penalties it faces. this type of machine learning is called
   id23. a lot (not all) of recent successes in the
   field is a result of combining perception abilities of a convnet or
   lstm to a set of algorithms called temporal difference learning. these
   include id24, sarsa and some other variants. these algorithms are
   a smart play on bellman   s equations to get a id168 that can be
   trained with rewards an agent gets from the environment.

   these algorithms are used to automatically play games mostly :d, also
   other applications in language generation and id164.

libraries:

   [103]https://github.com/keras-rl/keras-rl

   [104]https://github.com/tensorflow/minigo

introductory tutorial(s):

   grab the free sutton and barto book:
   [105]https://web2.qatar.cmu.edu/~gdicaro/15381/additional/suttonbarto-r
   l-5nov17.pdf

   watch david silver course:
   [106]https://www.youtube.com/watch?v=2pwv7govuf0

   these are the 10 machine learning algorithms which you can learn to
   become a data scientist.

   you can also read about machine learning libraries [107]here.

   we hope you liked the article. please [108]sign up for a free
   paralleldots account to start your ai journey. you can also check
   demo   s of pralleldots ai apis [109]here.

   [110]paralleldots

   posted in [111]data science, [112]data scientist, [113]featured,
   [114]machine learning   tagged [115]data science   [116]leave a comment on
   ten machine learning algorithms you should know to become a data
   scientist

post navigation

   [117]launching paralleldots ai apis in multiple languages
   [118]can machine learning predict poverty?

leave a reply [119]cancel reply

   you must be [120]logged in to post a comment.
   [121]get a free paralleldots account [122]schedule a demo

   or contact us at [123][email protected]

products

     * [124]excel add-in
     * [125]text analytics apis
     * [126]custom classifier

resources

     * [127]api docs
     * [128]api wrapper
     * [129]excel add-in docs

other links

     * [130]careers
     * [131]pricing
     * [132]blog
     * [133]webinar
     * [134]my dashboard
     * [135]milestones

connect

     * [136]facebook
     * [137]twitter
     * [138]linkedin
     * [139]google plus

     * [140]faqs
     * [141]terms & conditions
     * [142]privacy policy
     * [143]contact sales
     * [144]sign up

   copyright    paralleldots,inc. 2018. all rights reserved.

   learn something new every week. subscribe now!

   ____________________

   sign up
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://blog.paralleldots.com/feed/
   2. https://blog.paralleldots.com/comments/feed/
   3. https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/feed/
   4. https://blog.paralleldots.com/wp-json/oembed/1.0/embed?url=https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/
   5. https://blog.paralleldots.com/wp-json/oembed/1.0/embed?url=https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/&format=xml
   6. https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/#main
   7. https://user.apis.paralleldots.com/
   8. https://user.apis.paralleldots.com/signing-up?utm_source=website&utm_medium=homepage&utm_campaign=signup
   9. javascript:void(0)
  10. https://help.paralleldots.com/
  11. https://www.paralleldots.com/docs
  12. https://www.paralleldots.com/api-wrappers
  13. https://www.paralleldots.com/excel-docs
  14. https://www.paralleldots.com/google-sheet-add-on-docs
  15. https://www.paralleldots.com/pricing
  16. javascript:void(0)
  17. https://www.paralleldots.com/about-us
  18. https://blog.paralleldots.com/
  19. https://www.paralleldots.com/careers
  20. javascript:void(0)
  21. https://www.paralleldots.com/excel-plugin
  22. https://www.paralleldots.com/google-sheet-add-on
  23. javascript:void(0)
  24. https://www.paralleldots.com/sentiment-analysis
  25. https://www.paralleldots.com/emotion-detection
  26. https://www.paralleldots.com/keyword-generator
  27. https://www.paralleldots.com/multilingual-keywords
  28. https://www.paralleldots.com/named-entity-recognition
  29. https://www.paralleldots.com/text-classification
  30. https://www.paralleldots.com/semantic-analysis
  31. https://www.paralleldots.com/intent-analysis
  32. https://www.paralleldots.com/abusive-content
  33. https://www.paralleldots.com/object-recognizer
  34. https://www.paralleldots.com/facial-emotion
  35. javascript:void(0)
  36. https://smartreader.paralleldots.com/
  37. https://www.paralleldots.com/text-analysis-apis
  38. https://www.paralleldots.com/visual-analytics
  39. https://www.paralleldots.com/video-analysis-platform
  40. https://www.paralleldots.com/
  41. https://www.paralleldots.com/
  42. https://www.facebook.com/paralleldots
  43. https://twitter.com/paralleldots
  44. https://www.linkedin.com/company/paralleldots/
  45. http://blog.paralleldots.com/
  46. https://blog.paralleldots.com/category/news/
  47. https://blog.paralleldots.com/category/technology/product/
  48. https://blog.paralleldots.com/category/data-science/
  49. https://blog.paralleldots.com/category/research/
  50. https://blog.paralleldots.com/category/data-science/
  51. https://blog.paralleldots.com/category/data-science/data-scientist/
  52. https://blog.paralleldots.com/category/featured/
  53. https://blog.paralleldots.com/category/data-science/machine-learning/
  54. https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/
  55. https://blog.paralleldots.com/author/muktabh/
  56. https://www.kdnuggets.com/2018/05/top-stories-2018-apr.html
  57. https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html
  58. http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.pca.html
  59. https://arxiv.org/pdf/1404.1100.pdf
  60. https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html
  61. https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html
  62. https://lagunita.stanford.edu/c4x/humanitiesscience/statlearning/asset/linear_regression.pdf
  63. http://scikit-learn.org/stable/modules/linear_model.html
  64. https://www.youtube.com/watch?v=5asl5eq2x0a
  65. https://www.youtube.com/watch?v=jbwscwot51m
  66. http://scikit-learn.org/stable/modules/generated/sklearn.cluster.kmeans.html
  67. https://www.youtube.com/watch?v=hdmnf9jg3lo
  68. https://www.datascience.com/blog/id116-id91
  69. http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.logisticregression.html
  70. https://www.youtube.com/watch?v=-la3q9d7akq
  71. http://scikit-learn.org/stable/modules/generated/sklearn.id166.svc.html
  72. https://www.youtube.com/watch?v=ehserlpjwuu
  73. http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.sgdclassifier.html
  74. http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.mlpclassifier.html#sklearn.neural_network.mlpclassifier
  75. http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.mlpregressor.html
  76. https://github.com/keras-team/keras/blob/master/examples/reuters_mlp_relu_vs_selu.py
  77. http://www.deeplearningbook.org/contents/mlp.html
  78. http://www.deeplearningbook.org/contents/autoencoders.html
  79. http://www.deeplearningbook.org/contents/representation.html
  80. https://developer.nvidia.com/digits
  81. https://github.com/kuangliu/torchcv
  82. https://github.com/chainer/chainercv
  83. https://keras.io/applications/
  84. http://cs231n.github.io/
  85. https://adeshpande3.github.io/a-beginner's-guide-to-understanding-convolutional-neural-networks/
  86. https://github.com/tensorflow/models
  87. https://github.com/wabyking/textclassificationbenchmark
  88. http://openid4.net/
  89. http://cs224d.stanford.edu/
  90. http://www.wildml.com/category/neural-networks/recurrent-neural-networks/
  91. http://colah.github.io/posts/2015-08-understanding-lstms/
  92. https://sklearn-crfsuite.readthedocs.io/en/latest/
  93. http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/
  94. https://www.youtube.com/watch?v=gf3isjkgpba
  95. http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.randomforestclassifier.html
  96. http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.gradientboostingclassifier.html
  97. http://xgboost.readthedocs.io/en/latest/
  98. https://catboost.yandex/
  99. http://xgboost.readthedocs.io/en/latest/model.html
 100. https://arxiv.org/abs/1511.05741
 101. https://arxiv.org/abs/1407.7502
 102. http://education.parrotprediction.teachable.com/p/practical-xgboost-in-python
 103. https://github.com/keras-rl/keras-rl
 104. https://github.com/tensorflow/minigo
 105. https://web2.qatar.cmu.edu/~gdicaro/15381/additional/suttonbarto-rl-5nov17.pdf
 106. https://www.youtube.com/watch?v=2pwv7govuf0
 107. https://blog.paralleldots.com/data-science/lesser-known-machine-learning-libraries-part-ii/
 108. http://user.apis.paralleldots.com/signing-up?utm_source=blog&utm_medium=chat&utm_campaign=paralleldots_blog
 109. https://www.paralleldots.com/ai-apis
 110. http://user.apis.paralleldots.com/signing-up?utm_source=blog&utm_medium=chat&utm_campaign=paralleldots_blog
 111. https://blog.paralleldots.com/category/data-science/
 112. https://blog.paralleldots.com/category/data-science/data-scientist/
 113. https://blog.paralleldots.com/category/featured/
 114. https://blog.paralleldots.com/category/data-science/machine-learning/
 115. https://blog.paralleldots.com/tag/data-science/
 116. https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/#respond
 117. https://blog.paralleldots.com/product/paralleldots-ai-apis-multiple-languages/
 118. https://blog.paralleldots.com/product/competitive-analysis/can-machine-learning-predict-poverty/
 119. https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/#respond
 120. https://blog.paralleldots.com/wp-login.php?redirect_to=https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/
 121. https://user.apis.paralleldots.com/login
 122. https://www.paralleldots.com/contact-us
 123. https://blog.paralleldots.com/cdn-cgi/l/email-protection#3241535e574172425340535e5e575e565d46411c515d5f
 124. https://www.paralleldots.com/excel-plugin
 125. https://www.paralleldots.com/text-analysis-apis
 126. https://www.paralleldots.com/custom-classifier
 127. https://www.paralleldots.com/docs
 128. https://www.paralleldots.com/api-wrappers
 129. https://www.paralleldots.com/excel-docs
 130. https://recruiterflow.com/paralleldots/jobs
 131. https://www.paralleldots.com/pricing
 132. https://blog.paralleldots.com/
 133. https://www.paralleldots.com/webinar
 134. https://user.apis.paralleldots.com/login?next=/
 135. https://www.paralleldots.com/milestones-achieved
 136. https://www.facebook.com/paralleldots
 137. https://twitter.com/paralleldots
 138. https://www.linkedin.com/company/3572541
 139. https://plus.google.com/100119040678960878664
 140. https://help.paralleldots.com/
 141. https://www.paralleldots.com/terms-and-conditions
 142. https://www.paralleldots.com/privacy
 143. https://www.paralleldots.com/contact-us
 144. https://user.apis.paralleldots.com/signing-up?utm_source=website&utm_medium=footer&utm_campaign=signup

   hidden links:
 146. https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/#mobile-navigation
