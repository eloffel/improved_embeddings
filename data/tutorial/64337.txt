deep geometric matrix

completion

federico monti

universit`a della svizzera italiana

switzerland

federico.monti@usi.ch

joint work with m. m. bronstein (usi) and x. bresson (ntu)

1/44

deep geometric matrix

completion

federico monti

universit`a della svizzera italiana

switzerland

federico.monti@usi.ch

joint work with m. m. bronstein (usi) and x. bresson (ntu)

2/44

matrix completion:    net   ix challenge   

4

s
e
i
v
o
m
m

3

5

5

1

3

n users

min

x   rm  n

(cid:107)x(cid:107)    +   (cid:107)        (x     a)(cid:107)2

f

cand`es 2008

4/44

geometric matrix completion:    net   ix challenge   

h
p
a
r
g

e
i
v
o
m

5

5

4

4

5

5

5

1

user graph

1

2

4

5

min

x   rm  n

(cid:107)        (x     a)(cid:107)2

kalofolias et al. 2014

(cid:125)
f +   c tr(x   cx(cid:62))

(cid:123)(cid:122)

(cid:124)

(cid:107)x(cid:107)2gc

+   r tr(x(cid:62)   rx)

(cid:124)

(cid:123)(cid:122)

(cid:107)x(cid:107)2gr

(cid:125)

4/44

factorized geometric matrix completion models

h(cid:62)

user graph

h
p
a
r
g

e
i
v
o
m

w

(cid:107)        (x     a)(cid:107)2

f +   ctr(h(cid:62)   ch) +   rtr(w(cid:62)   rw)

min

w   rm  s
h   rn  s

rao et al. 2015

5/44

factorized geometric matrix completion models

h(cid:62)

user graph

h
p
a
r
g

e
i
v
o
m

w

(cid:107)        (x     a)(cid:107)2

f +   ctr(h(cid:62)   ch) +   rtr(w(cid:62)   rw)

min

w   rm  s
h   rn  s

do not fully exploit the local stationary structures that
users/items graphs present.

5/44

factorized geometric matrix completion models

h(cid:62)

user graph

h
p
a
r
g

e
i
v
o
m

w

(cid:107)        (x     a)(cid:107)2

f +   ctr(h(cid:62)   ch) +   rtr(w(cid:62)   rw)

min

w   rm  s
h   rn  s

do not fully exploit the local stationary structures that
users/items graphs present.
number of parameters to train is at least linear wrt the number of
users and item.

5/44

graph convolutional neural

networks

6/44

a new challenge: geometric data

7/44

a new challenge: geometric data

7/44

di   erent formulations of id98 on graphs

spectral domain1,2,3

spatial domain4,5,6

embedding domain7,8

1bruna et al. 2014; 2hena   , bruna, lecun 2015; 3de   errard, bresson,
vandergheynst 2016; 4masci et al. 2015; 5boscaini et al. 2016; 6monti et al. 2017;
7sinha, bai, ramani 2016; 8maron et al. 2017

8/44

laplacian eigenfunctions

9/44

convolution theorem

    given two functions f, h : z     r their convolution is a function

k/2(cid:88)

x(cid:48)=   k/2

(f (cid:63) h)(x) =

f (x     x(cid:48))h(x(cid:48)) = f   1{f{f}    f{h}}

10/44

convolution theorem

    given two functions f, h : z     r their convolution is a function

k/2(cid:88)

x(cid:48)=   k/2

(f (cid:63) h)(x) =

f (x     x(cid:48))h(x(cid:48)) = f   1{f{f}    f{h}}

    given two functions f, h : v     r their convolution is a function

10/44

convolution theorem

    given two functions f, h : z     r their convolution is a function

k/2(cid:88)

x(cid:48)=   k/2

(f (cid:63) h)(x) =

f (x     x(cid:48))h(x(cid:48)) = f   1{f{f}    f{h}}

    given two functions f, h : v     r their convolution is a function

10/44

convolution theorem

    given two functions f, h : z     r their convolution is a function

k/2(cid:88)

x(cid:48)=   k/2

(f (cid:63) h)(x) =

f (x     x(cid:48))h(x(cid:48)) = f   1{f{f}    f{h}}

    given two functions f, h : v     r their convolution is a function

10/44

spectral graph id98

convolutional layer expressed in the spectral domain

             p(cid:88)

l(cid:48)=1

              h(l,l(cid:48))

1

gl =   

  

               (cid:62)fl(cid:48)

             l = 1, . . . , q

l(cid:48) = 1, . . . , p

. . .

  h(l,l(cid:48))

n

where q is the number of features in output and p in input.

bruna et al. 2014

11/44

spectral graph id98

convolutional layer expressed in the spectral domain

             p(cid:88)

l(cid:48)=1

              h(l,l(cid:48))

1

gl =   

  

               (cid:62)fl(cid:48)

             l = 1, . . . , q

l(cid:48) = 1, . . . , p

. . .

  h(l,l(cid:48))

n

where q is the number of features in output and p in input.

o(n ) parameters per layer
o(n 2) computation of forward and inverse fourier transforms
  (cid:62),    (no fft on graphs)
no guarantee of spatial localization of    lters

bruna et al. 2014

11/44

spectral graph id98 with polynomial    lters

represent spectral transfer function as a polynomial or order r

r(cid:88)

    (  ) =

  j   j

where    = (  0, . . . ,   r)(cid:62) is the vector of    lter parameters

j=0

de   errard, bresson, vandergheynst 2016

12/44

spectral graph id98 with polynomial    lters

represent spectral transfer function as a chebyshev polynomial or order r

r(cid:88)

    (    ) =

  j tj (    )

j=0

where    = (  0, . . . ,   r)(cid:62) is the vector of    lter parameters,

tj (    ) = 2    tj   1(    )     tj   2(    )

t0(    ) = 1,

t1(    ) =     

and    1              1 is normalized frequency.

de   errard, bresson, vandergheynst 2016

12/44

spectral graph id98 with polynomial    lters

represent spectral transfer function as a chebyshev polynomial or order r

r(cid:88)

    (    ) =

  j tj (    )

where    = (  0, . . . ,   r)(cid:62) is the vector of    lter parameters,

tj (    ) = 2    tj   1(    )     tj   2(    )

t0(    ) = 1,

t1(    ) =     

j=0

and    1              1 is normalized frequency.
application of the    lter to scaled laplacian       = d   0.5   d   0.5     i =
         t :

r(cid:88)

r(cid:88)

g =   (

  j tj (     ))  t f =

  j tj (      )f

j=0

j=0

de   errard, bresson, vandergheynst 2016

12/44

spectral graph id98 with polynomial    lters

represent spectral transfer function as a chebyshev polynomial or order r

r(cid:88)

    (    ) =

  j tj (    )

where    = (  0, . . . ,   r)(cid:62) is the vector of    lter parameters,

tj (    ) = 2    tj   1(    )     tj   2(    )

t0(    ) = 1,

t1(    ) =     

j=0

and    1              1 is normalized frequency.
application of the    lter to scaled laplacian       = d   0.5   d   0.5     i =
         t :

r(cid:88)

r(cid:88)

g =   (

  j tj (     ))  t f =

  j tj (      )f

j=0

j=0

o(1) parameters per layer
filters have guaranteed r-hops support
no explicit computation of   (cid:62),        o(r|e|) computational
complexity

de   errard, bresson, vandergheynst 2016

12/44

community graph example

15

10

5

0

0

200

400

unnorm. laplacian eigenvalues

1

0.5

0

synthetic graph with 15 communities

normalized laplacian eigenvalues

0

200

400

levie et al. 2017

13/44

community graph example

1

|
)
  
(
  
|

0

  min

example of chebyshev    lters learned on the 15-communities graph

levie et al. 2017

  max

14/44

chebyshev: community graph example

100

80

60

40

20

%
y
c
a
r
u
c
c
a

chebnet

1

3

5

7

order r

9

11

13

community detection accuracy of chebnet on the synthetic

15-community graph

levie et al. 2017

15/44

spectral id98s

    splinenet: bruna, zaremba, szlam, lecun 2014; hena   , bruna,

lecun 2015

    chebnet: de   errard, bresson, vandergheynst 2016

    cayleynet: levie*, monti*, bresson, bronstein 2017

16/44

spectral zoom

cayley transform c(  ) =      i

  +i is a smooth bijection from r to eir \ {1}

levie et al. 2017

17/44

spectral zoom

cayley transform c(  ) =      i
applying cayley transform to the scaled eigenvalues h  

  +i is a smooth bijection from r to eir \ {1}

c(h  ) = (h       i)(h   + i)   1

results in a non-linear transformation of the eigenvalues (spectral zoom)

levie et al. 2017

17/44

spectral zoom

cayley transform c(  ) =      i
applying cayley transform to the scaled eigenvalues h  

  +i is a smooth bijection from r to eir \ {1}

c(h  ) = (h       i)(h   + i)   1

results in a non-linear transformation of the eigenvalues (spectral zoom)

m

i

0
   0.5

   1

m

i

0
   0.5

   1

m

i

0
   0.5

   1

   1    0.5 0
re

0.5

1

   1    0.5 0
re

0.5

1

   1    0.5 0
re

0.5

1

cayley transform c(h  ) for (left-to-right) h = 0.1, 1, and 10

of the 15-communities graph laplacian spectrum

levie et al. 2017

17/44

cayley polynomials

cayley polynomials of order r are a family of real-valued rational
functions with complex coe   cients cj

  c(h   ) =   

c0 +

cjc(h  )j +

  cjc(h  )   j

  t =

(cid:18)

r(cid:88)

j=1

r(cid:88)

= c0 +

cjc(h   )j +

(cid:110) r(cid:88)

j=1

= c0 + 2re

(cid:19)

j=1

r(cid:88)
r(cid:88)
cjc(h   )j(cid:111)

j=1

  cjc(h   )   j =

note that:   c(h  )  t = c(h   ) = (h        ii)(h    + ii)   1

j=1

(cayley 1846); levie et al. 2017

18/44

chebyshev vs cayley: community graph example

1

|
)
  
(
  
|

0

  min

example of cayley    lters learned on the 15-communities graph

levie et al. 2017

  max

19/44

chebyshev vs cayley: community graph example

100

80

60

40

20

%
y
c
a
r
u
c
c
a

chebnet
cayleynet

1

3

5

7

order r

9

11

13

community detection accuracy of chebnet and cayleynet

on the synthetic 15-community graph

levie et al. 2017

20/44

fast inversion

application of cayley    lters   c(h   )f = re
the computation of

j=0 cjc(h   )j(cid:111)
(cid:110)(cid:80)r

f requires

y0 = f
y1 = c(h   )f
y2 = c(h   )2f
...
yr = c(h   )rf

with c(h   ) = (h        ii)(h    + ii)   1     o(n3) operations.

(jacobi 1834); levie et al. 2017

21/44

fast inversion

application of cayley    lters   c(h   )f = re
the computation of

j=0 cjc(h   )j(cid:111)
(cid:110)(cid:80)r

f requires

y0 = f
y1 = c(h   )f = c(h   )y0
y2 = c(h   )2f = c(h   )y1
...
yr = c(h   )rf = c(h   )yr   1

with c(h   ) = (h        ii)(h    + ii)   1     o(n3) operations.

(jacobi 1834); levie et al. 2017

21/44

fast inversion

application of cayley    lters   c(h   )f = re
the computation of

j=0 cjc(h   )j(cid:111)
(cid:110)(cid:80)r

f requires

y0 = f
y1 = c(h   )f = c(h   )y0
y2 = c(h   )2f = c(h   )y1
...
yr = c(h   )rf = c(h   )yr   1

for a generic power j we have therefore

yj = c(h   )yj   1 = (h        ii)(h    + ii)   1yj   1

   

(h    + ii)yj = (h        ii)yj   1

(jacobi 1834); levie et al. 2017

21/44

fast inversion

approximate solution   yj     yj using k jacobi iterations

= j  y(k)

j + diag   1(h    + ii)(h        ii)  yj   1

  y(k+1)
j
j = diag   1(h    + ii)(h        ii)  yj   1
  y(0)

with j =    diag   1(h    + ii)o   (h    + ii)

(jacobi 1834); levie et al. 2017

22/44

fast inversion

approximate solution   yj     yj using k jacobi iterations

= j  y(k)

j + diag   1(h    + ii)(h        ii)  yj   1

  y(k+1)
j
j = diag   1(h    + ii)(h        ii)  yj   1
  y(0)

with j =    diag   1(h    + ii)o   (h    + ii)

cost: (cid:80)r

j=0 cj   yj        (h   )f has o(rk|e|) complexity for sparse graphs.

(jacobi 1834); levie et al. 2017

22/44

computational complexity of approximate inversion

training times

training times

0.5

)
c
e
s
(

e
m
t

i

0

full

13

9

5

1

cheb

0.5

)
c
e
s
(

e
m
t

i

0

full

13

9

5

1

cheb

1

3

5

7

9

11

13

200

400

600

800

1,000

order r

#vertices n

training computational complexities of cayleynet

levie et al. 2017

23/44

error bound

unnormalized laplacian: d = maxj djj and    = (cid:107)j(cid:107)    =

hd   

h2d2+1

< 1

normalized laplacian: assume that (h       + ii) is dominant diagonal s.t.
   = (cid:107)j(cid:107)    < 1

(jacobi 1834); levie et al. 2017

24/44

error bound

unnormalized laplacian: d = maxj djj and    = (cid:107)j(cid:107)    =

hd   

h2d2+1

< 1

normalized laplacian: assume that (h       + ii) is dominant diagonal s.t.
   = (cid:107)j(cid:107)    < 1

theorem 1 (approximation error) under the above assumptions

(cid:13)(cid:13)(cid:13)(cid:80)r
n(cid:80)r
j=1 j|cj| for a general graph and m =(cid:80)r

j=0 cj   yj        (h   )f

(cid:107)   (h   )f(cid:107)2

(cid:13)(cid:13)(cid:13)2

< m   k

   

j=1 j|cj| for

where m =
a regular graph

(jacobi 1834); levie et al. 2017

24/44

exponential decay

exponential decay on graphs f     lp(v), 1     p         has exponential
decay about vertex m if           (0, 1) and c > 0 such that for any k

where nk,m is the k-hop neighborhood of vertex m

(cid:107)f|n c

k,m

(cid:107)p     c  k(cid:107)f(cid:107)p

levie et al. 2017

25/44

exponential decay

exponential decay on graphs f     lp(v), 1     p         has exponential
decay about vertex m if           (0, 1) and c > 0 such that for any k

where nk,m is the k-hop neighborhood of vertex m

(cid:107)f|n c

k,m

(cid:107)p     c  k(cid:107)f(cid:107)p

compare to

exponential decay in r f (x) has exponential decay (about 0) if          
(0, 1) and c > 0 such that for any    > 0

(cid:107)f|bc

(cid:107)        c       (cid:107)f(cid:107)   

  

where b   is a ball of radius    about 0.

levie et al. 2017

25/44

exponential decay

exponential decay on graphs f     lp(v), 1     p         has exponential
decay about vertex m if           (0, 1) and c > 0 such that for any k

where nk,m is the k-hop neighborhood of vertex m

(cid:107)f|n c

k,m

(cid:107)p     c  k(cid:107)f(cid:107)p

theorem 2 (exponential decay of cayley    lters) let    (h   ) be a
cayley    lter of order r and   m a delta-function at vertex m of the
graph. then,    (h   )  m has exponential decay about m with p = 2,
c = 2m/(cid:107)   (   )  m(cid:107)2 and    =   1/r (where m =
j=1 j|cj|,    =
(cid:107)j(cid:107)    as in theorem 1)

n(cid:80)r

   

levie et al. 2017

25/44

chebyshev vs cayley

1

|
)
  
(
  
|

0

  min

example of chebyshev    lters (order r = 3) on euclidean grid

  max

26/44

chebyshev vs cayley

1

|
)
  
(
  
|

0

  min

example of chebyshev    lters (order r = 7) on euclidean grid

  max

26/44

chebyshev vs cayley

1

|
)
  
(
  
|

0

  min

example of cayley    lters (order r = 3) on euclidean grid

  max

26/44

poster

motifnet: a motif-based graph convolutional

network for directed graphs

f. monti, k. otness, m. m. bronstein

27/44

accuracy of approximate inversion

100

f u l l

80

13

%
y
c
a
r
u
c
c
a

60

40

20

9

5

1

c h e b

1

3

5

7

order r

9

11

13

community detection accuracy of cayleynet using approximate jacobi inversion

on the synthetic 15-community graph

levie et al. 2017

28/44

cora dataset

    citations network representing papers

(vertices) and citations (edges).

    goal: vertex-wise classi   cation

(paper topic).

    2708 documents, 7 topics.

    training set: 1,708 vertices;
validation set: 500 vertices;
test set: 500 vertices.

set et al. 2008

29/44

chebyshev vs cayley: cora example

normalized laplacian

scaled unnormalized laplacian

%
y
c
a
r
u
c
c
a

%
y
c
a
r
u
c
c
a

88

86

84

82

88

86

84

82

87.1

87.9

86.6

86.9

86.2

87.1

85.2

86.6

84.9

86.5

84.5

86.8

1

2

3
4
order r

5

6

87.1

87.3

86.6

86.9

86.2

86.2

85.2

86.4

84.9

85.3

84.5

85.3

%
y
c
a
r
u
c
c
a

%
y
c
a
r
u
c
c
a

90

85

80

75

90

85

80

75

78.0

87.7

85.7

86.0

86.6

86.8

87.5

85.7

87.7

85.2

87.4

85.1

1

2

3
4
order r

5

6

78.0

88.1

85.7

88.0

86.6

87.6

87.5

86.4

87.7

86.5

87.4

86.7

46k

69k

92k
115k
#params

138k

161k

46k

69k

92k
115k
#params

138k

161k

chebnet (blue) and cayleynet (orange) test accuracies on the cora dataset.
polynomials with complex coe   cients (top) and real coe   cients (bottom) have

been exploited with cayleynet in the two analysis.

levie et al. 2017; data: set et al. 2008

30/44

cayleynet: spectral graph id98 with cayley polynomials

represent spectral transfer function as a cayley polynomial or order r

(cid:110) r(cid:88)

cj(h       i)j(h   + i)   j(cid:111)

  c,h(  ) = c0 + 2re

where the    lter parameters are the vector of real/complex coe   cients
c = (c0, . . . , cr)(cid:62) and the spectral zoom h

j=1

levie et al. 2017

31/44

cayleynet: spectral graph id98 with cayley polynomials

represent spectral transfer function as a cayley polynomial or order r

(cid:110) r(cid:88)

cj(h       i)j(h   + i)   j(cid:111)

  c,h(  ) = c0 + 2re

where the    lter parameters are the vector of real/complex coe   cients
c = (c0, . . . , cr)(cid:62) and the spectral zoom h

j=1

o(1) parameters per layer
filters have guaranteed exponential spatial decay
o(r|e|) computational complexity with jacobi approximate
inversion (assuming sparsely-connected graph)

levie et al. 2017

31/44

cayleynet: spectral graph id98 with cayley polynomials

represent spectral transfer function as a cayley polynomial or order r

(cid:110) r(cid:88)

cj(h       i)j(h   + i)   j(cid:111)

  c,h(  ) = c0 + 2re

where the    lter parameters are the vector of real/complex coe   cients
c = (c0, . . . , cr)(cid:62) and the spectral zoom h

j=1

o(1) parameters per layer
filters have guaranteed exponential spatial decay
o(r|e|) computational complexity with jacobi approximate
inversion (assuming sparsely-connected graph)
spectral zoom property allowing to better localize in frequency

levie et al. 2017

31/44

cayleynet: spectral graph id98 with cayley polynomials

represent spectral transfer function as a cayley polynomial or order r

(cid:110) r(cid:88)

cj(h       i)j(h   + i)   j(cid:111)

  c,h(  ) = c0 + 2re

where the    lter parameters are the vector of real/complex coe   cients
c = (c0, . . . , cr)(cid:62) and the spectral zoom h

j=1

o(1) parameters per layer
filters have guaranteed exponential spatial decay
o(r|e|) computational complexity with jacobi approximate
inversion (assuming sparsely-connected graph)
spectral zoom property allowing to better localize in frequency
richer class of    lters than chebyshev for the same order

levie et al. 2017

31/44

mgid98

32/44

2d fourier transform

x

33/44

2d fourier transform

=

  

(  x1, . . . ,   xn)

  (cid:62)

x

column-wise trasform

33/44

2d fourier transform

=

  

  

  x

  (cid:62)

x

  

column-wise trasform + row-wise transform = 2d transform

33/44

multi-graph fourier transform

h
p
a
r
g
w
o
r

column graph

multi-graph fourier transform

  x =   (cid:62)

r x  c

where   c and   r are the eigenvectors of the column- and row-graph
laplacians    c and    r, respectively

monti, bresson, bronstein 2017

34/44

multi-graph convolution

h
p
a
r
g
w
o
r

column graph

multi-graph spectral convolution

x (cid:63) y =   r(   x       y)  (cid:62)

c

monti, bresson, bronstein 2017

34/44

multi-graph id98

multi-graph spectral coe   cient parametrization

r(cid:88)

j,j(cid:48)=0

    (    c,     r) =

  jj(cid:48)tj(    c)tj(cid:48)(    r)

monti, bresson, bronstein 2017

35/44

multi-graph id98

multi-graph spectral convolutional layer

       p(cid:88)

r(cid:88)

l(cid:48)=1

j,j(cid:48)=0

yl =   

  jj(cid:48)ll(cid:48)tj(      r)xl(cid:48)tj(cid:48)(      c)

       l = 1, . . . , q

l(cid:48) = 1, . . . , p

applied to p input channels (m    n matrices x1, . . . , xp) and producing
q output channels (m    n matrices y1, . . . , yq)

monti, bresson, bronstein 2017

35/44

multi-graph id98

multi-graph spectral convolutional layer

       p(cid:88)

r(cid:88)

l(cid:48)=1

j,j(cid:48)=0

yl =   

  jj(cid:48)ll(cid:48)tj(      r)xl(cid:48)tj(cid:48)(      c)

       l = 1, . . . , q

l(cid:48) = 1, . . . , p

applied to p input channels (m    n matrices x1, . . . , xp) and producing
q output channels (m    n matrices y1, . . . , yq)

o(1) parameters per layer
filters have guaranteed r-hops support on both graphs

monti, bresson, bronstein 2017

35/44

multi-graph id98

multi-graph spectral convolutional layer

       p(cid:88)

r(cid:88)

l(cid:48)=1

j,j(cid:48)=0

yl =   

  jj(cid:48)ll(cid:48)tj(      r)xl(cid:48)tj(cid:48)(      c)

       l = 1, . . . , q

l(cid:48) = 1, . . . , p

applied to p input channels (m    n matrices x1, . . . , xp) and producing
q output channels (m    n matrices y1, . . . , yq)

o(1) parameters per layer
filters have guaranteed r-hops support on both graphs
o(nm) computational complexity

monti, bresson, bronstein 2017

35/44

separable multi-graph spectral    lters

h
p
a
r
g

e
i
v
o
m

user graph

separable    lters applied to row- and column factors independently

ul =

  r,jtj(      r)wl

vl =

  c,j(cid:48)tj(cid:48)(      c)hl

l = 1, . . . , s

r(cid:88)

j(cid:48)=0

r(cid:88)

j=0

where   r = (  r,0, . . . ,   r,r) and   c = (  c,0, . . . ,   c,r) are the parameters of
the row- and column-    lters, w = (w1, . . . , ws) and h = (h1, . . . , hs)

monti, bresson, bronstein 2017

36/44

separable multi-graph id98

two spectral convolutional layers applied to each of the factors w, h

       p(cid:88)
       p(cid:88)

l(cid:48)=1

r(cid:88)
r(cid:88)

j=0

l(cid:48)=1

j(cid:48)=0

ul =   

vl =   

      
      

  r,jll(cid:48)tj(      r)wl(cid:48)

l = 1, . . . , q
l(cid:48) = 1, . . . , p

  c,j(cid:48)ll(cid:48)tj(cid:48)(      c)hl(cid:48)

monti, bresson, bronstein 2017

37/44

separable multi-graph id98

two spectral convolutional layers applied to each of the factors w, h

       p(cid:88)
       p(cid:88)

l(cid:48)=1

r(cid:88)
r(cid:88)

j=0

l(cid:48)=1

j(cid:48)=0

ul =   

vl =   

      
      

  r,jll(cid:48)tj(      r)wl(cid:48)

l = 1, . . . , q
l(cid:48) = 1, . . . , p

  c,j(cid:48)ll(cid:48)tj(cid:48)(      c)hl(cid:48)

o(1) parameters per layer
filters have guaranteed r-hops support on both graphs

monti, bresson, bronstein 2017

37/44

separable multi-graph id98

two spectral convolutional layers applied to each of the factors w, h

       p(cid:88)
       p(cid:88)

l(cid:48)=1

r(cid:88)
r(cid:88)

j=0

l(cid:48)=1

j(cid:48)=0

ul =   

vl =   

      
      

  r,jll(cid:48)tj(      r)wl(cid:48)

l = 1, . . . , q
l(cid:48) = 1, . . . , p

  c,j(cid:48)ll(cid:48)tj(cid:48)(      c)hl(cid:48)

o(1) parameters per layer
filters have guaranteed r-hops support on both graphs
o(n + m) computational complexity (assuming sparse graph)

monti, bresson, bronstein 2017

37/44

matrix completion with recurrent multi-graph id98

x(t+1) = x(t) + dx(t)

dx(t)

x

x(t)

mgid98

y(t)

id56

  

  

recurrent multigraph id98 (rmid98) architecture

(cid:107)x(t )

  ,  (cid:107)2gr

min
  ,  

for matrix completion
+ (cid:107)x(t )

  ,  (cid:107)2gc

+

  
2

(cid:107)        (x(t )

  ,       y)(cid:107)2

f

monti, bresson, bronstein 2017

38/44

matrix completion with recurrent multi-graph id98

w

h(t+1) = h(t) + dh(t)

h(cid:62)

h(t)

mgid98

u(t)

id56

dh(t)

column    lter

  c

  c

w(t+1) = w(t) + dw(t)

w(t)

mgid98

v(t)

row    lter

  r

id56

  r

dw(t)

separable recurrent multigraph id98 (srmid98) architecture

for matrix completion in factorized form
(cid:107)       (w(t )

+(cid:107)h(t )

+

(cid:107)2gc

  c,  c

  r,  r

(cid:107)w(t )

  r,  r

(cid:107)2gr

  
2

(h(t )

  c,  c

min

  r,  r,  r,  c

monti, bresson, bronstein 2017

)(cid:62)     y)(cid:107)2

f

39/44

incremental updates with id56

non-factorized (rmgid98)

factorized (srmgid98)

rmse=2.26

rmse=1.15

matrix completion results on a synthetic dataset.

t = 0

monti, bresson, bronstein 2017

40/44

incremental updates with id56

non-factorized (rmgid98)

factorized (srmgid98)

rmse=0.52

rmse=0.76

matrix completion results on a synthetic dataset.

t = 5

monti, bresson, bronstein 2017

40/44

incremental updates with id56

non-factorized (rmgid98)

factorized (srmgid98)

rmse=0.38

rmse=0.27

matrix completion results on a synthetic dataset.

t = 8

monti, bresson, bronstein 2017

40/44

incremental updates with id56

non-factorized (rmgid98)

factorized (srmgid98)

rmse=0.01

rmse=0.01

matrix completion results on a synthetic dataset.

t = 10

monti, bresson, bronstein 2017

40/44

matrix completion methods comparison

method
gmc1
grals2
srmgid983
rmgid983

mn

#params complexity rmse
0.3693
0.0114
0.0106
0.0053

m + n
m + n

m + n

mn

mn

1
1

comparison of geometric matrix completion methods on synthetic data

using both users and movies graphs

method
mgid983layers
mgid984layers
mgid985layers
mgid986layers
rmgid983

params

architecture

1mgc32, 32mgc10, 10mgc1

9k
1mgc32, 32mgc32    2, 32mgc1
53k
1mgc32, 32mgc32    3, 32mgc1
78k
104k 1mgc32, 32mgc32    4, 32mgc1
9k

1mgc32 + lstm

rmse
0.0116
0.0073
0.0074
0.0064
0.0053

reconstruction errors with multi-layer mgid98s and the proposed solution.
q(cid:48)mgcq denotes a multi-graph convolution with q(cid:48)/q input/output features.

methods: 1kalofolias et al. 2014; 2rao et al. 2015; 3monti, bresson, bronstein 2017;

41/44

matrix completion methods comparison

movielens1

method
imc5
gmc6
mc7
grals8
srmgid98 (cheby, r=4)9
srmgid98 (cheby, r=8)9
srmgid98 (cayley, r=4)10

1.653
0.996
0.973
0.945
0.929
0.925
0.922

flixster2

douban3 yahoo4

   
   
   

   
   
   

   
   
   

1.313/1.245
1.179/0.926

0.833
0.801

38.042
22.415

   
   

   
   

   
   

performance (rms error) on several datasets. for douban and yahoomusic, a

single graph (of users and items respectively) was used. for flixster, two

settings are shown: users+items graphs / only users graph.

data: 1miller et al. 2003; 2jamali, ester 2010; 3ma et al. 2011; 4dror et al. 2012
methods: 5jain, dhillon 2013; 6kalofolias et al. 2014; 7cand`es, recht 2012; 8rao et
al. 2015; 9monti, bresson, bronstein 2017; 10levie et al. 2017

42/44

conclusions

    we presented a new spectral approach with spectral zoom properties

(cayleynet).

    we introduced mgid98, the    rst multi-graph convolutional neural

network.

    we showed how coupling mgid98 with a id56 a learnable di   usion

process can be realized for reconstructing missing information.

    our geometric deep learning approach outperforms previous state

of the art solutions on the matrix completion problem.

geometricdeeplearning.com

43/44

thank you!

44/44

