   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]onfido tech
     * [9]machine learning
     * [10]front end
     * [11]mobile
     * [12]our team
     * [13]work with us
     __________________________________________________________________

higher-level apis in tensorflow

how to use estimator, experiment and dataset to train models

   [14]go to the profile of peter roelants
   [15]peter roelants (button) blockedunblock (button) followfollowing
   aug 30, 2017
   [1*ckg1ljvvtawqskysyvqtsq.png]

   [16]tensorflow has many libraries, like [17]keras, [18]tflearn, and
   [19]sonnet, which make it easier to train models rather than use
   lower-level functionality. while the keras api is being [20]implemented
   directly into tensorflow, tensorflow is providing some higher-level
   constructs itself, and some new ones were introduced in the latest 1.3
   version. ([21]click here for a post describing how the api   s changed in
   tensorflow 1.8)

   in this blog, we   ll look at an example using some of these new
   higher-level constructs, including [22]estimator, [23]experiment, and
   [24]dataset. it   s also worth noting that you can use experiment and
   dataset on their own. i   ll assume you know the basics of tensorflow; if
   not, tensorflow provides some great [25]tutorials.
   [1*zonzvvujb06yaghetc6bfq.png]
   overview of the experiment, estimator and dataset framework and how
   they interact. (these components will be explained in the following
   sections)

   we   ll be using [26]mnist as a dataset in this blog. it   s an easy-to-use
   dataset that is already accessible from tensorflow. you can find the
   full code example in [27]this gist. one benefit of using these
   frameworks is that we don   t have to deal with [28]graphs and
   [29]sessions directly.

estimator

   the [30]estimator class represents a model, as well as how this model
   should be trained and evaluated. we can create an estimator as follows:

   iframe: [31]/media/99d9795136cf7862e441ff43eda825e2?postid=67bfb602e6c0

   to create the estimator we need to pass in a model function, a
   collection of parameters and some configuration.
     * the parameters should be a collection of the model   s
       hyperparameters. this can be a dictionary, but we will represent it
       in this example as an [32]hparams object, which acts as a
       [33]namedtuple.
     * the configuration specifies how the training and evaluation are
       run, and where to store the results. this configuration will be
       represented by a [34]runconfig object, which communicates
       everything the estimator needs to know about the environment in
       which the model will be run.
     * the model function is a python function, which builds the model
       given the input. (more on this later)

model function

   the model function is a python function which is passed as a
   [35]first-class function to the estimator. we   ll see later that
   tensorflow uses first-class functions in other places. the benefit of
   representing the model as a function is that the model can be recreated
   over and over by instantiating the function. the model can be recreated
   during the training with different input, for example, to run
   validation tests during training.

   the model function takes the input features as parameters and the
   corresponding labels as tensors. it also takes a [36]mode that signals
   if the model is training, evaluating or performing id136. the last
   parameter to the model function should be a collection of
   hyperparameters, which are the same as those passed to the estimator.
   this model function should return an [37]estimatorspec object which
   will define the complete model.

   the estimatorspec takes in the prediction, loss, training and
   evaluation [38]operations so it defines the full model graph used for
   training, evaluation, and id136. because the estimatorspec just
   takes in regular tensorflow operations, we can use frameworks like
   [39]tf-slim to define our model.

experiment

   the [40]experiment class defines how to train a model and integrates
   nicely with the estimator. we can create an experiment as follows:

   iframe: [41]/media/0e9cc566bf0a1b1c760e02a9413bc501?postid=67bfb602e6c0

   the experiment takes as input:
     * an estimator (for example the one we defined above).
     * train and evaluation data as a [42]first-class function. the same
       concept as the model function explained earlier is used here. by
       passing in a function instead of operation, the input graph can be
       recreated if needed. we   ll talk more about this later.
     * [43]training and evaluating hooks. these hooks can be used to save
       or monitor specific things, or to set up certain operations in the
       graph or session. for example, we will be passing in operations to
       help initialize the data loaders (again, more later).
     * various parameters describing how long to train for and when to
       evaluate.

   once we have defined the experiment, we can run it to train and
   evaluate the model with [44]learn_runner.run as follows:

   iframe: [45]/media/9803954dfc66218d3fbf595bd38ab669?postid=67bfb602e6c0

   like the model function and the data functions, the learn runner takes
   in the function that creates the experiment as a parameter.

dataset

   we   ll be using the [46]dataset class and the corresponding [47]iterator
   to represent our training and evaluation data, and to create data
   feeders that iterate over the data during training. in this example, we
   will use the [48]mnist data that   s available in tensorflow, and build a
   dataset wrapper around it. for example, we will represent the training
   input data as:

   iframe: [49]/media/d358c0cfdddb405901750e836104fb5c?postid=67bfb602e6c0

   calling this get_train_inputs will return a [50]first-class function
   that creates the data loading operations in a tensorflow graph,
   together with a hook to initialize the iterator.

   the mnist data used in this example is initially represented as a
   [51]numpy array. we create a [52]placeholder tensor that gets the data
   fed in; we use a placeholder in order to avoid copying the data. next,
   we create a sliced dataset with the help of from_tensor_slices. we will
   make sure that this dataset runs for an infinite amount of epochs (the
   experiment can take care of limiting the number of epochs), and that
   the data gets shuffled and put into batches of the required size.

   to iterate over the data we need to create an iterator from the
   dataset. because we are using a placeholder we need to initialize the
   placeholder in the relevant session with the numpy data. we can do this
   by creating an [53]initializable iterator. we will create a custom
   defined iteratorinitializerhook object to initialize the iterator when
   the graph is created:

   iframe: [54]/media/94676d9e227fed5a00ca8c5ec178c6c8?postid=67bfb602e6c0

   the iteratorinitializerhook inherits from [55]sessionrunhook. this hook
   will call after_create_session as soon as the relevant session is
   created, and initialize the placeholder with the right data. this hook
   is returned by our get_train_inputs function and will be passed to the
   experiment object upon creation.

   the data loading operations returned by the train_inputs function are
   tensorflow [56]operations that will return a new batch every time they
   are evaluated.

running the code

   now that we have defined everything, we can run the code with the
   following command:
python mnist_estimator.py --model_dir ./mnist_training --data_dir ./mnist_data

   if you don   t pass in parameters, it will use the default [57]flags at
   the top of the file to figure out where to save the data and the model.

   the training will output information like the global step, loss, and
   accuracy over time on the terminal output. besides this, the experiment
   and estimator framework will log certain statistics to be visualized by
   [58]tensorboard. if we run:
tensorboard --logdir='./mnist_training'

   then we can see all training statistics like the training loss,
   evaluation accuracy, time per step, and the model graph.
   [1*asrked0btln7ruo1l9vpgg.png]
   evaluation accuracy visualised in tensorboard

   i   ve written this blog because i couldn   t find much information and
   examples on the tensorflow estimator experiment and dataset framework
   at the time i wrote the code example. i hope that this blog will give
   you a brief overview of how these frameworks work, what abstractions
   they tackle and how to use them.some notes and other documentation are
   below if you   re interested in using these frameworks.

notes on the estimator, experiment and dataset frameworks

     * there is a paper called [59]   tensorflow estimators: managing
       simplicity vs. flexibility in high-level machine learning
       frameworks    describing the high level-design of the estimator
       framework.
     * [60]tensorflow has more documentation on using the dataset api.
     * there are 2 versions of the estimator class. we are using the one
       at [61]tf.estimator.estimator in this example, but there is also an
       older unstable version at [62]tf.contrib.learn.estimator.
     * there are also 2 versions of the runconfig class. while we are
       using the one at [63]tf.contrib.learn.runconfig there is also a
       version at [64]tf.estimator.runconfig. i couldn   t get the latter
       one to work with the experiment framework so i stuck with the
       tf.contrib version.
     * while we didn   t use them in this example, the estimator framework
       defines predefined estimators for typical models such as
       [65]classifiers and [66]regressors. these predefined estimators are
       easy to use and come with a [67]detailed tutorial.
     * tensorflow also defines an abstraction for the    head    of a model,
       the part that sits on top of the architecture and defines the loss,
       evaluation and training operations. this head will take care of
       things like defining the model function, and all the required
       operations. you can find a version at [68]tf.contrib.learn.head.
       there is also a [69]prototype version in the newer estimator
       framework. we decided not to use it in this example due to its
       development being quite unstable.
     * this blog uses the tensorflow [70]slim framework to define the
       architecture of the model. slim is a lightweight library for
       defining complex models in tensorflow. they also define
       [71]pre-defined architectures and pre-trained models.

complete example

   iframe: [72]/media/552d38627453503060b24484223c4abb?postid=67bfb602e6c0

id136 on the trained model

   once we trained the model we can run estimator.predict to predict the
   class of a given image. the next code sample illustrates how to do
   this.

   iframe: [73]/media/8518f9c3153636cdccb92189fda62e98?postid=67bfb602e6c0

     * [74]tensorflow
     * [75]mnist
     * [76]deep learning
     * [77]machine learning
     * [78]python

   (button)
   (button)
   (button) 1.3k claps
   (button) (button) (button) 9 (button) (button)

     (button) blockedunblock (button) followfollowing
   [79]go to the profile of peter roelants

[80]peter roelants

   machine learning enthusiast

     (button) follow
   [81]onfido tech

[82]onfido tech

   stories from design, engineering, product and research at onfido

     * (button)
       (button) 1.3k
     * (button)
     *
     *

   [83]onfido tech
   never miss a story from onfido tech, when you sign up for medium.
   [84]learn more
   never miss a story from onfido tech
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/67bfb602e6c0
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://medium.com/onfido-tech/higher-level-apis-in-tensorflow-67bfb602e6c0&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://medium.com/onfido-tech/higher-level-apis-in-tensorflow-67bfb602e6c0&source=--------------------------nav_reg&operation=register
   8. https://medium.com/onfido-tech?source=logo-lo_drpibto9p9nl---93e4295ebb88
   9. https://medium.com/onfido-tech/machine-learning/home
  10. https://medium.com/onfido-tech/front-end/home
  11. https://medium.com/onfido-tech/mobile/home
  12. https://medium.com/onfido-tech/our-team/home
  13. https://goo.gl/2dbstt
  14. https://medium.com/@peter.roelants?source=post_header_lockup
  15. https://medium.com/@peter.roelants
  16. https://www.tensorflow.org/
  17. https://keras.io/
  18. https://github.com/tflearn/tflearn
  19. https://deepmind.github.io/sonnet/
  20. https://www.tensorflow.org/api_docs/python/tf/contrib/keras
  21. https://medium.com/@peter.roelants/tensorflow-estimator-dataset-apis-caeb71e6e196
  22. https://www.tensorflow.org/api_docs/python/tf/estimator/estimator
  23. https://www.tensorflow.org/api_docs/python/tf/contrib/learn/experiment
  24. https://www.tensorflow.org/api_docs/python/tf/contrib/data/dataset
  25. https://www.tensorflow.org/get_started/
  26. https://en.wikipedia.org/wiki/mnist_database
  27. https://gist.github.com/peterroelants/9956ec93a07ca4e9ba5bc415b014bcca
  28. https://www.tensorflow.org/api_docs/python/tf/graph
  29. https://www.tensorflow.org/api_docs/python/tf/session
  30. https://www.tensorflow.org/api_docs/python/tf/estimator/estimator
  31. https://medium.com/media/99d9795136cf7862e441ff43eda825e2?postid=67bfb602e6c0
  32. https://www.tensorflow.org/api_docs/python/tf/contrib/training/hparams
  33. https://docs.python.org/2/library/collections.html#collections.namedtuple
  34. https://www.tensorflow.org/api_docs/python/tf/contrib/learn/runconfig
  35. https://en.wikipedia.org/wiki/first-class_function
  36. https://www.tensorflow.org/api_docs/python/tf/contrib/learn/modekeys
  37. https://www.tensorflow.org/api_docs/python/tf/estimator/estimatorspec
  38. https://www.tensorflow.org/api_docs/python/tf/operation
  39. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim
  40. https://www.tensorflow.org/api_docs/python/tf/contrib/learn/experiment
  41. https://medium.com/media/0e9cc566bf0a1b1c760e02a9413bc501?postid=67bfb602e6c0
  42. https://en.wikipedia.org/wiki/first-class_function
  43. https://www.tensorflow.org/api_guides/python/train#training_hooks
  44. http://tf.contrib.learn.learn_runner.run/
  45. https://medium.com/media/9803954dfc66218d3fbf595bd38ab669?postid=67bfb602e6c0
  46. https://www.tensorflow.org/api_docs/python/tf/contrib/data/dataset
  47. https://www.tensorflow.org/api_docs/python/tf/contrib/data/iterator
  48. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist
  49. https://medium.com/media/d358c0cfdddb405901750e836104fb5c?postid=67bfb602e6c0
  50. https://en.wikipedia.org/wiki/first-class_function
  51. https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html
  52. https://www.tensorflow.org/api_docs/python/tf/placeholder
  53. https://www.tensorflow.org/api_docs/python/tf/contrib/data/dataset#make_initializable_iterator
  54. https://medium.com/media/94676d9e227fed5a00ca8c5ec178c6c8?postid=67bfb602e6c0
  55. https://www.tensorflow.org/api_docs/python/tf/train/sessionrunhook
  56. https://www.tensorflow.org/api_docs/python/tf/operation
  57. https://www.tensorflow.org/api_docs/python/tf/flags
  58. https://github.com/tensorflow/tensorboard
  59. https://terrytangyuan.github.io/data/papers/tf-estimators-kdd-paper.pdf
  60. https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets
  61. https://www.tensorflow.org/api_docs/python/tf/estimator/estimator
  62. https://www.tensorflow.org/api_docs/python/tf/contrib/learn/estimator
  63. https://www.tensorflow.org/api_docs/python/tf/contrib/learn/runconfig
  64. https://www.tensorflow.org/api_docs/python/tf/estimator/runconfig
  65. https://www.tensorflow.org/api_docs/python/tf/estimator/dnnclassifier
  66. https://www.tensorflow.org/api_docs/python/tf/estimator/dnnregressor
  67. https://www.tensorflow.org/extend/estimators
  68. https://www.tensorflow.org/api_docs/python/tf/contrib/learn/head
  69. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/canned/head.py
  70. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim
  71. https://github.com/tensorflow/models/tree/master/slim
  72. https://medium.com/media/552d38627453503060b24484223c4abb?postid=67bfb602e6c0
  73. https://medium.com/media/8518f9c3153636cdccb92189fda62e98?postid=67bfb602e6c0
  74. https://medium.com/tag/tensorflow?source=post
  75. https://medium.com/tag/mnist?source=post
  76. https://medium.com/tag/deep-learning?source=post
  77. https://medium.com/tag/machine-learning?source=post
  78. https://medium.com/tag/python?source=post
  79. https://medium.com/@peter.roelants?source=footer_card
  80. https://medium.com/@peter.roelants
  81. https://medium.com/onfido-tech?source=footer_card
  82. https://medium.com/onfido-tech?source=footer_card
  83. https://medium.com/onfido-tech
  84. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  86. https://medium.com/p/67bfb602e6c0/share/twitter
  87. https://medium.com/p/67bfb602e6c0/share/facebook
  88. https://medium.com/p/67bfb602e6c0/share/twitter
  89. https://medium.com/p/67bfb602e6c0/share/facebook
