institut
des algorithmes
d   apprentissage
de montr  al

alexei nordell-markovits
alexei@elementai.com

pedro oliveira pinheiro
pedro@elementai.com

introduction aux r  seaux 

convolutionnels (suite)

objectifs de la pr  sentation

o id163 et r  seaux modernes

o intuition de plusieurs architecture plus r  centes

o divers

source : kaiming he

id163

o plus de 10 millions d   images

o 3 millions d   images pour la v1 ( 2009 )

o organis  es via la hi  rarchie id138

o 2 ans (?!?)

o google + mechanical turk

o google pour trouver les images

o mechanical turk pour valider la classification

source : http://www.image-
net.org/papers/id163_cvpr09.pdf

id163 - ilsvrc

o comp  tition annuelle

o m  triques multiples

o classification task

o 1000 cat  gories

o top-5 pour chaque image

o pourcentage de succ  s

source : http://www.image-net.org/challenges/lsvrc/2015/

id163

2012 - alexnet - 16.4% 

o 8 couches 

o 5 convolutionel

o 3 connect  

source : alexnet paper

2012 - alexnet - 16.4% 

o relu

o dropout

source : adit deshpande

2012 - alexnet - 16.4% 

o 2 gtx 560 (3gb) / 1 semaine

o sch  ma d   entrainement

o 60 million param  tres

source : alexnet paper

2013 - clarifai/zg - 11.7% 

o similaire    alexnet

o    plumbing   

source : https://arxiv.org/abs/1311.2901v3

source : https://arxiv.org/abs/1311.2901v3

2013 - clarifai/zg - 11.7% 

o visualisation du mod  le
o

permis de modifier l   architecture

o g  n  ralisation du mod  le
o

caltech-101 & caltech-256

source : https://arxiv.org/abs/1311.2901v3

2014 - vgg  (2e)

o architecture simple

o compos  e de convolutions 3x3
o 5 couches de max pooling
o 3 connect  s
o couche 1x1
o 16 couches total (ou 19)

o disponible dans caffe zoo

source : https://arxiv.org/abs/1409.1556

2014 - vgg  (2e)

source : what is vgg - quora post

2014 - vgg  (2e)

o la profondeur est importante!

o pas besoin d     tre complexe pour bien 

fonctionner

o disponible dans caffe zoo

o    receptive field    beaucoup plus petit que 

les mod  les pr  c  cents

source : https://arxiv.org/abs/1409.1556

2014 - vgg  (2e)

o forte influence, malgr   la simplicit  

o encore retrouv   dans un nombre

d   application sous plusieurs variations

o simple    utiliser, entrainer, etc

o 2   3 semaines sur 4 gpu

source : https://arxiv.org/abs/1409.1556

2014 - inception - 7.3%

o les r  seaux convolutionnels ne sont pas si effrayants

o sauf inception

source : https://arxiv.org/pdf/1409.4842.pdf

2014 - inception - 7.3% 

2014 - inception

o intuition

o repr  sentation locale
o r  duction de 

dimensions

source : https://arxiv.org/abs/1409.4842

2014 - inception - 7.3%

o aussi : petit nombre de param  tres

o 2-3 gpu     1 semaine
o relativement rapide    entra  ner
o aussi    executer 

2015 - resnet - 3.57%

o meilleur qu'un humain!

o quelques b  mols

o est-ce que plus de couche

est la solution?

2015 - resnet - 3.57%

o trop de couches est nuisible

2015 - resnet - module r  siduel

o https://github.com/facebook/fb.resnet.torch

source: http://torch.ch/blog/2016/02/04/resnets.html

2015 - resnet - 3.57%

o l   intuition?

o quand m  me complexe
o fonctionne comme des 
m  thodes    ensembles?

o propager l   identit   semble

utile

source: residual networks behave like ensembles...

2016 - cuimage

source : https://arxiv.org/pdf/1610.02579.pdf

2017 - c   est la fin!

architecture bonus        densenet   

source: densenet paper

architecture bonus        densenet   

source: densenet paper

architecture bonus        two stream   

source: two stream paper

vous pensez faire mieux qu   un id98?

http://cs.stanford.edu/people/karpathy/ilsvrc/

apprentissage par transfert

un chat c   est un chat 

apprentissage par transfert

o entra  ner un id98 est long
o jours, parfois semaines

o beaucoup de caract  ristiques sont partag  es

o pourquoi ne pas couper la couche de   d  cisions   et utiliser la n  tre

o deux sc  narios:

o utiliser un r  seau convolutionnel comme outil pour d  finir les caract  ristiques
o re-entra  ner le r  seau en partant des poids initiaux

o voir : https://github.com/pkmital/cadl/tree/master/session-4/libs

apprentissage par transfert

o inception v3

o utilis   dans quelques projets    l   interne

o comme feature extractor avec des arbres de d  cisions

o avec une phase d'entra  nement suppl  mentaire connect  e    une

couche compl  te

o voir : https://www.tensorflow.org/tutorials/image_retraining
o aussi : https://research.googleblog.com/2016/03/train-your-own-image-

classifier-with.html

divers - 1 x 1 convolution

o l   intuition est difficile

o r  duire la dimensionnalit  

o poids uniques

o donc transformation lin  aire

o suivi de relu

in convolutional nets, there is no such thing 
as    fully-connected layers   . there are only 
convolution layers with 1x1 convolution 
kernels and a full connection table.     yann 
lecun

divers     augmentation des donn  es

o plus de donn  es = succ  s

o bruits
o coupes
o rotations
o translations
o etc

source  : https://www.quora.com/is-a-convolution-neural-network-
immune-to-image-resolutions-if-so-what-makes-this-possible

divers

o dropout

o fonctionne   galement pour les 

r  seaux convolutionnels

o tensorflow without a phd

o ensemble methods

o pourquoi voter une fois?  

divers - deconvnet

source : http://arxiv.org/abs/1311.2901

divers - deconvnet

https://www.youtube.com/watch?v=agkfiq4igam

divers - segmentation

blog #1

blog #2

architecture bonus        u-net   

source: segmentation for bio-medical...

divers - ocr

encore un blog

divers - d  tection

source : detection tutorial for caffe

source : deep convolutional neural network design patterns

divers  - conseils d   architecture et autre

o aucun
o http://cs231n.github.io/convolutional-networks/

ressources

o what makes a good selfie?

o id98 for text classification - mxnet

o id98 for translation     torch

o deep visual .... generating image 

descriptions

o advanced id98 architecture

questions

institut
des algorithmes
d   apprentissage
de montr  al

institut
des algorithmes
d   apprentissage
de montr  al

