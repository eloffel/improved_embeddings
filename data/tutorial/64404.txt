deep	learning,	language,	and	cognition

christopher	manning
stanford	university

@chrmanning	    @stanfordnlp	

nsf

plan
1. what	is	deep	learning?
2.
3. using	word	vectors	for	linguistic	semantics
4. compositional	language:	beyond	word	vectors
5. relation	to	linguistic	and	cognitive	science

introducing	distributed	word	vectors

1. what is deep learning?

deep	learning	is	a	subfield	of	machine	learning

most	machine	learning	methods	work	
well	because	of	carefully	human-designed	
representations	and	input	features

    for	example:	features	for	finding	
named	entities	like	locations	or	
organizations	(finkel et	al.,	2010)

machine	learning	becomes	just	optimizing
weights	to	best	make	a	final	prediction

previous	word
current	word
beginning	bigram
prev and	cur	tags
previous	state
current	signature
prev	state,	cur	sig
prev-cur-next	sig
p.	state	- p-cur	sig
   

at

grace
<g

in	nnp
other

xx
o-xx
x-xx-xx
o-x-xx

what is deep learning?
    representation	learning	attempts	

to	automatically	learn	the	good	
features	or	representations

    deep	learning	algorithms	attempt	to	

learn	multiple	levels	of
representation	h and	an	output

    from	   raw   	inputs	x	

(e.g.,	sound,	characters,	or	words)

what is deep learning?
three	senses	of	   deep	learning   :
#1 learning	a	data-dependent	hierarchy	of	multiple	
#2 use	of	distributed	representations	and	neural	net	learning	
#3 anything	to	do	with	artificial	intelligence

intermediate	levels	of	representation	of	increasing	abstraction

methods,	even	when	the	architecture	isn   t	technically	deep

   deep	learning	is	the	idea	that	machines	could	eventually	learn	by	
themselves	to	perform	functions	like	speech	recognition   			
http://readwrite.com/2014/01/29/

words

deep learning for speech

the	first	breakthrough	results	of	
   deep	learning   	on	large	datasets	
happened	in	speech	recognition

    context-dependent	pre-trained	deep	
neural	networks	for	large	vocabulary	
speech	recognition	(dahl	et	al.	2010)

acoustic	model

recog
wer
1-pass	
traditional	
gmm	features
   adapt
deep	learning 1-pass	
   adapt

rt03s	
fsh
27.4

hub5	
swb
23.6

18.5
(   33%)

16.1
(   32%)

(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:85)(cid:69)(cid:76)(cid:87)(cid:85)(cid:68)(cid:85)(cid:92)(cid:3)(cid:81)(cid:72)(cid:88)(cid:85)(cid:82)(cid:81)(cid:86)(cid:3)(cid:68)(cid:79)(cid:82)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:90)(cid:68)(cid:92)(cid:3)(cid:87)(cid:82)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:82)(cid:83)(cid:17)(cid:17)(cid:17)

deep learning for id161
the breakthrough	dl	paper:	
id163	classification	with	
deep	convolutional	neural	
networks	by	krizhevsky,	
sutskever,	&	hinton,	2012,	u.	
toronto.	37%	error	red.

(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:56)(cid:81)(cid:71)(cid:72)(cid:85)(cid:86)(cid:87)(cid:68)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:38)(cid:82)(cid:81)(cid:89)(cid:82)(cid:79)(cid:88)(cid:87)(cid:76)(cid:82)(cid:81)(cid:68)(cid:79)(cid:3)(cid:49)(cid:72)(cid:87)(cid:90)(cid:82)(cid:85)(cid:78)(cid:86)
(cid:61)(cid:72)(cid:76)(cid:79)(cid:72)(cid:85)(cid:3)(cid:9)(cid:3)(cid:41)(cid:72)(cid:85)(cid:74)(cid:88)(cid:86)(cid:15)(cid:3)(cid:21)(cid:19)(cid:20)(cid:22)
(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:85)(cid:69)(cid:76)(cid:87)(cid:85)(cid:68)(cid:85)(cid:92)(cid:3)(cid:81)(cid:72)(cid:88)(cid:85)(cid:82)(cid:81)(cid:86)(cid:3)(cid:68)(cid:79)(cid:82)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:90)(cid:68)(cid:92)(cid:3)(cid:87)(cid:82)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:82)(cid:83)(cid:17)(cid:17)(cid:17)

(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:56)(cid:81)(cid:71)(cid:72)(cid:85)(cid:86)(cid:87)(cid:68)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:38)(cid:82)(cid:81)(cid:89)(cid:82)(cid:79)(cid:88)(cid:87)(cid:76)(cid:82)(cid:81)(cid:68)(cid:79)(cid:3)(cid:49)(cid:72)(cid:87)(cid:90)(cid:82)(cid:85)(cid:78)(cid:86)
(cid:61)(cid:72)(cid:76)(cid:79)(cid:72)(cid:85)(cid:3)(cid:9)(cid:3)(cid:41)(cid:72)(cid:85)(cid:74)(cid:88)(cid:86)(cid:15)(cid:3)(cid:21)(cid:19)(cid:20)(cid:22)
(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:85)(cid:69)(cid:76)(cid:87)(cid:85)(cid:68)(cid:85)(cid:92)(cid:3)(cid:81)(cid:72)(cid:88)(cid:85)(cid:82)(cid:81)(cid:86)(cid:3)(cid:68)(cid:79)(cid:82)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:90)(cid:68)(cid:92)(cid:3)(cid:87)(cid:82)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:82)(cid:83)(cid:17)(cid:17)(cid:17)

(cid:41)(cid:72)(cid:76)(cid:16)(cid:41)(cid:72)(cid:76)(cid:3)(cid:47)(cid:76)(cid:3)(cid:9)(cid:3)(cid:36)(cid:81)(cid:71)(cid:85)(cid:72)(cid:77)(cid:3)(cid:46)(cid:68)(cid:85)(cid:83)(cid:68)(cid:87)(cid:75)(cid:92)
(cid:41)(cid:72)(cid:76)(cid:16)(cid:41)(cid:72)(cid:76)(cid:3)(cid:47)(cid:76)(cid:3)(cid:9)(cid:3)(cid:36)(cid:81)(cid:71)(cid:85)(cid:72)(cid:77)(cid:3)(cid:46)(cid:68)(cid:85)(cid:83)(cid:68)(cid:87)(cid:75)(cid:92)

olga russakovsky* et al.

(cid:22)(cid:20)

(cid:47)(cid:72)(cid:70)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:27)(cid:3)(cid:16)
(cid:47)(cid:72)(cid:70)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:27)(cid:3)(cid:16)

(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:56)(cid:81)(cid:71)(cid:72)(cid:85)(cid:86)(cid:87)(cid:68)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:38)(cid:82)(cid:81)(cid:89)(cid:82)(cid:79)(cid:88)(cid:87)(cid:76)(cid:82)(cid:81)(cid:68)(cid:79)(cid:3)(cid:49)(cid:72)(cid:87)(cid:90)(cid:82)(cid:85)(cid:78)(cid:86)
(cid:61)(cid:72)(cid:76)(cid:79)(cid:72)(cid:85)(cid:3)(cid:9)(cid:3)(cid:41)(cid:72)(cid:85)(cid:74)(cid:88)(cid:86)(cid:15)(cid:3)(cid:21)(cid:19)(cid:20)(cid:22)
(cid:21)(cid:3)(cid:41)(cid:72)(cid:69)(cid:3)(cid:21)(cid:19)(cid:20)(cid:24)
(cid:21)(cid:3)(cid:41)(cid:72)(cid:69)(cid:3)(cid:21)(cid:19)(cid:20)(cid:24)
(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:85)(cid:69)(cid:76)(cid:87)(cid:85)(cid:68)(cid:85)(cid:92)(cid:3)(cid:81)(cid:72)(cid:88)(cid:85)(cid:82)(cid:81)(cid:86)(cid:3)(cid:68)(cid:79)(cid:82)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:90)(cid:68)(cid:92)(cid:3)(cid:87)(cid:82)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:82)(cid:83)(cid:17)(cid:17)(cid:17)

ilsvrc

(cid:55)(cid:75)(cid:72)(cid:3)(cid:90)(cid:72)(cid:76)(cid:74)(cid:75)(cid:87)(cid:86)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:76)(cid:86)(cid:3)(cid:81)(cid:72)(cid:88)(cid:85)(cid:82)(cid:81)(cid:3)(cid:89)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:72)(cid:71)

(cid:41)(cid:72)(cid:76)(cid:16)(cid:41)(cid:72)(cid:76)(cid:3)(cid:47)(cid:76)(cid:3)(cid:9)(cid:3)(cid:36)(cid:81)(cid:71)(cid:85)(cid:72)(cid:77)(cid:3)(cid:46)(cid:68)(cid:85)(cid:83)(cid:68)(cid:87)(cid:75)(cid:92)
(cid:41)(cid:72)(cid:76)(cid:16)(cid:41)(cid:72)(cid:76)(cid:3)(cid:47)(cid:76)(cid:3)(cid:9)(cid:3)(cid:36)(cid:81)(cid:71)(cid:85)(cid:72)(cid:77)(cid:3)(cid:46)(cid:68)(cid:85)(cid:83)(cid:68)(cid:87)(cid:75)(cid:92)

(cid:47)(cid:72)(cid:70)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:27)(cid:3)(cid:16)
(cid:47)(cid:72)(cid:70)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:27)(cid:3)(cid:16)

(cid:22)(cid:19)

(cid:21)(cid:3)(cid:41)(cid:72)(cid:69)(cid:3)(cid:21)(cid:19)(cid:20)(cid:24)
(cid:21)(cid:3)(cid:41)(cid:72)(cid:69)(cid:3)(cid:21)(cid:19)(cid:20)(cid:24)

      

(cid:41)(cid:72)(cid:76)(cid:16)(cid:41)(cid:72)(cid:76)(cid:3)(cid:47)(cid:76)(cid:3)(cid:9)(cid:3)(cid:36)(cid:81)(cid:71)(cid:85)(cid:72)(cid:77)(cid:3)(cid:46)(cid:68)(cid:85)(cid:83)(cid:68)(cid:87)(cid:75)(cid:92)
(cid:41)(cid:72)(cid:76)(cid:16)(cid:41)(cid:72)(cid:76)(cid:3)(cid:47)(cid:76)(cid:3)(cid:9)(cid:3)(cid:36)(cid:81)(cid:71)(cid:85)(cid:72)(cid:77)(cid:3)(cid:46)(cid:68)(cid:85)(cid:83)(cid:68)(cid:87)(cid:75)(cid:92)

(cid:22)(cid:19)
(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:56)(cid:81)(cid:71)(cid:72)(cid:85)(cid:86)(cid:87)(cid:68)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:38)(cid:82)(cid:81)(cid:89)(cid:82)(cid:79)(cid:88)(cid:87)(cid:76)(cid:82)(cid:81)(cid:68)(cid:79)(cid:3)(cid:49)(cid:72)(cid:87)(cid:90)(cid:82)(cid:85)(cid:78)(cid:86)
(cid:61)(cid:72)(cid:76)(cid:79)(cid:72)(cid:85)(cid:3)(cid:9)(cid:3)(cid:41)(cid:72)(cid:85)(cid:74)(cid:88)(cid:86)(cid:15)(cid:3)(cid:21)(cid:19)(cid:20)(cid:22)
(cid:57)(cid:76)(cid:86)(cid:88)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:85)(cid:69)(cid:76)(cid:87)(cid:85)(cid:68)(cid:85)(cid:92)(cid:3)(cid:81)(cid:72)(cid:88)(cid:85)(cid:82)(cid:81)(cid:86)(cid:3)(cid:68)(cid:79)(cid:82)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:90)(cid:68)(cid:92)(cid:3)(cid:87)(cid:82)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:82)(cid:83)(cid:17)(cid:17)(cid:17)

(cid:47)(cid:72)(cid:70)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:27)(cid:3)(cid:16)
(cid:47)(cid:72)(cid:70)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:27)(cid:3)(cid:16)

(cid:21)(cid:3)(cid:41)(cid:72)(cid:69)(cid:3)(cid:21)(cid:19)(cid:20)(cid:24)
(cid:21)(cid:3)(cid:41)(cid:72)(cid:69)(cid:3)(cid:21)(cid:19)(cid:20)(cid:24)

7

      

zeiler and	fergus	(2013)

why successful now?

despite	prior	investigation	and	understanding	of	many	of	the	
algorithmic	techniques	before	2006,	training	deep	architectures	
was	unsuccessful	l
what	changed?

    new	methods	for	unsupervised	pre-training	
    better	initialization,	id173,	and	estimation	methods
    better	methods	for	information	flow	in	deep	pathways
    much	more	data
    much	faster	computers	(incl.	gpus)    

what   s special about human language?

a	human	language	is	a	system	specifically	constructed	to	convey	the	
speaker/writer   s	meaning

    not	just	an	environmental	signal,	it   s	a	deliberate	communication
    using	an	encoding	which	little	kids	can	(amazingly!)	quickly	learn	
a	human	language	is	a	discrete/symbolic/categorical	signaling	system

   rocket   	=	    ;	   violin   	=	    

   
    with	very	minor	exceptions	for	expressive	signaling

(   i	loooove it.   	   whoompaaa   )

    presumably	because	of	greater	signaling	reliability
    symbols	are	not	just	an	invention	of	logic	/	classical	ai!

what   s special about human language?

the	categorical	symbols	of	a	language	can	be	encoded	as	a	
continuous signal	for	communication	in	several	ways:

    sound
    gesture
   

images	(writing)

the	symbol	is	invariant	across	different	encodings!

cc	by	2.0	david	fulmer	2008

national	library	of	nz,	no	known	restrictions

what   s special about human language?
    traditionally,	linguists,	philosophers,	ai	people,	and	others	have	

extended	the	symbolic	system	of	language	into	the	brain:	
   the	language	of	thought   

    however,	a	brain	encoding	appears	to	be	a	continuous	pattern	

of	activation,	just	like	the	signal	used	to	transmit	language	
    deep	learning	is	exploring	a	continuous	encoding	of	thought
    cogsci question: whether	to	assume	symbolic	representations	
in	the	brain	or	to	model	using	the	continuous	neural	substrate

lab

sec. 9.2.2

2. from symbolic to distributed word 
representations
the	vast	majority	of	rule-based	and	statistical	natural	
language	processing	or	information	retrieval	(nlp/ir)	work	
regarded	words	as	atomic	symbols:	hotel, conference
in	machine	learning	vector	space	terms,	this	is	a	vector	with	
one	1	and	a	lot	of	zeroes

[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]

we	now	call	this	a	   one-hot   	representation
it	is	a	localist representation

from symbolic to distributed word 
representations

sec. 9.2.2

its	problem,	e.g.,	for	web	search:

    if	user	searches	for	[dell	notebook	battery	size],	we	would	
like	to	match	documents	with	   dell	laptop	battery	capacity   
    if	user	searches	for	[seattle	motel],	we	would	like	to	match	
documents	containing	   seattle	hotel   

butmotel [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]t

hotel  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0] = 0
our	query	and	document	vectors	are	orthogonal
there	is	no	natural	notion	of	similarity	in	a	set	of	one-hot	vectors

capturing similarity
there	are	many	things	you	can	do	to	capture	similarity:

query	expansion	with	synonym	dictionaries
separately	learning	word	similarities	from	large	corpora

but	a	word	representation	that	encodes	similarity	wins:

less	parameters	to	learn	(per	word,	not	per	pair)
more	sharing	of	statistics
more	opportunities	for	multi-task	learning

distributional similarity-based 
representations
you	can	get	a	lot	of	value	by	representing	a	word	by	
means	of	its	neighbors
   you	shall	know	a	word	by	the	company	it	keeps   

(j.	r.	firth	1957:	11)

one	of	the	most	successful	ideas	of	modern	nlp

government debt problems turning into banking crises as has happened in

saying that europe needs unified banking regulation to replace the hodgepodge

   these	words	will	represent	banking	  

word meaning as a vector

we	build	a	dense	vector	for	each	word	type,	chosen	so	that	it	is	
good	at	predicting	other	words	appearing	in	its	context
    those	other	words	also	being	represented	by	vectors

currency =

0.286
0.792
   0.177
   0.107
0.109
   0.542
0.349
0.271

basic idea of learning neural 
network id27s (predict!)

we	define	a	model	that	aims	to	predict	between	a	center	
word	wt and	context	words	in	terms	of	word	vectors

p(context|wt)	=	   

which	has	a	loss	function,	e.g.,

j =	1	   	p(w   t	|wt)	

we	look	at	many	positions	t	in	a	big	language	corpus
we	keep	adjusting	the	vector	representations	of	words	
to	minimize	this	loss

sec. 18.3

latent semantic analysis (lsa) vs. 
   neural    models
comparisons	to	older	work:	lsa	count!	models
    factorize	a	(maybe	weighted,	often	log-scaled)	term-

document	(deerwester et	al.	1990)	or	word-context	matrix	
(sch  tze	1992)	into	u  vt

    retain	only	k	singular	values,	in	order	to	generalize

k

[cf.	baroni:	don   t	count,	predict!	a	systematic	comparison	of	context-
counting	vs.	context-predicting	semantic	vectors.	acl	2014]

svd: intuition of 
id84

6
6

5
5

4
4

3
3

2
2

1
1

pca dimension 1

pca dimension 2

1
1

2
2

3
3

4
4

5
5

6
6

id97 encodes semantic components 
as linear vector differences

coals model (count-modified lsa)
[rohde, gonnerman & plaut, ms., 2005]

count based vs. direct prediction

lsa, hal (lund & burgess), 
coals (rohde et al), 
hellinger-pca (lebret & collobert)

    fast training
    efficient usage of statistics
    primarily used to capture 
word similarity
    may not use the best 
methods for scaling counts

    nnlm, hlbl, id56, id97 
skip-gram/cbow, (bengio et al; 
collobert & weston; huang et al; mnih & 
hinton; mikolov et al; mnih & kavukcuoglu)

    scales with corpus size
    inefficient usage of statistics
    generate improved performance 
on other tasks
    can capture complex patterns 
beyond word similarity 

encoding meaning in vector differences
[pennington, socher, and manning, emnlp 2014]
crucial	insight:	
ratios	of	co-occurrence	probabilities	can	encode	
meaning	components

x =	solid

x =	gas

x =	water			

x =	random			

large

small

small

large

large

large

large

small

~1

small

small

~1

encoding meaning in vector differences
[pennington, socher, and manning, emnlp 2014]
crucial	insight:	
ratios	of	co-occurrence	probabilities	can	encode	
meaning	components

x =	solid

x =	gas

x =	water			

x =	fashion

1.9	x	10-4

6.6	x	10-5

3.0	x	10-3

1.7	x	10-5

2.2	x	10-5

7.8	x	10-4

2.2	x	10-3

1.8	x	10-5

8.9

8.5	x	10-2

1.36

0.96

encoding meaning in vector differences

q:	how	can	we	capture	ratios	of	co-occurrence	probabilities	as	
meaning	components	in	a	word	vector	space?

a:	log-bilinear	model:

with	vector	differences

glove word similarities
[pennington et al., emnlp 2014]

nearest	words	to frog:

1.	frogs
2.	toad
3.	litoria
4.	leptodactylidae
5.	rana
6.	lizard
7.	eleutherodactylus

litoria

leptodactylidae

http://nlp.stanford.edu/projects/glove/

rana

eleutherodactylus

glove visualizations

http://nlp.stanford.edu/projects/glove/

glove visualizations: company - ceo

id39 performance
(finding person, organization names in text)

model	on	conll conll    03	dev conll    03	test ace	2 muc	7
73.4
categorical	crf
71.5
svd	(log	tf)
80.7
hpca
c&w
80.2
81.1
cbow
82.2
glove

85.4 77.4
84.8 73.6
88.7 81.7
87.4 81.7
88.2 82.2
88.3 82.9

91.0
90.5
92.6
92.2
93.1
93.2

f1	score	of	crf	trained	on	conll	2003	english	with	50	dim	word	vectors

id27s: conclusion

glove	translates	meaningful	relationships	between	word-word	
co-occurrence	counts into linear	relations in	the	word	vector	space

glove	shows	the	connection	between	count! work	and	predict!
work	    appropriate	scaling	of	counts	gives	the	properties	and	
performance	of	predict! models

a	lot	of	other	important	recent	work	in	this	line	of	research:

[levy	&	goldberg,	2014]	
[arora,	li,	liang,	ma	&	risteski,	2015]
[hashimoto,	alvarez-melis &	jaakkola,	2016]

3. diachronic word 
embeddings
issue:	you	can	see	changes	in	word	form	but	not	meaning

word vectors for 1920

word vectors 1990

   dog    1990 word vector

   dog    1920 word vector

1900

vs.

1950

2000

experimental set-up

    examine	semantic	change	in	4	languages	across	~150	

years.	

    english,	french,	german,	and	chinese	(google	books)
    english	(corpus	of	historical	american	english)

    build	separate	embeddings	for	each	year/language
    measure	change	across	decades.	

michel,	jean-baptiste,	et	al.	"quantitative	analysis	of	culture	using	millions	of	digitized	books."	science	331.6014	(2011)

davies,	mark.	"the	corpus	of	historical	american	english:	400	million	words,	1810-2009."	(2010)

sanity check

do the embeddings capture semantic change?

2d visualizations of semantic change using sgns embeddings and id167. 

role of frequency in change?
    frequent	words	change	faster	

    lenition	(phonetic	reduction)	happens	in	
frequent	words

    frequent	words	change	slower

    high	frequency	words	are	more	resistant	to	
morphological	id173

    bybee,	2007;	pagel et	al.,	2007;	etc.)

    verb	id173	follows	an	inverse	square	law
half-life	of	irregular	verb
frequency	of	its	usage
(lieberman et al, 2007)

role of polysemy/homonymy in 
change

    the	number	of	senses	a	word	has

    bank	(1)	sloping	land	(2)	financial	institution

    words	gain	senses	as	they	drift	(br  al,	1897;	wilkins,	
1993;	hopper	and	traugott,	2003)	
    polysemous words	occur	in	more	diverse	contexts,	
affecting	lexical	access	speed	(adelman	et	al.,	2006)	and	
rates	of	l2	learning	(crossley	et	al.,	2010).	
    but	does	that	make	them	faster	or	slower	to	
change?

why do some words change 
faster than others?
    measure	rate	of	semantic	change	across	decades
    5000	words	per	language
    mixed-effect	analysis
    fixed-effects	for	

    frequency,	
    polysemy	score,	
    decade

    random	intercept	per	word

statistical laws of semantic 
change

results across languages and datasets 

effect of frequency
(consistently negative)

effect of polysemy
(consistently positive)

implications for historical 
linguistics
    frequency	+	polysemy	

    explains	>40%	of	the	variance in	rates	of	semantic	
change.	

    consistent	with	simple	bayesian	models	of	

learning.	
    (reali and	griffiths,	2010)
    higher	frequency	->	better	learning	->	less	   drift   

    frequency	may	also	explain	polysemy

    more	polysemous words	have	more	rare	senses	
(kilgarriff 2004)

meaning change of sentiment words

examples of sentiment change

emnlp 2016 submission ***. con   dential review copy. do not distribute.

emnlp 2016 submission ***. con   dential review copy. do not distribute.

(a) lean becomes more positive. lean underwent amelioration,
becoming more similar to muscular and less similar to weak.

(a) lean becomes more positive. lean underwent amelioration,
becoming more similar to muscular and less similar to weak.

(b) pathetic becomes more negative. pathetic underwent pejora-
tion, becoming similar to weak and less similar to passionate.

(b) pathetic becomes more negative. pathetic underwent pejora-
tion, becoming similar to weak and less similar to passionate.

lean
figure 5: examples of amelioration and pejoration.

pathetic	
figure 5: examples of amelioration and pejoration.

gets	more	positive

gets	more	negative

a full modern sentiment lexicon as their seed set,
which problematically assumes that all these words
have not changed in sentiment. in contrast, we use a
small seed set of words that were manually selected
based upon having strong and stable sentiment over
the last 150 years (table 1; con   rmed via historical

a full modern sentiment lexicon as their seed set,
which problematically assumes that all these words
have not changed in sentiment. in contrast, we use a
small seed set of words that were manually selected
based upon having strong and stable sentiment over

computed using our learned historical word vectors
were used to contextualize the shifts.

computed using our learned historical word vectors
were used to contextualize the shifts.

some other well-known examples of sentiment
changes captured by our framework include the se-
mantic bleaching of sorry, which shifted from nega-
tive and serious (   he was in a sorry state   ) to uses

some other well-known examples of sentiment
changes captured by our framework include the se-
mantic bleaching of sorry, which shifted from nega-

4. compositionality

(artificial) intelligence requires being 
able to understand bigger things from 

knowing about smaller parts

id33 for finding 
sentence structure

neural	networks	can	accurately	determine	a	structure	
for	sentences,	supporting	interpretation

chen	and	manning	(2014)	was	the	first	simple,	
successful	neural	dependency	parser

dense,	distributed	representations	let	it	outperform	
other	greedy	parsers	in	both	accuracy	and	speed

5. why train a neural dependency 
parser? one-hot features revisited

    problem	#1:		sparse
    problem	#2:		incomplete
    problem	#3:		expensive	computation

dense
dim = ~1000

0.1

0.9 -0.2 0.3

   

-0.1 -0.5

more	than	95%	of	parsing	time	is	consumed	by	
feature	computation.

our	approach:
learn	a	dense	and	compact	feature	representation

a neural dependency parser
[chen and manning 2014]
    english	parsing	to	stanford	dependencies:

    unlabeled	attachment	score	(uas)	=	head
    labeled	attachment	score	(las)	=	head	and	label

parser

maltparser
mstparser
turboparser
c &	m	2014

uas
89.8
91.4
92.3
92.0

las
87.2
88.1
89.6
89.7

sent.	/	s

469
10
8
654

model architecture

softmax	probabilities of	actions

output layer y
y = softmax(uh + b2)

hidden layer h
h = relu(wx + b1)

input layer x
lookup	+	concat

cross-id178 error will be
back-propagated to the 
embeddings.

further developments in neural 
id33

this	work	was	developed	by	others,	including	at	google

    bigger,	deeper	networks	with	better	tuned	hyperparameters
    beam	search
    global,	conditional	random	field	(crf)-style	id136
leading	to	syntaxnet and	the	parsey mcparseface model
https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html

method
chen	&	manning	2014
weiss et	al.	2015
andor et	al.	2016
dozat &	manning	2017

uas
92.0
93.99
94.61
95.74

las	(ptb wsj	sd	3.3)
89.7
92.05
92.79
94.08

understand, not just word similarities, 

can we use neural networks to 
but language meaning in general? 

building embeddings for phrases
how	can	we	know	when	larger	linguistic	units	are	
similar	in	meaning?

the	snowboarder	is	leaping	over	the	mogul

a	person	on	a	snowboard	jumps	into	the	air

people	interpret	the	meaning	of	larger	text	units	   
entities,	descriptive	terms,	facts,	arguments,	stories	    by	
semantic	composition of	smaller	elements

beyond the bag of words: sentiment 
detection
is	the	tone	of	a	piece	of	text	positive,	negative,	or	neutral?
    sentiment	is	that	sentiment	is	   easy   
    detection	accuracy	for	longer	documents	~90%

   	   	loved	   	   	   	   	   	great	   	   	   	   	   	   	impressed	
   	   	   	   	   	   	marvelous	   	   	   	   

    but

stanford sentiment treebank
    215,154	phrases	labeled	in	11,855	sentences
    can	train	and	test	compositions

http://nlp.stanford.edu:8080/sentiment/

tree-structured long short-term 
memory networks      [tai et al., acl 2015]

tree-structured lstm

generalizes	sequential	lstm	to	trees	with	any	branching	factor

better dataset helped even simple 
models

positive/negative	sentence	classification	(binomial	na  ve	bayes)

95

90

85

80

75

70

training	with	sentence	labels

training	with	treebank
    but	hard	negation	cases	are	still	mostly	incorrect
    we	also	need	a	more	powerful	model!

positive/negative results on treebank

classifying sentences: accuracy improves to 88%

95

90

85

80

75

70

training	with	sentence	labels

training	with	treebank

bi	nb

treelstm

experimental results on treebank
    treeid56 can	capture	constructions	like	x	but	y
    biword na  ve	bayes	is	only	58%	on	these

results on negating negatives

e.g.,	sentiment	of	   not	uninteresting   
goal:	positive	activation	should	increase

5. relation to linguistic and 
cognitive science
is	the	success	of	distributed	representations	and	neural	
network	methods	relevant	only	for	engineering	
applications?
or	is	it	also	relevant	to	linguistic	science?

non-categorical language phenomena:
gerund v-ing forms: e.g., climbing
    v-ing form:	classically	described	as	ambiguous	between	a	

nominal	and	a	verbal	gerund

    really,	v-ing forms	can	appear	to	be	of	any	of	the	core	

categories	of	chomsky	(1970):

v

+

   

adj:	an	unassuming man

noun: the	opening of	the	store

verb:	she	is	eating dinner

prep:	concerning your	point

n

+		

   

mixed noun/verb status

    noun	criterion:	appearing	with	a	determiner
    verb	criterion:	taking	a	direct	object

    the	not	observing this	rule	is	that	which	the	world	has	

blamed	in	our	satorist (dryden,	essay	dram.	poesy,	
310,	1684)

    the	only	mental	provision	she	was	making	for	the	

evening	of	life,	was	the	collecting and	transcribing all	
the	riddles	of	every	sort	that	she	could	meet	with.	(jane	
austen,	emma,	1816)

    the	difficulty	is	in	the	getting the	gold	into	erewhon.	

(sam	butler,	erewhon revisited,	1902)

continued noncategoricalness

graded	judgements	continue	in	this	domain	(horn	1975):

    tom   s	winning the	election	was	a	big	upset
    ?this	teasing john	all	the	time	has	got	to	stop
    ?there	is	no	marking exams	on	fridays
    *the	cessation hostilities	was	unexpected

houston	(1985:	320)	shows	that	an	assignment	of	(ing)	forms	to	a	
discrete	pos	classification	is	less	successful	[in	a	predictive	sense]	
than	a	continuum	in	explaining	-ing vs.	-in   
       grammatical	categories	exist	along	a	continuum	which	does	

not	exhibit	sharp	boundaries	between	the	categories.   

example: kind/sort of
(tabor 1994)
    kind/sort can	head	an	np	or	be	an	adverbial	modifier:

[that	kind	[of	knife]]	isn   t	used	much.

   
    we	are	[kind	of]	hungry.

    there	is	a	path	of	reanalysis	through	ambiguous	forms:

   
   

[a	[kind	[of	dense	rock]]]
[a	[[kind	of]	dense]	rock]

example: kind/sort of (tabor 1994)
   

iesu christ	his	owne son	through	kind
    oe:	has	kind;	little/no	kind	of

    a	nette sent	in	to	the	see,	and	of	alle kind	of	fishis

gedrynge (1382	wyclif)

   

    their	finest	and	best,	is	a	kind	of	course	red	cloth	(1570	

true	report)
i	was	kind	of	provoked	at	the	way	you	came	up	(1830	
mass.	spy)

    nlp	is	kind	of	like	a	rabbit	in	the	headlights	of	the	deep	
learning	machine	(2015,	neil	lawrence,	dl	workshop)
this	is	history	not	synchrony	    presumably,	   kids	today   	
learn	the	softener	use	of	kind	of	first!

example: kind/sort of (tabor 1994)

the cognitive science legacy of 
deep learning
   

(restricted)	boltzman machines
    [hinton	&	sejnowsky 1983;	smolensky 1983]

    id26

    tensor	methods

    [rumelhart,	hinton,	and	williams	1986]

    [dolan	and	dyer	1987;	smolensky 1987,	1990]

    softmax	/	maximum	id178	models	/	harmonic	grammar

    [smolensky 1983,	1986;	legendre	et	al.	1990]

still more ideas on the table
    we   ve	explored	a	still	semi-local	tree	representation

    smolensky has	explored	fully	distributed	representations

ab =a   r1+b   r2 =    xax     rx  

    model	has	distributed	structural	roles	as	well	as	distributed	fillers

final thoughts

2011														2013										2015											2017
speech							vision						nlp										your	field?

