outline

motivating the importance of side information

zero-shot learning models for image classi   cation

uni   ed evaluation of zero-shot learning models

summary of zero-shot learning for image classi   cation

outline

data distribution in large-scale datasets

motivating the importance of side information

zero-shot learning models for image classi   cation

uni   ed evaluation of zero-shot learning models

summary of zero-shot learning for image classi   cation

number of 
images

number of classes

3

2

4

attributes as side-information

attributes as side-information

images

attributes

black-white

has tail

lives on land

small

gray

has tail

lives in water

big

class

zebra

whale

images

attributes

class

black-white

has tail

lives on land

small

gray

has tail

lives in water

big

zebra

[1 0 1 1 0 1]

[0 1 1 0 1 0]

whale

[lampert et.al. cvpr   09, ferrari et.al. cvpr   09]

[lampert et.al. cvpr   09, ferrari et.al. cvpr   09]

attributes as side-information

images

attributes

class

black-white

has tail

lives on land

small

gray

has tail

lives in water

big

zebra

[1 0 1 1 0 1]

[0 1 1 0 1 0]

whale

[lampert et.al. cvpr   09, ferrari et.al. cvpr   09]

5

5

attributes as side-information

images

attributes

class

black-white

has tail

lives on land

small

gray

has tail

lives in water

big

zebra

[1 0 1 1 0 1]

[0 1 1 0 1 0]

whale

[lampert et.al. cvpr   09, ferrari et.al. cvpr   09]

5

5

muldimodal embeddings for zero-shot learning

zero-shot learning

images

image

features

class

attributes

class
labels

zebra

whale

black

white

[akata et.al. cvpr   13, cvpr   15, cvpr   16 & tpami   16]

6

images

...

...

...

attributes

black-white

has tail

lives on land

small

black-white

no tail

lives on land

medium

gray

has tail

lives in water

big

white
has tail

lives on land

tiny

wikipedia and id138 as side information

experimental setting

wikipedia and id138: object descriptions or hierarchies

2

1

4

3

5

6

id97 [mikolov et.al. nips   13]
glove [pennington et.al emnlp   14]

2 = [1 0 2 3 3 3]

hierarchical similarity measures

8

animals with

attributes (awa)
[lampert et.al. cvpr   09]

caltech ucsd-birds

(cub)

[wah et.al.   11]

50
cls

85
att

200
cls

312
att

input embeddings   (x): 1k-dim googlenet features

output embeddings   (y): att, w2v, glo, hie

7

9

evaluation of class embeddings

evaluation of class embeddings

awa cub
51.2
28.4
24.2
58.8
20.6
51.2
60.1
29.9

73.9

51.7

w2v
glo
hie
att-
att+

awa cub
51.2
28.4
24.2
58.8
20.6
51.2
60.1
29.9

73.9

51.7

w2v
glo
hie
att-
att+

    attributes & wikipedia & id138 are complementary

10

10

gaze embeddings for zero-shot learning

gaze embeddings for zero-shot learning

cub-vw

cub-vw

random points
bubbles [deng et al. cvpr   13]
bag of words from wikipedia
attributes
gaze
attributes + gaze

39.5
43.2
55.2
72.9
73.9
78.2

random points
bubbles [deng et al. cvpr   13]
bag of words from wikipedia
attributes
gaze
attributes + gaze

39.5
43.2
55.2
72.9
73.9
78.2

gaze data     class discriminative + complements attributes

[karessli et.al. cvpr   17]

20

conclusions

standard image classi   cation models fail with the lack of labels

20

22

conclusions

conclusions

standard image classi   cation models fail with the lack of labels

standard image classi   cation models fail with the lack of labels

1. zero-shot learning is a challenging task

1. zero-shot learning is a challenging task
2. side information, e.g. attributes, is required

conclusions

outline

22

standard image classi   cation models fail with the lack of labels

1. zero-shot learning is a challenging task
2. side information, e.g. attributes, is required
3. several sources of side information exists

[akata et.al. ieee cvpr 2013, 2015, 2016, tpami 2016] [reed et.al. ieee
cvpr 2016, icml 2016, nips 2016] [lampert et.al. ieee cvpr 2009,
tpami 2013] [mikolov et.al. nips 2013, karessli et.al. ieee cvpr 2017]

22

motivating the importance of side information

zero-shot learning models for image classi   cation

uni   ed evaluation of zero-shot learning models

summary of zero-shot learning for image classi   cation

22

23

zero-shot learning: task formulation

zero-shot learning: task formulation

s = {(xn, yn), n = 1...n }, with yn     y tr

s = {(xn, yn), n = 1...n }, with yn     y tr

training: learn f : x     y by minimizing regularized empirical risk:

1
n

n

!

n=1

l(yn, f (xn; w )) +    (w )

l(.) = id168,    (.) = id173 term and

24

24

zero-shot learning: task formulation

zero-shot learning: task formulation

s = {(xn, yn), n = 1...n }, with yn     y tr

s = {(xn, yn), n = 1...n }, with yn     y tr

training: learn f : x     y by minimizing regularized empirical risk:

training: learn f : x     y by minimizing regularized empirical risk:

1
n

n

!

n=1

l(yn, f (xn; w )) +    (w )

1
n

n

!

n=1

l(yn, f (xn; w )) +    (w )

l(.) = id168,    (.) = id173 term and

l(.) = id168,    (.) = id173 term and

f (x; w ) = arg max
y   y

f (x, y; w )

f (x; w ) = arg max
y   y

f (x, y; w )

testing: assign an image to y ts     y with max compatibility

24

24

multimodal embeddings with linear compatibility

deep visual semantic embeddings: devise

pairwise ranking: convex objective

[   (yn, y) + f (xn, y; w )     f (xn, yn; w )]+

!
y   y tr

images

image

features

class

attributes

class
labels

zebra

whale

black

white

f (x, y; w ) =   (x)t w   (y)

25

deep visual semantic embeddings: devise

attribute label embedding: ale

weighted pairwise ranking loss:

lk[   (yn, y) + f (xn, y; w )     f (xn, yn; w )]+

!
y   y tr

pairwise ranking: convex objective

[   (yn, y) + f (xn, y; w )     f (xn, yn; w )]+

!
y   y tr

       (yn, y) = 1 if yn = y, otherwise 0
    optimized by sgd

[frome et.al. nips 2013]

26

26

27

attribute label embedding: ale

structured joint embedding: sje

multiclass objective:

[ max
y   y tr

(   (yn, y) + f (xn, y; w ))     f (xn, yn; w )]+

weighted pairwise ranking loss:

lk[   (yn, y) + f (xn, y; w )     f (xn, yn; w )]+

!
y   y tr

       (yn, y) = 1 if yn = y, otherwise 0
    lk = "k
    optimized by sgd

i=1   i with   i = 1/i

[akata et.al. cvpr 2013 & tpami 2016]

27

structured joint embedding: sje

embarassingly simple zero-shot learning: eszsl

multiclass objective:

[ max
y   y tr

(   (yn, y) + f (xn, y; w ))     f (xn, yn; w )]+

additional id173 term to sje objective:

     w   (y)   2 +        (x)t w    2 +      w    2

where   ,   ,    are id173 parameters

    full weight to the top of the ranked list
    requires computing score wrt all the classi   ers for each sample

    euclidean norm of projected attributes in the feature space
    projected image feature in the attribute space are bounded

[akata et.al. cvpr 2015 & reed et.al. cvpr 2016]

[romera-paredes and torr, icml 2015]

28

28

29

semantic autoencoder: sae

objective: similar to the linear auto-encoder

||  (x)     w t   (y)||2 +   ||w   (x)       (y)||2,

min
w

    learns a linear projection from   (x) to   (y)
    projection must reconstruct the original image embedding

[kodirov et.al. cvpr 2017]

30

cross-modal transfer: cmt

direct attribute prediction: dap

deep nonlinear embedding objective:

!
y   y tr

!
x   xy

     (y)     w1 tanh(w2.  (x))   2

    (w1, w2): weights of the two layer neural network
    novelty detection: to assign images to unseen or seen classes

[socher et.al. nips   13]

two step process

direct attribute prediction: dap

two step process

    learn attribute classi   ers

32

33

direct attribute prediction: dap

two step process

    learn attribute classi   ers
    combine scores of learned

attribute classi   ers

f (x) = arg max

c

m

#

m=1

p(ac
p(ac

m|x)
m)

[lampert et.al. cvpr   09 & tpami   13]

33

33

convex combination of semantic emb.: conse

convex combination of semantic emb.: conse

id203 of a training image belonging to a training class:

id203 of a training image belonging to a training class:

f (x, t) = arg max
y   y tr

ptr(y|x)

f (x, t) = arg max
y   y tr

ptr(y|x)

combination of semantic embeddings (s) is used to assign an
unknown image to an unseen class:

1
z

t

!

i=1

ptr(f (x, t)|x), s(f (x, t))

    z = tth most likely label for image x
    t maximum number of semantic embedding vectors

[norouzi et.al. iclr   14]

synthesized classi   ers: sync

synthesized classi   ers: sync

34

34

weighted bipartite graph (scr): training (wc) and phantom (vr)

weighted bipartite graph (scr): training (wc) and phantom (vr)

objective is to minimize distortion error:

min
wc

   wc    

r

!

r=1

scrvr   2
2.

35

35

synthesized classi   ers: sync

weighted bipartite graph (scr): training (wc) and phantom (vr)

objective is to minimize distortion error:

min
wc

   wc    

r

!

r=1

scrvr   2
2.

novel class: linear combination of phantom class classi   ers

[changpinyo et.al. cvpr   16]

summary of presented zsl models

existing zsl models can be grouped into 4:

35

37

summary of presented zsl models

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae

37

summary of presented zsl models

summary of presented zsl models

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae
2. non-linear compatibilty: latem, cmt

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae
2. non-linear compatibilty: latem, cmt
3. two-stage id136: dap, conse

summary of presented zsl models

outline

37

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae
2. non-linear compatibilty: latem, cmt
3. two-stage id136: dap, conse
4. hybrid model: sync

[akata et.al ieee cvpr 2013, frome et.al. nips 2013, akata et. al. 2015,
romera paredes and torr icml 2015, , kodirov et.al ieee cvpr 2017, xian
et.al. ieee cvpr 2016, socher et.al. nips 2013, , lampert et.al. ieee cvpr
2009 & tpami 2013, norouzi et.al. iclr 2014, changpinyo et.al. ieee cvpr
2016]

37

motivating the importance of side information

zero-shot learning models for image classi   cation

uni   ed evaluation of zero-shot learning models

summary of zero-shot learning for image classi   cation

37

38

zero-shot learning: the good, the bad, the ugly

zero-shot learning: the good, the bad, the ugly

the good: zsl is an important direction that has gained interest

the good: zsl is an important direction that has gained interest

the bad: no uni   ed evaluation protocol exists

zero-shot learning: the good, the bad, the ugly

benchmark on attribute datasets and id163

39

dataset
sun
cub
awa1
awa2*
apy

size
14k
11k
30k
37k
1.5k

|y|
717
200
50
50
32

|y tr|

580 + 65
100 + 50
27 + 13
27 + 13
15 + 5

|y ts|
72
50
10
10
12

the good: zsl is an important direction that has gained interest

the bad: no uni   ed evaluation protocol exists

the ugly: test classes overlap with id163 1k

39

39

40

benchmark on attribute datasets and id163

dataset
sun
cub
awa1
awa2*
apy

size
14k
11k
30k
37k
1.5k

|y|
717
200
50
50
32

|y tr|

580 + 65
100 + 50
27 + 13
27 + 13
15 + 5

|y ts|
72
50
10
10
12

id163 split
id163 21k - y tr
within 2/3 hops from y tr
most populated classes
least populated classes

|y ts|
20345

1509/7678
500/1k/5k
500/1k/5k

ranking models on attribute datasets

1

5

2

5

1

2

2

7

5

1

1

1

3

2

4

3

3

1

2

4

1

5

6

1

2

rank
5
6

7

8

9 10

1

2

1

4

5

1

1

1

5

1

1

3

3

1

1

1

3

4

2

3

1

1

4

5

5

2

4

1

8

8

6

1

ale [2.0]

devise [2.9]

sje [3.4]

eszsl [4.2]

latem [4.5]

sync [5.3]

dap [7.3]

sae [8.4]

cmt [8.5]

conse [8.6]

40

42

conclusions

conclusions

benchmark of zero-shot learning

benchmark of zero-shot learning

1. zero-shot learning has attracted lots of attention

1. zero-shot learning has attracted lots of attention
2. we propose a uni   ed evaluation procedure

conclusions

benchmark of zero-shot learning

1. zero-shot learning has attracted lots of attention
2. we propose a uni   ed evaluation procedure
3. comprehensive evaluation of 12 models on 6 datasets

[xian et.al. ieee cvpr 2017 & arxiv 2017]

44

44

outline

motivating the importance of side information

zero-shot learning models for image classi   cation

uni   ed evaluation of zero-shot learning models

summary of zero-shot learning for image classi   cation

44

45

summary of zsl for image classi   cation

summary of zsl for image classi   cation

1. large-scale image classi   cation fails with lack of data

1. large-scale image classi   cation fails with lack of data

[akata et.al. tpami   14]

[akata et.al. tpami   14]

2. structured joint embeddings tackles lack of visual data

[akata et.al. cvpr   13, akata et.al. tpami   16]

summary of zsl for image classi   cation

summary of zsl for image classi   cation

46

46

1. large-scale image classi   cation fails with lack of data

1. large-scale image classi   cation fails with lack of data

[akata et.al. tpami   14]

[akata et.al. tpami   14]

2. structured joint embeddings tackles lack of visual data

[akata et.al. cvpr   13, akata et.al. tpami   16]

2. structured joint embeddings tackles lack of visual data

[akata et.al. cvpr   13, akata et.al. tpami   16]

3. attributes, text and gaze provide side information

[akata et.al. cvpr   15 & cvpr   16, xian et.al. cvpr   16 &
cvpr   17, karessli et.al. cvpr   17]

3. attributes, text and gaze provide side information

[akata et.al. cvpr   15 & cvpr   16, xian et.al. cvpr   16 &
cvpr   17, karessli et.al. cvpr   17]

4. the good, the bad and the ugly aspects of zero-shot learning

[xian et.al. cvpr   17 & arxiv   17]

46

46

thank you!

47

localization	as	retrieval

query

zero-shot	localization by	free	text

    goal:	find	the	target	in	the	image
ranking	sliding	window	images

   

    sliding	window	search

thousands	of	images	generated

    learn	scoring	function	with	two	inputs

input	#1:	query	image
input	#2:	sliding	image
output:	siilarity(input	#1,	input	#2)

   

   
   
   

    similar	to	zero-shot	localization	[1]

#input	1	is	now	a	text	query

    rank	sliding	images

scoring	function	measures
similarity	of	image	to	text	

   

   

zero-shot	localization by	free	text

    semantic	attributes
   hat   ,	   white   ,	   
    spatial	attributes	too

   

   

   right   ,	   on	top	of   ,	   below   ,	   

    global	context

[1]	natural	language	object	retrieval,	hu	et	al.,	cvpr	2016

21

23

[1]	natural	language	object	retrieval,	hu	et	al.,	cvpr	2016

22

zero-shot	localization	in	videos,	aka
tracking	by	natural	language	[1]

    define	the	target	not	as	a	bounding	box	but	as	a	language	description?

[1]	tracking	by	natural	language	specification,	li	et	al.,	cvpr	2017

   track the little green person with 
the pointy ears and the beige robe!   

24

zero-shot	localization	in	videos,	aka
tracking	by	natural	language

zero-shot	localization	in	videos,	aka
tracking	by	natural	language

    novel	type	of	human-machine	
interaction

       tesla,	follow	the	red	car	in	the	middle	

lane   

    enables	novel	tracking	scenarios

    no	   first-frame   	requirement	   ideal	for	

   live   	or	online	tracking

    multiple-video,	multiple-target	tracking	  

ideal	for	large	scale	monitoring
    more	robust	standard	tracking

    tracker	adapts	to	appearance	variations
    helping	against	drift

model	i

model	ii

model	iii

[1]	tracking	by	natural	language	specification,	li	et	al.,	cvpr	2017

25

[1]	tracking	by	natural	language	specification,	li	et	al.,	cvpr	2017

26

person	search	with	natural	language

person	search	with	natural	language

    first	extract	region	proposals
    then	compute	word	specific
(dynamic)	filters
    computer	word-image	affinity

[1]	person	search	with	natural	language	description,	li	
et	al.,	cvpr	2017

27

[1]	person	search	with	natural	language	description,	li	et	al.,	cvpr	2017

28

conclusion

    attributes	belong	to	objects,	not	images
    zero-shot	localization	natural	extension
    object	tracking	by	natural	language	description	is	a	very	novel	and	
relevant	direction

    also	connected	to	video	object	detection

29

interacting	with	relative	attributes
    learn	relative	attributes

learning-to-rank

    interactive	search

learn	attributes	offline
at	id136	rank	images
according	to	relevance
user	indicates	relative
changes	in	top	ranks

predicting	unfamiliar	classes
    open set	of	classes	at	test	time
    slightly	different	than	zero-shot

p(unfamiliar	class) =	   (1	   	p(seen	class))

no	known	attribute-class	mapping

   
   

    user	corrects	misclassified	attributes

    active	labelling

[1]	relative	attributes	for	enhanced	man-machine	communication,	parikh	et	al.,	aaai	2012

[1]	attribute-based	detection	of	unfamiliar	classes	with	humans	in	the	loop,	wah et	al.,	cvpr	2013

tree-based	interactive	labelling
    image	labels	are	correlated

water,	river,	sea	   landscape	nature,	sky,	clouds
improved	prediction:	especially	when	human-in-the-loop
attribute-based	image	classification:	attributes	in	tree

tree-based	interactive	labelling
    criterion:	select	attribute	that	minimizes	uncertainty	on	final	class	
prediction

   
   

select	attribute	that	minimizes	conditional	class	id178
new	queries	are	conditioned	on	the	image	and	the	previously	selected	
attributes	

   

   
   

   

   
   
   

[1]	learning	structured	prediction	models	for	interactive	image	labelling,	mensink et	al.,	cvpr	2013

[1]	learning	structured	prediction	models	for	interactive	image	labelling,	mensink et	al.,	cvpr	2013

;
;
how	to	transfer?

class-attribute	mapping,	
e.g.,	costa	[2]

known	class	model
    old	datasets
    google

zero-shot	model

active	updates

new	image

   

how	to	actively	learn?
    simply	speaking

   
   

sample	from	margin
but	make	sure	positive/
negatives	labels	balanced
keep	running	log	of label
sampling	likelihoods

[1]	active	transfer	learning	with	zero-shot	priors:	reusing	past	datasets	for	future	tasks,gavves,	et	al.,	iccv	2015
[2]	costa:	co-occurrence	statistics	for	zero-shot	classification,		mensink,	gavves,	snoek,	cvpr	2014

[1]	active	transfer	learning	with	zero-shot	priors:	reusing	past	datasets	for	future	tasks,gavves,	et	al.,	iccv	2015

active	transfer	learning	with	zero-shot	priors

in	practice

using	knowledge	graphs	for	novel	qa

https://github.com/stratisgavves/activetransferlearning
www.egavves.com

or

19

[1]	the	more	you	know:	using	knowledge	graphs	for	image	classification,	marino	et	al.,	cvpr	2017

20

evaluating gzsl

evaluating gzsl

per-class top-1 accuracy for zsl:

per-class top-1 accuracy for zsl:

accy =

1

   y   

   y   
!

c=1

# correct in c

# in c

accy =

1

   y   

   y   
!

c=1

# correct in c

# in c

to insure that all classes will weigh the same

to insure that all classes will weigh the same

harmonic mean for gzsl:

h =

2     accy tr     accy ts
accy tr + accy ts

to insure that seen and unseen class accuracy will weigh the same

zero-shot learning models

existing zsl models can be grouped into 4:

4

5

zero-shot learning models

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae

4

5

zero-shot learning models

zero-shot learning models

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae
2. non-linear compatibilty: latem, cmt

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae
2. non-linear compatibilty: latem, cmt
3. two-stage id136: dap, conse

zero-shot learning models

datasets used for evaluation

5

existing zsl models can be grouped into 4:

1. linear compatibility: ale, devise, sje, eszsl, sae
2. non-linear compatibilty: latem, cmt
3. two-stage id136: dap, conse
4. hybrid model: sync

[akata et.al ieee cvpr 2013, frome et.al. nips 2013, akata et. al. 2015,
romera paredes and torr icml 2015, , kodirov et.al ieee cvpr 2017, xian
et.al. ieee cvpr 2016, socher et.al. nips 2013, , lampert et.al. ieee cvpr
2009 & tpami 2013, norouzi et.al. iclr 2014, changpinyo et.al. ieee cvpr
2016]

5

dataset
sun
cub
awa1
awa2*
apy

size
14k
11k
30k
37k
1.5k

|y|
717

200

50

50

32

|y tr|

580 + 65
100 + 50
27 + 13
27 + 13
15 + 5

|y ts|
72

50

10

10

12

5

6

conclusions

conclusions

in generalized zero-shot learning

in generalized zero-shot learning

1. the setup is challenging but more practical
2. unseen images embedded close to seen classes
3. results much lower than zsl: room for improvement

[xian et.al. ieee cvpr 2017 & arxiv 2017]

12

1. the setup is challenging but more practical
2. unseen images embedded close to seen classes

thank you!

12

13

zero-shot	with	localization

    attributes	belong	to	objects,	not	images
    zero-shot	localization	is	a	natural	extension	to	the	problem
    focus	on	visual	details	or	regions

each	with	their	merit,	depends	on	application

   
    maybe	a	smart	combination?

    localization	in	images	and	videos using	natural	language	queries	is	
possible	and	promising

    offers	also	a	great	evaluation	framework	for	image	captioning,	visual	question	

answering

zero-shot	retrieval
    zero-shot	retrieval	profits	from	semantic	alignment
   
    better	than	low- and	mid-level	alternatives
    adds	meaning	and	recounting	to	retrieval	results

learnable	from	freely	available	online	sources

    next	challenge:	
   

spatiotemporal	search	and	alerts	for	live	video	

open	problems
    the	evaluation	of	zero-shot	classifiers	is	very	important!

    thankfully,	now	there	is	a	benchmark	to	compare	against
    zero-shot	learning	- the	good,	the	bad	and	the	ugly,	xian	et	al.,	cvpr	2017
    12	models	compared	in	6	datasets
    generalized	zero-shot	learning
    more	challenging,	more	practical!
    unseen	images	embedded	close	to	seen	classes

    how	to	optimally	exploit	knowledge	graphs	to	answer	novel	qa?
    interaction	remedy	to	attribute-based	classification

   
   
   

correct	prediction	mistakes
guide	new	attribute	learning
guide	classification

    active	transfer	learning	   old	datasets	no	more	wasted

    much	faster	learning	than	state-of-the-art	alternatives

5

7

6

what   s	next?

[1]

[2]

[3]

[1]	multi-cue	zero-shot	learning	with	strong	supervision,	akata et	al.,	cvpr	2016
[2]	generative	adversarial	text	to	image	synthesis,	reed,	icml	2016
[3]	synthesized	classifiers	for	zero-shot	learning,	changpinyo,	cvpr	2016

8

thank	you!

slides	will	be	added	online	later	at	the	website:
https://staff.fnwi.uva.nl/t.e.j.mensink/zsl2017/

9

