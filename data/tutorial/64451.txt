   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]deep math machine learning.ai
   [7]deep math machine learning.ai
   [8]sign in[9]get started
     __________________________________________________________________

chapter 1.3:code for id75 with id119 (from scratch
and tensorflow & scikit learn ).

   [10]go to the profile of madhu sanjeevi ( mady )
   [11]madhu sanjeevi ( mady ) (button) blockedunblock (button)
   followfollowing
   sep 26, 2017

   in last two parts we talked about [12]id75 and
   [13]id119.

   this part i wanna code the algorithm from scratch and using other two
   libraries (tensorflow and scikit learn). lets get started!
   [1*wbzt7lg4reup8tipuvyewa.jpeg]

   full code is available on my [14]github.

   first things first, we should prepare the data-set , we can generate
   random data x and y using numpy and plot it.
   [1*cqln-g9zyq6axv0dogrgkq.jpeg]
   sine wave random

   now we have the x values and y values (inputs and targets), next step
   is to generate random weights (   values)
   [1*detrxdfkhyq2t520wwou8a.jpeg]

   we got our    values(  0 and   1) and x values , next step is to predict y
   values(remember these are different from actual y values from our
   data-set)

   y=  0+  1*x
   [1*lze2b3bkb6tylrebm0az-a.jpeg]
   dot operation for id127.

   the above code does id127 same as y1=x0*  0+x1*  1 (x0=1,
   x1=our first x value in data-set). next step is to calculate the error
   and minimize the error (id119 process)

   error=(predicted-actual)**2 and , to minimize the error we need to find
   the derivatives(gradients) for weights(   values) and update them as we
   reach the minimum value .
   [1*xlotyt8qxvg8ar4ywxjifa.jpeg]

   after iterating it by no of epochs, we finally get the final weights
   (best fit line for our data) here is the graph for error with epochs
   [1*ibjve0ygsajs3sysroxu8w.jpeg]

   as we can see the error is reduced as no of epochs are increasing and
   final we reach the minimum value, and we got our updated weights and
   best fit line.
   [1*umuzfxojjk5vrhnfegcaug.jpeg]
   best fit line

     what   s next??

   next step is to predict the new data we can simply do that by just
   calling the predict() function (weights w are final weights) by giving
   the set of test data (x values)

   we can also add many features to x (no of features can be more than
   one), create a data set with multiple features in x and run the same
   program

     it will work.

     lets use some other frameworks (tensorflow and scikit learn)

   #tensorflow
import tensorflow as tf
x = tf.placeholder(tf.float32)
y = tf.placeholder(tf.float32)
tf.set_random_seed(5)
w = tf.variable(tf.random_normal([1]),name="weights")
b = tf.variable(tf.random_normal([1]), name='bias')

   placeholders for the input and output of the network. placeholders are
   variables which we need to fill in when we are ready to compute the
   graph.

   next we predict the y values
y_pred = tf.add(tf.multiply(x, w), b) # same as   1*x +   0

   now calculate the error for every x value and sum it up for the final
   error
error=tf.square(y_pred-y)
f_error=tf.reduce_sum(error)/(points-1) #we just reduced error by dividing the n
o of x values (good practice)

   now update the weights to reduce the error , how? id119

   tensorflow has already implemented gd so we don   t need to write it.
optimizer=tf.train.gradientdescentoptimizer(0.01).minimize(f_error)

   note: we need to create a session in tensorflow to run the code
   [1*qt2eh4a4a6o6ynklt6gvha.jpeg]

   now we can do the same thing using scikit learn in just a few line of
   code , how awesome is that?
   [1*mj3aijmvbzdhnbbu-4m2xq.jpeg]

   oh! yeah! finally we made the same algorithm work in 3 different ways

   here is the final picture comparing the best fit line for all 3 methods
   [1*zo2wjzxepxwglmygn4qxuw.jpeg]
   from scratch(left),tensorflow(center),scikit(right)

   can you guess which one is best??? let me know what you think

   that   s it for this story. hope you changed and learned something let me
   know if it helps .

   in the next story i will cover another interesting machine leaning
   concept until then see ya!

   full code is available on my [15]github

     * [16]machine learning
     * [17]tensorflow
     * [18]scikit learn
     * [19]supervised learning
     * [20]id119

   (button)
   (button)
   (button) 241 claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   [21]go to the profile of madhu sanjeevi ( mady )

[22]madhu sanjeevi ( mady )

   writes about technology (ai, ml, dl) | writes about human mind and
   computer mind. interested in ||programming || science || psychology ||
   neuroscience || math

     (button) follow
   [23]deep math machine learning.ai

[24]deep math machine learning.ai

   this is all about machine learning and deep learning (topics cover
   math,theory and programming)

     * (button)
       (button) 241
     * (button)
     *
     *

   [25]deep math machine learning.ai
   never miss a story from deep math machine learning.ai, when you sign up
   for medium. [26]learn more
   never miss a story from deep math machine learning.ai
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/7ba084ff7e6d
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/deep-math-machine-learning-ai?source=avatar-lo_46hlkgqbyt5h-dedce56b468f
   7. https://medium.com/deep-math-machine-learning-ai?source=logo-lo_46hlkgqbyt5h---dedce56b468f
   8. https://medium.com/m/signin?redirect=https://medium.com/deep-math-machine-learning-ai/chapter-1-3-7ba084ff7e6d&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/deep-math-machine-learning-ai/chapter-1-3-7ba084ff7e6d&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@madhusanjeevi.ai?source=post_header_lockup
  11. https://medium.com/@madhusanjeevi.ai
  12. https://medium.com/@madhusanjeevi.ai/complete-linear-regression-with-math-edb05500e7ee
  13. https://medium.com/@madhusanjeevi.ai/chapter-1-2-gradient-descent-with-math-ad303eb33be8
  14. https://github.com/madhu009/medium_machine_learning_blog
  15. https://github.com/madhu009/medium_machine_learning_blog
  16. https://medium.com/tag/machine-learning?source=post
  17. https://medium.com/tag/tensorflow?source=post
  18. https://medium.com/tag/scikit-learn?source=post
  19. https://medium.com/tag/supervised-learning?source=post
  20. https://medium.com/tag/gradient-descent?source=post
  21. https://medium.com/@madhusanjeevi.ai?source=footer_card
  22. https://medium.com/@madhusanjeevi.ai
  23. https://medium.com/deep-math-machine-learning-ai?source=footer_card
  24. https://medium.com/deep-math-machine-learning-ai?source=footer_card
  25. https://medium.com/deep-math-machine-learning-ai
  26. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  28. https://medium.com/p/7ba084ff7e6d/share/twitter
  29. https://medium.com/p/7ba084ff7e6d/share/facebook
  30. https://medium.com/p/7ba084ff7e6d/share/twitter
  31. https://medium.com/p/7ba084ff7e6d/share/facebook
