   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

chapter 2.1: code for id28 with id119 (from scratch
and also using scikit learn ).

   [9]go to the profile of madhu sanjeevi ( mady )
   [10]madhu sanjeevi ( mady ) (button) blockedunblock (button)
   followfollowing
   sep 26, 2017

   in last two parts we talked about [11]id28 and
   [12]id119.

   this part i wanna code the algorithm from scratch and using other
   library(scikit learn). lets get started!

   full code is available on my [13]github.

   first things first, we should prepare the data-set , we can generate
   random data x and y using sklearn make_blobs and plot it.
   [1*hqdq9j6fhgq64ov5ifbfug.jpeg]

   we have two features(independent variables) and 1 dependent variable
   which is either 0 or 1, we can also plot the graph choosing y-axis as
   dependent variable which looks like this.
   [1*bwhj59un7itgmazw9-elua.jpeg]

   now we have the x values and y values (inputs and targets), next step
   is to generate random weights (   values)
   [1*nod_sqd9bg9tay3miyv5ra.jpeg]

   before we dive into the algorithm , lets define our sigmoid function.
   [1*5c6wpbozlsys8iubpws60q.jpeg]

   we got our s-shaped function, if we give any value, we get the
   probabilities (values between 0 and 1).

   next step is to calculate the hypothesis h(x).
h(x) = sigmoid(-h(x) of id75)
h(x) = sigmoid(-(   0+  1*x)) note:   0+  1*x is logit function here

   [1*4pbdueudmkb6ofv45cmyqq.jpeg]

   next step is to calculate the error , cost function.
   [1*7-xstijlvkq46-rzyjo2ka.jpeg]

   we got our error, next step will be to minimize the error gradient
   descent process. to minimize the error we need to find the
   derivatives(gradients) for weights(   values) and update them as we
   reach the minimum value .
   [1*ee5fndbxreqcixqoutz5xq.jpeg]

   that   s it we are done! after iterating it by no of epochs, we finally
   get the final weights here is the graph for error with epochs
   [1*k8dy4jt3ssg0fihpihqnwa.jpeg]

   as we can see the error is reduced as no of epochs are increasing and
   final we reach the minimum value, and we got our updated weights.

     what   s next??

   next step is to predict the new data we can simply do that by just
   calling the predict() function (weights w are final weights) by giving
   the set of test data (x values)

   we can also add many features to x (no of features can be more than
   one), create a data set with multiple features in x and run the same
   program

     it will work.

   lets predict our model with our training data only.

   note: usually we should have a test data.
   [1*58umkrl5nhvehyr7m6dhza.jpeg]

   lets see the accuracy and error.
   [1*jui7bqab4aknlmhxpwpsrw.jpeg]

   so we got 3 points misclassified and our error is 3 and our accuracy is
   97%

   which is okay and we can even improve the model by doing a lot of
   things, (not in the scope of this story)

     lets use some other framework (scikit learn)

   #scikit

   we can do the same thing using scikit learn in just a few lines of
   code , how awesome is that?
   [1*hjkckyswtyi7miij6w7tda.jpeg]

   wow!!! we got 0 error and 100% accuracy in just a few lines of code

   what the ****.

   question: do we need to work hard to learn these ?? our scikit learn
   makes it easy to solve and saves a lot of time.

   answer: depends if you wanna work for clients,go with the scikit,

   if you wanna work for people(users) learn the black box.
   [1*ea2xpjavlhgrkdgfozyizw.jpeg]

   that   s it for this story. hope you enjoyed and learned something let me
   know if it helps .

   in the next story i will cover another interesting machine leaning
   concept until then see ya!

   full code is available on my [14]github

     * [15]machine learning
     * [16]id28
     * [17]supervised learning
     * [18]classification
     * [19]scikit learn

   (button)
   (button)
   (button) 33 claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   [20]go to the profile of madhu sanjeevi ( mady )

[21]madhu sanjeevi ( mady )

   writes about technology (ai, ml, dl) | writes about human mind and
   computer mind. interested in ||programming || science || psychology ||
   neuroscience || math

     * (button)
       (button) 33
     * (button)
     *
     *

   [22]go to the profile of madhu sanjeevi ( mady )
   never miss a story from madhu sanjeevi ( mady ), when you sign up for
   medium. [23]learn more
   never miss a story from madhu sanjeevi ( mady )
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/84838d48647c
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@madhusanjeevi.ai/chapter-2-1-84838d48647c&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@madhusanjeevi.ai/chapter-2-1-84838d48647c&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@madhusanjeevi.ai?source=post_header_lockup
  10. https://medium.com/@madhusanjeevi.ai
  11. https://medium.com/@madhusanjeevi.ai/chapter-2-0-logistic-regression-with-math-85df56d28c08
  12. https://medium.com/@madhusanjeevi.ai/chapter-1-2-gradient-descent-with-math-ad303eb33be8
  13. https://github.com/madhu009/medium_machine_learning_blog/blob/master/logisticregression_from-scratch.ipynb
  14. https://github.com/madhu009/medium_machine_learning_blog/blob/master/logisticregression_from-scratch.ipynb
  15. https://medium.com/tag/machine-learning?source=post
  16. https://medium.com/tag/logistic-regression?source=post
  17. https://medium.com/tag/supervised-learning?source=post
  18. https://medium.com/tag/classification?source=post
  19. https://medium.com/tag/scikit-learn?source=post
  20. https://medium.com/@madhusanjeevi.ai?source=footer_card
  21. https://medium.com/@madhusanjeevi.ai
  22. https://medium.com/@madhusanjeevi.ai
  23. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  25. https://medium.com/p/84838d48647c/share/twitter
  26. https://medium.com/p/84838d48647c/share/facebook
  27. https://medium.com/p/84838d48647c/share/twitter
  28. https://medium.com/p/84838d48647c/share/facebook
