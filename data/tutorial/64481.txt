trend   #1:   scale   driving   deep   learning   progress

nuts   and   bolts   of   building   ai   

applications   using   deep   learning

andrew   ng

trend   #2:   the   rise   of   end-  to-  end   learning

learning   with   integer   or   real-  valued   outputs:   

learning   with   complex   (e.g.,   string   valued)   outputs:   

andrew   ng

andrew   ng

major   categories   of   dl   models

1. general   neural   networks   
2. sequence   models   (1d   sequences)

3.

    id56,   gru,   lstm,   ctc,   attention   models,      .
image   models
    2d   and   3d   convolutional   networks

4. advanced/future   tech:

    unsupervised   learning   (sparse   coding,   ica,   sfa,   

   ),   reinforcement   learning,      .   

andrew   ng

andrew   ng

andrew   ng

end-  to-  end   learning:   speech   recognition

traditional   model   

end-  to-  end   learning:   autonomous   driving
traditional   model   

end-  to-  end   learning

end-  to-  end   learning

this   works   well   given   enough   labeled   (audio,   transcript)   data.   

given   the   safety-  critical   requirement   of   autonomous   driving   and   thus   the   need   for   extremely   
high   levels   of   accuracy,   a   pure   end-  to-  end   approach   is   still   challenging   to   get   to   work.   end-  to-  
end   works   only   when   you   have   enough   (x,y)   data   to   learn   function   of   needed   level   of   complexity.   

andrew   ng

andrew   ng

machine   learning   strategy

traditional   train/dev/test   and   bias/variance

often   you   will   have   a   lot   of   ideas   for   how   to   improve   an   
ai   system,   what   do   you   do?   

good   strategy   will   help   avoid   months   of   wasted   effort.

say   you   want   to   build   a   human-  level   speech   recognition   system.   you   split   your   data   

into   train/dev/test:   

training   (60%)

dev   (20%)

test   (20%)

human   level   error            .   1%

training   set   error            ...   5%

dev   set   error                  ..   8%   

   avoidable   bias   

   variance   

andrew   ng

compared   to   earlier   eras,   we   still   talk   about   bias   and   variance,   but   somewhat   less   

about   the      tradeoff      between   them.   

andrew   ng

andrew   ng

basic   recipe   for   machine   learning

automatic   data   synthesis   examples

training   error   high?

no

dev   error   high?

no

done!

yes

yes

bigger   model
train   longer
new   model   architecture

(bias)

more   data
id173
new   model   architecture

(variance)

    ocr

    text   against   random   backgrounds

    speech   recognition

machine   learning

    synthesize   clean   audio   against   different   background   noise

    nlp:   grammar   correction

    synthesize   random   grammatical   errors

sometimes   synthesized   data   that   appears   great   to   human   eyes   is   
actually   very   impoverished   in   the   eyes   of   ml   algorithms,   and   covers   
only   a   minuscule   fraction   of   the   actual   distribution   of   data.   e.g.,   
images   of   cars   extracted   from   video   games.

andrew   ng

andrew   ng

different   training   and   test   set   distributions

say   you   want   to   build   a   speech   recognition   system   for   a   new   in-  car   
rearview   mirror   product.   you   have   50,000   hours   of   general   speech   
data,   and   10   hours   of   in-  car   data.   how   do   you   split   your   data?   this   
is   a   bad way   to   do   it:   

training

dev

test

general   speech   data   (50,000   hours)

in-  car   data   
(10   hours)

having   mismatched   dev   and   test   distributions   is   not   a   good   idea.   
your   team   may   spend   months   optimizing   for   dev   set   performance   
only   to   find   it   doesn   t   work   well   on   the   test   set.   

andrew   ng

different   training   and   test   set   distributions
better   way:   make   the   dev   and   test   sets   come   from   the   same   distribution.

training   (~50,000h)

general   speech   data

training-  dev   

(20h)

test   
dev
(5h)
(5h)
in-  car   data

human   level   error            ...   1%

training   error         ..............   1.1%

training-  dev   error            ...   1.5%

dev   set   error                     .   8%

test   set   error                     .   8.5%   

   avoidable   bias   

overfitting   of   training   set

data   mismatch

overfitting   of   dev   set

andrew   ng

andrew   ng

new   recipe   for   machine   learning

general   human/bias/variance   analysis   

training   error   high?

no

train-  dev   error   high?

no

dev   error   high?

no

test   error   high?

no

done!

yes

yes

yes

yes

bigger   model
train   longer
new   model   architecture

(bias)

more   data
id173
new   model   architecture

(variance)

make   training   data   more                     

similar   to   test   data.   

data   synthesis
(domain   adaptation.)
new   model   architecture

(train-  test   data   
mismatch)

more   dev   set   data

(overfit   dev   
set)

andrew   ng

general

speech   data   
(50,000   hours)

in-  car

speech   data   
(10   hours)

human-  level error   

(carry   out   human   

evaluation   to   measure.)

training   error

(insert some   in-  car   data   into   

training   set   to   measure.)

training-  dev   error

dev/test   error

performance of   
humans

performance on   
examples   you   ve   trained   
on

performance   on   
examples   you   haven   t   
trained   on

   avoidable   bias   

   variance   /degree   of   
overfitting

data   mismatch

andrew   ng

human   level   performance

quiz:   medical   imaging

you   ll   often   see   the   fastest   performance   improvements   on   a   task   while   the   

ml   is   performing   worse   than   humans.   

    human-  level   performance   is   a   proxy   for   bayes   optimal   error,   which   we   

can   never   surpass.

    can   rely   on   human   intuition:   (i)   have   humans   provide   labeled   data.                  
(ii)   error   analysis   to   understand   how   humans   got   examples   right.                              
(iii)   estimate   bias/variance.   e.g.,   on   an   image   recognition   task,   training   
error   =   8%,   dev   error   =   10%.   what   do   you   do?   two   cases:   

human   level   error            .   1%

training   set   error            ...   8%

dev   set   error                     10%   

focus   on   bias.

   avoidable   bias   

   variance   

human   level   error            .   7.5%

training   set   error            ...   8%

dev   set   error                     10%   

focus   on   variance.

   avoidable   bias   

   variance   

andrew   ng

suppose   that   on   an   image   labeling   task:
typical   human                     ..      3%   error
typical   doctor                        ...   1%   error
experienced   doctor                  .   0.7%   error
team   of   experienced   doctors      .   0.5%   error

what   is      human-  level   error   ?

answer:   for   purpose   of   driving   ml   progress,   0.5%   is   
best   answer   since   it   s   closest   to   bayes   error.   

andrew   ng

andrew   ng

ai   product   management

ai   product   management

the   availability   of   new   supervised   dl   algorithms   means   we   re   rethinking   the   workflow   
of   how   to   have   teams   collaborate   to   build   applications   using   dl.   a   product   manager   
(pm)   can   help   an   ai   team   prioritize   the   most   fruitful   ml   tasks.   e.g.,   should   you   
improve   speech   performance   with   car   noise,   caf     noise,   for   low-  bandwidth   audio,   for   
accented   speech,   or   improve   latency,   reduce   binary   size,   or   something   else?   

how   should   pms   and   ai   teams   work   together?   here   s   one   default   split   of   

responsibilities:

product   manager   (pm)   

responsibility

ai   scientist/engineer

responsibility

what   can   ai   do   today?   some   heuristics   for   pms:   
   

if   a   typical   person   can   do   a   mental   task   with   less   than   one   second   of   thought,   we   
can   probably   automate   it   using   ai   either   now   or   in   the   near   future.   

    for   any   concrete,   repeated   event   that   we   observe   (e.g.,   whether   user   clicks   on   ad;     

how   long   it   takes   to   deliver   a   package;        .),   we   can   reasonably   try   to   predict   the   
outcome   of   the   next   event   (whether   user   clicks   on   next   ad).   

    provide   dev/test   sets,   ideally   
drawn   from   same   distribution.

    provide   evaluation   metric   for   
learning   algorithm   (accuracy,   
f1,   etc.)   

this   is   a   way   for   the   pm   to   express   
what   ml   task   they   think   will   make   
the   biggest   difference   to   users.   

    acquire   training   data

    develop   system   that   does   well   

according   to   the   provided   
metric   on   the   dev/test   data.   

andrew   ng

andrew   ng

machine   learning   yearning

book   on   ai/ml   technical   strategy.

sign   up   at   http://mlyearning.org

thank   you   for   coming   to

this   tutorial!   

andrew   ng

andrew   ng

andrew   ng

