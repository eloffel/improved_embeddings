   [1]cornell university
   [2]we gratefully acknowledge support from
   the simons foundation and member institutions.

[3]arxiv.org > [4]stat > arxiv:1712.07897

   ____________________
   [all fields________]
   submit
   ([5]help | [6]advanced search)

   full-text links:

download:

     * [7]pdf
     * [8]other formats

   ([9]license)

current browse context:

   stat.ml
   [10]< prev  |  [11]next >
   [12]new | [13]recent | [14]1712

change to browse by:

   [15]cs
   [16]cs.lg
   [17]math
   [18]math.oc
   [19]stat

references & citations

     * [20]nasa ads

bookmark

   ([21]what is this?)
   [22]citeulike logo [23]bibsonomy logo [24]mendeley logo [25]reddit logo
   [26]sciencewise logo

statistics > machine learning

title:non-id76 for machine learning

   authors:[27]prateek jain, [28]purushottam kar
   (submitted on 21 dec 2017)

     abstract: a vast majority of machine learning algorithms train their
     models and perform id136 by solving optimization problems. in
     order to capture the learning and prediction problems accurately,
     structural constraints such as sparsity or low rank are frequently
     imposed or else the objective itself is designed to be a non-convex
     function. this is especially true of algorithms that operate in
     high-dimensional spaces or that train non-linear models such as
     tensor models and deep networks.
     the freedom to express the learning problem as a non-convex
     optimization problem gives immense modeling power to the algorithm
     designer, but often such problems are np-hard to solve. a popular
     workaround to this has been to relax non-convex problems to convex
     ones and use traditional methods to solve the (convex) relaxed
     optimization problems. however this approach may be lossy and
     nevertheless presents significant challenges for large scale
     optimization.
     on the other hand, direct approaches to non-id76 have
     met with resounding success in several domains and remain the
     methods of choice for the practitioner, as they frequently
     outperform relaxation-based techniques - popular heuristics include
     projected id119 and alternating minimization. however,
     these are often poorly understood in terms of their convergence and
     other properties.
     this monograph presents a selection of recent advances that bridge a
     long-standing gap in our understanding of these heuristics. the
     monograph will lead the reader through several widely used
     non-id76 techniques, as well as applications thereof.
     the goal of this monograph is to both, introduce the rich literature
     in this area, as well as equip the reader with the tools and
     techniques needed to analyze these simple procedures for non-convex
     problems.

   comments: the official publication is available from now publishers via
   [29]this http url
   subjects: machine learning (stat.ml); machine learning (cs.lg);
   optimization and control (math.oc)
   journal reference: foundations and trends in machine learning: vol. 10:
   no. 3-4, pp 142-336 (2017)
   doi: [30]10.1561/2200000058
   cite as: [31]arxiv:1712.07897 [stat.ml]
     (or [32]arxiv:1712.07897v1 [stat.ml] for this version)

submission history

   from: purushottam kar [[33]view email]
   [v1] thu, 21 dec 2017 12:05:40 utc (958 kb)
   [34]which authors of this paper are endorsers? | [35]disable mathjax
   ([36]what is mathjax?) [37]browse v0.1 released 2018-10-22   (button)
   feedback?

     * [38]about arxiv
     * [39]leadership team

     * [40]contact us
     * [41]follow us on twitter

     * [42]help
     * [43]privacy policy

     * [44]blog
     * [45]subscribe

   arxiv   is a registered trademark of cornell university.

   if you have a disability and are having trouble accessing information
   on this website or need materials in an alternate format, contact
   [46]web-accessibility@cornell.edu for assistance.

references

   1. https://www.cornell.edu/
   2. https://confluence.cornell.edu/x/allrf
   3. https://arxiv.org/
   4. https://arxiv.org/list/stat/recent
   5. https://arxiv.org/help
   6. https://arxiv.org/search/advanced
   7. https://arxiv.org/pdf/1712.07897
   8. https://arxiv.org/format/1712.07897
   9. http://arxiv.org/licenses/nonexclusive-distrib/1.0/
  10. https://arxiv.org/prevnext?site=arxiv.org&id=1712.07897&function=prev&context=stat.ml
  11. https://arxiv.org/prevnext?site=arxiv.org&id=1712.07897&function=next&context=stat.ml
  12. https://arxiv.org/list/stat.ml/new
  13. https://arxiv.org/list/stat.ml/recent
  14. https://arxiv.org/list/stat.ml/1712
  15. https://arxiv.org/abs/1712.07897?context=cs
  16. https://arxiv.org/abs/1712.07897?context=cs.lg
  17. https://arxiv.org/abs/1712.07897?context=math
  18. https://arxiv.org/abs/1712.07897?context=math.oc
  19. https://arxiv.org/abs/1712.07897?context=stat
  20. https://ui.adsabs.harvard.edu/#abs/arxiv:1712.07897
  21. https://arxiv.org/help/social_bookmarking
  22. https://arxiv.org/ct?url=http://www.citeulike.org/posturl?url=https://arxiv.org/abs/1712.07897&v=f7901c11
  23. https://arxiv.org/ct?url=http://www.bibsonomy.org/bibtexhandler?requtask=upload&url=https://arxiv.org/abs/1712.07897&description=non-convex+optimization+for+machine+learning&v=704780a3
  24. https://arxiv.org/ct?url=https://www.mendeley.com/import/?url=https://arxiv.org/abs/1712.07897&v=a3cd6537
  25. https://arxiv.org/ct?url=https://reddit.com/submit?url=https://arxiv.org/abs/1712.07897&title=non-convex+optimization+for+machine+learning&v=4461037e
  26. https://arxiv.org/ct?url=http://sciencewise.info/bookmarks/add?url=https://arxiv.org/abs/1712.07897&v=831689fa
  27. https://arxiv.org/search/stat?searchtype=author&query=jain,+p
  28. https://arxiv.org/search/stat?searchtype=author&query=kar,+p
  29. http://dx.doi.org/10.1561/2200000058
  30. https://arxiv.org/ct?url=https://dx.doi.org/10.1561%2f2200000058&v=b8c89aba
  31. https://arxiv.org/abs/1712.07897
  32. https://arxiv.org/abs/1712.07897v1
  33. https://arxiv.org/show-email/0d0c34ca/1712.07897
  34. https://arxiv.org/auth/show-endorsers/1712.07897
  35. javascript:setmathjaxcookie()
  36. https://arxiv.org/help/mathjax
  37. https://confluence.cornell.edu/x/mjmlfq
  38. https://arxiv.org/about
  39. https://arxiv.org/about/people/leadership_team
  40. https://arxiv.org/help/contact
  41. https://twitter.com/arxiv
  42. https://arxiv.org/help
  43. https://arxiv.org/help/policies/privacy_policy
  44. https://blogs.cornell.edu/arxiv
  45. https://arxiv.org/help/subscribe
  46. mailto:web-accessibility@cornell.edu
