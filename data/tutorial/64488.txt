id76     boyd & vandenberghe

1. introduction

    mathematical optimization
    least-squares and id135
    id76
    example
    course goals and topics
    nonlinear optimization
    brief history of id76

1   1

mathematical optimization

(mathematical) optimization problem

f0(x)

minimize
subject to fi(x)     bi,

i = 1, . . . , m

    x = (x1, . . . , xn): optimization variables
    f0 : rn     r: objective function
    fi : rn     r, i = 1, . . . , m: constraint functions

optimal solution x    has smallest value of f0 among all vectors that
satisfy the constraints

introduction

1   2

examples

portfolio optimization
    variables: amounts invested in di   erent assets
    constraints: budget, max./min. investment per asset, minimum return
    objective: overall risk or return variance
device sizing in electronic circuits
    variables: device widths and lengths
    constraints: manufacturing limits, timing requirements, maximum area
    objective: power consumption
data    tting
    variables: model parameters
    constraints: prior information, parameter limits
    objective: measure of mis   t or prediction error

introduction

1   3

solving optimization problems

general optimization problem

    very di   cult to solve
    methods involve some compromise, e.g., very long computation time, or

not always    nding the solution

exceptions: certain problem classes can be solved e   ciently and reliably

    least-squares problems
    id135 problems
    id76 problems

introduction

1   4

least-squares

minimize kax     bk2

2

solving least-squares problems

    analytical solution: x    = (at a)   1at b
    reliable and e   cient algorithms and software
    computation time proportional to n2k (a     rk  n); less if structured
    a mature technology

using least-squares

    least-squares problems are easy to recognize
    a few standard techniques increase    exibility (e.g., including weights,

adding id173 terms)

introduction

1   5

id135

minimize
subject to at

ct x
i x     bi,

i = 1, . . . , m

solving linear programs

    no analytical formula for solution
    reliable and e   cient algorithms and software
    computation time proportional to n2m if m     n; less with structure
    a mature technology
using id135

    not as easy to recognize as least-squares problems
    a few standard tricks used to convert problems into linear programs
(e.g., problems involving    1- or       -norms, piecewise-linear functions)

introduction

1   6

id76 problem

f0(x)

minimize
subject to fi(x)     bi,

i = 1, . . . , m

    objective and constraint functions are convex:

fi(  x +   y)       fi(x) +   fi(y)

if    +    = 1,        0,        0

    includes least-squares problems and linear programs as special cases

introduction

1   7

solving id76 problems

    no analytical solution
    reliable and e   cient algorithms
    computation time (roughly) proportional to max{n3, n2m, f}, where f

is cost of evaluating fi   s and their    rst and second derivatives

    almost a technology

using id76

    often di   cult to recognize
    many tricks for transforming problems into convex form
    surprisingly many problems can be solved via id76

introduction

1   8

example

m lamps illuminating n (small,    at) patches

lamp power pj

rkj

  kj

illumination ik

intensity ik at patch k depends linearly on lamp powers pj:

ik =

mxj=1

akjpj,

akj = r   2

kj max{cos   kj, 0}

problem: achieve desired illumination ides with bounded lamp powers

minimize maxk=1,...,n | log ik     log ides|
subject to 0     pj     pmax,
j = 1, . . . , m

introduction

1   9

how to solve?

1. use uniform power: pj = p, vary p

2. use least-squares:

minimize pn

k=1(ik     ides)2

round pj if pj > pmax or pj < 0

3. use weighted least-squares:

minimize pn

k=1(ik     ides)2 +pm

iteratively adjust weights wj until 0     pj     pmax

j=1 wj(pj     pmax/2)2

4. use id135:

minimize maxk=1,...,n |ik     ides|
subject to 0     pj     pmax,

j = 1, . . . , m

which can be solved via id135

of course these are approximate (suboptimal)    solutions   

introduction

1   10

5. use id76: problem is equivalent to

minimize
subject to 0     pj     pmax,

f0(p) = maxk=1,...,n h(ik/ides)
j = 1, . . . , m

with h(u) = max{u, 1/u}

)
u
(
h

5

4

3

2

1

0
0

1

2
u

3

4

f0 is convex because maximum of convex functions is convex

exact solution obtained with e   ort     modest factor    least-squares e   ort

introduction

1   11

additional constraints: does adding 1 or 2 below complicate the problem?

1. no more than half of total power is in any 10 lamps

2. no more than half of the lamps are on (pj > 0)

    answer: with (1), still easy to solve; with (2), extremely di   cult
    moral: (untrained) intuition doesn   t always work; without the proper

background very easy problems can appear quite similar to very di   cult
problems

introduction

1   12

course goals and topics

goals

1. recognize/formulate problems (such as the illumination problem) as

id76 problems

2. develop code for problems of moderate size (1000 lamps, 5000 patches)

3. characterize optimal solution (optimal power distribution), give limits of

performance, etc.

topics

1. convex sets, functions, optimization problems

2. examples and applications

3. algorithms

introduction

1   13

nonlinear optimization

traditional techniques for general nonconvex problems involve compromises

local optimization methods (nonid135)
       nd a point that minimizes f0 among feasible points near it
    fast, can handle large problems
    require initial guess
    provide no information about distance to (global) optimum

global optimization methods
       nd the (global) solution
    worst-case complexity grows exponentially with problem size

these algorithms are often based on solving convex subproblems

introduction

1   14

brief history of id76

theory (convex analysis): ca1900   1970

algorithms
    1947: simplex algorithm for id135 (dantzig)
    1960s: early interior-point methods (fiacco & mccormick, dikin, . . . )
    1970s: ellipsoid method and other subgradient methods
    1980s: polynomial-time interior-point methods for id135

(karmarkar 1984)

    late 1980s   now: polynomial-time interior-point methods for nonlinear

id76 (nesterov & nemirovski 1994)

applications
    before 1990: mostly in operations research; few in engineering
    since 1990: many new applications in engineering (control, signal

processing, communications, circuit design, . . . ); new problem classes
(semide   nite and second-order cone programming, robust optimization)

introduction

1   15

id76     boyd & vandenberghe

2. convex sets

    a   ne and convex sets
    some important examples
    operations that preserve convexity
    generalized inequalities
    separating and supporting hyperplanes
    dual cones and generalized inequalities

2   1

a   ne set

line through x1, x2: all points

x =   x1 + (1       )x2

(       r)

   = 1.2

   = 1

x1

   = 0.6

x2

   = 0
   =    0.2

a   ne set: contains the line through any two distinct points in the set

example: solution set of linear equations {x | ax = b}
(conversely, every a   ne set can be expressed as solution set of system of
linear equations)

convex sets

2   2

convex set

line segment between x1 and x2: all points

x =   x1 + (1       )x2

with 0            1

convex set: contains line segment between any two points in the set

x1, x2     c,

0            1 =      x1 + (1       )x2     c

examples (one convex, two nonconvex sets)

convex sets

2   3

convex combination and convex hull

convex combination of x1,. . . , xk: any point x of the form

x =   1x1 +   2x2 +        +   kxk

with   1 +        +   k = 1,   i     0

convex hull conv s: set of all convex combinations of points in s

convex sets

2   4

convex cone

conic (nonnegative) combination of x1 and x2: any point of the form

x =   1x1 +   2x2

with   1     0,   2     0

x1

0

x2

convex cone: set that contains all conic combinations of points in the set

convex sets

2   5

hyperplanes and halfspaces

hyperplane: set of the form {x | at x = b} (a 6= 0)

a

x0

x

at x = b

halfspace: set of the form {x | at x     b} (a 6= 0)

a

at x     b

x0

at x     b

    a is the normal vector
    hyperplanes are a   ne and convex; halfspaces are convex

convex sets

2   6

euclidean balls and ellipsoids

(euclidean) ball with center xc and radius r:

b(xc, r) = {x | kx     xck2     r} = {xc + ru | kuk2     1}

ellipsoid: set of the form

{x | (x     xc)t p    1(x     xc)     1}

with p     sn

++ (i.e., p symmetric positive de   nite)

xc

other representation: {xc + au | kuk2     1} with a square and nonsingular

convex sets

2   7

norm balls and norm cones

norm: a function k    k that satis   es
    kxk     0; kxk = 0 if and only if x = 0
    ktxk = |t|kxk for t     r
    kx + yk     kxk + kyk
notation: k    k is general (unspeci   ed) norm; k    ksymb is particular norm
norm ball with center xc and radius r: {x | kx     xck     r}

norm cone: {(x, t) | kxk     t}
euclidean norm cone is called second-
order cone

1

0.5

t

0
1

norm balls and cones are convex

0

x2

   1

   1

0

x1

1

convex sets

2   8

polyhedra

solution set of    nitely many linear inequalities and equalities

ax (cid:22) b,

cx = d

(a     rm  n, c     rp  n, (cid:22) is componentwise inequality)

a1

a2

a5

p

a3

a4

polyhedron is intersection of    nite number of halfspaces and hyperplanes

convex sets

2   9

positive semide   nite cone

notation:
    sn is set of symmetric n    n matrices
    sn

+ = {x     sn | x (cid:23) 0}: positive semide   nite n    n matrices

x     sn

+        zt xz     0 for all z

sn
+ is a convex cone
    sn
++ = {x     sn | x     0}: positive de   nite n    n matrices

example: (cid:20) x y

z (cid:21)     s2

y

+

1

0.5

z

0
1

0

y

   1

0

0.5

x

1

convex sets

2   10

operations that preserve convexity

practical methods for establishing convexity of a set c

1. apply de   nition

x1, x2     c,

0            1 =      x1 + (1       )x2     c

2. show that c is obtained from simple convex sets (hyperplanes,

halfspaces, norm balls, . . . ) by operations that preserve convexity
    intersection
    a   ne functions
    perspective function
    linear-fractional functions

convex sets

2   11

intersection

the intersection of (any number of) convex sets is convex

example:

s = {x     rm | |p(t)|     1 for |t|       /3}

where p(t) = x1 cos t + x2 cos 2t +        + xm cos mt
for m = 2:

1

0

   1

)
t
(
p

2

1

2
x

0

   1

s

0

  /3

2  /3

  

t

   2

   2

   1

0
x1

1

2

convex sets

2   12

a   ne function

suppose f : rn     rm is a   ne (f (x) = ax + b with a     rm  n, b     rm)
    the image of a convex set under f is convex

s     rn convex =    f (s) = {f (x) | x     s} convex

    the inverse image f    1(c) of a convex set under f is convex

c     rm convex =    f    1(c) = {x     rn | f (x)     c} convex

examples

    scaling, translation, projection
    solution set of linear matrix inequality {x | x1a1 +        + xmam (cid:22) b}

(with ai, b     sp)

    hyperbolic cone {x | xt p x     (ct x)2, ct x     0} (with p     sn
+)

convex sets

2   13

perspective and linear-fractional function

perspective function p : rn+1     rn:

p (x, t) = x/t,

dom p = {(x, t) | t > 0}

images and inverse images of convex sets under perspective are convex

linear-fractional function f : rn     rm:

f (x) =

ax + b
ct x + d

,

dom f = {x | ct x + d > 0}

images and inverse images of convex sets under linear-fractional functions
are convex

convex sets

2   14

example of a linear-fractional function

f (x) =

1

x1 + x2 + 1

x

1

2
x

0

   1

   1

c

0
x1

1

2
x

0

f (c)

1

   1

   1

0
x1

1

convex sets

2   15

generalized inequalities

a convex cone k     rn is a proper cone if
    k is closed (contains its boundary)
    k is solid (has nonempty interior)
    k is pointed (contains no line)

examples
    nonnegative orthant k = rn
    positive semide   nite cone k = sn
    nonnegative polynomials on [0, 1]:

+

+ = {x     rn | xi     0, i = 1, . . . , n}

k = {x     rn | x1 + x2t + x3t2 +        + xntn   1     0 for t     [0, 1]}

convex sets

2   16

generalized inequality de   ned by a proper cone k:

x (cid:22)k y        y     x     k,

x    k y        y     x     int k

examples
    componentwise inequality (k = rn
+)

x (cid:22)rn

+

y        xi     yi,

i = 1, . . . , n

    matrix inequality (k = sn
+)

x (cid:22)sn

+

y        y     x positive semide   nite

these two types are so common that we drop the subscript in (cid:22)k
properties: many properties of (cid:22)k are similar to     on r, e.g.,

x (cid:22)k y,

u (cid:22)k v =    x + u (cid:22)k y + v

convex sets

2   17

minimum and minimal elements

(cid:22)k is not in general a linear ordering : we can have x 6(cid:22)k y and y 6(cid:22)k x
x     s is the minimum element of s with respect to (cid:22)k if

y     s =    x (cid:22)k y

x     s is a minimal element of s with respect to (cid:22)k if

y     s,

y (cid:22)k x =    y = x

example (k = r2

+)

x1 is the minimum element of s1
x2 is a minimal element of s2

x1

s1

s2

x2

convex sets

2   18

separating hyperplane theorem

if c and d are nonempty disjoint convex sets, there exist a 6= 0, b s.t.

at x     b for x     c,

at x     b for x     d

at x     b

at x     b

d

c

a

the hyperplane {x | at x = b} separates c and d
strict separation requires additional assumptions (e.g., c is closed, d is a
singleton)

convex sets

2   19

supporting hyperplane theorem

supporting hyperplane to set c at boundary point x0:

{x | at x = at x0}

where a 6= 0 and at x     at x0 for all x     c

a

x0

c

supporting hyperplane theorem: if c is convex, then there exists a
supporting hyperplane at every boundary point of c

convex sets

2   20

dual cones and generalized inequalities

dual cone of a cone k:

k     = {y | yt x     0 for all x     k}

+: k     = rn
+
+: k     = sn
+

examples
    k = rn
    k = sn
    k = {(x, t) | kxk2     t}: k     = {(x, t) | kxk2     t}
    k = {(x, t) | kxk1     t}: k     = {(x, t) | kxk        t}
   rst three examples are self-dual cones

dual cones of proper cones are proper, hence de   ne generalized inequalities:

y (cid:23)k    0        yt x     0 for all x (cid:23)k 0

convex sets

2   21

minimum and minimal elements via dual inequalities

minimum element w.r.t. (cid:22)k
x is minimum element of s i    for all
      k    0, x is the unique minimizer
of   t z over s

s

x

minimal element w.r.t. (cid:22)k
    if x minimizes   t z over s for some       k    0, then x is minimal

  1

x1

s

x2

  2

    if x is a minimal element of a convex set s, then there exists a nonzero

   (cid:23)k    0 such that x minimizes   t z over s

convex sets

2   22

optimal production frontier

    di   erent production methods use di   erent amounts of resources x     rn
    production set p : resource vectors x for all possible production methods
    e   cient (pareto optimal) methods correspond to resource vectors x

that are minimal w.r.t. rn
+

example (n = 2)

x1, x2, x3 are e   cient; x4, x5 are not

convex sets

fuel

x1

p

x2

x5

x4
  

x3

labor

2   23

id76     boyd & vandenberghe

3. convex functions

    basic properties and examples
    operations that preserve convexity
    the conjugate function
    quasiconvex functions
    log-concave and log-convex functions
    convexity with respect to generalized inequalities

3   1

de   nition

f : rn     r is convex if dom f is a convex set and

f (  x + (1       )y)       f (x) + (1       )f (y)

for all x, y     dom f , 0            1

(x, f (x))

(y, f (y))

    f is concave if    f is convex
    f is strictly convex if dom f is convex and

f (  x + (1       )y) <   f (x) + (1       )f (y)

for x, y     dom f , x 6= y, 0 <    < 1

convex functions

3   2

examples on r

convex:
    a   ne: ax + b on r, for any a, b     r
    exponential: eax, for any a     r
    powers: x   on r++, for        1 or        0
    powers of absolute value: |x|p on r, for p     1
    negative id178: x log x on r++

concave:
    a   ne: ax + b on r, for any a, b     r
    powers: x   on r++, for 0            1
    logarithm: log x on r++

convex functions

3   3

examples on rn and rm  n

a   ne functions are convex and concave; all norms are convex

examples on rn
    a   ne function f (x) = at x + b

    norms: kxkp = (pn
examples on rm  n (m    n matrices)
    a   ne function

i=1 |xi|p)1/p for p     1; kxk    = maxk |xk|

f (x) = tr(at x) + b =

mxi=1

nxj=1

aijxij + b

    spectral (maximum singular value) norm

f (x) = kxk2 =   max(x) = (  max(x t x))1/2

convex functions

3   4

restriction of a convex function to a line

f : rn     r is convex if and only if the function g : r     r,

g(t) = f (x + tv),

dom g = {t | x + tv     dom f}

is convex (in t) for any x     dom f , v     rn
can check convexity of f by checking convexity of functions of one variable
example. f : sn     r with f (x) = log det x, dom f = sn
g(t) = log det(x + tv ) = log det x + log det(i + tx    1/2v x    1/2)

++

= log det x +

log(1 + t  i)

nxi=1

where   i are the eigenvalues of x    1/2v x    1/2

g is concave in t (for any choice of x     0, v ); hence f is concave

convex functions

3   5

extended-value extension

extended-value extension   f of f is

  f (x) = f (x),

x     dom f,

  f (x) =    ,

x 6    dom f

often simpli   es notation; for example, the condition

0            1 =      f (  x + (1       )y)          f (x) + (1       )   f (y)
(as an inequality in r     {   }), means the same as the two conditions

    dom f is convex
    for x, y     dom f ,

0            1 =    f (  x + (1       )y)       f (x) + (1       )f (y)

convex functions

3   6

first-order condition

f is di   erentiable if dom f is open and the gradient

   f (x) =(cid:18)   f (x)

   x1

,

   f (x)
   x2

, . . . ,

   f (x)

   xn (cid:19)

exists at each x     dom f
1st-order condition: di   erentiable f with convex domain is convex i   

f (y)     f (x) +    f (x)t (y     x)

for all x, y     dom f

f (y)

f (x) +    f (x)t (y     x)

(x, f (x))

   rst-order approximation of f is global underestimator

convex functions

3   7

second-order conditions

f is twice di   erentiable if dom f is open and the hessian    2f (x)     sn,

   2f (x)ij =

   2f (x)
   xi   xj

,

i, j = 1, . . . , n,

exists at each x     dom f
2nd-order conditions: for twice di   erentiable f with convex domain

    f is convex if and only if

   2f (x) (cid:23) 0

for all x     dom f

    if    2f (x)     0 for all x     dom f , then f is strictly convex

convex functions

3   8

examples

quadratic function: f (x) = (1/2)xt p x + qt x + r (with p     sn)

   f (x) = p x + q,

   2f (x) = p

convex if p (cid:23) 0
least-squares objective: f (x) = kax     bk2

2

   f (x) = 2at (ax     b),

   2f (x) = 2at a

convex (for any a)

quadratic-over-linear: f (x, y) = x2/y

   2f (x, y) =

2

y3(cid:20) y

   x (cid:21)(cid:20) y

   x (cid:21)t

(cid:23) 0

convex for y > 0

convex functions

)
y
,
x
(
f

2

1

0
2

1
y

0

   2

0
x

2

3   9

log-sum-exp: f (x) = logpn

k=1 exp xk is convex

1

   2f (x) =

1t z

diag(z)    

1

(1t z)2zzt

(zk = exp xk)

to show    2f (x) (cid:23) 0, we must verify that vt   2f (x)v     0 for all v:

vt   2f (x)v =
since (pk vkzk)2     (pk zkv2
geometric mean: f (x) = (qn

(similar proof as for log-sum-exp)

k)(pk zk)     (pk vkzk)2
(pk zk)2

(pk zkv2
k)(pk zk) (from cauchy-schwarz inequality)

    0

k=1 xk)1/n on rn

++ is concave

convex functions

3   10

epigraph and sublevel set

  -sublevel set of f : rn     r:

c   = {x     dom f | f (x)       }

sublevel sets of convex functions are convex (converse is false)
epigraph of f : rn     r:

epi f = {(x, t)     rn+1 | x     dom f, f (x)     t}

epi f

f

f is convex if and only if epi f is a convex set

convex functions

3   11

jensen   s inequality

basic inequality: if f is convex, then for 0            1,

f (  x + (1       )y)       f (x) + (1       )f (y)

extension: if f is convex, then

f (e z)     e f (z)

for any random variable z

basic inequality is special case with discrete distribution

prob(z = x) =   ,

prob(z = y) = 1       

convex functions

3   12

operations that preserve convexity

practical methods for establishing convexity of a function

1. verify de   nition (often simpli   ed by restricting to a line)

2. for twice di   erentiable functions, show    2f (x) (cid:23) 0
3. show that f is obtained from simple convex functions by operations

that preserve convexity

    nonnegative weighted sum
    composition with a   ne function
    pointwise maximum and supremum
    composition
    minimization
    perspective

convex functions

3   13

positive weighted sum & composition with a   ne function

nonnegative multiple:   f is convex if f is convex,        0
sum: f1 + f2 convex if f1, f2 convex (extends to in   nite sums, integrals)

composition with a   ne function: f (ax + b) is convex if f is convex

examples

    log barrier for linear inequalities

f (x) =    

mxi=1

log(bi     at

i x),

dom f = {x | at

i x < bi, i = 1, . . . , m}

    (any) norm of a   ne function: f (x) = kax + bk

convex functions

3   14

pointwise maximum

if f1, . . . , fm are convex, then f (x) = max{f1(x), . . . , fm(x)} is convex

examples

    piecewise-linear function: f (x) = maxi=1,...,m(at
    sum of r largest components of x     rn:

i x + bi) is convex

f (x) = x[1] + x[2] +        + x[r]

is convex (x[i] is ith largest component of x)

proof:

f (x) = max{xi1 + xi2 +        + xir | 1     i1 < i2 <        < ir     n}

convex functions

3   15

pointwise supremum

if f (x, y) is convex in x for each y     a, then
f (x, y)

g(x) = sup
y   a

is convex

examples
    support function of a set c: sc(x) = supy   c yt x is convex
    distance to farthest point in a set c:
f (x) = sup

y   c kx     yk

    maximum eigenvalue of symmetric matrix: for x     sn,

  max(x) = sup

yt xy

kyk2=1

convex functions

3   16

composition with scalar functions

composition of g : rn     r and h : r     r:
f (x) = h(g(x))

f is convex if

g convex, h convex,   h nondecreasing
g concave, h convex,   h nonincreasing

    proof (for n = 1, di   erentiable g, h)

f       (x) = h      (g(x))g   (x)2 + h   (g(x))g      (x)

    note: monotonicity must hold for extended-value extension   h
examples
    exp g(x) is convex if g is convex
    1/g(x) is convex if g is concave and positive

convex functions

3   17

vector composition

composition of g : rn     rk and h : rk     r:

f (x) = h(g(x)) = h(g1(x), g2(x), . . . , gk(x))

f is convex if

gi convex, h convex,   h nondecreasing in each argument
gi concave, h convex,   h nonincreasing in each argument

proof (for n = 1, di   erentiable g, h)

f       (x) = g   (x)t   2h(g(x))g   (x) +    h(g(x))t g      (x)

examples

i=1 log gi(x) is concave if gi are concave and positive

i=1 exp gi(x) is convex if gi are convex

    pm
    logpm

convex functions

3   18

minimization

if f (x, y) is convex in (x, y) and c is a convex set, then

g(x) = inf
y   c

f (x, y)

is convex

examples
    f (x, y) = xt ax + 2xt by + yt cy with

(cid:20) a b
bt c (cid:21) (cid:23) 0,

c     0

minimizing over y gives g(x) = inf y f (x, y) = xt (a     bc    1bt )x
g is convex, hence schur complement a     bc    1bt (cid:23) 0

    distance to a set: dist(x, s) = inf y   s kx     yk is convex if s is convex

convex functions

3   19

perspective

the perspective of a function f : rn     r is the function g : rn    r     r,

g(x, t) = tf (x/t),

dom g = {(x, t) | x/t     dom f, t > 0}

g is convex if f is convex

examples
    f (x) = xt x is convex; hence g(x, t) = xt x/t is convex for t > 0
    negative logarithm f (x) =     log x is convex; hence relative id178

g(x, t) = t log t     t log x is convex on r2

++

    if f is convex, then

g(x) = (ct x + d)f(cid:0)(ax + b)/(ct x + d)(cid:1)

is convex on {x | ct x + d > 0, (ax + b)/(ct x + d)     dom f}

convex functions

3   20

the conjugate function

the conjugate of a function f is

f    (y) = sup

x   dom f

(yt x     f (x))

f (x)

xy

x

(0,    f    (y))

    f     is convex (even if f is not)
    will be useful in chapter 5

convex functions

3   21

examples

    negative logarithm f (x) =     log x

f    (y) = sup
x>0

(xy + log x)

= (cid:26)    1     log(   y) y < 0

   

otherwise

    strictly convex quadratic f (x) = (1/2)xt qx with q     sn

++

f    (y) = sup
x
1
2

=

(yt x     (1/2)xt qx)
yt q   1y

convex functions

3   22

quasiconvex functions

f : rn     r is quasiconvex if dom f is convex and the sublevel sets

s   = {x     dom f | f (x)       }

are convex for all   

  

  

a

b

c

    f is quasiconcave if    f is quasiconvex
    f is quasilinear if it is quasiconvex and quasiconcave

convex functions

3   23

examples

    p|x| is quasiconvex on r

    ceil(x) = inf{z     z | z     x} is quasilinear
    log x is quasilinear on r++
    f (x1, x2) = x1x2 is quasiconcave on r2
    linear-fractional function

++

f (x) =

at x + b
ct x + d

,

dom f = {x | ct x + d > 0}

is quasilinear
    distance ratio

f (x) = kx     ak2
kx     bk2

,

is quasiconvex

dom f = {x | kx     ak2     kx     bk2}

convex functions

3   24

internal rate of return

    cash    ow x = (x0, . . . , xn); xi is payment in period i (to us if xi > 0)
    we assume x0 < 0 and x0 + x1 +        + xn > 0
    present value of cash    ow x, for interest rate r:

pv(x, r) =

(1 + r)   ixi

nxi=0

    internal rate of return is smallest interest rate for which pv(x, r) = 0:

irr(x) = inf{r     0 | pv(x, r) = 0}

irr is quasiconcave: superlevel set is intersection of open halfspaces

irr(x)     r       

nxi=0

(1 + r)   ixi > 0 for 0     r < r

convex functions

3   25

properties

modi   ed jensen inequality: for quasiconvex f

0            1 =    f (  x + (1       )y)     max{f (x), f (y)}

   rst-order condition: di   erentiable f with cvx domain is quasiconvex i   

f (y)     f (x) =       f (x)t (y     x)     0

   f (x)

x

sums of quasiconvex functions are not necessarily quasiconvex

convex functions

3   26

log-concave and log-convex functions

a positive function f is log-concave if log f is concave:

f (  x + (1       )y)     f (x)  f (y)1     

for 0            1

f is log-convex if log f is convex

    powers: xa on r++ is log-convex for a     0, log-concave for a     0
    many common id203 densities are log-concave, e.g., normal:

    cumulative gaussian distribution function    is log-concave

f (x) =

e    1

2(x     x)t      1(x     x)

1

p(2  )n det   
   2  z x

1

  (x) =

      

e   u2/2 du

convex functions

3   27

properties of log-concave functions

    twice di   erentiable f with convex domain is log-concave if and only if

f (x)   2f (x) (cid:22)    f (x)   f (x)t

for all x     dom f

    product of log-concave functions is log-concave
    sum of log-concave functions is not always log-concave
    integration: if f : rn    rm     r is log-concave, then

g(x) =z f (x, y) dy

is log-concave (not easy to show)

convex functions

3   28

consequences of integration property

    convolution f     g of log-concave functions f , g is log-concave

(f     g)(x) =z f (x     y)g(y)dy

    if c     rn convex and y is a random variable with log-concave pdf then

f (x) = prob(x + y     c)

is log-concave

proof: write f (x) as integral of product of log-concave functions

f (x) =z g(x + y)p(y) dy,

g(u) =(cid:26) 1 u     c

0 u 6    c,

p is pdf of y

convex functions

3   29

example: yield function

y (x) = prob(x + w     s)
    x     rn: nominal parameter values for product
    w     rn: random variations of parameters in manufactured product
    s: set of acceptable values

if s is convex and w has a log-concave pdf, then

    y is log-concave
    yield regions {x | y (x)       } are convex

convex functions

3   30

convexity with respect to generalized inequalities

f : rn     rm is k-convex if dom f is convex and

f (  x + (1       )y) (cid:22)k   f (x) + (1       )f (y)

for x, y     dom f , 0            1
example f : sm     sm, f (x) = x 2 is sm
proof: for    xed z     rm, zt x 2z = kxzk2

+ -convex

2 is convex in x, i.e.,

zt (  x + (1       )y )2z       zt x 2z + (1       )zt y 2z

for x, y     sm, 0            1

therefore (  x + (1       )y )2 (cid:22)   x 2 + (1       )y 2

convex functions

3   31

4. id76 problems

id76     boyd & vandenberghe

    optimization problem in standard form
    id76 problems
    quasiid76
    linear optimization
    quadratic optimization
    geometric programming
    generalized inequality constraints
    semide   nite programming
    vector optimization

4   1

optimization problem in standard form

f0(x)

minimize
subject to fi(x)     0,
hi(x) = 0,

i = 1, . . . , m
i = 1, . . . , p

    x     rn is the optimization variable
    f0 : rn     r is the objective or cost function
    fi : rn     r, i = 1, . . . , m, are the inequality constraint functions
    hi : rn     r are the equality constraint functions
optimal value:

p    = inf{f0(x) | fi(x)     0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p}

    p    =     if problem is infeasible (no x satis   es the constraints)
    p    =        if problem is unbounded below

id76 problems

4   2

optimal and locally optimal points

x is feasible if x     dom f0 and it satis   es the constraints
a feasible x is optimal if f0(x) = p   ; xopt is the set of optimal points

x is locally optimal if there is an r > 0 such that x is optimal for

minimize (over z) f0(z)
subject to

fi(z)     0,
kz     xk2     r

i = 1, . . . , m,

hi(z) = 0,

i = 1, . . . , p

examples (with n = 1, m = p = 0)
    f0(x) = 1/x, dom f0 = r++: p    = 0, no optimal point
    f0(x) =     log x, dom f0 = r++: p    =       
    f0(x) = x log x, dom f0 = r++: p    =    1/e, x = 1/e is optimal
    f0(x) = x3     3x, p    =       , local optimum at x = 1

id76 problems

4   3

implicit constraints

the standard form optimization problem has an implicit constraint

x     d =

m\i=0

dom fi    

p\i=1

dom hi,

    we call d the domain of the problem
    the constraints fi(x)     0, hi(x) = 0 are the explicit constraints
    a problem is unconstrained if it has no explicit constraints (m = p = 0)

example:

i=1 log(bi     at
is an unconstrained problem with implicit constraints at

minimize f0(x) =    pk

i x)

i x < bi

id76 problems

4   4

feasibility problem

x

   nd
subject to fi(x)     0,
hi(x) = 0,

i = 1, . . . , m
i = 1, . . . , p

can be considered a special case of the general problem with f0(x) = 0:

0

minimize
subject to fi(x)     0,
hi(x) = 0,

i = 1, . . . , m
i = 1, . . . , p

    p    = 0 if constraints are feasible; any feasible x is optimal
    p    =     if constraints are infeasible

id76 problems

4   5

id76 problem

standard form id76 problem

f0(x)

minimize
subject to fi(x)     0,
at
i x = bi,

i = 1, . . . , m
i = 1, . . . , p

    f0, f1, . . . , fm are convex; equality constraints are a   ne
    problem is quasiconvex if f0 is quasiconvex (and f1, . . . , fm convex)

often written as

f0(x)

minimize
subject to fi(x)     0,

ax = b

i = 1, . . . , m

important property: feasible set of a id76 problem is convex

id76 problems

4   6

example

minimize
subject to f1(x) = x1/(1 + x2

f0(x) = x2

1 + x2
2

2)     0
h1(x) = (x1 + x2)2 = 0

    f0 is convex; feasible set {(x1, x2) | x1 =    x2     0} is convex
    not a convex problem (according to our de   nition): f1 is not convex, h1

is not a   ne

    equivalent (but not identical) to the convex problem

x2
1 + x2
minimize
2
subject to x1     0

x1 + x2 = 0

id76 problems

4   7

local and global optima

any locally optimal point of a convex problem is (globally) optimal

proof: suppose x is locally optimal, but there exists a feasible y with
f0(y) < f0(x)

x locally optimal means there is an r > 0 such that

z feasible,

kz     xk2     r =    f0(z)     f0(x)

consider z =   y + (1       )x with    = r/(2ky     xk2)
    ky     xk2 > r, so 0 <    < 1/2
    z is a convex combination of two feasible points, hence also feasible
    kz     xk2 = r/2 and

f0(z)       f0(y) + (1       )f0(x) < f0(x)

which contradicts our assumption that x is locally optimal

id76 problems

4   8

optimality criterion for di   erentiable f0

x is optimal if and only if it is feasible and

   f0(x)t (y     x)     0

for all feasible y

      f0(x)

x

x

if nonzero,    f0(x) de   nes a supporting hyperplane to feasible set x at x

id76 problems

4   9

    unconstrained problem: x is optimal if and only if
   f0(x) = 0

x     dom f0,

    equality constrained problem
minimize f0(x)

subject to ax = b

x is optimal if and only if there exists a    such that

x     dom f0,

ax = b,

   f0(x) + at    = 0

    minimization over nonnegative orthant

minimize f0(x)

subject to x (cid:23) 0

x is optimal if and only if

x     dom f0,

x (cid:23) 0,

(cid:26)    f0(x)i     0 xi = 0

   f0(x)i = 0 xi > 0

id76 problems

4   10

equivalent convex problems

two problems are (informally) equivalent if the solution of one is readily
obtained from the solution of the other, and vice-versa

some common transformations that preserve convexity:

    eliminating equality constraints
f0(x)

minimize
subject to fi(x)     0,

ax = b

i = 1, . . . , m

is equivalent to

minimize (over z) f0(f z + x0)
subject to

fi(f z + x0)     0,

i = 1, . . . , m

where f and x0 are such that

ax = b        x = f z + x0 for some z

id76 problems

4   11

    introducing equality constraints

f0(a0x + b0)

minimize
subject to fi(aix + bi)     0,

i = 1, . . . , m

is equivalent to

minimize (over x, yi) f0(y0)
subject to

fi(yi)     0,
yi = aix + bi,

i = 1, . . . , m

i = 0, 1, . . . , m

    introducing slack variables for linear inequalities

minimize
subject to at

f0(x)
i x     bi,

i = 1, . . . , m

is equivalent to

minimize (over x, s) f0(x)
subject to

at
i x + si = bi,
si     0,

i = 1, . . . m

i = 1, . . . , m

id76 problems

4   12

    epigraph form: standard form convex problem is equivalent to

minimize (over x, t)
subject to

t
f0(x)     t     0
fi(x)     0,
ax = b

i = 1, . . . , m

    minimizing over some variables

is equivalent to

minimize
f0(x1, x2)
subject to fi(x1)     0,

i = 1, . . . , m

  f0(x1)

minimize
subject to fi(x1)     0,

i = 1, . . . , m

where   f0(x1) = inf x2 f0(x1, x2)

id76 problems

4   13

quasiid76

f0(x)

minimize
subject to fi(x)     0,

ax = b

i = 1, . . . , m

with f0 : rn     r quasiconvex, f1, . . . , fm convex

can have locally optimal points that are not (globally) optimal

(x, f0(x))

id76 problems

4   14

convex representation of sublevel sets of f0

if f0 is quasiconvex, there exists a family of functions   t such that:
      t(x) is convex in x for    xed t
    t-sublevel set of f0 is 0-sublevel set of   t, i.e.,

f0(x)     t          t(x)     0

example

f0(x) =

p(x)
q(x)

with p convex, q concave, and p(x)     0, q(x) > 0 on dom f0
can take   t(x) = p(x)     tq(x):
    for t     0,   t convex in x
    p(x)/q(x)     t if and only if   t(x)     0

id76 problems

4   15

quasiid76 via convex feasibility problems

  t(x)     0,

fi(x)     0,

i = 1, . . . , m,

ax = b

(1)

    for    xed t, a convex feasibility problem in x
    if feasible, we can conclude that t     p   ; if infeasible, t     p   

bisection method for quasiid76

given l     p   , u     p   , tolerance    > 0.
repeat

1. t := (l + u)/2.
2. solve the convex feasibility problem (1).
3. if (1) is feasible, u := t;
else l := t.

until u     l       .

requires exactly    log2((u     l)/  )    iterations (where u, l are initial values)

id76 problems

4   16

linear program (lp)

ct x + d
minimize
subject to gx (cid:22) h
ax = b

    convex problem with a   ne objective and constraint functions
    feasible set is a polyhedron

   c

x   

p

id76 problems

4   17

examples

diet problem: choose quantities x1, . . . , xn of n foods
    one unit of food j costs cj, contains amount aij of nutrient i
    healthy diet requires nutrient i in quantity at least bi
to    nd cheapest healthy diet,

ct x

minimize
subject to ax (cid:23) b,

x (cid:23) 0

piecewise-linear minimization

minimize maxi=1,...,m(at

i x + bi)

equivalent to an lp

minimize
subject to at

t

i x + bi     t,

i = 1, . . . , m

id76 problems

4   18

chebyshev center of a polyhedron

chebyshev center of

p = {x | at

i x     bi, i = 1, . . . , m}

is center of largest inscribed ball

b = {xc + u | kuk2     r}

    at

i x     bi for all x     b if and only if

xchebxcheb

sup{at

i (xc + u) | kuk2     r} = at

i xc + rkaik2     bi

    hence, xc, r can be determined by solving the lp

maximize
r
subject to at

i xc + rkaik2     bi,

i = 1, . . . , m

id76 problems

4   19

linear-fractional program

f0(x)

minimize
subject to gx (cid:22) h
ax = b

linear-fractional program

f0(x) =

ct x + d
et x + f

,

dom f0(x) = {x | et x + f > 0}

    a quasiid76 problem; can be solved by bisection
    also equivalent to the lp (variables y, z)

ct y + dz
minimize
subject to gy (cid:22) hz
ay = bz
et y + f z = 1
z     0

id76 problems

4   20

generalized linear-fractional program

f0(x) = max
i=1,...,r

ct
i x + di
et
i x + fi

,

dom f0(x) = {x | et

i x+fi > 0, i = 1, . . . , r}

a quasiid76 problem; can be solved by bisection

example: von neumann model of a growing economy

maximize (over x, x+) mini=1,...,n x+
subject to

i /xi

x+ (cid:23) 0, bx+ (cid:22) ax

    x, x+     rn: activity levels of n sectors, in current and next period
    (ax)i, (bx+)i: produced, resp. consumed, amounts of good i
    x+
allocate activity to maximize growth rate of slowest growing sector

i /xi: growth rate of sector i

id76 problems

4   21

quadratic program (qp)

(1/2)xt p x + qt x + r

minimize
subject to gx (cid:22) h
ax = b

+, so objective is convex quadratic

    p     sn
    minimize a convex quadratic function over a polyhedron

      f0(x   )

x   

p

id76 problems

4   22

least-squares

examples

minimize kax     bk2

2

    analytical solution x    = a   b (a    is pseudo-inverse)
    can add linear constraints, e.g., l (cid:22) x (cid:22) u
linear program with random cost

  ct x +   xt   x = e ct x +    var(ct x)

minimize
subject to gx (cid:22) h, ax = b

    c is random vector with mean   c and covariance   
    hence, ct x is random variable with mean   ct x and variance xt   x
       > 0 is risk aversion parameter; controls the trade-o    between

expected cost and variance (risk)

id76 problems

4   23

quadratically constrained quadratic program (qcqp)

(1/2)xt p0x + qt
minimize
subject to (1/2)xt pix + qt

0 x + r0
i x + ri     0,

ax = b

i = 1, . . . , m

    pi     sn
    if p1, . . . , pm     sn

an a   ne set

+; objective and constraints are convex quadratic

++, feasible region is intersection of m ellipsoids and

id76 problems

4   24

second-order cone programming

f t x

minimize
subject to kaix + bik2     ct

f x = g

i x + di,

i = 1, . . . , m

(ai     rni  n, f     rp  n)

    inequalities are called second-order cone (soc) constraints:
i x + di)     second-order cone in rni+1

(aix + bi, ct

    for ni = 0, reduces to an lp; if ci = 0, reduces to a qcqp
    more general than qcqp and lp

id76 problems

4   25

robust id135

the parameters in optimization problems are often uncertain, e.g., in an lp

minimize
subject to at

ct x
i x     bi,

i = 1, . . . , m,

there can be uncertainty in c, ai, bi

two common approaches to handling uncertainty (in ai, for simplicity)
    deterministic model: constraints must hold for all ai     ei

minimize
subject to at

ct x
i x     bi for all ai     ei,

i = 1, . . . , m,

    stochastic model: ai is random variable; constraints must hold with

id203   

minimize
subject to prob(at

ct x

i x     bi)       ,

i = 1, . . . , m

id76 problems

4   26

deterministic approach via socp

    choose an ellipsoid as ei:

ei = {  ai + piu | kuk2     1}

(  ai     rn, pi     rn  n)
center is   ai, semi-axes determined by singular values/vectors of pi

    robust lp

minimize
subject to at

ct x
i x     bi    ai     ei,

i = 1, . . . , m

is equivalent to the socp

minimize
subject to

ct x
i x + kp t
  at

i xk2     bi,

i = 1, . . . , m

(follows from supkuk2   1(  ai + piu)t x =   at

i x + kp t

i xk2)

id76 problems

4   27

stochastic approach via socp

    assume ai is gaussian with mean   ai, covariance   i (ai     n (  ai,   i))
    at

i x is gaussian r.v. with mean   at

i x, variance xt   ix; hence

prob(at

i x

i x     bi) =     bi       at
i xk2!
k  1/2
       e   t2/2 dt is cdf of n (0, 1)

where   (x) = (1/   2  )r x

    robust lp

minimize
subject to prob(at

ct x

i x     bi)       ,

i = 1, . . . , m,

with        1/2, is equivalent to the socp

minimize
subject to

ct x
i x +      1(  )k  1/2
  at

i xk2     bi,

i = 1, . . . , m

id76 problems

4   28

geometric programming

monomial function

f (x) = cxa1

1 xa2

2        xan
n ,

dom f = rn

++

with c > 0; exponent ai can be any real number

posynomial function: sum of monomials

f (x) =

kxk=1

ckxa1k

1 xa2k

2

       xank
n ,

dom f = rn

++

geometric program (gp)

f0(x)

minimize
subject to fi(x)     1,
hi(x) = 1,

i = 1, . . . , m
i = 1, . . . , p

with fi posynomial, hi monomial

id76 problems

4   29

geometric program in convex form

change variables to yi = log xi, and take logarithm of cost, constraints

    monomial f (x) = cxa1

1        xan

n transforms to

log f (ey1, . . . , eyn) = at y + b

(b = log c)

k=1 ckxa1k

1 xa2k

2

transforms to

    posynomial f (x) =pk

log f (ey1, . . . , eyn) = log  kxk=1

n

       xank
k y+bk!

eat

    geometric program transforms to convex problem

minimize

log(cid:16)pk
subject to log(cid:16)pk

gy + d = 0

k=1 exp(at
k=1 exp(at

0ky + b0k)(cid:17)
iky + bik)(cid:17)     0,

(bk = log ck)

i = 1, . . . , m

id76 problems

4   30

design of cantilever beam

segment 4 segment 3 segment 2 segment 1

    n segments with unit lengths, rectangular cross-sections of size wi    hi
    given vertical force f applied at the right end

f

design problem

minimize
subject to upper & lower bounds on wi, hi

total weight

upper bound & lower bounds on aspect ratios hi/wi
upper bound on stress in each segment
upper bound on vertical de   ection at the end of the beam

variables: wi, hi for i = 1, . . . , n

id76 problems

4   31

objective and constraint functions

    total weight w1h1 +        + wnhn is posynomial
    aspect ratio hi/wi and inverse aspect ratio wi/hi are monomials
    maximum stress in segment i is given by 6if/(wih2
i ), a monomial
    the vertical de   ection yi and slope vi of central axis at the right end of

segment i are de   ned recursively as

vi = 12(i     1/2)

+ vi+1

yi = 6(i     1/3)

+ vi+1 + yi+1

f

ewih3
i
f

ewih3
i

for i = n, n     1, . . . , 1, with vn +1 = yn +1 = 0 (e is young   s modulus)
vi and yi are posynomial functions of w, h

id76 problems

4   32

formulation as a gp

minimize w1h1 +        + wnhn
maxwi     1, wminw   1
subject to w   1
i     1,
hminh   1
h   1
maxhi     1,
i     1,
maxw   1
i hi     1, sminwih   1
s   1
maxw   1
6if      1
y   1
maxy1     1

i     1,

i h   2

i     1,
i = 1, . . . , n

i = 1, . . . , n

i = 1, . . . , n

note

    we write wmin     wi     wmax and hmin     hi     hmax
hmin/hi     1,

wi/wmax     1,

wmin/wi     1,

i = 1, . . . , n

hi/hmax     1

    we write smin     hi/wi     smax as
sminwi/hi     1,

hi/(wismax)     1

id76 problems

4   33

minimizing spectral radius of nonnegative matrix

perron-frobenius eigenvalue   pf(a)
    exists for (elementwise) positive a     rn  n
    a real, positive eigenvalue of a, equal to spectral radius maxi |  i(a)|
    determines asymptotic growth (decay) rate of ak: ak       k
pf as k        
    alternative characterization:   pf(a) = inf{   | av (cid:22)   v for some v     0}
minimizing spectral radius of matrix of posynomials

    minimize   pf(a(x)), where the elements a(x)ij are posynomials of x
    equivalent geometric program:

  

minimize

subject to pn

variables   , v, x

j=1 a(x)ijvj/(  vi)     1,

i = 1, . . . , n

id76 problems

4   34

generalized inequality constraints

convex problem with generalized inequality constraints

f0(x)

minimize
subject to fi(x) (cid:22)ki 0,

ax = b

i = 1, . . . , m

    f0 : rn     r convex; fi : rn     rki ki-convex w.r.t. proper cone ki
    same properties as standard convex problem (convex feasible set, local

optimum is global, etc.)

conic form problem: special case with a   ne objective and constraints

ct x

minimize
subject to f x + g (cid:22)k 0

ax = b

extends id135 (k = rm

+ ) to nonpolyhedral cones

id76 problems

4   35

semide   nite program (sdp)

ct x

minimize
subject to x1f1 + x2f2 +        + xnfn + g (cid:22) 0

ax = b

with fi, g     sk
    inequality constraint is called linear matrix inequality (lmi)
    includes problems with multiple lmi constraints: for example,

x1   f1 +        + xn   fn +   g (cid:22) 0,

x1   f1 +        + xn   fn +   g (cid:22) 0

is equivalent to single lmi

x1(cid:20)   f1

0

0

  f1 (cid:21)+x2(cid:20)   f2

0

0

  f2 (cid:21)+      +xn(cid:20)   fn

0

0

  fn (cid:21)+(cid:20)   g 0

  g (cid:21) (cid:22) 0

0

id76 problems

4   36

lp and socp as sdp

lp and equivalent sdp

lp: minimize

ct x

sdp: minimize

ct x

subject to ax (cid:22) b

subject to diag(ax     b) (cid:22) 0

(note di   erent interpretation of generalized inequality (cid:22))
socp and equivalent sdp

socp: minimize

f t x

subject to kaix + bik2     ct

i x + di,

i = 1, . . . , m

sdp:

f t x

minimize

subject to (cid:20) (ct

i x + di)i aix + bi

(aix + bi)t

i x + di (cid:21) (cid:23) 0,

ct

i = 1, . . . , m

id76 problems

4   37

eigenvalue minimization

minimize   max(a(x))

where a(x) = a0 + x1a1 +        + xnan (with given ai     sk)

equivalent sdp

t

minimize
subject to a(x) (cid:22) ti

    variables x     rn, t     r
    follows from

  max(a)     t        a (cid:22) ti

id76 problems

4   38

matrix norm minimization

minimize ka(x)k2 =(cid:0)  max(a(x)t a(x))(cid:1)1/2
where a(x) = a0 + x1a1 +        + xnan (with given ai     rp  q)
equivalent sdp

t

minimize

subject to (cid:20)

ti

a(x)t

a(x)

ti

(cid:21) (cid:23) 0

    variables x     rn, t     r
    constraint follows from

kak2     t        at a (cid:22) t2i,
       (cid:20) ti a

ti (cid:21) (cid:23) 0

at

t     0

id76 problems

4   39

vector optimization

general vector optimization problem

minimize (w.r.t. k) f0(x)
subject to

fi(x)     0,
hi(x) = 0,

i = 1, . . . , m
i = 1, . . . , p

vector objective f0 : rn     rq, minimized w.r.t. proper cone k     rq

convex vector optimization problem

minimize (w.r.t. k) f0(x)
subject to

fi(x)     0,
ax = b

i = 1, . . . , m

with f0 k-convex, f1, . . . , fm convex

id76 problems

4   40

optimal and pareto optimal points

set of achievable objective values

o = {f0(x) | x feasible}

    feasible x is optimal if f0(x) is the minimum value of o
    feasible x is pareto optimal if f0(x) is a minimal value of o

o

o

f0(xpo)

f0(x   )

x    is optimal

xpo is pareto optimal

id76 problems

4   41

multicriterion optimization

vector optimization problem with k = rq
+

f0(x) = (f1(x), . . . , fq(x))

    q di   erent objectives fi; roughly speaking we want all fi   s to be small
    feasible x    is optimal if

y feasible =    f0(x   ) (cid:22) f0(y)

if there exists an optimal point, the objectives are noncompeting

    feasible xpo is pareto optimal if

y feasible,

f0(y) (cid:22) f0(xpo) =    f0(xpo) = f0(y)

if there are multiple pareto optimal values, there is a trade-o    between
the objectives

id76 problems

4   42

regularized least-squares

minimize (w.r.t. r2

+)

(kax     bk2

2,kxk2
2)

22
k
x
k
=

)
x
(
2
f

25

20

15

10

5

0
0

o

10

20

30

40

50

f1(x) = kax     bk2

2

example for a     r100  10; heavy line is formed by pareto optimal points

id76 problems

4   43

risk return trade-o    in portfolio optimization

minimize (w.r.t. r2
subject to

+)

(     pt x, xt   x)
1t x = 1,

x (cid:23) 0

variable with mean   p, covariance   

    x     rn is investment portfolio; xi is fraction invested in asset i
    p     rn is vector of relative asset price changes; modeled as a random
      pt x = e r is expected return; xt   x = var r is return variance
example

15%

10%

5%

n
r
u
t
e
r

n
a
e
m

1

0.5

x

n
o
i
t
a
c
o

l
l

a

x(4)

x(3)

x(2)

x(1)

0%

0%

10%

20%

0

0%

10%

20%

standard deviation of return

standard deviation of return

id76 problems

4   44

scalarization

to    nd pareto optimal points: choose       k    0 and solve scalar problem

  t f0(x)
minimize
subject to fi(x)     0,
hi(x) = 0,

i = 1, . . . , m
i = 1, . . . , p

if x is optimal for scalar problem,
then it is pareto-optimal for vector
optimization problem

o

f0(x1)

  1

f0(x3)

f0(x2)   2

for convex vector optimization problems, can    nd (almost) all pareto
optimal points by varying       k    0

id76 problems

4   45

scalarization for multicriterion problems

to    nd pareto optimal points, minimize positive weighted sum

  t f0(x) =   1f1(x) +        +   qfq(x)

examples

    regularized least-squares problem of page 4   43

take    = (1,   ) with    > 0

minimize kax     bk2

2 +   kxk2

2

for    xed   , a ls problem

id76 problems

20

15

22
k
10
x
k

5

0
0

   = 1

5

10

kax     bk2

2

15

20

4   46

    risk-return trade-o    of page 4   44

minimize      pt x +   xt   x
subject to 1t x = 1,
x (cid:23) 0

for    xed    > 0, a quadratic program

id76 problems

4   47

id76     boyd & vandenberghe

5. duality

    lagrange dual problem
    weak and strong duality
    geometric interpretation
    optimality conditions
    perturbation and sensitivity analysis
    examples
    generalized inequalities

5   1

lagrangian

standard form problem (not necessarily convex)

f0(x)

minimize
subject to fi(x)     0,
hi(x) = 0,

i = 1, . . . , m
i = 1, . . . , p

variable x     rn, domain d, optimal value p   
lagrangian: l : rn    rm    rp     r, with dom l = d    rm    rp,

l(x,   ,   ) = f0(x) +

  ifi(x) +

mxi=1

  ihi(x)

pxi=1

    weighted sum of objective and constraint functions
      i is lagrange multiplier associated with fi(x)     0
      i is lagrange multiplier associated with hi(x) = 0

duality

5   2

lagrange dual function

lagrange dual function: g : rm    rp     r,

g(  ,   ) = inf
x   d

l(x,   ,   )

x   d f0(x) +

= inf

  ifi(x) +

mxi=1

  ihi(x)!

pxi=1

g is concave, can be        for some   ,   
lower bound property: if    (cid:23) 0, then g(  ,   )     p   
proof: if   x is feasible and    (cid:23) 0, then

f0(  x)     l(  x,   ,   )     inf

x   d

l(x,   ,   ) = g(  ,   )

minimizing over all feasible   x gives p        g(  ,   )

duality

5   3

least-norm solution of linear equations

minimize
subject to ax = b

xt x

dual function
    lagrangian is l(x,   ) = xt x +   t (ax     b)
    to minimize l over x, set gradient equal to zero:

   xl(x,   ) = 2x + at    = 0 =    x =    (1/2)at   

    plug in in l to obtain g:

g(  ) = l((   1/2)at   ,   ) =    

1
4

  t aat        bt   

a concave function of   

lower bound property: p           (1/4)  t aat        bt    for all   

duality

5   4

standard form lp

minimize
subject to ax = b,

ct x

x (cid:23) 0

dual function

    lagrangian is

l(x,   ,   ) = ct x +   t (ax     b)       t x
=    bt    + (c + at          )t x

    l is a   ne in x, hence

g(  ,   ) = inf
x

l(x,   ,   ) =(cid:26)    bt    at           + c = 0

       otherwise

g is linear on a   ne domain {(  ,   ) | at           + c = 0}, hence concave

lower bound property: p           bt    if at    + c (cid:23) 0

duality

5   5

equality constrained norm minimization

minimize
subject to ax = b

kxk

dual function

g(  ) = inf
x

(kxk       t ax + bt   ) =(cid:26) bt   

kat   k        1

       otherwise

where kvk    = supkuk   1 ut v is dual norm of k    k
proof: follows from inf x(kxk     yt x) = 0 if kyk        1,        otherwise
    if kyk        1, then kxk     yt x     0 for all x, with equality if x = 0
    if kyk    > 1, choose x = tu where kuk     1, ut y = kyk    > 1:
kxk     yt x = t(kuk     kyk   )            as t        

lower bound property: p        bt    if kat   k        1

duality

5   6

two-way partitioning

minimize
subject to x2

xt w x
i = 1,

i = 1, . . . , n

    a nonconvex problem; feasible set contains 2n discrete points
    interpretation: partition {1, . . . , n} in two sets; wij is cost of assigning

i, j to the same set;    wij is cost of assigning to di   erent sets

dual function

g(  ) = inf
x

(xt w x +xi

  i(x2

i     1)) = inf

x

xt (w + diag(  ))x     1t   
= (cid:26)    1t    w + diag(  ) (cid:23) 0

       otherwise

lower bound property: p           1t    if w + diag(  ) (cid:23) 0
example:    =      min(w )1 gives bound p        n  min(w )

duality

5   7

lagrange dual and conjugate function

f0(x)

minimize
subject to ax (cid:22) b, cx = d

dual function

g(  ,   ) =

inf

x   dom f0(cid:0)f0(x) + (at    + c t   )t x     bt        dt   (cid:1)
=    f    
0 (   at        c t   )     bt        dt   

    recall de   nition of conjugate f    (y) = supx   dom f (yt x     f (x))
    simpli   es derivation of dual if conjugate of f0 is known
example: id178 maximization

f0(x) =

nxi=1

xi log xi,

f    
0 (y) =

eyi   1

nxi=1

duality

5   8

lagrange dual problem

the dual problem

maximize
g(  ,   )
subject to    (cid:23) 0

       nds best lower bound on p   , obtained from lagrange dual function
    a id76 problem; optimal value denoted d   
      ,    are dual feasible if    (cid:23) 0, (  ,   )     dom g
    often simpli   ed by making implicit constraint (  ,   )     dom g explicit
example: standard form lp and its dual (page 5   5)

ct x

minimize
subject to ax = b
x (cid:23) 0

maximize    bt   
subject to at    + c (cid:23) 0

duality

5   9

weak and strong duality

weak duality: d        p   
    always holds (for convex and nonconvex problems)
    can be used to    nd nontrivial lower bounds for di   cult problems

for example, solving the sdp

maximize    1t   
subject to w + diag(  ) (cid:23) 0

gives a lower bound for the two-way partitioning problem on page 5   7

strong duality: d    = p   

    does not hold in general
    (usually) holds for convex problems
    conditions that guarantee strong duality in convex problems are called

constraint quali   cations

duality

5   10

slater   s constraint quali   cation

strong duality holds for a convex problem

f0(x)

minimize
subject to fi(x)     0,

ax = b

i = 1, . . . , m

if it is strictly feasible, i.e.,

   x     intd :

fi(x) < 0,

i = 1, . . . , m,

ax = b

    also guarantees that the dual optimum is attained (if p    >       )
    can be sharpened: e.g., can replace intd with relintd (interior

relative to a   ne hull); linear inequalities do not need to hold with strict
inequality, . . .

    there exist many other types of constraint quali   cations

duality

5   11

inequality form lp

ct x

minimize
subject to ax (cid:22) b

primal problem

dual function

g(  ) = inf

x (cid:0)(c + at   )t x     bt   (cid:1) =(cid:26)    bt    at    + c = 0

       otherwise

dual problem

maximize    bt   
subject to at    + c = 0,

   (cid:23) 0

    from slater   s condition: p    = d    if a  x     b for some   x
    in fact, p    = d    except when primal and dual are infeasible

duality

5   12

quadratic program

primal problem (assume p     sn

++)

xt p x
minimize
subject to ax (cid:22) b

dual function

g(  ) = inf

x (cid:0)xt p x +   t (ax     b)(cid:1) =    

1
4

  t ap    1at        bt   

dual problem

maximize    (1/4)  t ap    1at        bt   
subject to    (cid:23) 0

    from slater   s condition: p    = d    if a  x     b for some   x
    in fact, p    = d    always

duality

5   13

a nonconvex problem with strong duality

xt ax + 2bt x

minimize
subject to xt x     1

a 6(cid:23) 0, hence nonconvex
dual function: g(  ) = inf x(xt (a +   i)x + 2bt x       )
    unbounded below if a +   i 6(cid:23) 0 or if a +   i (cid:23) 0 and b 6    r(a +   i)
    minimized by x =    (a +   i)   b otherwise: g(  ) =    bt (a +   i)   b       

dual problem and equivalent sdp:

maximize    bt (a +   i)   b       
subject to a +   i (cid:23) 0

b     r(a +   i)

maximize    t       
bt

subject to (cid:20) a +   i

b

t (cid:21) (cid:23) 0

strong duality although primal problem is not convex (not easy to show)

duality

5   14

geometric interpretation

for simplicity, consider problem with one constraint f1(x)     0
interpretation of dual function:

g(  ) = inf

(u,t)   g

(t +   u),

where g = {(f1(x), f0(x)) | x     d}

t

g

p   

g(  )

  u + t = g(  )

t

g

p   
d   

u

u

      u + t = g(  ) is (non-vertical) supporting hyperplane to g
    hyperplane intersects t-axis at t = g(  )

duality

5   15

epigraph variation: same interpretation if g is replaced with
a = {(u, t) | f1(x)     u, f0(x)     t for some x     d}

t

  u + t = g(  )

p   

g(  )

a

u

strong duality
    holds if there is a non-vertical supporting hyperplane to a at (0, p   )
    for convex problem, a is convex, hence has supp. hyperplane at (0, p   )
    slater   s condition: if there exist (  u,   t)     a with   u < 0, then supporting

hyperplanes at (0, p   ) must be non-vertical

duality

5   16

complementary slackness

assume strong duality holds, x    is primal optimal, (     ,      ) is dual optimal

f0(x   ) = g(     ,      ) = inf

x  f0(x) +
mxi=1
    f0(x   ) +
    f0(x   )

mxi=1

     
i fi(x) +

i hi(x)!

     

pxi=1
pxi=1

i fi(x   ) +
     

i hi(x   )
     

hence, the two inequalities hold with equality

    x    minimizes l(x,      ,      )
         

i fi(x   ) = 0 for i = 1, . . . , m (known as complementary slackness):

i > 0 =    fi(x   ) = 0,
     

fi(x   ) < 0 =         

i = 0

duality

5   17

karush-kuhn-tucker (kkt) conditions

the following four conditions are called kkt conditions (for a problem with
di   erentiable fi, hi):

1. primal constraints: fi(x)     0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p
2. dual constraints:    (cid:23) 0
3. complementary slackness:   ifi(x) = 0, i = 1, . . . , m

4. gradient of lagrangian with respect to x vanishes:

   f0(x) +

mxi=1

  i   fi(x) +

pxi=1

  i   hi(x) = 0

from page 5   17: if strong duality holds and x,   ,    are optimal, then they
must satisfy the kkt conditions

duality

5   18

kkt conditions for convex problem

if   x,     ,      satisfy kkt for a convex problem, then they are optimal:
    from complementary slackness: f0(  x) = l(  x,     ,     )
    from 4th condition (and convexity): g(    ,     ) = l(  x,     ,     )
hence, f0(  x) = g(    ,     )

if slater   s condition is satis   ed:

x is optimal if and only if there exist   ,    that satisfy kkt conditions

    recall that slater implies strong duality, and dual optimum is attained
    generalizes optimality condition    f0(x) = 0 for unconstrained problem

duality

5   19

example: water-   lling (assume   i > 0)

minimize    pn

subject to x (cid:23) 0,

i=1 log(xi +   i)

1t x = 1

x is optimal i    x (cid:23) 0, 1t x = 1, and there exist        rn,        r such that

   (cid:23) 0,

  ixi = 0,

1

xi +   i

+   i =   

i=1 max{0, 1/         i} = 1

    if    < 1/  i:   i = 0 and xi = 1/         i
    if        1/  i:   i =        1/  i and xi = 0

    determine    from 1t x =pn

interpretation
    n patches; level of patch i is at height   i
       ood area with unit amount of water
    resulting level is 1/     

duality

1/     

xi

  i

5   20

i

perturbation and sensitivity analysis

(unperturbed) optimization problem and its dual

f0(x)

minimize
subject to fi(x)     0,
hi(x) = 0,

i = 1, . . . , m
i = 1, . . . , p

maximize
g(  ,   )
subject to    (cid:23) 0

perturbed problem and its dual

min. f0(x)
s.t.

fi(x)     ui,
hi(x) = vi,

i = 1, . . . , m
i = 1, . . . , p

max.
s.t.

g(  ,   )     ut        vt   
   (cid:23) 0

    x is primal variable; u, v are parameters
    p   (u, v) is optimal value as a function of u, v
    we are interested in information about p   (u, v) that we can obtain from

the solution of the unperturbed problem and its dual

duality

5   21

global sensitivity result

assume strong duality holds for unperturbed problem, and that      ,       are
dual optimal for unperturbed problem

apply weak duality to perturbed problem:

p   (u, v)     g(     ,      )     ut           vt      
= p   (0, 0)     ut           vt      

sensitivity interpretation
    if      
    if      
    if      
if      
    if      
if      

i large: p    increases greatly if we tighten constraint i (ui < 0)
i small: p    does not decrease much if we loosen constraint i (ui > 0)
i large and positive: p    increases greatly if we take vi < 0;
i large and negative: p    increases greatly if we take vi > 0
i small and positive: p    does not decrease much if we take vi > 0;
i small and negative: p    does not decrease much if we take vi < 0

duality

5   22

local sensitivity: if (in addition) p   (u, v) is di   erentiable at (0, 0), then

     
i =    

   p   (0, 0)

   ui

,

     
i =    

   p   (0, 0)

   vi

proof (for      

i ): from global sensitivity result,

   p   (0, 0)

   ui

= lim
t  0

p   (tei, 0)     p   (0, 0)

t

   p   (0, 0)

   ui

= lim
t  0

p   (tei, 0)     p   (0, 0)

t

            

i

            

i

hence, equality

p   (u) for a problem with one (inequality)
constraint:

duality

u = 0

p   (0)          u

u
p   (u)

5   23

duality and problem reformulations

    equivalent formulations of a problem can lead to very di   erent duals
    reformulating the primal problem can be useful when the dual is di   cult

to derive, or uninteresting

common reformulations

    introduce new variables and equality constraints
    make explicit constraints implicit or vice-versa
    transform objective or constraint functions

e.g., replace f0(x) by   (f0(x)) with    convex, increasing

duality

5   24

introducing new variables and equality constraints

minimize f0(ax + b)

    dual function is constant: g = inf x l(x) = inf x f0(ax + b) = p   
    we have strong duality, but dual is quite useless
reformulated problem and its dual

f0(y)

minimize
subject to ax + b     y = 0

bt        f    
maximize
subject to at    = 0

0 (  )

dual function follows from

g(  ) = inf
x,y

(f0(y)       t y +   t ax + bt   )

= (cid:26)    f    

      

0 (  ) + bt    at    = 0
otherwise

duality

5   25

norm approximation problem: minimize kax     bk

minimize
subject to y = ax     b

kyk

can look up conjugate of k    k, or derive dual directly
(kyk +   t y       t ax + bt   )

g(  ) = inf
x,y

= (cid:26) bt    + inf y(kyk +   t y) at    = 0
= (cid:26) bt    at    = 0,

       otherwise

k  k        1

      

otherwise

(see page 5   4)

dual of norm approximation problem

maximize
subject to at    = 0,

bt   

k  k        1

duality

5   26

implicit constraints

lp with box constraints: primal and dual problem

minimize
subject to ax = b

ct x

maximize    bt        1t   1     1t   2
subject to c + at    +   1       2 = 0

  1 (cid:23) 0,
reformulation with box constraints made implicit

   1 (cid:22) x (cid:22) 1

  2 (cid:23) 0

f0(x) =(cid:26) ct x    1 (cid:22) x (cid:22) 1

    otherwise

minimize

subject to ax = b

dual function

g(  ) =

inf

   1(cid:22)x(cid:22)1

(ct x +   t (ax     b))

=    bt        kat    + ck1

dual problem: maximize    bt        kat    + ck1

duality

5   27

problems with generalized inequalities

f0(x)

minimize
subject to fi(x) (cid:22)ki 0,

hi(x) = 0,

i = 1, . . . , m

i = 1, . . . , p

(cid:22)ki is generalized inequality on rki
de   nitions are parallel to scalar case:
    lagrange multiplier for fi(x) (cid:22)ki 0 is vector   i     rki
    lagrangian l : rn    rk1              rkm    rp     r, is de   ned as

l(x,   1,       ,   m,   ) = f0(x) +

pxi=1
    dual function g : rk1              rkm    rp     r, is de   ned as
l(x,   1,       ,   m,   )

g(  1, . . . ,   m,   ) = inf
x   d

  t
i fi(x) +

mxi=1

  ihi(x)

duality

5   28

lower bound property: if   i (cid:23)k   
proof: if   x is feasible and    (cid:23)k   

i

i

0, then g(  1, . . . ,   m,   )     p   
0, then

f0(  x)     f0(  x) +

  t
i fi(  x) +

  ihi(  x)

mxi=1

pxi=1

l(x,   1, . . . ,   m,   )

x   d

    inf
= g(  1, . . . ,   m,   )

minimizing over all feasible   x gives p        g(  1, . . . ,   m,   )
dual problem

g(  1, . . . ,   m,   )

maximize
subject to   i (cid:23)k   

i

0,

i = 1, . . . , m

    weak duality: p        d    always
    strong duality: p    = d    for convex problem with constraint quali   cation

(for example, slater   s: primal problem is strictly feasible)

duality

5   29

semide   nite program

primal sdp (fi, g     sk)
minimize
subject to x1f1 +        + xnfn (cid:22) g

ct x

    lagrange multiplier is matrix z     sk
    lagrangian l(x, z) = ct x + tr (z(x1f1 +        + xnfn     g))
    dual function
g(z) = inf
x

l(x, z) =(cid:26)     tr(gz)

tr(fiz) + ci = 0,
otherwise

      

i = 1, . . . , n

dual sdp

maximize     tr(gz)
subject to z (cid:23) 0,

tr(fiz) + ci = 0,

i = 1, . . . , n

p    = d    if primal sdp is strictly feasible (   x with x1f1 +        + xnfn     g)

duality

5   30

6. approximation and    tting

id76     boyd & vandenberghe

    norm approximation
    least-norm problems
    regularized approximation
    robust approximation

6   1

norm approximation

minimize kax     bk
(a     rm  n with m     n, k    k is a norm on rm)
interpretations of solution x    = argminx kax     bk:
    geometric: ax    is point in r(a) closest to b
    estimation: linear measurement model

y = ax + v

y are measurements, x is unknown, v is measurement error

given y = b, best guess of x is x   

    optimal design: x are design variables (input), ax is result (output)

x    is design that best approximates desired result b

approximation and    tting

6   2

examples

    least-squares approximation (k    k2): solution satis   es normal equations

at ax = at b

(x    = (at a)   1at b if rank a = n)

    chebyshev approximation (k    k   ): can be solved as an lp

t

minimize
subject to    t1 (cid:22) ax     b (cid:22) t1

    sum of absolute residuals approximation (k    k1): can be solved as an lp

1t y

minimize
subject to    y (cid:22) ax     b (cid:22) y

approximation and    tting

6   3

penalty function approximation

minimize
subject to r = ax     b

  (r1) +        +   (rm)

(a     rm  n,    : r     r is a convex penalty function)
examples
    quadratic:   (u) = u2
    deadzone-linear with width a:

1.5

2

log barrier

)
u
(
  

1

0.5

  (u) = max{0,|u|     a}

    log-barrier with limit a:

  (u) =(cid:26)    a2 log(1     (u/a)2)

   

0
   1.5    1    0.5

0.5

1

1.5

0
u

|u| < a
otherwise

quadratic

deadzone-linear

approximation and    tting

6   4

example (m = 100, n = 30): histogram of residuals for penalties

  (u) = |u|,   (u) = u2,   (u) = max{0,|u|   a},   (u) =     log(1   u2)

1
=
p

2
=
p

e
n
o
z
d
a
e
d

r
e
i
r
r
a
b

g
o
l

40

0
   2

10

0
   2

20

0
   2

10

0
   2

   1

   1

   1

   1

0

0

0

0
r

1

1

1

1

2

2

2

2

shape of penalty function has large e   ect on distribution of residuals

approximation and    tting

6   5

replacements

huber penalty function (with parameter m )

  hub(u) =(cid:26) u2

m (2|u|     m )

|u|     m
|u| > m

linear growth for large u makes approximation less sensitive to outliers

2

1.5

1

0.5

)
u
(
b
u
h
  

20

10

0

)
t
(
f

   10

0
   1.5    1    0.5

0.5

1

1.5

0
u

   20

   10

   5

0
t

5

10

    left: huber penalty for m = 1
    right: a   ne function f (t) =    +   t    tted to 42 points ti, yi (circles)

using quadratic (dashed) and huber (solid) penalty

approximation and    tting

6   6

least-norm problems

minimize
subject to ax = b

kxk

(a     rm  n with m     n, k    k is a norm on rn)
interpretations of solution x    = argminax=b kxk:
    geometric: x    is point in a   ne set {x | ax = b} with minimum

distance to 0

    estimation: b = ax are (perfect) measurements of x; x    is smallest

(   most plausible   ) estimate consistent with measurements

    design: x are design variables (inputs); b are required results (outputs)

x    is smallest (   most e   cient   ) design that satis   es requirements

approximation and    tting

6   7

examples

    least-squares solution of linear equations (k    k2):

can be solved via optimality conditions

2x + at    = 0,

ax = b

    minimum sum of absolute values (k    k1): can be solved as an lp

1t y

minimize
subject to    y (cid:22) x (cid:22) y, ax = b

tends to produce sparse solution x   

extension: least-penalty problem

minimize
subject to ax = b

  (x1) +        +   (xn)

   : r     r is convex penalty function

approximation and    tting

6   8

regularized approximation

minimize (w.r.t. r2

+)

(kax     bk,kxk)

a     rm  n, norms on rm and rn can be di   erent

interpretation:    nd good approximation ax     b with small x
    estimation: linear measurement model y = ax + v, with prior

knowledge that kxk is small

    optimal design: small x is cheaper or more e   cient, or the linear

model y = ax is only valid for small x

    robust approximation: good approximation ax     b with small x is

less sensitive to errors in a than good approximation with large x

approximation and    tting

6   9

scalarized problem

minimize kax     bk +   kxk

    solution for    > 0 traces out optimal trade-o    curve
    other common method: minimize kax     bk2 +   kxk2 with    > 0
tikhonov id173

minimize kax     bk2

2 +   kxk2

2

can be solved as a least-squares problem

minimize (cid:13)(cid:13)(cid:13)(cid:13)(cid:20) a     i (cid:21) x    (cid:20) b
0 (cid:21)(cid:13)(cid:13)(cid:13)(cid:13)

solution x    = (at a +   i)   1at b

2

2

approximation and    tting

6   10

optimal input design

linear dynamical system with impulse response h:

y(t) =

tx   =0

h(   )u(t        ),

t = 0, 1, . . . , n

input design problem: multicriterion problem with 3 objectives

1. tracking error with desired output ydes: jtrack =pn
2. input magnitude: jmag =pn
3. input variation: jder =pn    1

t=0 (u(t + 1)     u(t))2

t=0 u(t)2

track desired output using a small and slowly varying input signal

t=0(y(t)     ydes(t))2

regularized least-squares formulation

minimize jtrack +   jder +   jmag

for    xed   ,   , a least-squares problem in u(0), . . . , u(n )

approximation and    tting

6   11

example: 3 solutions on optimal trade-o    surface

(top)    = 0, small   ; (middle)    = 0, larger   ; (bottom) large   

5

0

)
t
(
u

   5

   10
0

4

2

0

)
t
(
u

   2

   4
0

4

2

0

)
t
(
u

   2

   4
0

50

100

t

150

200

50

100

t

150

200

50

100

t

150

200

1

0.5

0

)
t
(
y
   0.5

   1
0

1

0.5

0

)
t
(
y
   0.5

   1
0

1

0.5

0

)
t
(
y
   0.5

   1
0

50

100

t

150

200

50

100

t

150

200

50

100

t

150

200

approximation and    tting

6   12

signal reconstruction

minimize (w.r.t. r2

+)

(k  x     xcork2,   (  x))

    x     rn is unknown signal
    xcor = x + v is (known) corrupted version of x, with additive noise v
    variable   x (reconstructed signal) is estimate of x
       : rn     r is id173 function or smoothing objective

examples: quadratic smoothing, total variation smoothing:

  quad(  x) =

n   1xi=1

(  xi+1       xi)2,

  tv(  x) =

n   1xi=1

|  xi+1       xi|

approximation and    tting

6   13

quadratic smoothing example

0.5

x

0

   0.5

0.5

  x

0

   0.5

0

0.5

0

1000

2000

3000

4000

  x

0

0.5

r
o
c
x

0

   0.5

   0.5

0

0.5

  x

0

   0.5

1000

2000

3000

4000

1000

2000

3000

4000

0

1000

2000

i

3000

4000

0

1000

2000

i

3000

4000

original signal x and noisy

signal xcor

three solutions on trade-o    curve

k  x     xcork2 versus   quad(  x)

approximation and    tting

6   14

total variation reconstruction example

2

1

x

0

   1

   2
0

2

1

0

r
o
c
x

   1

   2
0

500

1000

1500

2000

500

1000

i

1500

2000

2

i

  x

0

   2
0
2

i

  x

0

   2
0
2

i

  x

0

   2
0

500

1000

1500

2000

500

1000

1500

2000

500

1000

i

1500

2000

original signal x and noisy

three solutions on trade-o    curve

signal xcor

k  x     xcork2 versus   quad(  x)
quadratic smoothing smooths out noise and sharp transitions in signal

approximation and    tting

6   15

2

1

x

0

   1

   2
0

2

1

0

r
o
c
x

   1

   2
0

500

1000

1500

2000

500

1000

i

1500

2000

2

  x

0

   2
0
2

  x

0

   2
0
2

  x

0

   2
0

500

1000

1500

2000

500

1000

1500

2000

500

1000

i

1500

2000

original signal x and noisy

three solutions on trade-o    curve

signal xcor

k  x     xcork2 versus   tv(  x)

total variation smoothing preserves sharp transitions in signal

approximation and    tting

6   16

robust approximation

minimize kax     bk with uncertain a
two approaches:

    stochastic: assume a is random, minimize ekax     bk
    worst-case: set a of possible values of a, minimize supa   a kax     bk
tractable only in special cases (certain norms k    k, distributions, sets a)

example: a(u) = a0 + ua1
    xnom minimizes ka0x     bk2
    xstoch minimizes eka(u)x     bk2

with u uniform on [   1, 1]

2

2

    xwc minimizes sup   1   u   1 ka(u)x     bk2
   gure shows r(u) = ka(u)x     bk2

2

approximation and    tting

12

10

8

6

4

2

)
u
(
r

xnom

xstoch
xwc

0
   2

   1

0
u

1

2

6   17

stochastic robust ls with a =   a + u , u random, e u = 0, e u t u = p

minimize ek(   a + u )x     bk2

2

    explicit expression for objective:

ekax     bk2

2 = ek   ax     b + u xk2

2

= k   ax     bk2
= k   ax     bk2

2 + e xt u t u x
2 + xt p x

    hence, robust ls problem is equivalent to ls problem
2 + kp 1/2xk2

minimize k   ax     bk2

2

    for p =   i, get tikhonov regularized problem

minimize k   ax     bk2

2 +   kxk2

2

approximation and    tting

6   18

worst-case robust ls with a = {   a + u1a1 +        + upap | kuk2     1}

minimize

supa   a kax     bk2

2 = supkuk2   1 kp (x)u + q(x)k2

2

where p (x) =(cid:2) a1x a2x        apx (cid:3), q(x) =   ax     b

    from page 5   14, strong duality holds between the following problems

maximize
subject to kuk2

kp u + qk2
2     1

2

minimize

subject to       

t +   
i
p t   i
qt
0

p q
0

t        (cid:23) 0

    hence, robust ls problem is equivalent to sdp

t +   

minimize

subject to       

i

p (x)

p (x)t
q(x)t

  i
0

q(x)

0

t        (cid:23) 0

approximation and    tting

6   19

example: histogram of residuals

r(u) = k(a0 + u1a1 + u2a2)x     bk2

with u uniformly distributed on unit disk, for three values of x

y
c
n
e
u
q
e
r
f

0.25

0.2

0.15

0.1

0.05

0

0

xrls

xtik

xls

1

2

r(u)

3

4

5

    xls minimizes ka0x     bk2
    xtik minimizes ka0x     bk2
2 +   kxk2
    xrls minimizes supa   a kax     bk2

2 (tikhonov solution)
2 + kxk2

2

approximation and    tting

6   20

7. statistical estimation

id76     boyd & vandenberghe

    id113
    optimal detector design
    experiment design

7   1

parametric distribution estimation

    distribution estimation problem: estimate id203 density p(y) of a

random variable from observed values

    parametric distribution estimation: choose from a family of densities

px(y), indexed by a parameter x

id113

maximize (over x)

log px(y)

    y is observed value
    l(x) = log px(y) is called log-likelihood function
    can add constraints x     c explicitly, or de   ne px(y) = 0 for x 6    c
    a id76 problem if log px(y) is concave in x for    xed y

statistical estimation

7   2

linear measurements with iid noise

linear measurement model

yi = at

i x + vi,

i = 1, . . . , m

    x     rn is vector of unknown parameters
    vi is iid measurement noise, with density p(z)
    yi is measurement: y     rm has density px(y) =qm

i=1 p(yi     at

i x)

maximum likelihood estimate: any solution x of

maximize

(y is observed value)

l(x) =pm

i=1 log p(yi     at

i x)

statistical estimation

7   3

examples

    gaussian noise n (0,   2): p(z) = (2    2)   1/2e   z2/(2  2),

l(x) =    

m
2

log(2    2)    

1
2  2

mxi=1

(at
i x     yi)2

ml estimate is ls solution

    laplacian noise: p(z) = (1/(2a))e   |z|/a,
1
a

l(x) =    m log(2a)    

ml estimate is    1-norm solution

mxi=1

|at
i x     yi|

    uniform noise on [   a, a]:

l(x) =(cid:26)    m log(2a)

      

|at
i x     yi|     a,
otherwise

i = 1, . . . , m

ml estimate is any x with |at

i x     yi|     a

statistical estimation

7   4

id28

random variable y     {0, 1} with distribution

p = prob(y = 1) =

exp(at u + b)

1 + exp(at u + b)

    a, b are parameters; u     rn are (observable) explanatory variables
    estimation problem: estimate a, b from m observations (ui, yi)
log-likelihood function (for y1 =        = yk = 1, yk+1 =        = ym = 0):

exp(at ui + b)

1 + exp(at ui + b)

l(a, b) = log      
kxi=1

=

kyi=1
(at ui + b)    

mxi=1

myi=k+1

1

1 + exp(at ui + b)      

log(1 + exp(at ui + b))

concave in a, b

statistical estimation

7   5

example (n = 1, m = 50 measurements)

)
1
=
y
(
b
o
r
p

1

0.8

0.6

0.4

0.2

0

0

2

4

u

6

8

10

    circles show 50 points (ui, yi)
    solid curve is ml estimate of p = exp(au + b)/(1 + exp(au + b))

statistical estimation

7   6

(binary) hypothesis testing

detection (hypothesis testing) problem

given observation of a random variable x     {1, . . . , n}, choose between:
    hypothesis 1: x was generated by distribution p = (p1, . . . , pn)
    hypothesis 2: x was generated by distribution q = (q1, . . . , qn)

randomized detector

    a nonnegative matrix t     r2  n, with 1t t = 1t
    if we observe x = k, we choose hypothesis 1 with id203 t1k,

hypothesis 2 with id203 t2k

    if all elements of t are 0 or 1, it is called a deterministic detector

statistical estimation

7   7

detection id203 matrix:

d =(cid:2) t p t q (cid:3) =(cid:20) 1     pfp

pfp

pfn

1     pfn (cid:21)

    pfp is id203 of selecting hypothesis 2 if x is generated by

distribution 1 (false positive)

    pfn is id203 of selecting hypothesis 1 if x is generated by

distribution 2 (false negative)

multicriterion formulation of detector design

minimize (w.r.t. r2
subject to

+)

variable t     r2  n

(pfp, pfn) = ((t p)2, (t q)1)
t1k + t2k = 1,
tik     0,

i = 1, 2,

k = 1, . . . , n

k = 1, . . . , n

statistical estimation

7   8

scalarization (with weight    > 0)

minimize
subject to t1k + t2k = 1,

(t p)2 +   (t q)1

tik     0,

i = 1, 2,

k = 1, . . . , n

an lp with a simple analytical solution

(t1k, t2k) =(cid:26) (1, 0) pk       qk

(0, 1) pk <   qk

    a deterministic detector, given by a likelihood ratio test
    if pk =   qk for some k, any value 0     t1k     1, t1k = 1     t2k is optimal

(i.e., pareto-optimal detectors include non-deterministic detectors)

minimax detector

minimize max{pfp, pfn} = max{(t p)2, (t q)1}
i = 1, 2,
subject to t1k + t2k = 1,

tik     0,
an lp; solution is usually not deterministic

k = 1, . . . , n

statistical estimation

7   9

example

p =            

0.70 0.10
0.20 0.10
0.05 0.70
0.05 0.10

            

n
f
p

1

0.8

0.6

0.4

0.2

0
0

1

2

4

3

0.2

0.4

pfp

0.6

0.8

1

solutions 1, 2, 3 (and endpoints) are deterministic; 4 is minimax detector

statistical estimation

7   10

experiment design

m linear measurements yi = at

i x + wi, i = 1, . . . , m of unknown x     rn

    measurement errors wi are iid n (0, 1)
    ml (least-squares) estimate is

    error e =   x     x has zero mean and covariance

yiai

aiat

i!   1 mxi=1
  x =  mxi=1
e = e eet =  mxi=1
i!   1

aiat

con   dence ellipsoids are given by {x | (x       x)t e   1(x       x)       }
experiment design: choose ai     {v1, . . . , vp} (a set of possible test
vectors) to make e    small   

statistical estimation

7   11

vector optimization formulation

minimize (w.r.t. sn
subject to

+) e =(cid:0)pp

k=1 mkvkvt

k(cid:1)   1

mk     0, m1 +        + mp = m
mk     z

    variables are mk (# vectors ai equal to vk)
    di   cult in general, due to integer constraint
relaxed experiment design

assume m     p, use   k = mk/m as (continuous) real variable
k=1   kvkvt

minimize (w.r.t. sn
subject to

+) e = (1/m)(cid:0)pp

   (cid:23) 0,

1t    = 1

k(cid:1)   1

    common scalarizations: minimize log det e, tr e,   max(e), . . .
    can add other convex constraints, e.g., bound experiment cost ct        b

statistical estimation

7   12

d-optimal design

minimize
subject to    (cid:23) 0,

log det(cid:0)pp

k=1   kvkvt
1t    = 1

k(cid:1)   1

interpretation: minimizes volume of con   dence ellipsoids

dual problem

maximize
subject to vt

log det w + n log n
k w vk     1,

k = 1, . . . , p

interpretation: {x | xt w x     1} is minimum volume ellipsoid centered at
origin, that includes all test vectors vk

complementary slackness: for   , w primal and dual optimal

  k(1     vt

k w vk) = 0,

k = 1, . . . , p

optimal experiment uses vectors vk on boundary of ellipsoid de   ned by w

statistical estimation

7   13

example (p = 20)

  1 = 0.5

  2 = 0.5

design uses two vectors, on boundary of ellipse de   ned by optimal w

statistical estimation

7   14

derivation of dual of page 7   13

   rst reformulate primal problem with new variable x:

log det x    1

minimize

subject to x =pp

k=1   kvkvt
k ,

   (cid:23) 0,

1t    = 1

l(x,   , z, z,   ) = log det x    1+tr z x    

  kvkvt

k!!   zt   +  (1t      1)

pxk=1

    minimize over x by setting gradient to zero:    x    1 + z = 0
    minimum over   k is        unless    vt
dual problem

k zvk     zk +    = 0

maximize
subject to vt

n + log det z       
k zvk       ,

k = 1, . . . , p

change variable w = z/  , and optimize over    to get dual of page 7   13

statistical estimation

7   15

8. geometric problems

id76     boyd & vandenberghe

    extremal volume ellipsoids
    centering
    classi   cation
    placement and facility location

8   1

minimum volume ellipsoid around a set

l  owner-john ellipsoid of a set c: minimum volume ellipsoid e s.t. c     e
    parametrize e as e = {v | kav + bk2     1}; w.l.o.g. assume a     sn
    vole is proportional to det a   1; to compute minimum volume ellipsoid,

++

minimize (over a, b)
subject to

log det a   1
supv   c kav + bk2     1

convex, but evaluating the constraint can be hard (for general c)

   nite set c = {x1, . . . , xm}:
minimize (over a, b)
subject to

log det a   1
kaxi + bk2     1,

i = 1, . . . , m

also gives l  owner-john ellipsoid for polyhedron conv{x1, . . . , xm}

geometric problems

8   2

maximum volume inscribed ellipsoid

maximum volume ellipsoid e inside a convex set c     rn
    parametrize e as e = {bu + d | kuk2     1}; w.l.o.g. assume b     sn
    vole is proportional to det b; can compute e by solving

++

log det b

maximize
subject to supkuk2   1 ic(bu + d)     0
(where ic(x) = 0 for x     c and ic(x) =     for x 6    c)
convex, but evaluating the constraint can be hard (for general c)

polyhedron {x | at

i x     bi, i = 1, . . . , m}:

log det b

maximize
subject to kbaik2 + at
(constraint follows from supkuk2   1 at

i = 1, . . . , m

i d     bi,
i (bu + d) = kbaik2 + at

i d)

geometric problems

8   3

e   ciency of ellipsoidal approximations

c     rn convex, bounded, with nonempty interior
    l  owner-john ellipsoid, shrunk by a factor n, lies inside c
    maximum volume inscribed ellipsoid, expanded by a factor n, covers c
example (for two polyhedra in r2)

factor n can be improved to    n if c is symmetric

geometric problems

8   4

centering

some possible de   nitions of    center    of a convex set c:

    center of largest inscribed ball (   chebyshev center   )

for polyhedron, can be computed via id135 (page 4   19)

    center of maximum volume inscribed ellipsoid (page 8   3)

xchebxcheb

xmve

mve center is invariant under a   ne coordinate transformations

geometric problems

8   5

analytic center of a set of inequalities

the analytic center of set of convex inequalities and linear equations

fi(x)     0,

i = 1, . . . , m,

f x = g

is de   ned as the optimal point of

minimize    pm

subject to f x = g

i=1 log(   fi(x))

    more easily computed than mve or chebyshev center (see later)
    not just a property of the feasible set: two sets of inequalities can

describe the same set, but have di   erent analytic centers

geometric problems

8   6

analytic center of linear inequalities at

i x     bi, i = 1, . . . , m

xac is minimizer of

  (x) =    

mxi=1

log(bi     at

i x)

xac

inner and outer ellipsoids from analytic center:

einner     {x | at

i x     bi, i = 1, . . . , m}     eouter

where

einner = {x | (x     xac)t   2  (xac)(x     xac)     1}
eouter = {x | (x     xac)t   2  (xac)(x     xac)     m(m     1)}

geometric problems

8   7

linear discrimination

separate two sets of points {x1, . . . , xn}, {y1, . . . , ym} by a hyperplane:

at xi + b > 0,

i = 1, . . . , n,

at yi + b < 0,

i = 1, . . . , m

homogeneous in a, b, hence equivalent to

at xi + b     1,

i = 1, . . . , n,

at yi + b        1,

i = 1, . . . , m

a set of linear inequalities in a, b

geometric problems

8   8

robust linear discrimination

(euclidean) distance between hyperplanes

h1 = {z | at z + b = 1}
h2 = {z | at z + b =    1}

is dist(h1,h2) = 2/kak2

to separate two sets of points by maximum margin,

(1/2)kak2
minimize
subject to at xi + b     1,
at yi + b        1,

i = 1, . . . , n

i = 1, . . . , m

(after squaring objective) a qp in a, b

geometric problems

(1)

8   9

lagrange dual of maximum margin separation problem (1)

maximize

1t    + 1t   

subject to 2(cid:13)(cid:13)(cid:13)pn

i=1   ixi    pm

i=1   iyi(cid:13)(cid:13)(cid:13)2     1

   (cid:23) 0,    (cid:23) 0

1t    = 1t   ,

(2)

from duality, optimal value is inverse of maximum margin of separation

interpretation
    change variables to   i =   i/1t   ,   i =   i/1t   , t = 1/(1t    + 1t   )
    invert objective to minimize 1/(1t    + 1t   ) = t

t

minimize

subject to (cid:13)(cid:13)(cid:13)pn

   (cid:23) 0,

i=1   ixi    pm

1t    = 1,

i=1   iyi(cid:13)(cid:13)(cid:13)2     t

   (cid:23) 0,

1t    = 1

optimal value is distance between convex hulls

geometric problems

8   10

approximate linear separation of non-separable sets

1t u + 1t v

minimize
subject to at xi + b     1     ui,
at yi + b        1 + vi,
u (cid:23) 0,

v (cid:23) 0

i = 1, . . . , n

i = 1, . . . , m

    an lp in a, b, u, v
    at optimum, ui = max{0, 1     at xi     b}, vi = max{0, 1 + at yi + b}
    can be interpreted as a heuristic for minimizing #misclassi   ed points

geometric problems

8   11

support vector classi   er

kak2 +   (1t u + 1t v)
minimize
subject to at xi + b     1     ui,
at yi + b        1 + vi,
u (cid:23) 0,

v (cid:23) 0

i = 1, . . . , n

i = 1, . . . , m

produces point on trade-o    curve between inverse of margin 2/kak2 and
classi   cation error, measured by total slack 1t u + 1t v

same example as previous page,
with    = 0.1:

geometric problems

8   12

nonlinear discrimination

separate two sets of points by a nonlinear function:

f (xi) > 0,

i = 1, . . . , n,

f (yi) < 0,

i = 1, . . . , m

    choose a linearly parametrized family of functions

f (z) =   t f (z)

f = (f1, . . . , fk) : rn     rk are basis functions

    solve a set of linear inequalities in   :

  t f (xi)     1,

i = 1, . . . , n,

  t f (yi)        1,

i = 1, . . . , m

geometric problems

8   13

quadratic discrimination: f (z) = zt p z + qt z + r

i p xi + qt xi + r     1,
xt

i p yi + qt yi + r        1
yt

can add additional constraints (e.g., p (cid:22)    i to separate by an ellipsoid)
polynomial discrimination: f (z) are all monomials up to a given degree

separation by ellipsoid

separation by 4th degree polynomial

geometric problems

8   14

placement and facility location

    n points with coordinates xi     r2 (or r3)
    some positions xi are given; the other xi   s are variables
    for each pair of points, a cost function fij(xi, xj)

placement problem

minimize pi6=j fij(xi, xj)

variables are positions of free points

interpretations

    points represent plants or warehouses; fij is transportation cost between

facilities i and j

    points represent cells on an ic; fij represents wirelength

geometric problems

8   15

example: minimizep(i,j)   a h(kxi     xjk2), with 6 free points, 27 links

optimal placement for h(z) = z, h(z) = z2, h(z) = z4

1

0

   1

   1

0

1

1

0

   1

   1

0

1

histograms of connection lengths kxi     xjk2

4

3

2

1

0
0

4

3

2

1

0
0

0.5

1

1.5

2

   1

0

1

1

0

   1

6

5

4

3

2

1

geometric problems

8   16

0.5

1

1.5

0
0

0.5

1

1.5

9. numerical id202 background

id76     boyd & vandenberghe

    matrix structure and algorithm complexity
    solving linear equations with factored matrices
    lu, cholesky, ldlt factorization
    block elimination and the matrix inversion lemma
    solving underdetermined equations

9   1

matrix structure and algorithm complexity

cost (execution time) of solving ax = b with a     rn  n
    for general methods, grows as n3
    less if a is structured (banded, sparse, toeplitz, . . . )

   op counts

       op (   oating-point operation): one addition, subtraction,
multiplication, or division of two    oating-point numbers

    to estimate complexity of an algorithm: express number of    ops as a

(polynomial) function of the problem dimensions, and simplify by
keeping only the leading terms

    not an accurate predictor of computation time on modern computers
    useful as a rough estimate of complexity

numerical id202 background

9   2

vector-vector operations (x, y     rn)
    inner product xt y: 2n     1    ops (or 2n if n is large)
    sum x + y, scalar multiplication   x: n    ops
matrix-vector product y = ax with a     rm  n
    m(2n     1)    ops (or 2mn if n large)
    2n if a is sparse with n nonzero elements
    2p(n + m) if a is given as a = u v t , u     rm  p, v     rn  p
matrix-matrix product c = ab with a     rm  n, b     rn  p
    mp(2n     1)    ops (or 2mnp if n large)
    less if a and/or b are sparse
    (1/2)m(m + 1)(2n     1)     m2n if m = p and c symmetric

numerical id202 background

9   3

linear equations that are easy to solve

diagonal matrices (aij = 0 if i 6= j): n    ops

x = a   1b = (b1/a11, . . . , bn/ann)

lower triangular (aij = 0 if j > i): n2    ops

x1

x2

x3

xn

:= b1/a11
:= (b2     a21x1)/a22
:= (b3     a31x1     a32x2)/a33
...
:= (bn     an1x1     an2x2                an,n   1xn   1)/ann

called forward substitution

upper triangular (aij = 0 if j < i): n2    ops via backward substitution

numerical id202 background

9   4

orthogonal matrices: a   1 = at
    2n2    ops to compute x = at b for general a
    less with structure, e.g., if a = i     2uut with kuk2 = 1, we can

compute x = at b = b     2(ut b)u in 4n    ops

permutation matrices:

aij =(cid:26) 1 j =   i

0 otherwise

where    = (  1,   2, . . . ,   n) is a permutation of (1, 2, . . . , n)
    interpretation: ax = (x  1, . . . , x  n)
    satis   es a   1 = at , hence cost of solving ax = b is 0    ops
example:

a =      

0 1 0
0 0 1

1 0 0        ,

a   1 = at =      

0 0 1
1 0 0

0 1 0       

numerical id202 background

9   5

the factor-solve method for solving ax = b

    factor a as a product of simple matrices (usually 2 or 3):

a = a1a2        ak
(ai diagonal, upper or lower triangular, etc)

    compute x = a   1b = a   1

1 b by solving k    easy    equations

a1x1 = b,

. . . ,

akx = xk   1

2 a   1

k        a   1
a2x2 = x1,

cost of factorization step usually dominates cost of solve step

equations with multiple righthand sides

ax1 = b1,

ax2 = b2,

. . . ,

axm = bm

cost: one factorization plus m solves

numerical id202 background

9   6

lu factorization

every nonsingular matrix a can be factored as

a = p lu

with p a permutation matrix, l lower triangular, u upper triangular

cost: (2/3)n3    ops

solving linear equations by lu factorization.

given a set of linear equations ax = b, with a nonsingular.

1. lu factorization. factor a as a = p lu ((2/3)n3    ops).
2. permutation. solve p z1 = b (0    ops).
3. forward substitution. solve lz2 = z1 (n2    ops).
4. backward substitution. solve u x = z2 (n2    ops).

cost: (2/3)n3 + 2n2     (2/3)n3 for large n

numerical id202 background

9   7

sparse lu factorization

a = p1lu p2

    adding permutation matrix p2 o   ers possibility of sparser l, u (hence,

cheaper factor and solve steps)

    p1 and p2 chosen (heuristically) to yield sparse l, u
    choice of p1 and p2 depends on sparsity pattern and values of a
    cost is usually much less than (2/3)n3; exact value depends in a

complicated way on n, number of zeros in a, sparsity pattern

numerical id202 background

9   8

cholesky factorization

every positive de   nite a can be factored as

a = llt

with l lower triangular

cost: (1/3)n3    ops

solving linear equations by cholesky factorization.

given a set of linear equations ax = b, with a     sn

++.

1. cholesky factorization. factor a as a = llt ((1/3)n3    ops).
2. forward substitution. solve lz1 = b (n2    ops).
3. backward substitution. solve lt x = z1 (n2    ops).

cost: (1/3)n3 + 2n2     (1/3)n3 for large n

numerical id202 background

9   9

sparse cholesky factorization

a = p llt p t

    adding permutation matrix p o   ers possibility of sparser l
    p chosen (heuristically) to yield sparse l
    choice of p only depends on sparsity pattern of a (unlike sparse lu)
    cost is usually much less than (1/3)n3; exact value depends in a

complicated way on n, number of zeros in a, sparsity pattern

numerical id202 background

9   10

ldlt factorization

every nonsingular symmetric matrix a can be factored as

a = p ldlt p t

with p a permutation matrix, l lower triangular, d block diagonal with
1    1 or 2    2 diagonal blocks
cost: (1/3)n3

    cost of solving symmetric sets of linear equations by ldlt factorization:

(1/3)n3 + 2n2     (1/3)n3 for large n

    for sparse a, can choose p to yield sparse l; cost     (1/3)n3

numerical id202 background

9   11

equations with structured sub-blocks

a21 a22 (cid:21)(cid:20) x1
(cid:20) a11 a12

b2 (cid:21)
x2 (cid:21) =(cid:20) b1
    variables x1     rn1, x2     rn2; blocks aij     rni  nj
    if a11 is nonsingular, can eliminate x1: x1 = a   1

to compute x2, solve

11 (b1     a12x2);

(1)

(a22     a21a   1

11 a12)x2 = b2     a21a   1
11 b1

solving linear equations by block elimination.

given a nonsingular set of linear equations (1), with a11 nonsingular.

11 a12 and a   1

1. form a   1
11 b1.
2. form s = a22     a21a   1
3. determine x2 by solving sx2 =   b.
4. determine x1 by solving a11x1 = b1     a12x2.

11 a12 and   b = b2     a21a   1

11 b1.

numerical id202 background

9   12

dominant terms in    op count

2n1 (cost dominated by product of a21 and a   1

    step 1: f + n2s (f is cost of factoring a11; s is cost of solve step)
    step 2: 2n2
    step 3: (2/3)n3
total: f + n2s + 2n2

2n1 + (2/3)n3
2

11 a12)

2

examples
    general a11 (f = (2/3)n3
1 + 2n2

#   ops = (2/3)n3

1, s = 2n2

1): no gain over standard method

1n2 + 2n2

2n1 + (2/3)n3

2 = (2/3)(n1 + n2)3

    block elimination is useful for structured a11 (f     n3
1)
for example, diagonal (f = 0, s = n1): #   ops     2n2
2n1 + (2/3)n3
2

numerical id202 background

9   13

structured matrix plus low rank term

(a + bc)x = b

    a     rn  n, b     rn  p, c     rp  n
    assume a has structure (ax = b easy to solve)
   rst write as

c    i (cid:21)(cid:20) x
(cid:20) a b

0 (cid:21)
y (cid:21) =(cid:20) b

now apply block elimination: solve

(i + ca   1b)y = ca   1b,

then solve ax = b     by
this proves the matrix inversion lemma: if a and a + bc nonsingular,

(a + bc)   1 = a   1     a   1b(i + ca   1b)   1ca   1

numerical id202 background

9   14

example: a diagonal, b, c dense

    method 1: form d = a + bc, then solve dx = b

cost: (2/3)n3 + 2pn2

    method 2 (via matrix inversion lemma): solve

(i + ca   1b)y = ca   1b,

(2)

then compute x = a   1b     a   1by
total cost is dominated by (2): 2p2n + (2/3)p3 (i.e., linear in n)

numerical id202 background

9   15

underdetermined linear equations

if a     rp  n with p < n, rank a = p,

{x | ax = b} = {f z +   x | z     rn   p}

      x is (any) particular solution
    columns of f     rn  (n   p) span nullspace of a
    there exist several numerical methods for computing f
(qr factorization, rectangular lu factorization, . . . )

numerical id202 background

9   16

10. unconstrained minimization

id76     boyd & vandenberghe

    terminology and assumptions
    id119 method
    steepest descent method
    newton   s method
    self-concordant functions
    implementation

10   1

unconstrained minimization

minimize f (x)

    f convex, twice continuously di   erentiable (hence dom f open)
    we assume optimal value p    = inf x f (x) is attained (and    nite)

unconstrained minimization methods
    produce sequence of points x(k)     dom f , k = 0, 1, . . . with

f (x(k))     p   

    can be interpreted as iterative methods for solving optimality condition

   f (x   ) = 0

unconstrained minimization

10   2

initial point and sublevel set

algorithms in this chapter require a starting point x(0) such that
    x(0)     dom f
    sublevel set s = {x | f (x)     f (x(0))} is closed
2nd condition is hard to verify, except when all sublevel sets are closed:
    equivalent to condition that epi f is closed
    true if dom f = rn
    true if f (x)         as x     bd dom f
examples of di   erentiable functions with closed sublevel sets:

f (x) = log(

mxi=1

exp(at

i x + bi)),

f (x) =    

mxi=1

log(bi     at

i x)

unconstrained minimization

10   3

strong convexity and implications

f is strongly convex on s if there exists an m > 0 such that

   2f (x) (cid:23) mi

for all x     s

implications

    for x, y     s,

f (y)     f (x) +    f (x)t (y     x) +

m
2 kx     yk2

2

hence, s is bounded

    p    >       , and for x     s,

f (x)     p       

1
2mk   f (x)k2

2

useful as stopping criterion (if you know m)

unconstrained minimization

10   4

descent methods

x(k+1) = x(k) + t(k)   x(k) with f (x(k+1)) < f (x(k))

    other notations: x+ = x + t   x, x := x + t   x
       x is the step, or search direction; t is the step size, or step length
    from convexity, f (x+) < f (x) implies    f (x)t    x < 0

(i.e.,    x is a descent direction)

general descent method.

given a starting point x     dom f .
repeat

1. determine a descent direction    x.
2. line search. choose a step size t > 0.
3. update. x := x + t   x.

until stopping criterion is satis   ed.

unconstrained minimization

10   5

line search types

exact line search: t = argmint>0 f (x + t   x)
backtracking line search (with parameters        (0, 1/2),        (0, 1))
    starting at t = 1, repeat t :=   t until

f (x + t   x) < f (x) +   t   f (x)t    x

    graphical interpretation: backtrack until t     t0

f (x + t   x)

f (x) + t   f (x)t    x

t = 0

t0

f (x) +   t   f (x)t    x
t

unconstrained minimization

10   6

id119 method

general descent method with    x =       f (x)

given a starting point x     dom f .
repeat

1.    x :=       f (x).
2. line search. choose step size t via exact or backtracking line search.
3. update. x := x + t   x.

until stopping criterion is satis   ed.

    stopping criterion usually of the form k   f (x)k2       
    convergence result: for strongly convex f ,

f (x(k))     p        ck(f (x(0))     p   )

c     (0, 1) depends on m, x(0), line search type

    very simple, but often very slow; rarely used in practice

unconstrained minimization

10   7

quadratic problem in r2

f (x) = (1/2)(x2

1 +   x2
2)

(   > 0)

with exact line search, starting at x(0) = (  , 1):

x(k)

   + 1(cid:19)k
1 =   (cid:18)       1

,

x(k)

2 =(cid:18)   

       1

   + 1(cid:19)k

    very slow if        1 or        1
    example for    = 10:

4

2
x

0

   4

   10

0
x1

x(0)

x(1)

10

unconstrained minimization

10   8

nonquadratic example

f (x1, x2) = ex1+3x2   0.1 + ex1   3x2   0.1 + e   x1   0.1

x(0)

x(2)

x(1)

x(0)

x(1)

backtracking line search

exact line search

unconstrained minimization

10   9

a problem in r100

f (x) = ct x    

500xi=1

log(bi     at

i x)

   
p
   
)
)
k
(
x
(
f

104

102

100

10   2

10   4
0

exact l.s.

backtracking l.s.

50

100
k

150

200

   linear    convergence, i.e., a straight line on a semilog plot

unconstrained minimization

10   10

steepest descent method

normalized steepest descent direction (at x, for norm k    k):

   xnsd = argmin{   f (x)t v | kvk = 1}
interpretation: for small v, f (x + v)     f (x) +    f (x)t v;
direction    xnsd is unit-norm step with most negative directional derivative

(unnormalized) steepest descent direction

   xsd = k   f (x)k      xnsd

   

satis   es    f (x)t    xsd =    k   f (x)k2
steepest descent method
    general descent method with    x =    xsd
    convergence properties similar to id119

unconstrained minimization

10   11

examples

    euclidean norm:    xsd =       f (x)
    quadratic norm kxkp = (xt p x)1/2 (p     sn
++):    xsd =    p    1   f (x)
       1-norm:    xsd =    (   f (x)/   xi)ei, where |   f (x)/   xi| = k   f (x)k   

unit balls and normalized steepest descent directions for a quadratic norm
and the    1-norm:

      f (x)

   xnsd

      f (x)

   xnsd

unconstrained minimization

10   12

choice of norm for steepest descent

x(0)

x(1)

x(2)

x(0)
x(2)

x(1)

    steepest descent with backtracking line search for two quadratic norms
    ellipses show {x | kx     x(k)kp = 1}
    equivalent interpretation of steepest descent with quadratic norm k    kp :

id119 after change of variables   x = p 1/2x

shows choice of p has strong e   ect on speed of convergence

unconstrained minimization

10   13

newton step

   xnt =       2f (x)   1   f (x)

interpretations

    x +    xnt minimizes second order approximation
1
2

    x +    xnt solves linearized optimality condition

vt   2f (x)v

bf (x + v) = f (x) +    f (x)t v +
   f (x + v)        bf (x + v) =    f (x) +    2f (x)v = 0

(x, f (x))

(x +    xnt, f (x +    xnt))

unconstrained minimization

bf

f

bf    
f    

(x +    xnt, f    (x +    xnt))

(x, f    (x))

10   14

       xnt is steepest descent direction at x in local hessian norm

kuk   2f (x) =(cid:0)ut   2f (x)u(cid:1)1/2

x

x +    xnsd
x +    xnt

dashed lines are contour lines of f ; ellipse is {x + v | vt   2f (x)v = 1}
arrow shows       f (x)

unconstrained minimization

10   15

newton decrement

  (x) =(cid:0)   f (x)t   2f (x)   1   f (x)(cid:1)1/2

a measure of the proximity of x to x   

properties

    gives an estimate of f (x)     p   , using quadratic approximation bf :

    equal to the norm of the newton step in the quadratic hessian norm

f (x)     inf

  (x) =(cid:0)   xt

1
2

  (x)2

y bf (y) =
nt   2f (x)   xnt(cid:1)1/2

    directional derivative in the newton direction:    f (x)t    xnt =      (x)2
    a   ne invariant (unlike k   f (x)k2)

unconstrained minimization

10   16

newton   s method

given a starting point x     dom f , tolerance    > 0.
repeat

1. compute the newton step and decrement.

   xnt :=       2f (x)   1   f (x);   2 :=    f (x)t    2f (x)   1   f (x).

2. stopping criterion. quit if   2/2       .
3. line search. choose step size t by backtracking line search.
4. update. x := x + t   xnt.

a   ne invariant, i.e., independent of linear changes of coordinates:

newton iterates for   f (y) = f (t y) with starting point y(0) = t    1x(0) are

y(k) = t    1x(k)

unconstrained minimization

10   17

classical convergence analysis

assumptions
    f strongly convex on s with constant m
       2f is lipschitz continuous on s, with constant l > 0:

k   2f (x)        2f (y)k2     lkx     yk2

(l measures how well f can be approximated by a quadratic function)

outline: there exist constants        (0, m2/l),    > 0 such that
    if k   f (x)k2       , then f (x(k+1))     f (x(k))          
    if k   f (x)k2 <   , then

l

2m2k   f (x(k+1))k2    (cid:18) l

2m2k   f (x(k))k2(cid:19)2

unconstrained minimization

10   18

damped newton phase (k   f (x)k2       )
    most iterations require backtracking steps
    function value decreases by at least   
    if p    >       , this phase ends after at most (f (x(0))     p   )/   iterations

quadratically convergent phase (k   f (x)k2 <   )
    all iterations use step size t = 1
    k   f (x)k2 converges to zero quadratically: if k   f (x(k))k2 <   , then

l

2m2k   f (xl)k2    (cid:18) l

2m2k   f (xk)k2(cid:19)2l   k

   (cid:18)1
2(cid:19)2l   k

,

l     k

unconstrained minimization

10   19

conclusion: number of iterations until f (x)     p           is bounded above by

f (x(0))     p   

  

+ log2 log2(  0/  )

      ,   0 are constants that depend on m, l, x(0)
    second term is small (of the order of 6) and almost constant for

practical purposes

    in practice, constants m, l (hence   ,   0) are usually unknown
    provides qualitative insight in convergence properties (i.e., explains two

algorithm phases)

unconstrained minimization

10   20

examples

example in r2 (page 10   9)

x(0)

x(1)

   
p
   
)
)
k
(
x
(
f

105

100

10   5

10   10

10   15
0

    backtracking parameters    = 0.1,    = 0.7
    converges in only 5 steps
    quadratic local convergence

1

2

k

3

4

5

unconstrained minimization

10   21

example in r100 (page 10   10)

   
p
   
)
)
k
(
x
(
f

105

100

10   5

10   10

10   15
0

backtracking

exact line search

2

1.5

)
k
(
t

1

e
z
i
s

p
e
t
s

0.5

exact line search

backtracking

2

4

k

6

8

10

0
0

2

4
k

6

8

    backtracking parameters    = 0.01,    = 0.5
    backtracking line search almost as fast as exact l.s. (and much simpler)
    clearly shows two phases in algorithm

unconstrained minimization

10   22

example in r10000 (with sparse ai)

f (x) =    

10000xi=1

log(1     x2

i )    

100000xi=1

log(bi     at

i x)

105

100

10   5

   
p
   
)
)
k
(
x
(
f

0

5

10
k

15

20

    backtracking parameters    = 0.01,    = 0.5.
    performance similar as for small examples

unconstrained minimization

10   23

self-concordance

shortcomings of classical convergence analysis

    depends on unknown constants (m, l, . . . )
    bound is not a   nely invariant, although newton   s method is

convergence analysis via self-concordance (nesterov and nemirovski)

    does not depend on any unknown constants
    gives a   ne-invariant bound
    applies to special class of convex functions (   self-concordant    functions)
    developed to analyze polynomial-time interior-point methods for convex

optimization

unconstrained minimization

10   24

self-concordant functions

de   nition
    convex f : r     r is self-concordant if |f          (x)|     2f       (x)3/2 for all

    f : rn     r is self-concordant if g(t) = f (x + tv) is self-concordant for

x     dom f

all x     dom f , v     rn

examples on r
    linear and quadratic functions
    negative logarithm f (x) =     log x
    negative id178 plus negative logarithm: f (x) = x log x     log x
a   ne invariance: if f : r     r is s.c., then   f (y) = f (ay + b) is s.c.:

  f          (y) = a3f          (ay + b),

  f       (y) = a2f       (ay + b)

unconstrained minimization

10   25

self-concordant calculus

properties

    preserved under positive scaling        1, and sum
    preserved under composition with a   ne function
    if g is convex with dom g = r++ and |g         (x)|     3g      (x)/x then

f (x) = log(   g(x))     log x

is self-concordant

examples: properties can be used to show that the following are s.c.

    f (x) =    pm
i=1 log(bi     at
    f (x) =     log det x on sn
    f (x) =     log(y2     xt x) on {(x, y) | kxk2 < y}

i x) on {x | at

++

i x < bi, i = 1, . . . , m}

unconstrained minimization

10   26

convergence analysis for self-concordant functions

summary: there exist constants        (0, 1/4],    > 0 such that
    if   (x) >   , then

    if   (x)       , then

f (x(k+1))     f (x(k))          
2  (x(k+1))    (cid:16)2  (x(k))(cid:17)2

(   and    only depend on backtracking parameters   ,   )

complexity bound: number of newton iterations bounded by

f (x(0))     p   

  

+ log2 log2(1/  )

for    = 0.1,    = 0.8,    = 10   10, bound evaluates to 375(f (x(0))     p   ) + 6

unconstrained minimization

10   27

numerical example: 150 randomly generated instances of

minimize f (x) =    pm

25

i=1 log(bi     at

i x)

   : m = 100, n = 50

(cid:3): m = 1000, n = 500
   : m = 1000, n = 50

20

15

10

s
n
o
i
t
a
r
e
t
i

5

0
0

5

10

15

20

25

30

35

f (x(0))     p   

    number of iterations much smaller than 375(f (x(0))     p   ) + 6
    bound of the form c(f (x(0))     p   ) + 6 with smaller c (empirically) valid

unconstrained minimization

10   28

implementation

main e   ort in each iteration: evaluate derivatives and solve newton system

h   x =    g

where h =    2f (x), g =    f (x)

via cholesky factorization

h = llt ,

   xnt =    l   t l   1g,

  (x) = kl   1gk2

    cost (1/3)n3    ops for unstructured system
    cost     (1/3)n3 if h sparse, banded

unconstrained minimization

10   29

example of dense newton system with structure

f (x) =

nxi=1

  i(xi) +   0(ax + b),

h = d + at h0a

    assume a     rp  n, dense, with p     n
    d diagonal with diagonal elements         
method 1: form h, solve via dense cholesky factorization: (cost (1/3)n3)

i (xi); h0 =    2  0(ax + b)

method 2 (page 9   15): factor h0 = l0lt

0 ; write newton system as

lt
0 a   x     w = 0
eliminate    x from    rst equation; compute w and    x from

d   x + at l0w =    g,

(i + lt

0 ad   1at l0)w =    lt

0 ad   1g,

d   x =    g     at l0w

cost: 2p2n (dominated by computation of lt

0 ad   1at l0)

unconstrained minimization

10   30

11. equality constrained minimization

id76     boyd & vandenberghe

    equality constrained minimization
    eliminating equality constraints
    newton   s method with equality constraints
    infeasible start id77
    implementation

11   1

equality constrained minimization

minimize
subject to ax = b

f (x)

    f convex, twice continuously di   erentiable
    a     rp  n with rank a = p
    we assume p    is    nite and attained

optimality conditions: x    is optimal i    there exists a       such that

   f (x   ) + at       = 0,

ax    = b

equality constrained minimization

11   2

equality constrained quadratic minimization (with p     sn
+)

minimize
subject to ax = b

(1/2)xt p x + qt x + r

optimality condition:

(cid:20) p at
a 0 (cid:21)(cid:20) x   

      (cid:21) =(cid:20)    q
b (cid:21)

    coe   cient matrix is called kkt matrix
    kkt matrix is nonsingular if and only if

ax = 0,

x 6= 0

=   

xt p x > 0

    equivalent condition for nonsingularity: p + at a     0

equality constrained minimization

11   3

eliminating equality constraints

represent solution of {x | ax = b} as

{x | ax = b} = {f z +   x | z     rn   p}

      x is (any) particular solution
    range of f     rn  (n   p) is nullspace of a (rank f = n    p and af = 0)
reduced or eliminated problem

minimize f (f z +   x)

    an unconstrained problem with variable z     rn   p
    from solution z   , obtain x    and       as

x    = f z    +   x,

      =    (aat )   1a   f (x   )

equality constrained minimization

11   4

example: optimal allocation with resource constraint

minimize
subject to x1 + x2 +        + xn = b

f1(x1) + f2(x2) +        + fn(xn)

eliminate xn = b     x1                xn   1, i.e., choose

  x = ben,

f =(cid:20)

i

   1t (cid:21)     rn  (n   1)

reduced problem:

minimize f1(x1) +        + fn   1(xn   1) + fn(b     x1                xn   1)

(variables x1, . . . , xn   1)

equality constrained minimization

11   5

newton step

newton step    xnt of f at feasible x is given by solution v of

(cid:20)    2f (x) at

0 (cid:21)(cid:20) v

w (cid:21) =(cid:20)       f (x)

a

0

(cid:21)

interpretations

       xnt solves second order approximation (with variable v)

minimize
subject to a(x + v) = b

bf (x + v) = f (x) +    f (x)t v + (1/2)vt   2f (x)v

       xnt equations follow from linearizing optimality conditions

   f (x + v) + at w        f (x) +    2f (x)v + at w = 0,

a(x + v) = b

equality constrained minimization

11   6

newton decrement

properties

  (x) =(cid:0)   xt

nt   2f (x)   xnt(cid:1)1/2

=(cid:0)      f (x)t    xnt(cid:1)1/2
    gives an estimate of f (x)     p    using quadratic approximation bf :

  (x)2

1
2

f (x)     inf

ay=bbf (y) =
f (x + t   xnt)(cid:12)(cid:12)(cid:12)(cid:12)t=0

d
dt

    directional derivative in newton direction:

=      (x)2
    in general,   (x) 6=(cid:0)   f (x)t   2f (x)   1   f (x)(cid:1)1/2

equality constrained minimization

11   7

newton   s method with equality constraints

given starting point x     dom f with ax = b, tolerance    > 0.
repeat

1. compute the newton step and decrement    xnt,   (x).
2. stopping criterion. quit if   2/2       .
3. line search. choose step size t by backtracking line search.
4. update. x := x + t   xnt.

    a feasible descent method: x(k) feasible and f (x(k+1)) < f (x(k))
    a   ne invariant

equality constrained minimization

11   8

newton   s method and elimination

newton   s method for reduced problem

minimize

  f (z) = f (f z +   x)

    variables z     rn   p
      x satis   es a  x = b; rank f = n     p and af = 0
    newton   s method for   f , started at z(0), generates iterates z(k)
newton   s method with equality constraints

when started at x(0) = f z(0) +   x, iterates are

x(k+1) = f z(k) +   x

hence, don   t need separate convergence analysis

equality constrained minimization

11   9

newton step at infeasible points

2nd interpretation of page 11   6 extends to infeasible x (i.e., ax 6= b)
linearizing optimality conditions at infeasible x (with x     dom f ) gives

(cid:20)    2f (x) at

0 (cid:21)(cid:20)    xnt

w (cid:21) =    (cid:20)    f (x)
ax     b (cid:21)

a

(1)

primal-dual interpretation
    write optimality condition as r(y) = 0, where

y = (x,   ),

r(y) = (   f (x) + at   , ax     b)
    linearizing r(y) = 0 gives r(y +    y)     r(y) + dr(y)   y = 0:

(cid:20)    2f (x) at

0 (cid:21)(cid:20)    xnt

     nt (cid:21) =    (cid:20)    f (x) + at   

ax     b

a

(cid:21)

same as (1) with w =    +      nt

equality constrained minimization

11   10

infeasible start id77

given starting point x     dom f ,   , tolerance    > 0,        (0, 1/2),        (0, 1).
repeat

1. compute primal and dual newton steps    xnt,      nt.
2. backtracking line search on krk2.

t := 1.
while kr(x + t   xnt,    + t     nt)k2 > (1       t)kr(x,   )k2,

t :=   t.

3. update. x := x + t   xnt,    :=    + t     nt.

until ax = b and kr(x,   )k2       .

    not a descent method: f (x(k+1)) > f (x(k)) is possible
    directional derivative of kr(y)k2 in direction    y = (   xnt,      nt) is

d

dt kr(y + t   y)k2(cid:12)(cid:12)(cid:12)(cid:12)t=0

=    kr(y)k2

equality constrained minimization

11   11

solving kkt systems

(cid:20) h at
a 0 (cid:21)(cid:20) v

h (cid:21)
w (cid:21) =    (cid:20) g

solution methods

    ldlt factorization
    elimination (if h nonsingular)

ah    1at w = h     ah    1g,

hv =    (g + at w)

    elimination with singular h: write as

(cid:20) h + at qa at

0 (cid:21)(cid:20) v

w (cid:21) =    (cid:20) g + at qh

a

h

(cid:21)

with q (cid:23) 0 for which h + at qa     0, and apply elimination

equality constrained minimization

11   12

equality constrained analytic centering

i=1 log xi subject to ax = b

primal problem: minimize    pn
dual problem: maximize    bt    +pn
three methods for an example with a     r100  500, di   erent starting points
1. id77 with equality constraints (requires x(0)     0, ax(0) = b)

i=1 log(at   )i + n

   
p
   

)
)
k
(
x
(
f

105

100

10   5

10   10
0

5

10
k

15

20

equality constrained minimization

11   13

2. id77 applied to dual problem (requires at   (0)     0)

)
)
k
(
  
(
g
   

   
p

105

100

10   5

10   10
0

2

4

k

6

8

10

3. infeasible start id77 (requires x(0)     0)

2
k
)
)
k
(
  
,

)
k
(
x
(
r
k

1010

105

100

10   5

10   10

10   15
0

5

10

k

15

20

25

equality constrained minimization

11   14

complexity per iteration of three methods is identical

1. use block elimination to solve kkt system

(cid:20) diag(x)   2 at

0 (cid:21)(cid:20)    x

w (cid:21) =(cid:20) diag(x)   11

a

0

(cid:21)

reduces to solving a diag(x)2at w = b

2. solve newton system a diag(at   )   2at       =    b + a diag(at   )   11
3. use block elimination to solve kkt system

(cid:20) diag(x)   2 at

0 (cid:21)(cid:20)    x

      (cid:21) =(cid:20) diag(x)   11     at   

b     ax

a

(cid:21)

reduces to solving a diag(x)2at w = 2ax     b

conclusion: in each case, solve adat w = h with d positive diagonal

equality constrained minimization

11   15

    directed graph with n arcs, p + 1 nodes
    xi:    ow through arc i;   i: cost    ow function for arc i (with         
    node-incidence matrix   a     r(p+1)  n de   ned as

i (x) > 0)

network    ow optimization

minimize pn

subject to ax = b

i=1   i(xi)

  aij =         

1 arc j leaves node i
   1 arc j enters node i
0 otherwise

    reduced node-incidence matrix a     rp  n is   a with last row removed
    b     rp is (reduced) source vector
    rank a = p if graph is connected

equality constrained minimization

11   16

kkt system

(cid:20) h at
a 0 (cid:21)(cid:20) v

w (cid:21) =    (cid:20) g
h (cid:21)

1(x1), . . . ,         

n(xn)), positive diagonal

    h = diag(        
    solve via elimination:

ah    1at w = h     ah    1g,

hv =    (g + at w)

sparsity pattern of coe   cient matrix is given by graph connectivity

(ah    1at )ij 6= 0        (aat )ij 6= 0

       nodes i and j are connected by an arc

equality constrained minimization

11   17

analytic center of linear matrix inequality

minimize     log det x
subject to tr(aix) = bi,

i = 1, . . . , p

variable x     sn
optimality conditions

x         0,

   (x    )   1 +

pxj=1

     
j ai = 0,

tr(aix    ) = bi,

i = 1, . . . , p

newton equation at feasible x:

x    1   xx    1 +

pxj=1

wjai = x    1,

tr(ai   x) = 0,

i = 1, . . . , p

    follows from linear approximation (x +    x)   1     x    1     x    1   xx    1
    n(n + 1)/2 + p variables    x, w

equality constrained minimization

11   18

solution by block elimination

    eliminate    x from    rst equation:    x = x    pp

    substitute    x in second equation

j=1 wjxajx

tr(aixajx)wj = bi,

i = 1, . . . , p

(2)

pxj=1

a dense positive de   nite set of linear equations with variable w     rp

   op count (dominant terms) using cholesky factorization x = llt :

    form p products lt ajl: (3/2)pn3
    form p(p + 1)/2 inner products tr((lt ail)(lt ajl)): (1/2)p2n2
    solve (2) via cholesky factorization: (1/3)p3

equality constrained minimization

11   19

12. interior-point methods

id76     boyd & vandenberghe

    inequality constrained minimization
    logarithmic barrier function and central path
    barrier method
    feasibility and phase i methods
    complexity analysis via self-concordance
    generalized inequalities

12   1

inequality constrained minimization

f0(x)

minimize
subject to fi(x)     0,

ax = b

i = 1, . . . , m

(1)

    fi convex, twice continuously di   erentiable
    a     rp  n with rank a = p
    we assume p    is    nite and attained
    we assume problem is strictly feasible: there exists   x with

  x     dom f0,

fi(  x) < 0,

i = 1, . . . , m,

a  x = b

hence, strong duality holds and dual optimum is attained

interior-point methods

12   2

examples

    lp, qp, qcqp, gp
    id178 maximization with linear inequality constraints

minimize pn

subject to f x (cid:22) g
ax = b

i=1 xi log xi

with dom f0 = rn

++

    di   erentiability may require reformulating the problem, e.g.,

piecewise-linear minimization or       -norm approximation via lp

    sdps and socps are better handled as problems with generalized

inequalities (see later)

interior-point methods

12   3

logarithmic barrier

reformulation of (1) via indicator function:

minimize
subject to ax = b

f0(x) +pm

i=1 i   (fi(x))

where i   (u) = 0 if u     0, i   (u) =     otherwise (indicator function of r   )
approximation via logarithmic barrier

minimize
subject to ax = b

f0(x)     (1/t)pm

i=1 log(   fi(x))

    an equality constrained problem
    for t > 0,    (1/t) log(   u) is a
smooth approximation of i   

    approximation improves as t        

10

5

0

   5

   3

   2

   1
u

0

1

interior-point methods

12   4

logarithmic barrier function

  (x) =    

mxi=1

log(   fi(x)), dom    = {x | f1(x) < 0, . . . , fm(x) < 0}

    convex (follows from composition rules)
    twice continuously di   erentiable, with derivatives

     (x) =

   2  (x) =

mxi=1
mxi=1

1

   fi(x)   fi(x)
fi(x)2   fi(x)   fi(x)t +

1

mxi=1

1

   fi(x)   2fi(x)

interior-point methods

12   5

central path

    for t > 0, de   ne x   (t) as the solution of

minimize
subject to ax = b

tf0(x) +   (x)

(for now, assume x   (t) exists and is unique for each t > 0)

    central path is {x   (t) | t > 0}

example: central path for an lp

c

minimize
subject to at

ct x
i x     bi,

i = 1, . . . , 6

hyperplane ct x = ct x   (t) is tangent to
level curve of    through x   (t)

x   (10)

x   

interior-point methods

12   6

dual points on central path

x = x   (t) if there exists a w such that

t   f0(x) +

mxi=1

1

   fi(x)   fi(x) + at w = 0,

ax = b

    therefore, x   (t) minimizes the lagrangian

l(x,      (t),      (t)) = f0(x) +

mxi=1

     
i (t)fi(x) +      (t)t (ax     b)

where we de   ne      

i (t) = 1/(   tfi(x   (t)) and      (t) = w/t

    this con   rms the intuitive idea that f0(x   (t))     p    if t        :

p        g(     (t),      (t))

= l(x   (t),      (t),      (t))
= f0(x   (t))     m/t

interior-point methods

12   7

interpretation via kkt conditions

x = x   (t),    =      (t),    =      (t) satisfy

1. primal constraints: fi(x)     0, i = 1, . . . , m, ax = b
2. dual constraints:    (cid:23) 0
3. approximate complementary slackness:      ifi(x) = 1/t, i = 1, . . . , m
4. gradient of lagrangian with respect to x vanishes:

   f0(x) +

mxi=1

  i   fi(x) + at    = 0

di   erence with kkt is that condition 3 replaces   ifi(x) = 0

interior-point methods

12   8

force    eld interpretation

centering problem (for problem with no equality constraints)

minimize

tf0(x)    pm

i=1 log(   fi(x))

force    eld interpretation

    tf0(x) is potential of force    eld f0(x) =    t   f0(x)
        log(   fi(x)) is potential of force    eld fi(x) = (1/fi(x))   fi(x)
the forces balance at x   (t):

f0(x   (t)) +

mxi=1

fi(x   (t)) = 0

interior-point methods

12   9

example

minimize
subject to at

ct x
i x     bi,

i = 1, . . . , m

    objective force    eld is constant: f0(x) =    tc
    constraint force    eld decays as inverse distance to constraint hyperplane:

fi(x) =    ai
bi     at
i x
i x = bi}

where hi = {x | at

,

kfi(x)k2 =

1

dist(x,hi)

   c

t = 1

   3c

t = 3

interior-point methods

12   10

barrier method

given strictly feasible x, t := t(0) > 0,    > 1, tolerance    > 0.
repeat
1. centering step. compute x   (t) by minimizing tf0 +   , subject to ax = b.
2. update. x := x   (t).
3. stopping criterion. quit if m/t <   .
4.

increase t. t :=   t.

    terminates with f0(x)     p           (stopping criterion follows from

f0(x   (t))     p        m/t)

    centering usually done using newton   s method, starting at current x
    choice of    involves a trade-o   : large    means fewer outer iterations,

more inner (newton) iterations; typical values:    = 10   20

    several heuristics for choice of t(0)

interior-point methods

12   11

convergence analysis

number of outer (centering) iterations: exactly

(cid:24)log(m/(  t(0)))

log   

(cid:25)

plus the initial centering step (to compute x   (t(0)))

centering problem

minimize

tf0(x) +   (x)

see convergence analysis of newton   s method
    tf0 +    must have closed sublevel sets for t     t(0)
    classical analysis requires strong convexity, lipschitz condition
    analysis via self-concordance requires self-concordance of tf0 +   

interior-point methods

12   12

examples

inequality form lp (m = 100 inequalities, n = 50 variables)

p
a
g

y
t
i
l

a
u
d

102

100

10   2

10   4

10   6

   = 50    = 150

   = 2

0

20

40

60

80

newton iterations

s
n
o
i
t
a
r
e
t
i

n
o
t
w
e
n

140

120

100

80

60

40

20

0
0

40

80

120

160

200

  

    starts with x on central path (t(0) = 1, duality gap 100)
    terminates when t = 108 (gap 10   6)
    centering uses newton   s method with backtracking
    total number of newton iterations not very sensitive for        10

interior-point methods

12   13

geometric program (m = 100 inequalities and n = 50 variables)

minimize

log(cid:16)p5
subject to log(cid:16)p5

k=1 exp(at
k=1 exp(at

0kx + b0k)(cid:17)
ikx + bik)(cid:17)     0,

i = 1, . . . , m

102

100

10   2

10   4

p
a
g

y
t
i
l

a
u
d

10   6

   = 150

   = 50

   = 2

0

20

60

40
80
newton iterations

100

120

interior-point methods

12   14

family of standard lps (a     rm  2m)
ct x

minimize
subject to ax = b,

x (cid:23) 0

m = 10, . . . , 1000; for each m, solve 100 randomly generated instances

35

30

25

20

s
n
o
i
t
a
r
e
t
i

n
o
t
w
e
n

15

101

102
m

103

number of iterations grows very slowly as m ranges over a 100 : 1 ratio

interior-point methods

12   15

feasibility and phase i methods

feasibility problem:    nd x such that

fi(x)     0,

i = 1, . . . , m,

ax = b

(2)

phase i: computes strictly feasible starting point for barrier method

basic phase i method

minimize (over x, s)
subject to

s
fi(x)     s,
ax = b

i = 1, . . . , m

(3)

    if x, s feasible, with s < 0, then x is strictly feasible for (2)
    if optimal value   p    of (3) is positive, then problem (2) is infeasible
    if   p    = 0 and attained, then problem (2) is feasible (but not strictly);

if   p    = 0 and not attained, then problem (2) is infeasible

interior-point methods

12   16

sum of infeasibilities phase i method

1t s

minimize
subject to s (cid:23) 0,
ax = b

fi(x)     si,

i = 1, . . . , m

for infeasible problems, produces a solution that satis   es many more
inequalities than basic phase i method

example (infeasible set of 100 linear inequalities in 50 variables)

60

r
e
b
m
u
n

40

20

0
   1    0.5

0

0.5

bi     at

i xmax

60

r
e
b
m
u
n

40

20

1

1.5

0
   1    0.5

0

0.5

bi     at

i xsum

1

1.5

left: basic phase i solution; satis   es 39 inequalities
right: sum of infeasibilities phase i solution; satis   es 79 inequalities

interior-point methods

12   17

example: family of linear inequalities ax (cid:22) b +      b
    data chosen to be strictly feasible for    > 0, infeasible for        0
    use basic phase i, terminate when s < 0 or dual objective is positive

s
n
o
i
t
a
r
e
t
i

n
o
t
w
e
n

infeasible

feasible

100

80

60

40

20

0
   1

   0.5

0
  

0.5

1

s
n
o
i
t
a
r
e
t
i

n
o
t
w
e
n

100

80

60

40

20

0
   100

100

s
n
o
i
t
a
r
e
t
i

80

60

40

20

0
10   6

10   4

  

10   2

100

n
o
t
w
e
n

   10   2    10   4    10   6

  

number of iterations roughly proportional to log(1/|  |)

interior-point methods

12   18

complexity analysis via self-concordance

same assumptions as on page 12   2, plus:

    sublevel sets (of f0, on the feasible set) are bounded
    tf0 +    is self-concordant with closed sublevel sets

second condition

    holds for lp, qp, qcqp
    may require reformulating the problem, e.g.,

minimize pn

subject to f x (cid:22) g

i=1 xi log xi

       minimize pn

subject to f x (cid:22) g,

i=1 xi log xi

x (cid:23) 0

    needed for complexity analysis; barrier method works even when

self-concordance assumption does not apply

interior-point methods

12   19

newton iterations per centering step: from self-concordance theory

#newton iterations    

  tf0(x) +   (x)       tf0(x+)       (x+)

  

+ c

    bound on e   ort of computing x+ = x   (  t) starting at x = x   (t)
      , c are constants (depend only on newton algorithm parameters)
    from duality (with    =      (t),    =      (t)):
  tf0(x) +   (x)       tf0(x+)       (x+)
mxi=1
log(     t  ifi(x+))     m log   
mxi=1
      tf0(x)       tf0(x+)       t
      tf0(x)       tg(  ,   )     m     m log   
= m(       1     log   )

=   tf0(x)       tf0(x+) +

  ifi(x+)     m     m log   

interior-point methods

12   20

total number of newton iterations (excluding    rst centering step)

#newton iterations     n =(cid:24)log(m/(t(0)  ))

log   

(cid:25)(cid:18)m(       1     log   )

  

+ c(cid:19)

5 104

4 104

3 104

n

2 104

1 104

0
1

1.1
  

1.2

   gure shows n for typical values of   , c,

m = 100,

m
t(0)  

= 105

    con   rms trade-o    in choice of   
    in practice, #iterations is in the tens; not very sensitive for        10

interior-point methods

12   21

polynomial-time complexity of barrier method

    for    = 1 + 1/   m:

n = o(cid:18)   m log(cid:18)m/t(0)
   (cid:19)(cid:19)

    number of newton iterations for    xed gap reduction is o(   m)
    multiply with cost of one newton iteration (a polynomial function of

problem dimensions), to get bound on number of    ops

this choice of    optimizes worst-case complexity; in practice we choose   
   xed (   = 10, . . . , 20)

interior-point methods

12   22

generalized inequalities

f0(x)

minimize
subject to fi(x) (cid:22)ki 0,

ax = b

i = 1, . . . , m

    f0 convex, fi : rn     rki, i = 1, . . . , m, convex with respect to proper

cones ki     rki

    fi twice continuously di   erentiable
    a     rp  n with rank a = p
    we assume p    is    nite and attained
    we assume problem is strictly feasible; hence strong duality holds and

dual optimum is attained

examples of greatest interest: socp, sdp

interior-point methods

12   23

generalized logarithm for proper cone

   : rq     r is generalized logarithm for proper cone k     rq if:
    dom    = int k and    2  (y)     0 for y    k 0
      (sy) =   (y) +    log s for y    k 0, s > 0 (   is the degree of   )

examples
    nonnegative orthant k = rn
    positive semide   nite cone k = sn
+:

+:   (y) =pn

i=1 log yi, with degree    = n

  (y ) = log det y

(   = n)

    second-order cone k = {y     rn+1 | (y2

1 +        + y2

  (y) = log(y2

n+1     y2

1                y2
n)

n)1/2     yn+1}:
(   = 2)

interior-point methods

12   24

properties (without proof): for y    k 0,

     (y) (cid:23)k    0,

yt     (y) =   

    nonnegative orthant rn

+:   (y) =pn

i=1 log yi

     (y) = (1/y1, . . . , 1/yn),

yt     (y) = n

    positive semide   nite cone sn

+:   (y ) = log det y

     (y ) = y    1,

    second-order cone k = {y     rn+1 | (y2

n)1/2     yn+1}:

     (y) =

2
y2
n+1     y2
1                y2

n

yt     (y) = 2

tr(y      (y )) = n
1 +        + y2
   y1
...
   yn
yn+1

             ,

            

interior-point methods

12   25

logarithmic barrier and central path

logarithmic barrier for f1(x) (cid:22)k1 0, . . . , fm(x) (cid:22)km 0:

  (x) =    

mxi=1

  i(   fi(x)),

dom    = {x | fi(x)    ki 0, i = 1, . . . , m}

      i is generalized logarithm for ki, with degree   i
       is convex, twice continuously di   erentiable

central path: {x   (t) | t > 0} where x   (t) solves
tf0(x) +   (x)

minimize
subject to ax = b

interior-point methods

12   26

dual points on central path

x = x   (t) if there exists w     rp,

t   f0(x) +

mxi=1

dfi(x)t     i(   fi(x)) + at w = 0

(dfi(x)     rki  n is derivative matrix of fi)
    therefore, x   (t) minimizes lagrangian l(x,      (t),      (t)), where

     
i (t) =

1
t     i(   fi(x   (t))),

     (t) =

w
t

    from properties of   i:      

i (t)    k   

i

0, with duality gap

f0(x   (t))     g(     (t),      (t)) = (1/t)

  i

mxi=1

interior-point methods

12   27

example: semide   nite programming (with fi     sp)

ct x

minimize

subject to f (x) =pn

i=1 xifi + g (cid:22) 0

    logarithmic barrier:   (x) = log det(   f (x)   1)
    central path: x   (t) minimizes tct x     log det(   f (x)); hence

tci     tr(fif (x   (t))   1) = 0,

i = 1, . . . , n

    dual point on central path: z    (t) =    (1/t)f (x   (t))   1 is feasible for

maximize
subject to tr(fiz) + ci = 0,

tr(gz)

i = 1, . . . , n

z (cid:23) 0

    duality gap on central path: ct x   (t)     tr(gz    (t)) = p/t

interior-point methods

12   28

barrier method

given strictly feasible x, t := t(0) > 0,    > 1, tolerance    > 0.
repeat
1. centering step. compute x   (t) by minimizing tf0 +   , subject to ax = b.
2. update. x := x   (t).
3. stopping criterion. quit if (pi   i)/t <   .
4.

increase t. t :=   t.

    only di   erence is duality gap m/t on central path is replaced bypi   i/t

    number of outer iterations:

&log((pi   i)/(  t(0)))

log   

'

    complexity analysis via self-concordance applies to sdp, socp

interior-point methods

12   29

examples

second-order cone program (50 variables, 50 soc constraints in r6)

p
a
g

y
t
i
l

a
u
d

102

100

10   2

10   4

10   6

   = 50    = 200

   = 2

0

20

40

60

80

newton iterations

s
n
o
i
t
a
r
e
t
i

n
o
t
w
e
n

120

80

40

0

20

60

100
  

140

180

semide   nite program (100 variables, lmi constraint in s100)

p
a
g

y
t
i
l

a
u
d

102

100

10   2

10   4

10   6

   = 150

   = 50

   = 2

140

100

60

20

s
n
o
i
t
a
r
e
t
i

n
o
t
w
e
n

0

20

40

60

80

100

newton iterations

0

20

40

60
  

80

100 120

interior-point methods

12   30

family of sdps (a     sn, x     rn)

1t x

minimize
subject to a + diag(x) (cid:23) 0

n = 10, . . . , 1000, for each n solve 100 randomly generated instances

35

30

25

20

s
n
o
i
t
a
r
e
t
i

n
o
t
w
e
n

15

101

102
n

103

interior-point methods

12   31

primal-dual interior-point methods

more e   cient than barrier method when high accuracy is needed

    update primal and dual variables at each iteration; no distinction

between inner and outer iterations

    often exhibit superlinear asymptotic convergence
    search directions can be interpreted as newton directions for modi   ed

kkt conditions

    can start at infeasible points
    cost per iteration same as barrier method

interior-point methods

12   32

id76     boyd & vandenberghe

13. conclusions

    main ideas of the course
    importance of modeling in optimization

13   1

modeling

mathematical optimization

    problems in engineering design, data analysis and statistics, economics,

management, . . . , can often be expressed as mathematical
optimization problems

    techniques exist to take into account multiple objectives or uncertainty

in the data

tractability

    roughly speaking, tractability in optimization requires convexity
    algorithms for nonid76    nd local (suboptimal) solutions,

or are very expensive

    surprisingly many applications can be formulated as convex problems

conclusions

13   2

theoretical consequences of convexity

    local optima are global
    extensive duality theory

    systematic way of deriving lower bounds on optimal value
    necessary and su   cient optimality conditions
    certi   cates of infeasibility
    sensitivity analysis

    solution methods with polynomial worst-case complexity theory

(with self-concordance)

conclusions

13   3

practical consequences of convexity

(most) convex problems can be solved globally and e   ciently

    interior-point methods require 20     80 steps in practice
    basic algorithms (e.g., newton, barrier method, . . . ) are easy to

implement and work well for small and medium size problems (larger
problems if structure is exploited)

    more and more high-quality implementations of advanced algorithms

and modeling tools are becoming available

    high level modeling tools like cvx ease modeling and problem

speci   cation

conclusions

13   4

how to use id76

to use id76 in some applied context

    use rapid prototyping, approximate modeling

    start with simple models, small problem instances, ine   cient solution

methods

    if you don   t like the results, no need to expend further e   ort on more

accurate models or e   cient algorithms

    work out, simplify, and interpret optimality conditions and dual
    even if the problem is quite nonconvex, you can use id76

    in subproblems, e.g., to    nd search direction
    by repeatedly forming and solving a convex approximation at the

current point

conclusions

13   5

further topics

some topics we didn   t cover:

    methods for very large scale problems
    subgradient calculus, convex analysis
    localization, subgradient, and related methods
    distributed id76
    applications that build on or use id76

conclusions

13   6

what   s next?

    ee364b     id76 ii
    math301     advanced topics in id76
    ms&e314     linear and conic optimization
    ee464     semide   nite optimization and algebraic techniques

conclusions

13   7

