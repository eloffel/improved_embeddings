   #[1]rss [2]slideshare search [3]alternate [4]alternate [5]alternate
   [6]alternate [7]alternate [8]alternate [9]slideshow json oembed profile
   [10]slideshow xml oembed profile [11]alternate [12]alternate
   [13]alternate

   (button)

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our [14]user
   agreement and [15]privacy policy.

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our
   [16]privacy policy and [17]user agreement for details.

   [18]slideshare [19]explore search [20]you

     * [21]linkedin slideshare

     * [22]upload
     * [23]login
     * [24]signup

     *
     * ____________________ (button) submit search

     * [25]home
     * [26]explore

     * [27]presentation courses
     * [28]powerpoint courses
     *
     * by [29]linkedin learning

   ____________________
   successfully reported this slideshow.

   we use your linkedin profile and activity data to personalize ads and
   to show you more relevant ads. [30]you can change your ad preferences
   anytime.
   introduction to id22 (capsnets)

   id22 aur  lien g  ron, november 2017
   https://youtu.be/ppn8d0e3900

   aur  lien g  ron, 2017 nips 2017 paper dynamic routing between capsules
   by sara sabour, nicholas frosst, geoffrey e. hinton ...

   aur  lien g  ron, 2017 computer graphics rectangle x=20 y=30 angle=16  
   triangle x=24 y=25 angle=-65   instantiation parameter...

   aur  lien g  ron, 2017 inverse graphics instantiation parameters
   imageinverse rendering rectangle x=20 y=30 angle=16   triang...

   aur  lien g  ron, 2017 capsules capsule activations imageinverse
   rendering = =

   aur  lien g  ron, 2017 activation vector: capsules length = estimated
   id203 of presence orientation = object   s estimat...

   aur  lien g  ron, 2017 squash(u) = capsules = = convolutional layers +
   reshape + squash ||u||2 1 + ||u||2 u ||u||

   aur  lien g  ron, 2017 equivariance = =

   aur  lien g  ron, 2017 equivariance = =

   aur  lien g  ron, 2017 a hierarchy of parts boat x=22 y=28 angle=16  

   aur  lien g  ron, 2017 a hierarchy of parts rectangle x=20 y=30 angle=16  
   triangle x=24 y=25 angle=-65   boat x=22 y=28 angle...

   aur  lien g  ron, 2017 a hierarchy of parts rectangle x=20 y=30 angle=-5  
   triangle x=26 y=31 angle=137   house x=22 y=28 angl...

   aur  lien g  ron, 2017 primary capsules = = primary capsules

   aur  lien g  ron, 2017 predict next layer   s output = = primary capsules

   aur  lien g  ron, 2017 predict next layer   s output = = primary capsules

   aur  lien g  ron, 2017 predict next layer   s output = = one transformation
   matrix wi,j per part/whole pair (i, j).   j|i = wi,...

   aur  lien g  ron, 2017 predict next layer   s output = = primary capsules

   aur  lien g  ron, 2017 predict next layer   s output = = primary capsules

   aur  lien g  ron, 2017 compute next layer   s output = = predicted outputs
   primary capsules

   aur  lien g  ron, 2017 routing by agreement = = predicted outputs primary
   capsules strong agreement!

   aur  lien g  ron, 2017 the rectangle and triangle capsules should be
   routed to the boat capsules. routing by agreement = = p...

   aur  lien g  ron, 2017 clusters of agreement

   aur  lien g  ron, 2017 clusters of agreement mean

   aur  lien g  ron, 2017 clusters of agreement mean

   aur  lien g  ron, 2017 clusters of agreement mean

   aur  lien g  ron, 2017 clusters of agreement mean

   aur  lien g  ron, 2017 clusters of agreement mean

   aur  lien g  ron, 2017 routing weights = = predicted outputs primary
   capsules bi,j=0 for all i, j

   aur  lien g  ron, 2017 routing weights = = predicted outputs primary
   capsules 0.5 0.5 0.5 0.5 bi,j=0 for all i, j ci = softm...

   aur  lien g  ron, 2017 compute next layer   s output = = predicted outputs
   sj = weighted sum primary capsules 0.5 0.5 0.5 0.5

   aur  lien g  ron, 2017 compute next layer   s output = = predicted outputs
   primary capsules 0.5 0.5 0.5 0.5 sj = weighted sum ...

   aur  lien g  ron, 2017 actual outputs of the next layer capsules (round
   #1) compute next layer   s output = = predicted output...

   aur  lien g  ron, 2017 actual outputs of the next layer capsules (round
   #1) update routing weights = = predicted outputs pri...

   aur  lien g  ron, 2017 actual outputs of the next layer capsules (round
   #1) update routing weights = = predicted outputs pri...

   aur  lien g  ron, 2017 actual outputs of the next layer capsules (round
   #1) update routing weights = = predicted outputs pri...

   aur  lien g  ron, 2017 actual outputs of the next layer capsules (round
   #1) update routing weights = = predicted outputs pri...

   aur  lien g  ron, 2017 compute next layer   s output = = predicted outputs
   primary capsules 0.2 0.1 0.8 0.9

   aur  lien g  ron, 2017 compute next layer   s output = = predicted outputs
   sj = weighted sum primary capsules 0.2 0.1 0.8 0.9

   aur  lien g  ron, 2017 compute next layer   s output = = predicted outputs
   primary capsules sj = weighted sum vj = squash(sj)0...

   aur  lien g  ron, 2017 actual outputs of the next layer capsules (round
   #2) compute next layer   s output = = predicted output...

   aur  lien g  ron, 2017 handling crowded scenes = = = =

   aur  lien g  ron, 2017 handling crowded scenes = = = = is this an upside
   down house?

   aur  lien g  ron, 2017 handling crowded scenes = = = = house thanks to
   routing by agreement, the ambiguity is quickly resolv...

   aur  lien g  ron, 2017 classification capsnet ||    2 || estimated class
   id203

   aur  lien g  ron, 2017 training ||    2 || estimated class id203 to
   allow multiple classes, minimize margin loss: lk = t...

   aur  lien g  ron, 2017 training translated to english:    if an object of
   class k is present, then ||vk||2 should be no less t...

   aur  lien g  ron, 2017 id173 by reconstruction ||    2 ||
   feedforward neural network decoder reconstruction

   aur  lien g  ron, 2017 id173 by reconstruction ||    2 ||
   feedforward neural network decoder reconstruction loss = ma...

   aur  lien g  ron, 2017 a capsnet for mnist (figure 1 from the paper)

   aur  lien g  ron, 2017 a capsnet for mnist     decoder (figure 2 from the
   paper)

   aur  lien g  ron, 2017 interpretable activation vectors (figure 4 from
   the paper)

   aur  lien g  ron, 2017 pros     reaches high accuracy on mnist, and
   promising on cifar10     requires less training data     posit...

   aur  lien g  ron, 2017     not state of the art on cifar10 (but it   s a good
   start)     not tested yet on larger images (e.g., im...

   aur  lien g  ron, 2017 implementations     keras w/ tensorflow backend:
   https://github.com/xifengguo/capsnet- keras     tensorfl...

   amazon: https://goo.gl/iowykd twitter: @aureliengeron github.com/ageron
   upcoming slideshare
   []
   loading in    5
     
   [] 1
   (button)
   1 of 55 (button)
   (button) (button)
   like this presentation? why not share!
     * share
     * email
     *
     *

     * [31]the ai rush the ai rush by jean-baptiste dumont 1045862 views
     * [32]ai and machine learning demystified... ai and machine learning
       demystified... by carol smith 3618058 views
     * [33]10 facts about jobs in the future 10 facts about jobs in the
       future by pew research cent... 660381 views
     * [34]2017 holiday survey: an annual anal... 2017 holiday survey: an
       annual anal... by deloitte united s... 1068376 views
     * [35]harry surden - artificial intellige... harry surden -
       artificial intellige... by harry surden 622027 views
     * [36]inside google's numbers in 2017 inside google's numbers in 2017
       by rand fishkin 1205023 views

   (button)

   share slideshare
     __________________________________________________________________

     * [37]facebook
     * [38]twitter
     * [39]linkedin

   embed
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   size (px)
   start on
   [x] show related slideshares at end
   wordpress shortcode ____________________
   link ____________________

introduction to id22 (capsnets)

   6,403 views

     * (button) share
     * (button) like
     * (button) download
     * ...
          +

   [40]aur  lien g  ron

[41]aur  lien g  ron

   [42]follow

   (button) (button) (button)

   published on nov 22, 2017

   capsnets are a hot new architecture for neural networks, invented by
   geoffrey hinton, one of the godfathers of deep learning.
   you can view this presentation on youtube at:
   https://youtu.be/ppn8d0e3900
   nips 2017 paper:
   * dynamic routing between capsules,
   * by sara sabour, nicholas frosst, geoffrey e. hinton
   * https://arxiv.org/abs/1710.09829
   the 2011 paper:
   * transforming autoencoders
   * by geoffrey e. hinton, alex krizhevsky and sida d. wang
   * https://goo.gl/arswm6
   capsnet implementations:
   * keras w/ tensorflow backend:
   https://github.com/xifengguo/capsnet-keras
   * tensorflow: https://github.com/naturomics/capsnet-tensorflow
   * pytorch: https://github.com/gram-ai/capsule-networks
   book:
   hands-on machine with scikit-learn and tensorflow
   o'reilly, 2017
   amazon: https://goo.gl/iowykd
   github: https://github.com/ageron
   twitter: https://twitter.com/aureliengeron
   (button) ...

   published in: [43]data & analytics

     * [44]5 comments
     * [45]25 likes
     * [46]statistics
     * [47]notes

     * full name
       full name
       comment goes here.
       12 hours ago   [48]delete [49]reply [50]block
       are you sure you want to [51]yes [52]no
       your message goes here

   no profile picture user
   ____________________
   [53](button) post
     * [54]elizabethwilsona508
       [55]teri hamilton
       your opinions matter! get paid for them! click here for more
       info...          https://tinyurl.com/make2793amonth
       4 weeks ago    [56]reply
       are you sure you want to  [57]yes  [58]no
       your message goes here
     * [59]barmakheidarasadi
       [60]barmak heidarasadi , project lead at samsung r&d
       in slide 6, only two capsules are fired (are longer and have proper
       orientation) and the rest are correctly shown as smaller arrows
       (i.e. not fired/inactive); but they have several different
       orientations. i do not understand the interpretation behind the
       orientation of the inactive arrows. the question is that if they
       have not detected any shape, how come they possess some orientation
       (i.e. other features of the shape). if my assumption is correct, i
       would draw all of them as small pale arrows with the same
       orientation (e.g. upward); otherwise i would appreciate if you
       could elaborate more on the orientation of the inactive arrows in
       the picture.
       9 months ago    [61]reply
       are you sure you want to  [62]yes  [63]no
       your message goes here
     * [64]johnmayer664
       [65]johnmayer664
       hi there! essay help for students | discount 10% for your first
       order! - check our website! https://vk.cc/80sako
       11 months ago    [66]reply
       are you sure you want to  [67]yes  [68]no
       your message goes here
     * [69]vadymserpak
       [70]vadym serpak , entry level dl engineer | data scientist |
       android developer
       thank you very much!
       1 year ago    [71]reply
       are you sure you want to  [72]yes  [73]no
       your message goes here
     * [74]aureliengeron
       [75]aur  lien g  ron
       in slide 46 (at 15:47 in the video), in the margin loss equation,
       the max should be squared, but not the norm: l_k = t_k max(0, m+    
       ||v_k||)   +    (1     t_k) max(0, ||v_k||     m   )  . therefore, on slide
       47 (at 16:08 in the video), the network should output a vector
       whose length (not squared length) is longer than 0.9 for digits
       that are present, or smaller than 0.1 for digits that are absent.
       1 year ago    [76]reply
       are you sure you want to  [77]yes  [78]no
       your message goes here

     * [79]farzad_bz
       [80]farzad_bz
       2 months ago
     * [81]zihaozhao8
       [82]zihaozhao8
       2 months ago
     * [83]justinworsey
       [84]justinworsey
       7 months ago
     * [85]jaepilko10
       [86]jaypi ko
       9 months ago
     * [87]motokitakagi
       [88]motokitakagi
       10 months ago

   [89]show more
   no downloads
   views
   total views
   6,403
   on slideshare
   0
   from embeds
   0
   number of embeds
   409
   actions
   shares
   0
   downloads
   849
   comments
   5
   likes
   25
   embeds 0
   no embeds
   no notes for slide

     this presentation will tell you all about id22, a hot new
   architecture for neural nets. geoffrey hinton had the idea of capsule
   networks several years ago, and he published a paper in 2011 that
   introduced many of the key ideas, but he had a hard time making them
   work properly, until now.

     a few weeks ago, in october 2017, a paper called    dynamic routing
   between capsules    was published by sara sabour, nicholas frosst and of
   course geoffrey hinton. they managed to reach state of the art
   performance on the mnist dataset, and demonstrated considerably better
   results than convolutional neural nets on highly overlapping digits. so
   what are id22 exactly?

     well, in computer graphics, you start with an abstract representation
   of a scene, for example a rectangle at position x=20 and y=30, rotated
   by 16  , and so on. each object type has various instantiation
   parameters. then you call some rendering function, and boom, you get an
   image.

     inverse graphics, is just the reverse process. you start with an
   image, and you try to find what objects it contains, and what their
   instantiation parameters are. a capsule network is basically a neural
   network that tries to perform inverse graphics.

     it is composed of many capsules. a capsule is any function that tries
   to predict the presence and the instantiation parameters of a
   particular object at a given location. for example, the network above
   contains 50 capsules. the arrows represent the output vectors of these
   capsules. the capsules output vectors. the black arrows correspond to
   capsules that try to find rectangles, while the blue arrows represent
   the output of capsules looking for triangles. the length of an
   activation vector represents the estimated id203 that the object
   the capsule is looking for is indeed present. you can see that most
   arrows are tiny, meaning the capsules didn   t detect anything, but two
   arrows are quite long. this means that the capsules at these locations
   are pretty confident that they found what they were looking for, in
   this case a rectangle, and a triangle.

     next, the orientation of the activation vector encodes the
   instantiation parameters of the object, for example in this case the
   object   s rotation, but it could be also its thickness, how stretched or
   skewed it is, its exact position (there might be slight translations),
   and so on. for simplicity, i   ll just focus on the rotation parameter,
   but in a real capsule network, the activation vectors may have 5, 10
   dimensions or more.

     in practice, a good way to implement this is to first apply a couple
   convolutional layers, just like in a regular convolutional neural net.
   this will output an array containing a bunch of feature maps. you can
   then reshape this array to get a set of vectors for each location. for
   example, suppose the convolutional layers output an array containing,
   say, 18 feature maps (2 times 9), you can easily reshape this array to
   get 2 vectors of 9 dimensions each, for every location. you could also
   get 3 vectors of 6 dimensions each, and so on. something that would
   look like the capsule network represented here with two vectors at each
   location. the last step is to ensure that no vector is longer than 1,
   since the vector   s length is meant to represent a id203, it
   cannot be greater than 1. to do this, we apply a squashing function. it
   preserves the vector   s orientation, but it squashes it to ensure that
   its length is between 0 and 1.

     one key feature of id22 is that they preserve detailed
   information about the object   s location and its pose, throughout the
   network. for example, if i rotate the image slightly...

     ...notice that the activation vectors also change slightly. right?
   this is called equivariance. in a regular convolutional neural net,
   there are generally several pooling layers, and unfortunately these
   pooling layers tend to lose information, such as the precise location
   and pose of the objects. it   s really not a big deal if you just want to
   classify the whole image, but it makes it challenging to perform
   accurate image segmentation or id164 (which require precise
   location and pose). the fact that capsules are equivariant makes them
   very promising for these applications.

     all right, so now let   s see how id22 can handle objects
   that are composed of a hierarchy of parts. for example, consider a boat
   centered at position x=22 and y=28, and rotated by 16  . this boat is
   composed of parts. in this case one rectangle and one triangle.

     so this is how it would be rendered. now we want to do the reverse,
   we want inverse graphics, so we want to go from the image to this whole
   hierarchy of parts with their instantiation parameters.

     similarly, we could also draw a house, using the same parts, a
   rectangle and a triangle, but this time organized in a different way.
   so the trick will be to try to go from this image containing a
   rectangle and a triangle, and figure out, not only that the rectangle
   and triangle are at this location and this orientation, but also that
   they are part of a boat, not a house. so let   s figure out how it would
   do this.

     the first step we have already seen: we run a couple convolutional
   layers, we reshape the output to get vectors, and we squash them. this
   gives us the output of the primary capsules. we   ve got the first layer
   already. the next step is where most of the magic and complexity of
   id22 takes place. every capsule in the first layer tries to
   predict the output of every capsule in the next layer.

     for example, let   s consider the capsule that detected the rectangle.
   i   ll call it the rectangle-capsule.

     let   s suppose that there are just two capsules in the next layer, the
   house-capsule and the boat-capsule. since the rectangle-capsule
   detected a rectangle rotated by 16  , it predicts that the house-capsule
   will detect a house rotated by 16  , that makes sense, and the
   boat-capsule will detect a boat rotated by 16   as well. that   s what
   would be consistent with the orientation of the rectangle.

     so, to make this prediction, what the rectangle-capsule does is it
   simply computes the dot product of a transformation matrix w_i,j with
   its own activation vector u_i. during training, the network will
   gradually learn a transformation matrix for each pair of capsules in
   the first and second layer. in other words, it will learn all the
   part-whole relationships, for example the angle between the wall and
   the roof of a house, and so on.

     now let   s see what the triangle-capsule predicts.

     this time, it   s a bit more interesting: given the rotation angle of
   the triangle, it predicts that the house-capsule will detect an
   upside-down house, and that the boat-capsule will detect a boat rotated
   by 16  . these are the positions that would be consistent with the
   rotation angle of the triangle.

     now we have a bunch of predicted outputs, what do we do with them?

     as you can see, the rectangle-capsule and the triangle-capsule
   strongly agree on what the boat-capsule will output. in other words,
   they agree that a boat positioned in this way would explain their own
   positions and rotations. and they totally disagree on what the
   house-capsule will output. therefore, it makes sense to assume that the
   rectangle and triangle are part of a boat, not a house.

     now that we know that the rectangle and triangle are part of a boat,
   the outputs of the rectangle capsule and the triangle capsule really
   concern only the boat capsule, there   s no need to send these outputs to
   any other capsule, this would just add noise. they should be sent only
   to the boat capsule. this is called routing by agreement. there are
   several benefits: first, since capsule outputs are only routed to the
   appropriate capsule in the next layer, these capsules will get a
   cleaner input signal and will more accurately determine the pose of the
   object. second, by looking at the paths of the activations, you can
   easily navigate the hierarchy of parts, and know exactly which part
   belongs to which object (like, the rectangle belongs to the boat, or
   the triangle belongs to the boat, and so on). lastly, routing by
   agreement helps parse crowded scenes with overlapping objects (we will
   see this in a few slides). but first, let   s look at how routing by
   agreement is implemented in id22.

     here, i have represented the various poses of the boat, as predicted
   by the lower-level capsules. for example, one of these circles may
   represent what the rectangle-capsule thinks about the most likely pose
   of the boat, and another circle may represent what the triangle-capsule
   thinks, and if we suppose that there are many other low-level capsules,
   then we might get a cloud of prediction vectors, for the boat capsule,
   like this. in this example, there are two pose parameters: one
   represents the rotation angle, and the other represents the size of the
   boat. as i mentioned earlier, pose parameters may capture many
   different kinds of visual features, like skew, thickness, and so on. or
   precise location. so the first thing we do, is we compute the mean of
   all these predictions.

     this gives us this vector. the next step is to measure the distance
   between each predicted vector and the mean vector. i will use here the
   euclidian distance here, but id22 actually use the scalar
   product. basically, we want to measure how much each predicted vector
   agrees with the mean predicted vector. using this agreement measure, we
   can update the weight of every predicted vector accordingly.

     note that the predicted vectors that are far from the mean now have a
   very small weight, and the ones closest to the mean have a much
   stronger weight. i   ve represented them in black. now we can just
   compute the mean once again (or i should say, the weighted mean).

     and you   ll notice that it moves slightly towards the cluster, towards
   the center of the cluster. so next, we can once again update the
   weights.

     and now most of the vectors within the cluster have turned black. and
   again, we can update the mean.

     and we can repeat this process a few times. in practice 3 to 5
   iterations are generally sufficient. this might remind you, i suppose,
   of the id116 id91 algorithm if you know it. okay, so this is
   how we find clusters of agreement. now let   s see how the whole
   algorithm works in a bit more details.

     first, for every predicted output, we start by setting a raw routing
   weight b_i,j equal to 0.

     next, we apply the softmax function to these raw weights, for each
   primary capsule. this gives the actual routing weights for each
   predicted output, in this example 0.5 each.

     next we compute a weighted sum of the predictions, for each capsule
   in the next layer.

     this might give vectors longer than 1, so as usual we apply the
   squash function.

     and voil  ! we now have the actual outputs of the house-capsule and
   boat-capsule. but this is not the final output, it   s just the end of
   the first round, the first iteration.

     now we can see which predictions were most accurate. for example, the
   rectangle-capsule made a great prediction for the boat-capsule   s
   output. it really matches it pretty closely.

     this is estimated by computing the scalar product of the predicted
   output vector   _j|i and the actual product vector v_j. this scalar
   product is simply added to the predicted output   s raw routing weight,
   b_i,j. so the weight of this particular predicted output is increased.

     when there is a strong agreement, this scalar product is large, so
   good predictions will have a higher weight.

     on the other hand, the rectangle-capsule made a pretty bad prediction
   for the house-capsule   s output, so the scalar product in this case will
   be quite small, and the raw routing weight of this predicted vector
   will not grow much.

     next, we update the routing weights by computing the softmax of the
   raw weights, once again. and as you can see, the rectangle-capsule   s
   predicted vector for the boat-capsule now has a weight of 0.8, while
   it   s predicted vector for the house-capsule dropped down to 0.2. so
   most of its output is now going to go to the boat capsule, not the
   house capsule.

     once again we compute the weighted sum of all the predicted output
   vectors for each capsule in the next layer, that is the house-capsule
   and the boat-capsule. and this time, the house-capsule gets so little
   input that its output is a tiny vector. on the other hand the
   boat-capsule gets so much input that it outputs a vector much longer
   than 1. so again we squash it.

     and that   s the end of round #2.

     and as you can see, in just a couple iterations, we have already
   ruled out the house and clearly chosen the boat. after perhaps one or
   two more rounds, we can stop and proceed to the next capsule layer in
   exactly the same way.

     so as i mentioned earlier, routing by agreement is really great to
   handle crowded scenes, such as the one represented in this image.

     one way to interpret this image (as you can see there is a bit of
   ambiguity), you can see a house upside down in the middle. however, if
   this was the case, then there would be no explanation for the bottom
   rectangle or the top triangle, no reason for them to be where they are.

     the best way to interpret the image is that there is a house at the
   top and a boat at the bottom. and routing by agreement will tend to
   choose this solution, since it makes all the capsules perfectly happy,
   each of them making perfect predictions for the capsules in the next
   layer. the ambiguity is explained away. okay, so what can you do with a
   capsule network now that you know how it works?

     well for one, you can create a nice image classifier of course. just
   have one capsule per class in the top layer and that   s almost all there
   is to it. all you need to add is a layer that computes the length of
   the top-layer activation vectors, and this gives you the estimated
   class probabilities. you could then just train the network by
   minimizing the cross-id178 loss, as in a regular classification
   neural network, and you would be done.

     however, in the paper they use a margin loss that makes it possible
   to detect multiple classes in the image.

     so without going into too much details, this margin loss is such that
   if an object of class k is present in the image, then the corresponding
   top-level capsule should output a vector whose squared length is at
   least 0.9. it should be long. conversely, if an object of class k is
   not present in the image, then the capsule should output a short
   vector, one whose squared length is shorter than 0.1. so the total loss
   is the sum of losses for all classes.

     in the paper, they also add a decoder network on top of the capsule
   network. it   s just 3 fully connected layers with a sigmoid activation
   function in the output layer. it learns to reconstruct the input image
   by minimizing the squared difference between the reconstructed image
   and the input image.

     the full loss is the margin loss we discussed earlier, plus the
   reconstruction loss (scaled down considerably so as to ensure that the
   margin loss dominates training). the benefit of applying this
   reconstruction loss is that it forces the network to preserve all the
   information required to reconstruct the image, up to the top layer of
   the capsule network, its output layer. this constraint acts a bit like
   a regularizer: it reduces the risk of overfitting and helps generalize
   to new examples. and that   s it! you know how a capsule network works,
   and how to train it. let   s look a little bit at some of the figures in
   the paper, which i find interesting.

     this is figure 1 from the paper, showing a full capsule network for
   mnist. you can see the first two regular convolutional layers, whose
   output is reshaped and squashed to get the activation vectors of the
   primary capsules. and these primary capsules are organized in a 6 by 6
   grid, with 32 primary capsules in each cell of this grid, and each
   primary capsule outputs an 8-dimensional vector. so this first layer of
   capsules is fully connected to the 10 output capsules, which output 16
   dimensional vectors. the length of these vectors is used to compute the
   margin loss, as explained earlier.

     now this is figure 2 from the paper. it shows the decoder sitting on
   top of the capsnet. it is composed of 2 fully connected relu layers
   plus a fully connected sigmoid layer which outputs 784 numbers that
   correspond to the pixel intensities of the reconstructed image (which
   is a 28 by 28 pixel image). the squared difference between this
   reconstructed image and the input image gives the reconstruction loss.

     right, and this is figure 4 from the paper. one nice thing about
   id22 is that the activation vectors are often
   interpretable. for example, this image shows the reconstructions that
   you get when you gradually modify one of the 16 dimensions of the top
   layer capsules    output. you can see that the first dimension seems to
   represent scale and thickness. the fourth dimension represents a
   localized skew. the fifth represents the width of the digit plus a
   slight translation to get the exact position. so as you can see, it   s
   rather clear what most of these parameters do.

     okay, to conclude, let   s summarize the pros and cons. capsule
   networks have reached state of the art accuracy on mnist. on cifar10,
   they got a bit over 10% error, which is far from state of the art, but
   it   s similar to what was first obtained with other techniques before
   years of efforts were put into them, so it   s still a good start.
   id22 require less training data. they offer equivariance,
   which means that position and pose information are preserved. and this
   is very promising for image segmentation and id164. the
   routing by agreement algorithm is great for crowded scenes. the routing
   tree also maps the hierarchy of objects parts, so every part is
   assigned to a whole. and it   s rather robust to rotations, translations
   and other affine transformations. the activation vectors somewhat are
   interpretable. and finally, obviously, it   s hinton   s idea, so don   t bet
   against it.

     however, there are a few cons: first, as i mentioned the results are
   not yet state of the art on cifar10, even though it   s a good start.
   plus, it   s still unclear whether id22 can scale to larger
   images, such as the id163 dataset. what will the accuracy be?
   id22 are also quite slow to train, in large part because of
   the routing by agreement algorithm which has an inner loop, as you saw
   earlier. finally, there is only one capsule of any given type in a
   given location, so it   s impossible for a capsule network to detect two
   objects of the same type if they are too close to one another. this is
   called crowding, and it has been observed in human vision as well, so
   it   s probably not a show-stopper.

     all right! i highly recommend you take a look at the code of a
   capsnet implementation, such as the ones listed here (i   ll leave the
   links in the video description below). if you take your time, you
   should have no problem understanding everything the code is doing. the
   main difficulty in implementing capsnets is that it contains an inner
   loop for the routing by agreement algorithm. implementing loops in
   keras and tensorflow can be a little bit trickier than in pytorch, but
   it can be done. if you don   t have a particular preference, then i would
   say that the pytorch code is the easiest to understand.

     and that   s all i had, i hope you enjoyed this presentation. if you
   did, please visit my youtube channel, like, share, comment, subscribe,
   etc. it   s my first real youtube video, and if people find it useful, i
   might make some more. if you want to learn more about machine learning,
   deep learning and deep id23, you may want to read my
   o   reilly book hands-on machine learning with scikit-learn and
   tensorflow. it covers a ton of topics, with many code examples that you
   will find on my github account, so i   ll leave the links in the video
   description. that   s all for today, have fun and see you next time!

introduction to id22 (capsnets)

    1. 1. id22 aur  lien g  ron, november 2017
       https://youtu.be/ppn8d0e3900
    2. [90]2. aur  lien g  ron, 2017 nips 2017 paper dynamic routing between
       capsules by sara sabour, nicholas frosst, geoffrey e. hinton
       october 2017: https://arxiv.org/abs/1710.09829
    3. [91]3. aur  lien g  ron, 2017 computer graphics rectangle x=20 y=30
       angle=16   triangle x=24 y=25 angle=-65   instantiation parameters
       imagerendering
    4. [92]4. aur  lien g  ron, 2017 inverse graphics instantiation
       parameters imageinverse rendering rectangle x=20 y=30 angle=16  
       triangle x=24 y=25 angle=-65  
    5. [93]5. aur  lien g  ron, 2017 capsules capsule activations
       imageinverse rendering = =
    6. [94]6. aur  lien g  ron, 2017 activation vector: capsules length =
       estimated id203 of presence orientation = object   s estimated
       pose parameters = =
    7. [95]7. aur  lien g  ron, 2017 squash(u) = capsules = = convolutional
       layers + reshape + squash ||u||2 1 + ||u||2 u ||u||
    8. [96]8. aur  lien g  ron, 2017 equivariance = =
    9. [97]9. aur  lien g  ron, 2017 equivariance = =
   10. [98]10. aur  lien g  ron, 2017 a hierarchy of parts boat x=22 y=28
       angle=16  
   11. [99]11. aur  lien g  ron, 2017 a hierarchy of parts rectangle x=20
       y=30 angle=16   triangle x=24 y=25 angle=-65   boat x=22 y=28
       angle=16  
   12. [100]12. aur  lien g  ron, 2017 a hierarchy of parts rectangle x=20
       y=30 angle=-5   triangle x=26 y=31 angle=137   house x=22 y=28
       angle=-5  
   13. [101]13. aur  lien g  ron, 2017 primary capsules = = primary capsules
   14. [102]14. aur  lien g  ron, 2017 predict next layer   s output = =
       primary capsules
   15. [103]15. aur  lien g  ron, 2017 predict next layer   s output = =
       primary capsules
   16. [104]16. aur  lien g  ron, 2017 predict next layer   s output = = one
       transformation matrix wi,j per part/whole pair (i, j).   j|i = wi,j
       ui primary capsules
   17. [105]17. aur  lien g  ron, 2017 predict next layer   s output = =
       primary capsules
   18. [106]18. aur  lien g  ron, 2017 predict next layer   s output = =
       primary capsules
   19. [107]19. aur  lien g  ron, 2017 compute next layer   s output = =
       predicted outputs primary capsules
   20. [108]20. aur  lien g  ron, 2017 routing by agreement = = predicted
       outputs primary capsules strong agreement!
   21. [109]21. aur  lien g  ron, 2017 the rectangle and triangle capsules
       should be routed to the boat capsules. routing by agreement = =
       predicted outputs primary capsules strong agreement!
   22. [110]22. aur  lien g  ron, 2017 clusters of agreement
   23. [111]23. aur  lien g  ron, 2017 clusters of agreement mean
   24. [112]24. aur  lien g  ron, 2017 clusters of agreement mean
   25. [113]25. aur  lien g  ron, 2017 clusters of agreement mean
   26. [114]26. aur  lien g  ron, 2017 clusters of agreement mean
   27. [115]27. aur  lien g  ron, 2017 clusters of agreement mean
   28. [116]28. aur  lien g  ron, 2017 routing weights = = predicted outputs
       primary capsules bi,j=0 for all i, j
   29. [117]29. aur  lien g  ron, 2017 routing weights = = predicted outputs
       primary capsules 0.5 0.5 0.5 0.5 bi,j=0 for all i, j ci =
       softmax(bi)
   30. [118]30. aur  lien g  ron, 2017 compute next layer   s output = =
       predicted outputs sj = weighted sum primary capsules 0.5 0.5 0.5
       0.5
   31. [119]31. aur  lien g  ron, 2017 compute next layer   s output = =
       predicted outputs primary capsules 0.5 0.5 0.5 0.5 sj = weighted
       sum vj = squash(sj)
   32. [120]32. aur  lien g  ron, 2017 actual outputs of the next layer
       capsules (round #1) compute next layer   s output = = predicted
       outputs primary capsules 0.5 0.5 0.5 0.5 sj = weighted sum vj =
       squash(sj)
   33. [121]33. aur  lien g  ron, 2017 actual outputs of the next layer
       capsules (round #1) update routing weights = = predicted outputs
       primary capsules agreement
   34. [122]34. aur  lien g  ron, 2017 actual outputs of the next layer
       capsules (round #1) update routing weights = = predicted outputs
       primary capsules agreement bi,j +=   j|i . vj
   35. [123]35. aur  lien g  ron, 2017 actual outputs of the next layer
       capsules (round #1) update routing weights = = predicted outputs
       primary capsules agreement bi,j +=   j|i . vj large
   36. [124]36. aur  lien g  ron, 2017 actual outputs of the next layer
       capsules (round #1) update routing weights = = predicted outputs
       primary capsules disagreement bi,j +=   j|i . vj small
   37. [125]37. aur  lien g  ron, 2017 compute next layer   s output = =
       predicted outputs primary capsules 0.2 0.1 0.8 0.9
   38. [126]38. aur  lien g  ron, 2017 compute next layer   s output = =
       predicted outputs sj = weighted sum primary capsules 0.2 0.1 0.8
       0.9
   39. [127]39. aur  lien g  ron, 2017 compute next layer   s output = =
       predicted outputs primary capsules sj = weighted sum vj =
       squash(sj)0.2 0.1 0.8 0.9
   40. [128]40. aur  lien g  ron, 2017 actual outputs of the next layer
       capsules (round #2) compute next layer   s output = = predicted
       outputs primary capsules 0.2 0.1 0.8 0.9
   41. [129]41. aur  lien g  ron, 2017 handling crowded scenes = = = =
   42. [130]42. aur  lien g  ron, 2017 handling crowded scenes = = = = is
       this an upside down house?
   43. [131]43. aur  lien g  ron, 2017 handling crowded scenes = = = = house
       thanks to routing by agreement, the ambiguity is quickly resolved
       (explaining away). boat
   44. [132]44. aur  lien g  ron, 2017 classification capsnet ||    2 ||
       estimated class id203
   45. [133]45. aur  lien g  ron, 2017 training ||    2 || estimated class
       id203 to allow multiple classes, minimize margin loss: lk =
       tk max(0, m+ - ||vk||2) +    (1 - tk) max(0, ||vk||2 - m-) tk = 1
       iff class k is present in the paper: m- = 0.1 m+ = 0.9    = 0.5
   46. [134]46. aur  lien g  ron, 2017 training translated to english:    if
       an object of class k is present, then ||vk||2 should be no less
       than 0.9. if not, then ||vk||2 should be no more than 0.1.    ||    2
       || estimated class id203 to allow multiple classes, minimize
       margin loss: lk = tk max(0, m+ - ||vk||2) +    (1 - tk) max(0,
       ||vk||2 - m-) tk = 1 iff class k is present in the paper: m- = 0.1
       m+ = 0.9    = 0.5
   47. [135]47. aur  lien g  ron, 2017 id173 by reconstruction ||
          2 || feedforward neural network decoder reconstruction
   48. [136]48. aur  lien g  ron, 2017 id173 by reconstruction ||
          2 || feedforward neural network decoder reconstruction loss =
       margin loss +    reconstruction loss the reconstruction loss is the
       squared difference between the reconstructed image and the input
       image. in the paper,    = 0.0005.
   49. [137]49. aur  lien g  ron, 2017 a capsnet for mnist (figure 1 from
       the paper)
   50. [138]50. aur  lien g  ron, 2017 a capsnet for mnist     decoder (figure
       2 from the paper)
   51. [139]51. aur  lien g  ron, 2017 interpretable activation vectors
       (figure 4 from the paper)
   52. [140]52. aur  lien g  ron, 2017 pros     reaches high accuracy on
       mnist, and promising on cifar10     requires less training data    
       position and pose information are preserved (equivariance)     this
       is promising for image segmentation and id164     routing
       by agreement is great for overlapping objects (explaining away)    
       capsule activations nicely map the hierarchy of parts     offers
       robustness to affine transformations     activation vectors are
       easier to interpret (rotation, thickness, skew   )     it   s hinton! ;-)
   53. [141]53. aur  lien g  ron, 2017     not state of the art on cifar10
       (but it   s a good start)     not tested yet on larger images (e.g.,
       id163): will it work well?     slow training, due to the inner
       loop (in the routing by agreement algorithm)     a capsnet cannot see
       two very close identical objects     this is called    crowding   , and
       it has been observed as well in human vision cons
   54. [142]54. aur  lien g  ron, 2017 implementations     keras w/ tensorflow
       backend: https://github.com/xifengguo/capsnet- keras     tensorflow:
       https://github.com/naturomics/capsnet-tensorflow     pytorch:
       https://github.com/gram-ai/capsule-networks
   55. [143]55. amazon: https://goo.gl/iowykd twitter: @aureliengeron
       github.com/ageron

          [144]recommended

     * creative insights: renaldo lawrence on elearning
       creative insights: renaldo lawrence on elearning
       online course - linkedin learning
     * teacher tips
       teacher tips
       online course - linkedin learning
     * learning management systems (lms) quick start
       learning management systems (lms) quick start
       online course - linkedin learning
     * id13s for search & discovery
       id13s for search & discovery
       aur  lien g  ron
     * r  seaux de capsules (capsnets)
       r  seaux de capsules (capsnets)
       aur  lien g  ron
     * synthetic gradients tutorial
       synthetic gradients tutorial
       aur  lien g  ron
     * how to implement capsnets using tensorflow
       how to implement capsnets using tensorflow
       aur  lien g  ron
     * the ai rush
       the ai rush
       jean-baptiste dumont
     * ai and machine learning demystified by carol smith at midwest ux
       2017
       ai and machine learning demystified by carol smith at midwest ux
       2017
       carol smith
     * 10 facts about jobs in the future
       10 facts about jobs in the future
       pew research center's internet & american life project

     * [145]english
     * [146]espa  ol
     * [147]portugu  s
     * [148]fran  ais
     * [149]deutsch

     * [150]about
     * [151]dev & api
     * [152]blog
     * [153]terms
     * [154]privacy
     * [155]copyright
     * [156]support

     *
     *
     *
     *
     *

   linkedin corporation    2019

     

share clipboard
     __________________________________________________________________

   [157]  
     * facebook
     * twitter
     * linkedin

   link ____________________

public clipboards featuring this slide
     __________________________________________________________________

   (button)   
   no public clipboards found for this slide

select another clipboard
     __________________________________________________________________

   [158]  

   looks like you   ve clipped this slide to already.
   ____________________

   create a clipboard

you just clipped your first slide!

   clipping is a handy way to collect important slides you want to go back
   to later. now customize the name of a clipboard to store your clips.
     __________________________________________________________________

   name* ____________________
   description ____________________
   visibility
   others can see my clipboard [ ]
   (button) cancel (button) save

   bizographics tracking image

references

   visible links
   1. https://www.slideshare.net/rss/latest
   2. https://www.slideshare.net/opensearch.xml
   3. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
   4. https://es.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
   5. https://fr.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
   6. https://de.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
   7. https://pt.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
   8. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
   9. https://www.slideshare.net/api/oembed/2?format=json&url=http://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  10. https://www.slideshare.net/api/oembed/2?format=xml&url=http://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  11. https://www.slideshare.net/mobile/aureliengeron/introduction-to-capsule-networks-capsnets
  12. android-app://net.slideshare.mobile/slideshare-app/ss/82511760
  13. ios-app://917418728/slideshare-app/ss/82511760
  14. http://www.linkedin.com/legal/user-agreement
  15. http://www.linkedin.com/legal/privacy-policy
  16. http://www.linkedin.com/legal/privacy-policy
  17. http://www.linkedin.com/legal/user-agreement
  18. https://www.slideshare.net/
  19. https://www.slideshare.net/explore
  20. https://www.slideshare.net/login
  21. https://www.slideshare.net/
  22. https://www.slideshare.net/upload
  23. https://www.slideshare.net/login
  24. https://www.slideshare.net/w/signup
  25. https://www.slideshare.net/
  26. https://www.slideshare.net/explore
  27. https://www.linkedin.com/learning/topics/presentations?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  28. https://www.linkedin.com/learning/topics/powerpoint?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  29. https://www.linkedin.com/learning?trk=slideshare_subnav_learning
  30. https://www.linkedin.com/psettings/privacy
  31. https://public.slidesharecdn.com/jeanbaptiste.dumont/the-ai-rush-121047435
  32. https://public.slidesharecdn.com/carologic/ai-and-machine-learning-demystified-by-carol-smith-at-midwest-ux-2017
  33. https://public.slidesharecdn.com/pewinternet/10-facts-about-jobs-in-the-future
  34. https://public.slidesharecdn.com/deloitteus/2017-holiday-survey-an-annual-analysis-of-the-peak-shopping-season
  35. https://public.slidesharecdn.com/harrysurden/harry-surden-artificial-intelligence-and-law-overview
  36. https://public.slidesharecdn.com/randfish/inside-googles-numbers-in-2017
  37. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  38. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  39. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  40. https://www.slideshare.net/aureliengeron?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  41. https://www.slideshare.net/aureliengeron?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  42. https://www.slideshare.net/signup?login_source=slideview.popup.follow&from=addcontact&from_source=https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  43. https://www.slideshare.net/featured/category/data-analytics
  44. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets#comments-panel
  45. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets#likes-panel
  46. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets#stats-panel
  47. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets#notes-panel
  48. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  49. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  50. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  51. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  52. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  53. https://www.slideshare.net/signup?login_source=slideview.popup.comment&from=comments&from_source=https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  54. https://www.slideshare.net/elizabethwilsona508?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  55. https://www.slideshare.net/elizabethwilsona508?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  56. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  57. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  58. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  59. https://www.slideshare.net/barmakheidarasadi?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  60. https://www.slideshare.net/barmakheidarasadi?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  61. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  62. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  63. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  64. https://www.slideshare.net/johnmayer664?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  65. https://www.slideshare.net/johnmayer664?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  66. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  67. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  68. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  69. https://www.slideshare.net/vadymserpak?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  70. https://www.slideshare.net/vadymserpak?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  71. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  72. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  73. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  74. https://www.slideshare.net/aureliengeron?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  75. https://www.slideshare.net/aureliengeron?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  76. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  77. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  78. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  79. https://www.slideshare.net/farzad_bz?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  80. https://www.slideshare.net/farzad_bz?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  81. https://www.slideshare.net/zihaozhao8?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  82. https://www.slideshare.net/zihaozhao8?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  83. https://www.slideshare.net/justinworsey?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  84. https://www.slideshare.net/justinworsey?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  85. https://www.slideshare.net/jaepilko10?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  86. https://www.slideshare.net/jaepilko10?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  87. https://www.slideshare.net/motokitakagi?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  88. https://www.slideshare.net/motokitakagi?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  89. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
  90. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-2-638.jpg?cb=1511604232
  91. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-3-638.jpg?cb=1511604232
  92. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-4-638.jpg?cb=1511604232
  93. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-5-638.jpg?cb=1511604232
  94. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-6-638.jpg?cb=1511604232
  95. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-7-638.jpg?cb=1511604232
  96. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-8-638.jpg?cb=1511604232
  97. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-9-638.jpg?cb=1511604232
  98. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-10-638.jpg?cb=1511604232
  99. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-11-638.jpg?cb=1511604232
 100. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-12-638.jpg?cb=1511604232
 101. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-13-638.jpg?cb=1511604232
 102. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-14-638.jpg?cb=1511604232
 103. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-15-638.jpg?cb=1511604232
 104. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-16-638.jpg?cb=1511604232
 105. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-17-638.jpg?cb=1511604232
 106. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-18-638.jpg?cb=1511604232
 107. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-19-638.jpg?cb=1511604232
 108. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-20-638.jpg?cb=1511604232
 109. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-21-638.jpg?cb=1511604232
 110. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-22-638.jpg?cb=1511604232
 111. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-23-638.jpg?cb=1511604232
 112. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-24-638.jpg?cb=1511604232
 113. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-25-638.jpg?cb=1511604232
 114. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-26-638.jpg?cb=1511604232
 115. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-27-638.jpg?cb=1511604232
 116. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-28-638.jpg?cb=1511604232
 117. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-29-638.jpg?cb=1511604232
 118. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-30-638.jpg?cb=1511604232
 119. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-31-638.jpg?cb=1511604232
 120. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-32-638.jpg?cb=1511604232
 121. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-33-638.jpg?cb=1511604232
 122. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-34-638.jpg?cb=1511604232
 123. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-35-638.jpg?cb=1511604232
 124. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-36-638.jpg?cb=1511604232
 125. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-37-638.jpg?cb=1511604232
 126. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-38-638.jpg?cb=1511604232
 127. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-39-638.jpg?cb=1511604232
 128. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-40-638.jpg?cb=1511604232
 129. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-41-638.jpg?cb=1511604232
 130. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-42-638.jpg?cb=1511604232
 131. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-43-638.jpg?cb=1511604232
 132. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-44-638.jpg?cb=1511604232
 133. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-45-638.jpg?cb=1511604232
 134. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-46-638.jpg?cb=1511604232
 135. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-47-638.jpg?cb=1511604232
 136. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-48-638.jpg?cb=1511604232
 137. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-49-638.jpg?cb=1511604232
 138. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-50-638.jpg?cb=1511604232
 139. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-51-638.jpg?cb=1511604232
 140. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-52-638.jpg?cb=1511604232
 141. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-53-638.jpg?cb=1511604232
 142. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-54-638.jpg?cb=1511604232
 143. https://image.slidesharecdn.com/capsnets-171122121800/95/introduction-to-capsule-networks-capsnets-55-638.jpg?cb=1511604232
 144. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets#related-tab-content
 145. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
 146. https://es.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
 147. https://pt.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
 148. https://fr.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
 149. https://de.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
 150. https://www.slideshare.net/about
 151. https://www.slideshare.net/developers
 152. http://blog.slideshare.net/
 153. https://www.slideshare.net/terms
 154. https://www.slideshare.net/privacy
 155. http://www.linkedin.com/legal/copyright-policy
 156. https://www.linkedin.com/help/slideshare
 157. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
 158. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets

   hidden links:
 160. https://www.slideshare.net/aureliengeron/introduction-to-capsule-networks-capsnets
 161. https://www.slideshare.net/login?from_source=%2faureliengeron%2fintroduction-to-capsule-networks-capsnets%3ffrom_action%3dsave&from=download&layout=foundation
 162. https://www.slideshare.net/signup?login_source=slideview.popup.flags&from=flagss&from_source=https%3a%2f%2fwww.slideshare.net%2faureliengeron%2fintroduction-to-capsule-networks-capsnets
 163. https://www.linkedin.com/learning/creative-insights-renaldo-lawrence-on-elearning?trk=slideshare_sv_learning
 164. https://www.linkedin.com/learning/teacher-tips?trk=slideshare_sv_learning
 165. https://www.linkedin.com/learning/learning-management-systems-lms-quick-start?trk=slideshare_sv_learning
 166. https://www.slideshare.net/aureliengeron/knowledge-graphs-for-search-amp-discovery-101596477
 167. https://www.slideshare.net/aureliengeron/rseaux-de-capsules-capsnets
 168. https://www.slideshare.net/aureliengeron/synthetic-gradients-tutorial
 169. https://www.slideshare.net/aureliengeron/how-to-implement-capsnets-using-tensorflow
 170. https://www.slideshare.net/jeanbaptiste.dumont/the-ai-rush-121047435
 171. https://www.slideshare.net/carologic/ai-and-machine-learning-demystified-by-carol-smith-at-midwest-ux-2017
 172. https://www.slideshare.net/pewinternet/10-facts-about-jobs-in-the-future
 173. http://www.linkedin.com/company/linkedin
 174. http://www.facebook.com/linkedin
 175. http://twitter.com/slideshare
 176. http://www.google.com/+linkedin
 177. https://www.slideshare.net/rss/latest
