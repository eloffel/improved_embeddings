the cost of calibration

kilian q. weinberger, cornell university

doc, i am not feeling well. i 

have symptoms x, y, z.

let me feed your data 

into my classi   er to see if 

you have disease q. 

decision

p

r
e

dictio

n

outline

in deep-nets calibration is easily achievable.

[guo et al., icml 2017]

calibration has unexpected and undesirable side-effects.

[kleinberg et al., nips 2017]

calibrated id203 
estimates

input

prediction

0.3

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.8

0.3

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.8

conf. = 0.7

classi   er

well calibrated 

id203 estimate

calibrated id203 
estimates

input

prediction

0.3

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.8

0.3

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.8

conf. = 0.7
e [y] = 0.7

classi   er

well calibrated 

id203 estimate

visualizing miscalibration

bin a

bin b

bin c

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

conf. = 0.5

conf. = 0.7

conf. = 0.9

visualizing miscalibration

bin a

bin b

bin c

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

   

gap:

conf. = 0.5
e [y| a] = 0.4
0.1

conf. = 0.7
e [y| b] = 0.7
0.0

conf. = 0.9
e [y| c] = 0.8
0.1

visualizing miscalibration

bin a

bin b

bin c

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

0.5

0.7
con   dence

   

gap:

conf. = 0.5
e [y| a] = 0.4
0.1

conf. = 0.7
e [y| b] = 0.7
0.0

conf. = 0.9
e [y| c] = 0.8
0.1

01con   dence01e[y]01con   dence01e[y]outputgapare deepnets calibrated?

[niculescu-misel & caruana, 2005]

miscalibration deepnets

mention related work

lenet (1998)

densenet-40 (2017)

cifar-100

[guo et al. , icml 2017]

0.00.20.40.60.81.00.00.20.40.60.81.0accuracyerror=44.9outputsgap0.00.20.40.60.81.0error=30.6outputsgapcon   dence0.00.51.0con   dence0.00.20.40.60.81.0e[y]uncal.-sst-binarytreelstmoutputsgap0.00.51.0con   dence0.00.20.40.60.81.0e[y]uncal.-sst-binarytreelstmoutputsgap0.00.51.0con   dence0.00.20.40.60.81.0e[y]uncal.-sst-binarytreelstmoutputsgap0.00.51.0con   dence0.00.20.40.60.81.0e[y]uncal.-cifar-100densenet-40outputsgap0.8

0.6

r
o
r
r
e

0.4

0.2

0.0

0

0/1 error

densenet-40, cifar-100

train
test

100

200

300

epoch

[gao et al. , icml 2017]

l
l
n

3.0

2.5

2.0

1.5

1.0

0.5

0.0

prob. error

densenet-40, cifar-100

train
test

0

100

200

300

epoch

[gao et al. , icml 2017]

temperature scaling

[jaynes, 1957]
[hinton et al., 2015] 

last layer

softmax

-5.2
-7.2

0.1
0.2

2.1
4.3

ez(x)/t

pi ezi(x)/t

class1
p = 0

prob. 
simplex

important to note here:

- this is a post processing step: once 
the rest of the network has been 
trained

- we optimize t to minimize nll on a 
holdout validation set

class 2
p = 0.88

class 3
p = 0.12

[platt, 1999]

[gao et al. , icml 2017]

temperature scaling

[jaynes, 1957]
[hinton et al., 2015] 

last layer

softmax

-7.2

0.2

4.3

ez(x)/t

pi ezi(x)/t

class1
p = 0

prob. 
simplex

important to note here:

- this is a post processing step: once 
the rest of the network has been 
trained

- we optimize t to minimize nll on a 
holdout validation set

class 2
p = 0.91

class 3
p = 0.09

[platt, 1999]

[gao et al. , icml 2017]

temperature scaling

[jaynes, 1957]
[hinton et al., 2015] 

last layer

softmax

-7.2

0.2

4.3

ez(x)/t

pi ezi(x)/t

class1
p = 0.07

prob. 
simplex

important notes here:

temp scaling is just averaging with 
the uniform distribution

because of this, it preserves the 
mode. in other words, our most 
probable class prediction stays the 
same

class 2
p = 0.72

class 3
p = 0.11

[platt, 1999]

[gao et al. , icml 2017]

temperature scaling on 
cifar-100

0.00.51.0con   dence0.00.20.40.60.81.0e[y]uncal.-cifar-100densenet-40outputsgap0.00.51.0con   dence0.00.20.40.60.81.0e[y]temp.scale-cifar-100densenet-40outputsgap0.00.51.0con   dence0.00.20.40.60.81.0e[y]uncal.-sst-binarytreelstmoutputsgap0.00.51.0con   dence0.00.20.40.60.81.0e[y]temp.scale-sst-binarytreelstmoutputsgapside effects of calibration

calibration

bin a

bin b

bin c

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

conf. = 0.5
=

e [y| a] = 0.5

conf. = 0.7
=

e [y| b] = 0.7

conf. = 0.9
=
e [y| c] = 0.9

19

calibration

bin a

bin b

bin c

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

conf. = 0.5
=

e [y| a] = 0.5

conf. = 0.7
=

e [y| b] = 0.7

conf. = 0.9
=
e [y| c] = 0.9

e[conf.] = e[y]
e[conf.] = e[y]

e[conf.] = e[y]
e[conf.] = e[y]e[conf. | y = 0] p[y = 0] + e[conf. | y = 1] p[y = 1]

20

acalibration

bin a

bin b

bin c

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

0.5

0.5

0.5

0.5

0.5

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.9

0.9

constant

e[conf.] = e[y]

e[conf.] = e[y]e[conf. | y = 0] p[y = 0] + e[conf. | y = 1] p[y = 1]

conf. = 0.5
=

e [y| a] = 0.5

conf. = 0.7
=

e [y| b] = 0.7

conf. = 0.9
=
e [y| c] = 0.9

constant

constant

1 - (false negative rate)

(fnr)

21

false positive rate

(fpr)

alinearity of 
calibrated classifiers

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

0

1   e[y]

e[y]

false positive rate

1

e[conf.] = e[y]

e[conf.] = e[y]

(fpr) (1   e[y]) + (1   fnr) e[y] = e[y]

group-wise calibration

conf. = 0.7

0.3

0.3

0.3

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.3

0.3

0.3

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.9

group-wise calibration

0.3

0.3

0.3

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.3

0.3

0.3

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

group-wise calibration

conf. = 0.7

conf. = 0.7

0.3

0.3

0.3

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.3

0.3

0.3

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.7

0.9

0.9

0.9

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

ewomen

[conf.] = ewomen

[y]

6=

emen

[y] = emen

[conf.]

group-wise calibration

conf. = 0.6

conf. = 0.8

0.3

0.3

0.3

0.6

0.6

0.6

0.6

0.6

0.8

0.8

0.8

0.8

0.8

0.9

0.9

0.9

0.3

0.3

0.3

0.6

0.6

0.6

0.6

0.6

0.8

0.8

0.8

0.8

0.8

0.9

0.9

0.9

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

0.3

0.3

0.9

0.9

0.9

0.9

0.9

0.9

0.3

0.3

0.3

0.3

0.3

0.3

0.9

0.9

ewomen

[conf.] = ewomen

[y]

6=

emen

[y] = emen

[conf.]

group-wise calibration

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

women

0

false positive rate

1

ewomen

[conf.] = ewomen

[y]

6=

emen

[y] = emen

[conf.]

error disparity

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

women

0

false positive rate

1

fnr
women

< fnr
men

fpr
women

> fpr
men

error disparity

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

women

0

false positive rate

1

fnr
women

= fnr
men

fpr
women

= fpr
men

[https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing]

impossibility of calibrated 
equalized odds
impossibility theorem:
[kleinberg, mullainathan, raghavan 2016]

there will always be some disparity 
between two groups, if base rates 
aren   t equal

1

groupwise calib.

fnr
women

= fnr
men

fpr
women

= fpr
men

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

women

can only be mutually satis   ed in trivial cases.

0

false positive rate

1

relaxed conditions

groupwise calib.

fpr
women

= fpr
men

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

women

0

false positive rate

1

fnrwomen=fnrmenrelaxed conditions

groupwise calib.

fnr
women

= fnr
men

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

women

0

false positive rate

1

fprwomen=fprmenrelaxed conditions

groupwise calib.
women   
      w fpr
=      mfpr
men   

+  w fnr

+  mfnr

women

men

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

women

0

false positive rate

1

an optimal algorithm :-(

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

men

assume we want equal fpr

the dotted line is the best we can 
possibly do.

women

0

false positive rate

1

   best possible   

classi   ers

an optimal algorithm :-(

1

e
t
a
r
 
e
v
i
t
a
g
e
n
 
e
s
l
a
f

original classi   er

men

   trivial classi   er   

women

0

false positive rate

1

   best possible    non-

discriminatory classi   ers

[kleinberg et al. nips, 2017]

example: criminal recidivism 
prediction

goal of this slide: sometimes it   s not 
even possible to achieve a notion of 
non-discrimination.


i will    x this plot

compas

0.8

0.7

0.6

0.5

0.4

0.3

e
t
a
r

.
g
e
n
e
s
l
a
f

0.2

0.2

calib. + equal f.p.

orig. g1
orig. g2
derived g2

0.4
0.6
false pos. rate

0.8

conclusion

calibration is important!

d

p

r

deep nets are badly calibrated (overcon   dent)

simple temperature scaling    xes the calibration gap

group-wise calibration is inherently at odds with some notions 
of fairness 

0.00.51.0con   dence0.00.20.40.60.81.0e[y]uncal.-cifar-100densenet-40outputsgapacknowledgements

geoff pleiss

chuan guo

yu sun

manish raghavan

felix wu

jon kleinberg

we are hiring

tenure-track faculty 

postdoc positions 

http://cs.cornell.edu

