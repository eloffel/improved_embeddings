   #[1]rss [2]slideshare search [3]alternate [4]alternate [5]alternate
   [6]alternate [7]alternate [8]alternate [9]slideshow json oembed profile
   [10]slideshow xml oembed profile [11]alternate [12]alternate
   [13]alternate

   (button)

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our [14]user
   agreement and [15]privacy policy.

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our
   [16]privacy policy and [17]user agreement for details.

   [18]slideshare [19]explore search [20]you

     * [21]linkedin slideshare

     * [22]upload
     * [23]login
     * [24]signup

     *
     * ____________________ (button) submit search

     * [25]home
     * [26]explore

     * [27]presentation courses
     * [28]powerpoint courses
     *
     * by [29]linkedin learning

   ____________________
   successfully reported this slideshow.

   we use your linkedin profile and activity data to personalize ads and
   to show you more relevant ads. [30]you can change your ad preferences
   anytime.
   id23 and artificial neural nets

   id23 and artificial neural nets pierre de lacaze
   director, machine intelligence shareablee inc. lisp nyc...

   overview     id23 (rl)     artificial neural nets (ann)    
   deep learning (dl)     deep id23 (...

   part 1 id23 most of the material is drawn from tom
   mitchell   s book machine learning (chpt. 13)

   id23 scenario     similar to a markov decision process
   (bellman 1957)     however in id23 ...

   id23 problem     agent that can observe and act upon an
   environment     learn a policy (sequence of actions)...

   the id23 task     markov decision process     agent has
   set s of observable states and set a of actions     at...

   id24 motivation     cannot learn   * directly because no training
   data of the form <s, a>     recall v* is the discounted...

   the q function     q(s,a) = r(s, a) +    v*(  (s, a))       *(s) = argmax q(s,
   a) a     by learning q instead of v* we no longer ne...

   id24 algorithm     initialize the state/action rewards table to 0    
   start in initial state s     repeat forever     select...

   simple grid example initial q value estimates table {:s1 {:east [:s2
   0], :south [:s4 0]} :s2 {:east [:s3 100], :west [:s1 ...

   id24 convergence     under the following criteria id24 is
   provably convergent:     deterministic mdp     bounded imm...

   reminder show code examples from rl.clj

   nondeterministic id24     nondeterministic mdp: a single action can
   yield one of several states with some id203 ...

   temporal difference learning     id24 learns from immediate
   successor state.     td-learning learns from distant states ...

   td-gammon     td-gammon, gerry tesaro, 1995     used temporal difference
   learning     used neural net to learn value function     ...

   issues in id23     exploration vs. exploitation     open
   research area       -greedy action selection     softmax...

   reminder show cool videos from pieter abdeel   s (uc berkeley) ijcai 2016
   presentation

   part 2 id158s most of the material is drawn from
   tom mitchell   s book machine learning (chpt. 4)

   neural nets in a nutshell     neural nets are a network of layers of
   units     input layer, hidden layers, output layer     diff...

   properties of anns     general method for learning real-valued,
   discrete-value and vector-valued functions from examples     b...

   appropriateness of anns     many training instances     target function is
   real-valued, discrete-value or vector-valued     trai...

   linear units and id88s     linear unit: a linear combination of
   weighted inputs (real-valued)     id88: thresholde...

   representational capacity     a single id88 can represent all
   primitive boolean functions: and, or, nand and nor all o...

   linear unit error function     recall output of a linear unit: w0 + w1x1
   +    . wnxn     use the mean squared error to measure t...

   weight space error surface

   training rules for single units 1. delta rule for linear units based on
   derivative of error function 2. id88 trainin...

   id119 algorithm (standard version) 1. initialize each of
   weights wi to small random values +/- 0.5 1. repeat un...

   standard vs. stochastic     standard id119 increments the
   weights after summing over all training examples     incr...

   absolute basics of anns     a network of units     network organized into
   layers:     input layer of inputs     hidden layer of un...

   sigmoid units need redefine the error function e to sum over all output
   units gradient for this new error function e is gi...

   id26 algorithm (using incremental id119) 1.
   initial weights to small random numbers 2. until termina...

   vectorizing id26     each layer can be represented as     matrix
   of weights, where ith row are weights of the ith u...

   advanced topics in ann     alternative error functions     adding a
   momentum term     adding penalty term for weight magnitude    ...

   alvinn: early self-driving car     drove up to 70 mph on sectioned off
   california highway.     network architecture     960 inpu...

   reminder show code examples annv.clj 1. identity function 2. mnist data
   set

   references     id23    
   http://personal.disco.unimib.it/vanneschi/mcgrawhill_-_machine_learning
   _-tom_mitchel...
   upcoming slideshare
   []
   loading in    5
     
   [] 1
   (button)
   1 of 36 (button)
   (button) (button)
   like this presentation? why not share!
     * share
     * email
     *
     *

     * [31]secrets behind alphago secrets behind alphago by yan xu
       341 views
     * [32]netnography - theory & how-to's netnography - theory & how-to's
       by tony yu 22166 views

   (button)

   share slideshare
     __________________________________________________________________

     * [33]facebook
     * [34]twitter
     * [35]linkedin

   embed
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   size (px)
   start on
   [x] show related slideshares at end
   wordpress shortcode ____________________
   link ____________________

id23 and artificial neural nets

   867 views

     * (button) share
     * (button) like
     * (button) download
     * ...
          +

   [36]pierre de lacaze

[37]pierre de lacaze

   , director of artificial intelligence
   [38]follow

   (button) (button) (button)

   published on sep 27, 2016

   video link: https://vimeo.com/184511491
   (button) ...

   published in: [39]science

     * [40]1 comment
     * [41]4 likes
     * [42]statistics
     * [43]notes

     * full name
       full name
       comment goes here.
       12 hours ago   [44]delete [45]reply [46]block
       are you sure you want to [47]yes [48]no
       your message goes here

   no profile picture user
   ____________________
   [49](button) post
     * [50]delaray
       [51]pierre de lacaze , director of artificial intelligence at
       insuite
       the video is here: https://vimeo.com/184511491
       2 years ago    [52]reply
       are you sure you want to  [53]yes  [54]no
       your message goes here

     * [55]cristianbalas
       [56]cristian balas , electrical engineer at tardec at tardec
       10 months ago
     * [57]patrickchan108
       [58]patrick chan , account manager at agilent technologies at
       agilent technologies
       1 year ago
     * [59]pedronius
       [60]peter morgan
       1 year ago
     * [61]mikepham12
       [62]mike pham , human resources professional at nyc
       2 years ago

   no downloads
   views
   total views
   867
   on slideshare
   0
   from embeds
   0
   number of embeds
   2
   actions
   shares
   0
   downloads
   33
   comments
   1
   likes
   4
   embeds 0
   no embeds
   no notes for slide

id23 and artificial neural nets

    1. 1. id23 and artificial neural nets pierre de
       lacaze director, machine intelligence shareablee inc. lisp nyc
       september 20th, 2016 rpl@lispnyc.org pierre@shareablee.com
    2. [63]2. overview     id23 (rl)     artificial neural
       nets (ann)     deep learning (dl)     deep id23 (drl)
           google deepmind alphago
    3. [64]3. part 1 id23 most of the material is drawn
       from tom mitchell   s book machine learning (chpt. 13)
    4. [65]4. id23 scenario     similar to a markov
       decision process (bellman 1957)     however in id23
       agent has no previous knowledge.
    5. [66]5. id23 problem     agent that can observe and
       act upon an environment     learn a policy (sequence of actions) to
       solve particular goals.     state transition and rewards provided by
       the environment     agent typically has no domain knowledge    
       differences with other ml approaches     delayed reward     involves
       exploration     partially observable states     training instances are
       generated by agent
    6. [67]6. the id23 task     markov decision process    
       agent has set s of observable states and set a of actions     at each
       step agent observes state and selects an action     environment
       responds with a next state and a reward. st+1 =   (st, at), rt =
       r(st, at)     learning task     learn a policy   : s     a for selecting
       next action     a solution is to choose at each state the action with
       largest cumulative reward v  (st) = rt +   rt+1 +   +   2rt+2 +   ..,
       where 0 <=    <= 1     in fact we would like to learn an optimal such
       policy   *(s) = argmax v  (s), for all states s   
    7. [68]7. id24 motivation     cannot learn   * directly because no
       training data of the form <s, a>     recall v* is the discounted
       cumulative reward     prefer s1 to s2 when v*(s1) > v*(s2)       *(s) =
       argmax[r(s, a) +    v*(  (s, a))] a     problem is requires perfect
       knowledge of reward function and state transition function
    8. [69]8. the q function     q(s,a) = r(s, a) +    v*(  (s, a))       *(s) =
       argmax q(s, a) a     by learning q instead of v* we no longer need to
       have complete knowledge of r and   .     we will need to estimate
       training values for q
    9. [70]9. id24 algorithm     initialize the state/action rewards
       table to 0     start in initial state s     repeat forever     select an
       action a ad execute it     observe immediate reward r and new state
       s        update the table entry for s, a as follows     q(s, a) = r +   
       max [a   , q(s   , a   )]     s     s   
   10. [71]10. simple grid example initial q value estimates table {:s1
       {:east [:s2 0], :south [:s4 0]} :s2 {:east [:s3 100], :west [:s1
       0], :south [:s5 0]} :s3 {:east [:s3 0], :west [:s3 0], :north [:s3
       0], :south [:s3 0]} :s4 {:east [:s5 0], :north [:s1 0]} :s5 {:east
       [:s6 0], :west [:s4 0], :north [:s2 0]} :s6 {:east [:s5 0], :north
       [:s3 100]}} final q value estimates table {:s1 {:east [:s2 90.0],
       :south [:s4 72.9]} :s2 {:east [:s3 100.0], :west [:s1 81.0], :south
       [:s5 81.0]} :s3 {:east [:s3 0], :west [:s3 0], :north [:s3 0],
       :south [:s3 0]} :s4 {:east [:s5 81.0], :north [:s1 81.0]} :s5
       {:east [:s6 90.0], :west [:s4 72.9], :north [:s2 90.0]} :s6 {:east
       [:s5 81.0], :north [:s3 100.0]}} optimal policy: [:s1 :east :s2
       :east :s3]    = 0.9
   11. [72]11. id24 convergence     under the following criteria
       id24 is provably convergent:     deterministic mdp     bounded
       immediate reward values     actions are executed with nonzero
       frequency
   12. [73]12. reminder show code examples from rl.clj
   13. [74]13. nondeterministic id24     nondeterministic mdp: a
       single action can yield one of several states with some id203
       distribution.     augment deterministic q function with expected
       reward and weighted average of estimated q values. q(s,a) =
       e[r(s,a)] +      p(s   |s, a) max q(s   , a   ) s    s        to ensure
       convergence need a decaying weighted average: qn(s,a)    
       (1-  n)qn-1(s,a) +   n[r + max qn-1(s   , a   )]    1 where   n =
       ------------------ 1 + visitsn(s, a)
   14. [75]14. temporal difference learning     id24 learns from
       immediate successor state.     td-learning learns from distant states
       as well.     q(1)(st, a) = rt +    max [a, q(st+1, a)]     q(2)(st, a) =
       rt +   rt+1 +   2 max [a, q(st+2, a)]     q(n)(st, a) = rt +   rt+1 +   +
         n-1rt+n-1 +   n max [a, q(st+n, a)]     sutton, 1988: td(  )    
       q(  )(st, a) = rt +   rt+1 +   2 max [a, q(st+2, a)]
   15. [76]15. td-gammon     td-gammon, gerry tesaro, 1995     used temporal
       difference learning     used neural net to learn value function    
       trained with 1.5 million games     effectively the first time neural
       nets were successfully used in conjunction with reinforcement
       learning     http://courses.cs.washington.edu/courses/cse590hk/01s
       p/readings/tesauro95cacm.pdf
   16. [77]16. issues in id23     exploration vs.
       exploitation     open research area       -greedy action selection    
       softmax action selection     generalization     too many state, action
       pairs in real life     learn state abstractions     transference     q
       function approximators     neural nets as universal approximators
       (drl)     using the q values estimates as training data     cost of
       exploration in non-simulation settings     partial episodes    
       estimate reward that would obtained by completing the episode    
       trace functions     parallelism     multiple agents learning a shared
       global policy     deepmind rl asynchronous library
   17. [78]17. reminder show cool videos from pieter abdeel   s (uc
       berkeley) ijcai 2016 presentation
   18. [79]18. part 2 id158s most of the material is
       drawn from tom mitchell   s book machine learning (chpt. 4)
   19. [80]19. neural nets in a nutshell     neural nets are a network of
       layers of units     input layer, hidden layers, output layer    
       different types of units:     linear unit, id88, sigmoid unit,
       relu     task is to learn weights for different units     typically
       given a set of training examples     id119 algorithm used
       to train units     id26 algorithm used to train network
   20. [81]20. properties of anns     general method for learning
       real-valued, discrete-value and vector-valued functions from
       examples     id26 uses gradient-descent to adjust weights
       to best fit training data (input/output pairs)     robust to noisy
       data     successfully used in image recognition & id103
           yann lecun 1989 (handwritten chars),     gary cottrell 1990 (face
       recognition)
   21. [82]21. appropriateness of anns     many training instances     target
       function is real-valued, discrete-value or vector-valued     training
       data contains errors/noise     training time is not an issue     fast
       evaluation is important     humans understanding of target function
       is not important.
   22. [83]22. linear units and id88s     linear unit: a linear
       combination of weighted inputs (real-valued)     id88:
       thresholded linear unit (discrete-valued) note: w0 is a bias whose
       purpose is to move the threshold of the activation function.
   23. [84]23. representational capacity     a single id88 can
       represent all primitive boolean functions: and, or, nand and nor
       all of which are all linear separable.     every boolean function can
       be represented by some network of id88s.     the xor cannot be
       represented by a single id88 because the decision surface is
       not linearly separable.
   24. [85]24. linear unit error function     recall output of a linear
       unit: w0 + w1x1 +    . wnxn     use the mean squared error to measure
       the error of the unit:     where d is the set of training examples    
       goal is to learn a weight vector that minimizes the error
   25. [86]25. weight space error surface
   26. [87]26. training rules for single units 1. delta rule for linear
       units based on derivative of error function 2. id88 training
       rule based on derivative of the error function     converges
       asymptotically to minimum error hypothesis     takes unbounded time
       to converge     convergence is independent on linear separability    
       converges to a hypothesis that perfectly fits the training data    
       takes bounded time to converge if learning rate is small enough    
       convergence is dependent on linear separability     convergence
       proved by minsky & pappert 1969
   27. [88]27. id119 algorithm (standard version) 1. initialize
       each of weights wi to small random values +/- 0.5 1. repeat until
       termination criteria is reached a. set each   wi to zero b. for each
       training example ([x1,   ,xn], t)     compute the output o of the unit
           for each unit weight     set   wi =   wi +    (t     o) xi     for each
       unit weight     set wi = wi +   wi     note:    is the learning rate,
       typically 0.5 or less.
   28. [89]28. standard vs. stochastic     standard id119
       increments the weights after summing over all training examples    
       incremental or stochastic id119 increments the weights
       for each training example.     both approaches used in practice.    
       stochastic version can avoid local minima.
   29. [90]29. absolute basics of anns     a network of units     network
       organized into layers:     input layer of inputs     hidden layer of
       units (one or more)     output layer of units     a standard ann is
       fully connected     all outputs of a previous layers are connected to
       all units of the next layer.     outputs of the network are computed
       by feeding the inputs into the next layer, computing the outputs of
       that layer, feeding those into the subsequent layer, etc.     a
       feed-forward ann forms an acyclic graph.
   30. [91]30. sigmoid units need redefine the error function e to sum
       over all output units gradient for this new error function e is
       given by sigmoid   (x) function has the nice property that its
       derivative is   (x)(1       (x))
   31. [92]31. id26 algorithm (using incremental gradient
       descent) 1. initial weights to small random numbers 2. until
       termination criteria for each training example a. compute the
       network outputs for the training example b. for each output unit k
       compute its error:   k = ok (1     ok) (tk     ok) c. for each hidden
       unit h compute its error:   h = oh (1     oh)    (whk   k ) k d. update
       each network weight wij wij = wij +      h xij
   32. [93]32. vectorizing id26     each layer can be represented
       as     matrix of weights, where ith row are weights of the ith unit    
       bias vector where ith element is the bias of the ith unit
   33. [94]33. advanced topics in ann     alternative error functions    
       adding a momentum term     adding penalty term for weight magnitude    
       adding terms for errors in the slope (mitchell&thrun, 1993)    
       decoupling distance and direction     line search     conjugate
       gradient method     dynamically altering network structure     removing
       least salient connections. (lecunn, 1990)     using different
       id180     hyperbolic tangent: tanh     rectified linear
       units (relu)     used only in past couple of years     f(x) = max(0,x)
   34. [95]34. alvinn: early self-driving car     drove up to 70 mph on
       sectioned off california highway.     network architecture     960
       input units     4 hidden units     30 output units     pomerleau,1993
   35. [96]35. reminder show code examples annv.clj 1. identity function
       2. mnist data set
   36. [97]36. references     id23    
       http://personal.disco.unimib.it/vanneschi/mcgrawhill_-_machine_lear
       ning_-tom_mitchell.pdf    
       https://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html    
       neural nets & deep learning    
       http://personal.disco.unimib.it/vanneschi/mcgrawhill_-_machine_lear
       ning_-tom_mitchell.pdf    
       http://neuralnetworksanddeeplearning.com/chap2.html    
       https://en.wikipedia.org/wiki/recurrent_neural_network    
       http://deeplearning.net/tutorial/deeplearning.pdf     convolutional
       neural networks     http://cs231n.github.io/convolutional-networks/    
       http://neuralnetworksanddeeplearning.com/chap6.html     deep
       id23    
       http://www0.cs.ucl.ac.uk/staff/d.silver/web/resources_files/deep_rl
       .pdf    
       http://neuro.cs.ut.ee/demystifying-deep-reinforcement-learning/    
       alphago    
       https://storage.googleapis.com/deepmind-media/alphago/alphagonature
       paper.pdf     http://deeplearningskysthelimit.blogspot.com/

          [98]recommended

     * learning to teach online
       learning to teach online
       online course - linkedin learning
     * data-driven presentations with excel and powerpoint 2016
       data-driven presentations with excel and powerpoint 2016
       online course - linkedin learning
     * visual aesthetics for elearning
       visual aesthetics for elearning
       online course - linkedin learning
     * secrets behind alphago
       secrets behind alphago
       yan xu
     * netnography - theory & how-to's
       netnography - theory & how-to's
       tony yu
     * deep learning
       deep learning
       pierre de lacaze
     * logic programming and ilp
       logic programming and ilp
       pierre de lacaze
     * meta object protocols
       meta object protocols
       pierre de lacaze
     * prolog 7-languages
       prolog 7-languages
       pierre de lacaze
     * clojure 7-languages
       clojure 7-languages
       pierre de lacaze

     * [99]english
     * [100]espa  ol
     * [101]portugu  s
     * [102]fran  ais
     * [103]deutsch

     * [104]about
     * [105]dev & api
     * [106]blog
     * [107]terms
     * [108]privacy
     * [109]copyright
     * [110]support

     *
     *
     *
     *
     *

   linkedin corporation    2019

     

share clipboard
     __________________________________________________________________

   [111]  
     * facebook
     * twitter
     * linkedin

   link ____________________

public clipboards featuring this slide
     __________________________________________________________________

   (button)   
   no public clipboards found for this slide

select another clipboard
     __________________________________________________________________

   [112]  

   looks like you   ve clipped this slide to already.
   ____________________

   create a clipboard

you just clipped your first slide!

   clipping is a handy way to collect important slides you want to go back
   to later. now customize the name of a clipboard to store your clips.
     __________________________________________________________________

   name* ____________________
   description ____________________
   visibility
   others can see my clipboard [ ]
   (button) cancel (button) save

   bizographics tracking image

references

   visible links
   1. https://www.slideshare.net/rss/latest
   2. https://www.slideshare.net/opensearch.xml
   3. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
   4. https://es.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
   5. https://fr.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
   6. https://de.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
   7. https://pt.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
   8. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
   9. https://www.slideshare.net/api/oembed/2?format=json&url=http://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  10. https://www.slideshare.net/api/oembed/2?format=xml&url=http://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  11. https://www.slideshare.net/mobile/delaray/reinforcement-learning-and-artificial-neural-nets
  12. android-app://net.slideshare.mobile/slideshare-app/ss/66465815
  13. ios-app://917418728/slideshare-app/ss/66465815
  14. http://www.linkedin.com/legal/user-agreement
  15. http://www.linkedin.com/legal/privacy-policy
  16. http://www.linkedin.com/legal/privacy-policy
  17. http://www.linkedin.com/legal/user-agreement
  18. https://www.slideshare.net/
  19. https://www.slideshare.net/explore
  20. https://www.slideshare.net/login
  21. https://www.slideshare.net/
  22. https://www.slideshare.net/upload
  23. https://www.slideshare.net/login
  24. https://www.slideshare.net/w/signup
  25. https://www.slideshare.net/
  26. https://www.slideshare.net/explore
  27. https://www.linkedin.com/learning/topics/presentations?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  28. https://www.linkedin.com/learning/topics/powerpoint?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  29. https://www.linkedin.com/learning?trk=slideshare_subnav_learning
  30. https://www.linkedin.com/psettings/privacy
  31. https://public.slidesharecdn.com/xuyangela/secrets-behind-alphago
  32. https://public.slidesharecdn.com/tonyyu2/netnography-presentation-slideshare
  33. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  34. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  35. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  36. https://www.slideshare.net/delaray?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  37. https://www.slideshare.net/delaray?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  38. https://www.slideshare.net/signup?login_source=slideview.popup.follow&from=addcontact&from_source=https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  39. https://www.slideshare.net/featured/category/science
  40. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets#comments-panel
  41. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets#likes-panel
  42. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets#stats-panel
  43. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets#notes-panel
  44. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  45. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  46. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  47. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  48. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  49. https://www.slideshare.net/signup?login_source=slideview.popup.comment&from=comments&from_source=https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  50. https://www.slideshare.net/delaray?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  51. https://www.slideshare.net/delaray?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare
  52. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  53. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  54. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
  55. https://www.slideshare.net/cristianbalas?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  56. https://www.slideshare.net/cristianbalas?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  57. https://www.slideshare.net/patrickchan108?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  58. https://www.slideshare.net/patrickchan108?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  59. https://www.slideshare.net/pedronius?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  60. https://www.slideshare.net/pedronius?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  61. https://www.slideshare.net/mikepham12?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  62. https://www.slideshare.net/mikepham12?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  63. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-2-638.jpg?cb=1474979219
  64. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-3-638.jpg?cb=1474979219
  65. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-4-638.jpg?cb=1474979219
  66. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-5-638.jpg?cb=1474979219
  67. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-6-638.jpg?cb=1474979219
  68. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-7-638.jpg?cb=1474979219
  69. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-8-638.jpg?cb=1474979219
  70. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-9-638.jpg?cb=1474979219
  71. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-10-638.jpg?cb=1474979219
  72. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-11-638.jpg?cb=1474979219
  73. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-12-638.jpg?cb=1474979219
  74. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-13-638.jpg?cb=1474979219
  75. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-14-638.jpg?cb=1474979219
  76. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-15-638.jpg?cb=1474979219
  77. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-16-638.jpg?cb=1474979219
  78. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-17-638.jpg?cb=1474979219
  79. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-18-638.jpg?cb=1474979219
  80. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-19-638.jpg?cb=1474979219
  81. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-20-638.jpg?cb=1474979219
  82. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-21-638.jpg?cb=1474979219
  83. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-22-638.jpg?cb=1474979219
  84. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-23-638.jpg?cb=1474979219
  85. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-24-638.jpg?cb=1474979219
  86. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-25-638.jpg?cb=1474979219
  87. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-26-638.jpg?cb=1474979219
  88. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-27-638.jpg?cb=1474979219
  89. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-28-638.jpg?cb=1474979219
  90. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-29-638.jpg?cb=1474979219
  91. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-30-638.jpg?cb=1474979219
  92. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-31-638.jpg?cb=1474979219
  93. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-32-638.jpg?cb=1474979219
  94. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-33-638.jpg?cb=1474979219
  95. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-34-638.jpg?cb=1474979219
  96. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-35-638.jpg?cb=1474979219
  97. https://image.slidesharecdn.com/reinforcement-learning-and-neural-nets-lispnyc-160927122128/95/reinforcement-learning-and-artificial-neural-nets-36-638.jpg?cb=1474979219
  98. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets#related-tab-content
  99. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
 100. https://es.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
 101. https://pt.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
 102. https://fr.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
 103. https://de.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
 104. https://www.slideshare.net/about
 105. https://www.slideshare.net/developers
 106. http://blog.slideshare.net/
 107. https://www.slideshare.net/terms
 108. https://www.slideshare.net/privacy
 109. http://www.linkedin.com/legal/copyright-policy
 110. https://www.linkedin.com/help/slideshare
 111. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
 112. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets

   hidden links:
 114. https://www.slideshare.net/delaray/reinforcement-learning-and-artificial-neural-nets
 115. https://www.slideshare.net/signup?login_source=slideview.clip.like&from=clip&layout=foundation&from_source=
 116. https://www.slideshare.net/login?from_source=%2fdelaray%2freinforcement-learning-and-artificial-neural-nets%3ffrom_action%3dsave&from=download&layout=foundation
 117. https://www.slideshare.net/signup?login_source=slideview.popup.flags&from=flagss&from_source=https%3a%2f%2fwww.slideshare.net%2fdelaray%2freinforcement-learning-and-artificial-neural-nets
 118. https://www.linkedin.com/learning/learning-to-teach-online?trk=slideshare_sv_learning
 119. https://www.linkedin.com/learning/data-driven-presentations-with-excel-and-powerpoint-2016?trk=slideshare_sv_learning
 120. https://www.linkedin.com/learning/visual-aesthetics-for-elearning?trk=slideshare_sv_learning
 121. https://www.slideshare.net/xuyangela/secrets-behind-alphago
 122. https://www.slideshare.net/tonyyu2/netnography-presentation-slideshare
 123. https://www.slideshare.net/delaray/deep-learning-77246289
 124. https://www.slideshare.net/delaray/logic-programming-and-ilp
 125. https://www.slideshare.net/delaray/meta-objectprotocols
 126. https://www.slideshare.net/delaray/prolog-7languages
 127. https://www.slideshare.net/delaray/clojure-7languages
 128. http://www.linkedin.com/company/linkedin
 129. http://www.facebook.com/linkedin
 130. http://twitter.com/slideshare
 131. http://www.google.com/+linkedin
 132. https://www.slideshare.net/rss/latest
