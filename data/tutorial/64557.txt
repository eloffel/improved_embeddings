an	
   overview	
   of	
   
transfer	
   learning 

qiang yang,  
huawei noah   s ark lab and hkust 
 
thanks: sinno pan  
ntu and i2r singapore 

http://www.cse.ust.hk/tl 	


transfer of learning	
   
a	
   psychological	
   point	
   of	
   view 

       the	
   study	
   of	
   dependency	
   of	
   human	
   conduct,	
   learning	
   or	
   
performance	
   on	
   prior	
   experience.	
   

       [thorndike and woodworth, 1901] explored how individuals 

would transfer in one context to another context that share similar 
characteristics. 

        c++       java 
        maths/physics      	
   computer	
   science/economics 

2	


id21	
   
in	
   the	
   machine	
   learning	
   community 

       the ability of a system to recognize and apply 
knowledge and skills learned in previous 
domains/tasks to novel tasks/domains, which 
share some commonality. 

       given a target domain/task, how to identify the 
commonality between the domain/task and 
previous domains/tasks, and transfer knowledge 
from the previous domains/tasks to the target 
one? 

3	


id21 
different fields 
       transfer	
   learning	
   for	
   
reinforcement	
   
learning.	
   

       transfer	
   learning	
   for	
   
classi   ca=on,	
   and	
   
regression	
   problems.	
   

	
   
     
 
 
 
     [taylor and stone, transfer 
learning for reinforcement 
learning domains: a survey, 
jmlr 2009] 

	
   
	
   
     [pan and yang, a survey on 

focus! 

id21, ieee 
tkde 2010] 

4	


	
   indoor	
   wifi	
   localization 

motivating example i:  

-30dbm 

-70dbm 

-40dbm 

5	


difference between domains 
time period b	


time period a	


device a	


device b	


6	


indoor wifi localization 
(cont.) 

training 
s=(-     37dbm,	
   ..,	
   -     77dbm),	
   l=(1,	
   3)	
   
s=(-     41dbm,	
   ..,	
   -     83dbm),	
   l=(1,	
   4)	
   
   	
   
s=(-     49dbm,	
   ..,	
   -     34dbm),	
   l=(9,	
   10)	
   
s=(-     61dbm,	
   ..,	
   -     28dbm),	
   l=(15,22)	
   

device a 

training 

localization 

model 

test 

s=(-     37dbm,	
   ..,	
   -     77dbm)	
   
s=(-     41dbm,	
   ..,	
   -     83dbm)	
   	
   
   	
   
s=(-     49dbm,	
   ..,	
   -     34dbm)	
   	
   
s=(-     61dbm,	
   ..,	
   -     28dbm)	
   

device a 

test 

average error 

distance 

~ 1.5 meters 

drop! 

s=(-     33dbm,	
   ..,	
   -     82dbm),	
   l=(1,	
   3)	
   
   	
   
s=(-     57dbm,	
   ..,	
   -     63dbm),	
   l=(10,	
   23)	
   

localization 

model 

s=(-     37dbm,	
   ..,	
   -     77dbm)	
   
s=(-     41dbm,	
   ..,	
   -     83dbm)	
   	
   
   	
   
s=(-     49dbm,	
   ..,	
   -     34dbm)	
   	
   
s=(-     61dbm,	
   ..,	
   -     28dbm)	
   

~10 meters 

device b 

device a 

7	


sentiment	
   classi<ication 

motivating example ii: 

8	


difference between domains 

electronics 

(1) compact; easy to operate; 
very good picture quality; 
looks sharp! 

(3) i purchased this unit from 
circuit city and i was very 
excited about the quality of the 
picture. it is really nice and 
sharp. 
(5) it is also quite blurry in 
very dark settings. i will never 
buy hp again. 

video games 

(2) a very good game! it is 
action packed and full of 
excitement. i am very much 
hooked on this game. 
(4) very realistic shooting 
action and good plots. we 
played this and were hooked. 

(6) the game is so boring. i 
am extremely unhappy and will 
probably never buy ubisoft 
again. 

9	


sentiment classification 

training 

test 

electronics 

training 

sentiment 
classifier 

sentiment 
classifier 

electronics 

test 

dvd 

electronics 

classification 

accuracy 

~ 85% 

drop! 

~70% 

10	


a	
   major	
   assumption	
   in	
   
traditional	
   machine	
   
learning 
        training and future (test) data come from the same domain, 

which implies 

q       represented in the same feature space. 

q       follow the same data distribution. 

11	


in	
   real-     world	
   applications	
   

       training	
   and	
   tes=ng	
   data	
   may	
   come	
   from	
   di   erent	
   domains,	
   
which	
   have:	
   
q      different marginal distributions, or different feature spaces: 
 
q      different predictive distributions, or different label spaces: 

12	


how to build systems on each 
domain of interest 
        build	
   every	
   system	
   from	
   scratch?	
   	
   
q      	
   time	
   consuming	
   and	
   expensive!	
   

        reuse	
   common	
   knowledge	
   extracted	
   from	
   exis=ng	
   systems?	
   

q      	
   more	
   prac=cal!	
   

13	


the goal of id21	
   

labeled training 

source 

domain data 

electronics 

time period a 

device a 

id21 

algorithms 

predictive 

models 

target 

domain data 

unlabeled training/with a few 

labeled data 

time period b 

target 

domain data 

testing 

14	


device b 

dvd 

id21 v.s. multi-task 

learning 

id21	


source domain 

target domain 

id72	


target 

domain 1 

target 

domain 2 

target 

domain 3 

target 

domain 4 

id21 settings	
   

heterogeneous 
id21 

heterogeneous 

transfer 
learning 

feature 
space 

homogeneous 

focus! 
homogeneous 
id21 

supervised transfer 

learning 

semi-supervised 
id21 

unsupervised 

id21 

16	


id21 approaches	
   

instance-based 

approaches 

feature-based 
approaches 

parameter-based 

approaches 

relational 
approaches 

17	


instance-based transfer 
learning approaches 

general assumption 

source and target domains 
have a lot of overlapping  
features (domains share  
the same/similar support) 

18	


instance-based transfer 
learning approaches 

case	
   i 
problem setting 

	
    

case	
   ii 

problem setting 
	
    

assumption 

assumption 

19	


instance-based approaches 
case i 

given	
   a	
   target	
   task, 

20	


instance-based approaches 
case i (cont.) 

assumption: 

	
   
	
   
	
   
	
   
 

21	


instance-based approaches 
case i (cont.) 

	
    

correcting sample selection bias / covariate shift  
[quionero-candela, etal, data shift in machine learning, mit press 2009] 

22	


correcting sample selection bias	
   

instance-based approaches 

       imagine	
   a	
   rejec%on	
   sampling	
   process,	
   and	
   view	
   
the	
   source	
   domain	
   as	
   samples	
   from	
   the	
   target	
   
domain	
   

assumption: sample selection bias is caused by 
the data generation process 

23	


correcting sample selection bias (cont.)	
   

instance-based approaches 

       the	
   distribu=on	
   of	
   the	
   selector	
   variable	
   maps	
   the	
   target	
   onto	
   
the	
   source	
   distribu=on	
   	
   

         label instances from the source domain with label 1	

         label instances from the target domain with label 0	

         train a binary classifier 

24	


[zadrozny, icml-04] 

instance-based approaches 
kernel mean matching (kmm) 
maximum mean discrepancy (mmd) 
	
   
	
   
	
   
	
   
	
   
	
   
	
   
[alex smola, arthur gretton and kenji kukumizu, icml-08 tutorial] 

25	


instance-based approaches 
 kernel mean matching (kmm) (cont.) 

[huang etal., nips-06] 

the required optimization is a simple qp problem	


26	


instance-based approaches 
direct density ratio estimation 

kl divergence loss 

least squared loss 

[sugiyama etal., nips-07] 

[kanamori etal., jmlr-09] 

27	


case ii	
   

instance-based approaches 

       intui=on:	
   part of the labeled data in the source domain can be 
reused in the target domain after re-weighting based on their 
contributions to the classification accuracy of the learning 
problem in the target domain 

28	


case ii (cont.)	
   

instance-based approaches 

         tradaboost [dai etal icml-07] 
      for each boosting iteration, 

q       use the same strategy as adaboost to 
update the weights of target domain data. 
q       use a new mechanism to decrease the 
weights of misclassified source domain data. 

29	


instance-transfer approaches	
   
[j.jiang	
   and	
   c.	
   zhai,	
   acl	
   2007]	
   	
   

[wu and dietterich icml-04]  

[dai, yang et al. icml-07] 

uniform weights 

correct the decision boundary by re-weighting 

id168 on the 
target domain data 

id168 of 
source domain data 

id173 
term 

30	


tradaboost  [dai, yang et al. icml-07]	
   

hedge (   ) 
[freund et al. 1997] 

       misclassi   ed examples:	

       increase the weights of 
evaluation with 20ng: 22%     8%    
the misclassi   ed target 
http://people.csail.mit.edu/jrennie/20newsgroups/ 
data	


adaboost 
[freund et al. 1997] 

to increase the weights of 
the misclassified data 

to decrease the weights 
of the misclassified data 

  

source domain  
labeled data 

target domain  
labeled data 

the whole 
training data set 

classifiers trained on  
re-weighted labeled data 

target domain  
unlabeled data 

       decrease the weights of 
the misclassi   ed source 
data	


31	


feature-based transfer 
learning approaches 

when source and target  
domains only have some  
overlapping features. (lots  
of features only have  
support in either the source  
or the target domain) 

32	


learning approaches (cont.)	
   

feature-based transfer 

how	
   to	
   learn	
   	
   	
   	
   	
   ?	
   
        solution 1: encode application-specific knowledge to learn the 

transformation.  

 
        solution 2: general approaches to learning the transformation. 

33	


feature-based approaches 
encode application-specific knowledge 
        for	
   instance,	
   sen=ment	
   analysis	
   

        structural correspondence learning (scl) [biltzer etal. 

emnlp-06] 

        spectral feature alignment (sfa) [pan etal. www-10] 

34	


feature-based approaches 
develop general approaches 

time period a 

time period b 

device a	


device b 

35	


general approaches	
   

feature-based approaches 

        learning	
   features	
   by	
   minimizing	
   distance	
   	
   between	
   
distribu=ons	
   in	
   a	
   latent	
   space	
   
        learning	
   features	
   inspired	
   by	
   mul=-     task	
   learning	
   
        learning features via self-taught learning	
   

36	


learning	
   features	
   by	
   minimizing	
   distance	
   	
   
between	
   distributions	
   in	
   a	
   latent	
   space 
transfer component analysis [pan etal.,  ijcai-09, tnn-11] 
motivation 

source 

target 

latent factors 

temperature  

signal 
properties 

power of aps 

building 
structure   

37	


transfer component analysis (cont.) 

source 

target 

common 
latent factors 

temperature  

signal 
properties 

power of aps 

building 
structure   

38	


cause the data distributions between domains different 

transfer component analysis (cont.) 

source 

target 

noisy 
component 

signal 
properties 

building 
structure   

principal components 

39	


transfer component analysis (cont.) 

learning	
   	
   	
   	
   	
   by	
   only	
   minimizing	
   distance	
   between	
   	
   
distribu=ons	
   may	
   map	
   the	
   data	
   onto	
   noisy	
   

factors. 

40	


transfer component analysis (cont.) 
main idea: the learned     should map the source 
and target domain data to the latent space spanned 
by the factors which can reduce domain distance 
as well as preserving original data structure. 

high level optimization problem 

41	


transfer component analysis (cont.) 

mmd 

42	


transfer component analysis (cont.) 

to minimize the distance 
between domains 

to preserve the local 
geometric structure 

[pan etal., aaai-08] 

to maximize the 
data variance 

         it is a sdp problem, expensive! 
         it is transductive, cannot generalize on unseen instances! 
         pca is post-processed on the learned kernel matrix, which may 

potentially discard useful information. 

43	


transfer component analysis (cont.) 

to minimize the distance 
between domains 

empirical kernel map 

resultant parametric 
kernel 

id173 

to maximize the 
data variance 

44	


feature space: document-word 
co-occurrence 

source 

d_s 

t
r
a
n
s
f
e
r
 

k
n
o
w
e
d
g
e

l

 

target 

d_t 

45	


co-     id91	
   based	
   classi<ication	
   (kdd	
   2007) 

       co-     id91	
   is	
   applied	
   between	
   features	
   (words)	
   and	
   

target-     domain	
   documents	
   

       word	
   id91	
   is	
   constrained	
   by	
   the	
   labels	
   of	
   in-     domain	
   

(old)	
   documents	
   
       the	
   word	
   id91	
   part	
   in	
   both	
   domains	
   serve	
   as	
   a	
   bridge	
   

46	


46	
   

structural	
   correspondence	
   learning	
   
[blitzer	
   et	
   al.	
   acl	
   2007] 

       scl:	
   [ando	
   and	
   zhang,	
   jmlr	
   2005]	
   
       method	
   

       de   ne	
   pivot	
   features:	
   common	
   in	
   two	
   domains	
   (not	
   
buy)	
   
       find	
   non-     pivot	
   features	
   in	
   each	
   domain	
   (repe==ve)	
   
       build	
   classi   ers	
   through	
   the	
   non-     pivot	
   features	
   

(1) the book is so repetitive that i 
found myself yelling    . i will 
de   nitely not buy another.	


(2) do not buy the shark portable 
steamer    . trigger mechanism is 
defective. 	


book domain	


kitchen domain	


47	


scl 

 [blitzer et al. emnl-06, blitzer et al. acl-07, ando and zhang jmlr-05] 

  

a) heuristically choose m pivot 
features, which is task specific. 
b) transform each vector of pivot 
feature to a vector of binary 
values and then create 
corresponding prediction 
problem. 

learn parameters of each 
prediction problem 

do eigen decomposition 
on the matrix of 
parameters and learn the 
linear mapping function. 

courtesy of sinno pan	


use the learnt mapping function to 
construct new features and train 
classifiers onto the new representations. 

self-taught id171	
   

feature-based approaches 

        intuition: there exist some high-level features  
that can help the target learning task even only a 
few labeled data are given 
        how to learn high-level features 

        sparse coding [raina etal., 2007] 
        deep learning [glorot etal., 2011] 

49	


parameter-based transfer 
learning approaches 

 
 
motivation: a well-trained model      has learned a 
 
lot of structure. if two tasks are related, this 
 
structure can be transferred to learn      . 
 

50	


parameter-based approaches 
multi-task parameter learning 
assumption: 
if tasks are related, they may share similar parameter vectors. 
for example, [evgeniou and pontil, kdd-04] 
 
 
 
 
 

specific part for individual task 

common part 

51	


parameter-based approaches 
multi-task parameter learning (cont.) 

a general framework: 
 

[zhang and yeung, uai-10] 

[agarwal etal, nips-10] 

52	


relational id21 
approaches 
        motivation:	
   if	
   two	
   rela=onal	
   domains	
   (data	
   is	
   non-     i.i.d)	
   are	
   
related,	
   they	
   may	
   share	
   some	
   similar	
   rela=ons	
   among	
   objects.	
   
these	
   rela=ons	
   can	
   be	
   used	
   for	
   knowledge	
   transfer	
   across	
   
domains.	
   

53	


relational id21 
approaches (cont.) 

academic domain (source) 

movie domain (target) 

student (b) 

advisedby 

professor (a) 

workedfor 

actor(a) 

director(b) 

publication 

publication 

moviemember  moviemember 

paper (t) 

movie (m) 

advisedby (b, a)    publication (b, t)  
=> publication (a, t)  

workedfor (a, b)    moviemember (a, m)  
=> moviemember (b, m)  

p1(x, y)    p2 (x, z)  => p2 (y, z)  
[davis and domingos, icml-09]	


54	


summary	
   

transfer 
learning 

heterogeneous 
id21 

supervised transfer 

learning 

semi-supervised 
id21 

unsupervised 

id21 

homogeneous 

id21 

in data level 

instance-based 

approaches 

feature-based 
approaches 

relational 
approaches 

parameter-based 

approaches 

55	


in model level 

some research issues in 
id21 
        when should id21 be applied 
        id21 across heterogeneous feature spaces 
or different label spaces  
        active learning meets id21 
        id21 meets lifelong learning 
        id21 to novel application areas 

56	


reference 

        [thorndike and woodworth, the influence of improvement in one 
mental function upon the efficiency of the other functions, 1901] 
        [taylor and stone, id21 for id23 

domains: a survey, jmlr 2009] 

        [pan and yang, a survey on id21, ieee tkde 2010] 
        [quionero-candela, etal, data shift in machine learning, mit press 

        [biltzer	
   etal..	
   domain	
   adapta=on	
   with	
   structural	
   correspondence	
   

        [pan etal., cross-domain sentiment classification via spectral feature 

learning,	
   emnlp	
   2006] 

alignment, www 2010] 

        [pan etal., id21 via id84, aaai 

57	


2009] 

2008] 

reference	
   (cont.) 

        [pan etal., id20 via transfer component analysis, 

ijcai 2009, tnn 2011] 

        [evgeniou and pontil, regularized id72, kdd 2004] 
        [zhang and yeung, a convex formulation for learning task 

relationships in id72, uai 2010] 

        [agarwal etal, learning multiple tasks using manifold 

id173, nips 2010]  

        [argyriou etal., multi-task id171, nips 2007] 
        [ando and zhang, a framework for learning predictive structures 

from multiple tasks and unlabeled data, jmlr 2005] 

        [ji etal, extracting shared subspace for multi-label classification, 

kdd 2008] 

        [dai etal., boosting for id21, icml 2007] 

58	


reference	
   (cont.) 

        [raina etal., self-taught learning: id21 from unlabeled 

data, icml 2007] 

        [glorot etal., id20 for large-scale sentiment 

classification: a deep learning approach, icml 2011] 

        [davis and domingos, deep transfer via second-order markov logic, 

icml 2009] 

        [sugiyama etal., direct importance estimation with model selection 

and its application to covariate shift adaptation, nips 2007] 

        [kanamori etal., a least-squares approach to direct importance 

estimation, jmlr 2009] 

        [huang etal., correcting sample selection bias by unlabeled data, 

nips 2006] 

        [zadrozny, learning and evaluating classifiers under sample 

selection bias, icml 2004] 

59	


selected	
   applica,ons	
   
of	
   transfer	
   learning	
   

qiang	
   yang,	
   huawei	
   noah   s	
   ark	
   lab	
   

and	
   hkust	
   

hbp://www.noahlab.com.hk	
   	
   

part	
   1.	
   cross	
   domain	
   transfer	
   learning	
   

for	
   ac,vity	
   recogni,on	
   

       vincent	
   w.	
   zheng,	
   derek	
   h.	
   hu	
   and	
   qiang	
   yang.	
   cross-     domain	
   ac,vity	
   

recogni,on.	
   in	
   proceedings	
   of	
   the	
   11th	
   interna2onal	
   conference	
   on	
   
ubiquitous	
   compu2ng	
   (ubicomp-     09),	
   orlando,	
   florida,	
   usa,	
   sept.30-     oct.
3,	
   2009.	
   

       derek	
   hao	
   hu,	
   qiang	
   yang.	
   transfer	
   learning	
   for	
   ac,vity	
   recogni,on	
   via	
   

sensor	
   mapping.	
   in	
   proceedings	
   of	
   the	
   22nd	
   interna2onal	
   joint	
   conference	
   
on	
   ar2   cial	
   intelligence	
   (ijcai-     11),	
   barcelona,	
   spain,	
   july	
   2011	
   

ehealth	
   demo	
   

sensor	
   data	
   

3	
   
3	
   

ehealth	
   demo	
   

ac,vity	
   annota,on	
   

4	
   
4	
   

ehealth	
   demo	
   

auto	
   logging	
   /	
   ac,vity	
   recogni,on	
   

(service	
   in	
   background)	
   

5	
   
5	
   

ehealth	
   demo	
   

real-     ,me	
   ac,vity	
   recogni,on	
   

6	
   
6	
   

ehealth	
   demo	
   

ac,vity	
   pro   ling	
   

7	
   
7	
   

ehealth	
   demo	
   

ac,vity	
   pro   ling	
   for	
   health	
   management	
   

8	
   
8	
   

key	
   problem:	
   recognizing	
   ac,ons	
   and	
   

context	
   (loca,ons)	
   

inferred through ar 

ar: activity recognition via sensors 

walking? 

buying ticket? 

open door? 

sightseeing 

gps and other 

sensors 

sensors 

sensors 

watch show 

9	
   

1. cross-domain activity recognition 
 [zheng, hu, yang: ubicomp-2009, pcm-2011] 

       challenge: 

       some activities without data (partially labeled) 

       cross-domain activity recognition 

       use other activities with available labeled data 

       happen in kitchen 
       use cup, pot 
           

making	
   co   ee	
   

making	
   tea	
   

10	
   

cleaning	
   
indoor	
   

laundry	
   

dishwashing	
   

11	
   

system workflow  

<sensor reading, 
activity name> 

example: <ss,    make 

coffee   > 

source	
   domain	
   
labeled	
   data	
   

example:	
   

sim(   make	
   co   ee   ,	
   
   make	
   tea   )	
   =	
   0.6	
   

similarity	
   
measure	
   

the	
   web	
   

example:	
   pseudo	
   
training	
   data:	
   <ss,	
   
   make	
   tea   ,	
   0.6>	
   

target	
   domain	
   
pseudo	
   labeled	
   

data	
   

weighted	
   id166	
   

classi   er	
   

12	
   
12	
   

calculating activity similarities 

calculated similarity 

with the activity 

"sweeping"

        how similar are two 
activities? 
       use web search 
results 
       tfidf: traditional ir 
similarity metrics 
(cosine similarity) 
       example 

         mined similarity between 

the activity    sweeping    
and    vacuuming   ,    making 
the bed   ,    gardening    

13	
   13	
   

datasets:	
   mit	
   placelab	
   

hbp://architecture.mit.edu/house_n/placelab.html	
   	
   

       mit	
   placelab	
   dataset	
   (plia2)	
   [in,lle	
   et	
   al.	
   

pervasive	
   2005]	
   

       ac,vi,es:	
   common	
   household	
   ac,vi,es	
   

14	
   
14	
   

datasets:	
   intel	
   research	
   lab	
   

       intel	
   research	
   lab	
   

[paberson,	
   fox,	
   
kautz,	
   philipose,	
   
iswc2005]	
   
       ac,vi,es	
   performed:	
   

11	
   ac,vi,es	
   

       sensors	
   

       rfid	
   readers	
   &	
   tags	
   

       length:	
   

       10	
   mornings	
   

picture	
   excerpted	
   from	
   [paberson,	
   fox,	
   
kautz,	
   philipose,	
   iswc2005].	
   

15	
   
15	
   

cross-domain ar: performance 

accuracy 
with cross 
domain 
transfer 

63.2% 

65.8% 

58.9% 

53.2% 

intel 
research 
lab dataset 
amsterdam 
dataset 
mit dataset 
(cleaning to 
laundry) 
mit dataset 
(cleaning to 
dishwashing) 

# activities 
(source 
domain) 

# activities 
(target 
domain) 

baseline 
(random 
guess) 

supervised 
(upper 
bound) 

5 

4 

13 

13 

6 

3 

8 

7 

16.7% 

78.3% 

33.3% 

72.3% 

12.5% 

14.3% 

- 

- 

         activities in the source domain and the target domain are generated 

from ten random trials, mean accuracies are reported. 

16	
   16	
   

derek	
   hao	
   hu	
   and	
   qiang	
   yang,	
   ijcai	
   

2011	
   

transferrin
g	
   across	
   
feature	
   
space	
   

transferring	
   
across	
   label	
   

space	
   

p y x
(
t

|

t

)

transfer	
   from	
   

source	
   domain	
   to	
   
target	
   domain	
   

	
   
	
   
	
   

=       

i
( )

l
   

c

p c x
( |
t

)

p y c
(
| )

t

s

proposed	
   approach	
   

       final	
   goal:	
   es,mate	
   	
   

      we	
   have	
   

p y x
(
|t

t

)

      es,ma,ng	
   the	
   above	
   equa,on	
   at	
   its	
   mode:	
   

feature	
   transfer	
   

label	
   transfer	
   

experiments	
   

       datasets	
   

       baseline	
   

       uva	
   dataset	
   [van	
   kasteren	
   et	
   al.	
   ubicomp	
   2008]	
   
       mit	
   placelab	
   (plia1)	
   dataset	
   [in,lle	
   et	
   al.	
   ubicomp	
   2006]	
   
      
intel	
   research	
   lab	
   dataset	
   [paberson	
   et	
   al.	
   iswc	
   2005]	
   

       unsupervised	
   ac,vity	
   recogni,on	
   algorithm	
   [wyab	
   et	
   al.	
   2005]	
   

       di   erent	
   sensors	
   for	
   di   erent	
   datasets	
   

state-     based	
   sensors	
   

for	
   uva	
   dataset	
   

a	
   series	
   of	
   di   erent	
   wired	
   
sensors	
   for	
   mit	
   dataset	
   

rfid	
   sensor	
   for	
   intel	
   

research	
   lab	
   

dataset	
   

experiments:	
   

di   erent	
   feature	
   &	
   label	
   spaces	
   

       source:	
   mit	
   
plia1	
   dataset	
   
target:	
   uva	
   
(intel)	
   datasets	
   

part	
   2.	
   source-     free	
   transfer	
   learning	
   
       source	
   free	
   transfer	
   learning	
   
       evan	
   wei	
   xiang,	
   sinno	
   jialin	
   pan,	
   weike	
   pan,	
   jian	
   su	
   and	
   
qiang	
   yang.	
   source-     selec,on-     free	
   transfer	
   learning.	
   in	
   
proceedings	
   of	
   the	
   22nd	
   interna,onal	
   joint	
   conference	
   on	
   
ar,   cial	
   intelligence	
   (ijcai-     11),	
   barcelona,	
   spain,	
   july	
   2011.	
   

source-selection-free  

id21 

evan	
   xiang,	
   sinno	
   pan,	
   weike	
   pan,	
   

jian	
   su,	
   qiang	
   yang	
   

hkust	
   -     	
   ijcai	
   2011	
   

22	
   

id21 

supervised	
   	
   
learning 

lack	
   of	
   labeled	
   
training	
   data	
   
always	
   happens	
   

transfer	
   	
   
learning 

when	
   we	
   have	
   
some	
   related	
   
source	
   domains	
   

hkust	
   -     	
   ijcai	
   2011	
   

23	
   

where are the    right    source data? 

we	
   may	
   have	
   an	
   extremely	
   large	
   number	
   of	
   

choices	
   of	
   poten2al	
   sources	
   to	
   use.	
   

hkust	
   -     	
   ijcai	
   2011	
   

24	
   

outline of source-selection-free 

id21 (ssftl) 

	
   

v      stage	
   1:	
   building	
   base	
   models	
   
v      stage	
   2:	
   label	
   bridging	
   via	
   laplacian	
   graph	
   embedding	
   
v      stage	
   3:	
   mapping	
   the	
   target	
   instance	
   using	
   the	
   base	
   

	
   

classi   ers	
   &	
   the	
   projecaon	
   matrix	
   	
   
	
   

v      stage	
   4:	
   learning	
   a	
   matrix	
   w	
   to	
   directly	
   project	
   the	
   

target	
   instance	
   to	
   the	
   latent	
   space	
   	
   
	
   

v      stage	
   5:	
   making	
   predicaons	
   for	
   the	
   incoming	
   test	
   data	
   

using	
   w	
   

hkust	
   -     	
   ijcai	
   2011	
   

25	
   

ssftl     building base models 

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

from	
   the	
   taxonomy	
   of	
   the	
   online	
   informa2on	
   source,	
   we	
   can	
   

   compile   	
   a	
   lot	
   of	
   base	
   classi   ca2on	
   models	
   

hkust	
   -     	
   ijcai	
   2011	
   

26	
   

ssftl     label bridging via laplacian 

graph embedding 

problem 

however,	
   the	
   label	
   spaces	
   
of	
   the	
   based	
   classi   ca2on	
   

models	
   and	
   the	
   target	
   
task	
   can	
   be	
   di   erent	
   

	
   

 
 
 
 
 
 
vs.	
   
 
 
 
 
 
 
 
 
 
 
 
 

h
c
t
a
m

m

s
i

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

since	
   the	
   label	
   names	
   
are	
   usually	
   short	
   and	
   
sparse,	
   ,	
   in	
   order	
   to	
   
uncover	
   the	
   intrinsic	
   
rela2onships	
   between	
   
the	
   target	
   and	
   source	
   

labels,	
   we	
   turn	
   to	
   
some	
   social	
   media	
   
such	
   as	
   delicious,	
   
which	
   can	
   help	
   to	
   

bridge	
   di   erent	
   label	
   

sets	
   together.	
   

neighborhood	
   matrix	
   

for	
   label	
   graph	
   

q

m	
   

q

bob	
   

tom	
   

john	
   

gary	
   

steve	
   

history	
   

travel	
   

finance	
   

tech	
   

sports	
   

laplacian	
   eigenmap	
   
[belkin	
   &	
   niyogi,2003]	
   

m-     dimensional	
   
latent	
   space	
   

projecaon	
   matrix	
   

q

v	
   

m

the	
   relaaonships	
   between	
   labels,	
   e.g.,	
   similar	
   or	
   dissimilar,	
   can	
   be	
   

represented	
   by	
   the	
   distance	
   between	
   their	
   corresponding	
   prototypes	
   in	
   

the	
   latent	
   space,	
   e.g.,	
   close	
   to	
   or	
   far	
   away	
   from	
   each	
   other.	
   

hkust	
   -     	
   ijcai	
   2011	
   

27	
   

ssftl     mapping the target instance using 
the base classifiers & the projection matrix v 

vs.	
   

vs.	
   

vs.	
   

0.1:0.9 

0.3:0.7 

0.2:0.8 

vs.	
   

vs.	
   

0.6:0.4 

0.7:0.3 

target	
   instance	
   

   ipad2	
   is	
   
released	
   in	
   
march,	
         	
   

for	
   each	
   target	
   instance,	
   we	
   can	
   

obtain	
   a	
   combined	
   result	
   on	
   the	
   label	
   
space	
   via	
   aggrega2ng	
   the	
   predic2ons	
   

from	
   all	
   the	
   base	
   classi   ers	
   

then	
   we	
   can	
   use	
   the	
   projecaon	
   matrix	
   v	
   
to	
   transform	
   such	
   combined	
   results	
   from	
   

the	
   label	
   space	
   to	
   a	
   latent	
   space	
   

	
   
y
t
i
l
i

b
a
b
o
r
p

tech	
   

finance	
   

travel	
   

sports	
   

history	
   

label	
   space	
   

q

projecaon	
   matrix	
   

q

v	
   

m

=	
   <z1,	
   z2,	
   z3,	
      ,	
   zm>	
   

m-     dimensional	
   
latent	
   space	
   

however,	
   do	
   we	
   need	
   to	
   recall	
   the	
   base	
   classi   ers	
   during	
   the	
   predicaon	
   phase?	
   	
   

the	
   answer	
   is	
   no!	
   

hkust	
   -     	
   ijcai	
   2011	
   

28	
   

ssftl     learning a matrix w to directly 

project the target instance to the latent space  

target domain 

 
 
 
 
data 
 

labeled & 
unlabeled 

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

projecaon	
   matrix	
   

q

v	
   

m

for	
   each	
   target	
   instance,	
   we	
      rst	
   aggregate	
   
its	
   predic2on	
   on	
   the	
   base	
   label	
   space,	
   and	
   

then	
   project	
   it	
   onto	
   the	
   latent	
   space	
   

loss	
   on	
   unlabeled	
   data	
   

loss	
   on	
   labeled	
   data	
   

our	
   regression	
   model	
   

learned	
   projecaon	
   matrix	
   

d

w	
   

m

29	
   

hkust	
   -     	
   ijcai	
   2011	
   

ssftl     making predictions for the  

incoming test data 

target domain 

 
 
 
 
 

incoming 
test data 

vs.	
   

vs.	
   

vs.	
   

vs.	
   

vs.	
   

learned	
   projecaon	
   matrix	
   

d

q

w	
   

m

projecaon	
   matrix	
   

v	
   

m

the	
   learned	
   projec2on	
   matrix	
   w	
   can	
   be	
   used	
   

to	
   transform	
   any	
   target	
   instance	
   directly	
   
from	
   the	
   feature	
   space	
   to	
   the	
   latent	
   space	
   

therefore,	
   we	
   can	
   make	
   
predic2on	
   directly	
   for	
   any	
   

incoming	
   test	
   data	
   based	
   on	
   the	
   
distance	
   to	
   the	
   label	
   prototypes,	
   

without	
   calling	
   the	
   base	
   

classi   caaon	
   models	
   

hkust	
   -     	
   ijcai	
   2011	
   

30	
   

experiments - datasets 
v      building	
   source	
   classi   ers	
   with	
   wikipedia	
   

v      3m	
   ar,cles,	
   500k	
   categories	
   (mirror	
   of	
   aug	
   2009)	
   
v      50,	
   000	
   pairs	
   of	
   categories	
   are	
   sampled	
   for	
   source	
   models	
   

v      building	
   label	
   graph	
   with	
   delicious	
   

v      800-     day	
   historical	
   tagging	
   log	
   (jan	
   2005	
   ~	
   march	
   2007)	
   
v      50m	
   tagging	
   logs	
   of	
   200k	
   tags	
   on	
   5m	
   web	
   pages	
   

v      benchmark	
   target	
   tasks	
   
v      20	
   newsgroups	
   (190	
   tasks)	
   
v      google	
   snippets	
   (28	
   tasks)	
   
v      aol	
   web	
   queries	
   (126	
   tasks)	
   
v      ag	
   reuters	
   corpus	
   (10	
   tasks)	
   

hkust	
   -     	
   ijcai	
   2011	
   

31	
   

ssftl - building base classifiers 

parallelly using mapreduce 

input	
   

map	
   

reduce	
   

1 

2 

1 

3 

3 

2 

   

   

   

   

   

   

the	
   training	
   data	
   are	
   replicated	
   
and	
   assigned	
   to	
   di   erent	
   bins	
   

1 

2 

3 

vs.	
   

vs.	
   

vs.	
   

vs.	
   

in	
   each	
   bin,	
   the	
   training	
   data	
   
are	
   paired	
   for	
   building	
   binary	
   

base	
   classi   ers	
   

these	
   pre-     trained	
   source	
   base	
   classi   ers	
   are	
   stored	
   

and	
   reused	
   for	
   di   erent	
   incoming	
   target	
   tasks.	
   

hkust	
   -     	
   ijcai	
   2011	
   

32	
   

if	
   we	
   need	
   to	
   build	
   50,000	
   
base	
   classi   ers,	
   it	
   would	
   take	
   
about	
   two	
   days	
   if	
   we	
   run	
   the	
   
training	
   process	
   on	
   a	
   single	
   
server.	
   	
   
therefore,	
   we	
   distributed	
   the	
   
training	
   process	
   to	
   a	
   cluster	
   
with	
   30	
   cores	
   using	
   
mapreduce,	
   and	
      nished	
   the	
   
training	
   within	
   two	
   hours.	
   	
   

experiments - results 

unsupervised	
   ssftl	
   

semi-     supervised	
   ssftl	
   

our	
   regression	
   model	
   

-     parameter	
   sezangs-     	
   
source	
   models:	
   5,000	
   
unlabeled	
   target	
   data:	
   100%	
   
lambda_2:	
   0.01	
   

hkust	
   -     	
   ijcai	
   2011	
   

33	
   

experiments - results 

for	
   each	
   target	
   instance,	
   we	
      rst	
   aggregate	
   
its	
   predic2on	
   on	
   the	
   base	
   label	
   space,	
   and	
   

then	
   project	
   it	
   onto	
   the	
   latent	
   space	
   

loss	
   on	
   unlabeled	
   data	
   

our	
   regression	
   model	
   

-     parameter	
   sezangs-     	
   
mode:	
   semi-     supervised	
   
labeled	
   target	
   data:	
   20	
   
unlabeled	
   target	
   data:	
   100%	
   
lambda_2:	
   0.01	
   

hkust	
   -     	
   ijcai	
   2011	
   

34	
   

experiments - results 

our	
   regression	
   model	
   

-     parameter	
   sezangs-     	
   
mode:	
   semi-     supervised	
   
labeled	
   target	
   data:	
   20	
   
source	
   models:	
   5,000	
   
lambda_2:	
   0.01	
   

hkust	
   -     	
   ijcai	
   2011	
   

35	
   

experiments - results 

supervised	
   ssftl	
   

semi-     supervised	
   ssftl	
   

our	
   regression	
   model	
   

-     parameter	
   sezangs-     	
   
labeled	
   target	
   data:	
   20	
   
unlabeled	
   target	
   data:	
   100%	
   
source	
   models:	
   5,000	
   

hkust	
   -     	
   ijcai	
   2011	
   

36	
   

experiments - results 

for	
   each	
   target	
   instance,	
   we	
      rst	
   aggregate	
   
its	
   predic2on	
   on	
   the	
   base	
   label	
   space,	
   and	
   

then	
   project	
   it	
   onto	
   the	
   latent	
   space	
   

loss	
   on	
   unlabeled	
   data	
   

our	
   regression	
   model	
   

-     parameter	
   sezangs-     	
   
mode:	
   semi-     supervised	
   
labeled	
   target	
   data:	
   20	
   
source	
   models:	
   5,000	
   
unlabeled	
   target	
   data:	
   100%	
   
lambda_2:	
   0.01	
   

hkust	
   -     	
   ijcai	
   2011	
   

37	
   

related works 

hkust	
   -     	
   ijcai	
   2011	
   

38	
   

summary 

v      source-     selecaon-     free	
   transfer	
   learning	
   

v      when	
   the	
   poten2al	
   auxiliary	
   data	
   is	
   embedded	
   in	
   very	
   

large	
   online	
   informa2on	
   sources	
   

v      no	
   need	
   for	
   task-     speci   c	
   source-     domain	
   data	
   
v      we	
   compile	
   the	
   label	
   sets	
   into	
   a	
   graph	
   laplacian	
   for	
   

automa2c	
   label	
   bridging	
   
v      ssftl	
   is	
   highly	
   scalable	
   

v      processing	
   of	
   the	
   online	
   informa2on	
   source	
   can	
   be	
   done	
   

o   ine	
   and	
   reused	
   for	
   di   erent	
   tasks.	
   

hkust	
   -     	
   ijcai	
   2011	
   

39	
   

heterogeneous	
   transfer	
   

learning	
   

heterogeneous	
   transfer	
   learning	
   for	
   image	
   id91	
   

via	
   the	
   social	
   web.	
   

qiang	
   yang,	
   yuqiang	
   chen,	
   gui-     rong	
   xue,	
   wenyuan	
   dai	
   

and	
   yong	
   yu.	
   	
   

	
   in	
   proceedings	
   of	
   the	
   47th	
   annual	
   mee2ng	
   of	
   the	
   acl	
   

and	
   the	
   4th	
   ijcnlp	
   of	
   the	
   afnlp	
   (acl-     ijcnlp'09),	
   

sinagpore,	
   aug	
   2009,	
   pages	
   1	
   -     -     	
   9.	
   

htl	
   seung:	
   text	
   to	
   images	
   

       source	
   data:	
   labeled	
   or	
   unlabeled	
   
       target	
   training	
   data:	
   labeled	
   
	
   

the apple is the pomaceous fruit
 of the apple tree, species malus
 domestica in the rose family
 rosaceae ... 

apple 

banana 

banana is the common name for a
 type of fruit and also the
 herbaceous plants of the genus
 musa which produce this commonly
 eaten fruit ... 

training:	
   text 

tes,ng:	
   images 

41	
   

y.	
   zhu,	
   g.	
   xue,	
   q.	
   yang	
   et	
   al.	
   	
   heterogeneous	
   transfer	
   learning	
   for	
   

image	
   classi   ca,on.	
   aaai	
   2011	
   

unlabeled	
   source	
   data	
   

42	
   

current	
   work	
   on	
   htl	
   -     	
   id91 
       core	
   idea:	
   	
   

      looking	
   for	
   a	
   latent	
   space	
   z	
   (cluster	
   center	
   space) 

tags 

image	
   space 

bag-     of-     features 

current	
   work	
   on	
   htl	
   -     	
   id91 

sources	
   used	
   for	
   

transferring 

auxiliary	
   co-     occurrence	
   data 

target	
   images 

grass 

football 

duck 

water	
    

swim 

exploit	
   tags	
   to	
   help	
   

target	
   images   	
   

id91 

current	
   work	
   on	
   htl	
   -     	
   classi   ca,on 

sources	
   used	
   for	
   

transferring 

document	
   1	
   

how	
    about	
    playing	
   
the	
   football	
   at	
   night? 

document	
   2	
   

the	
    duck	
    is	
    so	
    cute	
   
that	
   i	
   cannot	
   leave	
   it. 

document	
   3	
   
i	
    swim	
    in	
    the	
   
morning       

auxiliary	
   co-     occurrence	
   data 

target	
   images 

grass 

football 

duck 

water	
    

swim 

exploit	
   abundant	
   unlabeled	
   documents	
   to	
   

help	
   target	
   images   	
   classi   ca,on 

experiments:	
   #	
   text	
   docs	
   

accuracy	
   

#	
   text	
   docs	
   

46	
   

adding	
   documents	
   as	
   if	
   they	
   were	
   
images	
   (ying	
   wei	
   and	
   yangqiu	
   song) 
       supervised	
   alignment	
   and	
   classi   ca,on	
   

      obtain	
   the	
   latent	
   space	
   as	
   yin   s	
   work,	
   i.e.	
   cmf	
   
      project	
   both	
   source	
   and	
   target	
   data	
   into	
   the	
   
latent	
   space,	
   as	
   depicted	
   in	
      gure	
   (a)	
   
      align	
   and	
   classify	
   simultaneously,	
   obtain	
   the	
   
results	
   in	
      gure	
   (b)	
   

(a) 

(b) 

results 

       why	
   add	
   documents/

not	
   images?	
   
      abundant	
   documents	
   
but	
   comparably	
   less	
   
labeled	
   images	
   
      the	
   documents	
   added	
   
may	
   outperform	
   the	
   
same	
   number	
   of	
   
images	
   added	
   

results 

       comparison	
   of	
   algorithm	
   1/cmf/vicad	
   

      cmf	
   can	
   hardly	
   converge	
   azer	
   60	
   documents	
   
added	
   

 

conclusions	
   

       we	
   have	
   seen	
   three	
   applica,ons	
   of	
   transfer	
   

learning	
   
      cross-     domain	
   sensor-     based	
   ac,vity	
   recogni,on	
   
      social-     media	
   source	
   free	
   transfer	
   learning	
   
      heterogeneous	
   transfer	
   learning	
   

