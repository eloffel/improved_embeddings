id21 with 

applications 

sinno jialin pan  1, qiang yang2,3 and wei fan3 

 

1 institute for infocomm research, singapore  

2 hong kong university of science and technology 

3 huawei noah's ark research lab, hong kong 

outline 

    part i: an overview of id21     (sinno j. pan) 
 
    part ii: id21 applications (prof. qiang yang) 

 

    part iii: advanced research topics: heterogeneous transfer 

learning (wei fan) 

2 

id21 

overview 

sinno jialin pan (ph.d.) 

lab head, text analytics, 
data analytics department, 

institute for infocomm research (i2r), singapore 

transfer of learning 

a psychological point of view 

    the study of dependency of human conduct, 
learning or performance on prior experience. 
 

    [thorndike and woodworth, 1901] explored how individuals 

would transfer in one context to another context that share similar 
characteristics. 

 

    c++     java 
    maths/physics     computer science/economics 

2 

id21 
in the machine learning community 

    the ability of a system to recognize and apply 

knowledge and skills learned in previous 
domains/tasks to novel tasks/domains, which share 
some commonality. 
 

    given a target domain/task, how to identify the 

commonality between the domain/task and 
previous domains/tasks, and transfer knowledge 
from the previous domains/tasks to the target one? 

3 

id21 

traditional machine learning 
  

id21 

 
s
n
i
a
m
o
d
g
n
i
n
i
a
r
t

 

 
s
n
i
a
m
o
d
 
t
s
e
t

 
s
m
e
t
i
 
g
n
i
n
i
a
r
t

 
s
m
e
t
i
 
t
s
e
t

domain a 

domain b 

domain c 

4 

id21 

different fields 

    id21 for 

id23. 

 
     
 
 
 
     [taylor and stone, transfer 
learning for reinforcement 
learning domains: a survey, 
jmlr 2009] 

    id21 for 

classification, and 
regression problems. 
 

focus! 

 
 
     [pan and yang, a survey on 

id21, ieee tkde 
2010] 

5 

motivating example i:  

 indoor wifi localization 

-30dbm 

-70dbm 

-40dbm 

6 

indoor wifi localization (cont.) 

training 
s=(-37dbm, .., -77dbm), l=(1, 3) 
s=(-41dbm, .., -83dbm), l=(1, 4) 
    
s=(-49dbm, .., -34dbm), l=(9, 10) 
s=(-61dbm, .., -28dbm), l=(15,22) 

device a 

training 

localization 

model 

test 

s=(-37dbm, .., -77dbm) 
s=(-41dbm, .., -83dbm)  
    
s=(-49dbm, .., -34dbm)  
s=(-61dbm, .., -28dbm) 

device a 

test 

average error 

distance 

~ 1.5 meters 

drop! 

s=(-33dbm, .., -82dbm), l=(1, 3) 
    
s=(-57dbm, .., -63dbm), l=(10, 23) 

localization 

model 

s=(-37dbm, .., -77dbm) 
s=(-41dbm, .., -83dbm)  
    
s=(-49dbm, .., -34dbm)  
s=(-61dbm, .., -28dbm) 

~10 meters 

device b 

device a 

7 

difference between domains 

time period a 

time period b 

device a 

device b 

8 

motivating example ii: 

sentiment classification 

9 

sentiment classification (cont.) 

classification 

accuracy 

training 

test 

sentiment 
classifier 

sentiment 
classifier 

electronics 

test 

~ 84.6% 

drop! 

~72.65% 

electronics 

10 

electronics 

training 

dvd 

difference between domains 

electronics 

(1) compact; easy to operate; 
very good picture quality; 
looks sharp! 

(3) i purchased this unit from 
circuit city and i was very 
excited about the quality of the 
picture. it is really nice and 
sharp. 
(5) it is also quite blurry in 
very dark settings. i will never 
buy hp again. 

video games 

(2) a very good game! it is 
action packed and full of 
excitement. i am very much 
hooked on this game. 
(4) very realistic shooting 
action and good plots. we 
played this and were hooked. 

(6) the game is so boring. i 
am extremely unhappy and will 
probably never buy ubisoft 
again. 

11 

a major assumption in 

traditional machine learning 
   training and future (test) data come from 

the same domain, which implies 

 

    represented in the same feature spaces. 

 

    follow the same data distribution. 

 

12 

in real-world applications 

    training and testing data may come from 

different domains, which have: 
   different marginal distributions, or different 

feature spaces: 

 
   different predictive distributions, or different 

label spaces: 
 

13 

how to build systems on each 

domain of interest 
    build every system from scratch?  

    time consuming and expensive! 

 

    reuse common knowledge extracted from 

existing systems? 
    more practical! 

14 

the goal of id21 

labeled training 

source 

domain data 

electronics 

time period a 

device a 

id21 

algorithms 

predictive 
models 

target 

domain data 

unlabeled data/a few labeled 

data for adaptation 

target 

domain data 

testing 

time period b 

device b 

dvd 

15 

id21 settings 

heterogeneous 

id21 

heterogeneous 

transfer 
learning 

feature 
space 

homogeneous 

supervised transfer 

learning 

semi-supervised 
id21 

unsupervised transfer 

learning 

homogeneous 

id21 

16 

id21 approaches 

instance-based 
approaches 

feature-based 
approaches 

parameter-based 

approaches 

relational 
approaches 

17 

instance-based transfer 
learning approaches 

 

general assumption 

source and target domains 
have a lot of overlapping  
features (domains share  
the same/similar support) 

18 

instance-based transfer 
learning approaches 

case i 
problem setting 
  

case ii 
problem setting 
  

assumption 

assumption 

19 

instance-based approaches 

case i 

given a target task, 

20 

instance-based approaches 

case i (cont.) 

 

  

 
 
 
 
 

21 

instance-based approaches 

case i (cont.) 

assumption: 

 

 
 
 
 
 

22 

instance-based approaches 

case i (cont.) 

  

correcting sample selection bias / covariate shift  
[quionero-candela, etal, data shift in machine learning, mit press 2009] 

23 

instance-based approaches 

correcting sample selection bias 

    imagine a rejection sampling process, and 

view the source domain as samples from the 
target domain 

assumption: sample selection bias is caused by 
the data generation process 
24 

instance-based approaches 
correcting sample selection bias (cont.) 
    the distribution of the selector variable 

maps the target onto the source distribution  

[zadrozny, icml-04] 

    label instances from the source domain with label 1 
    label instances from the target domain with label 0 
    train a binary classifier 

25 

instance-based approaches 

kernel mean matching (kmm) 

maximum mean discrepancy (mmd) 
 
 
 
 
 
 
 
[alex smola, arthur gretton and kenji kukumizu, icml-08 tutorial] 

26 

instance-based approaches 
 kernel mean matching (kmm) (cont.) 

[huang etal., nips-06] 

27 

instance-based approaches 

direct density ratio estimation 
[sugiyama etal., nips-07, kanamori etal., jmlr-09] 

kl divergence loss 

least squared loss 

[sugiyama etal., nips-07] 

[kanamori etal., jmlr-09] 

28 

instance-based approaches 

case ii 

 
 

    intuition: part of the labeled data in the 

source domain can be reused in the target 
domain after re-weighting 
 

29 

instance-based approaches 

case ii (cont.) 

    tradaboost [dai etal icml-07] 

    for each boosting iteration, 

    use the same strategy as adaboost to 
update the weights of target domain data. 
    use a new mechanism to decrease the 
weights of misclassified source domain data. 

 

 

30 

feature-based transfer 
learning approaches 

 

when source and target  
domains only have some  
overlapping features. (lots  
of features only have  
support in either the source  
or the target domain) 

31 

feature-based transfer 

learning approaches (cont.) 
how to learn     ? 
   solution 1: encode application-specific 
knowledge to learn the transformation.  
 

   solution 2: general approaches to learning 

the transformation. 

32 

feature-based approaches 
 encode application-specific knowledge 

electronics 

(1) compact; easy to operate; 
very good picture quality; 
looks sharp! 

(3) i purchased this unit from 
circuit city and i was very 
excited about the quality of the 
picture. it is really nice and 
sharp. 
(5) it is also quite blurry in 
very dark settings. i will 
never_buy hp again. 

video games 

(2) a very good game! it is 
action packed and full of 
excitement. i am very much 
hooked on this game. 
(4) very realistic shooting 
action and good plots. we 
played this and were hooked. 

(6) the game is so boring. i 
am extremely unhappy and will 
probably never_buy ubisoft 
again. 

33 

feature-based approaches 

 encode application-specific knowledge (cont.) 

electronics 

compact  sharp  blurry  hooked  realistic  boring 

1 
0 
0 

1 
1 
0 

0 
0 
1 

0 
0 
0 

0 
0 
0 

0 
0 
0 

training 

y
   

=

f x
( )

=

sgn(

w x
   

t

),

w

=

[1,1, 1,0,0,0]

   

prediction 

video game 

compact  sharp  blurry  hooked  realistic  boring 

0 
0 
0 

0 
0 
0 

0 
0 
0 

1 
1 
0 

0 
1 
0 

0 
0 
1 

34 

feature-based approaches 

 encode application-specific knowledge (cont.) 

electronics 

(1) compact; easy to operate; 
very good picture quality; 
looks sharp! 

(3) i purchased this unit from 
circuit city and i was very 
excited about the quality of the 
picture. it is really nice and 
sharp. 
(5) it is also quite blurry in 
very dark settings. i will 
never_buy hp again. 

video games 

(2) a very good game! it is 
action packed and full of 
excitement. i am very much 
hooked on this game. 
(4) very realistic shooting 
action and good plots. we 
played this and were hooked. 

(6) the game is so boring. i 
am extremely unhappy and 
will probably never_buy 
ubisoft again. 

35 

feature-based approaches 

 encode application-specific knowledge (cont.) 
    three different types of features 

     source domain (electronics) specific features, e.g.,   
     compact, sharp, blurry  
     target domain (video game) specific features, e.g.,  
     hooked, realistic, boring 
     domain independent features (pivot features), e.g.,  
     good, excited, nice, never_buy  

36 

feature-based approaches 

 encode application-specific knowledge (cont.) 

    how to identify pivot features? 
    term frequency on both domains 
    mutual information between features and labels (source domain) 
    mutual information on between features and domains 

 

    how to utilize pivots to align features across domains? 

    structural correspondence learning (scl) [biltzer etal. 

emnlp-06] 

    spectral feature alignment (sfa) [pan etal. www-10] 

37 

feature-based approaches 
structural correspondence learning (scl)  

   intuition 

    use pivot features to construct pseudo tasks that 

related to target classification task 

    model correlations between pivot features and 

other features using id72 techniques 

    discover new shared features by exploiting the 

feature correlations 

38 

structural correspondence learning 

algorithm  

    identify p pivot features 
    build p classifiers to predict the pivot features 

from remaining features 

    discover shared feature subspace 

   compute top k eigenvectors 
   project original features into eigenvectors to 

derive new shared features 

    train classifiers on the source using augmented 

features (original features + new features) 

39 

feature-based approaches 

spectral feature alignment (sfa) 

   intuition 

    use a bipartite graph to model the correlations 

between pivot features and other features 

    discover new shared features by applying 
spectral id91 techniques on the graph 

40 

spectral feature alignment (sfa) 

high level idea 

domain-specific features 

pivot features 

exciting 

good 

6 

never_buy 

realistic 

compact 

hooked 

7 

6 
3 

8 

2 

sharp 

5 

4 

blurry 

boring 

electronics 

video game 

    if two domain-specific words have connections to more common pivot words in 
the graph, they tend to be aligned or clustered together with a higher id203. 
    if two pivot words have connections to more common domain-specific words in 
41 
the graph, they tend to be aligned together with a higher id203. 

derive new features 

domain-specific features 

pivot features 

exciting 

good 

6 

never_buy 

electronics 

realistic 

compact 

hooked 

7 

6 
3 

8 

2 

sharp 

5 

4 

blurry 

boring 

video game 

compact 

realistic 

electronics 

sharp 

hooked 

video game 

video game 

42 

electronics 

spectral id91 

boring 

blurry 

video game 

electronics 

spectral feature alignment (sfa) 

derive new features (cont.) 

sharp/hooked  compact/realistic 

blurry/boring 

electronics 

1 
1 
0 

1 
0 
0 
training 

0 
0 
1 

y
   

=

f x
( )

=

sgn(

w x
   

t

[1,1, 1]

   

=

w

),
prediction 

video game 

sharp/hooked 

1 
1 
0 

0 
1 
0 

compact/realistic  blurry/boring 

0 
0 
1 

43 

spectral feature alignment (sfa) 

algorithm 

    identify p pivot features 
    construct a bipartite graph between the pivot and 

remaining features. 

    apply spectral id91 on the graph to derive 

new features 

    train classifiers on the source using augmented 

features (original features + new features) 

44 

feature-based approaches 

develop general approaches 
time period b 
time period a 

device a 

device b 

45 

feature-based approaches 

general approaches 

   learning features by minimizing distance  

between distributions 

   learning features inspired by multi-task 

learning 

   learning features inspired by self-taught 

learning 

46 

feature-based approaches 

transfer component analysis [pan etal.,  ijcai-09, tnn-11] 
motivation 

source 

target 

latent factors 

temperature  

signal 
properties 

power of aps 

building 
structure   

47 

transfer component analysis (cont.) 

source 

target 

latent factors 

temperature   signal 

properties 

power of aps 

building 
structure   

cause the data distributions between domains different 

48 

transfer component analysis (cont.) 

source 

target 

noisy 
component 

signal 
properties 

principal components 

building 
structure   

49 

transfer component analysis (cont.) 

learning     by only minimizing distance between  
distributions may map the data onto noisy factors. 

50 

transfer component analysis (cont.) 

main idea: the learned     should map the source and  
target domain data to the latent space spanned by the  
factors which can reduce domain difference and  
preserve original data structure. 

high level optimization problem 

51 

transfer component analysis (cont.) 

  
recall: maximum mean discrepancy (mmd) 

52 

transfer component analysis (cont.) 

53 

transfer component analysis (cont.) 

    the id81 can be a highly nonlinear function of  
    a direct optimization of minimizing the quantity w.r.t.       can get 
stuck in poor local minima 

54 

transfer component analysis (cont.) 

[pan etal., aaai-08] 

to maximize the 
data variance 

to minimize the distance 
between domains 

to preserve the local 
geometric structure 

    it is a sdp problem, expensive! 
    it is transductive, cannot generalize on unseen instances! 
    pca is post-processed on the learned kernel matrix, which may 

potentially discard useful information. 

55 

transfer component analysis (cont.) 

parametric kernel 

id173 term 

minimize distance 
between domains 

maximize data variance 

56 

transfer component analysis (cont.) 

an illustrative example 

latent features learned by pca and tca 

original feature space 

pca 

tca 

57 

feature-based approaches 

multi-task id171 

general id72 setting 

    assumption: if tasks are related, they should 

share some good common features. 

    goal: learn a low-dimensional representation 

shared across related tasks. 

58 

feature-based approaches 
multi-task id171 (cont.) 

  

[argyriou etal., nips-07] 

[ando and zhang, jmlr-05] 
[ji etal, kdd-08] 

59 

feature-based approaches 

self-taught id171 

    intuition: there exist some higher-level features  that 
can help the target learning task even only a few labeled 
data are given. 

    steps: 
1) learn higher-level features from a lot of  unlabeled  data. 
2) use the learned higher-level features to represent the data 

of the target task. 

3) training models from the new representations of the 

target task with corresponding labels. 

60 

feature-based approaches 

self-taught id171 
    how to learn higher-level features 

    sparse coding [raina etal., 2007] 
    deep learning [glorot etal., 2011] 

 

61 

parameter-based transfer 

learning approaches 

tasks are learned 
independently 

 
 
 
 
 

motivation: a well-trained model      has learned a 
lot of structure. if two tasks are related, this 
structure can be transferred to learn      . 

62 

parameter-based approaches 

multi-task parameter learning 

common part 

assumption: 
if tasks are related, they may share similar parameter vectors. 
for example, [evgeniou and pontil, kdd-04] 
 
 
 
 
 

specific part for individual task 

63 

parameter-based approaches 

multi-task parameter learning (cont.) 

a general framework: 
 

[zhang and yeung, uai-10] 

[agarwal etal, nips-10] 

64 

relational id21 

approaches 

   motivation: if two relational domains (data 

is non-i.i.d) are related, they may share 
some similar relations among objects. these 
relations can be used for knowledge transfer 
across domains. 

65 

relational id21 

approaches (cont.) 

[mihalkova etal., aaai-07, davis and domingos, icml-09] 
movie domain (target) 

academic domain (source) 

student (b) 

advisedby 

professor (a) 

workedfor 

actor(a) 

director(b) 

publication 

publication 

moviemember  moviemember 

paper (t) 

movie (m) 

advisedby (b, a)    publication (b, t)  
=> publication (a, t)  

workedfor (a, b)    moviemember (a, m)  
=> moviemember (b, m)  

p1(x, y)    p2 (x, z)  => p2 (y, z)  

66 

relational approaches 

relational adaptive id64 [li etal., acl-12]  

task: sentiment summarization 
    what is the opinion expressed on? 

    to construct lexicon of topic or target words 

    how is the opinion expressed? 

    to construct lexicon of sentiment words 

 
sentiment lexicon (camera) 
great, amazing, light 
recommend, excellent, etc. 
artifacts, noise, never but, 
boring, etc. 

 
topic lexicon (camera) 
camera, product, screen, 
photo, size, weight, quality, 
price, memory, etc. 

67 

relational approaches 

 relational adaptive id64 (rap) (cont.) 

reviews on cameras 
 
the camera is great. 
it is a very amazing product. 
i highly recommend this camera. 
photos had some artifacts and noise. 

reviews on movies 
 
this movie has good script, great casting, excellent acting. 
this movie is so boring. 
the godfather was the most amazing movie. 
the movie is excellent. 

68 

relational approaches 

rap (cont.) 

   bridge between cross-domain sentiment words 

    domain independent (general) sentiment words 

 

    bridge between cross-domain topic words 

69 

relational approaches 

rap (cont.) 

   bridge between cross-domain topic words 

    syntactic structure between topic and sentiment 

words 

sentiment words 

topic word 

topic word 

common syntactic pattern:    topic word        nsubj        sentiment word    

70 

transfer 
learning 

summary 

heterogeneous 

id21 

supervised transfer 

learning 

semi-supervised 
id21 

unsupervised 

id21 

homogeneous 

id21 

in data level 

instance-based 
approaches 

feature-based 
approaches 

relational 
approaches 

parameter-based 

approaches 

in model level 

71 

some advanced research 
issues in id21 
    how to transfer knowledge across heterogeneous 

feature spaces 
 

    active learning meets id21 

 

    id21 from multiple sources 

72 

reference 

    [thorndike and woodworth, the influence of improvement in one 

mental function upon the efficiency of the other functions, 1901] 
    [taylor and stone, id21 for id23 

domains: a survey, jmlr 2009] 

    [pan and yang, a survey on id21, ieee tkde 2009] 
    [quionero-candela, etal, data shift in machine learning, mit press 

2009] 

    [biltzer etal.. id20 with structural correspondence 

learning, emnlp 2006] 

    [pan etal., cross-domain sentiment classification via spectral feature 

alignment, www 2010] 

    [pan etal., id21 via id84, aaai 

2008] 

73 

reference (cont.) 

    [pan etal., id20 via transfer component analysis, 

ijcai 2009] 

    [evgeniou and pontil, regularized id72, kdd 2004] 
    [zhang and yeung, a convex formulation for learning task 

relationships in id72, uai 2010] 

    [agarwal etal, learning multiple tasks using manifold id173, 

nips 2010]  

    [argyriou etal., multi-task id171, nips 2007] 
    [ando and zhang, a framework for learning predictive structures 

from multiple tasks and unlabeled data, jmlr 2005] 

    [ji etal, extracting shared subspace for multi-label classification, 

kdd 2008] 
 

74 

reference (cont.) 

    [raina etal., self-taught learning: id21 from unlabeled 

data, icml 2007] 

    [dai etal., boosting for id21, icml 2007] 
    [glorot etal., id20 for large-scale sentiment 

classification: a deep learning approach, icml 2011] 

    [davis and domingos, deep transfer vis second-order markov logic, 

icml 2009] 

    [mihalkova etal., mapping and revising markov logic networks for 

id21, aaai 2007] 

    [li etal., cross-domain co-extraction of sentiment and topic 

lexicons, acl 2012] 
 
 

75 

reference (cont.) 

    [sugiyama etal., direct importance estimation with model selection 

and its application to covariate shift adaptation, nips 2007] 

    [kanamori etal., a least-squares approach to direct importance 

estimation, jmlr 2009] 

    [cristianini etal., on kernel target alignment, nips 2002] 
    [huang etal., correcting sample selection bias by unlabeled data, 

nips 2006] 

    [zadrozny, learning and evaluating classifiers under sample 

selection bias, icml 2004] 
 
 

76 

thank you 

77 

selected applications of transfer 

learning 

qiang yang and sinno j. pan 

2013 pakdd tutorial 
brisbane, australia 

part i. cross domain id21 

for activity recognition 

    vincent w. zheng, derek h. hu and qiang yang. cross-domain activity 

recognition. in proceedings of the 11th international conference on 
ubiquitous computing (ubicomp-09), orlando, florida, usa, sept.30-
oct.3, 2009. 

    derek hao hu, qiang yang. id21 for activity recognition via 

sensor mapping. in proceedings of the 22nd international joint conference 
on artificial intelligence (ijcai-11), barcelona, spain, july 2011 

demo 

    annotation 

3 

ehealth demo 

sensor data 

4 
4 

ehealth demo 

activity annotation 

5 
5 

ehealth demo 

auto logging / activity recognition 

(service in background) 

6 
6 

demo 

    recognition 

 

7 

ehealth demo 

real-time activity recognition 

8 
8 

demo 

    profiling 

9 

ehealth demo 

activity profiling 

10 
10 

ehealth demo 

activity profiling for health management 

11 
11 

key problem: recognizing actions and 

context (locations) 

inferred through ar 

ar: activity recognition via sensors 

walking? 

buying ticket? 

open door? 

sightseeing 

gps and other 

sensors 

sensors 

sensors 

watch show 

12 

1. cross-domain activity recognition 
 [zheng, hu, yang: ubicomp-2009, pcm-2011] 

    challenge: 

    some activities without data (partially labeled) 

    cross-domain activity recognition 

    use other activities with available labeled data 

 

    happen in kitchen 
    use cup, pot 
        

making coffee 

making tea 

13 

cleaning 
indoor 

laundry 

dishwashing 

14 

system workflow  

<sensor reading, 
activity name> 

example: <ss,    make 

coffee   > 

source domain 
labeled data 

example: 

sim(   make coffee   , 
   make tea   ) = 0.6 

similarity 
measure 

the web 

example: pseudo 
training data: <ss, 
   make tea   , 0.6> 

target domain 
pseudo labeled 

data 

weighted id166 

classifier 

15 
15 

calculating activity similarities 

    how similar are two 

activities? 
    use web search 

results 

    tfidf: traditional ir 

similarity metrics 
(cosine similarity) 

    example 

    mined similarity between 

the activity    sweeping    
and    vacuuming   ,    making 
the bed   ,    gardening    

calculated similarity 

with the activity 

"sweeping"

16 16 

datasets: mit placelab 

http://architecture.mit.edu/house_n/placelab.html  

    mit placelab dataset (plia2) [intille et al. 

pervasive 2005] 

    activities: common household activities 

17 
17 

datasets: intel research lab 

    intel research lab 

[patterson, fox, 
kautz, philipose, 
iswc2005] 
    activities performed: 

11 activities 

    sensors 

    rfid readers & tags 

    length: 

    10 mornings 

picture excerpted from [patterson, fox, 
kautz, philipose, iswc2005]. 

18 
18 

cross-domain ar: performance 

accuracy 
with cross 
domain 
transfer 

63.2% 

65.8% 

58.9% 

53.2% 

intel 
research 
lab dataset 
amsterdam 
dataset 
mit dataset 
(cleaning to 
laundry) 
mit dataset 
(cleaning to 
dishwashing) 

# activities 
(source 
domain) 

# activities 
(target 
domain) 

baseline 
(random 
guess) 

supervised 
(upper 
bound) 

5 

4 

13 

13 

6 

3 

8 

7 

16.7% 

78.3% 

33.3% 

72.3% 

12.5% 

14.3% 

- 

- 

    activities in the source domain and the target domain are generated 

from ten random trials, mean accuracies are reported. 

19 19 

derek hao hu and qiang yang, ijcai 

2011 

transferring 

across 
feature 
space 

transferring 

across 

label space 

transfer from 

source domain to 

target domain 
x
|
t

   

=

)

 
 
i
( )
c
 

l
   

s

p y
(
t

p c x
( |
t

)

   

p y c
(
| )

t

proposed approach 

p y x
|t
(
)
    final goal: estimate  

t

    we have 

 

    estimating the above equation at its mode: 

 
feature transfer 

label transfer 

experiments 

    datasets 

    uva dataset [van kasteren et al. ubicomp 2008] 
    mit placelab (plia1) dataset [intille et al. ubicomp 2006] 
    intel research lab dataset [patterson et al. iswc 2005] 

    baseline 

    unsupervised activity recognition algorithm [wyatt et al. 2005] 

    different sensors for different datasets 

 

state-based sensors 

for uva dataset 

a series of different wired 
sensors for mit dataset 

rfid sensor for intel 

research lab 

dataset 

experiments: 

different feature & label spaces 

    source: mit 

plia1 dataset 
target: uva 
(intel) datasets 

part ii 

    source free id21 
    evan wei xiang, sinno jialin pan, weike pan, jian su and qiang 
yang. source-selection-free id21. in proceedings 
of the 22nd international joint conference on artificial 
intelligence (ijcai-11), barcelona, spain, july 2011. 

source-selection-free  

id21 

evan xiang, sinno pan, weike pan, 

jian su, qiang yang 

hkust - ijcai 2011 

25 

id21 

supervised  
learning 

lack of labeled 
training data 
always happens 

transfer  
learning 

when we have 
some related 
source domains 

hkust - ijcai 2011 

26 

where are the    right    source data? 

we may have an extremely large number of 

choices of potential sources to use. 

hkust - ijcai 2011 

27 

outline of source-selection-free 

id21 (ssftl) 

    stage 1: building base models 

 

 

    stage 2: label bridging via laplacian graph embedding 

    stage 3: mapping the target instance using the base 

classifiers & the projection matrix  
 

    stage 4: learning a matrix w to directly project the 

target instance to the latent space  
 

    stage 5: making predictions for the incoming test data 

using w 

hkust - ijcai 2011 

28 

ssftl     building base models 

vs. 

vs. 

vs. 

vs. 

vs. 

vs. 

vs. 

vs. 

vs. 

vs. 

vs. 

from the taxonomy of the online information source, we can 

   compile    a lot of base classification models 

hkust - ijcai 2011 

29 

ssftl     label bridging via laplacian 

graph embedding 

problem 

however, the label spaces 
of the based classification 

models and the target 
task can be different 

 

h
c
t
a
m

 
 
 
 
 
 
vs. 
 
 
 
 
 
 
 
 
 
 
 
 

m

s
i

vs. 

vs. 

vs. 

vs. 

vs. 

since the label names 
are usually short and 
sparse, , in order to 
uncover the intrinsic 
relationships between 
the target and source 

labels, we turn to 
some social media 
such as delicious, 
which can help to 

bridge different label 

sets together. 

neighborhood matrix 

for label graph 

q 

m 

q 

bob 

tom 

john 

gary 

steve 

history 

travel 

finance 

tech 

sports 

laplacian eigenmap 
[belkin & niyogi,2003] 

m-dimensional 
latent space 

projection matrix 

q 

v 

m 

the relationships between labels, e.g., similar or dissimilar, can be 

represented by the distance between their corresponding prototypes in 

the latent space, e.g., close to or far away from each other. 

hkust - ijcai 2011 

30 

ssftl     mapping the target instance using 
the base classifiers & the projection matrix v 
vs. 

target instance 

0.1:0.9 

   ipad2 is 
released in 
march,        

for each target instance, we can 

obtain a combined result on the label 
space via aggregating the predictions 

from all the base classifiers 

vs. 

vs. 

0.3:0.7 

0.2:0.8 

vs. 

vs. 

0.6:0.4 

0.7:0.3 

then we can use the projection matrix v 
to transform such combined results from 

the label space to a latent space 

 
y
t
i
l
i

b
a
b
o
r
p

tech 

finance 

travel 

sports 

history 

label space 

q 

projection matrix 

q 

v 

m 

= <z1, z2, z3,    , zm> 

m-dimensional 
latent space 

however, do we need to recall the base classifiers during the prediction phase?  

the answer is no! 

hkust - ijcai 2011 

31 

ssftl     learning a matrix w to directly 

project the target instance to the latent space  

target domain 

 
 
 
 
data 
 

labeled & 
unlabeled 

vs. 

vs. 

vs. 

vs. 

vs. 

projection matrix 

q 

v 

m 

for each target instance, we first aggregate 
its prediction on the base label space, and 

then project it onto the latent space 

loss on unlabeled data 

loss on labeled data 

our regression model 

learned projection matrix 

d 

w 

m 

32 

hkust - ijcai 2011 

ssftl     making predictions for the  

incoming test data 

target domain 

 
 
 
 
 

incoming 
test data 

vs. 

vs. 

vs. 

vs. 

vs. 

learned projection matrix 

d 

w 

m 

projection matrix 

q 

v 

m 

the learned projection matrix w can be used 

to transform any target instance directly 
from the feature space to the latent space 

therefore, we can make 
prediction directly for any 

incoming test data based on the 
distance to the label prototypes, 

without calling the base 

classification models 

hkust - ijcai 2011 

33 

experiments - datasets 
   building source classifiers with wikipedia 

   3m articles, 500k categories (mirror of aug 2009) 
   50, 000 pairs of categories are sampled for source models 

   building label graph with delicious 

   800-day historical tagging log (jan 2005 ~ march 2007) 
   50m tagging logs of 200k tags on 5m web pages 

   benchmark target tasks 
   20 newsgroups (190 tasks) 
   google snippets (28 tasks) 
   aol web queries (126 tasks) 
   ag reuters corpus (10 tasks) 

hkust - ijcai 2011 

34 

ssftl - building base classifiers 

parallelly using mapreduce 

input 

map 

reduce 

1 

2 

1 

3      

    

3      

    

2      

    

the training data are replicated 
and assigned to different bins 

1 

2 

3 

vs. 

vs. 

vs. 

vs. 

in each bin, the training data 
are paired for building binary 

base classifiers 

these pre-trained source base classifiers are stored 

and reused for different incoming target tasks. 

hkust - ijcai 2011 

35 

if we need to build 50,000 
base classifiers, it would take 
about two days if we run the 
training process on a single 
server.  
therefore, we distributed the 
training process to a cluster 
with 30 cores using 
mapreduce, and finished the 
training within two hours.  

experiments - results 

unsupervised ssftl 

semi-supervised ssftl 

our regression model 

-parameter setttings- 
source models: 5,000 
unlabeled target data: 100% 
lambda_2: 0.01 

hkust - ijcai 2011 

36 

experiments - results 

for each target instance, we first aggregate 
its prediction on the base label space, and 

then project it onto the latent space 

loss on unlabeled data 

our regression model 

-parameter setttings- 
mode: semi-supervised 
labeled target data: 20 
unlabeled target data: 100% 
lambda_2: 0.01 

hkust - ijcai 2011 

37 

experiments - results 

our regression model 

-parameter setttings- 
mode: semi-supervised 
labeled target data: 20 
source models: 5,000 
lambda_2: 0.01 

hkust - ijcai 2011 

38 

experiments - results 

supervised ssftl 

semi-supervised ssftl 

our regression model 

-parameter setttings- 
labeled target data: 20 
unlabeled target data: 100% 
source models: 5,000 

hkust - ijcai 2011 

39 

experiments - results 

for each target instance, we first aggregate 
its prediction on the base label space, and 

then project it onto the latent space 

loss on unlabeled data 

our regression model 

-parameter setttings- 
mode: semi-supervised 
labeled target data: 20 
source models: 5,000 
unlabeled target data: 100% 
lambda_2: 0.01 

hkust - ijcai 2011 

40 

related works 

hkust - ijcai 2011 

41 

conclusion 

   source-selection-free id21 

   when the potential auxiliary data is embedded in very 

large online information sources 
 

   no need for task-specific source-domain data 
   we compile the label sets into a graph laplacian for 

automatic label bridging 
 

   ssftl is highly scalable 

   processing of the online information source can be done 

offline and reused for different tasks. 

hkust - ijcai 2011 

42 

q & a 

hkust - ijcai 2011 

43 

advance research topics 

in id21 

wei fan 

 

huawei noah's ark research lab, hong kong 

predictive modeling  

with heterogeneous sources 

 

xiaoxiao shi   qi liu  wei fan       

qiang yang   philip s. yu 

 
 
 

why learning  

with heterogeneous sources? 
standard supervised learning 
test 

(unlabeled) 

training 
(labeled) 

 classifier 

85.5% 

new york times 

new york times 

1/18 

why heterogeneous sources? 

in reality    

training 
(labeled) 

how to improve  
the performance? 

test 

(unlabeled) 

labeled data are 
new york times 

insufficient! 

47.3% 

new york times 

2/18 

why heterogeneous sources? 

labeled data from 

other sources 

reuters 

target domain 
test (unlabeled) 

82.6% 
47.3% 

new york times 

1. different distributions 
2. different outputs 
3. different feature spaces 

3/18 

real world examples 

    social network: 

    can various bookmarking systems help predict social tags for a 

new system given that their outputs (social tags) and data 
(documents) are different? 

wikipedia 

odp 

backflip 

blink 

? 

       

4/18 

real world examples 

    applied sociology: 

    can the suburban housing price census data help predict the 

downtown housing prices?  

? 

#rooms  #bathrooms  #windows price 
  5               2                  12         xxx 
  6               3                   11        xxx               

#rooms  #bathrooms  #windows price 
  2               1                  4           xxxxx 
  4               2                  5           xxxxx          

5/18 

other examples 

    bioinformatics 

    previous years    flu data     new swine flu 
    drug efficacy data against breast cancer     

drug data against lung cancer 

           

    intrusion detection 

types of intrusions  

    id31 

    existing types of intrusions     unknown 

    review from sdm    review from kdd 
 

6/18 

 

learning with  

heterogeneous sources 
    the paper mainly attacks two sub-

problems: 
    heterogeneous data distributions 

    id91 based kl divergence and a 

corresponding sampling technique 

    heterogeneous outputs (to regression 

problem) 
    unifying outputs via preserving similarity. 

7/18 

learning with  

heterogeneous sources 

    general framework 

source data 

target data 

unifying  

data distributions 

unifying outputs 

source data 

target data 

8/18 

unifying data distributions 

    basic idea:  

    combine the source and target data and 

perform id91. 

    select the clusters in which the target and 

source data are similarly distributed, 
evaluated by kl divergence. 

9/18 

an example 
t 

d 

adaptive 
id91 

combined data 

10/18 

unifying outputs 

    basic idea: 

    generate initial outputs according to the 

regression model 

    for the instances similar in the original output 

space, make their new outputs closer. 

11/18 

i

n
i
t
i
a

l
 

o
u
t
p
u
t
s

 

i

n
i
t
i
a

l
 

o
u
t
p
u
t
s

 

16 

21.25 

26.5 

31.75 

37 

12/18 

experiment 

    bioinformatics data set: 

13/18 

experiment 

14/18 

experiment 

    applied sociology data set: 

15/18 

experiment 

16/18 

conclusions 

    problem: learning with heterogeneous 

sources: 
    heterogeneous data distributions 
    heterogeneous outputs 

    solution: 

    id91 based kl divergence help perform 

    similarity preserving output generation help 

sampling 

unify outputs 

17/18 

id21 on heterogeneous 
feature spaces via spectral transformatio

xiaoxiao shi, qi liu, wei fan, 
philip s. yu, and ruixin zhu 

motivation 

standard supervised learning 

training documents 

(labeled) 

classifier 

test documents 

(unlabeled) 

85.5% 

1/18 

motivation 

in reality    

training 
(labeled) 

how to improve  
the performance? 

huge set of unlabeled 

documents 

labeled data are 

insufficient! 

47.3% 

learning formulations 

learning from heterogeneous sources 

labeled data from 

other sources 

target domain 
test (unlabeled) 

??? 

heterogeneous datasets: 

1.different data distributions: p(xtrain) and p(xtest) are different 

2.different outputs: ytrain and ytest are different 

3.different feature spaces: xtrain and xtest are different 

3/18 

some applications of id21 

    wifi-based localization tracking [pan et 

al'08] 

    id185 [pan et al'10] 
    activity recognition [zheng et al'09] 
    text classification [dai et al'07] 
    sentiment classification [blitzer et al   07] 
    image categorization [shi et al   10] 
            

issues 

     different data distributions: p(xtrain) and p(xtest) 

are different 

 

 

focuses more on chicago local news  

focuses more on global news  

focuses more on scientific/objective documents 

issues 

   

 different outputs: ytrain and ytest are 
different 
 wikipedia 

odp 

yahoo! 

issues 

     different feature spaces (the focus on the 

paper) 
     drug efficacy tests: 
     physical properties 
     topological properties 

 

 

 
 
 

     image classification 

     wavelet features 
     color histogram 

unify different feature spaces 

    different number of features; different meanings 

of the features, no common feature, no 
overlap. 

    projection-based approach hemap 

    find a projected space where (1) the source and 

target data are similar in distribution; (2) the original 
structure (separation) of each of the dataset is 
preserved. 

 
 

unify different feature spaces  

via hemap 

optimization objective of hemap: 

the linear projection 

the linear projection 

the difference between 

error 

error 

the projected data 

unify different feature spaces  

via hemap 

with some derivations, the objective can be reformulated as 

(more details can be found in the paper): 

algorithm flow of hemap 

generalized hemap to handle heterogeneous data 
(different distributions, outputs and feature spaces) 

unify different distributions and outputs 

    unify different distributions 

    id91 based sample selection [shi etc 

al,09] 

    unify different outputs 
    bayesian like schema 

 

generalization bound 

and  are 

domain-specific 
parameters;  
is model 

complexity 

principle i: minimize the 
difference between target 

and source datasets 

principle ii: minimize the combined 

expected error by maintaining the original 

structure (minimize projection error) 

experiments 

    drug efficacy prediction 

    the dataset is collected by the college of life 

science and biotechnology of tongji 
university, china. it is to predict the efficacy of 
drug compounds against certain cell lines. 

    the data are generated in two different 

feature spaces 
    general descriptors: refer to physical properties of 

    drug-like index: refer to simple topological indices 

compounds 

of compounds. 

experiments 

experiments 

    image classification 

c
a
r
t

 

m
a
n
&
b
o
n
s
a

 

i
 

c
o
n

i

 

i

h
o
m
e
r
 
s
m
p
s
o
n
&

 

 

 

c
a
c
t
u
s
 

i

h
o
m
e
r
 
s
m
p
s
o
n
&

 

 

s
u
p
e
r
m
a
n
&
c
d

 

 

 

experiments 

conclusions 

    extends the applicability of supervised 
learning, semi-supervised learning and 
id21 by using heterogeneous 
data: 
    different data distributions 
    different outputs 
    different feature spaces 
    unify different feature spaces via linear 
projection with two principles 
    maintain the original structure of the data 
    maximize the similarity of the two data in the 
 

projected space 

 

cross validation framework to choose amongst 

models and datasets for id21 

erheng zhong  , wei fan   , qiang yang  ,  

olivier verscheure   , jiangtao ren    

 

id21: what is it     
definition 

   source-domains    to improve    target-domain   : short of 

labeled information. 

    supervised 
    unsupervised 

    semi-supervised 
    id21 

applications 

1. wifi-based localization tracking [pan et al'08] 

2. id185 [pan et al'10] 
3. activity recognition [zheng et al'09] 

4. text classification [dai et al'07] 

5. sentiment classification [blitzer et al   07] 

6. image categorization [shi et al   10] 

....... 

application     

indoor wifi localization tracking 

transfer 

ap is the access point of device. 

(lx, ly) is the coordinate of location. 

application     

id185 

id21: how it works data selection 

model selection 

re-cast:   model and data selection 

(1) how to select the right id21 algorithms?  

(2) how to tune the optimal parameters?  

(3) how to choose the most helpful source-domain from a 

large pool of datasets? 

 

 

model & data selection  traditional methods 

1. analytical techniques: aic, bic, srm, etc. 

 
 
 
 
 

2. k-fold cross validation 

model & data selection    issuses 

xp
)(
s

   

xp
)(
t

ideal 

hypothesis  

the estimation is not consistent. 

xyp
s

(

|

)

   

xyp
t

(

|

)

a model approximating            is not necessarily close to  
(

xyps
|

xypt
|

(

)

)
 

the number of labeled data in target domain is limited and 

thus the directly estimation of            is not reliable. 

xypt
|

)

(

model & data selection model selection example 

source 

target 

if we choose the wrong model.... 

model & data selection data selection example 

target 

if we choose the wrong source-domain.... 

transfer cross-validation (trcv) 

new criterion for id21 

hard to 
calculate 
in practice 

1. the density ration between two domains 
data?  
reverse validation  

limited labeled 

2. the difference between the conditional distribution 

 

estimated by model     and the true conditional distribution. 

how to calculate 
this difference with 

practical method: transfer cross-validation (trcv) 

density ratio weighting  

density ratio weighting 
    the selected model is an unbiased estimator to the ideal 

model  

is the expected loss to approximate 

is the model complexity 

important property to choose the right model even when p(x) and p(y|x) are 

different 

    we adopt an existing method kmm (huang et al   07) for 

density ratio weighting 

    reverse validation to estimate pt(y|x)     p(y|x,f) (next slide) 

  

reverse validation 

the source-domain data in i-th fold 
the remaining data  
the predicted label of        in i-th fold  
the predicted label of        in i-th fold  
the true label of        in i-th fold  

the unlabeled and labeled target-domain data  

properties 

    the selected model  is  an unbiased estimator to the 

ideal one. [lemma 1] 

    the model selected by the proposed method has a 
generalization bound over target-domain data. [theorem 1] 
    the value of reverse validation        is related to the 
difference between true id155 and 

model approximation. 

    the confidence of trcv has a bound.  

the accuracy estimated by trcv 
the true accuracy of  
                   quantile point of the standard normal distribution 

experiment    data set 

    wine quality: two subsets related to red and white 
variants of the portuguese    vinho verde    wine. 

 

 
 
 
 

for algorithm and parameters selection  

experiment    data set 

    reuters-21578:the primary benchmark of text 

categorization formed by different news with a hierarchial 
structure. 
 

for algorithm and parameters selection  

experiment    data set 

    syskillwebert: the standard dataset used to test web 
page ratings, generated by the html source of web 
pages plus the user rating. we randomly reserve 
   bands-recording artists    as source-domain and the 
three others as target-domain data. 

 

for algorithm and parameters selection  

experiment    data set 

    20-newsgroup: primary benchmark of text categorization 

similar to reuters-21578 

for source-domain selection 

experiment    baseline methods 

    scv: standard k-fold cv on source-domain 
    tcv: standard k-fold cv on labeled data from target-

domain 

    stv: building a model on the source-domain data and 

validating it on labeled target-domain data 

    wcv: using density ratio weighting to reduce the 

difference of marginal distribution between two domains, 
but ignoring the difference in id155. 

experiment    other settings 

    algorithms: 

    naive bayes(nb), id166, c4.5, id92 and nnge(ng) 
    tradaboost(ta): instances weighting [dai et al.'07] 
    latentmap(lm): feature transform [xie et al.'09] 
    lwe : model weighting ensemble [gao et al.'08] 

    evaluation:  if one criterion can select the better model in 

the comparison, it gains a higher measure value. 

the accuracy and value of criteria (e.g trcv, scv, etc) 

the number of comparisions between models 

results   algorithm selection 

6 win and 2 lose! 

results   parameter tuning 

13 win and 3 lose! 

results   source-domain selection 

no lose! 

results   parameter analysis 

trcv achieves the highest correlation value under different  

number of folds from 5 to 30 with step size 5 . 

results   parameter analysis 

when only a few labeled data(< 0.4    |t|) can be obtained  
in the target-domain, the performance of trcv is much better 

than both svt and tcv. 

conclusion 

    model and data selection when margin and conditional 

distributions are different between two domains. 

    key points 

    point-1 density weighting to reduce the difference 

between marginal distributions of two domains; 

    point-2 reverse validation to measure how well a 

model approximates the true conditional distribution 
of target-domain. 

    code and data available from the authors 

    www.weifan.info 

thanks! 

18/18 

