   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

geoffrey hinton   s id22: a novel approach to deep learning

   [9]go to the profile of alibaba cloud
   [10]alibaba cloud (button) blockedunblock (button) followfollowing
   jan 23, 2018
   [1*3v-yynsnvgwlas00rs9mlg.png]

   in 2012, geoffrey hinton changed the way machines    see    the world.
   along with two of his students, alex krizhevsky and ilya sutskever, dr.
   hinton published a paper titled id163 classification with deep
   convolutional neural networks. in the paper, he proposed a deep
   convolution neural network model named alexnet, which won first prize
   in a large-scale image recognition competition in that year. alexnet
   reduced the errors of rank-1 and rank-5 to 37.5% and 17.0%
   respectively, a significant improvement in terms of image recognition
   accuracy. with this success, hinton joined google brain, and alexnet
   became one of the most classic image recognition models widely used in
   the industry.

solving issues from tradition convolutional neural networks (id98) using
capsule network

   in 2017, together with his two colleagues at google brain, sara sabour
   and nicholas frosst, hinton published the paper dynamic routing between
   capsules. the team proposed a new neural network model called the
   capsule network, which has better results for specific task than the
   traditional convolutional neural network (id98). unlike id98, the capsule
   network helps machines understand images by giving them a new
   perspective, similar to the three-dimensional perspective that humans
   have.

   although there is much room for improvement, the capsule network has
   reached the highest accuracy in mnist, [11]analysis as analyzed by
   aur  lien g  ron, the author of the hands-on machine learning with
   scikit-learn and tensorflow. its performance on the cifar10 dataset can
   be further enhanced, which is reassuring for the development of capsule
   network.

   the capsule network also requires less training data. it delivers
   equivariant mapping, allowing for the preservation of position and pose
   information. this is promising for image segmentation and object
   detection. in addition, routing by agreement is great for overlapping
   objects. capsule activations nicely map the hierarchy of parts,
   assigning each part to a whole. it offers robustness to rotation,
   translation and other affine transformations. activation vectors are
   easier to interpret. finally, as the idea of master hinton,    it is
   undoubtedly forward-looking.   

   the new york times published an article recently about a visit to
   hinton   s laboratory in toronto, interviewing hinton and sara sabour,
   author of dynamic routing between capsules, who described her ambitious
   vision of the capsule network.
   [0*fn04m_61qjc5j6yk.jpeg]

   can you combine the two models in the picture into a pyramid? this
   seemingly simple task is beyond the capabilities of most computers, and
   even humans. image source: new york times

   if a traditional neural network is trained on images that show a coffee
   cup only from the side, for example, it is unlikely to recognize a
   coffee cup turned upside down. this is the limitation of traditional
   id98s. however, hinton wants to use the capsule network to realize human
   3d vision.

   in the report, the reporter described a two-piece pyramid puzzle held
   by hinton and sabour, as shown in the above picture. the two gypsum
   models can actually be put together to form a tetrahedral pyramid.
   conceptually, it doesn   t seem too hard, but most people actually fail
   this test, including the reporter and two tenured professors at the
   massachusetts institute of technology. one declined to try, and the
   other insisted it wasn   t possible.

   mr. hinton explained,    we picture the whole thing sitting in
   three-dimensional space. and because of the way the puzzle cuts the
   pyramid in two, it prevents us from picturing it in 3-d space as we
   normally would.   

   with his id22, mr. hinton aims to finally give machines the
   same three-dimensional perspective that humans have         allowing them to
   recognize a coffee cup from any angle after learning what it looks like
   from only one.

utilizing soft id90 for better classification

   while overcoming the shortcomings of traditional neural networks,
   hinton has also been devoted to understanding deep neural networks.

   recently, the 16th international conference of the italian association
   for artificial intelligence (aiia) was held. the comprehensibility and
   explanation in ai and ml, cex workshop was also held concurrently with
   the aiia 2017. as its name implies, the cex workshop addresses
   fundamental questions for the nature of    comprehensibility    and
      explanation    in an ai and ml context from a theoretical and an applied
   perspective. research into philosophical approximations to what an
   explanation in ai and ml is (or can be) or how the comprehensibility of
   an intelligent system can formally be defined will be presented. next
   to work addressing practical questions of how to assess a systems
   comprehensibility from a psychological perspective, or how to design
   and build better explainable ai and ml systems.
   [0*cch544ytxaph8cz0.jpeg]

   at the workshop, hinton and his colleague nicholas frosst at google
   brain co-authored and submitted a paper entitled    distilling a neural
   network into a soft decision tree   .
   [0*axvsljdbptbdtw97.jpeg]

   summary of the paper

   deep neural networks have proved to be a very effective way to perform
   classification tasks. they excel when the input data is high
   dimensional, the relationship between the input and the output is
   detailed, and the number of labeled training examples is large. but it
   is hard to explain why a learned network makes a particular
   classification decision on a particular test case. this is due to their
   reliance on distributed hierarchical representations. if we could take
   the knowledge acquired by the neural net and express the same knowledge
   in a model that relies on hierarchical decisions instead, explaining a
   particular decision would be much easier. we describe a way of using a
   trained neural net to create a type of soft decision tree that
   generalizes better than one learned directly from the training data.

   the excellent generalization abilities of deep neural nets depend on
   their use of distributed representations in their hidden layers, but
   these representations are hard to understand. for the first hidden
   layer we can understand what causes an activation of a unit and for the
   last hidden layer we can understand the effects of activating a unit,
   but for the other hidden layers it is much harder to understand the
   causes and effects of a feature activation in terms of variables that
   are meaningful such as the input and output variables.

   also, the units in a hidden layer factor the representation of the
   input vector into a set of feature activations in such a way that the
   combined effects of the active features can cause an appropriate
   distributed representation in the next hidden layer. this makes it very
   difficult to understand the functional role of any particular feature
   activation in isolation since its marginal effect depends on the
   effects of all the other units in the same layer.

   these difficulties are further compounded by the fact that deep neural
   nets can make decisions by modeling a very large number of weak
   statistical regularities in the relationship between the inputs and
   outputs of the training data. however, there is nothing in the neural
   network to distinguish the weak regularities that are true properties
   of the data from the spurious regularities that are created by the
   sampling peculiarities of the training set. faced with all these
   difficulties, it seems wise to abandon the idea of trying to understand
   how a deep neural network makes a classification decision by
   understanding what the individual hidden units do.

   by contrast, it is easy to explain how a decision tree makes any
   particular classification because this depends on a relatively short
   sequence of decisions and each decision is based directly on the input
   data. id90, however, do not usually generalize as well as
   deep neural nets. unlike the hidden units in a neural net, a typical
   node at the lower levels of a decision tree is only used by a very
   small fraction of the training data so the lower parts of the decision
   tree tend to overfit unless the size of the training set is
   exponentially large compared with the depth of the tree.

   in this paper, the authors proposed a novel way of resolving the
   tension between generalization and interpretability. instead of trying
   to understand how a deep neural network makes its decisions, they use
   the deep neural network to train a decision tree that mimics the
   input-output function discovered by the neural network but in a
   completely different way. now they have got a model, through which the
   decision made is interpretable.
   [0*4xl8wutobplvrhem.jpeg]

   classification using a soft decision tree

   the image above shows the visualization of a soft decision tree of
   depth 4 trained on mnist. the images at the inner nodes are the learned
   filters, and the images at the leaves are visualizations of the learned
   id203 distribution over classes. the final most likely
   classification at each leaf, as well as the likely classifications at
   each edge are annotated. if we take for example the right most internal
   node, we can see that at that level in the tree the potential
   classifications are only 3 or 8, thus the learned filter is simply
   learning to distinguish between those two digits. the result is a
   filter that looks for the presence of two areas that would join the
   ends of the 3 to make an 8.
   [0*snmcybw8ydvmpqgb.jpeg]

   analyzing the image of a connect4 game

   this is a visualization of the first 2 layers of a soft decision tree
   trained on the connect4 data set. from examining the learned filters we
   can see that the game can be split into two distinct sub types of
   games         games where the players have placed pieces on the edges of the
   board, and games where the players have placed pieces in the center of
   the board.

   the main motivation behind this work was to create a model whose
   behavior is easy to explain; in order to fully understand why a
   particular example was given a particular classification, one can
   simply examine all the learned filters along the path between the root
   and the classification   s leaf node. the crux of this model is that it
   does not rely on hierarchical features, it relies on hierarchical
   decisions instead. the hierarchical features of a traditional neural
   network allow it to learn robust and novel representations of the input
   space, but past a single level or two, they become extremely difficult
   to engage with.

   in this paper, the authors mentioned,    some current attempts at
   explanations for neural networks rely on the use of id119 to
   find an input that particularly excites a given neuron, but this
   results is a single point on a manifold of inputs, meaning that other
   inputs could yield the same pattern of neural excitement, and so it
   does not reflect the entire manifold   . ribeiro et al. propose a
   strategy which relies on fitting some explainable model which    acts
   over absence/presence of interpretable components    to the behavior of a
   deep neural net around some area of interest in the input space. this
   is accomplished by sampling from the input space and querying the model
   around the area of interest and then fitting an explainable model to
   the output of the model. this avoids the problem of attempting to
   explain a particular output by visualizing a single point on a manifold
   but introduces the problem of necessitating a new explainable model for
   every area of interest in the input space, and attempting to explain
   changes in the model   s behavior by first order changes in a discretized
   interpretation of the input space.    by relying on hierarchical
   decisions instead of hierarchical features we side-step these problems,
   as each decision is made at a level of abstraction that the reader can
   engage with directly.   

   if there is a large amount of unlabeled data, the neural net can be
   used to create a much larger labeled data set to train a decision tree,
   thus overcoming the statistical inefficiency of id90. even if
   unlabeled data is unavailable, it may be possible to use recent
   advances in generative modeling (such as gan) to generate synthetic
   unlabeled data from a distribution that is close to the data
   distribution. moreover, without using unlabeled data, it is still
   possible to transfer the generalization abilities of the neural net to
   a decision tree by using a technique called distillation (hinton et
   al., 2015; bucilu   et al., 2006) and a type of decision tree that makes
   soft decisions.

the future of capsule network

   what   s the latest progress in hinton   s work? let   s quote new york
   times    story.

   hinton believes that the capsule network will eventually be applicable
   beyond id161 and enjoy much broader prospects, including
   conversational computing. hinton knows that many people are skeptical
   about the capsule network, just as many people were skeptical about the
   neural networks five years ago. according to the nyt report, hinton
   stated his confidence in capsule network with the quote,    history will
   prove the same result, i think so   .

   reference:

   [12]https://www.alibabacloud.com/blog/geoffrey-hinton's-capsule-network
   s-a-novel-approach-to-deep-learning_p370957?spm=a2c41.11181204.0.0

     * [13]machine learning
     * [14]deep learning
     * [15]capsule network
     * [16]geoffrey hinton
     * [17]neural networks

   (button)
   (button)
   (button) 50 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [18]go to the profile of alibaba cloud

[19]alibaba cloud

   a global cloud computing and ai company, a subsidiary of alibaba group.
   website: [20]https://www.alibabacloud.com/

     * (button)
       (button) 50
     * (button)
     *
     *

   [21]go to the profile of alibaba cloud
   never miss a story from alibaba cloud, when you sign up for medium.
   [22]learn more
   never miss a story from alibaba cloud
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/7591d0a10e77
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@alibaba_cloud/geoffrey-hintons-capsule-networks-a-novel-approach-to-deep-learning-7591d0a10e77&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@alibaba_cloud/geoffrey-hintons-capsule-networks-a-novel-approach-to-deep-learning-7591d0a10e77&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@alibaba_cloud?source=post_header_lockup
  10. https://medium.com/@alibaba_cloud
  11. http://mp.weixin.qq.com/s?__biz=mzi3mta0mtk1ma==&mid=2652008886&idx=3&sn=7bf5ccda237025734d451461b422f983&chksm=f1210547c6568c51c54f7ab254e0ea7e6742de0936d6f2a64e93f5f292d0e72ebd83014922df&scene=21
  12. https://www.alibabacloud.com/blog/geoffrey-hinton's-capsule-networks-a-novel-approach-to-deep-learning_p370957?spm=a2c41.11181204.0.0
  13. https://medium.com/tag/machine-learning?source=post
  14. https://medium.com/tag/deep-learning?source=post
  15. https://medium.com/tag/capsule-networks?source=post
  16. https://medium.com/tag/geoffrey-hinton?source=post
  17. https://medium.com/tag/neural-networks?source=post
  18. https://medium.com/@alibaba_cloud?source=footer_card
  19. https://medium.com/@alibaba_cloud
  20. https://www.alibabacloud.com/
  21. https://medium.com/@alibaba_cloud
  22. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  24. https://medium.com/p/7591d0a10e77/share/twitter
  25. https://medium.com/p/7591d0a10e77/share/facebook
  26. https://medium.com/p/7591d0a10e77/share/twitter
  27. https://medium.com/p/7591d0a10e77/share/facebook
