   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

capsule neural networks: the next neural networks? part 1: id98s and their
problems.

convolutional (   regular   ) neural networks are the latest hype in machine
learning, but they have their flaws. capsule neural networks are the recent
development from hinton which help us solve some of these issues.

   [16]go to the profile of tomer eldor
   [17]tomer eldor (button) blockedunblock (button) followfollowing
   mar 9, 2018

     this is part of a series of posts built to teach about capsule
     neural networks. this first post will explain about    normal   
     (convolutional) neural networks and their problems.

   neural networks may be the hottest field in machine learning. in recent
   years, there were many new developments improving neural networks and
   building making them more accessible. however, they were mostly
   incremental, such as adding more layers or slightly improving the
   activation function, but did not introduce a new type of architecture
   or topic.

   [18]geoffery hinton is one of the founding fathers of many highly
   utilized deep learning algorithms including many developments to neural
   networks         no wonder, for having neurosciences and artificial
   intelligence background.

    at late october 2017, geoffrey hinton, sara sabour, and nicholas
   frosst published a research paper under google brain named    [19]dynamic
   routing between capsules   , introducing a true innovation to neural
   networks. this is exciting, since such development has been long
   awaited for, will likely spur much more research and progress around
   it, and is supposed to make neural networks even better than they are
   now.
     __________________________________________________________________

the baseline: convolutional neural networks

   convolutional neural networks (id98s) are extremely flexible machine
   learning models which were originally inspired by principles from how
   our brains are theorized to work.

     neural networks utilize layers of    neurons    to process raw data into
     patterns and objects.

   the primary building blocks of a neural network is a    convolutional   
   layer (hence the name). what does it do? it takes raw information from
   a previous layer, makes sense of patterns in it, and send it onward to
   the next layer to make sense of a larger picture.

    if you are new to neural networks and want to understand it, i
   recommend:
    1. watching the animated videos by [20]3blue1brown.
    2. for a more detailed textual/visual guide, you can check out this
       [21]beginner   s blogpost
    3. if you can deal with some more math and greater details, you can
       read instead [22]this guide from cs231 at stanford.
        in case you didn   t do any of the above, and plan to continue, here
       is a hand-wavy brief overview.

the intuition behind convolutional neural networks

   let   s start from the beginning.
    the neural net receives raw input data. let   s say it   s a doodle of a
   dog. when you see a dog, you brain automatically detects it   s a dog.
   but to the computer, the image is really just an array of numbers
   representing the colors intensity in the colors channels. let   s say
   it   s just a black&white doodle, so we can represent it with one array
   where each cell represents the brightness of the pixel from black to
   white.
   [1*boo9l-2xnldzic9omqypka.png]
   example dog face for a neural network to recognize. source: [23]the
   sun, image: lovable dog rescue

   what is our goal? our goal is for the net to make visual sense of what
   is in the picture (which is for it just a sequence of numbers). one way
   to do it is bottom-up: start by looking at small groups of pixels, make
   sense of them (like small lines and curves: the curve of the dog   s ear,
   the small circle of its pupil, the small line in its leg), then build
   those up to bigger groups of these lines and curves (like: ear, nose,
   snout, eye), make sense of bigger groups of these shapes (like: face,
   leg, tail), and finally make sense of the entire picture of the dog.

    it does so with many layers transferring information in a sequence
   from one to another.
    if this was new to you, see my summary of convolutional networks
   structure here: [24]understanding convolutional neural networks.

    in case you didn   t read it but it   s still new to you, below is an even
   shorter summary of that summary:
     __________________________________________________________________

[25]understanding convolutional neural networks.

    1. convolutional layers. the first convolutional layer maps the image
       space to a lower space         summarizing what   s happening in each group
       of, say 5x5 pixels         is it a vertical line? horizontal line? curve
       of what shape? this happens with element wise multiplication and
       then summation of all the values in the filter with the original
       filter value and summing up to a single number.
    2. this leads to the neuron, or convolutional filters. each filter /
       neuron is designed to react to one specific form (a vertical line?
       a horizontal line? etc   ). the groups of pixels from layer 1 reach
       these neurons, and lights up the neurons that match its structure
       according to how much this slice is similar to what the neuron
       looks for.
    3. activation (usually    relu   ) layers         after each convolutional
       layer, we apply a nonlinear layer (or activation layer), which
       introduces non-linearity to the system, enabling it to discover
       also nonlinear relations in the data. relu is a very simple one:
       making any negative input to 0, or if it   s positive         keeping it
       the same. relu(x) = max(0,x).
    4. pooling layers. this allows to reduce    unnecessary    information,
       summarize what we know about a region, and continue to refine
       information. for example, this might be    maxpooling    where the
       computer will just take the highest value of the passed this
       patch         so that the computer knows    around these 5x5 pixels, the
       most dominant value is 255. i don   t know exactly in which pixel but
       the exact location isn   t as important as that it   s around there.    
       notice: this is not good. we loose information here. capsule
       networks don   t have this operation here, which is an improvement.
    5. dropout layers. this layer    drops out    a random set of activations
       in that layer by setting them to zero. this makes the network more
       robust (kind of like you eating dirt builds up your immunity
       system, the network is more immune to small changes) and reduces
       overfitting. this is only used when training the network.
    6. last fully connected layer. for a classification problem, we want
       each final neuron represents the final class. it looks at the
       output of the previous layer (which as we remember should represent
       the activation maps of high level features) and determines which
       features most correlate to a particular class.
    7. softmax         this layer is sometimes added as a another way to
       represent the outputs per classes that we can later pass on in a
       id168. softmax represents the distribution of probabilities
       to the various categories.

   usually, there are more layers which provide nonlinearities and
   preservation of dimensions (like padding with 0   s around the edges)
   that help to improve the robustness of the network and control
   overfitting. but these are the basics you need to understand what comes
   after.

    now, importantly, these layers are connected only sequentially. this
   is in contrast to the structure of id22.
   [1*od7jm__bqdbemdonfqmytq.png]
   neural network structure, [26]from a google article be szegedy, toshev
   & erhan presenting neural networks
     __________________________________________________________________

what is the problem with convolutional neural networks?

   if this interests you, [27]watch hinton's lecture explaining exactly
   what it wrong with them. below you'll get a couple of key points that
   are improved by id22.

   hinton says that they have too few levels of substructures (nets are
   composed from layers composed from neurons, that's it); and that we
   need to group the neurons in each layer into    capsules   , like
   mini-columns, that do a lot of internal computations, and then output a
   summary result.

problem #1: pooling looses information

   id98 use    pooling    or equivalent methods to    summarize    what's going on
   in the smaller regions and make sense of larger and larger chunks of
   the image. this was a solution that made id98s work well, but it looses
   valuable information.

    id22 will compute a pose (transnational and rotational)
   relationship between smaller features to make up a larger feature.
    this loss of information leads to loss of spatial information.

problem #2: id98s don't account for the spatial relations between the parts of
the image. therefore, they also are too sensitive to orientation.

     subsampling (and pooling) loses the precise spatial relationships
     between higher-level parts like a nose and a mouth. the precise
     spatial relationships are needed for identity recognition.

   [28](hinton, 2012, in his lecture).

    id98s don't account for spatial relationships between the underlying
   objects. by having these flat layers of neurons that light up according
   to which objects they've seen, they recognize the presence of such
   objects. but then they are passed on to other activation and pooling
   layers and on to the next layer of neurons (filters), without
   recognizing what are the relations between these objects we identified
   in that single layer.
    they just account for their presence.

   so a (simplistic) neural network will not hesitate about categorizing
   both these dogs, pablo and picasso, as similarly good representations
   of    corgi-pit-bull-terrier mix   .
   [1*jodqcqawdavliwmcankz1a.png]
   normal (convolutional) neural network will recognize both of these
   lovely dogs as the same type of dog face, because it does not care
   about where the elements of the dog   s face are located relatively to
   each other in space. picasso (the dog on the left) will luckily not be
   discriminated against by the model, but we really want a model to
   realize this is not a regular example of a corgi-pit-bull-terrier mix
   dog. image source: [29]the sun. image: lovable dog rescue

   the network will categorize both these dogs as similarly good
   representations of    corgi-pit-bull-terrier mix    dogs because they both
   answer the same conditions at the face composition convolutional layer,
   for example:
if: (2 eyes & pitbullmix_snout
     + pitbullmix_wet_nose & mouth)
then: pitbullmix_face

   incorrectly activating the neuron for pitbullmix_face, instead of
   something like:
if: 2 eyes
& below: pitbullmix_snout
     & pitbullmix_wet_nose
& below: mouth
then: pitbullmix_face

   conversely, id22 represent directionality along with
   content and connect between capsules of neurons to infer spatial
   relationships and retain pose information.

    lacking a grouped capsule representation, pose calculations, and
   overlapping check between the capsules leads to the next problem.

problem #3: id98s can't transfer their understanding of geometric
relationships to new viewpoints.

   this makes them more sensitive to the original image itself in order to
   classify images as the same category.

    id98s are great for solving problems with data similar to what they
   have been trained on. it can classify images or objects within them
   which are very close to things it has seen before.

    but if the object is slightly rotated, photographed from a slightly
   different angle, especially in 3d, is tilted or in another orientation
   than what the id98 has seen - the network won't recognize it well.

    one solution is to artificially create tilted representation of the
   image or groups and add them to the    training    set. however, this still
   lacks a fundamentally more robust structure.

encoding a viewpoint-invariant spatial relationship pose

   so how can we encode spatial relationships between 3d objects?
    hinton [30]took inspiration from a field that already solved that
   problem: 3d computer graphics.
    in 3d graphics, a [31]pose [32]matrix is a special technique to
   represent the relationships between objects. poses are essentially
   matrices representing translation plus rotation. now we got it. we can
   retain spatial relationships information using pose relationships
   between sub-objects; measuring the relative rotations and translations
   between objects as a 4d pose matrix.
    this would be key to understanding dynamic routing between capsules.
     __________________________________________________________________

   now that we know the basics of neural networks and their spatial
   recognition problems, we can continue to learn about the recently
   developed solution to that: capsule neural network. that will be the
   topic of my next post. stay tuned!

     * [33]machine learning
     * [34]neural networks
     * [35]id22
     * [36]data science
     * [37]ai

   (button)
   (button)
   (button) 618 claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   [38]go to the profile of tomer eldor

[39]tomer eldor

   passionate about data science & ai for social good and making great
   user-focused products. a jazz composer living every 4 months in another
   country.

     (button) follow
   [40]towards data science

[41]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 618
     * (button)
     *
     *

   [42]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [43]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/693b7c99b12
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/capsule-neural-networks-are-here-to-finally-recognize-spatial-relationships-693b7c99b12&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/capsule-neural-networks-are-here-to-finally-recognize-spatial-relationships-693b7c99b12&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_4fkaxg9m8ygv---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@tomereldor?source=post_header_lockup
  17. https://towardsdatascience.com/@tomereldor
  18. https://research.google.com/pubs/geoffreyhinton.html
  19. https://arxiv.org/abs/1710.09829
  20. https://www.youtube.com/watch?v=aircaruvnkk
  21. https://adeshpande3.github.io/adeshpande3.github.io/a-beginner's-guide-to-understanding-convolutional-neural-networks/
  22. http://cs231n.github.io/convolutional-networks/
  23. https://www.thesun.co.uk/living/3009674/dog-called-picasso-because-of-his-wonky-face-is-looking-for-a-new-home-and-offers-are-already-flooding-in/
  24. https://quip.com/a4mbabjjb7on
  25. https://quip.com/a4mbabjjb7on
  26. https://pdfs.semanticscholar.org/d8b9/eadcadb12d4d4e19201b4c5519470e21114c.pdf
  27. https://www.youtube.com/watch?v=rtawfwuvnle&feature=youtu.be
  28. https://www.youtube.com/watch?v=tfimqt0yt2i&feature=youtu.be
  29. https://www.thesun.co.uk/living/3009674/dog-called-picasso-because-of-his-wonky-face-is-looking-for-a-new-home-and-offers-are-already-flooding-in/
  30. http://helper.ipam.ucla.edu/publications/gss2012/gss2012_10754.pdf
  31. https://en.wikipedia.org/wiki/pose_(computer_vision)
  32. http://digitalrune.github.io/digitalrune-documentation/html/d995ee69-0650-4993-babd-1cdb1fd8fd7a.htm
  33. https://towardsdatascience.com/tagged/machine-learning?source=post
  34. https://towardsdatascience.com/tagged/neural-networks?source=post
  35. https://towardsdatascience.com/tagged/capsule-networks?source=post
  36. https://towardsdatascience.com/tagged/data-science?source=post
  37. https://towardsdatascience.com/tagged/ai?source=post
  38. https://towardsdatascience.com/@tomereldor?source=footer_card
  39. https://towardsdatascience.com/@tomereldor
  40. https://towardsdatascience.com/?source=footer_card
  41. https://towardsdatascience.com/?source=footer_card
  42. https://towardsdatascience.com/
  43. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  45. https://medium.com/p/693b7c99b12/share/twitter
  46. https://medium.com/p/693b7c99b12/share/facebook
  47. https://medium.com/p/693b7c99b12/share/twitter
  48. https://medium.com/p/693b7c99b12/share/facebook
