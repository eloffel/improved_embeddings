   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

nlp         building a id53 model

   [16]go to the profile of priya dwivedi @ deep learning analytics
   [17]priya dwivedi @ deep learning analytics (button) blockedunblock
   (button) followfollowing
   mar 29, 2018

   doing cool things with data!

   i recently completed a course on nlp through deep learning (cs224n) at
   stanford and loved the experience. learnt a whole bunch of new things.
   for my final project i worked on a id53 model built on
   [18]stanford id53 dataset (squad). in this blog, i want
   to cover the main building blocks of a id53 model.
   [1*xfkz_ma_el54cw5szbtzdg.gif]

   you can find the full code on my [19]github repo.

   i have also recently added a [20]web demo for this model where you can
   put in any paragraph and ask questions related to it. check it out at
   [21]link

   squad dataset

   stanford id53 dataset ([22]squad) is a new reading
   comprehension dataset, consisting of questions posed by crowdworkers on
   a set of wikipedia articles, where the answer to every question is a
   segment of text, or span, from the corresponding reading passage. with
   100,000+ question-answer pairs on 500+ articles, squad is significantly
   larger than previous reading comprehension datasets.

   there has been a rapid progress on the squad dataset with some of the
   latest models achieving human level accuracy in the task of question
   answering!

   examples of context, question and answer on squad

   context         apollo ran from 1961 to 1972, and was supported by the
   two-man gemini program which ran concurrently with it from 1962 to
   1966. gemini missions developed some of the space travel techniques
   that were necessary for the success of the apollo missions. apollo used
   saturn family rockets as launch vehicles. apollo/saturn vehicles were
   also used for an apollo applications program, which consisted of
   skylab, a space station that supported three manned missions in
   1973   74, and the apollo   soyuz test project, a joint earth orbit mission
   with the soviet union in 1975.

   question         what space station supported three manned missions in
   1973   1974?

   answer         skylab

   key features of squad:

   i) it is a closed dataset meaning that the answer to a question is
   always a part of the context and also a continuous span of context

   ii) so the problem of finding an answer can be simplified as finding
   the start index and the end index of the context that corresponds to
   the answers

   iii) 75% of answers are less than equal to 4 words long

machine comprehension model         key components

   i) embedding layer

   the training dataset for the model consists of context and
   corresponding questions. both of these can be broken into individual
   words and then these words converted into id27s using
   pretrained vector like [23]glove vectors. to learn more about word
   embeddings please check out [24]this article from me. id27s
   are much better at capturing the context around the words than using a
   one hot vector for every word. for this problem i used 100 dimension
   glove id27s and didn   t tune them during the training process
   since we didn   t have sufficient data.

   ii) encoder layer
   [1*p3pq3ojoeebu-e8feyvcnw.png]
   id56 encoder

   the next layer we add in the model is a id56 based encoder layer. we
   would like each word in the context to be aware of words before it and
   after it. a bi-directional gru/lstm can help do that. the output of the
   id56 is a series of hidden vectors in the forward and backward direction
   and we concatenate them. similarly we can use the same id56 encoder to
   create question hidden vectors.

   iii) attention layer

   up til now we have a hidden vector for context and a hidden vector for
   question. to figure out the answer we need to look at the two together.
   this is where attention comes in. it is the key component in the
   id53 system since it helps us decide, given the question
   which words in the context should i    attend    to. lets start with the
   simplest possible attention model:

   dot product attention
   [1*oq7v3p8q5cxemeoh6h8psg.png]
   basic attention visualisation from cs224n

   the dot product attention would be that for each context vector c i we
   multiply each question vector q j to get vector e i (attention scores
   in the figure above). then we take a softmax over e i to get   
   i(attention distribution in the figure above). softmax ensures that the
   sum of all e i is 1. finally we calculate a i as the product of the
   attention distribution    i and the corresponding question
   vector(attention output in the figure above). dot product attention is
   also described in the equations below
   [1*owyx924xnjq8bhqkeqbaja.png]
   [1*iyf7lthw32tizyrjanutna.png]

   the above attention has been implemented as baseline attention in the
   github code.

   more complex attention         bidaf attention

   you can run the squad model with the basic attention layer described
   above but the performance would not be good. more complex attention
   leads to much better performance.

   lets describe the attention in the [25]bidaf paper. the main idea is
   that attention should flow both ways         from the context to the question
   and from the question to the context.

   we first compute the similarity matrix s     r n  m, which contains a
   similarity score sij for each pair (ci , qj ) of context and question
   hidden states. sij = wt sim[ci ; qj ; ci     qj ]     r here, ci     qj is an
   elementwise product and wsim     r 6h is a weight vector. described in
   equation below:
   [1*nmi5zm6ip6yk_egtqy1cdw.png]

   next, we perform context-to-question (c2q) attention. (this is similar
   to the dot product attention described above). we take the row-wise
   softmax of s to obtain attention distributions    i , which we use to
   take weighted sums of the question hidden states q j , yielding c2q
   attention outputs a i .
   [1*kcckgb2g7rht_lbkv85wug.png]

   next, we perform question-to-context(q2c) attention. for each context
   location i     {1, . . . , n}, we take the max of the corresponding row
   of the similarity matrix, m i = max j sij     r. then we take the softmax
   over the resulting vector m     r n         this gives us an attention
   distribution        r n over context locations. we then use    to take a
   weighted sum of the context hidden states c i         this is the q2c
   attention output c prime. see equations below
   [1*vvoimkln1mlav3blyypryw.png]

   finally for each context position c i we combine the output from c2q
   attention and q2c attention as described in the equation below
   [1*pxdigejrrn3vutlqrodaaq.png]

   if you found this section confusing, don   t worry. attention is a
   complex topic. try reading the bidaf paper with a cup of tea :)

   iv) output layer

   almost there. the final layer of the model is a softmax output layer
   that helps us decide the start and the end index for the answer span.
   we combine the context hidden states and the attention vector from the
   previous layer to create blended reps. these blended reps become the
   input to a fully connected layer which uses softmax to create a p_start
   vector with id203 for start index and a p_end vector with
   id203 for end index. since we know that most answers the start
   and end index are max 15 words apart, we can look for start and end
   index that maximize p_start*p_end.

   our id168 is the sum of the cross-id178 loss for the start
   and end locations. and it is minimized using adam optimizer.

   the final model i built had a bit more complexity than described above
   and got to a f1 score of 75 on the test set. not bad!

next steps

   couple of additional ideas for future exploration:
     * i have been experimenting with a id98 based encoder to replace the
       id56 encoder described since id98s are much faster than id56s and more
       easy to parallelize on a gpu
     * additional attention mechanisms like dynamic co-attention as
       described in the [26]paper

   give me a        if you liked this post:) hope you pull the code and try it
   yourself.

   other writings: [27]http://deeplearninganalytics.org/blog

   ps: i have my own deep learning consultancy and love to work on
   interesting problems. i have helped several startups deploy innovative
   ai based solutions. check us out
   at         [28]http://deeplearninganalytics.org/.

   if you have a project that we can collaborate on, then please contact
   me through my website or at priya.toronto3@gmail.com

   references:
     * [29]cs 224n
     * [30]squad dataset
     * [31]bidaf model

     * [32]machine learning
     * [33]deep learning
     * [34]artificial intelligence
     * [35]data science
     * [36]nlp

   (button)
   (button)
   (button) 2.8k claps
   (button) (button) (button) 22 (button) (button)

     (button) blockedunblock (button) followfollowing
   [37]go to the profile of priya dwivedi @ deep learning analytics

[38]priya dwivedi @ deep learning analytics

   [39]http://www.deeplearninganalytics.org/

     (button) follow
   [40]towards data science

[41]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 2.8k
     * (button)
     *
     *

   [42]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [43]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/ed0529a68c54
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_vhz5t52bdde3---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@priya.dwivedi?source=post_header_lockup
  17. https://towardsdatascience.com/@priya.dwivedi
  18. https://rajpurkar.github.io/squad-explorer/
  19. https://github.com/priya-dwivedi/cs224n-squad-project
  20. http://deeplearninganalytics.org/demos
  21. http://deeplearninganalytics.org/demos
  22. https://rajpurkar.github.io/squad-explorer/
  23. https://nlp.stanford.edu/projects/glove/
  24. https://towardsdatascience.com/training-and-visualising-word-vectors-2f946c6430f8
  25. https://arxiv.org/abs/1611.01603
  26. https://arxiv.org/abs/1611.01604
  27. http://deeplearninganalytics.org/blog
  28. http://deeplearninganalytics.org/
  29. http://web.stanford.edu/class/cs224n/
  30. https://rajpurkar.github.io/squad-explorer/
  31. https://arxiv.org/abs/1611.01603
  32. https://towardsdatascience.com/tagged/machine-learning?source=post
  33. https://towardsdatascience.com/tagged/deep-learning?source=post
  34. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  35. https://towardsdatascience.com/tagged/data-science?source=post
  36. https://towardsdatascience.com/tagged/nlp?source=post
  37. https://towardsdatascience.com/@priya.dwivedi?source=footer_card
  38. https://towardsdatascience.com/@priya.dwivedi
  39. http://www.deeplearninganalytics.org/
  40. https://towardsdatascience.com/?source=footer_card
  41. https://towardsdatascience.com/?source=footer_card
  42. https://towardsdatascience.com/
  43. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  45. https://medium.com/p/ed0529a68c54/share/twitter
  46. https://medium.com/p/ed0529a68c54/share/facebook
  47. https://medium.com/p/ed0529a68c54/share/twitter
  48. https://medium.com/p/ed0529a68c54/share/facebook
