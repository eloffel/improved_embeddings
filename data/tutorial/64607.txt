   #[1]rubik's code    feed [2]rubik's code    comments feed [3]rubik's code
      two ways to implement lstm network using python     with tensorflow and
   keras comments feed [4]alternate [5]alternate

   [6]skip to content

     * [7]linkedin
     * [8]twitter
     * [9]git
     * [10]fb

   [11]rubik's code

   machine learning without tears

     * products
          + [12]introducing test driven development in c#     video course
          + [13]test driven development with c# and .net core mvc     video
            course
          + [14]real-world machine learning projects with sci-kit learn
     * [15]articles
     * [16]series
          + [17]id158s series
               o [18]introduction to id158s
               o [19]common neural network id180
               o [20]how do id158s learn?
               o [21]id26 algorithm in artificial neural
                 networks
               o [22]implementing simple neural network in c#
               o [23]introduction to tensorflow     with python example
               o [24]implementing simple neural network using keras     with
                 python example
               o [25]introduction to convolutional neural networks
               o [26]implementation of convolutional neural network using
                 python and keras
               o [27]introduction to recurrent neural networks
               o [28]understanding id137 (lstms)
               o [29]two ways to implement lstm network using python    
                 with tensorflow and keras
          + [30]gan series
               o [31]introduction to id3
                 (gans)
               o [32]implementing gan & dcgan with python
               o [33]introduction to adversarial autoencoders
               o [34]generating images using adversarial autoencoders and
                 python
               o [35]implementing cyclegan using python
               o [36]introduction to cyclegan
          + [37]machine learning with ml.net
               o [38]ultimate guide to machine learning with ml.net
               o [39]using ml.net     introduction to machine learning and
                 ml.net
               o [40]machine learning with ml.net     solving real-world
                 regression problem (bike sharing demands)
               o [41]machine learning with ml.net     solving real-world
                 classification problem (wine quality)
               o [42]machine learning in ml.net     using machine learning
                 model in asp.net core application
               o [43]machine learning with ml.net     comparing data
                 exploration in python with data exploration in ml.net
          + [44]asynchronous programming in .net
               o [45]motivation and unit testing
               o [46]common mistakes and best practices
               o [47]task-based asynchronous pattern (tap)
               o [48]benefits and tradeoffs of using valuetask
          + [49]self- organizing maps series
               o [50]introduction to self-organizing maps
               o [51]implementing self-organizing maps with python and
                 tensorflow
               o [52]implementing self-organizing maps with .net core
               o [53]credit card fraud detection using self-organizing
                 maps and python
          + [54]restricted id82 series
               o [55]introduction to restricted id82s
               o [56]implementing restricted id82 with python
                 and tensorflow
               o [57]implementing restricted id82 with .net
                 core
               o [58]generate music using tensorflow and python
          + [59]mongodb series
               o [60]introduction to nosql and polyglot persistence
               o [61]mongodb basics     part 1.
               o [62]mongo db basics     part 2.
               o [63]using mongodb in c#
               o [64]mean stack crash course     using mongodb with node.js,
                 express and angular 4
               o [65]serverless and playing around with mongodb atlas
          + [66]philosophy as motivational tool for software crafters
            series
               o [67]how to use miyamoto musashi   s philosophy to become
                 better software crafter
               o [68]how to use marcus aurelius   s meditations to become
                 better software crafter
               o [69]   how to use friedrich nietzsche   s philosophy to be
                 better software crafter
               o [70]how to use    art of war    to be better software crafter
     * categories
          + [71]ai
          + [72]machine learning
          + [73].net
          + [74]python
          + [75]nosql
     * [76]about
     * [77]contact

   (button) open a search box close a search box search for:
   ____________________ (button) search

two ways to implement lstm network using python     with tensorflow and keras

   [78]march 26, 2018march 28, 2018 by [79]rubikscode [80]1 comment

   in the [81]previous article, we talked about the way that powerful type
   of recurrent neural networks     long short-term memory (lstm) networks
   function. they are not keeping just propagating output information to
   the next time step, but they are also storing and propagating the state
   of the so-called lstm cell. this cell is holding four neural networks
   inside     gates, which are used to decide which information will be
   stored in cell state and pushed to output. so, the output of the
   network at one time step is not depending only on the previous time
   step but depends on n previous time steps.

   [tfhlrb0.png]

   ok, that is enough to get us up to speed with theory, and prepare us
   for the practical part     implementation of this kind of networks. if
   however, you want to learn more about id137,
   you can do it [82]here. in this article, we will consider two similar
   id38 problems and solve them using two different apis.
   firstly we will create the network that will be able to predict words
   based on the provided peace of text and for this purpose, we will use
   [83]tensorflow. in second implementation we will be classifying reviews
   from the imdb dataset using the [84]keras.

   before we wander off into the problem we are solving and the code
   itself make sure to setup your environment. as in all previous articles
   from this [85]series, i will be using python 3.6. also, i am using
   anaconda and spyder, but you can use any ide that you prefer. however,
   the important thing to do is to install tensorflow and keras.
   instructions for installing and using tensorflow can be found [86]here,
   while instructions for installing and using keras are [87]here.

the problem for tensorflow implementation

   let   s say that we want to train one lstm to predict the next word using
   a sample text. simple text in our example will be one of the favorite
   sections of mine from [88]marcus aurelius     meditations:

     in a sense , people are our proper occupation . our job is to do
     them good and put up with them . but when they obstruct our proper
     tasks , they become irrelevant to us   like sun , wind, animals . our
     actions may be impeded by them , but there can be no impeding our
     intentions or our dispositions . because we can accommodate and
     adapt . the mind adapts and converts to its own purposes the
     obstacle to our acting . the impediment to action advances action .
     what stands in the way becomes the way .

   note that this text is a bit modified. every punctuation mark is
   surrounded by space characters, ergo every word and every
   punctuation mark are considered as a symbol. to demonstrate how lstm
   networks work, we will use simplified process. we will push sequences
   of three symbols as inputs and one output. by repeating this process,
   the network will learn how to predict next word based on three previous
   ones.

   [yorkqpm.png?w=720&#038;ssl=1]

tensorflow implementation

   so, we have our plan of attack: provide a sequence of three symbols and
   one output to the lstm network and learn it to predict that output.
   however, since we are using mathematical models first thing we need to
   do is to prepare this data (text) for any kind of operation. these
   networks understand numbers, not strings as we have it in our text, so
   we need to convert these symbols into numbers. we will do this by
   assigning a unique integer to each symbol based the on the frequency of
   occurrence.

   [whn0bko.png?w=720&#038;ssl=1]

   for this purpose, we will use datahandler class. this class has two
   purposes, to load the data from the file, and to assign a number to
   each symbol. here is the code:

   the first method of this class read_data is used to read text from the
   defined file and create an array of symbols. here is how that looks
   like once called on the sample text:

   [dgpm4xx.png?w=720&#038;ssl=1]

   the second method build_datasets is used for creating two dictionaries.
   the first dictionary labeled as just dictionary contains symbols as
   keys and their corresponding number as a value. second
   dictionary reverse_dictionary contains the same information, just keys
   are numbers and values are the symbols themselves. this is how they
   will look like created using the sample text we are using in this
   example:

   [srx62fk.png?w=720&#038;ssl=1]

   awesome! our data is ready for use. off to the fun part, the creation
   of the model. for this purpose, we will create a new class that will be
   able to generate lstm network based on the passed parameters. take a
   look:

   we imported some important classes there: tensorflow itself and id56
   class form tensorflow.contrib. since our lstm network is a subtype of
   id56s we will use this to create our model. firstly, we reshaped our
   input and then split it into sequences of three symbols. then we
   created the model itself.

   we created two lstm layers using basiclstmcell method. each of these
   layers has a number of units defined by the parameter num_units. apart
   from that, we use multiid56cell to combine these two layers in one
   network. then we used static_id56 method to construct the network and
   generate the predictions.

   in the end, we will use sessionrunner class. this class contains
   environment in which our model will be run and evaluated. here is how
   the code looks like:

   50000 iterations are being run using our model. we injected model,
   optimizer, id168, etc. in the constructor, so the class has
   this information available. of course, the first thing we need to do is
   slice up the data in the provided dictionary, and make encoded outputs
   (sym_in_keys and sym_out_onehot, respectively). also, we are pushing
   random sequences in the model so we avoid overfitting. this is handled
   by offset variable. finally, we will run the session and get accuracy.
   don   t get confused by final if statement in the code it is used just
   for display purposes (at every 1000 iterations present the average
   accuracy).

   our main script combines all this into one, and here is how it looks
   like:

   once we run this code we get the accuracy of 97.10%:

   [2dcawps.png?w=720&#038;ssl=1]

the problem for keras implementation

   this example with tensorflow was pretty straightforward, and simple. we
   used the small amount of data and network was able to learn this rather
   quickly. what if we have a more complex problem? for example, let   s say
   that we want to classify sentiment of each movie review on some site.
   lucky for us there is already a dataset, dedicated to this problem    
   [89]the large movie review dataset (often referred to as the imdb
   dataset).

   this dataset was collected by stanford researchers back in 2011. it
   contains 25000 movie reviews (good or bad) for training and the same
   amount of reviews for testing. our goal is to create a network that
   will be able to determine which of these reviews are positive and which
   are negative. we will use keras api which has this dataset built in.

keras implementation

   the power of keras is that it abstracts a lot of things we had to take
   care while we were using tensorflow. however, it is giving us a less
   flexibility. of course, everything is a trade-off. so, let   s start this
   implementation by importing necessary classes and libraries.

   as you can see there are is a little difference in imports from
   examples where we implemented [90]standard ann or when we implemented
   [91]convolutional neural network. we imported sequential, dense and
   dropout. still, we can see a couple new imports. we used embedding as
   well as lstm from the keras.layers. as you can imagine lstm is used for
   creating lstm layers in the networks. embedding, on the other hand, is
   used to provide a dense representation of words.

   this is one cool technique that will map each movie review into a real
   vector domain. words are encoded as real-valued vectors in a high
   dimensional space, where the similarity between words in terms of
   meaning translates to closeness in the vector space. we can notice that
   we imported imdb dataset that is provided in the keras.datasets.
   however, to load data from that dataset we need to do this:

   we are loading dataset of top 1000 words. after this, we need to divide
   this dataset and create and pad sequences. this is done by
   using sequence from keras.preprocessing, like this:

   in the padding we used number 200, meaning that our sequences will be
   200 words long. here is how training input data is looking like after
   this:

   [uwqkygl.png?w=720&#038;ssl=1]

   now we can define, compile and fit lstm model:

   as we have learned from the [92]previous articles, sequential is used
   for model composition. the first layer that is added to it is embedding
   and we   ve explained its purpose in the previous chapter. after the word
   embedding is done we added one lstm layer. in the end, since this is a
   classification problem, we are trying to figure out was the review good
   or bad, dense layer with sigmoid function is added. finally, the model
   is compiled and binary_crossentorpy and adam optimizer are used. this
   is how our model is looking like:

   [ttne3te.png?w=720&#038;ssl=1]

   let   s fit our data to the model and get the accuracy:

   we got the accuracy of 85.12%.

   [2crp9a8.png?w=720&#038;ssl=1]

conclusion

   we saw two approaches when creating id137. both approaches were
   dealing with simple problems and each was using a different api. this
   way one could see that tensorflow is more detailed and flexible,
   however, you need to take care of lot more stuff than when you are
   using keras. keras is simpler and more straightforward but it doesn   t
   give us the flexibility and possibilities we have when we are using
   pure tensorflow. both of these examples provided ok results, but they
   could be even better. especially the second example, for which we
   usually use a combination of id98 and id56 to get higher accuracy, but
   that is a topic for another article.
   thanks for reading!
     __________________________________________________________________

   this article is a part of  [93]id158s series.
     __________________________________________________________________

   read more posts from the author at [94]rubik   s code.
     __________________________________________________________________

   [95]codeproject

share:

     * [96]click to share on twitter (opens in new window)
     * [97]click to share on facebook (opens in new window)
     *

like this:

   like loading...

   posted in: [98]ai
   tagged: [99]ai [100]artificaial inteligance [101]artificial neural
   networks [102]deep learning [103]lstm [104]lstms [105]machine learning
   [106]neural networks [107]software development

post navigation

   previous entry:[108]understanding id137
   (lstms)
   next entry:[109]exploring dependency injection in c#     part 1.

one comment

    1. pingback: [110]dew drop - march 26, 2018 (#2691) - morning dew

leave a reply [111]cancel reply

   iframe: [112]jetpack_remote_comment

   this site uses akismet to reduce spam. [113]learn how your comment data
   is processed.

subscribe to rubik's code via email

   email address ____________________

   (button) subscribe

video courses

     * introducing test driven development in c#
     * test driven development with c# and .net core mvc
     * real-world machine learning projects with scikit-learn

follow rubik   s code

     * [114]linkedin
     * [115]twitter
     * [116]github
     * [117]facebook

   close and accept
   privacy & cookies: this site uses cookies. by continuing to use this
   website, you agree to their use.
   to find out more, including how to control cookies, see here: [118]info

   (button) go to the top

products

     * [119]introducing test driven development in c#
     * [120]test driven development with c# and .net core mvc
     * [121]real-world machine learning projects with sci-kit learn

series

     * [122]id158s series
     * [123]machine learning with ml.net series
     * [124]asynchronous programming in .net series
     * [125]mongodb series
     * [126]philosophy as motivational tool for software crafters series

rubik   s code

     * [127]about
     * [128]contact

     * [129]linkedin
     * [130]twitter
     * [131]git
     * [132]fb

   iframe: [133]likes-master

   %d bloggers like this:

references

   visible links
   1. https://rubikscode.net/feed/
   2. https://rubikscode.net/comments/feed/
   3. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/feed/
   4. https://rubikscode.net/wp-json/oembed/1.0/embed?url=https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/
   5. https://rubikscode.net/wp-json/oembed/1.0/embed?url=https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/&format=xml
   6. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/#content
   7. https://www.linkedin.com/in/nmzivkovic/
   8. https://twitter.com/nmzivkovic?lang=en
   9. https://github.com/nmzivkovic
  10. https://www.facebook.com/rubikscodenet/
  11. https://rubikscode.net/
  12. https://www.packtpub.com/application-development/introducing-test-driven-development-c-video
  13. https://www.packtpub.com/application-development/test-driven-development-c-and-net-core-mvc-video
  14. https://www.packtpub.com/big-data-and-business-intelligence/real-world-machine-learning-projects-scikit-learn-video
  15. https://rubikscode.net/
  16. https://rubikscode.net/category/series/
  17. https://rubikscode.net/2018/02/19/artificial-neural-networks-series/
  18. https://rubikscode.net/2017/11/13/introduction-to-artificial-neural-networks/
  19. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/
  20. https://rubikscode.net/2018/01/15/how-artificial-neural-networks-learn/
  21. https://rubikscode.net/2018/01/22/id26-algorithm-in-artificial-neural-networks/
  22. https://rubikscode.net/2018/01/29/implementing-simple-neural-network-in-c/
  23. https://rubikscode.net/2018/02/05/introduction-to-tensorflow-with-python-example/
  24. https://rubikscode.net/2018/02/12/implementing-simple-neural-network-using-keras-with-python-example/
  25. https://rubikscode.net/2018/02/26/introduction-to-convolutional-neural-networks/
  26. https://rubikscode.net/2018/03/05/implementation-of-convolutional-neural-network-using-python-and-keras/
  27. https://rubikscode.net/2018/03/12/introuduction-to-recurrent-neural-networks/
  28. https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/
  29. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/
  30. http://rtrtr.com/
  31. https://rubikscode.net/2018/12/10/introduction-to-generative-adversarial-networks-gans/
  32. https://rubikscode.net/2018/12/17/implementing-gan-dcgan-with-python/
  33. https://rubikscode.net/2019/01/14/introduction-to-adversarial-autoencoders/
  34. https://rubikscode.net/2019/01/21/generating-images-using-adversarial-autoencoders-and-python/
  35. https://rubikscode.net/2019/02/11/implementing-cyclegan-using-python/
  36. https://rubikscode.net/2019/02/04/introduction-to-cyclegan/
  37. https://rubikscode.net/2018/07/23/machine-learning-with-ml-net-series/
  38. https://rubikscode.net/2019/02/18/ultimate-guide-to-machine-learning-with-ml-net/
  39. https://rubikscode.net/2018/06/18/using-ml-net-introduction-to-machine-learning-and-ml-net/
  40. https://rubikscode.net/2018/06/25/machine-learning-with-ml-net-solving-real-world-regression-problem-bike-sharing-demands/
  41. https://rubikscode.net/2018/07/02/machine-learning-with-ml-net-solving-real-world-classification-problem-wine-quality/
  42. https://rubikscode.net/2018/07/09/machine-learning-in-ml-net-using-machine-learning-model-in-asp-net-mvc-application/
  43. https://rubikscode.net/2018/07/16/machine-learning-with-ml-net-comparing-data-exploration-in-python-with-data-exploration-in-ml-net/
  44. https://rubikscode.net/2018/08/06/asynchronous-programming-in-net/
  45. https://rubikscode.net/2018/05/21/asynchronous-programming-in-net-motivation-and-unit-testing/
  46. https://rubikscode.net/2018/05/28/asynchronous-programming-in-net-common-mistakes-and-best-practices/
  47. https://rubikscode.net/2018/06/04/asynchronous-programming-in-net-task-based-asynchronous-pattern-tap/
  48. https://rubikscode.net/2018/06/11/asynchronous-programming-in-net-benefits-and-tradeoffs-of-using-valuetask/
  49. https://rubikscode.net/2018/09/26/self-organizing-maps-series/
  50. https://rubikscode.net/2018/08/20/introduction-to-self-organizing-maps/
  51. https://rubikscode.net/2018/08/27/implementing-self-organizing-maps-with-python-and-tensorflow/
  52. https://rubikscode.net/2018/09/17/implementing-self-organizing-maps-with-net-core/
  53. https://rubikscode.net/2018/09/24/credit-card-fraud-detection-using-self-organizing-maps-and-python/
  54. https://rubikscode.net/2019/01/07/restricted-boltzmann-machine-series/
  55. https://rubikscode.net/2018/10/01/introduction-to-restricted-boltzmann-machines/
  56. https://rubikscode.net/2018/10/22/implementing-restricted-boltzmann-machine-with-python-and-tensorflow/
  57. https://rubikscode.net/2018/10/15/implementing-restricted-boltzmann-machine-with-net-core/
  58. https://rubikscode.net/2018/11/12/generate-music-using-tensorflow-and-python/
  59. https://rubikscode.net/2017/10/16/mongodb-serial/
  60. https://rubikscode.net/2017/07/19/introduction-to-nosql-and-polyglot-persistence/
  61. https://rubikscode.net/2017/07/24/mongo-db-basics-part-1/
  62. https://rubikscode.net/2017/07/31/mongo-db-basics-part-2/
  63. https://rubikscode.net/2017/10/02/using-mongodb-in-c/
  64. https://rubikscode.net/2017/10/09/mean-stack-crash-course-using-mongodb-with-node-js-express-and-angular-4/
  65. https://rubikscode.net/2017/10/15/serverless-and-mongodb-atlas/
  66. https://rubikscode.net/2018/04/30/philosophy-as-motivational-tool-for-software-crafters-series/
  67. https://rubikscode.net/2018/04/23/how-to-use-miyamoto-musashis-philosophy-to-become-better-software-crafter/
  68. https://rubikscode.net/2017/11/06/how-to-use-marcus-aureliuss-meditations-to-become-better-software-craftsman/
  69. https://rubikscode.net/2017/06/22/   how-to-use-friedrich-nietzsches-philosophy-to-be-better-software-craftsman/
  70. https://rubikscode.net/2017/05/14/how-to-use-art-of-war-to-be-better-software-craftsman/
  71. https://rubikscode.net/category/ai/
  72. https://rubikscode.net/category/machine-learning/
  73. https://rubikscode.net/category/net/
  74. https://rubikscode.net/category/python/
  75. https://rubikscode.net/category/nosql/
  76. https://rubikscode.net/about/
  77. https://rubikscode.net/contact/
  78. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/
  79. https://rubikscode.net/author/rubikscode/
  80. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/#comments
  81. https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/
  82. https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/
  83. https://rubikscode.net/2018/02/05/introduction-to-tensorflow-with-python-example/
  84. https://rubikscode.net/2018/02/12/implementing-simple-neural-network-using-keras-with-python-example/
  85. http://rubikscode.net/2018/02/19/artificial-neural-networks-series/
  86. http://rubikscode.net/2018/02/05/introduction-to-tensorflow-with-python-example/
  87. http://rubikscode.net/2018/02/12/implementing-simple-neural-network-using-keras-with-python-example/
  88. https://rubikscode.net/2017/11/06/how-to-use-marcus-aureliuss-meditations-to-become-better-software-craftsman/
  89. http://ai.stanford.edu/~amaas/data/sentiment/
  90. https://rubikscode.net/2018/02/12/implementing-simple-neural-network-using-keras-with-python-example/
  91. https://rubikscode.net/2018/03/05/implementation-of-convolutional-neural-network-using-python-and-keras/
  92. https://rubikscode.net/2018/02/19/artificial-neural-networks-series/
  93. http://rubikscode.net/2018/02/19/artificial-neural-networks-series/
  94. https://rubikscode.net/
  95. https://www.codeproject.com/
  96. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/?share=twitter
  97. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/?share=facebook
  98. https://rubikscode.net/category/ai/
  99. https://rubikscode.net/tag/ai/
 100. https://rubikscode.net/tag/artificaial-inteligance/
 101. https://rubikscode.net/tag/artificial-neural-networks/
 102. https://rubikscode.net/tag/deep-learning/
 103. https://rubikscode.net/tag/lstm/
 104. https://rubikscode.net/tag/lstms/
 105. https://rubikscode.net/tag/machine-learning/
 106. https://rubikscode.net/tag/neural-networks/
 107. https://rubikscode.net/tag/software-development/
 108. https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/
 109. https://rubikscode.net/2018/04/02/exploring-dependency-injection-principle-in-c-part-1/
 110. https://www.alvinashcraft.com/2018/03/26/dew-drop-march-26-2018-2691/
 111. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/#respond
 112. https://jetpack.wordpress.com/jetpack-comment/?blogid=128253944&postid=8056&comment_registration=0&require_name_email=1&stc_enabled=1&stb_enabled=1&show_avatars=1&avatar_default=identicon&greeting=leave+a+reply&greeting_reply=leave+a+reply+to+%s&color_scheme=light&lang=en_us&jetpack_version=7.2.1&show_cookie_consent=10&has_cookie_consent=0&sig=7ef2e0a9467316f44986e7bb95c88de0cccceffa#parent=https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/
 113. https://akismet.com/privacy/
 114. https://www.linkedin.com/in/nmzivkovic/
 115. https://twitter.com/nmzivkovic
 116. https://github.com/nmzivkovic
 117. https://www.facebook.com/rubikscodenet
 118. https://automattic.com/cookies/
 119. https://www.packtpub.com/application-development/introducing-test-driven-development-c-video
 120. https://www.packtpub.com/application-development/test-driven-development-c-and-net-core-mvc-video
 121. https://www.packtpub.com/big-data-and-business-intelligence/real-world-machine-learning-projects-scikit-learn-video
 122. https://rubikscode.net/2018/02/19/artificial-neural-networks-series/
 123. https://rubikscode.net/2018/07/23/machine-learning-with-ml-net-series/
 124. https://rubikscode.net/2018/08/06/asynchronous-programming-in-net/
 125. https://rubikscode.net/2017/10/16/mongodb-serial/
 126. https://rubikscode.net/2018/04/30/philosophy-as-motivational-tool-for-software-crafters-series/
 127. https://rubikscode.net/about/
 128. https://rubikscode.net/contact/
 129. https://www.linkedin.com/in/nmzivkovic/
 130. https://twitter.com/nmzivkovic?lang=en
 131. https://github.com/nmzivkovic
 132. https://www.facebook.com/rubikscodenet/
 133. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914

   hidden links:
 135. https://rubikscode.net/
 136. https://www.packtpub.com/application-development/introducing-test-driven-development-c-video
 137. https://www.packtpub.com/application-development/test-driven-development-c-and-net-core-mvc-video
 138. https://www.packtpub.com/big-data-and-business-intelligence/real-world-machine-learning-projects-scikit-learn-video
