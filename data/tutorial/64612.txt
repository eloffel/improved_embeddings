   #[1]rubik's code    feed [2]rubik's code    comments feed [3]rubik's code
      common neural network id180 comments feed [4]alternate
   [5]alternate

   [6]skip to content

     * [7]linkedin
     * [8]twitter
     * [9]git
     * [10]fb

   [11]rubik's code

   machine learning without tears

     * products
          + [12]introducing test driven development in c#     video course
          + [13]test driven development with c# and .net core mvc     video
            course
          + [14]real-world machine learning projects with sci-kit learn
     * [15]articles
     * [16]series
          + [17]id158s series
               o [18]introduction to id158s
               o [19]common neural network id180
               o [20]how do id158s learn?
               o [21]id26 algorithm in artificial neural
                 networks
               o [22]implementing simple neural network in c#
               o [23]introduction to tensorflow     with python example
               o [24]implementing simple neural network using keras     with
                 python example
               o [25]introduction to convolutional neural networks
               o [26]implementation of convolutional neural network using
                 python and keras
               o [27]introduction to recurrent neural networks
               o [28]understanding id137 (lstms)
               o [29]two ways to implement lstm network using python    
                 with tensorflow and keras
          + [30]gan series
               o [31]introduction to id3
                 (gans)
               o [32]implementing gan & dcgan with python
               o [33]introduction to adversarial autoencoders
               o [34]generating images using adversarial autoencoders and
                 python
               o [35]implementing cyclegan using python
               o [36]introduction to cyclegan
          + [37]machine learning with ml.net
               o [38]ultimate guide to machine learning with ml.net
               o [39]using ml.net     introduction to machine learning and
                 ml.net
               o [40]machine learning with ml.net     solving real-world
                 regression problem (bike sharing demands)
               o [41]machine learning with ml.net     solving real-world
                 classification problem (wine quality)
               o [42]machine learning in ml.net     using machine learning
                 model in asp.net core application
               o [43]machine learning with ml.net     comparing data
                 exploration in python with data exploration in ml.net
          + [44]asynchronous programming in .net
               o [45]motivation and unit testing
               o [46]common mistakes and best practices
               o [47]task-based asynchronous pattern (tap)
               o [48]benefits and tradeoffs of using valuetask
          + [49]self- organizing maps series
               o [50]introduction to self-organizing maps
               o [51]implementing self-organizing maps with python and
                 tensorflow
               o [52]implementing self-organizing maps with .net core
               o [53]credit card fraud detection using self-organizing
                 maps and python
          + [54]restricted id82 series
               o [55]introduction to restricted id82s
               o [56]implementing restricted id82 with python
                 and tensorflow
               o [57]implementing restricted id82 with .net
                 core
               o [58]generate music using tensorflow and python
          + [59]mongodb series
               o [60]introduction to nosql and polyglot persistence
               o [61]mongodb basics     part 1.
               o [62]mongo db basics     part 2.
               o [63]using mongodb in c#
               o [64]mean stack crash course     using mongodb with node.js,
                 express and angular 4
               o [65]serverless and playing around with mongodb atlas
          + [66]philosophy as motivational tool for software crafters
            series
               o [67]how to use miyamoto musashi   s philosophy to become
                 better software crafter
               o [68]how to use marcus aurelius   s meditations to become
                 better software crafter
               o [69]   how to use friedrich nietzsche   s philosophy to be
                 better software crafter
               o [70]how to use    art of war    to be better software crafter
     * categories
          + [71]ai
          + [72]machine learning
          + [73].net
          + [74]python
          + [75]nosql
     * [76]about
     * [77]contact

   (button) open a search box close a search box search for:
   ____________________ (button) search

common neural network id180

   [78]november 20, 2017february 26, 2018 by [79]rubikscode [80]5 comments

   in the [81]previous article, i was talking about what neural networks
   are and how they are trying to imitate biological neural system. also,
   the structure of the neuron, smallest building unit of these networks,
   was presented. neurons have this simple structure, and one might say
   that they alone are useless. nevertheless, when they are connected with
   each other, they become a powerful tool. something like a bee and a
   hive. bee cannot produce that much honey alone, but thanks to the
   effort of many bees working together, you have honey in your kitchen.

   as a little reminder, let   s run through neuron   s structure. basically,
   they have these connections, which simulate synapses of a biological
   neuron. connections are the input of every neuron, and they are
   weighted, meaning that some connections are more important than others.
   in a nutshell, neurons are some kind of input collectors. also, they
   have an output, which is activated when certain criteria are met.
   usually, input from weighted connections is summarized, which is done
   by so-called weighted sum function. this value is then passed to
   the activation function, which calculates the value of the output. you
   can read more about this in [82]previous article.

   [i2wpfnw.png?w=720&#038;ssl=1]

   now, i would like to dive a little bit more into one aspect of an
   artificial neuron. that aspect is activation function itself, and what
   are the predominant id180 out there. why? well,
   activation function is a very important factor in this game. because,
   by using the right functions, neural networks can compute nontrivial
   problems by using only a small number of nodes. so, let   s dive into it.

activation function

   as mentioned before, this function will define the output value of our
   artificial neuron, i.e., is that neuron    activated    or not.
   biologically speaking, this function can be modeled as the expected
   firing rate of the total input currently arising out of incoming
   signals at synapses. apart from that, this function in global will
   define how    smart    our neural network is, and how hard it will be to
   train it. since these networks are biologically inspired, one of the
   first id180 that was ever used was the step function,
   also known as the [83]id88.

id88

   this activation function has an interesting piece of history attached
   to it. this algorithm was first used back in 1957 in the custom-made
   computer called mark 1 id88, and was used for image
   recognition. it was considered the future of artificial intelligence
   during the first expansion of the field. even the author of the
   algorithm     frank rosenblatt said that id88 is    the embryo of an
   electronic computer that [the navy] expects will be able to walk, talk,
   see, write, reproduce itself and be conscious of its existence.   
   although it seemed promising in the begging, it was proved that
   id88 was not able to recognize many classes of patterns. this
   caused the field of neural networks to stagnate for a while.

   [czkamwd.png?resize=354%2c229&#038;ssl=1]

   in its essence, id88 is a step function, that maps its
   real-valued vector input to a single binary output value. so, if the
   summed value of the input reaches the certain threshold, the value on
   the neuron   s output will be     1, otherwise will be     0. very
   straightforward and especially useful in the last layer of a network.

sigmoid function

   this function is smoother and more biologically plausible than a simple
   step function. consider that one neuron gets fired, meaning that it
   starts sending neurotransmitters through the synapses to another
   neuron. this will happen gradually over time and it will take some time
   to pass all neurotransmitters. this is, of course, a very simplified
   description of that scenario. the sigmoid function looks like:

   [rdxtkxz.gif?resize=355%2c227&#038;ssl=1]

   when using this function, we are calculating neuron   s output value
   using the formula:

   [jeaqrs4.png?w=720&#038;ssl=1]

   where x is network input of the neuron. basically, the weighted input
   is multiplied by a slope parameter. this function is heavily used
   for [84]id75     one of the most well-known algorithms in
   statistics and machine learning. this function is also heavily used for
   the output layer of the neural network, especially for id203
   calculations.

hyperbolic tangent function

   this function is similar to the sigmoid function. output values of this
   function can variate from -1 to 1, indifference to the sigmoid function
   which covers values from 0 to 1. although this is not what happens in
   the neurons, biologically wise, this function gives better results when
   it comes to training neural networks. sometimes, neural networks get
      stuck    during training when the sigmoid function, meaning that when
   provided with input that is strongly-negative, the output of these
   networks very near zero. this in turns messes up the learning process,
   that will be more covered in next posts. nevertheless, this is how
   hyperbolic tangent function looks like:

   [634nfro.gif?resize=355%2c230&#038;ssl=1]

   the formula that we are using is tahn(x), where x is network input of
   the neuron. it is used for the same purposes as the sigmoid function,
   but in networks that have negative inputs. what is interesting to
   notice here is how this function gives better results in some cases
   even though it doesn   t have strong biological interpretation.

rectifier function

   rectifier function is probably the most popular activation function in
   the world of neural networks. it is heavily used to solve all kind of
   problems out there and for a good reason. this function is most
   biologically plausible of all functions described so far, and the most
   efficient function when it comes to training neural networks. here is
   how it looks like:

   [dycbpcq.png?resize=358%2c203&#038;ssl=1]

   the formula that we are using is max(0, x), where x is network input of
   the neuron. this is one of the reasons this function is so efficient
   because they don   t require id172 or other complicated
   calculations.

conclusion

   in this article, we reviewed a few most popular id180 in
   neural networks. note that there are also many other options for
   id180 not covered here, that might be the right choice
   for your specific problem. however, these basic id180
   covered here can be used to solve a majority of the problems one will
   likely face. do you have a favorite activation function?
     __________________________________________________________________

   this article is a part of  id158s series, which you
   can check out [85]here.
     __________________________________________________________________

   read more posts from the author at [86]rubik   s code.
     __________________________________________________________________

   [87]codeproject

share:

     * [88]click to share on twitter (opens in new window)
     * [89]click to share on facebook (opens in new window)
     *

like this:

   like loading...

   posted in: [90]ai
   tagged: [91]ai [92]artificaial inteligance [93]artificial neural
   networks [94]software development

post navigation

   previous entry:[95]introduction to id158s
   next entry:[96]how do id158s learn?

5 comments

    1. pingback: [97]dew drop - november 20, 2017 (#2607) - morning dew
    2.
   [98]david says:
       [99]january 24, 2018 at 11:12 pm
       why is the rectifier function said to be the most biologically
       plausible of these functions?
       loading...
       [100]reply
         1.
        [101]rubikscode says:
            [102]january 25, 2018 at 8:05 am
            good question     
            when we use rectifier function, during the training process,
            our network will easily remove unnecessary connections (by
            setting their weights to 0). this way we will have only useful
            connections. this is something which would happen in nature,
            ie. it has more biological plausibility.
            thanks for reading.
            loading...
            [103]reply
    3. pingback: [104]introduction to convolutional neural networks    
       developparadise
    4. pingback: [105]id158s series     deep in thought

leave a reply [106]cancel reply

   iframe: [107]jetpack_remote_comment

   this site uses akismet to reduce spam. [108]learn how your comment data
   is processed.

subscribe to rubik's code via email

   email address ____________________

   (button) subscribe

video courses

     * introducing test driven development in c#
     * test driven development with c# and .net core mvc
     * real-world machine learning projects with scikit-learn

follow rubik   s code

     * [109]linkedin
     * [110]twitter
     * [111]github
     * [112]facebook

   close and accept
   privacy & cookies: this site uses cookies. by continuing to use this
   website, you agree to their use.
   to find out more, including how to control cookies, see here: [113]info

   (button) go to the top

products

     * [114]introducing test driven development in c#
     * [115]test driven development with c# and .net core mvc
     * [116]real-world machine learning projects with sci-kit learn

series

     * [117]id158s series
     * [118]machine learning with ml.net series
     * [119]asynchronous programming in .net series
     * [120]mongodb series
     * [121]philosophy as motivational tool for software crafters series

rubik   s code

     * [122]about
     * [123]contact

     * [124]linkedin
     * [125]twitter
     * [126]git
     * [127]fb

   iframe: [128]likes-master

   %d bloggers like this:

references

   visible links
   1. https://rubikscode.net/feed/
   2. https://rubikscode.net/comments/feed/
   3. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/feed/
   4. https://rubikscode.net/wp-json/oembed/1.0/embed?url=https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/
   5. https://rubikscode.net/wp-json/oembed/1.0/embed?url=https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/&format=xml
   6. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/#content
   7. https://www.linkedin.com/in/nmzivkovic/
   8. https://twitter.com/nmzivkovic?lang=en
   9. https://github.com/nmzivkovic
  10. https://www.facebook.com/rubikscodenet/
  11. https://rubikscode.net/
  12. https://www.packtpub.com/application-development/introducing-test-driven-development-c-video
  13. https://www.packtpub.com/application-development/test-driven-development-c-and-net-core-mvc-video
  14. https://www.packtpub.com/big-data-and-business-intelligence/real-world-machine-learning-projects-scikit-learn-video
  15. https://rubikscode.net/
  16. https://rubikscode.net/category/series/
  17. https://rubikscode.net/2018/02/19/artificial-neural-networks-series/
  18. https://rubikscode.net/2017/11/13/introduction-to-artificial-neural-networks/
  19. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/
  20. https://rubikscode.net/2018/01/15/how-artificial-neural-networks-learn/
  21. https://rubikscode.net/2018/01/22/id26-algorithm-in-artificial-neural-networks/
  22. https://rubikscode.net/2018/01/29/implementing-simple-neural-network-in-c/
  23. https://rubikscode.net/2018/02/05/introduction-to-tensorflow-with-python-example/
  24. https://rubikscode.net/2018/02/12/implementing-simple-neural-network-using-keras-with-python-example/
  25. https://rubikscode.net/2018/02/26/introduction-to-convolutional-neural-networks/
  26. https://rubikscode.net/2018/03/05/implementation-of-convolutional-neural-network-using-python-and-keras/
  27. https://rubikscode.net/2018/03/12/introuduction-to-recurrent-neural-networks/
  28. https://rubikscode.net/2018/03/19/understanding-long-short-term-memory-networks-lstms/
  29. https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/
  30. http://rtrtr.com/
  31. https://rubikscode.net/2018/12/10/introduction-to-generative-adversarial-networks-gans/
  32. https://rubikscode.net/2018/12/17/implementing-gan-dcgan-with-python/
  33. https://rubikscode.net/2019/01/14/introduction-to-adversarial-autoencoders/
  34. https://rubikscode.net/2019/01/21/generating-images-using-adversarial-autoencoders-and-python/
  35. https://rubikscode.net/2019/02/11/implementing-cyclegan-using-python/
  36. https://rubikscode.net/2019/02/04/introduction-to-cyclegan/
  37. https://rubikscode.net/2018/07/23/machine-learning-with-ml-net-series/
  38. https://rubikscode.net/2019/02/18/ultimate-guide-to-machine-learning-with-ml-net/
  39. https://rubikscode.net/2018/06/18/using-ml-net-introduction-to-machine-learning-and-ml-net/
  40. https://rubikscode.net/2018/06/25/machine-learning-with-ml-net-solving-real-world-regression-problem-bike-sharing-demands/
  41. https://rubikscode.net/2018/07/02/machine-learning-with-ml-net-solving-real-world-classification-problem-wine-quality/
  42. https://rubikscode.net/2018/07/09/machine-learning-in-ml-net-using-machine-learning-model-in-asp-net-mvc-application/
  43. https://rubikscode.net/2018/07/16/machine-learning-with-ml-net-comparing-data-exploration-in-python-with-data-exploration-in-ml-net/
  44. https://rubikscode.net/2018/08/06/asynchronous-programming-in-net/
  45. https://rubikscode.net/2018/05/21/asynchronous-programming-in-net-motivation-and-unit-testing/
  46. https://rubikscode.net/2018/05/28/asynchronous-programming-in-net-common-mistakes-and-best-practices/
  47. https://rubikscode.net/2018/06/04/asynchronous-programming-in-net-task-based-asynchronous-pattern-tap/
  48. https://rubikscode.net/2018/06/11/asynchronous-programming-in-net-benefits-and-tradeoffs-of-using-valuetask/
  49. https://rubikscode.net/2018/09/26/self-organizing-maps-series/
  50. https://rubikscode.net/2018/08/20/introduction-to-self-organizing-maps/
  51. https://rubikscode.net/2018/08/27/implementing-self-organizing-maps-with-python-and-tensorflow/
  52. https://rubikscode.net/2018/09/17/implementing-self-organizing-maps-with-net-core/
  53. https://rubikscode.net/2018/09/24/credit-card-fraud-detection-using-self-organizing-maps-and-python/
  54. https://rubikscode.net/2019/01/07/restricted-boltzmann-machine-series/
  55. https://rubikscode.net/2018/10/01/introduction-to-restricted-boltzmann-machines/
  56. https://rubikscode.net/2018/10/22/implementing-restricted-boltzmann-machine-with-python-and-tensorflow/
  57. https://rubikscode.net/2018/10/15/implementing-restricted-boltzmann-machine-with-net-core/
  58. https://rubikscode.net/2018/11/12/generate-music-using-tensorflow-and-python/
  59. https://rubikscode.net/2017/10/16/mongodb-serial/
  60. https://rubikscode.net/2017/07/19/introduction-to-nosql-and-polyglot-persistence/
  61. https://rubikscode.net/2017/07/24/mongo-db-basics-part-1/
  62. https://rubikscode.net/2017/07/31/mongo-db-basics-part-2/
  63. https://rubikscode.net/2017/10/02/using-mongodb-in-c/
  64. https://rubikscode.net/2017/10/09/mean-stack-crash-course-using-mongodb-with-node-js-express-and-angular-4/
  65. https://rubikscode.net/2017/10/15/serverless-and-mongodb-atlas/
  66. https://rubikscode.net/2018/04/30/philosophy-as-motivational-tool-for-software-crafters-series/
  67. https://rubikscode.net/2018/04/23/how-to-use-miyamoto-musashis-philosophy-to-become-better-software-crafter/
  68. https://rubikscode.net/2017/11/06/how-to-use-marcus-aureliuss-meditations-to-become-better-software-craftsman/
  69. https://rubikscode.net/2017/06/22/   how-to-use-friedrich-nietzsches-philosophy-to-be-better-software-craftsman/
  70. https://rubikscode.net/2017/05/14/how-to-use-art-of-war-to-be-better-software-craftsman/
  71. https://rubikscode.net/category/ai/
  72. https://rubikscode.net/category/machine-learning/
  73. https://rubikscode.net/category/net/
  74. https://rubikscode.net/category/python/
  75. https://rubikscode.net/category/nosql/
  76. https://rubikscode.net/about/
  77. https://rubikscode.net/contact/
  78. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/
  79. https://rubikscode.net/author/rubikscode/
  80. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/#comments
  81. https://rubikscode.net/2017/11/13/introduction-to-artificial-neural-networks/
  82. https://rubikscode.net/2017/11/13/introduction-to-artificial-neural-networks/
  83. https://en.wikipedia.org/wiki/id88
  84. https://en.wikipedia.org/wiki/linear_regression
  85. http://rubikscode.net/2018/02/19/artificial-neural-networks-series/
  86. https://rubikscode.net/
  87. https://www.codeproject.com/
  88. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/?share=twitter
  89. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/?share=facebook
  90. https://rubikscode.net/category/ai/
  91. https://rubikscode.net/tag/ai/
  92. https://rubikscode.net/tag/artificaial-inteligance/
  93. https://rubikscode.net/tag/artificial-neural-networks/
  94. https://rubikscode.net/tag/software-development/
  95. https://rubikscode.net/2017/11/13/introduction-to-artificial-neural-networks/
  96. https://rubikscode.net/2018/01/15/how-artificial-neural-networks-learn/
  97. https://www.alvinashcraft.com/2017/11/20/dew-drop-november-20-2017-2607/
  98. https://astudyofthemind.blogspot.com/
  99. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/#comment-486
 100. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/?replytocom=486#respond
 101. http://rubikscode.wordpress.com/
 102. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/#comment-488
 103. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/?replytocom=488#respond
 104. http://devepar.com/archives/2679
 105. http://deepinthought.in/artificial-neural-networks-series
 106. https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/#respond
 107. https://jetpack.wordpress.com/jetpack-comment/?blogid=128253944&postid=7899&comment_registration=0&require_name_email=1&stc_enabled=1&stb_enabled=1&show_avatars=1&avatar_default=identicon&greeting=leave+a+reply&greeting_reply=leave+a+reply+to+%s&color_scheme=light&lang=en_us&jetpack_version=7.2.1&show_cookie_consent=10&has_cookie_consent=0&sig=cf1974c3672507615eac41f8c25a873e02f6a2f3#parent=https://rubikscode.net/2017/11/20/common-neural-network-activation-functions/
 108. https://akismet.com/privacy/
 109. https://www.linkedin.com/in/nmzivkovic/
 110. https://twitter.com/nmzivkovic
 111. https://github.com/nmzivkovic
 112. https://www.facebook.com/rubikscodenet
 113. https://automattic.com/cookies/
 114. https://www.packtpub.com/application-development/introducing-test-driven-development-c-video
 115. https://www.packtpub.com/application-development/test-driven-development-c-and-net-core-mvc-video
 116. https://www.packtpub.com/big-data-and-business-intelligence/real-world-machine-learning-projects-scikit-learn-video
 117. https://rubikscode.net/2018/02/19/artificial-neural-networks-series/
 118. https://rubikscode.net/2018/07/23/machine-learning-with-ml-net-series/
 119. https://rubikscode.net/2018/08/06/asynchronous-programming-in-net/
 120. https://rubikscode.net/2017/10/16/mongodb-serial/
 121. https://rubikscode.net/2018/04/30/philosophy-as-motivational-tool-for-software-crafters-series/
 122. https://rubikscode.net/about/
 123. https://rubikscode.net/contact/
 124. https://www.linkedin.com/in/nmzivkovic/
 125. https://twitter.com/nmzivkovic?lang=en
 126. https://github.com/nmzivkovic
 127. https://www.facebook.com/rubikscodenet/
 128. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914

   hidden links:
 130. https://rubikscode.net/
 131. https://www.packtpub.com/application-development/introducing-test-driven-development-c-video
 132. https://www.packtpub.com/application-development/test-driven-development-c-and-net-core-mvc-video
 133. https://www.packtpub.com/big-data-and-business-intelligence/real-world-machine-learning-projects-scikit-learn-video
