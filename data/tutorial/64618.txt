   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

only numpy: vanilla recurrent neural network deriving back propagation
through time practice         part 1/2

   [16]go to the profile of jae duk seo
   [17]jae duk seo (button) blockedunblock (button) followfollowing
   dec 22, 2017

   so this is my official first educational post in medium, and i have to
   say medium is truly amazing blog platform. anyways here we go. the
   problem is very simple, we are going to use id56 to count how many ones
   there are in the given data. if you just want the video tutorial and
   the code please follow the links below.

   iframe: [18]/media/54f6a9641207ad24ec0bcb719a5ac43d?postid=956fbea32704

   github link:
   [19]https://github.com/jaedukseo/only_numpy_basic/blob/master/id56/a_id56
   _simple.py
     __________________________________________________________________

   [1*pi_aesw5mpff7vsvtg3gva.jpeg]

   as seen above at (a) the training data is x and the test data is y
   (ground truth). (b) we are only going to have two weights, wx (where we
   are going to multiple with the input x) and wrec (where we are going to
   multiple with the previous states)

   it is very important to understand ( c ) since it is our network
   architecture that is the unrolled version of our network architecture.
   however it clearly show that state 0 (denoted as s0) have some
   relationship with state 1(denoted as s1). that relationship is shown
   below!
   [1*w_uhqjq5ncgxb99znataja.jpeg]

   under (e) we can see one equation, that clears up the relation between
   state.

   current_state_k = previous_state k * wrec + current_input_x * wx

   that one line of math is the relationship between state 0 and state 1.
   but what about the numbers below each state? very simple, those are
   inputs at each state, so at state 1 the input x is a vector [0,0,1].t.
   [1*zkeqfveryayy2wza4a5ofw.jpeg]
   same color box indicate inputs at each state

   they you might ask, what about state 0? great question they are all
   zeros!
     __________________________________________________________________

   so lets get dirty with the math         forward feed.
   [1*bqulxubkw7cenlfftj5nha.jpeg]

   that   s it! we are done with forward feed propagation. also, just one
   side note we are going to use mse as cost function, and from now on we
   are only going to denote that cost function as the notation beside the
   star. (sorry i am not math major, i have no idea what that notation is
   called.)
     __________________________________________________________________

   now lets perform back propagation through time. we have to get
   derivative respect to wx and wrec for each state. and that is exactly
   what we have done below!
   [1*gpvrohtouuqbj8zoa7r8fw.jpeg]

   so that   s it! the simple math behind training id56. however, try to fill
   in the state 1 by yourself. but there is one interesting fact to note,
   while getting the derivative respect to wx and wrec, there are lots of
   mathematical symbols that gets repeated overtime, look at the image
   below.
   [1*yajzi_nntjnlreml-jgyjq.jpeg]

   it would be more computationally efficient to get those repeated values
   in a matrix and use them later by just multiplying appropriate x or
   state. and that is exactly what i do in the video tutorial!
   [1*cnusfcxucl6jokov0dzvda.png]
   calculate the repeating terms

   another, important thing to note is that when we get the derivative we
   multiply wrec multiple times, other words that variables plays a key
   role! (i am not going to explain further but this topic is important!)

   and finally, lets perform the weight update via stochastic gradient
   descent.
   [1*19ac-hs6vu9dcp5clipwag.jpeg]

   at the top right corner we are adding up the terms accordingly and
   performing sgd.

   update! here is part 2 : [20]link

   finally, just as a reminder, i used a lot of material from peter!
   please follow the link below to check out the amazing tutorial! and
   this is my first post, i am still learning how to make great tutorials,
   any feedback would be helpful!
   [ plz be nice :   ( ] thanks!
   [21]peter's notes
   notes and code samples about artificial intelligence, machine learning,
   neural networkspeterroelants.github.io

   for more tutorial check out my website and my youtube channel!

   website: [22]https://jaedukseo.me/

   youtube channel: [23]https://www.youtube.com/c/jaedukseo
   [24]jae duk seo - dj seo
   hi, my name is jae, i love machine learning, please come in and have a
   look! personal website for data scientist jae   jaedukseo.me
   [25]jae duk seo
   hello! my name is jae, this is my youtube channel. i like dogs and
   artificial intelligences, healthcare and blockchain   www.youtube.com

     * [26]artificial intelligence
     * [27]id56
     * [28]recurrent neural network
     * [29]id26
     * [30]machine learning

   (button)
   (button)
   (button) 139 claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   [31]go to the profile of jae duk seo

[32]jae duk seo

   [33]https://jaedukseo.me | | | | |your everyday seo, who likes kimchi

     (button) follow
   [34]towards data science

[35]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 139
     * (button)
     *
     *

   [36]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [37]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/956fbea32704
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/only-numpy-vanilla-recurrent-neural-network-back-propagation-practice-math-956fbea32704&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/only-numpy-vanilla-recurrent-neural-network-back-propagation-practice-math-956fbea32704&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_s9tvhlzp16ok---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@seojaeduk?source=post_header_lockup
  17. https://towardsdatascience.com/@seojaeduk
  18. https://towardsdatascience.com/media/54f6a9641207ad24ec0bcb719a5ac43d?postid=956fbea32704
  19. https://github.com/jaedukseo/only_numpy_basic/blob/master/id56/a_id56_simple.py
  20. http://only numpy: vanilla recurrent neural network deriving back propagation through time practice         part 1/2
  21. http://peterroelants.github.io/posts/id56_implementation_part01/#updating-the-parameters
  22. https://jaedukseo.me/
  23. https://www.youtube.com/c/jaedukseo
  24. https://jaedukseo.me/
  25. https://www.youtube.com/channel/ucf5jue1ewgwryw9bjtynv4g/featured?view_as=subscriber
  26. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  27. https://towardsdatascience.com/tagged/id56?source=post
  28. https://towardsdatascience.com/tagged/recurrent-neural-network?source=post
  29. https://towardsdatascience.com/tagged/id26?source=post
  30. https://towardsdatascience.com/tagged/machine-learning?source=post
  31. https://towardsdatascience.com/@seojaeduk?source=footer_card
  32. https://towardsdatascience.com/@seojaeduk
  33. https://jaedukseo.me/
  34. https://towardsdatascience.com/?source=footer_card
  35. https://towardsdatascience.com/?source=footer_card
  36. https://towardsdatascience.com/
  37. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  39. http://peterroelants.github.io/posts/id56_implementation_part01/#updating-the-parameters
  40. https://jaedukseo.me/
  41. https://www.youtube.com/channel/ucf5jue1ewgwryw9bjtynv4g/featured?view_as=subscriber
  42. https://medium.com/p/956fbea32704/share/twitter
  43. https://medium.com/p/956fbea32704/share/facebook
  44. https://medium.com/p/956fbea32704/share/twitter
  45. https://medium.com/p/956fbea32704/share/facebook
