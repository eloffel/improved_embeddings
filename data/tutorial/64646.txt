   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

the variational autoencoder as a two-player game         part i

alice and bob at the autoencoding olympics

   go to the profile of max frenzel
   [16]max frenzel (button) blockedunblock (button) followfollowing
   apr 1, 2018
   [1*4okap-5drfq37q244wojfg.jpeg]
   illustrations by [17]kittyzilla

   [disclaimer: the aim of this article series is to make the basic ideas
   behind id5 and the encoding of natural language as
   accessible as possible, as well as encourage people already familiar
   with them to view them from a new perspective. in order to do so, i
   have made some use of artistic freedom for the sake of a nicer
   narrative, maybe sometimes sacrificing a bit of technical accuracy. i
   advise readers without any technical background to take everything with
   a grain of salt.]

   [18]part ii, [19]part iii

meet alice and bob (and charlie)

   the field of ai, and particularly the sub-field of deep learning, has
   been exploding with progress in the past few years. one particular
   approach, [20]generative models, has been responsible for much of this
   progress.

   an intuitive argument for why generative models are useful on the way
   to real artificial intelligence is that a system that can generate
   realistic data must have gained at least some understanding of the real
   world.

   generative models come in various flavors. one of them is the so called
   [21]variational autoencoder (vae), first introduced by diederik kingma
   and max welling in 2013.

   vaes have many practical applications, and many more are being
   discovered constantly.

   they can be used to compress data, or reconstruct noisy or corrupted
   data. they allow us to smoothly interpolate between real data, e.g.
   taking a photo of one face and then gradually morphing it into another
   face. they allow for sophisticated data manipulation, for example
   realistically varying the hair length on the image of a person, or
   smoothly changing a voice recording from male to female without varying
   any other sound characteristics.

   more subtly, but in practice often of most interest, they can uncover
   hidden concepts and relations in large amounts of unlabelled data. this
   puts them in the class of unsupervised learning algorithms (as opposed
   to supervised algorithms which require labelled data).

   there is also a group of related models that follow very similar
   principles as the vae. the model used for google translate for example
   is one of these. if you understand this series of articles, you are
   basically also ready to understand how google translate works under the
   hood.
     __________________________________________________________________

   there are many great blog posts that explain in technical detail and
   with code how vaes work (e.g. [22]this one and [23]that one), and the
   academic literature is full of countless explanations, applications,
   and extensions to the original idea.

   my goal here is neither to give you the technical understanding to
   actually implement a vae, nor to comment on any particular recent
   development in the field.

   instead i want to provide a new way of viewing what a vae is actually
   doing. a way that i hope is simple enough that you could explain it to
   your grandma or an elementary school student, while at the same time
   not leaving out too much detail or being too fluffy.

   and even if you are an experienced practitioner or researcher in the
   field, i hope that this slightly quirky interpretation can maybe
   stimulate some new creative insights.

   in this three part series, we are first going to explore the
   foundations of autoencoders in part i. in [24]part ii we will take a
   look at why it makes sense to make them variational (and what that even
   means). finally, in [25]part iii we will discover why encoding text is
   particularly challenging. parts i and ii are really just a build-up for
   part iii.

   the basic concepts of (variational) autoencoders have seen extensive
   coverage, from simple introductions all the way to academic papers.
   however, for the concepts in part iii, i have so far not come across
   any good non-academic discussions. i hope this series can fill this gap
   and also teach you a lot of other things along the way.
     __________________________________________________________________

   my own background is in quantum id205. both quantum
   physicists and information theorists love to understand and explain the
   world by boiling complex scenarios down into simple games.

   for example many cryptographic problems can be phrased as a game
   between a sender and a receiver, with a malicious player who acts as an
   eavesdropper. or check out the great little book [26]   q is for quantum   
   by my former phd advisor terry rudolph for many examples of easily
   understandable quantum games.

   having shifted my own research focus from physics to ai, i have spent
   many hours thinking about and working with vaes. given my quantum
   background, the idea of viewing a vae as a game came quite naturally.

   in particular, i see the vae as a two-player cooperative game.

   but before getting into the details of the game, let   s introduce the
   players. meet alice the encoder
   [1*n0_qzv4rolocnks-dmj0kq.jpeg]

   and bob the decoder (not to be confused with bob the builder).
   [1*8pi2xxomv-dbu2c1plk0mg.jpeg]

   alice and bob are very ambitious. their goal is to compete in the newly
   established autoencoding olympics, where the world   s best
   encoder-decoder pairs meet to show off their skills.

   to prepare for the games, alice and bob have enlisted their friend
   charlie the critic, who will be judging the performance of our two
   contestants and act as their coach.
   [1*ihs3jfmcprhmwwy3ics9ug.jpeg]

   now let   s take a look at the rules of the game.

the autoencoding game

   as we will see, the game comes in various flavors and disciplines, each
   with its own set of rules and objectives.

   we will first consider the most simple version of the game, on which
   all later versions will build. in deep learning speak, this simple
   version corresponds to a normal (i.e. non-variational) autoencoder.

   the basic idea is this: alice gets some kind of data, for example an
   image, a text, an audio clip, etc. she then has to communicate this to
   bob, who doesn   t get to look at the data, in a way so that he can
   reconstruct what alice saw or heard.

   charlie (who knows exactly what alice saw) then evaluates how accurate
   bob   s reconstruction was and gives him a score based on his
   performance.

   the goal is for alice and bob to achieve the highest possible score,
   i.e. for bob to perfectly reproduce the data alice was given.

   the catch is that alice and bob are separated from each other and can
   only communicate in a very limited way through a set of special
   devices.

   in particular, alice can   t just directly explain what she saw. the only
   information she can pass on to bob is a bunch of numbers, a    code   .
   [1*tmemxxqxmvnwcnbmnbztlq.jpeg]

   alice needs to encode the data.

   how many numbers she is allowed to send is called the    code dimension   
   or    code size   . in real vaes the code dimension can often be in the
   hundreds. but for simplicity and ease of visualization let us assume it
   is just two. this is not just a simplification for the sake of this
   game, but is also done in practice when people want to visualize the
   code.

   if the code size is two, we can directly intepret the code as an (x,
   y)-coordinate in a two-dimensional coordinate system.

   for this initial version of the game, we will also assume that the data
   alice is shown are photos of cats and dogs. and there is lots of this
   data, which we will call the training data. again for simplicity, let   s
   just say we have one million training images. that   s a fairly average
   to low number for realistic datasets.

   some representative examples could be
   [1*j6wjllichhvwnci2njeqta.jpeg]

   so given one of these images, alice has to enter two numbers into her
   machine, say (2.846, -5.049), and send this code to bob.

   bob now has to try and paint what he thinks alice saw, given nothing
   but those two numbers.

   sounds hard?

   the truth is, it   s much, much worse!

   we all have a notion of what dogs and cats are, what they look like,
   how they behave, in what environment we usually see them, and so on.
   but ai has to start literally from scratch, with no preconception of
   the real world or what images are likely or not.

   it   s as if both bob and alice grew up in an isolated room with their
   eyes closed and are now seeing the real world for the first time,
   through the photos they are shown. they have absolutely no notion of
      dog    or    cat   , and at the beginning of the game, a photo of a cat
   would look to them just as probable and realistic as would random noise
   or an abstract painting.
   [1*6hd_fty4daxnwjwxhyplzq.jpeg]

   they are not even told that the photos contain mostly these things we
   call    cat    and    dog   .

   and the difficulty doesn   t even end there. while alice actually gets to
   look at real photos, bob never sees a real photo. all he ever sees is
   the code coming from alice. he can only make random paintings based on
   these cryptic numbers.

   but this is where the importance of our coach charlie comes in. every
   time bob finishes a painting based on one of alice   s codes, charlie
   compares it with the original and assigns a score to it (the technical
   term for this score is    id168   ). the more accurate, the higher
   the score.
   [1*xz2ueeqlgi7bbtme1r4efw.jpeg]

   and more than just providing a single score to tell bob how good (or
   bad) he was, charlie also tells him which of his decisions contributed
   to this score and how. in technical terms, he provides bob with
      gradients   . based on this information, bob can tweak his process
   towards gaining a higher score next time.

   and because bob knows how alice   s code influenced his process and final
   output, he can also tell alice how to improve her encoding. what kind
   of code he would have liked to get in order to receive a higher score
   in this particular case. for example he could think    number 1 should be
   0.043 smaller, number 2 should be 4.956 larger   .
   [1*f6ujsoo0m4y87qhu_j9kwa.jpeg]

   this is the only communication allowed from bob to alice. we call this
   process    back-propagation    since we start from the final score and then
   work backwards, based on the feedback adjusting the process that lead
   to the score.

   this method of back-propagation currently forms the basis of training
   the majority of deep neural networks, not just vaes or generative
   models.

   while adjusting their process, alice and bob need to be careful not to
   tweak it too much based on a single photo. if they do, they only ever
   become better at the previous image they were given, and then
      overwrite    that progress by over-adjusting to the next one.

   instead they need to make small updates to their process based on each
   feedback, and hope that over time those small adjustments will add up
   to a unique process that gives them a good score across all images, not
   just the current one.

   how much they adjust their process based on the feedback for each
   individual image is determined by what   s called the learning rate. the
   higher the learning rate, the more quickly they adjust their process.
   but if the learning rate is too high, they risk overcompensating for
   each new image.
     __________________________________________________________________

   initially, since alice has never seen real photos and also has no idea
   what codes bob would like, all she can do is send bob random numbers.

   also, bob has no idea what these numbers mean, nor what kind of
   paintings he is expected to produce. literally any painting is as
   likely to him as any other. it   s complete randomness throughout.

   but after producing many random paintings which all get terrible scores
   from charlie, bob starts to notice something.

   when he uses certain colors in the centre of his painting, and others
   on the edge, he gets slightly higher scores. particularly when he
   paints a gray or brown blob in the centre that has two round shapes in
   it, he usually gets a higher average score than if he just paints
   completely at random.
   [1*g-oc_ee5og0srsx6bpjyha.jpeg]

   bob, without having a concept of    fur    or    eyes   , just discovered that
   most of the pictures contain animals with fur, that usually have two
   eyes.

   remember this for later. what might seem like great inital progress
   here will actually come back to haunt alice and bob later in [27]part
   iii when they are trying to encode text.

   also, this approach of completely ignoring alice   s input and just
   painting a brown blob with two circles only gets him so far. he   s stuck
   and can   t increase his score. he needs to start trying to make use of
   alice   s code, which at this point is still random since alice has not
   gotten any useful feedback from bob. he needs to start incorporating
   the code in his creative process and give alice clues to steer her
   encoding in the right direction.

   the process that ensues is a joint effort between alice and bob. bob
   first learns what images are at all realistic or likely, and alice,
   aided by bob   s feedback, can then steer him in the right direction for
   a given input. without bob having a knowledge of the world, like at the
   beginning of the game, she would literally have to specify every single
   pixel of the image for him. later she can get away with much less
   information (cat or dog? brown or gray? sitting, standing, or running?
   etc.)
     __________________________________________________________________

   as a short aside on data compression, let us consider a trivial version
   of the game. in this version the code dimension is exactly the same as
   the number of pixels of the image.

   with a machine that has as many input slots as the image has pixels,
   alice can simply transfer the exact image through the machine.
   (assuming it   s black and white. for a color photo we actually need
   three times the number of pixels, to encode the red, green, and blue
   values for every pixel.)

   bob simply needs to paint each pixel exactly as alice instructs him and
   can get an absolute perfect replica, 100% of the time.

   a slightly less trivial version is where the code size is half the
   number of pixels.

   alice can now learn to specify every second pixel, a downsampled
   version of the photo. bob just needs to fill in the remaining pixels.
   assuming he has a good notion of how the real world looks, this becomes
   a fairly trivial task. the images won   t all be 100% accurate, but close
   enough.

   but alice and bob won   t get away with this    pixel encoding    forever. as
   the code size gets smaller, say down to two like in our original game,
   they have to change their strategy if they want to have any hope of
   being successful.
   [1*cido99-k6pdy5w0fj7ga7a.jpeg]

   instead of encoding pixels, they need to come up with a smarter, more
      information dense    code. a code that captures more abstract concepts,
   like what animal, what pose, what camera angle, etc.

   this is the basis of data compression. the more we want to compress a
   piece of data, the more efficient a code we need to devise (and the
   more we risk it not being reconstructed completely faithfully).

   the trick is to break down complex information into a few concepts that
   are as simple and universal as possible, but still allow for a fairly
   faithful reconstruction.
     __________________________________________________________________

   back to our original game, alice and bob have now played for a while
   (and i really mean a long while), and have played the game with each of
   the photos in the training dataset maybe ten times or so. bob has
   become a prolific painter, having painted millions of paintings, and
   alice has become an expert information encoder and learned to provide
   bob with codes that help him figure out what photo she saw.

   bob   s idea of the real world has dramatically improved compared to the
   original randomness.
   [1*javw6onidwzypt4yxaezaa.jpeg]

   however, note that alice and bob only know things they have encountered
   in their training images. another animal will be almost as unlikely to
   them as random noise (although they might for example find such
   concepts as eyes, legs, and fur familiar from their cat/dog centred
   worldview).

   alice and bob have become pretty good at the game and start scoring
   fairly high.

the learned code

   let   s take a brief look at the kind of code alice might have figured
   out during training.

   since the code consists of two numbers, we can easily visualize them as
   x- and y-coordinates in a plane.

   in one possible code, alice could have decided to use a negative
   x-value for cats and a positive one for dogs. the y-axis could have
   been used for fur color. positive values being darker, negative ones
   lighter.
   [1*r43altberj4y0xplj_qygg.jpeg]

   with this code, if alice gets a photo of an extremely    dogly    black
   dog, she would send bob two large positive numbers. if she sees an
   extremely    catly    white cat, she sends two large negative numbers. for
   a photo where she   s barely sure if it   s a dog or a cat, and the fur
   color is of medium darkness, she sends two values close to zero. and so
   on.

   if bob has learned that this is the code alice is using, it will allow
   him to make much better guesses for his paintings.

   however, while being a huge improvement over completely random
   paintings, his new paintings will still contain a lot of randomness and
   guessing. he knows if it   s a cat or a dog and how dark the fur is, but
   there is a lot of information this particular encoding cannot transmit.

   for example, bob has no idea what the fur length and pattern are, what
   pose the animal is in and in which part of the image, what   s in the
   background, what is the lighting of the scene, ...

   he needs much more information to fully specify the problem. that   s why
   real neural networks usually tend to learn very complicated codes that
   in most cases don   t have an easy human interpretation of the axes. that
   way they can cram much more information into these two numbers.

   if you think about it, there is really lots of info in an a simple
   image. if you are asked to look for cats or dogs you will view images
   in a particular way, very binary. cat or dog?

   if you   re on the other hand asked if the cats or dogs are in an urban
   or natural scence you   ll consider the images very differently. alice
   and bob are not asked to look for anything specific. they don   t have
   this human context. they only know the task of reconstructing the
   entire image.

   however, as they learn, they might naturally figure out concepts like
      dog    and    cat   . but there is also a large chance that an ai will come
   up with concepts that are completely meaningless to us humans. concepts
   that are much more abstract and    efficient   .

   so if alice and bob are playing for long enough, they will eventually
   agree on one of these more complicated codes that capture highly
   abstract and efficient concepts.

   seems like they mastered the game, right?

what happens if alice and bob get too    smart   

   well, not so fast. they need to be careful. there is a risk of becoming
      too good   .

   alice and bob, with the help of charlie, are currently training for the
   autoencoding olympics. during training they practice with the same set
   of photos over and over again.

   but the photos that will be used at the olympics are a well kept
   secret. they won   t see them until they actually get to do them at
   competition time.

   at that point, they might realize they are in trouble.

   instead of understanding the    general world of dog and cat photos   ,
   they just learned to perfectly memorize all the photos in their
   training set.

   it turns out they actually did not discover any of the concepts we
   discussed in the previous section. they basically just figured out a
   way to cheat to get a perfect score on their training images, without
   actually having any real understanding.
   [1*bj8bcabyauwltn-c-mynfg.jpeg]

   this problem, extremely common in all of deep learning, is known as
   overfitting.

   much like a student who steals the answers to a test and then memorizes
   those instead of actually studying the subject, alice and bob, once
   overfitting sets in, are 100% confident on examples they have
   encountered, but have absolutely no clue about anything else.
     __________________________________________________________________

   taking this to the extreme, if alice and bob are very    smart   , have
   large memory, and are allowed to train for a very long time, they can
   actually learn to perfectly encode any image in their training dataset
   into even just a single number, no matter how many images there are.

   how could they do this?

   there are an infinite number of codes that would allow them to do this,
   but let   s consider a particularly simple on.

   we earlier assumed that there are exactly one million training images.
   given that knowledge, they could just agree to encode them starting
   with 0.000001 for the first one, 0.000002 for the second, and so on up
   to 1.000000 for the millionth one. for each image, they simply decide
   on a unique code number.

   in this code, consecutively numbered images are very close in terms of
   their code, but the images don   t have to be similar in the least. image
   156 could be a black dog playing with a ball in a living room, and
   image 157 could be a white cat chasing a mouse through grass.

   whenever alice sees image 156, she just sends 0.000156. and bob has
   learned exactly what he needs to paint to get a perfect score. and
   similarly he has figured out what exactly to paint when he sees
   0.000157 flashing up on his machine.

   they get a perfect score, 100% of the time.

   but if bob sees 0.0001565? or -0.000001? or 1.000001?

   absolutely no idea.

   similarly if alice is suddenly shown a new image that she never
   encountered before, how would she fit that into the existing code so
   that bob could make an informed guess straight away?

   again, absolutely no idea.

   this is not learning or understanding. it   s pure memorization.

   every little change, every tiny unfamiliarity, completely throws them
   off.
   [1*fdvwcn7c-gpcrpcl_sr6cg.jpeg]

   we need to prevent them from reaching this stage, instead enforcing
   understanding.

   if done correctly, they might still to some extent remember examples
   they previously encountered, but also have learned general principles
   that allow them to reason about things they haven   t previously seen.

   this is called generalization, and is one of the core criteria for
   almost any deep learning algorithm.

   one way to prevent the problem, which is the approach people used to
   take for a long time (and are still using jointly with more
   sophisticated approaches), is simply to stop the training early, before
   a basic understanding gives way to memorization.

   but in the case of autoencoders, there is a better way of ensuring
   actual understanding and meaningful codes.
     __________________________________________________________________

   in [28]part ii, we will take a look at how alice and bob deal with
   their defeat, and see how a new training method, using so called
   variational machines, can help them improve their performance and come
   up with meaningful codes that generalize to previously unseen data.
     __________________________________________________________________

   iframe: [29]/media/2ce0a7875499acd621c2e04c2242351f?postid=4c3737f0987b

     * [30]artificial intelligence
     * [31]deep learning
     * [32]machine learning
     * [33]nlp
     * [34]towards data science

   (button)
   (button)
   (button) 2k claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of max frenzel

[35]max frenzel

   medium member since apr 2018

   things i   ve read, thoughts i   ve had. ai researcher by day, writer and
   beatmaker by night.

     (button) follow
   [36]towards data science

[37]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 2k
     * (button)
     *
     *

   [38]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [39]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/4c3737f0987b
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-i-4c3737f0987b&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-i-4c3737f0987b&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_v2y87dhppwab---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@maxfrenzel
  17. https://kittyzilla.tokyo/
  18. https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-ii-b80d48512f46
  19. https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-iii-d8d56c301600
  20. https://blog.openai.com/generative-models/
  21. https://arxiv.org/abs/1312.6114
  22. http://kvfrans.com/variational-autoencoders-explained/
  23. http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html
  24. https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-ii-b80d48512f46
  25. https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-iii-d8d56c301600
  26. https://www.amazon.com/q-quantum-terry-rudolph/dp/0999063502/
  27. https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-iii-d8d56c301600
  28. https://towardsdatascience.com/the-variational-autoencoder-as-a-two-player-game-part-ii-b80d48512f46
  29. https://towardsdatascience.com/media/2ce0a7875499acd621c2e04c2242351f?postid=4c3737f0987b
  30. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  31. https://towardsdatascience.com/tagged/deep-learning?source=post
  32. https://towardsdatascience.com/tagged/machine-learning?source=post
  33. https://towardsdatascience.com/tagged/nlp?source=post
  34. https://towardsdatascience.com/tagged/towards-data-science?source=post
  35. https://towardsdatascience.com/@maxfrenzel
  36. https://towardsdatascience.com/?source=footer_card
  37. https://towardsdatascience.com/?source=footer_card
  38. https://towardsdatascience.com/
  39. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  41. https://towardsdatascience.com/@maxfrenzel?source=post_header_lockup
  42. https://medium.com/p/4c3737f0987b/share/twitter
  43. https://medium.com/p/4c3737f0987b/share/facebook
  44. https://towardsdatascience.com/@maxfrenzel?source=footer_card
  45. https://medium.com/p/4c3737f0987b/share/twitter
  46. https://medium.com/p/4c3737f0987b/share/facebook
