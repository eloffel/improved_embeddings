   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]ai society
   [7]ai society
   [8]sign in[9]get started
     __________________________________________________________________

gans from scratch 1: a deep introduction. with code in pytorch and tensorflow

   [10]go to the profile of diego gomez mosquera
   [11]diego gomez mosquera (button) blockedunblock (button)
   followfollowing
   feb 1, 2018

        the coolest idea in deep learning in the last 20 years.            yann
     lecun on gans.

     * [12]tl;dr #showmethecode

   in this blog post we will explore id3
   (gans). if you haven   t heard of them before, this is your opportunity
   to learn all of what you   ve been missing out until now. if you   re not
   familiar with gans, they   ve been hype during the last few years,
   specially the last semester. though they   ve existed since 2014, gans
   have already become widely known for their application versatility and
   their outstanding results in generating data.

   they have been used in real-life applications for text/image/video
   generation, drug discovery and text-to-image synthesis. just to give
   you an idea of their potential, here   s a short list of incredible
   projects created with gans that you should definitely check out:
   [1*nke_kwzoefrelghh06sbuw.jpeg]
   image-to-image translation using gans.
     * [13]ai generates fake celebrity faces ([14]paper)
     * [15]ai learns fashion sense ([16]paper)
     * [17]image to image translation using cycle-consistent adversarial
       neural networks
     * [18]ai creates modern art ([19]paper)
     * [20]this deep learning ai generated thousands of creepy cat
       pictures
     * [21]mit is using ai to create pure horror
     * [22]amazon   s new algorithm designs clothing by analyzing a bunch of
       pictures
     * [23]ai creates photo-realistic images ([24]paper)
     __________________________________________________________________

   in this blog post we   ll start by describing generative algorithms and
   why gans are becoming increasingly relevant. an overview and a detailed
   explanation on how and why gans work will follow. finally, we   ll be
   programming a vanilla gan, which is the [25]first gan model ever
   proposed! feel free to read this blog in the order you like.

   for demonstration purposes we   ll be using pytorch, although a
   tensorflow implementation can also be found in my github repo
   [26]diegoalejogm/gans. you can check out some of the advanced gan
   models (e.g. dcgan) in the same github repository if you   re interested,
   which by the way will also be explained in the series of posts that i   m
   starting, so make sure to stay tuned.
   [1*xo7aefzfj1sxqssq0y8j6q.gif]
   output of a gan through time, learning to create hand-written digits.
   we   ll code this example!

1. introduction

   [27]id3 (or gans for short) are one of the
   most popular machine learning algorithms developed in recent times.

   for those new to the field of artificial intelligence (ai), we can
   briefly describe machine learning (ml) as the sub-field of ai that uses
   data to    teach    a machine/program how to perform a new task. a simple
   example of this would be using images of a person   s face as input to
   the algorithm, so that a program learns to recognize that same person
   in any given picture (it   ll probably need negative samples too). for
   this purpose, we can describe machine learning as applied mathematical
   optimization, where an algorithm can represent data (e.g. a picture) in
   a multi-dimensional space (remember the cartesian plane? that   s a 2
   dimensional field), and then learns to distinguish new
   multi-dimensional vector samples as belonging to the target
   distribution or not. for a visual understanding on how machines learn i
   recommend this [28]broad video explanation and this other video on
   [29]the rise of machines, which i were very fun to watch. though this
   is a very fascinating field to explore and discuss, i   ll leave the
   in-depth explanation for a later post, we   re here for gans!
   [1*xwzif0xi1oexk5jbe75-xg.png]
   google trend   s interest over time for term    generative adversarial
   networks   

what   s so magic about gans?

   in short, they belong to the set of algorithms named [30]generative
   models. these algorithms belong to the field of [31]unsupervised
   learning, a sub-set of ml which aims to study algorithms that learn the
   underlying structure of the given data, without specifying a target
   value. generative models learn the intrinsic distribution function of
   the input data p(x) (or p(x,y) if there are multiple targets/classes in
   the dataset), allowing them to generate both synthetic inputs x    and
   outputs/targets y   , typically given some [32]hidden parameters.

   in contrast, [33]supervised learning algorithms learn to map a function
   y   =f(x), given labeled data y. an example of this would be
   classification, where one could use customer purchase data (x) and the
   customer respective age (y) to classify new customers. most of the
   supervised learning algorithms are inherently discriminative, which
   means they learn how to model the id155 distribution
   function (p.d.f) p(y|x) instead, which is the id203 of a target
   (age=35) given an input (purchase=milk). despite the fact that one
   could make predictions with this p.d.f, one is not allowed to sample
   new instances (simulate customers with ages) from the input
   distribution directly.
   side-note: it is possible to use discriminative algorithms which are
   not probabilistic, they are called discriminative functions.

   gans they have proven to be really succesfull in modeling and
   generating high dimensional data, which is why they   ve become so
   popular. nevertheless they are not the only types of generative models,
   others include id5 ([34]vaes) and
   [35]pixelid98/[36]pixelid56 and [37]real nvp. each model has its own
   tradeoffs.

   some of the most relevant gan pros and cons for the are:
     * they currently generate the sharpest images
     * they are easy to train (since no statistical id136 is
       required), and only back-propogation is needed to obtain gradients
     * gans are difficult to optimize due to unstable training dynamics.
     * no statistical id136 can be done with them ([38]except here):
       gans belong to the class of direct implicit density models; they
       model p(x) without explicitly defining the p.d.f.

so.. why generative models?

   generative models are one of the most promising approaches to
   understand the vast amount of data that surrounds us nowadays.
   according to [39]openai, algorithms which are able to create data might
   be substantially better at understanding intrinsically the world. the
   idea that generative models hold a better potential at solving our
   problems can be illustrated using the quote of one of my favourite
   physicists.

        what i cannot create, i do not understand.            richard p. feynman

   (i strongly suggest reading his book [40]   surely you   re joking mr.
   feynman   )

   generative models can be thought as containing more information than
   their discriminative counterpart/complement, since they also be used
   for discriminative tasks such as classification or regression (where
   the target is a continuous value such as    ). one could calculate the
   conditional p.d.f p(y|x) needed most of the times for such tasks, by
   using statistical id136 on the joint p.d.f. p(x,y) if it is
   available in the generative model.

   though generative models work for classification and regression, fully
   discriminative approaches are usually more successful at discriminative
   tasks in comparison to generative approaches [41]in some scenarios.

use cases

   among several use cases, generative models may be applied to:
     * generating realistic artwork samples (video/image/audio).
     * [42]simulation and planning using time-series data.
     * statistical id136.
     * machine learning engineers and scientists reading this article may
       have already realized that generative models can also be used to
       generate inputs which may expand small datasets.

   i also found a very long and interesting curated list of awesome gan
   applications [43]here.

2. understanding a gan: overview

   [1*5rmmuxmaqugtt-odw-bopw.jpeg]
   global concept of a gan. [44]source link

   id3 are composed of two models:
     * the first model is called a generator and it aims to generate new
       data similar to the expected one. the generator could be asimilated
       to a human art forger, which creates fake works of art.
     * the second model is named the discriminator. this model   s goal is
       to recognize if an input data is    real            belongs to the original
       dataset         or if it is    fake            generated by a forger. in this
       scenario, a discriminator is analogous to the police (or an art
       expert), which tries to detect artworks as truthful or fraud.

   how do these models interact?[45] id141 the original paper which
   proposed this framework, it can be thought of the generator as having
   an adversary, the discriminator. the generator (forger) needs to learn
   how to create data in such a way that the discriminator isn   t able to
   distinguish it as fake anymore. the competition between these two teams
   is what improves their knowledge, until the generator succeeds in
   creating realistic data.

mathematically modeling a gan

   # talk about x and z, with their respective distributions

   though the gans framework could be applied to any two models that
   perform the tasks described above, it is easier to understand when
   using [46]universal approximators such as [47]artificial neural
   networks.

   a neural network g(z,      ) is used to model the generator mentioned
   above. it   s role is mapping input noise variables z to the desired data
   space x (say images). conversely, a second neural network d(x,      )
   models the discriminator and outputs the id203 that the data came
   from the real dataset, in the range (0,1). in both cases,       represents
   the weights or parameters that define each neural network.

   as a result, the discriminator is trained to correctly classify the
   input data as either real or fake. this means it   s weights are updated
   as to maximize the id203 that any real data input x is classified
   as belonging to the real dataset, while minimizing the id203 that
   any fake image is classified as belonging to the real dataset. in more
   technical terms, the loss/error function used maximizes the function
   d(x), and it also minimizes d(g(z)).

   furthermore, the generator is trained to fool the discriminator by
   generating data as realistic as possible, which means that the
   generator   s weight   s are optimized to maximize the id203 that any
   fake image is classified as belonging to the real datase. formally this
   means that the loss/error function used for this network maximizes
   d(g(z)).

   in practice, the logarithm of the id203 (e.g. log d(   )) is used
   in the id168s instead of the raw probabilies, since using a log
   loss heavily penalises classifiers that are confident about an
   incorrect classification.
   [1*9sflt97rk7t4jqi4oic3ba.png]
   log loss visualization: low id203 values are highly penalized

   after several steps of training, if the generator and discriminator
   have enough capacity (if the networks can approximate the objective
   functions), they will reach a point at which both cannot improve
   anymore. at this point, the generator generates realistic synthetic
   data, and the discriminator is unable to differentiate between the two
   types of input.

   since during training both the discriminator and generator are trying
   to optimize opposite id168s, they can be thought of two agents
   playing a [48]minimax game with value function v(g,d). in this minimax
   game, the generator is trying to maximize it   s id203 of having
   it   s outputs recognized as real, while the discriminator is trying to
   minimize this same value.
   [1*ldvqzz6c5n_nbyobub0p5g.png]
   value function of minimax game played by generator and discriminator

training a gan

   since both the generator and discriminator are being modeled with
   neural, networks, agradient-based optimization algorithm can be used to
   train the gan. in our coding example we   ll be using stochastic gradient
   descent, as it has proven to be succesfull in multiple fields.
   [1*oz62_qvc6gaih7cdajsrqg.png]
   algorithm on how to train a gan using stochastic id119

   the fundamental steps to train a gan can be described as following:
    1. sample a noise set and a real-data set, each with size m.
    2. train the discriminator on this data.
    3. sample a different noise subset with size m.
    4. train the generator on this data.
    5. repeat from step 1.

3. coding a gan

   finally, the moment several of us were waiting for has arrived.     

   we   ll implement a gan in this tutorial, starting by downloading the
   required libraries.

   pip install torchvision tensorboardx jupyter matplotlib numpy

   in case you haven   t downloaded pytorch yet, check out their
   [49]download helper here. remember that you can also find a
   [50]tensorflow example here.

   we   ll proceed by creating a file/notebook and importing the following
   dependencies.
import torch
from torch import nn, optim
from torch.autograd.variable import variable
from torchvision import transforms, datasets

   to log our progress, we will import an additional file i   ve created,
   which will allow us to visualize the training process in
   console/[51]jupyter, and at the same time store it in tensorboard for
   those who already know how to use it.
from utils import logger

   you need to download the file and put it in the same folder where your
   gan file will be. it is not necessary that you understand the code in
   this file, as it is only used for visualization purposes.

   the file can be found in any of the following links:
     * [52]github repo link
     * [53]github raw content link

   [54][1*eusn-qaidgiwqpciwxkhea.png]
   preview of the file we will use for logging.

   dataset
   [1*7hmsjoabtcrzwmvob3fjla.png]
   mnist dataset samples

   the dataset we   ll be using here is lecunn   s [55]mnist dataset,
   consisting of about 60.000 black and white images of handwritten
   digits, each with size 28x28 pixels  . this dataset will be preprocessed
   according to some [56]useful    hacks    proven to be useful for training
   gans.

   **specifically, the input values which range in between [0, 255] will
   be normalized between -1 and 1.
def mnist_data():
    compose = transforms.compose(
        [transforms.totensor(),
         transforms.normalize((.5, .5, .5), (.5, .5, .5))
        ])
    out_dir = './dataset'
    return datasets.mnist(root=out_dir, train=true, transform=compose, download=
true)
# load data
data = mnist_data()
# create loader with data, so that we can iterate over it
data_loader = torch.utils.data.dataloader(data, batch_size=100, shuffle=true)
# num batches
num_batches = len(data_loader)

   networks

   next, we   ll define the neural networks, starting with the
   discriminator. this network will take a [57]flattened image as its
   input, and return the id203 of it belonging to the real dataset,
   or the synthetic dataset. the input size for each image will be
   28x28=784. regarding the structure of this network, it will have three
   hidden layers, each followed by a [58]leaky-relu nonlinearity and a
   [59]dropout layer to prevent overfitting. a [60]sigmoid/logistic
   function is applied to the real-valued output to obtain a value in the
   open-range (0, 1):
class discriminatornet(torch.nn.module):
    """
    a three hidden-layer discriminative neural network
    """
    def __init__(self):
        super(discriminatornet, self).__init__()
        n_features = 784
        n_out = 1

        self.hidden0 = nn.sequential(
            nn.linear(n_features, 1024),
            nn.leakyrelu(0.2),
            nn.dropout(0.3)
        )
        self.hidden1 = nn.sequential(
            nn.linear(1024, 512),
            nn.leakyrelu(0.2),
            nn.dropout(0.3)
        )
        self.hidden2 = nn.sequential(
            nn.linear(512, 256),
            nn.leakyrelu(0.2),
            nn.dropout(0.3)
        )
        self.out = nn.sequential(
            torch.nn.linear(256, n_out),
            torch.nn.sigmoid()
        )
    def forward(self, x):
        x = self.hidden0(x)
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.out(x)
        return x
discriminator = discriminatornet()

   we also need some additional functionality that allows us to convert a
   flattened image into its 2-dimensional representation, and another one
   that does the opposite.
def images_to_vectors(images):
    return images.view(images.size(0), 784)
def vectors_to_images(vectors):
    return vectors.view(vectors.size(0), 1, 28, 28)

   on the other hand, the generative network takes a latent variable
   vector as input, and returns a 784 valued vector, which corresponds to
   a flattened 28x28 image. remember that the purpose of this network is
   to learn how to create undistinguishable images of hand-written digits,
   which is why its output is itself a new image.

   this network will have three hidden layers, each followed by a
   [61]leaky-relu nonlinearity. the output layer will have a [62]tanh
   activation function, which maps the resulting values into the (-1, 1)
   range, which is the same range in which our preprocessed mnist images
   is bounded.
class generatornet(torch.nn.module):
    """
    a three hidden-layer generative neural network
    """
    def __init__(self):
        super(generatornet, self).__init__()
        n_features = 100
        n_out = 784

        self.hidden0 = nn.sequential(
            nn.linear(n_features, 256),
            nn.leakyrelu(0.2)
        )
        self.hidden1 = nn.sequential(
            nn.linear(256, 512),
            nn.leakyrelu(0.2)
        )
        self.hidden2 = nn.sequential(
            nn.linear(512, 1024),
            nn.leakyrelu(0.2)
        )

        self.out = nn.sequential(
            nn.linear(1024, n_out),
            nn.tanh()
        )
    def forward(self, x):
        x = self.hidden0(x)
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.out(x)
        return x
generator = generatornet()

   we also need some additional functionality that allows us to create the
   random noise. the random noise will be sampled from a normal
   distribution with mean 0 and variance 1 as proposed in [63]this link.
def noise(size):
    '''
    generates a 1-d vector of gaussian sampled random values
    '''
    n = variable(torch.randn(size, 100))
    return n

   optimization

   here we   ll use [64]adam as the optimization algorithm for both neural
   networks, with a learning rate of 0.0002. the proposed learning rate
   was obtained after testing with several values, though it isn   t
   necessarily the optimal value for this task.
d_optimizer = optim.adam(discriminator.parameters(), lr=0.0002)
g_optimizer = optim.adam(generator.parameters(), lr=0.0002)

   the id168 we   ll be using for this task is named binary cross
   entopy loss (bce loss), and it will be used for this scenario as it
   resembles the log-loss for both the generator and discriminator defined
   earlier in the post (see modeling mathematically a gan). specifically
   we   ll be taking the average of the loss calculated for each minibatch.
loss = nn.bceloss()

   [1*icuf1_txjngf2vhqjdwzjg.png]
   binary cross id178 log. mean is calculated by computing sum(l) / n.

   in this formula the values y are named targets, v are the inputs, and w
   are the weights. since we don   t need the weight at all, it   ll be set to
   w   =1 for all i.

   discriminator loss:
   [1*vh9pn7ktjms7fh71yankkg.png]
   discriminator   s loss.

   if we replace v    = d(x   ) and y   =1     i (for all i) in the bce-loss
   definition, we obtain the loss related to the real-images. conversely
   if we set v    = d(g(z   )) and y   =0     i, we obtain the loss related to the
   fake-images. in the mathematical model of a gan i described earlier,
   the gradient of this had to be ascended, but pytorch and most other
   machine learning frameworks usually minimize functions instead. since
   maximizing a function is equivalent to minimizing it   s negative, and
   the bce-loss term has a minus sign, we don   t need to worry about the
   sign.

   additionally, we can observe that the real-images targets are always
   ones, while the fake-images targets are zero, so it would be helpful to
   define the following functions:
def ones_target(size):
    '''
    tensor containing ones, with shape = size
    '''
    data = variable(torch.ones(size, 1))
    return data
def zeros_target(size):
    '''
    tensor containing zeros, with shape = size
    '''
    data = variable(torch.zeros(size, 1))
    return data

   by summing up these two discriminator losses we obtain the total
   mini-batch loss for the discriminator. in practice, we will calculate
   the gradients separately, and then update them together.
def train_discriminator(optimizer, real_data, fake_data):
    n = real_data.size(0)
    # reset gradients
    optimizer.zero_grad()

    # 1.1 train on real data
    prediction_real = discriminator(real_data)
    # calculate error and backpropagate
    error_real = loss(prediction_real, ones_target(n) )
    error_real.backward()
    # 1.2 train on fake data
    prediction_fake = discriminator(fake_data)
    # calculate error and backpropagate
    error_fake = loss(prediction_fake, zeros_target(n))
    error_fake.backward()

    # 1.3 update weights with gradients
    optimizer.step()

    # return error and predictions for real and fake inputs
    return error_real + error_fake, prediction_real, prediction_fake

   generator loss:
   [1*77hb-xbwpcc-zigbyaoisa.png]
   generator   s loss

   rather than minimizing log(1- d(g(z))), training the generator to
   maximize log d(g(z)) will provide much stronger gradients early in
   training. both losses may be swapped interchangeably since they result
   in the same dynamics for the generator and discriminator.

   maximizing log d(g(z)) is equivalent to minimizing it   s negative and
   since the bce-loss definition has a minus sign, we don   t need to take
   care of the sign. similarly to the discriminator, if we set v    =
   d(g(z   )) and y   =1     i, we obtain the desired loss to be minimized.
def train_generator(optimizer, fake_data):
    n = fake_data.size(0)
    # reset gradients
    optimizer.zero_grad()
    # sample noise and generate fake data
    prediction = discriminator(fake_data)
    # calculate error and backpropagate
    error = loss(prediction, ones_target(n))
    error.backward()
    # update weights with gradients
    optimizer.step()
    # return error
    return error

   testing

   last thing before we run our algorithm, we want to visualize how the
   training process develops while our gan learns. to do so, we will
   create a static batch of noise, every few steps we will visualize the
   batch of images the generator outputs when using this noise as input.
num_test_samples = 16
test_noise = noise(num_test_samples)

   training

   now that we   ve defined the dataset, networks, optimization and learning
   algorithms we can train our gan. this part is really simple, since the
   only thing we   ve got to do is to code in python the pseudocode shown
   earlier on traning a gan (see [65]training a gan).

   we   ll be using all the pieces we   ve coded already, plus the logging
   file i asked you to download earlier for this procedure:
# create logger instance
logger = logger(model_name='vgan', data_name='mnist')
# total number of epochs to train
num_epochs = 200
for epoch in range(num_epochs):
    for n_batch, (real_batch,_) in enumerate(data_loader):
        n = real_batch.size(0)
        # 1. train discriminator
        real_data = variable(images_to_vectors(real_batch))
        # generate fake data and detach
        # (so gradients are not calculated for generator)
        fake_data = generator(noise(n)).detach()
        # train d
        d_error, d_pred_real, d_pred_fake = \
              train_discriminator(d_optimizer, real_data, fake_data)
        # 2. train generator
        # generate fake data
        fake_data = generator(noise(n))
        # train g
        g_error = train_generator(g_optimizer, fake_data)
        # log batch error
        logger.log(d_error, g_error, epoch, n_batch, num_batches)
        # display progress every few batches
        if (n_batch) % 100 == 0:
            test_images = vectors_to_images(generator(test_noise))
            test_images = test_images.data
            logger.log_images(
                test_images, num_test_samples,
                epoch, n_batch, num_batches
            );
            # display status logs
            logger.display_status(
                epoch, num_epochs, n_batch, num_batches,
                d_error, g_error, d_pred_real, d_pred_fake
            )

   and that   s it, we   ve made it!     

results

   in the beginning the images generated are pure noise:
   [1*vdsdhjskbp3sktmuew60og.png]

   but then they improve,
   [1*6xo1lgydpj5rd2uhn1tfha.png]

   until you get pretty good syntethic images,
   [1*9sgc7rrulilakozvoflihg.png]

   it is also possible to visualize the learning process. as you can see
   in the next figures, the discriminator error is very high in the
   beginning, as it doesn   t know how to classify correctly images as being
   either real or fake. as the discriminator becomes better and its error
   decreases to about .5 at step 5k, the generator error increases,
   proving that the discriminator outperforms the generator and it can
   correctly classify the fake samples. as time passes and training
   continues, the generator error lowers, implying that the images it
   generates are better and better. while the generator improves, the
   discriminator   s error increases, because the synthetic images are
   becoming more realistic each time.
   [1*30xhkjbfsnqaahswnsndjq.png]
   generator   s error through time
   [1*ncfxfcj9x3fp7u5tnceqfg.png]
   discriminator   s error through time

   you can also check out the notebook named vanilla gan pytorch in this
   [66]link and run it online. you may also [67]download the output data.
     * [68]runs/ folder contains the tensor board data.
     * [69]data/ folder contains the images generated through time and the
       already trained neural network models.

conclusions

   in this blog post i have introduced id3. we
   started by learning what kind of algorithms they are, and why they   re
   so relevant nowadays. next we explored the parts that conform a gan and
   how they work together. finally we finished linking the theory with the
   practice by programming with a fully working implementation of a gan
   that learned to create synthetic examples of the mnist dataset.

   now that you   ve learned all of this, next steps would be to keep on
   reading and learning about the more advanced gan methods that i listed
   in the further reading section. as mentioned earlier, i   ll keep writing
   these kind of tutorials to make it easier for enthusiasts to learn
   machine learning in a practical way, and learning required maths in the
   way.

further reading/watching

   iframe: [70]/media/db058a657ff7226cf747469bb6a93960?postid=cb03cdcdba0f

     * [71]dcgan, [72]discogan and [73]cyclegan (gan variations with
       better performance on specific tasks).
     * google deepmind   s[74] slides on understanding generative
       adversarial networks by balaji lakshminarayanan.
     * [75]deep convolutional id3 paper by
       radford, metz and chintala.
     * [76]university at buffalo   s slides on generative and discriminative
       models by sargur n. srihari.
     * [77]andrew ng [78]and michael i. jordan   s paper on generative vs.
       discriminative classifiers.
     * stanford   s cs229: [79]machine learning lecture notes on generative
       learning algorithms by [80]andrew ng.
     * stanford   s cs231n: [81]convolutional neural networks for visual
       recognition lecture 13 notes on generative models by fei-fei li,
       justin johnson and serena yeung.
     * my [82]github   s repository on id3 in
       tensorflow and pytorch.
     * ian goodfellow   s [83]reddit thread on generative adversarial
       networks for text.
     * [84]deeper maths on gans
     __________________________________________________________________

   thanks for reading this post until the end, i   m really glad to find
   people who   re as motivated as i am about science (specifically cs and
   ai).

   make sure to like/share this post      , and comment your experience
   reading it!

   feel free to message me.

   github: [85]diegoalejogm
   twitter: [86]diegoalejogm
   linkedin: [87]diegoalejogm

   thanks to [88]sebastian valencia and [89]juan camilo bages prada who
   helped reviewing the article!

     * [90]machine learning
     * [91]generative model
     * [92]tensorflow
     * [93]pytorch
     * [94]neural networks

   (button)
   (button)
   (button) 3.8k claps
   (button) (button) (button) 22 (button) (button)

     (button) blockedunblock (button) followfollowing
   [95]go to the profile of diego gomez mosquera

[96]diego gomez mosquera

   ml engineer      former google intern     computer scientist                in love with
   science      linkedin.com/in/diegoalejogm | github.com/diegoalejogm

     (button) follow
   [97]ai society

[98]ai society

   artificial intelligence hacking group

     * (button)
       (button) 3.8k
     * (button)
     *
     *

   [99]ai society
   never miss a story from ai society, when you sign up for medium.
   [100]learn more
   never miss a story from ai society
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/cb03cdcdba0f
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/ai-society?source=avatar-lo_80kgy7ecdxop-bc8767f5d170
   7. https://medium.com/ai-society?source=logo-lo_80kgy7ecdxop---bc8767f5d170
   8. https://medium.com/m/signin?redirect=https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@diegoalejogm0?source=post_header_lockup
  11. https://medium.com/@diegoalejogm0
  12. https://github.com/diegoalejogm/gans
  13. https://www.theverge.com/2017/10/30/16569402/ai-generate-fake-faces-celebs-nvidia-gan
  14. http://research.nvidia.com/publication/2017-10_progressive-growing-of
  15. https://www.technologyreview.com/s/609469/this-ai-learns-your-fashion-sense-and-invents-your-next-outfit/
  16. https://arxiv.org/pdf/1711.02231.pdf
  17. https://junyanz.github.io/cyclegan/
  18. https://www.technologyreview.com/s/608195/machine-creativity-beats-some-modern-art/
  19. https://arxiv.org/abs/1706.07068
  20. https://motherboard.vice.com/en_us/article/a3dn9j/this-deep-learning-ai-generated-thousands-of-creepy-cat-pictures
  21. https://qz.com/817604/mits-nightmare-machine-uses-artificial-intelligence-to-create-horrific-images-of-ghoulish-faces-and-scary-places/
  22. https://www.theverge.com/2017/8/24/16195858/amazon-ai-fashion-designer
  23. https://www.inverse.com/article/39018-these-neutral-networks-can-generate-realistic-photos
  24. https://arxiv.org/pdf/1711.11585.pdf
  25. https://arxiv.org/abs/1406.2661
  26. https://github.com/diegoalejogm/gans
  27. https://arxiv.org/abs/1406.2661
  28. https://www.youtube.com/watch?v=r9ohn5zf4uo
  29. https://www.youtube.com/watch?v=wski8hfcxek
  30. https://en.wikipedia.org/wiki/generative_model
  31. https://en.wikipedia.org/wiki/unsupervised_learning
  32. https://en.wikipedia.org/wiki/latent_variable
  33. https://en.wikipedia.org/wiki/supervised_learning
  34. https://arxiv.org/abs/1312.6114
  35. https://arxiv.org/abs/1606.05328
  36. https://arxiv.org/abs/1601.06759
  37. https://arxiv.org/abs/1605.08803
  38. https://ishmaelbelghazi.github.io/ali/
  39. https://blog.openai.com/generative-models/
  40. https://www.amazon.com/surely-feynman-adventures-curious-character/dp/0393316041
  41. http://www.cs.cmu.edu/~aarti/class/10701/readings/ngjordannips2001.pdf
  42. https://en.wikipedia.org/wiki/reinforcement_learning
  43. https://github.com/nashory/gans-awesome-applications
  44. http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html
  45. https://arxiv.org/abs/1406.2661
  46. https://en.wikipedia.org/wiki/universal_approximation_theorem
  47. https://en.wikipedia.org/wiki/artificial_neural_network
  48. https://en.wikipedia.org/wiki/minimax
  49. http://pytorch.org/#pip-install-pytorch
  50. https://github.com/diegoalejogm/gans/blob/master/1. vanilla gan tensorflow.ipynb
  51. http://jupyter.org/
  52. https://github.com/diegoalejogm/gans/blob/master/utils.py
  53. https://raw.githubusercontent.com/diegoalejogm/gans/master/utils.py
  54. https://raw.githubusercontent.com/diegoalejogm/gans/master/utils.py
  55. http://yann.lecun.com/exdb/mnist/
  56. https://github.com/soumith/ganhacks
  57. https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.flatten.html
  58. http://pytorch.org/docs/master/nn.html#torch.nn.leakyrelu
  59. http://pytorch.org/docs/master/nn.html#torch.nn.dropout
  60. https://ipfs.io/ipfs/qmxoypizjw3wknfijnklwhcnl72vedxjqkddp1mxwo6uco/wiki/sigmoid_function.html
  61. http://pytorch.org/docs/master/nn.html#torch.nn.leakyrelu
  62. http://mathworld.wolfram.com/hyperbolictangent.html
  63. https://github.com/soumith/ganhacks
  64. https://arxiv.org/abs/1412.6980
  65. https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f#training a gan
  66. https://github.com/diegoalejogm/gans/blob/master/1. vanilla gan pytorch.ipynb
  67. https://www.floydhub.com/diegoalejogm/projects/gans/10/output
  68. https://www.floydhub.com/diegoalejogm/projects/gans/10/output/runs
  69. https://www.floydhub.com/diegoalejogm/projects/gans/10/output/data
  70. https://medium.com/media/db058a657ff7226cf747469bb6a93960?postid=cb03cdcdba0f
  71. https://arxiv.org/abs/1511.06434
  72. https://arxiv.org/abs/1703.05192
  73. https://arxiv.org/abs/1703.10593
  74. http://www.gatsby.ucl.ac.uk/~balaji/understanding-gans.pdf
  75. https://arxiv.org/abs/1511.06434
  76. http://www.cedar.buffalo.edu/~srihari/cse574/discriminative-generative.pdf
  77. https://medium.com/@andrewng
  78. http://www.cs.cmu.edu/~aarti/class/10701/readings/ngjordannips2001.pdf
  79. http://cs229.stanford.edu/notes/cs229-notes2.pdf
  80. https://medium.com/@andrewng
  81. http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf
  82. https://github.com/diegoalejogm/gans
  83. https://www.reddit.com/r/machinelearning/comments/40ldq6/generative_adversarial_networks_for_text/
  84. https://lilianweng.github.io/lil-log/2017/08/20/from-gan-to-wgan.html
  85. http://github.com/diegoalejogm
  86. http://twitter.com/diegoalejogm
  87. http://linkedin.com/in/diegoalejogm
  88. https://medium.com/@scvalencia606
  89. https://medium.com/@jcbages
  90. https://medium.com/tag/machine-learning?source=post
  91. https://medium.com/tag/generative-model?source=post
  92. https://medium.com/tag/tensorflow?source=post
  93. https://medium.com/tag/pytorch?source=post
  94. https://medium.com/tag/neural-networks?source=post
  95. https://medium.com/@diegoalejogm0?source=footer_card
  96. https://medium.com/@diegoalejogm0
  97. https://medium.com/ai-society?source=footer_card
  98. https://medium.com/ai-society?source=footer_card
  99. https://medium.com/ai-society
 100. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
 102. https://medium.com/p/cb03cdcdba0f/share/twitter
 103. https://medium.com/p/cb03cdcdba0f/share/facebook
 104. https://medium.com/p/cb03cdcdba0f/share/twitter
 105. https://medium.com/p/cb03cdcdba0f/share/facebook
