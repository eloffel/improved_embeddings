submodular function maximization

andreas krause (eth zurich)

daniel golovin (google)

submodularity1 is a property of set functions with deep theoretical consequences and far   
reaching applications. at    rst glance it appears very similar to concavity, in other ways it
resembles convexity. it appears in a wide variety of applications: in computer science it
has recently been identi   ed and utilized in domains such as viral marketing (kempe et al.,
2003), information gathering (krause and guestrin, 2007), image segmentation (boykov and
jolly, 2001; kohli et al., 2009; jegelka and bilmes, 2011a), document summarization (lin
and bilmes, 2011), and speeding up satis   ability solvers (streeter and golovin, 2008). in
this survey we will introduce submodularity and some of its generalizations, illustrate how it
arises in various applications, and discuss algorithms for optimizing submodular functions.
our emphasis here is on maximization; there are many important results and applications
related to minimizing submodular functions that we do not cover2.

as a concrete running example, we will consider the problem of deploying sensors in a
drinking water distribution network (see figure 1) in order to detect contamination. in this
domain, we may have a model of how contaminants, accidentally or maliciously introduced
into the network, spread over time. such a model then allows to quantify the bene   t f (a)
of deploying sensors at a particular set a of locations (junctions or pipes in the network) in
terms of the detection performance (such as average time to detection). based on this notion
of utility, we then wish to    nd an optimal subset a     v of locations maximizing the utility,
maxa f (a), subject to some constraints (such as bounded cost). this application requires
solving a di   cult real-world optimization problem, that can be handled with the techniques
discussed in this chapter (krause et al. 2008b show in detail how submodular optimization
can be applied in this domain.) we will also discuss more complex settings, for example how
one can incorporate complex constraints on the feasible sets a, robustly optimize against
adversarially chosen objective functions f , or adaptively select sensors based on previous
observations.

several algorithms for submodular optimization described in this survey are implemented

in an open source matlab toolbox3 (krause, 2010).

2

1 submodular functions

submodularity is a property of set functions, i.e., functions f : 2v     r that assign each
subset s     v a value f (s). hereby v is a    nite set, commonly called the ground set. in our
example, v may refer to the locations where sensors can be placed, and f (s) the utility
(e.g., detection performance) obtained when placing sensors at locations s. in the following,
we will also assume that f (   ) = 0, i.e., the empty set carries no value. submodularity has
two equivalent de   nitions, which we will now describe. the    rst de   nition relies on a notion
of discrete derivative, often also called the marginal gain.
de   nition 1.1 (discrete derivative) for a set function f : 2v     r, s     v , and e     v ,
let    f (e | s) := f (s     {e})     f (s) be the discrete derivative of f at s with respect to e.

where the function f is clear from the context, we drop the subscript and simply write

   (e | s).
de   nition 1.2 (submodularity) a function f : 2v     r is submodular if for every
a     b     v and e     v \ b it holds that

   (e | a)        (e | b) .

equivalently, a function f : 2v     r is submodular if for every a, b     v ,

f (a     b) + f (a     b)     f (a) + f (b).

for submodular maximization, the intuition provided by the    rst de   nition is often help-
ful: suppose we interpret s     v as a set of actions which provide some bene   t f (s). then
the    rst de   nition says that for a submodular function f , after performing a set a of ac-
tions, the marginal bene   t of any action e does not increase as we perform the actions in
b \ a. therefore, submodular set functions exhibit a natural diminishing returns property.
figure 1 illustrates this e   ect in our sensor placement application. in this example, the
marginal bene   t provided by placing a sensor at a    xed location s(cid:48) given that we deployed
sensors at locations s1, s2 does not increase as we deploy more sensors (s3 and s4).

an important subclass of submodular functions are those which are monotone, where

enlarging the argument set cannot cause the function to decrease.
de   nition 1.3 (monotonicity) a function f : 2v     r is monotone if for every a     b    
v , f (a)     f (b).

note that a function f is monotone i    all its discrete derivatives are nonnegative, i.e., i   
for every a     v and e     v it holds that    (e | a)     0. further note that the important
subclass of monotone submodular functions can be characterized by requiring that for all
a     b     v and e     v it holds that    (e | a)        (e | b). this is slightly di   erent from
de   nition 1.2 in that we do not require e /    b.

typically, and in most of this chapter, we will assume that f is given in terms of a value

oracle, a black box that computes4 f (s) on any input set s.

submodular function maximization

3

(a) adding s(cid:48) to set {s1, s2}

(b) adding s(cid:48) to superset {s1, . . . , s4}

figure 1 illustration of the diminishing returns e   ect in context of placing sensors in a water dis-
tribution network to detect contaminations. the blue regions indicate nodes where contamination
is detected quickly using the existing sensors s. the red region indicates the additional coverage
by adding a new sensor s(cid:48). if more sensors are already placed (b), there is more overlap, hence
less gain in utility:    (s(cid:48) | {s1, s2})        (s(cid:48) | {s1, . . . , s4}).

submodular functions comprise a broad class of functions that arise in several applications.
here are some examples.

1.1 examples

modular functions and generalizations. the simplest example of submodular func-
tions are modular functions, those for which the inequalities characterizing submodularity
hold with equality, i.e., for all a, b     v it holds that f (a) + f (b) = f (a     b) + f (a     b).
such functions are analogous to linear functions, insofar as their discrete derivatives are
constant:    (e | b) =    (e | a) for all a, b and e /    a     b. assuming f (   ) = 0, they can
e   s w(e) for some weight function w : v     r.
another example is the composition of any monotone modular function g : 2v     r and

always be expressed in the form f (s) =(cid:80)
any concave function h : r     r     for example, f (s) =(cid:112)|s|.

weighted coverage functions. an important example of a submodular function is the
weighted coverage of a collection of sets: fix a set x, a nonnegative modular function
g : 2x     r, and a collection v of subsets of x. then for a subcollection s     v , the
function

(cid:17)

(cid:16)(cid:91)

v   s

(cid:88)
x   (cid:83)

v   s v

f (s) := g

v

=

w(x),

is monotone submodular. hereby w : x     r is the weight function representing g. in our
example, x may refer to a set of contamination events, w(x) quanti   es the severity of event
x, and with each possible sensor location v     v we associate the subset v     x of events
detected. perhaps the simplest example is where g(a) = |a| is the cardinality function
(which is modular), in which case the problem of maximizing f (s) is the well-known max-
cover problem. in fact, f (s) is submodular even for arbitrary submodular functions g. it is
monotone i    g is monotone.

s    s2 s1 s    s2 s1 s3 s4 4

the rank function of a matroid. another important class of submodular functions
arises in the context of matroids:
de   nition 1.4 (matroid) a matroid is a pair (v,i) such that v is a    nite set, and
i     2v is a collection of subsets of v satisfying the following two properties:

    a     b     v and b     i implies a     i
    a, b     i and |b| > |a| implies     e     b \ a such that a     {e}     i.

sets in i are called independent, and matroids generalize the concept of linear indepen-
dence found in id202. an important function associated with a matroid (v,i),
which describes it completely, is its rank function f (s) := max{|u| : u     s, u     i}. the
rank function of any matroid is monotone submodular (birkho   , 1933).

facility location. suppose we wish to select, out of a set v = {1, . . . , n}, some locations
to open up facilities in order to serve a collection of m customers. if we open up a facility at
location j, then it provides service of value mi,j to customer i, where m     rm  n. if each
customer chooses the facility with highest value, the total value provided to all customers
is modeled by the set function

m(cid:88)

i=1

f (s) =

max
j   s

mi,j.

hereby we set f (   ) = 0. if mi,j     0 for all i, j, then f (s) is monotone submodular (frieze,
1974). this model is quite general, and captures other applications as well. in our sensor
placement example, mi,j could refer to the bene   t provided by sensor j in scenario i,
quanti   ed, e.g., in terms of the expected reduction in detection time (krause et al., 2008b).

id178. given a joint id203 distribution p (x) over a discrete-valued random vector
x = [x1, x2, . . . , xn], the function f (s) = h(xs) is monotone submodular (fujishige,
1978), where h is the shannon id178, i.e.,

h(xs) =    (cid:88)

xs

p (xs) log2 p (xs)

where we use the notational convention that xs is the random vector consisting of the
coordinates of x indexed by s, and likewise xs is the vector consisting of the coordinates of
an assignment x indexed by s. if the random variables are real-valued, with a id203
density function f , the di   erential id178

(cid:90)

h(xs) =    

p (xs) log2 p (xs)dxs

is submodular as well, but not generally monotone.

submodular function maximization

5

mutual information. given a joint id203 distribution p (x, y) over two dependent
random vectors, x = [x1, x2, . . . , xn] and y = [y1, y2, . . . , ym], consider the mutual infor-
mation: f (s) = i(y; xs) = h(y)     h(y | xs), which quanti   es the expected reduction
of uncertainty about y upon revelation of xs. in general, the function f is not submodular :
suppose x1, x2     bernoulli(0.5), and y = x1 xor x2. then f (   ) = f ({1}) = f ({2}) = 0,
but f ({1, 2}) = 1, violating submodularity. however, if the variables x are conditionally
independent given y, i.e., for all disjoint sets a, b     v if holds that xa     xb | y, then
f is monotone submodular (krause and guestrin, 2005). this holds both for discrete and
continuous distributions. in our example, we may associate a variable yv with the water
quality at location v     v , and xv is a noisy measurement of yv that we obtain if we place a
sensor at location v. then f (s) quanti   es how much we can reduce our uncertainty about
the water quality everywhere when deploying sensors at locations s.
symmetric mutual information. let v = {1, 2, . . . , n}. given any joint id203 dis-
tribution p over a random vector x = [x1, x2, . . . , xn], the function f (s) = i(xs; xv \s)
is submodular. however, f is not monotone in general, since f (   ) = f (v ) = 0, and unless
x1, x2, . . . , xn are independent, it will be the case that f (s) > 0 for some s. this function
has been used by narasimhan et al. (2005) for information-theoretic id91 problems,
and by krause et al. (2008a) for the purpose of sensor placement.
more generally, if y = [y1, y2, . . . , ym] is another random vector, and x and y have joint
distribution p (x, y) the conditional mutual information i(xs; xv \s | y) is submodular
(but not monotone). this function arises in the context of structure learning in probabilistic
id114, as studied by narasimhan and bilmes (2004).

then the function f (s) =(cid:80)

cut capacity functions. fix any undirected graph g = (v, e) with nonnegative edge ca-
pacities c : e     r+. let    s be the boundary of s     v , de   ned as    s := {{u, v}     e : |s     {u, v}| = 1}.
e      s c(e) is submodular (schrijver, 2003). the same is true for
directed graphs, if we de   ne    s := {(u, v)     e : u     s, v /    s}. note that f is not generally
monotone: in particular, f (   ) = f (v ) = 0.

1.2 properties of submodular functions

are submodular, and   1, . . . ,   n     0, then f (s) := (cid:80)n

submodular functions have many useful properties. for example, submodularity is pre-
served under taking nonnegative linear combinations. in other words, if g1, . . . , gn : 2v     r
i=1   igi(s) is submodular as well.
this is readily proved using the de   nition of submodularity based on discrete derivatives.
this insight is extremely useful, as it allows to build complex submodular objectives from
simpler constituents (c.f., kempe et al. 2003; leskovec et al. 2007; stobbe and krause
2010). submodularity is also preserved when we take the residual : if g : 2v     r is sub-
modular, and a, b     v are any disjoint sets, then the residual f : 2a     r de   ned via
f (s) := g(s     b)     g(b) is submodular. monotone submodular functions remain so un-
der truncation: if g : 2v     r is submodular, so is f (s) := min{g(s), c} for any constant
c. while truncation preserves submodularity, in general, the minimum and maximum of
two submodular functions are not submodular, i.e., for submodular functions f1 and f2, the

6

functions fmin(s) = min(f1(s), f2(s)) and fmax(s) = max(f1(s), f2(s)) are not necessarily
submodular.

interestingly, there are many natural connections between submodular functions and
both convex and concave functions. for example, for a function g : n     r, the set function
f (s) = g(|s|) is submodular if and only if g is concave. in contrast, similar to convex
functions, which can be minimized e   ciently, (unconstrained) submodular minimization
is possible in (strongly) polynomial time (c.f., schrijver 2003). see (lovasz, 1983) for a
discussion about the relationship between submodular, concave and convex functions.

submodular set functions can also be extended to continuous functions (de   ned over
the unit cube [0, 1]|v |) in several natural ways. see section 3.2 for more details on such
extensions.

2 greedy maximization of submodular functions

as argued in section 1.1, submodular functions arise in many applications, and therefore it
is natural to study submodular optimization. there is a large amount of work on minimizing
submodular functions (c.f., fujishige 2005; schrijver 2003). in this chapter, we will focus
on the problem of maximizing submodular functions. that is, we are interested in solving
problems of the form

max
s   v

f (s) subject to some constraints on s.

(1)

the simplest example are cardinality constraints, where we require that |s|     k for some k.
in our example, we may wish to identify the k best locations to place sensors. unfortunately,
even this simple problem is np-hard, for many classes of submodular functions, such as
weighted coverage (feige, 1998) or mutual information (krause and guestrin, 2005). while
there are specialized branch and bound algorithms for maximizing submodular functions
(nemhauser and wolsey, 1981; goldengorin et al., 1999; kawahara et al., 2009), ultimately
their scalability is limited by the hardness of problem 1. therefore, in the remaining of this
chapter we focus on e   cient algorithms with theoretical approximation guarantees.

the greedy algorithm. in the following, we will consider the problem of approximately
maximizing monotone submodular functions. a simple approach towards solving problem 1
in the case of cardinality constraints is the greedy algorithm, which starts with the empty
set s0, and in iteration i, adds the element maximizing the discrete derivative    (e | si   1)
(ties broken arbitrarily):

si = si   1     {arg max

e

   (e | si   1)}.

(2)

a celebrated result by nemhauser et al. (1978) proves that the greedy algorithm provides
a good approximation to the optimal solution of the np-hard optimization problem.

theorem 1.5 (nemhauser et al. 1978) fix a nonnegative monotone submodular function
f : 2v     r+ and let {si}i   0 be the greedily selected sets de   ned in eq. (2). then for all

submodular function maximization

7

positive integers k and (cid:96),

f (s(cid:96))    (cid:16)

1     e   (cid:96)/k(cid:17)

f (s).

max
s:|s|   k
in particular, for (cid:96) = k, f (sk)     (1     1/e) max|s|   k f (s).
proof nemhauser et al. only discussed the case (cid:96) = k, however their very elegant argument
easily yields the slight generalization above. it goes as follows. fix (cid:96) and k. let s       
arg max{f (s) : |s|     k} be an optimal set of size k (due to monotonicity of f we can assume
w.l.o.g. it is of size exactly k), and order the elements of s    arbitrarily as {v   
k}. then
1, . . . , v   
we have the following sequence of inequalities for all i < (cid:96), which we explain below.

1, . . . , v   

j   1

f (s   )     f (s        si)

= f (si) +

    f (si) +

k(cid:88)
   (cid:0)v   
j | si    (cid:8)v   
(cid:88)
(cid:88)

   (v | si)

v   s   

j=1

(f (si+1)     f (si))

    f (si) +
    f (si) + k (f (si+1)     f (si))

v   s   

(cid:9)(cid:1)

(3)

(4)

(5)

(6)

(7)

eq. (3) follows from monotonicity of f , eq. (4) is a straightforward telescoping sum, eq. (5)
follows from the submodularity of f , eq. (6) holds because si+1 is built greedily from si in
order to maximize the marginal bene   t    (v | si), and eq. (7) merely re   ects the fact that
|s   |     k. hence

(8)
now de   ne   i := f (s   )     f (si), which allows us to rewrite eq. (8) as   i     k (  i       i+1),
which can be rearranged to yield

f (s   )     f (si)     k (f (si+1)     f (si)) .

  i

(9)

hence   (cid:96)    (cid:0)1     1

(cid:1)(cid:96)

by assumption, and by the well-known inequality 1     x     e   x for all x     r we have

k

  0. next note that   0 = f (s   )     f (   )     f (s   ) since f is nonnegative

(10)
substituting   (cid:96) = f (s   )     f (s(cid:96)) and rearranging then yields the claimed bound of f (s(cid:96))    

  (cid:96)    

1     1
k

  0     e   (cid:96)/kf (s   ).

(cid:0)1     e   (cid:96)/k(cid:1) f (s   ).

the slight generalization allowing (cid:96) (cid:54)= k is quite useful. for example, if we let the greedy
algorithm pick 5k sensors, the approximation ratio (compared to the optimal set of size k)
improves from     .63 to     .99.

for several classes of submodular functions, this result is the best that can be achieved
with any e   cient algorithm. in fact, nemhauser and wolsey (1978) proved that any al-
gorithm that is allowed to only evaluate f at a polynomial number of sets will not be

(cid:19)

  i+1    

1     1
k

(cid:18)

(cid:19)(cid:96)

(cid:18)

8
able to obtain an approximation guarantee better than (1     1/e). (subsequently, vondr  ak
(2010) provided more re   ned results on the best possible approximation factor in terms of
a parameter called the curvature of f .)

matroid constraints. going beyond cardinality constraints, the greedy algorithm is also
guaranteed to provide near-optimal solutions for more complex constraints. in our sensing
example, in order to preserve energy, each sensor may decide when to activate. the problem
of optimizing such a sensing schedule requires maximizing a submodular function subject
to a partition matroid constraint (krause et al., 2009).

suppose (v,i) is a matroid, and we wish to solve the problem

then the greedy algorithm, which starts with sg and sets

max
s   i f (s),

sg     sg    (cid:110)

arg max

e /   sg:sg   {e}   i

   (e | sg)

(cid:111)

(11)

2 maxs   i f (s).

even more generally, suppose (v,i1), . . . , (v,ip) are p matroids, and i =(cid:84)

until there is no more e such that sg     {e}     i (i.e., there is no element which can
be added to create a feasible solution), is guaranteed to produce a solution sg so that
f (sg)     1
i ii. that is, i
consists of all subsets of v that are independent in all p matroids. even though (v,i) is not
generally a matroid anymore, the greedy algorithm 11 is guaranteed to produce a solution
so that f (sg)     1
p+1 maxs   i f (s). in fact, this results holds even more generally whenever
(v,i) is a p-extensible system, a combinatorial notion which generalizes the intersections of
p matroids (calinescu et al., 2011).

min-cost coverage. instead of maximizing a monotone submodular function subject to
constraints, it is also natural to search for minimum cost sets that achieve a given amount
q of submodular value. in particular, we may wish to solve
|s| s.t. f (s)     q,

(12)
for some quota 0     q     f (v ) of value. in our sensing example, we may wish to deploy
as few sensors as possible, while guaranteeing that all possible contamination scenarios are
eventually detected.

s    = arg min

s

wolsey (1982) proves the following result about the greedy algorithm:

theorem 1.6 (wolsey 1982) suppose f : 2v     n is monotone submodular and integer-
valued, and let 0     q     f (v ). let s0, s1, . . . be the sequence of sets picked by the greedy
algorithm, and let (cid:96) be the smallest index such that f (s(cid:96))     q. then

(cid:18)

(cid:96)    

(cid:19)

1 + ln max
v   v

f ({v})

op t,

where op t = mins |s| s.t. f (s)     q.

submodular function maximization

9

in fact, wolsey proves the special case q = f (v ), but the result above immediately follows
by applying his result to the submodular function min{f (s), q}. wolsey also proves that
the same result holds in the case where the elements of v have non-uniform cost, using a
slightly modi   ed greedy algorithm (see also section 3.1).

speeding up the greedy algorithm through lazy evaluations. in some applications,
evaluating the function f can be expensive. in our example, evaluating f may require run-
ning computationally costly water quality simulations. in this case, even applying the stan-
dard greedy algorithm can be infeasible. fortunately, submodularity can be exploited algo-
rithmically to implement an accelerated variant of the greedy algorithm, originally proposed
by minoux (1978). in each iteration i, the greedy algorithm must identify the element e with
maximum marginal gain    (e | si   1), where si   1 is the set of elements selected in the previ-
ous iterations. the key insight is that, as a consequence of submodularity of f , the marginal
bene   ts of any    xed element e     v are monotonically nonincreasing during the iterations of
the algorithm, i.e.,    (e | si)        (e | sj) whenever i     j. instead of recomputing    (e | si   1)
for each element e     v (requiring o(n) computations of f ), the accelerated greedy algo-
rithm maintains a list of upper bounds   (e) (initialized to    ) on the marginal gains sorted
in decreasing order. in each iteration, the algorithm extracts the maximal element

e    

arg max

e(cid:48):si   1   {e(cid:48)}   i

  (e(cid:48))

from the ordered list. it then updates the bound   (e)        (e | si   1). if, after this update,
  (e)       (e(cid:48)) for all e(cid:48) (cid:54)= e, then submodularity guarantees that    (e | si   1)        (e(cid:48) | si   1)
(cid:54)= e, and therefore the greedy algorithm has identi   ed the element of largest
for all e(cid:48)
marginal gain, without having to compute    (e(cid:48) | si   1) for a potentially large number of
elements e(cid:48). it sets si     si   1     {e} and repeats until there is no further feasible element
which can be added. this idea of using lazy evaluations can lead to orders of magnitude
performance speedups, and is useful beyond the greedy algorithm (c.f., leskovec et al. 2007).

3 beyond the greedy algorithm: handling more complex

constraints

in this section, we will survey some work on submodular optimization beyond the standard
greedy algorithm discussed in section 2. using more complex algorithms allows to handle
maximization subject to more complex constraints. we will mostly focus on the case of
monotone functions, but also mention results about optimizing non-monotone functions.

3.1 knapsack constraints

instead of selecting a set of at most k elements, in many applications, the elements v     v
may have non-uniform costs c(s)     0, and we may wish to maximize f subject to a budget
that the total cost cannot exceed:

max

s

f (s) s.t.

c(v)     b.

(cid:88)

v   s

10

thus, we would like to maximize f (s) subject to a (w.l.o.g.) nonnegative modular constraint,
also called knapsack constraint (as the problem of maximizing a modular f subject to a
modular constraint c is called the knapsack problem). naturally, the standard (uniform
cost) greedy algorithm, selecting the next a   ordable element of maximum marginal gain
can perform arbitarily badly, as it ignores cost. it can be easily modi   ed to take cost into
account: the cost-bene   t greedy algorithm starts with s0 =    , and iteratively adds

si+1 = si    

arg max

v   v \si:c(v)   b   c(si)

   (e | si)

c(v)

,

(13)

(cid:40)

(cid:41)

i.e., the element v that maximizes the bene   t cost ratio among all elements still a   ordable
with the remaining budget. for the min-cost covering problem (12), wolsey (1982) proves
a generalization of theorem 1.6 for this cost-bene   t greedy algorithm. unfortunately, for
the budgeted maximization problem, even though this modi   ed algorithm takes cost into
account, it can still perform arbitrarily badly. however, perhaps surprisingly, at least one
of the greedy solutions     the solution suc returned by the uniform cost or the one scb pro-
vided by the cost-bene   t greedy algorithm cannot perform too badly: it can be shown that
max{f (suc), f (scb)}     1   1/e
2 op t (leskovec et al., 2007). in fact, a more computationally
complex algorithm, which enumerates all sets s of size 3, and augments them using the cost-
bene   t greedy algorithm, is known to provide a 1     1/e approximation (sviridenko, 2004).

3.2 submodular maximization using the multilinear extension

one important idea, which has seen a number of applications in submodular optimization,
is the use of extensions. suppose f : 2v     r is a set function. by identifying sets s
with binary vectors es (in which the i-th component is 1 if i     s, and 0 otherwise),
we can equivalently represent f as a function de   ned over corners of the unit cube:   f :
{0, 1}n     r, where n = |v |, and   f (es) = f (s). from this perspective, it is natural to
extend   f to the entire unit cube [0, 1]n. there are several important extensions. the lova  sz
extension (lovasz, 1983) extends   f to a convex function   f : [0, 1]n     r, for which (at
least some of) its minimizers are attained at a corner of [0, 1]n. minimization of   f over
[0, 1]n is possible using the ellipsoid method, which proved that unconstrained submodular
minimization is possible in polynomial time. however, for the purpose of (constrained)
submodular maximization, a di   erent extension, pioneered by vondr  ak (2008) has proven
to be very useful: the multilinear extension of f ,   f : [0, 1]n     r is de   ned as

(cid:88)

s   v

(cid:89)

i   s

(cid:89)

j /   s

  f (x) =

f (s)

xi

(1     xj).

thus,   f (x) is the expected value of f over sets, where each element i is included indepen-
dently with id203 xi. several recent algorithms for submodular maximization are built
around (approximately) solving the problem

over some domain f     [0, 1]n, and then rounding the continuous solution to obtain a
near-optimal set.

max   f (x) s.t. x     f

submodular function maximization

11

the    rst application of this elegant idea, due to vondr  ak (2008), is the continuous greedy
algorithm for maximizing a submodular function subject to matroid constraints. in this
application, the feasible set f is the matroid polytope, the convex hull of the independent
sets of the underlying matroid. conceptually, the algorithm traces the continuous particle,
parameterized as a function x : [0, 1]     f, originating at x(0) = 0, and following the
di   erential equation

(cid:16)

(cid:17)

  x = arg max

v   f

vt          f (x)

.

calinescu et al. (2011) prove that for matroid polytopes f, it holds that

  f (x(1))     (1     1/e) max
x   f

  f (x),

thus at time 1, the particle has reached a point which provides a (1     1/e) approximation
of the optimal value of   f over f. calinescu et al. also show how this continuous di   erential
equation can be approximated by a discrete process up to arbitrarily small error. they also
show how the continuous solution y can be e   ciently rounded to a feasible discrete solution
without loss in objective value, using pipage rounding (ageev and sviridenko, 2004). this
result a   rmatively closed the long-standing open question of whether the optimal approx-
imation ratio of (1     1/e), which the standard greedy algorithm achieves for cardinality
constraints, can be achieved for arbitrary matroids (for which the standard algorithm only
gives a 1/2 approximation).

however, this general technique of relaxing constrained submodular maximization to a
continuous problem, and rounding the obtained solution has proven to be far more general.
for example, kulik et al. (2009) have shown how to obtain a (1    1/e      ) approximation for
the problem of maximizing a monotone submodular functions subject to multiple knapsack
constraints. recently, chekuri et al. (2011) have used the multilinear relaxation to obtain a
.38/k approximation for maximizing a monotone submodular function subject to k matroid
and a constant number of knapsack constraints (as well as an even more general class of
other downward-closed constraints).

3.3 submodular optimization over graphs

another natural class of constraints arise when solving submodular optimization problems
on graphs. suppose that we identify the elements v as vertices of a (weighted) graph
g = (v, e, w) with edges e, and a function w that assigns each edge a nonnegative weight.
in this setting, we may wish to maximize a submodular function f (s) de   ned over the
vertices, subject to the constraint that the set s forms a path, or a tree on g of weight at
most b. similarly, we may wish to obtain a tree (path) on g of submodular value q, and with
approximately minimal total weight. these problems have natural applications in placing
sensors under communication constraints, where the vertices v denote possible locations
for sensors, f the informativeness of having sensors at a set of locations, and edges and their
weights denote the communication cost between arbitrary pairs of locations (krause et al.,
2011b). another application is in planning informative paths for mobile sensors (singh et al.,
2007). in these applications, id192 can be shown to perform arbitrarily poorly.

12

(cid:17)

(cid:16) 1

calinescu and zelikovsky (2005) develop a polynomial-time algorithm, which, given an
integral-valued monotone submodular function f and a quota 0     q     f (v ), and any    > 0,
produce a tree of cost at most o
times the optimal cost. for the

1

ln ln n (ln n)2+   log q

  

related problem of path constraints, chekuri and pal (2005) develop an algorithm that,
given a budget b > 0 and nodes s, t     v produces an s   t path of length at most b (if
such exists) of submodular value    ( op t
log op t ). however, the running time of the algorithm is
(n log b)o(log n), which is only quasi-polynomial in n. nevertheless, singh et al. (2007) show
how this algorithm can be scaled to fairly large problems, and present results on planning
informative paths for robotic sensors. for submodular functions that satisfy an additional
locality property, which arises naturally in spatial monitoring problems, improved algorithms
can be obtained, both for tree (krause et al., 2006) and path (singh et al., 2009) constraints.

3.4 robust submodular optimization

in our example of placing sensors in a drinking water distribution network, we may wish to
protect against malicious contaminations (krause et al., 2008b). in this case, there may be
a collection of m possible intrusion scenarios (e.g., locations whether contaminants could be
introduced), and for each of the scenarios, we use a separate monotone submodular function
fi(s) that quanti   es the bene   t (e.g., chance of detection) of having sensors at locations
s, in scenario i. the problem of optimally placing sensors to protect against an adversary
who wants to maximize their chances to go undetected therefore requires to solve

s    = arg max
|s|   k

min

i

fi(s),

(14)

where f1, . . . , fm are monotone submodular functions.

unfortunately, the function fmin(s) = mini fi(s) is not generally submodular. more-
over, the greedy algorithm applied to fmin can perform arbitrarily poorly. in fact, krause
et al. (2008c) prove that problem (14) is extremely inapproximable: unless p=np, no ef-
   cient algorithm can provide a solution s such that fmin(s)       (n)op tk, where op tk =
max|s(cid:48)|   k fmin(s(cid:48)), for any function    that may even depend on the problem size n (for
example, it is not e   ciently possible to even recoup an exponentially small fraction of the
optimal value). perhaps surprisingly, given the hardness of the problem, it is possible to pro-
vide a di   erent kind of approximation guarantee. krause et al. (2008c) develop saturate,
an algorithm that is guaranteed to e   ciently obtain a set s such that fmin(s)     op tk,

i fi({v})(cid:1)k. thus, it is possible to obtain a set s that provides as

and |s|    (cid:0)1 + maxv ln(cid:80)

much value as the best set of size k, at a cost that is logarithmically larger than k. this
logarithmic approximation is optimal under reasonable complexity-theoretic assumptions.
problem 14 is much more general. for example, schulman et al. (2011) have recently applied
saturate in personal robotics in order to plan where to grasp objects.

instead of committing to a    xed set s     v , in some applications it may be possible to
select a id203 distribution over sets. for example, when controlling a sensor network in
a building to protect against intrusions, we may wish to obtain a randomized sensing strat-
egy that performs as well as possible against an intruder who attempts to evade detection,

submodular function maximization

13

knowing the randomized strategy. this problem is formalized as

p    =

arg max

p:p(s)>0   |s|   k

u (p) where u (p) = min

i

es   p[fi(s)] .

thus, we wish to obtain a distribution p    over feasible sets s, such that our value is max-
imized in expectation, even under an adversarially chosen objective. solving this problem
optimally is a formidable task, as even representing the optimal distribution may require
exponential space. however, krause et al. (2011a) show how it is possible, for any    > 0, to
e   ciently obtain a distribution   p over o(ln m/  2) sets such that u (  p)     (1    1/e)u (p   )      .

3.5 nonmonotone submodular functions

while most work has focused on maximizing monotone submodular functions, several ap-
plications require maximizing nonmonotone submodular functions. for example, suppose
we have a monotone submodular function f , and a modular cost function c, assigning each
element v a cost c(v). in this setting, we may wish to solve the unconstrained problem

f (s)     c(s).

max

s

here, the function g(s) = f (s)     c(s) is submodular, but nonmonotone. another exam-
ple is maximizing the symmetric mutual information f (s) = i(xs; xv \s) (c.f.,   1.1). for
arbitrary submodular functions f , even verifying whether there exists a set s such that
f (s) > 0 is np-hard (feige et al., 2007), thus no approximation is possible. however, there
have been recent breakthroughs on maximizing arbitrary nonnegative submodular functions
(i.e., f (s)     0 for all sets s).

3       

n2 ) terminates with a set s such that either s or v \ s provides
n ) approximation to the optimal unconstrained solution. they also prove that a
5     o(1))

feige et al. (2007) prove that a local-search algorithm which iteratively adds or removes
elements, ensuring that each addition or removal increases the function value by at least a
multiplicative factor of (1 +   
a ( 1
more expensive, randomized local search procedure produces a solution with is a ( 2
approximation to the optimal value. this is contrasted by their hardness result, proving
that no approximation better than 1
2 is achievable in the value oracle model. krause and
horvitz (2008) present an application of unconstrained submodular maximization to the
problem of trading o    utility and privacy in online services.

further improvements have been obtained utilizing the multilinear extension as discussed
above. in particular, gharan and vondr  ak (2011) show that a simulated annealing algorithm
is guaranteed to obtain a 0.41 approximation for unconstrained maximization, and 0.325
approximation for maximization subject to a matroid constraint. most recently, chekuri
et al. (2011) show how the factor 0.325 can also be obtained for a constant number of
knapsack constraints, and how a 0.19/k approximation is achievable for maximizing any
nonnegative submodular function subject to k matroid and a constant number of knapsack
constraints.

14

4 online maximization of submodular functions

in the previous sections, we have assumed that we are given an objective function f that
we wish to maximize. in some applications, the objective may not be known in advance.
however, if we perform the same task repeatedly while facing objectives f1, . . . , ft drawn
from some distribution, we might hope to learn to perform well on average over time. this
is the premise behind no   regret algorithms, which are widely used in machine learning.

in many interesting applications the (unknown) objective functions ft are monotone sub-
modular. one example that we discuss below is learning to hybridize di   erent algorithms
for a computationally hard problem to generate a meta-algorithm which may outperform all
of its constituent algorithms. other examples include online sensor selection, news recom-
mendation systems, online advertising and others. as we will see below, there are analogues
of theorem 1.5 in this no   regret setting, i.e., it is possible to learn to optimize submodular
functions in an online manner.

4.1 the no   regret setting

suppose we face the problem of repeatedly, over t rounds, choosing an action from a set
v . in each round t, after selecting an action v     v , you observe either the reward of
every action (in the so-called full information feedback model) in that round, or merely the
reward of the action you selected (in the so   called bandit feedback model). let rt(v) denote
the reward of action v in round t. orthogonal to the feedback model, the rewards may be
stochastic, in which case the reward functions {rt : t = 1, 2, . . . , t} are drawn from some
   xed (but unknown) distribution, or non-stochastic, in which case they may be arbitrary
(even possibly chosen by an adversary). at    rst glance it seems impossible to give any
interesting performance guarantees for the non-stochastic bandit setting. however, there
are many beautiful results in this area based on the notion of minimizing the regret against
the best action in hindsight (c.f., cesa-bianchi and lugosi 2006).

de   nition 1.7 (regret) the regret of action sequence v1, . . . , vt is

rt = max

v   

and the average regret is rt /t .

t(cid:88)

rt(v   )     t(cid:88)

t=1

t=1

rt(vt)

there is a large literature on no   regret algorithms, to which we cannot do justice here.
however, a key point is that if the reward functions are bounded, e.g., if rt(v)     [0, 1]
for all v and t, then in many settings, such as the case where v is    nite, there are ran-
domized algorithms whose expected regret grow as o(t ), so that the average regret rt /t
converges to zero as t        . there are algorithms which achieve o(|v | log t ) expected

regret for stochastic rewards with bandit feedback (auer et al., 2002), o((cid:112)t log |v |) for
(cid:16)(cid:112)t|v | log |v |(cid:17)

the non-stochastic rewards with full information feedback (freund and schapire, 1999), and

o
for the non-stochastic rewards with bandit feedback (auer et al., 2003).
this means that in all settings we can converge to the performance of the best action in
hindsight.

submodular function maximization

15
now, suppose that instead of choosing an element v     v in each round you had to choose
a set s     v of bounded cardinality, say, |s|     k? na    vely using the algorithms for the
single action case (k = 1) by treating each feasible set as a distinct action has two major
disadvantages. first, the algorithms require time at least linear in the number of feasible

(cid:1). second, the average regret will shrink very slowly in the bandit feedback
(cid:1) rounds are required before the regret bounds are meaningful.

sets, namely(cid:0)|v |
model, so that at least(cid:0)|v |

k

k

unfortunately, for arbitrary reward functions rt(s), there is not much one can do about this
situation. however, if the reward functions rt(  ) are monotone submodular, this structure
can be exploited to get regret bounds roughly k times that of the original problem, with
the caveat that the regret is against a (1     1/e) approximation to the best feasible set in
hindsight. we call such a regret measure the (1     1/e)-regret. formally, for any        0 the
  -regret is de   ned as follows.

de   nition 1.8 (  -regret) the   -regret of a sequence of sets s(1), . . . , s(t ) is

r   =       max

s    feasible

and the average   -regret is r  /t .

t(cid:88)

rt(s   )     t(cid:88)

t=1

t=1

(cid:16)

s(t)(cid:17)

rt

(cid:16)

k(cid:112)t|v | log |v |(cid:17)

4.2 submodular maximization in the no   regret setting

suppose rt : 2v     [0, 1] are monotone submodular, with bounded range. (we rescale so
that the range is [0, 1].) for clarity of exposition, we will focus here on a natural partially
transparent feedback model de   ned as follows, but results in other models are available. for
an ordered set s, let si be the    rst i elements of s. in the partially transparent feedback
model, after selecting ordered set s(t), the marginal bene   t of each action is revealed,
s(t)
assuming they were added in order. formally, we observe rt
for each
i   1
i = 1, 2, . . . , k. in this model, it is possible to obtain results like the following.

(cid:17)     rt

s(t)
i

(cid:16)

(cid:16)

(cid:17)

theorem 1.9 (streeter and golovin 2007) there is an e   cient algorithm which incurs
expected (1     1/e)-regret at most o
partially transparent feedback.

, in the non   stochastic setting with

hence it is possible to ensure the expected average (1    1/e)-regret converges to zero at a
t , so that asymptotically the algorithm achieves at least (1    1/e)

   
rate proportional to 1/
of the optimal reward obtained by any    xed set of size k.

one algorithm obtaining the claimed regret bound, called the online greedy algorithm,
combines the greedy algorithm with no-regret algorithms for the bandit feedback setting in
a simple manner: there are k instantiations of such no-regret algorithms a1, . . . ,ak, each
with a set of actions v to choose among. in each round t, each ai selects an action vt
i and the
set s(t) = {vt
,
where s(t)

k} is selected. for its trouble, ai receives reward rt

(cid:17)     rt

1, . . . , vt

s(t)
i   1

s(t)
i

(cid:16)

(cid:16)

(cid:17)

j = {vt

i : i     j}.

at a very high level, the key reason that the online greedy algorithm performs well is
that the greedy algorithm is noise-resistant in the following sense. suppose that instead

16
of selecting si = si   1     {arg maxv    (v | si   1)} a    noisy    version of the greedy algorithm
selects si = si   1     {vi} such that    (vi | si   1) = maxv    (v | si   1)      i for some  i     0.
then a relatively straightforward modi   cation of the proof by nemhauser et al. (1978),
which may be found in (streeter and golovin, 2008), shows that

f (sk)     (1     1/e) max
s:|s|   k

 i.

(15)

f (s)     k(cid:88)

i=1

it turns out that the online greedy algorithm can be interpreted as a noisy version of the
(standard) greedy algorithm running on a larger instance (which encodes all t instances
the online greedy algorithm encounters), where the noise  i is exactly the regret of ai.
using known regret bounds for the case of selecting a single action then yields theorem 1.9.
streeter and golovin (2007) also provide results for other feedback models showing it is
possible to obtain expected average (1     1/e)-regret which converges to zero as t        , up
to and including the bandit feedback model in which only the reward of the set selected,
namely rt
, is observed at the end of round t (though in this very harsh feedback
model the convergence rate on (1     1/e)-regret is much slower).

s(t)
i   1

(cid:16)

(cid:17)

4.3 applications of online maximization of submodular functions

there are several applications that can bene   t from the results mentioned in   4.2. these
include online sensor selection, database query optimization, news recommendation sys-
tems, online ad selection, and combining multiple heuristics for computationally hard prob-
lems (streeter and golovin, 2008; golovin et al., 2010b; munagala et al., 2005; babu et al.,
2004; streeter et al., 2009; radlinski et al., 2008; streeter et al., 2007a). here we discuss
the problem of combining multiple heuristics in detail.

combining multiple heuristics online certain computationally hard problems such as
integer programming and boolean satis   ability are ubiquitous in industrial and scienti   c
applications, and a great deal of e   ort has gone into developing heuristics which solve them
as quickly as possible in practice. typically, there is no single heuristic which outperforms
all others on every instance. rather, heuristics often complement each other, so that there
are opportunities for combining them into a meta-heuristic that outperforms its constituent
heuristics in practice     in some cases by an order of magnitude or more. before giving a
concrete example where this e   ect occurs, we must clarify how heuristics are    combined.   
for this purpose, we use a task switching schedule:
de   nition 1.10 (run and task switching schedule) for a heuristic h and        r+, a run
is a pair (h,    ) representing the execution of h until either the problem is solved, or until   
time units have expired, after which execution is terminated. a task switching schedule is a

sequence of runs, {(hi,   i)}i   0, and it   s length is(cid:80)

i   0   i.

a task switching schedule   , such as the one illustrated in figure 2, represents a meta-
heuristic which performs its constituent runs in order and terminates immediately upon
   nding a solution. for example, the schedule (h1, 1), (h2, 1) will    rst run h1 until either the

submodular function maximization

17

figure 2 illustration of a task switching schedule over    ve heuristics output by the online greedy
algorithm.

solution is found or one time unit elapses, whichever comes    rst. if the    rst run terminates
without    nding the solution, the schedule next runs h2 until either the solution is found or
one time unit elapses, whichever comes    rst, and then terminates.

how is it that the best task switching schedule can outperform the best heuristic in it?
a simple concrete example of this is for boolean satis   ability (sat) where there are many
randomized heuristics. any    xed randomized heuristic h de   nes a family of deterministic
heuristics consisting of the h run with random seed r, denoted by hr, for each possible ran-
dom seed. empirically, the running time distribution of h with di   erent seeds on an given
sat instance    is commonly heavy tailed. hence it makes sense to periodically terminate
h and restart it with a fresh random seed. in an example given by streeter et al. (2007b),
a particular heuristic solver had about a 20% chance of solving an instance after running
for 2 seconds, but also a 20% chance that a run will not terminate after having run for
1000 seconds. hence restarting the solver every 2 seconds rather than simply running it
once until a solution is found reduces the mean time to solution by over an order of magni-
tude. when multiple solvers with complementary strengths are available, the potential for
speedups increases. in experiments, when given access to state   of   the-art solvers entered
into various academic competitions, the algorithm we are about to describe generated a
meta-solver, which signi   cantly outperformed all of the constituent solvers 5.

two natural performance measures are total execution time to solve a set of instances, and
percent of instances solved within a    xed time limit. the optimal task switching schedule
will often outperform the best heuristic on both measures simultaneously. while there are
strong empirical and theoretical results for both performance measures given by streeter
and golovin (2008), for clarity of exposition here we focus on the latter.
fix an arbitrary computational problem for which we have a    nite set of (possibly random-
ized) heuristics h, and    x a time bound b     z+. we formulate the problem of combining
heuristics as a problem of online maximization of submodular functions as follows. con-
of potential-runs in which (h,      )     v represents
a random run which is the actual run (h,    ) with id203 1/   and is (h, 0) (i.e., it does
nothing) otherwise. a sequence of instances of our problem arrives online, one per round.
in each round t the instance is represented by a monotone submodular function rt which
takes in a set of potential runs as input and gives the id203 that at least one of them
solves the instance. formally,

struct a ground set v = h   (cid:110)  1,   2, . . . ,   b

(cid:111)

(cid:19)

p [run (h,    ) solves instance t]

.

(16)

rt(s) := 1     (cid:89)

(h,     )   s

(cid:18)

1     1
  

18

given a set s of potential runs of size b, we sample a task switching schedule by sampling
their actual runs independently for each potential runs. the result is a set of runs r whose
total length is b in expectation, and whose id203 of solving the tth instance is precisely
rt(s) in expectation. hence in each round t we can use the online greedy algorithm to select
an ordered set of potential runs s(t), from which we can sample a task switching schedule
r(t). executing r(t) allows us to feedback unbiased estimates of the marginal increase in rt
from all of the potential runs, so that we are in the partially transparent feedback model.
t=1 that has vanishing average (1     1/e)-regret

hence we can generate a sequence (cid:8)s(t)(cid:9)t
resulting sampled sequence of task switching schedules (cid:8)r(t)(cid:9)t

against any    xed set of potential runs. with slightly more work, one can show that the
t=1 has vanishing average

(1     1/e)-regret against any    xed task switching schedule of length b.

4.4 online maximization with irrevocable choices: the submodular

secretaries problem

in the no   regret setting of section 4.1, the choices in any round are not constrained by
what one did in previous rounds, and (typically) the goal is to perform well on average.
by contrast, in the competitive online setting, one is faced with a sequence of irrevocable
decisions among options that are revealed over time, and the goal is to do well in hindsight
against any set of choices which were feasible given the revealed options. for example, in the
secretary problem, you must hire exactly one applicant from a pool of applicants (of known
size). each applicant has a score, which is revealed during their interview. the applicants
are interviewed in random order, and at the end of each interview you must irrevocably
hire or reject the applicant being interviewed. the goal is to    nd a strategy maximizing the
expected score of the hired applicant.

in submodular secretary problems, the applicants (denoted by the set v ) are also inter-
viewed in random order, and at the end of each interview you must irrevocably hire or
reject the applicant being interviewed. however, now you are allowed to hire any subset of
applicants in a feasible class f     2v (e.g., the independent sets of a matroid), and upon hir-
ing a set s of applicants your reward is f (s) for some nonnegative (possibly nonmonotone)
submodular function f . here, the function f is revealed to you during the interview process;
after interviewing a set a of applicants, you are granted access to an oracle computing f (s)
for any s     a. the goal is to    nd a strategy maximizing the expected reward of the hired
secretaries, measured with respect to f .

submodular secretary problems generalize several important problems in practice, such
as online bipartite matching (for e.g., matching display ads with search engine users) and
certain caching problems. gupta et al. (2010) and bateni et al. (2010) provide constant
competitive6 algorithms for the uniform matroid (where f = {s     v : |s|     k} for some k).
gupta et al. also give a o(log r)-competitive algorithm when f consists of the independent
sets of a matroid of rank r, and bateni et al. give an o((cid:96) log2 r)-competitive algorithm when
f is the intersection of the independent sets of (cid:96) matroids of rank at most r.

submodular function maximization

19

5 adaptive submodularity

in some applications we may wish to adaptively select a set, observing and taking into
account feedback after selecting any particular element. for example, we may wish to se-
quentially activate sensors, adaptively taking into account measurements provided by the
sensors selected so far when selecting the next sensor7. in such adaptive optimization prob-
lems, we must optimize over policies, i.e., functions from the information we have obtained
to the next action. there are many variants of the problem, depending on which modeling
assumptions (e.g., about the planning horizon, prior knowledge of the environment, and
how the environment is a   ected by our actions) and goals (e.g., worst-case vs. average case
reward) are suitable. many such problems are notoriously intractable. in this section, we
will review the notion of adaptive submodularity (golovin and krause, 2011b), a recent
generalization of submodularity to adaptive optimization, that allows to develop e   cient,
provably near-optimal policies to an interesting class of adaptive optimization problems.

example applications that exhibit adaptive submodular structure include problems in
active learning, where we must adaptively select data points to label to maximize the per-
formance of a classi   er trained on the selected data points, machine diagnosis, where we
must adaptively select tests to run on a patient or system to determine the best treatment
plan, and certain adaptive resource deployment problems, where we irrevocably commit re-
sources over time and may observe the bene   ts of our previous commitments before making
additional commitments.

5.1 the adaptive submodularity framework

in order to formalize adaptive optimization, we need to describe the process of how we
gather information. we model the state of the world abstractly as a random variable   ,
using    to refer to a concrete value that    can take. in our sensing application,    may refer
to the water quality at all nodes in the network. we presume a bayesian model, so that we
have a prior id203 p [  ] distribution over   . 8 we suppose there is a set of actions v
we can perform and a set of outcomes o we might observe. we interpret the world state
   as a function from actions to outcomes of those actions, i.e.,    : v     o and   (v) is the
outcome of performing action v. in our sensing application,   (v) may refer to the particular
measurement we obtain if we have a sensor at location v, and the world is in state   . we
represent the actions we have performed, as well as the outcomes we have observed as a
partial function    from actions to outcomes. hereby, the domain of   , denoted dom(  ), is
the set of actions performed up until that point. we call    a realization (of the world-state)
and    a partial realization. in our example,    may encode water quality measurements
obtained at a subset dom(  ) of nodes in the network. we assume there is an objective
function f : 2v    ov     r+ indicating the reward f (a,   ) obtained from actions a under
realization of the world state   . a policy    can then be represented as a function from
partial realizations    to the actions, so that   (  ) is the action taken by    upon observing
  . see figure 3 for an illustration. if    is not in the domain of   , then    terminates upon
observing   . finally, de   ne v (  ,   ) to be the set of actions played by    under realization
  . informally, two natural optimization problems that arise are to get the most value out

20

of a    xed number of actions, and to get a certain amount of value with as few actions as
possible. we formalize these as follows.

figure 3 a policy and its representation as a decision tree.

(cid:88)

adaptive stochastic maximization. based on the notation above, the expected reward
of a policy    is

favg(  ) := e [f (v (  ,   ),   )] =

p [  ] f (v (  ,   ),   ).

  

the goal of the adaptive stochastic maximization problem is to    nd a policy       such that

          arg max

  

favg(  ) subject to |v (  ,   )|     k for all   ,

(17)

where k is a budget on how many actions can be played (e.g., we would like to adaptively
choose k sensor locations such that the selected sensors provide as much information as
possible in expectation).

adaptive stochastic minimum cost cover. alternatively, we can specify a quota q of
reward that we would like to obtain, and try to    nd the cheapest policy achieving that quota
(e.g., we would like to achieve a certain amount of information, as cheaply as possible in
expectation). formally, we de   ne the average cost cavg(  ) of a policy as the expected number
of actions it plays, so that cavg(  ) := e [|v (  ,   )|]. our goal of this adaptive stochastic
minimum cost cover problem is then to    nd

          arg min

  

cavg(  ) such that f (v (  ,   ),   )     q for all   ,

(18)

i.e., the policy       that minimizes the expected number of items picked such that under all
possible realizations, at least reward q is achieved.

problems (17) and (18) are intractable in general, even to approximate to a factor of
o(|v |1    ), under reasonable complexity-theoretic assumptions. however, if f is satis   es
certain conditions, which generalize monotonicity and submodularity, then the classic results
bounding the performance of the greedy algorithm generalize. the following de   nitions are
from (golovin and krause, 2011b), and presume that in order to observe   , all the actions
in dom(  ) must have already been performed. they rely on a generalization of the discrete
derivative    (v | s) to the adaptive setting.

submodular function maximization

21

de   nition 1.11 (conditional expected marginal bene   t) given a partial realization   
and an item v, the conditional expected marginal bene   t of v conditioned on having observed
  , denoted    (v|   ), is

   (v|   ) := e [f (dom(  )     {v} ,   )     f (dom(  ),   ) |   ]

(19)

where the expectation is taken with respect to p [   |   ].
de   nition 1.12 (adaptive monotonicity) a function f : 2v    ov     r+ is adaptive
monotone with respect to distribution p [  ] if the conditional expected marginal bene   t of
any item is nonnegative, i.e., for all    with p [  ] > 0 and all v     v we have

   (v|   )     0.

(20)
de   nition 1.13 (adaptive submodularity) a function f : 2v    ov     r+ is adaptive
submodular with respect to distribution p [  ] if the conditional expected marginal bene   t
of any    xed item does not increase as more items are selected and their states are ob-
served. formally, f is adaptive submodular w.r.t. p [  ] if for all    and   (cid:48) such that    is a
subrealization of   (cid:48) (i.e.,          (cid:48)), and for all v     v \ dom(  (cid:48)), we have

   (v|   )        (v|   (cid:48)) .

(21)

adaptive submodularity generalizes the classical notion of submodularity, in the sense
that it reduces to submodularity in the case when the world state realization    is deter-
ministic. the same is true for adaptive monotonicity. not surprisingly, there is a natural
generalization of the greedy algorithm as well, called the adaptive greedy algorithm, which
iteratively selects the action maximizing the conditional expected marginal bene   t, condi-
tioned on the outcomes of all of its previous actions:

while not done

select v        arg maxv    (v|   );
observe   (v   );
set               {(v   ,   (v   ))};

(22)

for adaptive stochastic maximization, the algorithm terminates after selecting k actions.
for adaptive stochastic minimum cost cover, it stops when it has achieved the quota q of
value, i.e., when it has observed    such that f (dom(  ),   )     q for all           (treating    and
   as relations, i.e., sets of input   output pairs).

remarkably, it turns out that the adaptive greedy algorithm has performance guarantees
that generalize various classic results for the greedy algorithm, for example, theorem 1.5.

theorem 1.14 (golovin and krause 2011b) let   greedy
be the greedy policy implicitly
represented by the pseudocode in (22), run for (cid:96) iterations (so that it selects (cid:96) actions), and
let      

k be any policy selecting at most k actions for any realization   . then

(cid:96)

favg(  greedy

(cid:96)

favg(     
k)

(23)

)    (cid:16)

1     e   (cid:96)/k(cid:17)

where recall favg(  ) := e [f (v (  ,   ),   )] is the expected reward of   .

22

asadpour et al. (2008) prove theorem 1.14 for a special case of stochastic submodular
maximization. golovin and krause (2011b) also provide results for the adaptive stochastic
min-cost cover problem (18) that generalize theorem 1.6. furthermore, golovin and krause
(2011a) prove generalizations of results for maximizing monotone submodular functions un-
der matroid constraints. similarly, lazy evaluations (as discussed in   2) can still be applied
to accelerate the adaptive greedy algorithm.

5.2 example applications

as mentioned in the beginning of this section, the adaptive submodularity framework has
many applications. in some cases, greedily maximizing an adaptive submodular objective
is already the algorithm of choice in practice. the framework then immediately provides
theoretical justi   cation in the form of approximation guarantees, and allows us to speed
up existing algorithms. one example is active learning in the noiseless case (c.f., kosaraju
et al. 1999; dasgupta 2004; golovin and krause 2011b), in which we must adaptively select
data points to be labelled for us (at some cost) until we can infer the labeling of all data
points, while attempting to minimize the cost. in some other cases it is possible to frame
the problem in the form of optimizing a carefully designed adaptive submodular objective.
given such an objective, the adaptive greedy algorithm may be used with this new objective
to obtain a new approximation algorithm for the problem. recent work on active learning
with noise (golovin et al., 2010a; bellala and scott, 2010), where the labels we receive may
sometimes be incorrect, falls under this category. active learning with noise can also be
used to tackle sequential experimental design problems, in which an algorithm adaptively
selects experiments to perform in order to distinguish scienti   c theories.

another class of problems where adaptive submodularity is useful is for adaptively com-
mitting resources to achieve some goal. for example, in adaptive sensor placement one can
deploy a set of sensors one by one, and decide where to place the next sensor based on the
data obtained from previous sensors. in adaptive viral marketing, one must adaptively select
people to target with a viral ad campaign     for example, to receive a free subscription to
some service     on the premise that some of those targeted will enjoy the service, convince
their friends to join, who will in turn convince their friends, and so on. for more informa-
tion on these applications, see (golovin and krause, 2011b). golovin et al. (2011) consider
a dynamic resource allocation problem for conservation planning, in which a conservation
agency with a    xed annual budget selects additional land parcels to buy each year while at-
tempting to maximize the id203 that certain (rare or endangered) species persist in the
wild. liu et al. (2008) consider a joint query optimization problem for streaming database
systems; their problem is a special case of stochastic set cover, as discussed by golovin and
krause (2011b).

5.3 worst   case adaptive optimization

guillory and bilmes (2010, 2011) provide a di   erent recent approach to adaptive optimiza-
tion based on submodularity, tailored to the worst   case scenario in which the outcome of
any action is chosen adversarially. in their model there is a set of hypotheses h, actions v

submodular function maximization

23
with costs c : v     r+, and outcomes o, as well as a set of monotone submodular functions
{fh : h     h} of type 2v   o     r+, and a threshold        r+. upon performing action v, an
adversary selects outcome o     v(h   ), where h    is an adversarially chosen hypothesis. the
goal is to adaptively select, as cheaply as possible, actions until the resulting set of action   
outcome pairs achieves    reward measured with respect to fh    . guillory and bilmes provide
elegant reductions of this problem to a standard min-cost submodular cover problem, in-
cluding one which, surprisingly, works even in the presence of certain types of adversarially
selected noise. this allows them to obtain logarithmic approximations for these problems.
they empirically tested their algorithms on a movie recommendation task in which users
are asked a sequence of questions in an attempt to recommend movies for them to watch
immediately.

6 conclusions

we have reviewed the concept of submodular functions, a natural discrete analogue of con-
vex functions. focusing on the problem of maximizing submodular functions, we reviewed
guarantees about e   cient greedy methods, as well as more complex algorithms that can
handle complex combinatorial constraints. we discussed extensions of submodular opti-
mization to the online (no-regret and secretary) settings, as well as recent generalizations
of submodularity to adaptive (interactive) optimization problems such as active learning.

while much progress was recently made, there are many interesting open problems, such
as developing approximation algorithms for handling yet more general classes of constraints.
in particular, the online- and adaptive extensions are still rather little explored. lastly,
while we focused on submodular maximization, there is a large literature on submodular
minimization, with many open problems, such as the development of e   cient methods
for large-scale submodular minimization, and approximation algorithms for constrained
minimization.

submodularity is a broadly useful powerful concept, and we believe there are many in-
teresting applications of submodular optimization to machine learning, ai and computer
science in general yet to be discovered.

24

notes

1 the study of submodular functions goes back at least to lattice theory (bergmann, 1929).

edmonds (1970)    rst studied submodular functions in context of discrete optimization. see
(fujishige, 2005) and (schrijver, 2003) for an in-depth discussion of submodular functions and
their properties. this chapter focuses on modern results on submodular maximization.

2 there has been extensive research into algorithms for minimizing submodular functions (c.f.,
fujishige 2005; schrijver 2003). interestingly, unconstrained submodular minimization can be
done e   ciently, even if f can only be evaluated via a membership oracle (i.e., a black-box
subroutine), whereas unconstrained maximization is np-hard for general (non-monotone)
submodular functions, since it includes the maximum cut problem as a special case (via the
cut capacity example in section 1.1). there are also e   cient online algorithms for submodular
minimization in the no-regret framework (hazan and kale, 2009; jegelka and bilmes, 2011b),
which complement the results in section 4.

3 the sfo toolbox for submodular optimization is available for download under

http://mloss.org/software/view/201/

4 in some applications (c.f., kempe et al. 2003), calculating f (s) may itself be di   cult. in those
cases, we may only be able to approximately evaluate f (s) up to some multiplicative relative
error   . fortunately, most results about maximizing submodular functions are robust against
such error (c.f., goundan and schulz 2007; calinescu et al. 2011; streeter and golovin 2008;
golovin and krause 2011b).

5 empirical evaluations of the online submodular maximization approach to combining

heuristics appear in (streeter et al., 2008) and (streeter and golovin, 2008). additionally, a
solver named metaprover 1.0 developed based on these ideas competed in the sat and fnt
divisions of the 4th international joint conference on automated reasoning cade atp
system competition (http://www.cs.miami.edu/~tptp/casc/j4/), where it won both
divisions.

6 in the context of the submodular secretary problem, an algorithm is   -competitive if, in

expectation over the random ordering of the interviews, it obtains at least    times the optimal
value.

7 note that in contrast with the secretary problems of section 4.4, in the adaptive optimization

problems of section 5 the information we acquire depends on what action we select.

8 in general adaptive optimization problems, actions can alter the state of the world, however
the framework described in section 5 considers cases where the world state is a    xed sample
from the distribution, and does not change in response to our actions.

references

ageev, a. a., and sviridenko, m. i. 2004. pipage rounding: a new method of constructing
algorithms with proven performance guarantee. journal of combinatorial optimization, 8.
asadpour, arash, nazerzadeh, hamid, and saberi, amin. 2008. stochastic submodular maximiza-
tion. pages 477   489 of: wine    08: proc. of the 4th international workshop on internet and
network economics. berlin, heidelberg: springer-verlag.

auer, peter, cesa-bianchi, nicol`o, and fischer, paul. 2002. finite-time analysis of the multiarmed

bandit problem. machine learning, 47(2), 235   256.

auer, peter, bianchi, nicol`o, freund, yoav, and schapire, robert. 2003. the nonstochastic mul-

tiarmed bandit problem. siam j. comput., 32(1), 48   77.

babu, shivnath, motwani, rajeev, munagala, kamesh, nishizawa, itaru, and widom, jennifer.
2004. adaptive ordering of pipelined stream    lters. pages 407   418 of: proceedings of the 2004
acm sigmod international conference on management of data.

bateni, mohammadhossein, hajiaghayi, mohammadtaghi, and zadimoghaddam, morteza. 2010.
submodular secretary problem and extensions. pages 39   52 of: proceedings of the 13th inter-
national conference on approximation, and 14 the international conference on randomization,

submodular function maximization

25

and combinatorial optimization: algorithms and techniques. approx/random   10. berlin,
heidelberg: springer-verlag.

bellala, g., and scott, c. 2010. modi   ed group generalized binary search with near-optimal

performance guarantees. tech. rept. university of michigan.

bergmann, g. 1929. zur axiomatik der elementargeometrie. monatshefte f  ur mathematik und

physik, 36, 269   284.

birkho   , g. 1933. on the combination of subalgebras. cambridge philosophical society, 29,

441   464.

boykov, yuri, and jolly, marie-pierre. 2001. interactive graph cuts for optimal boundary and
region segmentation of objects in n-d images. in: international conference on computer
vision (iccv).

calinescu, g., and zelikovsky, a. 2005. the polymatroid steiner tree problems. journal of

combinatorial optimization, 3, 281   294.

calinescu, gruia, chekuri, chandra, pal, martin, and vondrak, jan. 2011. maximizing a submod-
ular set function subject to a matroid constraint. to appear in siam journal on computing.
cesa-bianchi, nicol`o, and lugosi, g  abor. 2006. prediction, learning, and games. cambridge

university press.

chekuri, chandra, and pal, martin. 2005. a recursive greedy algorithm for walks in directed

graphs. pages 245   253 of: focs.

chekuri, chandra, vondr  ak, jan, and zenklusen, rico. 2011. submodular function maximization
in: proceedings of the

via the multilinear relaxation and contention resolution schemes.
43rd acm symposium on theory of computing (stoc).

dasgupta, sanjoy. 2004. analysis of a greedy active learning strategy. pages 337   344 of: nips:

advances in neural information processing systems. mit press.

edmonds, jack. 1970. submodular functions, matroids and certain polyhedra. in: combinatorial

structures and their applications. gordon and breach, new york.

feige, u., mirrokni, v., and vondrak, j. 2007. maximizing non-monotone submodular functions.

in: focs.

feige, uriel. 1998. a threshold of ln n for approximating set cover. journal of the acm, 45(4),

634     652.

freund, y, and schapire, re. 1999. adaptive game playing using multiplicative weights. games

and economic behavior, 29(1-2), 79   103.

frieze, a. m. 1974. a cost function property for plant location problems. mathematical program-

ming, 7, 245   248. 10.1007/bf01585521.

fujishige, s. 1978. polymatroidal dependence structure of a set of random variables. inform.

contr., 39, 55   72.

fujishige, satoru. 2005. submodular functions and optimization. 2nd edn. vol. 58. north holland,

amsterdam: annals of discrete mathematics.

gharan, shayan oveis, and vondr  ak, jan. 2011. submodular maximization by simulated anneal-

ing. in: soda.

goldengorin, boris, sierksma, gerard, tijssen, gert a., and tso, michael. 1999. the data-
correcting algorithm for the minimization of supermodular functions. management science,
45(11), 1539   1551.

golovin, daniel, and krause, andreas. 2011a. adaptive submodular optimization under matroid

constraints. corr, abs/1101.4450.

golovin, daniel, and krause, andreas. 2011b. adaptive submodularity: theory and applications
in active learning and stochastic optimization. journal of arti   cial intelligence research
(jair). to appear.

golovin, daniel, krause, andreas, and ray, debajyoti. 2010a. near-optimal bayesian active

26

learning with noisy observations. pages 766   774 of: la   erty, j., williams, c. k. i., shawe-
taylor, j., zemel, r.s., and culotta, a. (eds), nips    10: advances in neural information
processing systems 23.

golovin, daniel, faulkner, matthew, and krause, andreas. 2010b. online distributed sensor
selection. in: proc. acm/ieee international conference on information processing in sensor
networks (ipsn).

golovin, daniel, krause, andreas, gardner, beth, converse, sarah j., and morey, steve. 2011.
in: aaai    11: proceedings of the

dynamic resource allocation in conservation planning.
twenty   fifth aaai conference on arti   cial intelligence.

goundan, pranava r., and schulz, andreas s. 2007. revisiting the greedy approach to submodular

set function maximization. working paper. massachusetts institute of technology.

guillory, andrew, and bilmes, je   . 2010. interactive submodular set cover. in: proc. international

conference on machine learning (icml).

guillory, andrew, and bilmes, je    a. 2011. simultaneous learning and covering with adversarial

noise. in: international conference on machine learning (icml).

gupta, anupam, roth, aaron, schoenebeck, grant, and talwar, kunal. 2010. constrained non-
monotone submodular maximization: o   ine and secretary algorithms. pages 246   257 of:
saberi, amin (ed), wine. lecture notes in computer science, vol. 6484. springer.

hazan, elad, and kale, satyen. 2009. online submodular minimization. pages 700   708 of: bengio,
y., schuurmans, d., la   erty, j., williams, c. k. i., and culotta, a. (eds), advances in neural
information processing systems 22.

jegelka, stefanie, and bilmes, je   . 2011a. submodularity beyond submodular energies: coupling

edges in graph cuts. in: cvpr.

jegelka, stefanie, and bilmes, je    a. 2011b. online submodular minimization for combinatorial

structures. in: international conference on machine learning (icml).

kawahara, yoshinobu, nagano, kiyohito, tsuda, koji, and bilmes, je   . 2009. submodularity cuts

and applications. in: nips.

kempe, david, kleinberg, jon, and tardos,   eva. 2003. maximizing the spread of in   uence through
a social network. pages 137   146 of: kdd    03: proceedings of the ninth acm sigkdd inter-
national conference on knowledge discovery and data mining. new york, ny, usa: acm.
kohli, pushmeet, kumar, pawan, and torr, philip. 2009. p 3 & beyond: move making algorithms
for solving higher order functions. ieee transactions on pattern analysis and machine
intelligence, 31(9), 1645     1656.

kosaraju, s. rao, przytycka, teresa m., and borgstrom, ryan s. 1999. on an optimal split
tree problem. pages 157   168 of: proc. of the 6th intl. workshop on algorithms and data
structures. london, uk: springer-verlag.

krause, a., and guestrin, c. 2005. near-optimal nonmyopic value of information in graphical

models. in: proc. of uncertainty in arti   cial intelligence (uai).

krause, a., and horvitz, e. 2008. a utility-theoretic approach to privacy and personalization.
in: proc. 23rd conference on arti   cial intelligence (aaai), special track on ai & the web.
krause, a., guestrin, c., gupta, a., and kleinberg, j. 2006. near-optimal sensor placements:
maximizing information while minimizing communication cost. in: proceedings of the fifth
international symposium on information processing in sensor networks (ipsn).

krause, a., singh, a., and guestrin, c. 2008a. near-optimal sensor placements in gaussian pro-
cesses: theory, e   cient algorithms and empirical studies. in: journal of machine learning
research, vol. 9.

krause, andreas. 2010. sfo: a toolbox for submodular function optimization. journal of

machine learning research (jmlr), 11, 1141   1144.

krause, andreas, and guestrin, carlos. 2007. near-optimal observation selection using submodular
functions. pages 1650   1654 of: aaai   07: proceedings of the 22nd national conference on
arti   cial intelligence. aaai press.

submodular function maximization

27

krause, andreas, leskovec, jure, guestrin, carlos, vanbriesen, jeanne, and faloutsos, christos.
2008b. e   cient sensor placement optimization for securing large water distribution net-
works. journal of water resources planning and management, 134(6), 516   526.

krause, andreas, mcmahan, brendan, guestrin, carlos, and gupta, anupam. 2008c. robust sub-
modular observation selection. journal of machine learning research (jmlr), 9(december),
2761   2801.

krause, andreas, rajagopal, ram, gupta, anupam, and guestrin, carlos. 2009. simultaneous
placement and scheduling of sensors. in: in proc. acm/ieee international conference on
information processing in sensor networks (ipsn).

krause, andreas, roper, alex, and golovin, daniel. 2011a. randomized sensing in adversarial
in: ijcai    11: proceedings of the 22nd international joint conference on

environments.
arti   cial intelligence. to appear.

krause, andreas, guestrin, carlos, gupta, anupam, and kleinberg, jon. 2011b. robust sen-
sor placements at informative and cost-e   ective locations. acm transactions on sensor
networks, 7(4).

kulik, a., shachnai, h., and tamir, t. 2009. maximizing submodular functions subject to multiple

linear constraints. in: proc. of acm-siam soda.

leskovec, jure, krause, andreas, guestrin, carlos, faloutsos, christos, vanbriesen, jeanne, and
glance, natalie. 2007. cost-e   ective outbreak detection in networks. pages 420   429 of: kdd
   07: proceedings of the 13th acm sigkdd international conference on knowledge discovery
and data mining. new york, ny, usa: acm.

lin, hui, and bilmes, je   . 2011. a class of submodular functions for document summariza-
tion. in: in north american chapter of the association for computational linguistics/human
language technology conference (naacl/hlt-2011).

liu, zhen, parthasarathy, srinivasan, ranganathan, anand, and yang, hao. 2008. near-optimal
algorithms for shared    lter evaluation in data stream systems. pages 133   146 of: sigmod
   08: proceedings of the 2008 acm sigmod international conference on management of data.
new york, ny, usa: acm.

lovasz, l. 1983. submodular functions and convexity. mathematical programming - state of the

art, 235   257.

minoux, m. 1978. accelerated id192 for maximizing submodular set functions. opti-

mization techniques, lncs, 234   243.

munagala, kamesh, babu, shivnath, motwani, rajeev, widom, jennifer, and thomas, eiter. 2005.
the pipelined set cover problem. pages 83   98 of: proceedings of the international conference
on database theory.

narasimhan, mukund, and bilmes, je   . 2004. pac-learning bounded tree-width id114.

in: uncertainty in arti   cial intelligence.

narasimhan, mukund, jojic, nebojsa, and bilmes, je   . 2005. q-id91. in: nips.
nemhauser, g. l., and wolsey, l. a. 1978. best algorithms for approximating the maximum of a

submodular set function. math. oper. research, 3(3), 177   188.

nemhauser, g. l., and wolsey, l. a. 1981. maximizing submodular set functions: formulations and
analysis of algorithms. studies on graphs and discrete programming, volume 11 of annals of
discrete mathematics.

nemhauser, george l., wolsey, laurence a., and fisher, marshall l. 1978. an analysis of approx-
imations for maximizing submodular set functions - i. mathematical programming, 14(1),
265   294.

radlinski, filip, kleinberg, robert, and joachims, thorsten. 2008. learning diverse rankings

with multi-armed bandits. pages 784   791 of: icml.

schrijver, alexander. 2003. combinatorial optimization : polyhedra and e   ciency. volume b, part

iv, chapters 39-49. springer.

28

schulman, john d., goldberg, ken, and abbeel, pieter. 2011. grasping and fixturing as submod-

ular coverage problems. in: isrr.

singh, amarjeet, krause, andreas, guestrin, carlos, kaiser, william j., and batalin, maxim a.
2007 (january). e   cient planning of informative paths for multiple robots. pages 2204   2211
of: international joint conference on arti   cial intelligence (ijcai).

singh, amarjeet, krause, andreas, and kaiser, william. 2009. nonmyopic adaptive informative
in: proc. international joint conference on arti   cial

path planning for multiple robots.
intelligence (ijcai).

stobbe, peter, and krause, andreas. 2010. e   cient minimization of decomposable submodular

functions. in: proc. neural information processing systems (nips).

streeter, matthew, and golovin, daniel. 2007. an online algorithm for maximizing submodular

functions. tech. rept. cmu-cs-07-171. carnegie mellon university.

streeter, matthew, and golovin, daniel. 2008. an online algorithm for maximizing submodular

functions. pages 1577   1584 of: nips.

streeter, matthew, golovin, daniel, and smith, stephen f. 2007a. combining multiple heuristics
online. pages 1197   1203 of: aaai    07: proceedings of the twenty   second aaai conference
on arti   cial intelligence. menlo park, california: aaai press.

streeter, matthew, golovin, daniel, and smith, stephen f. 2007b. restart schedules for ensembles
of problem instances. pages 1204   1210 of: aaai    07: proceedings of the twenty   second aaai
conference on arti   cial intelligence. menlo park, california: aaai press.

streeter, matthew, golovin, daniel, and smith, stephen f. 2008. combining multiple constraint
solvers: results on the cpai   06 competition data. pages 11   18 of: proceedings of the second
international csp solver competition.

streeter, matthew, golovin, daniel, and krause, andreas. 2009. online learning of assignments.
pages 1794   1802 of: bengio, y., schuurmans, d., la   erty, j., williams, c. k. i., and culotta,
a. (eds), nips    09: advances in neural information processing systems 22.

sviridenko, m. 2004. a note on maximizing a submodular set function subject to knapsack

constraint. operations research letters, 32, 41   43.

vondr  ak, jan. 2008. optimal approximation for the submodular welfare problem in the value oracle

model. pages 67   74 of: stoc.

vondr  ak, jan. 2010. submodularity and curvature: the optimal algorithm. rims kokyuroku

bessatsu, b23, 253   266.

wolsey, laurence a. 1982. an analysis of the greedy algorithm for the submodular set covering

problem. combinatorica, 2(4), 385   393.

