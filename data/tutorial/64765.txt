   #[1]pyimagesearch    feed [2]pyimagesearch    comments feed
   [3]pyimagesearch    keras and convolutional neural networks (id98s)
   comments feed [4]alternate [5]alternate

[6]navigation

   [7]pyimagesearch [8]pyimagesearch be awesome at opencv, python, deep
   learning, and id161

   [9]home

main menu

     * [10]start here
     * [11]practical python and opencv
     * [12]pyimagesearch gurus
     * [13]opencv 3 & 4 tutorials
     * [14]free crash course
     * [15]about
     * [16]contact

   [17]return to content

keras and convolutional neural networks (id98s)

   by [18]adrian rosebrock on april 16, 2018 in [19]deep learning,
   [20]keras, [21]tutorials

   creating a convolutional neural network using keras to recognize a
   bulbasaur stuffed pokemon [[22]image source]
   today   s blog post is part two in a three-part series on building a
   complete end-to-end image classification + deep learning application:
     * part 1: [23]how to (quickly) build a deep learning image dataset
     * part 2: keras and convolutional neural networks (today   s post)
     * part 3: running a keras model on ios (to be published next week)

   by the end of today   s blog post, you will understand how to implement,
   train, and evaluate a convolutional neural network on your own custom
   dataset.

   and in next week   s post, i   ll be demonstrating how you can take your
   trained keras model and deploy it to a smartphone app with just a few
   lines of code!

   to keep the series lighthearted and fun, i am fulfilling a childhood
   dream of mine and building a pokedex. a pokedex is a device that exists
   in the world of pokemon, a popular tv show, video game, and trading
   card series (i was/still am a huge pokemon fan).

   if you are unfamiliar with pokemon, you should think of a pokedex as a
   smartphone app that can recognize pokemon, the animal-like creatures
   that exist in the world of pokemon.

   you can swap in your own datasets of course, i   m just having fun and
   enjoying a bit of childhood nostalgia.

   to learn how to train a convolutional neural network with keras and
   deep learning on your own custom dataset, just keep reading.

   looking for the source code to this post?
   [24]jump right to the downloads section.

keras and convolutional neural networks

   in last week   s blog post we learned how we can [25]quickly build a deep
   learning image dataset     we used the procedure and code covered in the
   post to gather, download, and organize our images on disk.

   now that we have our images downloaded and organized, the next step is
   to train a convolutional neural network (id98) on top of the data.

   i   ll be showing you how to train your id98 in today   s post using keras
   and deep learning. the final part of this series, releasing next week,
   will demonstrate how you can take your trained keras model and deploy
   it to a smartphone (in particular, iphone) with only a few lines of
   code.

   the end goal of this series is to help you build a fully functional
   deep learning app     use this series as an inspiration and starting
   point to help you build your own deep learning applications.

   let   s go ahead and get started training a id98 with keras and deep
   learning.

our deep learning dataset

   figure 1: a montage of samples from our pokemon deep learning dataset
   depicting each of the classes (i.e., pokemon species). as we can see,
   the dataset is diverse, including illustrations, movie/tv show stills,
   action figures, toys, etc.

   our deep learning dataset consists of 1,191 images of pokemon,
   (animal-like creatures that exist in the world of pokemon, the popular
   tv show, video game, and trading card series).

   our goal is to train a convolutional neural network using keras and
   deep learning to recognize and classify each of these pokemon.

   the pokemon we will be recognizing include:
     * [26]bulbasaur (234 images)
     * [27]charmander (238 images)
     * [28]squirtle (223 images)
     * [29]pikachu (234 images)
     * [30]mewtwo (239 images)

   a montage of the training images for each class can be seen in figure 1
   above.

   as you can see, our training images include a mix of:
     * still frames from the tv show and movies
     * trading cards
     * action figures
     * toys and plushes
     * drawings and artistic renderings from fans

   this diverse mix of training images will allow our id98 to recognize our
   five pokemon classes across a range of images     and as we   ll see, we   ll
   be able to obtain 97%+ classification accuracy!

the convolutional neural network and keras project structure

   today   s project has several moving parts     to help us wrap our head
   around the project, let   s start by reviewing our directory structure
   for the project:
   keras and convolutional neural networks (id98s)
   shell

             dataset_________________________________________________
                     bulbasaur [234 entries]_____________________________
                     charmander [238 entries]____________________________
                     mewtwo [239 entries]________________________________
                     pikachu [234 entries]_______________________________
                     squirtle [223 entries]______________________________
             examples [6 entries]____________________________________
             pyimagesearch___________________________________________
                     __init__.py_________________________________________
                     smallervggnet.py____________________________________
             plot.png________________________________________________
             lb.pickle_______________________________________________
             pokedex.model___________________________________________
             classify.py_____________________________________________
             train.py________________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
             dataset
                   bulbasaur [234 entries]
                   charmander [238 entries]
                   mewtwo [239 entries]
                   pikachu [234 entries]
                   squirtle [223 entries]
             examples [6 entries]
             pyimagesearch
                   __init__.py
                   smallervggnet.py
             plot.png
             lb.pickle
             pokedex.model
             classify.py
             train.py

   there are 3 directories:
    1. dataset : contains the five classes, each class is its own
       respective subdirectory to make parsing class labels easy.
    2. examples : contains images we   ll be using to test our id98.
    3. the pyimagesearch  module: contains our smallervggnet  model class
       (which we   ll be implementing later in this post).

   and 5 files in the root:
    1. plot.png : our training/testing accuracy and loss plot which is
       generated after the training script is ran.
    2. lb.pickle : our labelbinarizer  serialized object file     this
       contains a class index to class name lookup mechamisn.
    3. pokedex.model : this is our serialized keras convolutional neural
       network model file (i.e., the    weights file   ).
    4. train.py : we will use this script to train our keras id98, plot the
       accuracy/loss, and then serialize the id98 and label binarizer to
       disk.
    5. classify.py : our testing script.

our keras and id98 architecture

   figure 2: a vggnet-like network that i   ve dubbed    smallervggnet    will
   be used for training a deep learning classifier with keras. you can
   find the full resolution version of this network architecture diagram
   [31]here.

   the id98 architecture we will be utilizing today is a smaller, more
   compact variant of the vggnet network, introduced by simonyan and
   zisserman in their 2014 paper, [32]very deep convolutional networks for
   large scale image recognition.

   vggnet-like architectures are characterized by:
    1. using only 3  3 convolutional layers stacked on top of each other in
       increasing depth
    2. reducing volume size by max pooling
    3. fully-connected layers at the end of the network prior to a softmax
       classifier

   i assume you already have keras installed and configured on your
   system. if not, here are a few links to deep learning development
   environment configuration tutorials i have put together:
     * [33]configuring ubuntu for deep learning with python
     * [34]setting up ubuntu 16.04 + cuda + gpu for deep learning with
       python
     * [35]configuring macos for deep learning with python

   if you want to skip configuring your deep learning environment, i would
   recommend using one of the following pre-configured instances in the
   cloud:
     * [36]amazon ami for deep learning with python
     * [37]microsoft   s data science virtual machine (did166) for deep
       learning

   let   s go ahead and implement smallervggnet , our smaller version of
   vggnet. create a new file named smallervggnet.py  inside the
   pyimagesearch  module and insert the following code:
   keras and convolutional neural networks (id98s)
   python

   # import the necessary packages_____________________________
   from keras.models import sequential_________________________
   from keras.layers.id172 import batchid172___
   from keras.layers.convolutional import conv2d_______________
   from keras.layers.convolutional import maxpooling2d_________
   from keras.layers.core import activation____________________
   from keras.layers.core import flatten_______________________
   from keras.layers.core import dropout_______________________
   from keras.layers.core import dense_________________________
   from keras import backend as k______________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   # import the necessary packages
   from keras.models import sequential
   from keras.layers.id172 import batchid172
   from keras.layers.convolutional import conv2d
   from keras.layers.convolutional import maxpooling2d
   from keras.layers.core import activation
   from keras.layers.core import flatten
   from keras.layers.core import dropout
   from keras.layers.core import dense
   from keras import backend as k

   first we import our modules     notice that they all come from keras.
   each of these are covered extensively throughout the course of reading
   [38]deep learning for id161 with python.

   note: you   ll also want to create an __init__.py  file inside
   pyimagesearch  so python knows the directory is a module. if you   re
   unfamiliar with __init__.py  files or how they are used to create
   modules, no worries, just use the    downloads    section at the end of
   this blog post to download my directory structure, source code, and
   dataset + example images.

   from there, we define our smallervggnet  class:
   keras and convolutional neural networks (id98s)
   python

   class smallervggnet:________________________________________
   	@staticmethod______________________________________________
   	def build(width, height, depth, classes):__________________
   		# initialize the model along with the input shape to be___
   		# "channels last" and the channels dimension itself_______
   		model = sequential()______________________________________
   		inputshape = (height, width, depth)_______________________
   		chandim = -1______________________________________________
   ____________________________________________________________
   		# if we are using "channels first", update the input shape
   		# and channels dimension__________________________________
   		if k.image_data_format() == "channels_first":_____________
   			inputshape = (depth, height, width)______________________
   			chandim = 1______________________________________________
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   class smallervggnet:
   @staticmethod
   def build(width, height, depth, classes):
   # initialize the model along with the input shape to be
   # "channels last" and the channels dimension itself
   model = sequential()
   inputshape = (height, width, depth)
   chandim = -1

   # if we are using "channels first", update the input shape
   # and channels dimension
   if k.image_data_format() == "channels_first":
   inputshape = (depth, height, width)
   chandim = 1

   our build method requires four parameters:
     * width : the image width dimension.
     * height : the image height dimension.
     * depth : the depth of the image     also known as the number of
       channels.
     * classes : the number of classes in our dataset (which will affect
       the last layer of our model). we   re utilizing 5 pokemon classes in
       this post, but don   t forget that you could work with the 807
       pokemon species if you downloaded enough example images for each
       species!

   note: we   ll be working with input images that are  96 x 96 with a depth
   of 3  (as we   ll see later in this post). keep this in mind as we
   explain the spatial dimensions of the input volume as it passes through
   the network.

   since we   re using the tensorflow backend, we arrange the input shape
   with    channels last    data ordering, but if you want to use    channels
   first    (theano, etc.) then it is handled automagically on lines 23-25.

   now, let   s start adding layers to our model:
   keras and convolutional neural networks (id98s)
   python

   		# conv => relu => pool____________________________________
   		model.add(conv2d(32, (3, 3), padding="same",______________
   			input_shape=inputshape))_________________________________
   		model.add(activation("relu"))_____________________________
   		model.add(batchid172(axis=chandim))_______________
   		model.add(maxpooling2d(pool_size=(3, 3)))_________________
   		model.add(dropout(0.25))__________________________________
   27
   28
   29
   30
   31
   32
   33
   # conv => relu => pool
   model.add(conv2d(32, (3, 3), padding="same",
   input_shape=inputshape))
   model.add(activation("relu"))
   model.add(batchid172(axis=chandim))
   model.add(maxpooling2d(pool_size=(3, 3)))
   model.add(dropout(0.25))

   above is our first  conv => relu => pool  block.

   the convolution layer has 32  filters with a 3 x 3  kernel. we   re using
   relu  the activation function followed by batch id172.

   our pool  layer uses a 3 x 3  pool  size to reduce spatial dimensions
   quickly from 96 x 96  to 32 x 32 (we   ll be using   96 x 96 x 3 input
   images to train our network as we   ll see in the next section).

   as you can see from the code block, we   ll also be utilizing dropout in
   our network architecture. dropout works by randomly disconnecting nodes
   from the current layer to the next layer. this process of random
   disconnects during training batches helps naturally introduce
   redundancy into the model     no one single node in the layer is
   responsible for predicting a certain class, object, edge, or corner.

   from there we   ll add  (conv => relu) * 2  layers before applying
   another pool  layer:
   keras and convolutional neural networks (id98s)
   python

   		# (conv => relu) * 2 => pool______________________________
   		model.add(conv2d(64, (3, 3), padding="same"))_____________
   		model.add(activation("relu"))_____________________________
   		model.add(batchid172(axis=chandim))_______________
   		model.add(conv2d(64, (3, 3), padding="same"))_____________
   		model.add(activation("relu"))_____________________________
   		model.add(batchid172(axis=chandim))_______________
   		model.add(maxpooling2d(pool_size=(2, 2)))_________________
   		model.add(dropout(0.25))__________________________________
   35
   36
   37
   38
   39
   40
   41
   42
   43
   # (conv => relu) * 2 => pool
   model.add(conv2d(64, (3, 3), padding="same"))
   model.add(activation("relu"))
   model.add(batchid172(axis=chandim))
   model.add(conv2d(64, (3, 3), padding="same"))
   model.add(activation("relu"))
   model.add(batchid172(axis=chandim))
   model.add(maxpooling2d(pool_size=(2, 2)))
   model.add(dropout(0.25))

   stacking multiple conv  and relu  layers together (prior to reducing
   the spatial dimensions of the volume) allows us to learn a richer set
   of features.

   notice how:
     * we   re increasing our filter size from 32  to 64 . the deeper we go
       in the network, the smaller the spatial dimensions of our volume,
       and the more filters we learn.
     * we decreased how max pooling size from 3 x 3  to 2 x 2  to ensure
       we do not reduce our spatial dimensions too quickly.

   dropout is again performed at this stage.

   let   s add another set of   (conv => relu) * 2 => pool :
   keras and convolutional neural networks (id98s)
   python

   		# (conv => relu) * 2 => pool______________________________
   		model.add(conv2d(128, (3, 3), padding="same"))____________
   		model.add(activation("relu"))_____________________________
   		model.add(batchid172(axis=chandim))_______________
   		model.add(conv2d(128, (3, 3), padding="same"))____________
   		model.add(activation("relu"))_____________________________
   		model.add(batchid172(axis=chandim))_______________
   		model.add(maxpooling2d(pool_size=(2, 2)))_________________
   		model.add(dropout(0.25))__________________________________
   45
   46
   47
   48
   49
   50
   51
   52
   53
   # (conv => relu) * 2 => pool
   model.add(conv2d(128, (3, 3), padding="same"))
   model.add(activation("relu"))
   model.add(batchid172(axis=chandim))
   model.add(conv2d(128, (3, 3), padding="same"))
   model.add(activation("relu"))
   model.add(batchid172(axis=chandim))
   model.add(maxpooling2d(pool_size=(2, 2)))
   model.add(dropout(0.25))

   notice that we   ve increased our filter size to 128  here. dropout of
   25% of the nodes is performed to reduce overfitting again.

   and finally, we have a set of fc => relu  layers and a softmax
   classifier:
   keras and convolutional neural networks (id98s)
   python

   		# first (and only) set of fc => relu layers_______________
   		model.add(flatten())______________________________________
   		model.add(dense(1024))____________________________________
   		model.add(activation("relu"))_____________________________
   		model.add(batchid172())___________________________
   		model.add(dropout(0.5))___________________________________
   ____________________________________________________________
   		# softmax classifier______________________________________
   		model.add(dense(classes))_________________________________
   		model.add(activation("softmax"))__________________________
   ____________________________________________________________
   		# return the constructed network architecture_____________
   		return model______________________________________________
   55
   56
   57
   58
   59
   60
   61
   62
   63
   64
   65
   66
   67
   # first (and only) set of fc => relu layers
   model.add(flatten())
   model.add(dense(1024))
   model.add(activation("relu"))
   model.add(batchid172())
   model.add(dropout(0.5))

   # softmax classifier
   model.add(dense(classes))
   model.add(activation("softmax"))

   # return the constructed network architecture
   return model

   the fully connected layer is specified by dense(1024) with a rectified
   linear unit activation and batch id172.

   dropout is performed a final time     this time notice that we   re
   dropping out 50% of the nodes during training. typically you   ll use a
   dropout of 40-50% in our fully-connected layers and a dropout with much
   lower rate, normally 10-25% in previous layers (if any dropout is
   applied at all).

   we round out the model with a softmax classifier that will return the
   predicted probabilities for each class label.

   a visualization of the network architecture of first few layers of
   smallervggnet  can be seen in figure 2 at the top of this section. to
   see the full resolution of our keras id98 implementation of
   smallervggnet , refer to the following [39]link.

implementing our id98 + keras training script

   now that smallervggnet  is implemented, we can train our convolutional
   neural network using keras.

   open up a new file, name it train.py , and insert the following code
   where we   ll import our required packages and libraries:
   keras and convolutional neural networks (id98s)
   python

   # set the matplotlib backend so figures can be saved in the 
   import matplotlib___________________________________________
   matplotlib.use("agg")_______________________________________
   ____________________________________________________________
   # import the necessary packages_____________________________
   from keras.preprocessing.image import imagedatagenerator____
   from keras.optimizers import adam___________________________
   from keras.preprocessing.image import img_to_array__________
   from sklearn.preprocessing import labelbinarizer____________
   from sklearn.model_selection import train_test_split________
   from pyimagesearch.smallervggnet import smallervggnet_______
   import matplotlib.pyplot as plt_____________________________
   from imutils import paths___________________________________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import random_______________________________________________
   import pickle_______________________________________________
   import cv2__________________________________________________
   import os___________________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   # set the matplotlib backend so figures can be saved in the background
   import matplotlib
   matplotlib.use("agg")

   # import the necessary packages
   from keras.preprocessing.image import imagedatagenerator
   from keras.optimizers import adam
   from keras.preprocessing.image import img_to_array
   from sklearn.preprocessing import labelbinarizer
   from sklearn.model_selection import train_test_split
   from pyimagesearch.smallervggnet import smallervggnet
   import matplotlib.pyplot as plt
   from imutils import paths
   import numpy as np
   import argparse
   import random
   import pickle
   import cv2
   import os

   we are going to use the "agg"  matplotlib backend so that figures can
   be saved in the background (line 3).

   the imagedatagenerator  class will be used for data augmentation, a
   technique used to take existing images in our dataset and apply random
   transformations (rotations, shearing, etc.) to generate additional
   training data. data augmentation helps prevent overfitting.

   line 7 imports the adam  optimizer, the optimizer method used to train
   our network.

   the labelbinarizer  (line 9) is an important class to note     this class
   will enable us to:
    1. input a set of class labels (i.e., strings representing the
       human-readable class labels in our dataset).
    2. transform our class labels into one-hot encoded vectors.
    3. allow us to take an integer class label prediction from our keras
       id98 and transform it back into a human-readable label.

   i often get asked hereon the pyimagesearch blog how we can transform a
   class label string to an integer and vice versa. now you know the
   solution is to use the labelbinarizer  class.

   the train_test_split  function (line 10) will be used to create our
   training and testing splits. also take note of our smallervggnet
   import on line 11     this is the keras id98 we just implemented in the
   previous section.

   readers of this blog are familiar with [40]my very own imutils package.
   if you don   t have it installed/updated, you can install it via:
   keras and convolutional neural networks (id98s)
   shell

   $ pip install --upgrade imutils_____________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   $ pip install --upgrade imutils

   if you are using a python virtual environment (as we typically do here
   on the pyimagesearch blog), make sure you use the workon  command to
   access your particular virtual environment before installing/upgrading
   imutils .

   from there, let   s parse our [41]command line arguments:
   keras and convolutional neural networks (id98s)
   python

   # construct the argument parse and parse the arguments______
   ap = argparse.argumentparser()______________________________
   ap.add_argument("-d", "--dataset", required=true,___________
   	help="path to input dataset (i.e., directory of images)")__
   ap.add_argument("-m", "--model", required=true,_____________
   	help="path to output model")_______________________________
   ap.add_argument("-l", "--labelbin", required=true,__________
   	help="path to output label binarizer")_____________________
   ap.add_argument("-p", "--plot", type=str, default="plot.png"
   	help="path to output accuracy/loss plot")__________________
   args = vars(ap.parse_args())________________________________
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   # construct the argument parse and parse the arguments
   ap = argparse.argumentparser()
   ap.add_argument("-d", "--dataset", required=true,
   help="path to input dataset (i.e., directory of images)")
   ap.add_argument("-m", "--model", required=true,
   help="path to output model")
   ap.add_argument("-l", "--labelbin", required=true,
   help="path to output label binarizer")
   ap.add_argument("-p", "--plot", type=str, default="plot.png",
   help="path to output accuracy/loss plot")
   args = vars(ap.parse_args())

   for our training script, we need to supply three required [42]command
   line arguments:
     * --dataset : the path to the input dataset. our dataset is organized
       in a dataset  directory with subdirectories representing each
       class. inside each subdirectory is ~250 pokemon images. see the
       project directory structure at the top of this post for more
       details.
     * --model : the path to the output model     this training script will
       train the model and output it to disk.
     * --labelbin : the path to the output label binarizer     as you   ll see
       shortly, we   ll extract the class labels from the dataset directory
       names and build the label binarizer.

   we also have one optional argument, --plot . if you don   t specify a
   path/filename, then a plot.png  file will be placed in the current
   working directory.

   you do not need to modify lines 22-31 to supply new file paths. the
   command line arguments are handled at runtime. if this doesn   t make
   sense to you, be sure to review my [43]command line arguments blog
   post.

   now that we   ve taken care of our command line arguments, let   s
   initialize some important variables:
   keras and convolutional neural networks (id98s)
   python

   # initialize the number of epochs to train for, initial lear
   # batch size, and image dimensions__________________________
   epochs = 100________________________________________________
   init_lr = 1e-3______________________________________________
   bs = 32_____________________________________________________
   image_dims = (96, 96, 3)____________________________________
   ____________________________________________________________
   # initialize the data and labels____________________________
   data = []___________________________________________________
   labels = []_________________________________________________
   ____________________________________________________________
   # grab the image paths and randomly shuffle them____________
   print("[info] loading images...")___________________________
   imagepaths = sorted(list(paths.list_images(args["dataset"]))
   random.seed(42)_____________________________________________
   random.shuffle(imagepaths)__________________________________
   33
   34
   35
   36
   37
   38
   39
   40
   41
   42
   43
   44
   45
   46
   47
   48
   # initialize the number of epochs to train for, initial learning rate,
   # batch size, and image dimensions
   epochs = 100
   init_lr = 1e-3
   bs = 32
   image_dims = (96, 96, 3)

   # initialize the data and labels
   data = []
   labels = []

   # grab the image paths and randomly shuffle them
   print("[info] loading images...")
   imagepaths = sorted(list(paths.list_images(args["dataset"])))
   random.seed(42)
   random.shuffle(imagepaths)

   lines 35-38 initialize important variables used when training our keras
   id98:
     * epochs:  the total number of epochs we will be training our network
       for (i.e., how many times our network    sees    each training example
       and learns patterns from it).
     * init_lr:  the initial learning rate     a value of 1e-3 is the
       default value for the adam optimizer, the optimizer we will be
       using to train the network.
     * bs:  we will be passing batches of images into our network for
       training. there are multiple batches per epoch. the bs  value
       controls the batch size.
     * image_dims:  here we supply the spatial dimensions of our input
       images. we   ll require our input images to be 96 x 96  pixels with
       3  channels (i.e., rgb). i   ll also note that we specifically
       designed smallervggnet with 96 x 96  images in mind.

   we also initialize two lists     data  and labels which will hold the
   preprocessed images and labels, respectively.

   lines 46-48 grab all of the image paths and randomly shuffle them.

   and from there, we   ll loop over each of those imagepaths :
   keras and convolutional neural networks (id98s)
   python

   # loop over the input images________________________________
   for imagepath in imagepaths:________________________________
   	# load the image, pre-process it, and store it in the data 
   	image = cv2.imread(imagepath)______________________________
   	image = cv2.resize(image, (image_dims[1], image_dims[0]))__
   	image = img_to_array(image)________________________________
   	data.append(image)_________________________________________
    ___________________________________________________________
   	# extract the class label from the image path and update th
   	# labels list______________________________________________
   	label = imagepath.split(os.path.sep)[-2]___________________
   	labels.append(label)_______________________________________
   50
   51
   52
   53
   54
   55
   56
   57
   58
   59
   60
   61
   # loop over the input images
   for imagepath in imagepaths:
   # load the image, pre-process it, and store it in the data list
   image = cv2.imread(imagepath)
   image = cv2.resize(image, (image_dims[1], image_dims[0]))
   image = img_to_array(image)
   data.append(image)
   # extract the class label from the image path and update the
   # labels list
   label = imagepath.split(os.path.sep)[-2]
   labels.append(label)

   we loop over the imagepaths  on line 51 and then proceed to load the
   image (line 53) and resize it to accommodate our model (line 54).

   now it   s time to update our data  and labels  lists.

   we call the keras img_to_array  function to convert the image to a
   keras-compatible array (line 55) followed by appending the image to our
   list called data (line 56).

   for our labels  list, we extract the label  from the file path on line
   60 and append it (the label) on line 61.

   so, why does this class label parsing process work?

   consider that fact that we purposely created our dataset directory
   structure to have the following format:
   keras and convolutional neural networks (id98s)
   shell

   dataset/{class_label}/{filename}.jpg________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   1
   dataset/{class_label}/{filename}.jpg

   using the path separator on line 60 we can split the path into an array
   and then grab the second-to-last entry in the list     the class label.

   if this process seems confusing to you, i would encourage you to open
   up a python shell and explore an example imagepath  by splitting the
   path on your operating system   s respective path separator.

   let   s keep moving. a few things are happening in this next code block    
   additional preprocessing, binarizing labels, and partitioning the data:
   keras and convolutional neural networks (id98s)
   python

   # scale the raw pixel intensities to the range [0, 1]_______
   data = np.array(data, dtype="float") / 255.0________________
   labels = np.array(labels)___________________________________
   print("[info] data matrix: {:.2f}mb".format(________________
   	data.nbytes / (1024 * 1000.0)))____________________________
   ____________________________________________________________
   # binarize the labels_______________________________________
   lb = labelbinarizer()_______________________________________
   labels = lb.fit_transform(labels)___________________________
   ____________________________________________________________
   # partition the data into training and testing splits using 
   # the data for training and the remaining 20% for testing___
   (trainx, testx, trainy, testy) = train_test_split(data,_____
   	labels, test_size=0.2, random_state=42)____________________
   63
   64
   65
   66
   67
   68
   69
   70
   71
   72
   73
   74
   75
   76
   # scale the raw pixel intensities to the range [0, 1]
   data = np.array(data, dtype="float") / 255.0
   labels = np.array(labels)
   print("[info] data matrix: {:.2f}mb".format(
   data.nbytes / (1024 * 1000.0)))

   # binarize the labels
   lb = labelbinarizer()
   labels = lb.fit_transform(labels)

   # partition the data into training and testing splits using 80% of
   # the data for training and the remaining 20% for testing
   (trainx, testx, trainy, testy) = train_test_split(data,
   labels, test_size=0.2, random_state=42)

   here we first convert the data  array to a numpy array and then scale
   the pixel intensities to the range  [0, 1]  (line 64). we also convert
   the labels  from a list to a numpy array on line 65. an info message is
   printed which shows the size (in mb) of the data  matrix.

   then, we binarize the labels utilizing scikit-learn   s labelbinarizer
   (lines 70 and 71).

   with deep learning, or any machine learning for that matter, a common
   practice is to make a training and testing split. this is handled
   on lines 75 and 76 where we create an 80/20 random split of the data.

   next, let   s create our image data augmentation object:
   keras and convolutional neural networks (id98s)
   python

   # construct the image generator for data augmentation_______
   aug = imagedatagenerator(rotation_range=25, width_shift_rang
   	height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,___
   	horizontal_flip=true, fill_mode="nearest")_________________
   78
   79
   80
   81
   # construct the image generator for data augmentation
   aug = imagedatagenerator(rotation_range=25, width_shift_range=0.1,
   height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
   horizontal_flip=true, fill_mode="nearest")

   since we   re working with a limited amount of data points (< 250 images
   per class), we can make use of data augmentation during the training
   process to give our model more images (based on existing images) to
   train with.

   data augmentation is a tool that should be in every deep learning
   practitioner   s toolbox. i cover data augmentation in the practitioner
   bundle of [44]deep learning for id161 with python.

   we initialize aug, our imagedatagenerator , on lines 79-81.

   from there, let   s compile the model and kick off the training:
   keras and convolutional neural networks (id98s)
   python

   # initialize the model______________________________________
   print("[info] compiling model...")__________________________
   model = smallervggnet.build(width=image_dims[1], height=imag
   	depth=image_dims[2], classes=len(lb.classes_))_____________
   opt = adam(lr=init_lr, decay=init_lr / epochs)______________
   model.compile(loss="categorical_crossid178", optimizer=opt
   	metrics=["accuracy"])______________________________________
   ____________________________________________________________
   # train the network_________________________________________
   print("[info] training network...")_________________________
   h = model.fit_generator(____________________________________
   	aug.flow(trainx, trainy, batch_size=bs),___________________
   	validation_data=(testx, testy),____________________________
   	steps_per_epoch=len(trainx) // bs,_________________________
   	epochs=epochs, verbose=1)__________________________________
   83
   84
   85
   86
   87
   88
   89
   90
   91
   92
   93
   94
   95
   96
   97
   # initialize the model
   print("[info] compiling model...")
   model = smallervggnet.build(width=image_dims[1], height=image_dims[0],
   depth=image_dims[2], classes=len(lb.classes_))
   opt = adam(lr=init_lr, decay=init_lr / epochs)
   model.compile(loss="categorical_crossid178", optimizer=opt,
   metrics=["accuracy"])

   # train the network
   print("[info] training network...")
   h = model.fit_generator(
   aug.flow(trainx, trainy, batch_size=bs),
   validation_data=(testx, testy),
   steps_per_epoch=len(trainx) // bs,
   epochs=epochs, verbose=1)

   on lines 85 and 86, we initialize our keras id98 model with 96 x 96 x 3
   input spatial dimensions. i   ll state this again as i receive this
   question often     smallervggnet was designed to accept 96 x 96 x 3
   input images. if you want to use different spatial dimensions you may
   need to either:
    1. reduce the depth of the network for smaller images
    2. increase the depth of the network for larger images

   do not go blindly editing the code. consider the implications larger or
   smaller images will have first!

   we   re going to use the adam  optimizer with learning rate decay (line
   87) and then compile  our model  with categorical cross-id178 since
   we have > 2 classes (lines 88 and 89).

   note: for only two classes you should use binary cross-id178 as the
   loss.

   from there, we make a call to the keras fit_generator  method to train
   the network (lines 93-97). be patient     this can take some time
   depending on whether you are training using a cpu or a gpu.

   once our keras id98 has finished training, we   ll want to save both the
   (1) model and (2) label binarizer as we   ll need to load them from disk
   when we test the network on images outside of our training/testing set:
   keras and convolutional neural networks (id98s)
   python

   # save the model to disk____________________________________
   print("[info] serializing network...")______________________
   model.save(args["model"])___________________________________
   ____________________________________________________________
   # save the label binarizer to disk__________________________
   print("[info] serializing label binarizer...")______________
   f = open(args["labelbin"], "wb")____________________________
   f.write(pickle.dumps(lb))___________________________________
   f.close()___________________________________________________
   99
   100
   101
   102
   103
   104
   105
   106
   107
   # save the model to disk
   print("[info] serializing network...")
   model.save(args["model"])

   # save the label binarizer to disk
   print("[info] serializing label binarizer...")
   f = open(args["labelbin"], "wb")
   f.write(pickle.dumps(lb))
   f.close()

   we serialize the model (line 101) and the label binarizer (lines
   105-107) so we can easily use them later in our classify.py  script.

   the label binarizer file contains the class index to human-readable
   class label dictionary. this object ensures we don   t have to hardcode
   our class labels in scripts that wish to use our keras id98.

   finally, we can plot our training and loss accuracy:
   keras and convolutional neural networks (id98s)
   python

   # plot the training loss and accuracy_______________________
   plt.style.use("ggplot")_____________________________________
   plt.figure()________________________________________________
   n = epochs__________________________________________________
   plt.plot(np.arange(0, n), h.history["loss"], label="train_lo
   plt.plot(np.arange(0, n), h.history["val_loss"], label="val_
   plt.plot(np.arange(0, n), h.history["acc"], label="train_acc
   plt.plot(np.arange(0, n), h.history["val_acc"], label="val_a
   plt.title("training loss and accuracy")_____________________
   plt.xlabel("epoch #")_______________________________________
   plt.ylabel("loss/accuracy")_________________________________
   plt.legend(loc="upper left")________________________________
   plt.savefig(args["plot"])___________________________________
   109
   110
   111
   112
   113
   114
   115
   116
   117
   118
   119
   120
   121
   # plot the training loss and accuracy
   plt.style.use("ggplot")
   plt.figure()
   n = epochs
   plt.plot(np.arange(0, n), h.history["loss"], label="train_loss")
   plt.plot(np.arange(0, n), h.history["val_loss"], label="val_loss")
   plt.plot(np.arange(0, n), h.history["acc"], label="train_acc")
   plt.plot(np.arange(0, n), h.history["val_acc"], label="val_acc")
   plt.title("training loss and accuracy")
   plt.xlabel("epoch #")
   plt.ylabel("loss/accuracy")
   plt.legend(loc="upper left")
   plt.savefig(args["plot"])

   i elected to save my plot to disk (line 121) rather than displaying it
   for two reasons: (1) i   m on a headless server in the cloud and (2) i
   wanted to make sure i don   t forget to save the plot.

training our id98 with keras

   now we   re ready to train our pokedex id98.

   be sure to visit the    downloads    section of this blog post to download
   code + data.

   then execute the following command to train the mode; while making sure
   to provide the [45]command line arguments properly:
   keras and convolutional neural networks (id98s)
   shell

   $ $ python train.py --dataset dataset --model pokedex.model 
   using tensorflow backend.___________________________________
   [info] loading images...____________________________________
   [info] data matrix: 252.07mb________________________________
   [info] compiling model...___________________________________
   [info] training network...__________________________________
   name: geforce gtx titan x___________________________________
   major: 5 minor: 2 memoryclockrate (ghz) 1.076_______________
   pcibusid 0000:09:00.0_______________________________________
   total memory: 11.92gib______________________________________
   free memory: 11.71gib_______________________________________
   epoch 1/100_________________________________________________
   29/29 [==============================] - 2s - loss: 1.4015 -
   epoch 2/100_________________________________________________
   29/29 [==============================] - 1s - loss: 0.8578 -
   epoch 3/100_________________________________________________
   29/29 [==============================] - 1s - loss: 0.7370 -
   ..._________________________________________________________
   epoch 98/100________________________________________________
   29/29 [==============================] - 1s - loss: 0.0833 -
   epoch 99/100________________________________________________
   29/29 [==============================] - 1s - loss: 0.0678 -
   epoch 100/100_______________________________________________
   29/29 [==============================] - 1s - loss: 0.0890 -
   [info] serializing network..._______________________________
   [info] serializing label binarizer..._______________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   $ $ python train.py --dataset dataset --model pokedex.model --labelbin
   lb.pickle
   using tensorflow backend.
   [info] loading images...
   [info] data matrix: 252.07mb
   [info] compiling model...
   [info] training network...
   name: geforce gtx titan x
   major: 5 minor: 2 memoryclockrate (ghz) 1.076
   pcibusid 0000:09:00.0
   total memory: 11.92gib
   free memory: 11.71gib
   epoch 1/100
   29/29 [==============================] - 2s - loss: 1.4015 - acc:
   0.6088 - val_loss: 1.8745 - val_acc: 0.2134
   epoch 2/100
   29/29 [==============================] - 1s - loss: 0.8578 - acc:
   0.7285 - val_loss: 1.4539 - val_acc: 0.2971
   epoch 3/100
   29/29 [==============================] - 1s - loss: 0.7370 - acc:
   0.7809 - val_loss: 2.5955 - val_acc: 0.2008
   ...
   epoch 98/100
   29/29 [==============================] - 1s - loss: 0.0833 - acc:
   0.9702 - val_loss: 0.2064 - val_acc: 0.9540
   epoch 99/100
   29/29 [==============================] - 1s - loss: 0.0678 - acc:
   0.9727 - val_loss: 0.2299 - val_acc: 0.9456
   epoch 100/100
   29/29 [==============================] - 1s - loss: 0.0890 - acc:
   0.9684 - val_loss: 0.1955 - val_acc: 0.9707
   [info] serializing network...
   [info] serializing label binarizer...

   looking at the output of our training script we see that our keras id98
   obtained:
     * 96.84% classification accuracy on the training set
     * and 97.07% accuracy on the testing set

   the training loss/accuracy plot follows:

   figure 3: training and validation loss/accuracy plot for a pokedex deep
   learning classifier trained with keras.

   as you can see in figure 3, i trained the model for 100 epochs and
   achieved low loss with limited overfitting. with additional training
   data we could obtain higher accuracy as well.

creating our id98 and keras testing script

   now that our id98 is trained, we need to implement a script to classify
   images that are not part of our training or validation/testing set.
   open up a new file, name it classify.py , and insert the following
   code:
   keras and convolutional neural networks (id98s)
   python

   # import the necessary packages_____________________________
   from keras.preprocessing.image import img_to_array__________
   from keras.models import load_model_________________________
   import numpy as np__________________________________________
   import argparse_____________________________________________
   import imutils______________________________________________
   import pickle_______________________________________________
   import cv2__________________________________________________
   import os___________________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   # import the necessary packages
   from keras.preprocessing.image import img_to_array
   from keras.models import load_model
   import numpy as np
   import argparse
   import imutils
   import pickle
   import cv2
   import os

   first we import the necessary packages (lines 2-9).

   from there, let   s parse command line arguments:
   keras and convolutional neural networks (id98s)
   python

   # construct the argument parse and parse the arguments______
   ap = argparse.argumentparser()______________________________
   ap.add_argument("-m", "--model", required=true,_____________
   	help="path to trained model model")________________________
   ap.add_argument("-l", "--labelbin", required=true,__________
   	help="path to label binarizer")____________________________
   ap.add_argument("-i", "--image", required=true,_____________
   	help="path to input image")________________________________
   args = vars(ap.parse_args())________________________________
   11
   12
   13
   14
   15
   16
   17
   18
   19
   # construct the argument parse and parse the arguments
   ap = argparse.argumentparser()
   ap.add_argument("-m", "--model", required=true,
   help="path to trained model model")
   ap.add_argument("-l", "--labelbin", required=true,
   help="path to label binarizer")
   ap.add_argument("-i", "--image", required=true,
   help="path to input image")
   args = vars(ap.parse_args())

   we   ve have three required [46]command line arguments we need to parse:
     * --model : the path to the model that we just trained.
     * --labelbin : the path to the label binarizer file.
     * --image : our input image file path.

   each of these arguments is established and parsed on lines 12-19.
   remember, you don   t need to modify these lines     i   ll show you how to
   run the program in the next section using the command line arguments
   provided at runtime.

   next, we   ll load and preprocess the image:
   keras and convolutional neural networks (id98s)
   python

   # load the image____________________________________________
   image = cv2.imread(args["image"])___________________________
   output = image.copy()_______________________________________
    ___________________________________________________________
   # pre-process the image for classification__________________
   image = cv2.resize(image, (96, 96))_________________________
   image = image.astype("float") / 255.0_______________________
   image = img_to_array(image)_________________________________
   image = np.expand_dims(image, axis=0)_______________________
   21
   22
   23
   24
   25
   26
   27
   28
   29
   # load the image
   image = cv2.imread(args["image"])
   output = image.copy()
   # pre-process the image for classification
   image = cv2.resize(image, (96, 96))
   image = image.astype("float") / 255.0
   image = img_to_array(image)
   image = np.expand_dims(image, axis=0)

   here we load the input  image  (line 22) and make a copy called output
   for display purposes (line 23).

   then we preprocess the image  in the exact same manner that we did for
   training (lines 26-29).

   from there, let   s load the model + label binarizer and then classify
   the image:
   keras and convolutional neural networks (id98s)
   python

   # load the trained convolutional neural network and the labe
   # binarizer_________________________________________________
   print("[info] loading network...")__________________________
   model = load_model(args["model"])___________________________
   lb = pickle.loads(open(args["labelbin"], "rb").read())______
   ____________________________________________________________
   # classify the input image__________________________________
   print("[info] classifying image...")________________________
   proba = model.predict(image)[0]_____________________________
   idx = np.argmax(proba)______________________________________
   label = lb.classes_[idx]____________________________________
   31
   32
   33
   34
   35
   36
   37
   38
   39
   40
   41
   # load the trained convolutional neural network and the label
   # binarizer
   print("[info] loading network...")
   model = load_model(args["model"])
   lb = pickle.loads(open(args["labelbin"], "rb").read())

   # classify the input image
   print("[info] classifying image...")
   proba = model.predict(image)[0]
   idx = np.argmax(proba)
   label = lb.classes_[idx]

   in order to classify the image, we need the model  and label binarizer
   in memory. we load both on lines 34 and 35.

   subsequently, we classify the image  and create the label  (lines
   39-41).

   the remaining code block is for display purposes:
   keras and convolutional neural networks (id98s)
   python

   # we'll mark our prediction as "correct" of the input image 
   # contains the predicted label text (obviously this makes th
   # assumption that you have named your testing image files th
   filename = args["image"][args["image"].rfind(os.path.sep) + 
   correct = "correct" if filename.rfind(label) != -1 else "inc
   ____________________________________________________________
   # build the label and draw the label on the image___________
   label = "{}: {:.2f}% ({})".format(label, proba[idx] * 100, c
   output = imutils.resize(output, width=400)__________________
   cv2.puttext(output, label, (10, 25),  cv2.font_hershey_simpl
   	0.7, (0, 255, 0), 2)_______________________________________
   ____________________________________________________________
   # show the output image_____________________________________
   print("[info] {}".format(label))____________________________
   cv2.imshow("output", output)________________________________
   cv2.waitkey(0)______________________________________________
   43
   44
   45
   46
   47
   48
   49
   50
   51
   52
   53
   54
   55
   56
   57
   58
   # we'll mark our prediction as "correct" of the input image filename
   # contains the predicted label text (obviously this makes the
   # assumption that you have named your testing image files this way)
   filename = args["image"][args["image"].rfind(os.path.sep) + 1:]
   correct = "correct" if filename.rfind(label) != -1 else "incorrect"

   # build the label and draw the label on the image
   label = "{}: {:.2f}% ({})".format(label, proba[idx] * 100, correct)
   output = imutils.resize(output, width=400)
   cv2.puttext(output, label, (10, 25),  cv2.font_hershey_simplex,
   0.7, (0, 255, 0), 2)

   # show the output image
   print("[info] {}".format(label))
   cv2.imshow("output", output)
   cv2.waitkey(0)

   on lines 46 and 47, we   re extracting the name of the pokemon from the
   filename  and comparing it to the label . the correct  variable will be
   either "correct"  or "incorrect"  based on this. obviously these two
   lines make the assumption that your input image has a filename that
   contains the true label.

   from there we take the following steps:
    1. append the id203 percentage and "correct" / "incorrect"  text
       to the class  label  (line 50).
    2. resize the output  image so it fits our screen (line 51).
    3. draw the label  text on the output  image (lines 52 and 53).
    4. display the output  image and wait for a keypress to exit (lines 57
       and 58).

classifying images with our id98 and keras

   we   re now ready to run the classify.py  script!

   ensure that you   ve grabbed the code + images from
   the    downloads    section at the bottom of this post.

   once you   ve downloaded and unzipped the archive change into the root
   directory of this project and follow along starting with an image of
   charmander. notice that we   ve provided three command line arguments in
   order to run the script:
   keras and convolutional neural networks (id98s)
   shell

   $ python classify.py --model pokedex.model --labelbin lb.pic
   	--image examples/charmander_counter.png____________________
   using tensorflow backend.___________________________________
   [info] loading network...___________________________________
   [info] classifying image..._________________________________
   [info] charmander: 99.77% (correct)_________________________
   1
   2
   3
   4
   5
   6
   $ python classify.py --model pokedex.model --labelbin lb.pickle \
   --image examples/charmander_counter.png
   using tensorflow backend.
   [info] loading network...
   [info] classifying image...
   [info] charmander: 99.77% (correct)

   figure 4: correctly classifying an input image using keras and
   convolutional neural networks.

   and now let   s query our model with the loyal and
   fierce [47]bulbasaur stuffed pokemon:
   keras and convolutional neural networks (id98s)
   shell

   $ python classify.py --model pokedex.model --labelbin lb.pic
   	--image examples/bulbasaur_plush.png_______________________
   using tensorflow backend.___________________________________
   [info] loading network...___________________________________
   [info] classifying image..._________________________________
   [info] bulbasaur: 99.35% (correct)__________________________
   1
   2
   3
   4
   5
   6
   $ python classify.py --model pokedex.model --labelbin lb.pickle \
   --image examples/bulbasaur_plush.png
   using tensorflow backend.
   [info] loading network...
   [info] classifying image...
   [info] bulbasaur: 99.35% (correct)

   figure 5: again, our keras deep learning image classifier is able to
   correctly classify the input image [[48]image source]
   let   s try a toy action figure of [49]mewtwo (a genetically engineered
   pokemon):
   keras and convolutional neural networks (id98s)
   shell

   $ python classify.py --model pokedex.model --labelbin lb.pic
   	--image examples/mewtwo_toy.png____________________________
   using tensorflow backend.___________________________________
   [info] loading network...___________________________________
   [info] classifying image..._________________________________
   [info] mewtwo: 100.00% (correct)____________________________
   1
   2
   3
   4
   5
   6
   $ python classify.py --model pokedex.model --labelbin lb.pickle \
   --image examples/mewtwo_toy.png
   using tensorflow backend.
   [info] loading network...
   [info] classifying image...
   [info] mewtwo: 100.00% (correct)

   figure 6: using keras, deep learning, and python we are able to
   correctly classify the input image using our id98. [[50]image source]
   what would an example pokedex be if it couldn   t recognize the infamous
   [51]pikachu:
   keras and convolutional neural networks (id98s)
   shell

   $ python classify.py --model pokedex.model --labelbin lb.pic
   	--image examples/pikachu_toy.png___________________________
   using tensorflow backend.___________________________________
   [info] loading network...___________________________________
   [info] classifying image..._________________________________
   [info] pikachu: 99.58% (correct)____________________________
   1
   2
   3
   4
   5
   6
   $ python classify.py --model pokedex.model --labelbin lb.pickle \
   --image examples/pikachu_toy.png
   using tensorflow backend.
   [info] loading network...
   [info] classifying image...
   [info] pikachu: 99.58% (correct)

   figure 7: using our keras model we can recognize the iconic pikachu
   pokemon. [[52]image source]
   let   s try the cute [53]squirtle pokemon:
   keras and convolutional neural networks (id98s)
   shell

   $ python classify.py --model pokedex.model --labelbin lb.pic
   	--image examples/squirtle_plush.png________________________
   using tensorflow backend.___________________________________
   [info] loading network...___________________________________
   [info] classifying image..._________________________________
   [info] squirtle: 98.62% (correct)___________________________
   1
   2
   3
   4
   5
   6
   $ python classify.py --model pokedex.model --labelbin lb.pickle \
   --image examples/squirtle_plush.png
   using tensorflow backend.
   [info] loading network...
   [info] classifying image...
   [info] squirtle: 98.62% (correct)

   figure 8: correctly classifying image data using keras and a id98.
   [[54]image source]
   and last but not least, let   s classify my fire-tailed [55]charmander
   again. this time he is being shy and is partially occluded by my
   monitor.
   keras and convolutional neural networks (id98s)
   shell

   $ python classify.py --model pokedex.model --labelbin lb.pic
   	--image examples/charmander_hidden.png_____________________
   using tensorflow backend.___________________________________
   [info] loading network...___________________________________
   [info] classifying image..._________________________________
   [info] charmander: 59.82% (correct)_________________________
   1
   2
   3
   4
   5
   6
   $ python classify.py --model pokedex.model --labelbin lb.pickle \
   --image examples/charmander_hidden.png
   using tensorflow backend.
   [info] loading network...
   [info] classifying image...
   [info] charmander: 59.82% (correct)

   figure 9: one final example of correctly classifying an input image
   using keras and convolutional neural networks (id98s).

   each of these pokemons were no match for my new pokedex.

   currently, there are around [56]807 different species of pokemon. our
   classifier was trained on only five different pokemon (for the sake of
   simplicity).

   if you   re looking to train a classifier to recognize more pokemon for a
   bigger pokedex, you   ll need additional training images for each
   class. ideally, your goal should be to have 500-1,000 images per class
   you wish to recognize.

   to acquire training images, i suggest that you [57]look no further than
   microsoft bing   s image search api. this api is hands down easier to use
   than the [58]previous hack of google image search that i shared (but
   that would work too).

limitations of this model

   one of the primary limitations of this model is the small amount of
   training data. i tested on various images and at times the
   classifications were incorrect. when this happened, i examined the
   input image + network more closely and found that the color(s) most
   dominant in the image influence the classification dramatically.

   for example, lots of red and oranges in an image will likely
   return    charmander    as the label. similarly, lots of yellows in an
   image will normally result in a    pikachu    label.

   this is partially due to our input data. pokemon are obviously
   fictitious so there no actual    real-world    images of them (other than
   the action figures and toy plushes).

   most of our images came from either fan illustrations or stills from
   the movie/tv show. and furthermore, we only had a limited amount of
   data for each class (~225-250 images).

   ideally, we should have at least 500-1,000 images per class when
   training a convolutional neural network. keep this in mind when working
   with your own data.

can we use this keras deep learning model as a rest api?

   if you would like to run this model (or any other deep learning model)
   as a rest api, i wrote three blog posts to help you get started:
    1. [59]building a simple keras + deep learning rest api (keras.io
       guest post)
    2. [60]a scalable keras + deep learning rest api
    3. [61]deep learning in production with keras, redis, flask, and
       apache

summary

   in today   s blog post you learned how to train a convolutional neural
   network (id98) using the keras deep learning library.

   our dataset was gathered [62]using the procedure discussed in last
   week   s blog post.

   in particular, our dataset consists of 1,191 images of five separate
   pokemon (animal-like creatures that exist in the world of pokemon, the
   popular tv show, video game, and trading card series).

   using our convolutional neural network and keras, we were able to
   obtain 97.07% accuracy, which is quite respectable given (1) the
   limited size of our dataset and (2) the number of parameters in our
   network.

   in next week   s blog post i   ll be demonstrating how we can:
    1. take our trained keras + convolutional neural network model   
    2.    and deploy it to a smartphone with only a few lines of code!

   it   s going to be a great post, don   t miss it!

   to download the source code to this post (and be notified when next
   week   s can   t miss post goes live), just enter your email address in the
   form below!

downloads:

   if you would like to download the code and images used in this post,
   please enter your email address in the form below. not only will you
   get a .zip of the code, i   ll also send you a free 17-page resource
   guide on id161, opencv, and deep learning. inside you'll find
   my hand-picked tutorials, books, courses, and libraries to help you
   master cv and dl! sound good? if so, enter your email address and i   ll
   send you the code immediately!

   email address: ____________________

   download the code!

resource guide (it   s totally free).

   get your free 17-page id161 and deep learning resource guide
   pdf
   enter your email address below to get my free 17-page id161,
   opencv, and deep learning resource guide pdf. inside you'll find my
   hand-picked tutorials, books, courses, and python libraries to help you
   master id161 and deep learning!
   ____________________
   download the guide!

   [63]convolutional neural network, [64]deep learning, [65]machine
   learning, [66]neural nets, [67]pokedex, [68]pokemon, [69]python
   [70]how to (quickly) build a deep learning image dataset
   [71]running keras models on ios with coreml

266 responses to keras and convolutional neural networks (id98s)

    1. anirban april 16, 2018 at 11:38 am [72]#
       brilliant post as usual.thanks for sharing your knowledge.
       [73]reply
          + adrian rosebrock april 16, 2018 at 2:00 pm [74]#
            thanks anirban!
            [75]reply
    2. baterdene april 16, 2018 at 11:53 am [76]#
       thanks.
       [77]reply
    3. [78]mohamed emad april 16, 2018 at 12:56 pm [79]#
       hello adrian you are as distinct as usual
       i have touched something very important that stops too many people
       he wonders how to train a nervous network of my own
       and how to use id98 resnet models
       thank you very much for your efforts in pushing people seriously
       forward
       i had a question about something to stop me and excuse me for this
       i was asking how i was implementing a gradual training for my model
       for example, i had a picture base for about 100 objects
       each object has 10,000 pictures
       a model was built for this data
       when i collect more pictures i want to add them to my model
       here i have to add pictures to the photo collection and then
       training again on all old and new photos?
       as everyone knows, this needs too much time.
       i learned about the incremental training but i do not know how to
       use it in practice
       using any method (caffe or keras or etc)
       i hope you will give me a place to help me with the solution
       thank you adrian
       [80]reply
          + adrian rosebrock april 16, 2018 at 1:59 pm [81]#
            hi mohamed     you could technically train from scratch but this
            would likely be a waste of resources each and every time you
            add new images. i would suggest a hybrid approach where you:
            1. apply fine-tuning to the network, perhaps on a weekly or
            monthly basis
            2. only re-train from scratch once every 3-6 months
            the timeframes should be changed based on how often new images
            are added of course so you would need to change them to
            whatever is appropriate for your project. i also cover how to
            fine-tune a network inside [82]deep learning for computer
            vision with python.
            [83]reply
               o [84]mohamed emad april 16, 2018 at 3:00 pm [85]#
                 thank you very much adrian for your response
                 i really benefited a lot from you
                 always forward
                 thank you
                 [86]reply
    4. akbar hidayatuloh april 16, 2018 at 10:01 pm [87]#
       if i want to split my dataset into train, test and validation, what
       is the good method to do that? not only splitting dataset into
       train and test only.
       thank you very much
       [88]reply
          + adrian rosebrock april 17, 2018 at 9:27 am [89]#
            you would use scikit-learn   s train_test_split function twice.
            the first time you split the data into two splits: training
            and testing.
            you then split a second time on the training data, creating
            another two splits: training and validation.
            this process will leave you with three splits: training,
            testing, and validation.
            [90]reply
               o akbar hidayatuloh april 19, 2018 at 9:03 am [91]#
                 thank you, that is really helpful.
                 now i want to try top-5 accuracy, do you know how to do
                 that?
                 [92]reply
                    # adrian rosebrock april 20, 2018 at 10:08 am [93]#
                      i discuss rank-5 accuracy, including how to compute
                      it, inside [94]deep learning for id161
                      with python.
                      the gist is that you need to:
                      1. loop over each of your test data points
                      2. predict the class labels for it
                      3. sort labels by their id203 in descending
                      order
                      4. check to see if ground-truth label exists in the
                      top 5 predicted labels
                      refer to [95]deep learning for id161 with
                      python for more details, including implementation.
                      [96]reply
               o adam_my september 13, 2018 at 6:27 am [97]#
                 nice post adrian!!!, while running , i have got this
                 error ,    error: the following arguments are required:
                 -d/   dataset, -m/   model, -l/   labelbin    , plz help me in
                 this..
                 [98]reply
                    # adrian rosebrock september 14, 2018 at 9:37 am [99]#
                      you need to supply the command line arguments to the
                      python script. make sure you read [100]this tutorial
                      to help get you started.
                      [101]reply
    5. gilad april 17, 2018 at 3:03 am [102]#
       update:
       i tried to do the same on 5 actresses. i got 44% accuracy on the
       validation and above 80% on the main group.
       i have ~280 pictures for each actress.
       how to increase the accuracy?
       1. increase the number of pictures
       2. try to find the face and work on it as roi
       do you have other ideas? maybe play with the training parameters
       (alpha)?
       [103]reply
          + adrian rosebrock april 17, 2018 at 9:22 am [104]#
            when performing face recognition you need to:
            1. detect the face and extract the face roi
            2. classify the face
            training a network to recognize faces on an entire image is
            not going to work well at all.
            [105]reply
    6. sagar patil april 17, 2018 at 6:48 am [106]#
       this dataset looks smaller than mnist! i thing you should rather
       teach us how to work with real world data, where there a lot of
       classes, and the data is much more imbalanced.
       [107]reply
          + adrian rosebrock april 17, 2018 at 9:19 am [108]#
            i discuss how to gather your own training data in a
            [109]previous post. the post you are commenting on is meant to
            be an introduction to keras and id98s. if you want an advanced
            treatment of the material with real-world data i would kindly
            refer you to my book, [110]deep learning for id161
            with python, where i have over 900+ pages worth of content on
            training deep neural networks on real-world data.
            [111]reply
    7. jesper april 17, 2018 at 7:00 am [112]#
       as always a really great post!
       i was wondering if it   s possible to classify several objects in a
       picture (an image with several pokemons in it?) kinda like in one
       of your other great posts
       [113]https://www.pyimagesearch.com/2017/10/16/raspberry-pi-deep-lea
       rning-object-detection-with-opencv/, using the models i train using
       keras?
       thank you so much for an awesome post
       [114]reply
          + adrian rosebrock april 17, 2018 at 9:17 am [115]#
            hey jesper     i   ll be writing a blog post on how and when you
            can use a id98 trained for image classification for object
            detection. the answer is too long to include in a comment as
            there is a lot to explain including when/where it   s possible.
            the post will be publishing on/around may 14th so keep an eye
            out for it.
            [116]reply
               o jesper april 18, 2018 at 4:27 am [117]#
                 you are the superman of so many things     thanks also for
                 the distinction between image classification and object
                 detection. these blogs are so good!
                 thanks again
                 [118]reply
                    # adrian rosebrock april 18, 2018 at 2:52 pm [119]#
                      thank you jesper, i really appreciate that     
                      [120]reply
    8. sean april 17, 2018 at 4:31 pm [121]#
       hi adrian, thank you for the great explanation in detail. during my
       id161 course we were given 2 projects and i have used a
       lot of algorithms from your website. in the last project it is not
       required to use deep-learning but i went for it anyways as a bonus,
       and i   m using your pokedex code.
       thanks!
       [122]reply
          + adrian rosebrock april 18, 2018 at 3:03 pm [123]#
            nice! best of luck with the project sean. i hope it goes well.
            [124]reply
    9. michael alex april 18, 2018 at 2:06 am [125]#
       good job as usual adrian. i learned so much from this blog series!
       [126]reply
          + adrian rosebrock april 18, 2018 at 3:00 pm [127]#
            thank you, michael! believe it or not, the series only gets
            better from here     
            [128]reply
   10. idhant april 18, 2018 at 3:03 am [129]#
       hi, i loved this post and found it really useful as a beginner
       learning about id98   s.
       although i was getting a    memory error    at this step:
       data = np.array(data, dtype=   float   ) / 255.0
       actually, i added around 5k images to    data    and have around 13
       classes    but clearly it is not working in this case    could you
       suggest anything to tackle this issue   
       [130]reply
          + adrian rosebrock april 18, 2018 at 2:59 pm [131]#
            your system does not have enough memory to store all images in
            ram. you can either:
            1. update the code to use a data generator and augmentor that
            loads images from disk in small batches
            2. build a serialized dataset, such as hdf5 format, and loop
            over the images in batches
            if you   re working with an image dataset too large to fit into
            main memory i would suggest reading through [132]deep learning
            for id161 with python where i discuss my best
            practices and techniques to efficiently train your networks
            (code is included, of course).
            [133]reply
   11. alex april 18, 2018 at 11:50 am [134]#
       hi adrian. how can i use this network to select the object in the
       image, such as the face.
       [135]reply
          + adrian rosebrock april 18, 2018 at 2:44 pm [136]#
            hi alex     what do you mean by    select   ? can you clarify?
            perhaps you are referring to id164 or face
            detection?
            [137]reply
               o alex april 19, 2018 at 2:24 am [138]#
                 how do i use my trained model for id164
                 [139]reply
               o alex april 19, 2018 at 1:11 pm [140]#
                 id164
                 [141]reply
                    # adrian rosebrock april 20, 2018 at 10:04 am [142]#
                      you cannot use this exact model for object
                      detection. deep learning object detectors fall into
                      various frameworks such as faster r-id98, single shot
                      detectors (ssds), yolo, and others. i cover them in
                      detail inside [143]deep learning for id161
                      with python where i also demonstrate how to train
                      your own custom deep learning object detectors. be
                      sure to take a look.
                      i   ll also have a blog post coming out in early may
                      that will help discuss the differences between
                      id164 and image classification. this has
                      become a common question on the pyimagesearch blog.
                      finally, if you are specifically interested in face
                      detection, [144]refer to this blog post.
                      [145]reply
   12. bostjan april 18, 2018 at 12:14 pm [146]#
       hi adrian,
       did you try to use id98 for iris recognition?
       thanks for great post.
       [147]reply
          + adrian rosebrock april 18, 2018 at 2:43 pm [148]#
            hi bostjan     the iris of the eye? i have not used id98s for
            iris recognition.
            [149]reply
   13. abdullah april 19, 2018 at 12:29 pm [150]#
       hi adrian
       i got this error before starting training
       using tensorflow backend.
       [info] loading images   
       libpng warning: incorrect bkgd chunk length
       [info] data matrix: 252.07mb
       [info] compiling model.
       can you clarify this for me?
       moreover, for the val_loss, after about 10 epochs it hit high loss
       number and get back to normal
       thanks
       [151]reply
          + adrian rosebrock april 20, 2018 at 10:05 am [152]#
            this is not an error, it   s just a warning that the libpng
            library when it tried to load a specific image from disk. it
            can be safely ignored.
            [153]reply
               o abdullah april 20, 2018 at 10:28 am [154]#
                 thanks a lot adrian for sharing the informative knowledge
                 <<
                 [155]reply
   14. abdullah april 20, 2018 at 10:29 am [156]#
       by the way, can i use this model for one classification only?
       [157]reply
          + adrian rosebrock april 20, 2018 at 12:21 pm [158]#
            i   m not sure what you mean by    one classification only       
            could you clarify?
            [159]reply
               o abdullah april 20, 2018 at 1:51 pm [160]#
                 for example, i want to detect only cats , so inside
                 dataset folder i will have only cats folder
                 [161]reply
                    # adrian rosebrock april 23, 2018 at 4:57 pm [162]#
                      to train a model you need at least two classes. if
                      you want to detect only cats you should create a
                      separate    background    or    ignore    class that
                      consists of random (typically    natural scene   )
                      images that do not contain cats. you can then train
                      your model to predict    cat    or    background   .
                      [163]reply
   15. gilad april 20, 2018 at 10:56 am [164]#
       hi adrian,
       i would like to know how to set class weights for imbalanced
       classes in keras.
       i remember i read it in dl4cv but i can   t find it.
       can you point me to the chapter?
       thx,
       g
       [165]reply
          + adrian rosebrock april 20, 2018 at 12:20 pm [166]#
            hi gilad     the chapter you are referring to is the    smile
            detection    chapter of the starter bundle.
            [167]reply
   16. tyler april 20, 2018 at 6:07 pm [168]#
       very neat article, though i think there is still something to be
       said about pokemon (and children   s media in general) being
       pre-engineered to be easily identifiable.
       musing about a real-life equivalent, many esteemed researchers
       argue over which animals belong is which categories.
       i would be interesting to see a neural net which classifies animals
       among say, the order of ungulates.
       really cool and great work! about to start on some hobby work
       involving keras and opencv installed in blender environment.
       wish me luck!
       [169]reply
   17. mustafa april 21, 2018 at 1:16 am [170]#
       hi adrian,
       thanks for your great post. i want to detect more than one object
       and draw rectangle around them. how can i modify code?
       [171]reply
          + adrian rosebrock april 23, 2018 at 12:00 pm [172]#
            classification models cannot be directly used for object
            detection. you would need a deep learning id164
            framework such as faster r-id98, ssd, or yolo. i cover them
            inside [173]deep learning for id161 with python.
            [174]reply
   18. akshay mathur april 21, 2018 at 1:55 pm [175]#
       amazing post. really helpful for my project. eagerly awaiting your
       next post.
       [176]reply
          + adrian rosebrock april 23, 2018 at 12:00 pm [177]#
            hi akshay     you can find the [178]keras + ios + coreml post
            here
            [179]reply
   19. shashank april 22, 2018 at 7:11 am [180]#
       hey can you also make a tutorial for id164 using keras..
       [181]reply
          + adrian rosebrock april 23, 2018 at 11:59 am [182]#
            i cover deep learning id164 inside [183]deep
            learning for id161 with python.
            [184]reply
               o srinivas january 24, 2019 at 10:42 am [185]#
                 sir,
                 i have your 3 books. could you please tell me where is
                 the chapter that covers deep learning id164.
                 [186]reply
                    # adrian rosebrock january 25, 2019 at 6:54 am [187]#
                      the    id163 bundle    and    bonus bundle    both cover
                      deep learning id164.
                      [188]reply
   20. [189]navendu sinha april 22, 2018 at 1:30 pm [190]#
       adrian a great post, something i have been looking forward to. how
       would you save the keras model in a h5 format.?
       [191]reply
          + adrian rosebrock april 23, 2018 at 11:58 am [192]#
            if you call the save method of a model it will write it to
            disk in a serialized hdf5 format.
            [193]reply
   21. akbar hidayatuloh april 24, 2018 at 4:41 am [194]#
       # scale the raw pixel intensities to the range [0, 1]
       data = np.array(data, dtype=   float   ) / 255.0
       labels = np.array(labels)
       when i   m doing scaling my own data set on size 224 x 224 i got
       memory error, but the error not occurred if i used size 128 x 128.
       how to solve that error? i need to use the data set with size 224 x
       224
       thank you very much,
       [195]reply
          + adrian rosebrock april 24, 2018 at 5:38 pm [196]#
            your system is running out of ram. your entire dataset cannot
            fit into ram. you can either (1) install more ram on your
            system or (2) use a combination of lazy loading data
            generators from disk or use a serialized dataset, such an hdf5
            file. i demonstrate how to do both inside [197]deep learning
            for id161 with python.
            [198]reply
   22. bog flap april 24, 2018 at 7:07 am [199]#
       ran this on your deep-learning-for-computer-vision ami on aws using
       a c4.2xlarge (the c4.xlarge instance type gave alloc errors, out of
       memory?) instance type and got the following
       [info] serializing label binarizer   
       exception ignored in: <bound method basesession.__del__ of >
       traceback (most recent call last):
       file
          /home/ubuntu/.virtualenvs/dl4cv/lib/python3.5/site-packages/tensor
       flow/python/client/session.py   , line 701, in __del__
       typeerror:    nonetype    object is not callable
       [200]reply
          + adrian rosebrock april 24, 2018 at 5:36 pm [201]#
            this is a problem with the tensorflow engine shutting down
            properly. it will only happen sporadically and since it only
            happens during termination of the script it can be safely
            ignored.
            [202]reply
   23. shubham kumar april 24, 2018 at 10:51 am [203]#
       hi adrian,
       thanks a lot for such a wonderful post. i am doing my project
       somewhat similar to this. but in my dataset, i have only two
       labels.
       one is background and in another different person with the
       background. i want to detect the presence of these people i.e i
       want to classify images into presence or absence (based on the
       presence of a person). but images in my dataset are of size 1092 x
       1048 pixels. i have resized them to 512 x 512 using cv2.resize()
       function.
       my question is can i use this same model for the training. if not,
       how can i decide the model suitable for this case? i believe i have
       to use a deeper network because the size of images used is much
       large.
       thanks.
       [204]reply
          + adrian rosebrock april 24, 2018 at 5:40 pm [205]#
            instead of training your model from scratch is there a reason
            you wouldn   t use existing deep learning networks that are
            trained to perform person detection? secondly, if you apply
            face detection using haar cascades or hog + linear id166 you may
            be able to skip using deep learning entirely.
            depending on your input images, in particular how large, in
            pixels, the person is in the image, you may need to play
            around with larger input image dimensions     it   s hard to say
            which one will work best without seeing your data.
            [206]reply
   24. scott april 24, 2018 at 2:46 pm [207]#
       great post! i went through this exercise with 250 images of water
       bottles, 250 of tennis balls, and 60 of dog poop. yes dog poop.
       there   s a story in there for later. anyway, it classifies anything
       that looks like any of the three classes as dog poop and one image
       of a tree as a tennis ball with 50% confidence. most of the images
       are fairly well cropped. the failures on water bottles and tennis
       balls really surprise me. is it likely that i just don   t have
       enough samples of the dog poop class?
       [208]reply
          + adrian rosebrock april 24, 2018 at 5:35 pm [209]#
            you may not have enough examples of the dog poop class but you
            may also want to compute the class weights to handle the
            imbalance.
            [210]reply
   25. bog flap april 25, 2018 at 8:09 am [211]#
       ran this code on aws running a c4.2xlarge instance. no problems.
       messed up first time using the wrong ami image, version 1.2 is
       required. i am running this again now using bee images obtained
       using the bing image search as outlined by you adrian, about 11000+
       images with 35 classes. i suspect i may need to run this on a gpu
       instance, only time will tell.
       [212]reply
          + adrian rosebrock april 25, 2018 at 10:17 am [213]#
            congrats on getting up and running with your dataset and
            network! for 11,000 images i would likely suggest a gpu
            instance, but that really depends on which model architecture
            you are using.
            [214]reply
               o bog flap april 26, 2018 at 5:39 am [215]#
                 you are quite right. do not have the time or budget to
                 use cpu only. even using just a single gpu gives a ten
                 times reduction in the time to produce the model, that is
                 using a p2.xlarge.
                 so now i am going to look at the microsoft offering and
                 see how it fairs.
                 [216]reply
   26. bog flap april 25, 2018 at 8:10 am [217]#
       that is bee   s as in honey bees
       [218]reply
   27. dirk april 25, 2018 at 12:40 pm [219]#
       adrian,
       thanks for your great work. these posts are extremely helpful.
       that said, i do have a question and wonder if you can help. i   m
       running a paperspace p5000 instance w/ 16gb gpu memory and 30 gb
       general memory. when i was running your example w/ tensorflow gpu
       support i got a memory warning/error.
          
       w tensorflow/core/framework/op_kernel.cc:1273] op_requires failed
       at constant_op.cc:207 : resource exhausted: oom when allocating
       tensor with shape[32,128,8,8] and type float on
       /job:localhost/replica:0/task:0/device:gpu:0
          
       is there any way to set this up, so it does not run into any
       issues? one would think that 16gb are enough for this example?
       thanks in advance for your answer.
       dirk
       [220]reply
          + adrian rosebrock april 26, 2018 at 3:54 pm [221]#
            hey dirk, i   m sorry to hear about the issues with the training
            process. 16gb of memory is way more than sufficient for this
            project. my guess is that you may be running some other job on
            your gpu at the same time and tensorflow cannot allocate
            enough memory? otherwise it may be a paperspace issue. perhaps
            try to launch a new instance and see if it   s the same result?
            unfortunately i   m not sure what the exact error is, other than
            it   s likely an issue with the specific instance.
            [222]reply
   28. matt april 25, 2018 at 4:17 pm [223]#
       hi adrian,
       really excited to get something working from this amazing series.
       i   m hitting an error running my train.py     i get to the line:
       [info] compiling model   
       and get a traceback error: attributeerror    nontype    object has no
       attribute    compile   
       i followed along and created all the scripts while going through
       you   re posts. i don   t currently have a .model file in my project
       structure, but figured it would be generated at this point of
       execution. what am i missing?
       thanks!
       [224]reply
          + adrian rosebrock april 26, 2018 at 3:50 pm [225]#
            it looks like your    model    object was never defined. you do
            not recommend copying and pasting along with the tutorial.
            it   s too easy to miss code snippets or point them in the right
            place. make sure you use the    downloads    section of this
            tutorial to download my code. from there you can compare it to
            your own and determine what snippet you missed.
            [226]reply
   29. bog flap april 26, 2018 at 5:32 am [227]#
       is it possible to convert the saved model to a format that can be
       used by the movidius neural compute stick (ncs). from the ncs
       documentation it seems that it will accept caffe or tensorflow
       format models.
       i know    read the docs    but i am wondering of anybody knows off the
       top of their heads or have even attempted to use the ncs in this
       context?
       i am looking to use this in conjunction with a raspberry pi. not
       the same kudos as the apple but a-lot cheaper overall.
       [228]reply
          + bog flap april 26, 2018 at 5:58 am [229]#
            dummkopf. i just spotted your article    getting started with
            the intel movidius neural compute stick   
            [230]reply
               o adrian rosebrock april 26, 2018 at 3:52 pm [231]#
                 keras models are not directly supported by the intel ncs
                 sdk and their team but from what i understand it is on
                 their roadmap. there is an [232]open source tool that
                 claims to port keras models to tensorflow graphs to ncs
                 graphs but i have not tried it and cannot speak to it
                 (other than it exists).
                 [233]reply
   30. [234]peshmerge april 26, 2018 at 8:59 am [235]#
       hi adrian,
       thanks for this great tutorial!
       i have a question.
       after training model with all pokemons. can i remove a specific
       pokemon (for example charmander) such that it can   t be recognized
       anymore?
       how can i do that?
       [236]reply
          + adrian rosebrock april 26, 2018 at 3:49 pm [237]#
            thanks, i   m glad you enjoyed it!     
            you would need to apply id21, in particular
            fine-tuning to remove or add classes from a trained network. i
            cover id21 and fine-tuning inside [238]deep
            learning for id161 with python.
            [239]reply
               o peshmerge morad april 29, 2018 at 3:34 am [240]#
                 thanks adrian! you rock     
                 [241]reply
   31. shashank rao april 27, 2018 at 9:56 am [242]#
       hey, can you also make a tutorial to develop a id164
       model using keras: ssd.
       [243]reply
          + adrian rosebrock april 27, 2018 at 10:10 am [244]#
            hey shashank     [245]deep learning for id161 with
            python already covers id164, ssds, and faster
            r-id98s. give it a look!
            [246]reply
   32. silverstone april 30, 2018 at 2:46 pm [247]#
       hey adrian,
       first of all thank you for this great tutorial. it helped me a lot!
       now i   m trying to deploy keras model on heroku with flask but i
       couldn   t handle it. can you make a tutorial about it?
       [248]reply
   33. mimrankhan may 1, 2018 at 6:45 am [249]#
       i am on window and run this command
       python classify.py    model pokedex.model    labelbin lb.pickle \
          image examples/charmander_counter.png
       but getting this error anybudy can help me
       usage: classify.py [-h] -m model -l labelbin -i image
       classify.py : error: the following arguments are required:
       -i/   image
       [250]reply
          + adrian rosebrock may 1, 2018 at 1:12 pm [251]#
            it looks like you   re using the [252]command line arguments
            correctly but it is not finding the image argument. perhaps in
            windows you need to enter all the arguments on one line
            without the backslash.
            [253]reply
   34. jay may 1, 2018 at 1:59 pm [254]#
       hi adrian,
       i   m a bit confused as to what    % (incorrect) or % (correct)    is
       telling us.
       say for example we were to try to classify an image of a dog after
       we train our model, and it outputs    mewtwo: 90% (incorrect)   , what
       is this telling us? does this mean that it is 90% sure that it is
       not a mewtwo?? if that   s the case, how did it come up with the
          mewtwo    part being that the input image is titled    dog_test   
       i hope the question makes sense
       thanks for all your hard work in making these tutorials they are
       incredibly helpful
       thanks
       [255]reply
          + adrian rosebrock may 3, 2018 at 10:08 am [256]#
            the    correct    and    incorrect    text is determined via the
            filename. it   s only used for visual validation and to show us
            that our network correctly predicted an object. it will check
            the filename for the class label and then compare that to the
            prediction. if it matches then the prediction is    correct   . if
            it does not match, the prediction is    incorrect   .
            [257]reply
   35. akbar hidayatuloh may 1, 2018 at 9:55 pm [258]#
       how to decode the predictions? so on the output shows all classes
       that we have, not only one class?
       thank you
       [259]reply
          + adrian rosebrock may 3, 2018 at 10:05 am [260]#
            hey akbar     are you referring to showing the probabilities +
            human readable class labels for each possible label?
            [261]reply
               o akbar hidayatuloh may 3, 2018 at 10:25 pm [262]#
                 yes, so i can implement that with flask to create rest
                 api
                 [263]reply
                    # adrian rosebrock may 7, 2018 at 1:15 pm [264]#
                      an easy way to do this would be to use the
                      labelencoder object   s    .transform    method.
                      [265]reply
   36. lisa may 1, 2018 at 10:37 pm [266]#
       thanks adrian for the wonderful post. i have question. if i want to
       run the model for image size 28x28x4 (28 pixels, 4 bands r,g,b,nir)
       where should i modify in the script?
       thanks again
       [267]reply
          + adrian rosebrock may 3, 2018 at 9:38 am [268]#
            yes, you will need to modify the network to accept an extra
            channel provided you would like to pass it through the
            network.
            [269]reply
               o lisa may 4, 2018 at 5:52 pm [270]#
                 hi adrian, thanks for your reply. can you briefly tell me
                 how do i do it? can you point me to some resources so i
                 can learn how to do it
                 [271]reply
                    # adrian rosebrock may 7, 2018 at 1:17 pm [272]#
                      unfortunately i do not have any tutorials on the
                      topic and none come to mind off the top of my head.
                      if i come across any i   ll come back and update this
                      comment.
                      [273]reply
   37. lisa may 1, 2018 at 10:44 pm [274]#
       i get an error attributeerror:    labelbinarizer    object has no
       attribute    classes_   
       can you help me ?
       [275]reply
          + adrian rosebrock may 3, 2018 at 9:38 am [276]#
            hey lisa     what version of scikit-learn are you using?
            [277]reply
               o lisa may 4, 2018 at 6:03 pm [278]#
                 i am using scikit-learn version 0.19.1
                 [279]reply
                    # adrian rosebrock may 7, 2018 at 1:11 pm [280]#
                      i created this project using scikit-learn 0.19.0 so
                      i doubt that   s the issue. perhaps try re-installing
                      scikit-learn and see if that resolves the issue.
                      [281]reply
               o adam_my september 14, 2018 at 1:37 am [282]#
                 hello adrian,thanx a lot for your contribution.i have
                 tried this and got a error like this
                    valueerror: y has 0 samples: array([], dtype=float64)   
                 .plz help me in this..
                 [283]reply
                    # adrian rosebrock september 14, 2018 at 9:23 am
                      [284]#
                      what line of code is throwing that error?
                      [285]reply
   38. shubham pandey may 3, 2018 at 6:04 am [286]#
       hey adrian, i have one question. suppose i have large collection of
       images say 5000 in each category and i do not want to use data
       augmentation just to reduce the burden on my cpu. i.e. i want to
       skip these lines:
       aug = imagedatagenerator(rotation_range=25, width_shift_range=0.1,
       height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
       horizontal_flip=true, fill_mode=   nearest   )
       how i can do that and how i need to modify model.fit_generator()
       h = model.fit_generator(
       aug.flow(trainx, trainy, batch_size=bs),
       validation_data=(testx, testy),
       steps_per_epoch=len(trainx) // bs,
       epochs=epochs, verbose=1)
       please help.
       [287]reply
          + adrian rosebrock may 3, 2018 at 9:28 am [288]#
            is there a particular reason you want to skip data
            augmentation? typically you would use it in nearly all
            situations. if you do not want to use the data augmentation
            object you can just call model.fit.
            [289]reply
               o shubham pandey may 4, 2018 at 4:23 am [290]#
                 i have already created multiple images from sample images
                 using contrast, brightness adjustment and adding random
                 noise. after combining these different sets i have final
                 collection of data-sets in which every class has around
                 5000 images. all these pre-processing is done using
                 opencv and python. also i am working on cpu, so i wanted
                 to reduce the complexity.
                 i do not want to perform data augmentation like
                 horizontal flip, crop and others because it may eliminate
                 the required region of interest.
                 [291]reply
                    # adrian rosebrock may 7, 2018 at 1:16 pm [292]#
                      got it, that makes sense. if you have already
                      created your image dataset manually and created the
                      data augmentation manually then you would just call
                      the    .fit    method of the model. that said, i would
                      still recommend creating a custom python class to
                      perform your required data augmentation on the fly.
                      [293]reply
   39. [294]imrankhan may 5, 2018 at 9:36 am [295]#
       hi, there is another way to write this im not using cmd argument
       filename = args[   image   ][args[   image   ].rfind(os.path.sep) + 1:]
       correct =    correct    if filename.rfind(label) != -1 else    incorrect   
       [296]reply
          + adrian rosebrock may 7, 2018 at 1:05 pm [297]#
            you would simply remove those lines. they would not be needed
            if (1) you are not using command line arguments and (2) your
            input image paths would not contain the label for the image
            (which the code would use to validate that the prediction is
            indeed correct).
            [298]reply
   40. arun may 5, 2018 at 11:13 am [299]#
       hello adrian,
       great post as always. i am trying to use the code for binary
       classification (say cat vs dog).
       gathered around ~200 samples each using bing api.
       1. changed id168 to binary_crossid178
       2. changed the final dense layer to have one class. (is this right
       ?)
       i am stuck at ~55% accuracy even after 100 epochs. both training
       and test accuracy are low.
       what am i missing here ? what needs to be changed ? really
       appreciate your help.
       thanks.
       [300]reply
          + adrian rosebrock may 7, 2018 at 1:12 pm [301]#
            no, the final dense layer needs to have as many nodes as there
            are class labels. if you have two classes you need two nodes
            in that final dense layer.
            [302]reply
   41. shubham kumar may 6, 2018 at 2:33 pm [303]#
       i did not get the concept behind it. why you have given same
       input_shape, each time you are using model.add function.
       model.add(conv2d(64, (3, 3),
       padding=   same   ,input_shape=inputshape))
       after every convolutional layer, the input shape should change. am
       i wrong? please clear my doubts.
       thanks.
       [304]reply
          + adrian rosebrock may 7, 2018 at 1:13 pm [305]#
            are you asking why i explicitly use the padding=   same   
            parameter? if so, i only want to reduce the volume size via
            the pooling operations not via convolution.
            [306]reply
               o shubham kumar may 7, 2018 at 3:13 pm [307]#
                 no, i was asking about parameter
                    input_shape=inputshape   . because after every
                 convolutional layer, the input shape should change but
                 here initial input shape of image is provided to every
                 layer.
                 i am really confused with the parameter input_shape.
                 [308]reply
                    # adrian rosebrock may 9, 2018 at 9:53 am [309]#
                      the conv layer is the first layer of the network. we
                      define the input shape based on the parameters
                      passed to the    build    method. for this example,
                      assuming tensorflow ordering, the input shape will
                      be (96, 96, 3) since our input images are 96  96 with
                      a depth of 3. based on our conv and pool layers the
                      volume size will change as it flows through the
                      network.
                      for more information, examples, and code on learning
                      the fundamentals of id98s + keras i would recommend
                      taking a look at [310]deep learning for computer
                      vision with python where i discuss the topic in
                      detail.
                      [311]reply
               o [312]arun may 10, 2018 at 3:01 am [313]#
                 please correct me if i am wrong.
                 i think what shubham is asking is, why are we giving
                 inputshape each time we add conv2d to our model. is it
                 not enough to give to the first layer alone ?
                 rest of the layers, it should be automatically calculated
                 from the previous layer   s dimensions right ?
                 in this case, even if we pass inputshape to conv2d in
                 other than first layer keras will ignore it i guess. even
                 if we remove inputshape parameter in the later layers it
                 should run fine. (it ran fine for me)
                 [314]reply
                    # adrian rosebrock may 11, 2018 at 10:25 am [315]#
                      thanks arun! i understand the question now.
                      yes, the input shape does not have to be explicitly
                      passed into the conv2d layer after the first one. it
                      does for the first, but not for all others. i
                      accidentally left it in when i was copying and
                      pasting the blocks of layers. i   ll get the post
                      updated to avoid any confusion. thanks arun and
                      shubham!
                      [316]reply
   42. dave xanatos may 6, 2018 at 7:42 pm [317]#
       thanks again for this. i just got back to this today and am running
       into an issue: it gets all the way to [info] training network    and
       then errors out with (ultimately) this at the end of the traceback:
       while using as loss    categorical_crossid178    expects targets to
       be binary matrices (1s and 0s) of shape (samples, classes). if your
       targets are integer classes, you can convert them to teh expected
       format via:
       from keras.utils import categorical y_binary =
       to_categorical(y_int)
       any ideas what i must have screwed up to be able to get that far,
       but no further?
       thanks for any help,
       dave
       [318]reply
          + prince bhatia may 17, 2018 at 2:34 am [319]#
            hi dave,
            i guess this error is all because of data. i tried using my
            own data set and received the same error.
            [320]reply
   43. kin may 7, 2018 at 12:23 pm [321]#
       thanks for such an awesome post. pokedex.model is an unknown area.
       did you code anything there which is not provided. what exactly it
       is?
       [322]reply
          + adrian rosebrock may 7, 2018 at 1:10 pm [323]#
            hi kin     could you clarify what you mean by    an unknown area   ?
            i   m not sure what you are referring to.
            [324]reply
               o kin may 7, 2018 at 1:16 pm [325]#
                 sorry adrian, i didn   t frame my question correctly. i
                 wanted to understand how to made pokedex.model. is it
                 pre-built for you prepared it. i am new to deep learning
                 and id161. pardon me if it   s a stupid
                 questions.
                 [326]reply
                    # adrian rosebrock may 7, 2018 at 1:18 pm [327]#
                      the    pokedex.model    file is created after you run
                      the    train.py    file in this post. the    train.py   
                      file trains a keras id98. this model is then
                      serialized to disk as    pokedex.model   . if you   re new
                      to deep learning i would suggest working through
                      [328]deep learning for id161 with python
                      to help you get up to speed.
                      [329]reply
                         @ kin may 7, 2018 at 1:30 pm [330]#
                           hi adrian, thanks for the response. i will
                           definitely start referring that.
   44. [331]danny may 8, 2018 at 7:09 am [332]#
       hi adrian, really thanks for the post, i tried it, and it works
       great, i added pidgeotto and works great to, but i dowloaded a
       dataset of food from here
       [333]https://www.vision.ee.ethz.ch/datasets_extra/food-101/
       the dataset is the same as the pokemon one, but there are a lot of
       classes, at the first time, i got the error in this line
       image = image.astype(   float   ) / 255.0   
       memory error   ,
       then i tried only with 20 classes and is running, but every epoch
       have 500 steps, and every time i see the next message :
       w tensorflow/core/framework/allocator.cc:101] allocation of
       33554432 exceeds 10% of system memory.
       but is working till now, is too much time, i dont know, maybe my
       computer is not good enough for running with that dataset, or i
       have to change the dataset, or make it for parts, i need help,
       thanks for your time.
       [334]reply
          + adrian rosebrock may 9, 2018 at 9:44 am [335]#
            this tutorial assumes that you can fit the entire image
            dataset into memory. the dataset is too large for you to fit
            into memory. take a look at keras       flow from directory   
            methods as a first start. you should also take a look at
            [336]deep learning for id161 with python where i
            demonstrate how to work with datasets that are too large to
            fit into memory.
            [337]reply
   45. diego may 8, 2018 at 1:00 pm [338]#
       hi adrian!, great job! i have a question    i was testing the neural
       network for facial recognition and the result i think was good with
       the training set, but with my testing set it shows    incorrect    and
       displays the correct name of the face label. and that result
       confused me. can you explain me why that happens? i   m new on this
       and i want to learn and understand more about it. pls help me to
       understand why it recognizes the face but shows incorrect.
       [339]reply
          + adrian rosebrock may 9, 2018 at 9:35 am [340]#
            i should really remove the    correct/incorrect    code from the
            post as it seems to be doing more harm than good and just
            confusing readers. keep in mind that our id98 has no idea if
            it   s classification is correct or not. we validate if the id98
            is correct (or incorrect) in its prediction by letting it
            investigate the input file path. if the input file path
            matches the correctly predicted label, we mark it as correct.
            this requires that our input file paths contain the class
            label of the image. this is done only for visualization
            purposes.
            again, if it   s confusing you, ignore that part of the code.
            i   ll be ripping it out of the post next week as again it   s
            just causing too much confusion.
            [341]reply
   46. lee may 10, 2018 at 3:43 pm [342]#
       hi adrian, i face this problem when i try to compile the code as
       you mention:
          typeerror: softmax() got an unexpected keyword argument    axis'   
       any idea how to solve this?
       thanks for your help
       [343]reply
          + adrian rosebrock may 11, 2018 at 10:23 am [344]#
            hey lee     what version of keras are you using? i haven   t
            encountered that particular error before.
            [345]reply
   47. usup may 11, 2018 at 11:54 am [346]#
       hi adrian
       can the above code run on a laptop? for example laptop i use i5 and
       8gb ram?
       thanks in advance, very cool tutorials
       [347]reply
          + adrian rosebrock may 11, 2018 at 12:17 pm [348]#
            yes, the code in this tutorial can run on a laptop (you do not
            need a gpu). if you want to use a different dataset keep in
            mind that this method will store the entire image dataset in
            memory. for a large dataset you   ll run out of ram so you would
            need to either (1) update the code to apply keras    flow
            through directory or (2) follow my method inside [349]deep
            learning for id161 with python where i demonstrate
            how to serialize an image dataset to disk and then efficiently
            load batches from the dataset into memory for efficient
            training.
            [350]reply
   48. prince bhatia may 14, 2018 at 4:16 am [351]#
       hi adrian,
       how can i test on batch not on individual images? i want to test it
       on batch.
       [352]reply
          + adrian rosebrock may 14, 2018 at 11:49 am [353]#
            the model.predict method will naturally accept batches of
            images, and in fact, our code is already working for batch
            processing, we are just using a    batch of one    for this
            example. to build a batch with more than one image you would
            loop over all images apply the pre-processing steps on lines
            26-29, building a numpy array of images as you go. from there
            you can pass the entire batch through the network. if you   re
            interested in learning more about batch image classification
            be sure to refer to [354]deep learning for id161
            with python.
            [355]reply
   49. prince bhatia may 14, 2018 at 6:02 am [356]#
       hi adrian,
       i was thinking what if in test images there are also images which
       doesn   t contain pokemon toys then what output it should produce.?
       [357]reply
          + adrian rosebrock may 14, 2018 at 11:46 am [358]#
            i would suggest training a separate class called    background   
            or    ignore   . take a look at [359]this blog post for more
            information.
            [360]reply
   50. josep may 15, 2018 at 5:47 am [361]#
       hi, if we have 1000 pokemon images for each class, how we know wich
       epochs and batch size would be correct in order to have a good
       accuracy?
       [362]reply
          + adrian rosebrock may 15, 2018 at 6:14 am [363]#
            the number of epochs and batches are called    hyperparameters   .
            we normally run many experiments to manually tune such
            hyperparameters. the batch size wouldn   t typically change
            (it   s normally the largest value that could fit in your gpu).
            the epochs may change but you would manually run experiments
            to determine this.
            [364]reply
   51. aman may 17, 2018 at 8:17 am [365]#
       hello
       i am trying to implement my own dataset on this id98 model . is it
       possible for the id98 to take multiple images at the same time and
       then classify. for example if i give 20 images of just charmandar
       during the testing phase and the network would use all those 20
       images and make a decision based on those images that what type of
       pokemen it is?
       thank you
       [366]reply
          + adrian rosebrock may 17, 2018 at 8:49 am [367]#
            yep! what you are referring to is called    batching   . id98s
            naturally batch process images. you would build a numpy of
            your (preprocessed) images and then pass them to the .predict
            method of the model. the model will classify all 20 of your
            images and return the probabilities of each label. if you had
            20 images and 100 classes you were predicting your returned
            array would be 20  100.
            [368]reply
   52. aman may 20, 2018 at 1:27 pm [369]#
       what if i give it 20 different images of the same pokemon and i
       want only one prediction?.
       for my application i have a time series classification problem i.e
       i have the data which has multiple time steps(samples) and each
       time step has multiple images but the same class and i want the
       model to take one time step consisting of multiple images and
       predict based on that complete time step
       also i do not know if i can specify each sample during the training
       phase or not to improve the accuracy of the model
       [370]reply
          + adrian rosebrock may 22, 2018 at 6:10 am [371]#
            there are a few ways to approach this but the most simple
            method would be to make predictions on all 20 images and then
            average the probabilities for each class together.
            [372]reply
   53. tomdertech may 21, 2018 at 3:49 pm [373]#
       hi adrian,
       in the    limitations    section you mention that    when this happened,
       i examined the input image + network more closely and found that
       the color(s) most dominant in the image influence the
       classification dramatically.   
       how do you delve into the model to find out what    features    such as
       color has the most    weight   . i wouldn   t have thought that the model
       is human readable?
       regards,
       tom
       [374]reply
          + adrian rosebrock may 22, 2018 at 5:58 am [375]#
            you can visualize the activations for each layer. [376]this
            article on the official keras blog will help you get started.
            [377]reply
   54. daniel may 21, 2018 at 6:07 pm [378]#
       hello. i am trying to do a model with a different dataset (only
       with two classes), and i stuck in this error, and i don   t know how
       to fix it. could you bring me a hand with it?
       this is an image of the error that i mentioned:
       [379]https://drive.google.com/open?id=1ezd-eecsajyioazqklent3ei7u7v
       zhqq
       thanks.
       [380]reply
          + adrian rosebrock may 22, 2018 at 5:57 am [381]#
            the scikit-learn implementation of labelbinarizer will not
            work for only two classes. instead, you should use the
               np_utils.to_categorical    function included in keras. also
            make sure you swap out categorical cross-id178 for binary
            cross-id178. be sure to refer to [382]this post to help you
            get started.
            [383]reply
   55. sridhar may 22, 2018 at 5:06 am [384]#
       hi adran,
       your posts and your books are highly inspirational and every time i
       read it enlightens more on these technologies. i tried this example
       as is and works absolutely fine and results are amazing. i have a
       question for you. i am already having both your books ppcv and dlcv
       (p bundle)
       i just want to keep 32 pixel x 32 pixel images of training data
       which a shape of an object. now i tried the same code. it fails. it
       gives me the following error
       valueerror: error when checking target: expected activation_7 to
       have shape (none, 2) but got array with shape (106, 1)
       so can you please help me where i have to change the code in the
       above exercise.
       [385]reply
          + adrian rosebrock may 22, 2018 at 5:52 am [386]#
            based on the error i think you have an issue parsing your
            class labels. double-check your label parsing and ensure they
            are vectorized properly.
            [387]reply
               o martin november 22, 2018 at 8:32 am [388]#
                 hi adrian
                 i am experiencing the same error.
                 how do i check that they are vectorized properly?
                 [389]reply
                    # adrian rosebrock november 25, 2018 at 9:27 am [390]#
                      after the    for    loop started on line 51 ends just
                      write your labels to your terminal:
                      print(labels)
                      make sure the output is what you expect. in this
                      case your input paths are likely incorrect in which
                      case the labels list won   t be populated properly.
                      [391]reply
   56. ben bartling may 30, 2018 at 5:10 pm [392]#
       hi adrian,
       when i run the code, these warnings pop up:
       libpng warning: iccp: known incorrect srgb profile.
       is that anything i should be worried about? should i modify my
       training data??
       i just found your blog and running the code examples are really
       easy & well written compared to others    will your new deep learning
       book go on sale again? i should have jumped on that!
       thanks   
       [393]reply
          + adrian rosebrock may 31, 2018 at 4:55 am [394]#
            that is a warning from the libraries used to load png images
            from disk via opencv. it is just a warning, it can be safely
            ignored and will not have an impact on training your keras
            model. as for a sale on my deep learning book, no, i do not
            have any plans to run another sale.
            [395]reply
   57. ben may 31, 2018 at 9:18 am [396]#
       hi adrian,
       can you help me out on one more tip? when i run the classify.py
       file after training, i get an error:
       classify.py: error: the following arguments are required: -i/   image
       i   m also on a linux os and everything is working up here    thanks so
       much for your time to respond   
       [397]reply
          + adrian rosebrock june 5, 2018 at 8:37 am [398]#
            if you   re new to python command line arguments you   ll want to
            read [399]this blog post.
            [400]reply
   58. rui may 31, 2018 at 8:36 pm [401]#
       hi adrian!
       i want to perform image classification on a dataset made of 1000
       classes of very similar objects (medical pills). i am going to
       fine-tune a pre-trained model like mobilenets or inception and then
       my idea is to deploy the model in a mobile app (android).
       i am wondering about the hardware limitations of the smartphone
       because the majority of tutorials and examples of mobile
       applications regarding image classification or id164
       focus on a limited amount of classes. i am not sure if this
       methodology of the 3-post series is adequate for my specific
       problem, what do you think?
       besides, i am worried about the similarity between the classes,
       which i believe would be an obstacle to obtaining a good
       performance!
       do you think it is possible to achieve a good performance?
       thank you so much for this series of posts, i really appreciate
       your work! keep going!
       [402]reply
          + adrian rosebrock june 5, 2018 at 8:33 am [403]#
            1. you   ll likely want to use a different architecture than the
            one i discussed here but keep in mind that state-of-the-art
            networks such as mobilenet can run on mobile devices. i
            wouldn   t be too worried about that yet.
            2. instead, what you should be worried about is the similarity
            of pills. try to solve that problem first. i have a lot of
            experience with prescription pill identification and i can
            tell you it   s an incredibly challenging problem.
            3. spend a lot of time gathering data of your example pills
            you want to recognize. you   ll need the data.
            [404]reply
               o rui june 5, 2018 at 8:10 pm [405]#
                 thanks for the reply, adrian.
                 i followed your series of posts which ended with the
                    deep learning in production with keras, redis, flask,
                 and apache    and ifound it pretty awesome. it would be a
                 solution if the mobile app used the api to perform the
                 classification, what do you think?
                 what would you recommend to deal with the similarity of
                 the pills and what does this problem so challenging, in
                 your opinion?
                 in my dataset, i have only 10 or so pictures per class.
                 would you do data augmentation beforehand?
                 thank you so much for you answers! it   s really important
                 for me to get feedback from an expert.
                 [406]reply
                    # adrian rosebrock june 7, 2018 at 3:16 pm [407]#
                      you could have the api perform classification but
                      keep in mind that will require the mobile device to
                      upload the image to the api which of course requires
                      an internet connection. that may or may not be
                      possible in some situations. you will need to do
                      your research there.
                      if you have only 10 images per class i would spend
                      your time building a larger dataset. you should be
                      in the 100-1,000 images/class range before trying to
                      train a id98 on pill images.
                      [408]reply
   59. prince bhatia june 6, 2018 at 4:21 am [409]#
       hi adrian,
       i am performing image classification on a data set made of 6
       different classes of 2000 images in each class of watermark
       detection.
       i tried your model but achieved the accuracy not more than 69%. i
       just found out that there are quite similar images but with
       different watermarks in each class, will they be causing the
       problem to achieve high accuracy on running my model on cpu
       version.?
       is there any other model would you recommend?
       how can i achieve high rate of accuracy when and what are the
       parameters do we need to keep in mind while preparing dataset?
       [410]reply
          + adrian rosebrock june 7, 2018 at 3:12 pm [411]#
            exactly which methods you should use and which techniques you
            should try is highly dependent on your project. without
            knowing what those six classes are or what your end goal is
            it   s extremely challenging to provide guidance. my best
            general advice in this instance would be to read through
            [412]deep learning for id161 with python where i
            discuss my tips, tricks, and best practices when training id98s
            on datasets.
            [413]reply
   60. xavier june 7, 2018 at 5:19 am [414]#
       hi,
       this is great as usual.
       i am wondering how do you chose the model to classify with in
       testing. the last (100th) epoch may not be the best. so, do you
       choose the one with the best validation accuracy ? or the smallest
       validation loss ?
       regards,
       xavier
       [415]reply
          + adrian rosebrock june 7, 2018 at 2:59 pm [416]#
            it really depends on the application. keras includes
            [417]methods and callbacks to handle serializing the    best   
            model based on whichever metric you choose.
            [418]reply
   61. rye june 7, 2018 at 11:24 am [419]#
       hey adrian!
       first of all thank you for such a great post! i am trying to
       classify the aerial satellite images which consists of one roof in
       every image and i am trying to classify them into their roof types.
       i have 3 classes with around 9000 images per class. do you
       recommend neural network from scratch since i don   t see any
       pre-trained model with such data similarity so i am a little
       dubious about id21. also, do you recommend data
       augmentation?
       also, i tried using your pokedex network for the same dataset but
       it validation accuracy seems to fluctuate a lot. do you have any
       inputs that might help me?
       thanks again!
       [420]reply
          + adrian rosebrock june 7, 2018 at 2:58 pm [421]#
            hey rye, there are a lot of things that can be addressed in
            this project but i would suggest backing up a bit:
            1. are you trying to perform classification, detection, or
            segmentation?
            2. unless you have a very specific reason not to you should
            always apply data augmentation.
            3. keep in mind that the pokedex network accepts 64  64 input
            images. without knowing what your images look like it   s hard
            for me to recommend a spatial input size but if you   re using
            aerial/satellite images you   ll likely need larger image
            dimensions.
            [422]reply
               o rye june 11, 2018 at 1:53 pm [423]#
                 i am trying to perform classification of roofs. i have
                 been able to extract aerial images with each image
                 containing exactly one roof and i want to determine the
                 type of the roof through the image. each image of
                 approximately of 256*256 size and i changed my network a
                 bit accordingly and it gives me an accuracy of
                 approximately 90%. my current network has 4 blocks of id98
                 with each block containing two layers.
                 the first layer has 2 convnet of size (64,110), batch
                 normalized, 2d pooling and dropout of 0.15. (relu)
                 the second layer has 2 convnet of size(84,84),batch
                 normalized, 2d pooling and dropout of 0.20. (relu)
                 the third layer has 2 convnet of size(64,64),batch
                 normalized, 2d pooling and dropout of 0.20. (relu)
                 the fourth layer has 2 convnet of size(128,128), batch
                 normalized, 2d poolind and dropout of 0.20 (relu)
                 the final layer is a dense layer, of 1024 and then number
                 of classes, softmax activation and dropout of 0..50.
                 i chaged my input dimensions to 112*112 and for 120
                 epochs, batch size of 48 and data augmentation it
                 performs okayish and i get and accuracy of around 90%. i
                 tried using inception v3 pre-trained model, froze some of
                 the layers and used my above mentioned last layer as the
                 last layer but i don   t get a result better than 80% from
                 that model.
                 any input from your end to make the model perform better
                 would be appreciated!
                 thank you,
                 rye
                 [424]reply
                    # adrian rosebrock june 13, 2018 at 5:50 am [425]#
                      thanks for the added details although i   m a bit
                      confused by what you mean of 2 conv layers of size
                      64  110. are those your output volume dimensions? or
                      number of filters?
                      as far as fine-tuning goes you may want to continue
                      to tune your hyperparameters. you may want to apply
                      feature extraction via the pre-trained net and train
                      a simple linear model on top of them.
                      in general i would recommend that you work through
                      [426]deep learning for id161 with python
                      so you can gain a better understanding of how to
                      train deep neural networks, including my best
                      practices, tips, and techniques.
                      [427]reply
   62. [428]victor liendo june 8, 2018 at 7:36 am [429]#
       hi adrian,
       after running the training script, all the ouptuts are generated ok
       (model, plot, lb), but i get the following message:
       exception ignored in: <bound method basesession.__del__ of >
       traceback (most recent call last):
       file
          /usr/local/lib/python3.5/dist-packages/tensorflow/python/client/se
       ssion.py   , line 701, in __del__
       typeerror:    nonetype    object is not callable
       any idea of whats happening
       [430]reply
          + adrian rosebrock june 13, 2018 at 6:14 am [431]#
            this is just a bug in tensorflow where the session manager is
            having an issue shutting down. it does not impact the results
            of training the model. you can safely ignore it.
            [432]reply
   63. suresh kumar june 18, 2018 at 5:33 am [433]#
       i am in training neural network, but it seems quite long process,
       so i reduce the epooch to 3 ..
       to see first the result, how its working ?
       after training,
       python classify.py    model pokedex.model    labelbin lb.pickle \
          image examples/charmander_counter.png
       the above line will work to see results ?
       [434]reply
          + adrian rosebrock june 19, 2018 at 8:44 am [435]#
            yes, training the model can take a bit of time, especially if
            you are using a cpu. if you would like to see the first result
            you would need to execute the classify.py script as you
            suggested.
            [436]reply
   64. vamshi june 19, 2018 at 7:34 am [437]#
       hey adrian,
       thanks for the post..
       can i get an option on command prompt to change the no of epochs,no
       of id98 layers,batch size,filter size etc using argparse without
       always editing the code..
       if so,how can i.?
       [438]reply
          + adrian rosebrock june 19, 2018 at 8:20 am [439]#
            hey vamshi, are you asking how to edit the command line
            arguments to include the number of epochs and batch size?
            [440]reply
               o vamshi june 20, 2018 at 6:23 am [441]#
                 yes sir..
                 or can i add a separate config file which can change the
                 variables like epochs,batch size as given in below
                 link..how to do that
                 [442]https://github.com/thtrieu/darkflow/blob/master/id18/
                 yolo.id18
                 [443]reply
                    # adrian rosebrock june 21, 2018 at 5:48 am [444]#
                      it   s totally possible but you would need to edit the
                      code significantly. i would suggest creating a
                      configuration file and then loading the
                      configuration file via a command line argument. then
                      pass the configurations into your optimizer, model,
                      etc. it will require you to refactor the code to
                      handle additional parameters to the constructor.
                      again, it   s possible, but i would only advise you to
                      continue if you feel comfortable enough with your
                      programming skills.
                      [445]reply
   65. farshad july 5, 2018 at 7:18 am [446]#
       thanks adrian. very well and good job. i have a question. is there
       any way to draw bounding box around each predicted object? is this
       tutorial an id164 or a classification problem? thanks a
       lot.
       [447]reply
          + adrian rosebrock july 10, 2018 at 9:07 am [448]#
            what you are referring to is    id164   . i would
            suggest [449]you read this blog post which will help you get
            up to speed.
            [450]reply
   66. [451]kemas farosi july 17, 2018 at 6:46 am [452]#
       hi adrian,
       it   s a great tutorial !!!!. i followed all of your instructions in
       here, but i have a question for you. why your deep learning model
       when i applied a new pokemon such as raticate, resulted similarly
       with charmander ? because logically, it should have low id203
       in all of trained pokemon animals
       [453]reply
          + adrian rosebrock july 17, 2018 at 6:59 am [454]#
            hey kemas     this model was not trained on raticate so the
            model has no idea what raticate actually looks like. you might
            want to take a look at [455]this post where we introduced
            another class to to train on, a    background   , indicating that
            the input image/frame should be ignored.
            [456]reply
   67. [457]arun july 20, 2018 at 10:26 pm [458]#
       hi adrian
       am a newbie to ml and your blogs have been really helping me!
       thanks a lot.
       q. you used lenet architecture earlier to solve a similar problem
       (santa/not-santa) and here you have used vggnet. but in both cases,
       you trained the model only on your data, and aren   t depending on
       pre-trained data (like keras blog suggests to use vgg16 directly
       for cat/dog classification). do you believe that would potentially
       increase the accuracy even further?
       generic q     how do you judge which approach works best, without
       trying out different options. i understand that depends on the
       problem, and the classes one is going after; but is there is an
       implicit qualitative ordering?
       [459]reply
          + adrian rosebrock july 21, 2018 at 9:12 am [460]#
            1. i   m actually not using vgg16. i   m training a smaller
            version called    smallervggnet    from scratch. the network is
            inspired by the vgg-family of networks but is not pre-trained
            on anything. you could certainly use    id21   
            (which is what you are referring to) to potentially increase
            accuracy.
            2. i   m not sure what you mean by    implicit qualitative
            ordering   . perhaps you can elaborate?
            [461]reply
               o [462]arun july 22, 2018 at 4:35 am [463]#
                 thanks for clarifying. all i meant was how do you know
                 which approach to try for any given image classification
                 problem     lenet, vggnet, resnet etc.. or for that matter
                 something not involving deep learning.. or do you try all
                 approaches, and then figure out which gives the best
                 results..
                 [464]reply
                    # adrian rosebrock july 25, 2018 at 8:22 am [465]#
                      got it, i understand now. i would suggest taking a
                      look at [466]deep learning for id161 with
                      python where i provide all of my best practices,
                      tips, and suggestions when approaching an image
                      classification problem with deep learning.
                      [467]reply
   68. sridhar july 24, 2018 at 5:27 am [468]#
       hi adrian,
       i have trained the above pokedex model on three different lables
       (images) say apple, mango and pineapple. i ran for 50 epochs. now
       when i try to classify mango and pineapple its correctly
       classifying with a decent accuracy. but if i give any other image
       like mobile phone that also classifying as either mango or
       pineapple, how do i get out of this problem
       please suggest .. thanks
       sridhar
       [469]reply
          + adrian rosebrock july 25, 2018 at 8:05 am [470]#
            you need to include a    background    or    ignore    class and train
            the model on random images that it may encounter in a
            real-world scenario that are not part of your fruit classes.
            [471]reply
   69. akusyn august 9, 2018 at 4:27 pm [472]#
       hi adrian
       thanks for this tutorial, it is very helpful for a newbie.
       you saved the model weights and labels separately but i have seen
       others which saves the model as signature, graphs and variables. i
       tried saving this model using savedmodelbuilder (model.pb,
       variables.data and variables.index) but is unable to load it again
       for subsequent classification.
       any suggestion/comments on using a different model save and reload
       is appreciated.
       thanks
       akusyn
       [473]reply
          + adrian rosebrock august 10, 2018 at 6:13 am [474]#
            the    savedmodelbuilder    function is actually a tensorflow
            function. we   re using keras in this blog post. you need to
            save the model using    model.save    i don   t believe
               savedmodelbuilder    is compatible directly with keras models
            (but i   ve never tried eitehr).
            [475]reply
   70. igor august 13, 2018 at 5:09 pm [476]#
       adrian,
       great post.
       any thoughts on which libraries to use for prediction?
       we can predict with keras, opencv dnn, dllib? which one should we
       choose? what it the best practice?
       thanks,
       igor
       [477]reply
          + adrian rosebrock august 15, 2018 at 8:44 am [478]#
            if you used keras to train your model, i would suggest you use
            keras for prediction. if you used dlib for training, use dlib
            for prediction.
            [479]reply
   71. jon august 13, 2018 at 8:57 pm [480]#
       hi adrian,
       great tutorial! i   ve been struggling forever on finding out how to
       format the training and testing data and labels.
       i   m currently doing id164 and classification and
       currently have a satellite dataset consisting of image chips
       (224  224) and each chip has multiple objects and classes. so what
       would the y_train and y_test look like? from all of the examples
       i   ve seen it looks like the ground truth data consists of a single
       class label per sample (i.e. a classification problem). my ground
       truth data consists of multiple bounding boxes and class labels per
       sample (e.g. image chip).
       do you have any suggestions on how i should format/structure my
       data based on the ground truth? thank you for your time!
       [481]reply
          + adrian rosebrock august 15, 2018 at 8:40 am [482]#
            keep in mind that id164 and image classification
            are different. i would suggest reading through [483]deep
            learning for id161 with python where i discuss my
            best practices for both id164 and image
            classification, including how to format and annotate your
            data. i think it will really help with your project!
            [484]reply
   72. fjr august 21, 2018 at 1:09 am [485]#
       always got    incorrect    result when predict the image, but the
       prediction is correct. i   m confused about    correct    and    incorrect   
       conditions here, could you explain to me the problem what i   ve got?
       thanks in advance
       [486]reply
          + adrian rosebrock august 22, 2018 at 9:41 am [487]#
            you should refer to my reply to [488]jay for a detailed
            discussion on    correct    vs.    incorrect   .
            [489]reply
   73. miguel august 26, 2018 at 1:51 pm [490]#
       hi, adrian. very big thanks for all your helpful knowledge. i am
       working in the project of simple    autonomous driving    based image
       depth using id98. i am a little bit good in id98, learned from your
       blog, but still confused how to compute image depth map using id98.
       would you please guide me or give me a guidance how to perform id98
       in that case.
       thank you very much in advance for your kindness.
       here are sample paper found from internet used id98 for image depth:
       [491]https://arxiv.org/pdf/1803.10039.pdf
       [492]https://arxiv.org/pdf/1805.01328.pdf
       [493]https://github.com/mrharicot/monodepth
       [494]reply
          + adrian rosebrock august 30, 2018 at 9:26 am [495]#
            hey miguel, it   s awesome that you are studying id161
            and deep learning. i don   t have any guides on estimating depth
            via single images with id98s. i might be able to cover that in
            the future, but i don   t know if or when that may be.
            [496]reply
   74. diptendu august 29, 2018 at 12:33 pm [497]#
       fantastic post    did try and got exact result that i wanted. thank
       you so much adrian !! ..
       [498]reply
          + adrian rosebrock august 30, 2018 at 8:56 am [499]#
            congrats on your successful result, diptendu! nice job.
            [500]reply
   75. aniket august 31, 2018 at 12:26 am [501]#
       hi adrian,
       i have been following you from long now.. i ran the above code with
       my own dataset. so i have a question. i had 9 classes and each
       class has 1020 images. i can see that the data is divided into 80%
       training data and 20% validation data. now when i am training on my
       dataset the training is happening on only    229 images   . so i tried
       to figure out why but i think i will need you help in this.
       so please let me know what am i doing wrong here.
       thanks,
       aniket
       [502]reply
          + adrian rosebrock september 3, 2018 at 5:07 pm [503]#
            hi aniket,
            this line:
            imagepaths = sorted(list(paths.list_images(args["dataset"])))
               will grab all images in your dataset. it assumes that your
            image classes in your dataset are organized into directories
            similar to the how the dataset is organized according to
            pokemon species. to verify that all of your 9*1020 images will
            be used for training, just print the length of the list:
            len(imagepaths)
            i hope that makes sense.
            [504]reply
   76. khaw oat august 31, 2018 at 5:23 am [505]#
       i can train another picture?
       [506]reply
          + adrian rosebrock september 5, 2018 at 9:23 am [507]#
            you can use this code to train your own id98 on your own custom
            image datasets.
            [508]reply
   77. mohammed august 31, 2018 at 7:28 am [509]#
       how can i get vector of features for every image in dataset?
       [510]reply
          + adrian rosebrock september 5, 2018 at 9:23 am [511]#
            are you referring to id21, and specifically
            feature extraction, using a id98?
            [512]reply
   78. marwa said august 31, 2018 at 9:12 am [513]#
       thank you so much for this simple beginner post
       i didn   t use keras before now i can     
       [514]reply
          + adrian rosebrock september 5, 2018 at 9:21 am [515]#
            awesome, congratulations marwa!
            [516]reply
   79. rick september 6, 2018 at 4:41 pm [517]#
       thanks for sharing your knowledge adrian!. i   d like to do the same
       thing but to recognize the number of fingers i am showing. i have 5
       folders with count 1 ,2 ,3 , til 5 fingers. i would like to get
       some help because i am getting a dimension error when using your
       code. can you please guide me what things i can change so it will
       run. thanks!
       [518]reply
          + adrian rosebrock september 11, 2018 at 8:36 am [519]#
            i actually cover that exact problem (and include code to solve
            it) inside the [520]pyimagesearch gurus course. be sure to
            take a look!
            [521]reply
   80. sean september 13, 2018 at 3:07 pm [522]#
       this has really helped me understand ml. i have actually modified
       this and am using my data and i can get great accuracy (greater
       than 90%) with my examples!
       what i am trying to do now is to pass it a directory of images
       instead of single image for classify.py. these image wont have the
       predicted names (i.e. you would change your charmander_counter to
       just be pokeman_counter) and i want to have the model.predict tell
       me if that image is a charmander, squirtlle, etc. and then save
       that image out with the % and predicted label (e.g.
       img1_charmander_95per.jpg)
       thoughts?
       [523]reply
          + adrian rosebrock september 14, 2018 at 9:29 am [524]#
            congrats on training your model and having it working, sean!
            nice job.
            to solve your problem you would need to:
            1. loop over all images in your directory of input images
            2. load each of the input images and preprocess them
            3. append them to an array (which is your    batch   )
            4. pass the batch through the network using the exact same
            code in the guide
            from there you   ll be able to loop over the results and obtain
            your probabilities.
            for more information on how to get started with id98s, build
            batches, and make predictions, i would recommend working
            through [525]deep learning for id161 with python
            where i include lots of practical examples and code to help
            you accomplish your project.
            [526]reply
   81. biswaranjan biswal september 15, 2018 at 11:33 am [527]#
       thank you for such a great tutorial
       but i   am facing some problems like    your cpu supports instructions
       that this tensorflow binary was not compiled to use: avx2   
       please suggest a solution.
       [528]reply
          + adrian rosebrock september 17, 2018 at 2:27 pm [529]#
            it   s not an error message, it   s just a suggestion from
            tensorflow that you could further optimize your pipeline. it
            does not affect your code. ignore it and keep going     
            [530]reply
   82. arkhaya september 19, 2018 at 4:53 am [531]#
       i have a problem, even after changing id168 to binary for 2
       labels as well. but we keep getting a problem saying activation_7
       was expecting (2,) but got (1,).
       i   m using 640 x 480 images that are 500 images per label. total
       1000 images. not sure how to solve the problem.
       [532]reply
          + adrian rosebrock october 8, 2018 at 1:29 pm [533]#
            i think you may be parsing your class labels incorrectly from
            the file paths. double-check that your class labels were
            parsed correctly.
            [534]reply
               o valentin bouis november 5, 2018 at 12:09 am [535]#
                 hi and thank you for this wonderfull tutorial ! i am
                 facing the same issue as @arkhaya with the error :
                 valueerror: error when checking target: expected
                 activation_7 to have shape (2,) but got array with shape
                 (1,)
                 when training the network. my labels are correctly
                 extracted from the files paths, even if i dont really
                 understand how the binarizer work. do you have
                 suggestions ? thanks again
                 [536]reply
                    # adrian rosebrock november 6, 2018 at 1:19 pm [537]#
                      how many labels are in your dataset? keep in mind
                      that you need at least two unique image categories
                      to train the network. according to your error you
                      may only have one class label.
                      [538]reply
                    # satthi february 10, 2019 at 1:29 am [539]#
                      hi valentin!
                      i have same issue even images are dog and cat. can
                      you kindly tell me how you solved this.
                      [540]reply
   83. ishay kaplan september 20, 2018 at 4:21 am [541]#
       hi adrian,
       thanks a lot for your posts, they are really great!
       2 questions:
       i have a dataset with pictures in a large number of different
       sizes, what are the considerations when coming to select the size
       which all the pics have to be resized to it?
       if the selected size won   t be 96*96, what are the rules which
       according to them i have to change the smallervggnet?
       [542]reply
          + adrian rosebrock october 8, 2018 at 1:18 pm [543]#
            your input image dimensions are typically dictated by which
            id98 architecture you are using. typically input image
            dimensions include 32  32, 64  64, 96  96, 227  227, and 256  256.
            if you want to increase your input image dimensions for
            smallervggnet you would likely need to add more layers to the
            network, but keep in mind that the more weights you add,
            typically the more data you   ll need to obtain a reasonable
            result. i would suggest you read through [544]deep learning
            for id161 with python for more information.
            [545]reply
   84. oat september 27, 2018 at 9:28 am [546]#
       can i use it on raspberry pi?
       [547]reply
          + adrian rosebrock october 8, 2018 at 12:29 pm [548]#
            yes, but i would recommend that you only run the trained
            network on the pi. i would not recommend actually training the
            network itself on the pi.
            [549]reply
   85. carnat october 11, 2018 at 8:51 am [550]#
       hi adrian,
       when i run train.py, on my anaconda prompt just showing    using
       tensorflow backend.    and the program is stop.
       what should i do? thanks.
       [551]reply
          + adrian rosebrock october 12, 2018 at 9:03 am [552]#
            are you sure it has fully stopped and hung? check your system
            monitor and ensure the process is still busy.
            [553]reply
               o carnat october 12, 2018 at 9:15 am [554]#
                 thanks adrian, it has been solved. i already run the py
                 script and i got my model.
                 and i have another question, can we use gpu on windows os
                 for modelling the image instead of using cpu?
                 [555]reply
                    # adrian rosebrock october 12, 2018 at 9:34 am [556]#
                      yes, but i do not support windows officially here on
                      the pyimagesearch blog. you   ll want to install
                      tensorflow with gpu support. from there tensorflow,
                      and therefore keras, will automatically access your
                      gpu.
                      [557]reply
   86. [558]artur barseghyan october 13, 2018 at 4:14 pm [559]#
       excellent article! thank you.
       i have a question. you resize images to 96  96 px for both training
       and classification. i have used 32  32 px and it does not affect
       classification accuracy negatively, but rather speeds up training
       process, as well as brings minor classification speed ups in
       loading time (4 ms vs 3 ms) and trained model size (9 mb vs 90 mb).
       i have about 300 images per category (1500 in total).
       don   t get me wrong, please. i certainly have no doubts that you
       definitely have reasons for using 96  96, but rather want to know
          why   .
       again, thanks a lot for your time and efforts!
       [560]reply
          + adrian rosebrock october 16, 2018 at 8:46 am [561]#
            thanks artur, i   m glad you liked the tutorial!
            as for why you would choose varying image sizes for a id98, it
            is entirely dependent on your dataset. for example, if objects
            in images are super small in a 96  96 image they would be
            virtually invisible if resized to 32  32. but if your object is
            the most dominant region of the image then you may be able to
            get away with a 32  32 image. again, it   s highly dependent on
            your exact use case, your dataset, and how much quality data
            you have.
            [562]reply
   87. ali nawaz october 14, 2018 at 12:48 pm [563]#
       hello sir, your books and tutorials are just great.
       when i read your book and implementing the code it works fine but
       now i got this error    nonetype object has no attribute compile   .
       [564]reply
          + adrian rosebrock october 16, 2018 at 8:40 am [565]#
            it sounds like you introduced an error when copying and
            pasting the code. make sure you use the    downloads    section of
            the code to download the source code, ensuring it matches
            mine.
            [566]reply
   88. matt october 16, 2018 at 1:41 am [567]#
       hi adrain:
       i am very excited to see this blog, and tried to which runs well.
       but i   ve met one problem, i tried other pic which is not in these
       class, but it will become one of these class and the correct rate
       is very high. how can i solve it?
       [568]reply
          + adrian rosebrock october 16, 2018 at 8:15 am [569]#
            you need to add a separate class to the architecture and name
            it    unknown   ,    don   t care   , or something similar. then, fill
            this class with random images your classifier may see but
            shouldn   t care about. from there, train your network.
            [570]reply
   89. andie october 22, 2018 at 2:34 am [571]#
       hi, adrian.
       thank you! i love this tutorial and the model covered here is easy
       to apply.
       i would like to add some classes and train the pretrained model but
       i don   t know how.
       could you show me how to update the model and lb?
       [572]reply
          + adrian rosebrock october 22, 2018 at 7:49 am [573]#
            hey andie, you can simply replace my    dataset    directory with
            your own dataset where each class label has its own
            subdirectory. if you follow my exact directory structure
            you   ll be able to train the model on your own dataset. if
            you   re looking to apply fine-tuning (i.e., training a
            pre-trained model) you should see my example inside [574]deep
            learning for id161 with python.
            [575]reply
   90. [576]rui october 22, 2018 at 12:33 pm [577]#
       hi adrian!
       i am trying to perform image classification using id98s and my code
       is based on yours. however, my validation accuracy is much lower
       than the training accuracy.
       after 50 epochs, i get 60% accuracy for training but only 20% for
       validation.
       my dataset is limited and i am trying to classify 1000 different
       classes of medical pills. i have only 10 images per class. i
       performed real-time augmentation which allowed me to enlarge my
       dataset. how can i get better results? besides, my training loss is
       dropping well, reaching 1.5 while my validation loss stops at 5/6.
       how would you face this issue?
       thank you!
       [578]reply
          + adrian rosebrock october 22, 2018 at 12:58 pm [579]#
            as someone who   s built software to recognize nearly 10,000+
            unique prescription pills, i can tell you that the problem is
            extremely challenging. with only 10 images per class it   s
            very, very unlikely that you   ll be able to recognize 1,000
            different prescription pills unless you are doing some sort of
            triplet loss/training procedure. i would suggest investing
            your time in obtaining more training data. i would also
            suggest working through [580]deep learning for id161
            with python where i share my suggestions, tips, and best
            practices when training your own id98s on challenging datasets.
            [581]reply
   91. vishal borana november 16, 2018 at 1:35 pm [582]#
       hello, adrian. this was a great post as usual. you are the best. in
       the post, you mentioned that you would deploy the program to a
       smartphone app. i couldn   t find that post. could you please share
       the link?
       [583]reply
          + adrian rosebrock november 19, 2018 at 12:49 pm [584]#
            yes, see [585]this tutorial.
            [586]reply
   92.           november 17, 2018 at 4:12 am [587]#
       hi,adrian ! i get problem when used the train.py,that is it saied
       allocation of exceed 10% of system memory.what should i do? thank
       you so much for you to answer this question for me .
       [588]reply
          + adrian rosebrock november 19, 2018 at 12:45 pm [589]#
            it sounds like your machine is running out of ram. how big is
            your image dataset? how many images are you working with? and
            how much ram does your machine have? if you are working with
            datasets too large to fit into memory make sure you refer to
            [590]deep learning for id161 with python where i
            discuss how to train id98s on large datasets.
            [591]reply
   93. tomas december 13, 2018 at 2:47 pm [592]#
       hi adrian, great post! when i use your data set training works
       fine. i   d like to try to prepare model to distinguish 2 classes. i
       put my images into two separated directories inside dataset
       directory. my images are rgb images.
       however i have some issues with my data, i do not know why the
       dimension of trainy and testy are: (1106, 1) and (277, 1), instead
       of (1106, 2) and (277, 2) because of two classes. do you have any
       idea what might be wrong?
       [593]reply
          + adrian rosebrock december 18, 2018 at 9:31 am [594]#
            the labelbinarizer class will return just integers for 2
            classes rather than one-hot encoding. use keras   
            np_utils.to_categorical instead.
            [595]reply
   94. huangz december 27, 2018 at 10:06 am [596]#
       hi adrian, you mentioned that the smallervggnet was designed for
       96  96 image pixel right?
       suppose i want to modify the image dimenstion into 300 px, would
       you mind giving me tips in which part of the smallervggnet.py i
       should change?
       cause i tried to train a bunch of food images using your code, and
       it keeps resulting a low accuracy, so i think, perhaps i can   t
       train the food images with 96px.
       [597]reply
          + adrian rosebrock december 27, 2018 at 11:15 am [598]#
            it   s unfortunately not that simple. smallervggnet was designed
            with a balance between (1) image dimensions and (2) dataset
            complexity. you   ll want to consider if your dataset requires a
            network with a larger depth to accommodate the increase in
            input pixel dimensions. i would suggest referring to [599]deep
            learning for id161 with python where i include my
            tips, suggestions, and best practices when creating and
            training your own custom deep neural network architectures. be
            sure to give it a look, i   m confident the book will help you.
            [600]reply
   95. pepe january 6, 2019 at 5:38 am [601]#
       can i get the dataset in the above system you implemented??
       [602]reply
          + adrian rosebrock january 8, 2019 at 7:03 am [603]#
            yes, just use the    downloads    section of the tutorial to
            download the source code + dataset.
            [604]reply
   96. isaac january 11, 2019 at 11:30 am [605]#
       hey adrian!
       how did you run ubuntu for this tutorial?
       i   m running ubuntu 16.04 on windows 10 and if i   m thinking
       correctly, ubuntu can   t access the directory i   ve set up on windows
       with all the pictures. is this correct and if so, could you
       recommend a work-around?
       also, do all the images in the dataset need to be the same
       resolution or can they vary? if they need to be the same
       resolution, how would you ensure that using bing image search api?
       thanks!
       [606]reply
          + adrian rosebrock january 16, 2019 at 10:22 am [607]#
            i haven   t tried the windows/ubuntu integration (i haven   t used
            windows in 11+ years now) but my suggestion would be to
            transfer your directory of code/images to ubuntu via sftp,
            ftp, dropbox, or whatever is most convenient for you. from
            there you can execute the code from the ubuntu terminal.
            as for your second question they don   t have to be the same
            resolution.
            [608]reply
   97. vishnu january 16, 2019 at 12:36 am [609]#
       i tried modifying the code to take the video stream as input but i
       am getting 0.05 fps why is this classification so slow?
       [610]reply
          + adrian rosebrock january 16, 2019 at 9:35 am [611]#
            that is very, very slow. it sounds like there is a logic error
            somewhere in your code. try using [612]this tutorial as a
            template for classifying individual frames of a video stream
            with a keras id98.
            [613]reply
   98. mustapha nakbi january 18, 2019 at 4:13 pm [614]#
       hi mr adrian thank you for all your effort to explain and
       facilitate deep learning
       i ask it   s possible to recognize person from the dog and cat
       program like a first experience for a beginner and to classify just
       two person, thank you in advance.
       [615]reply
   99. rushad january 19, 2019 at 1:27 pm [616]#
       hi! your articles are super fun and useful, so thanks!
       i was trying training my own data set, but this time only with two
       categories, and i got the follow error :
       alueerror: error when checking target: expected activation_7 to
       have shape (2,) but got array with shape (1,)
       [617]reply
          + adrian rosebrock january 22, 2019 at 9:36 am [618]#
            99.9% percent of the time (at least with my code) the error is
            due to your directory structure being incorrect. you can
            verify by reviewing the parsed class labels     you   re likely
            parsing out the incorrect label from the file path.
            double-check and triple-check your label parsing.
            [619]reply
               o dave february 10, 2019 at 12:08 pm [620]#
                 hi,
                 i faced the same error.
                 i didn   t do anything on your code or folder structure but
                 deleted 3 folders (./data/mewtwo, ./data/pikachu and
                 ./data/squirtle).
                 i wonder whether this code works for 2 classes.
                 please help.
                 thank you.
                 [621]reply
                    # adrian rosebrock february 14, 2019 at 1:44 pm [622]#
                      for only two classes scikit-learn   s labelbinarizer
                      will only produce integer encodings, not one-hot
                      vector encodings.
                      to resolve the issue use the labelencoder function
                      and then keras    np_utils.to_categorical function.
                      [623]reply
   100. tomasz february 6, 2019 at 12:42 pm [624]#
       hi adrian,
       training a deep neural network on a huge dataset is really time
       consuming. is there any way to resume training starting on a
       particular epoch and iteration using keras?
       [625]reply
          + adrian rosebrock february 7, 2019 at 7:02 am [626]#
            absolutely. you can use keras checkpointing to save a model to
            disk every n epochs. from there you can re-load the model via
            the load_model function and resume training. i cover exactly
            how to do that inside my book, [627]deep learning for computer
            vision with python.
            [628]reply
               o tomasz february 9, 2019 at 2:57 pm [629]#
                 hi adrian,
                 thanks, you described it perfectly in your book in
                 chapter 18.
                 i highly recommend    deep learning for id161
                 with python.    to everyone.
                 [630]reply
                    # adrian rosebrock february 14, 2019 at 1:50 pm [631]#
                      thanks so much, tomasz!
                      [632]reply
   101. antoine february 7, 2019 at 11:55 am [633]#
       hi ! thank you for this great tutorial !
       i   ve managed to run your code on my computer but it seems that the
       model won   t converge.
       i can   t reach the 97% of accuracy. i   m merely about 90%.
       do you kow where this come from ?
       thanks
       [634]reply
   102. son vo february 12, 2019 at 12:01 am [635]#
       hi adrian,
       i have read your tutorials about object classification using
       smallvggnet. however, this architecture only supports low image
       resolution (96,96). i can   t use this architecture in my case in
       which i want to classify individual animals using only 3 or 4 high
       resolution images/individual for training. the resolution of images
       captured by pi cam v2 is 1944        2592 that i   m going to reduce to
       around 450  600 to ensure it still retains important information of
       patterns on the animal skin. i just wanted to know any suggestion
       from you on which architecture i can use for my case? do you have
       any tutorial to support high resolution images? thank you adrian.
       [636]reply
          + adrian rosebrock february 14, 2019 at 1:25 pm [637]#
            you need more images. 3-4 images per individual animal is not
            enough. additionally, you should look at triplet loss and
            siamese networks     they may work better in this case.
            [638]reply
   103. flavio february 21, 2019 at 3:24 pm [639]#
       hi adrian,
       i   m a beginner on dl and i started with the basic fashion-mnist to
       practice, i read in another blog about a similar id98 model that
       instead of using relu activation they use leakyrelu, saying that it
       is better since some neurons tend to    die    with relu, also i tested
       their implementation of the fashion-mnist against yours to compare,
       and the time using their code was less than half then yours,
       although your accuracy was better, why such a difference?
       [640]https://www.datacamp.com/community/tutorials/convolutional-neu
       ral-networks-python
       [641]reply
          + adrian rosebrock february 22, 2019 at 6:25 am [642]#
            there are a variety of various id180 including
            standard relu, leaky relu, elu, and other extensions. they are
            hyperparameters of your network that can be adjusted. i
            typically suggest using relu when building your initial model.
            once you are able to train it and obtain reasonable accuracy
            swap in a leaky relu or elu and you might be able to get some
            additional accuracy out of it. i cover these activation
            functions and best practices on how to use them inside
            [643]deep learning for id161 with python.
            [644]reply
   104. akk march 5, 2019 at 5:59 am [645]#
       i just want to know how to create a custom model in id98 with
       datasets which include photographed images.pls let me know
       [646]reply
          + adrian rosebrock march 5, 2019 at 8:26 am [647]#
            you can use this tutorial to train your own id98 with a custom
            dataset. have you given it a try?
            if you are looking for a more detailed guide on how to train
            your own custom id98s be sure to read through [648]deep
            learning for id161 with python.
            [649]reply
   105. mohammad march 8, 2019 at 2:24 pm [650]#
       hi adrian,
       thanks your best tutorial, i have some question,
       q1- if we have the tensorflow model, how i can convert that model
       to keras for using in the ios?
       q2     if we have one more model, is it possible to run on ios
       together? that    mean, i want capture a image and feed into the
       model-1 and pass the result of the model-1 into the model-2?
       if it   s possible, publish a new post about deploy the model on
       android.
       thanks,
       [651]reply
          + adrian rosebrock march 13, 2019 at 4:01 pm [652]#
            i have a tutorial on [653]keras and ios that you should read
            first. if your model is already in tensorflow format then you
            can likely just use tflite on the mobile device.
            [654]reply
   106. hassan march 11, 2019 at 4:32 am [655]#
       expected activation_7 to have shape (2,) but got array with shape
       (1,)
       when i change the folders in side the dataset to two folders
       (labels) it give this error
       [656]reply
          + adrian rosebrock march 13, 2019 at 3:39 pm [657]#
            you need to call np_utils.to_categorical on the labels after
            you transform them. unfortunately the labelbinarizer function
            will return integers if there are only 2 classes     i have no
            idea why they decided to implement it that way.
            [658]reply
   107. amit march 14, 2019 at 10:12 pm [659]#
       hi adrian
       what additional code would you add to generate plots of roc curve
       and pr curve. i would like to generate them in my model and present
       some arguments. pls help
       [660]reply
          + adrian rosebrock march 19, 2019 at 10:23 am [661]#
            take a look at the [662]scikit-learn documentation which will
            show you how to create and plot a roc curve.
            [663]reply
   108. pg march 31, 2019 at 7:31 am [664]#
       i have created a id98 model with 3 classes ( vehicles,birds,people
       ).
       now i have to do single prediction .
       how should i do that ? or which blog should i prefer ?
       [665]reply
          + adrian rosebrock april 2, 2019 at 6:02 am [666]#
            if you are new to deep learning, training your own models, and
            making predictions, you should definitely read through
            [667]deep learning for id161 with python where i
            teach you the fundamentals of deep learning and how to use
            keras. definitely give it a read as it will not only solve
            your problem but make you a better deep learning practitioner
            as well.
            [668]reply

leave a reply [669]click here to cancel reply.

   comment
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________

   ______________________________name (required)

   ______________________________email (will not be published) (required)

   ______________________________website

   submit comment

   search...___________ (search)

resource guide (it   s totally free).

   [670]get your free 17-page id161 and deep learning resource
   guide pdf

   get your free 17 page id161, opencv, and deep learning
   resource guide pdf. inside you'll find my hand-picked tutorials, books,
   courses, and libraries to help you master cv and dl.

                           [671]download for free!

deep learning for id161 with python book     out now!

   [672]deep learning with id161 and python kickstarter

   you're interested in deep learning and id161, but you don't
   know how to get started. let me help. [673]my new book will teach you
   all you need to know about deep learning.

   click here to master deep learning

you can detect faces in images & video.

   [674]learn how to detect faces in images and video

   are you interested in detecting faces in images & video? but tired of
   googling for tutorials that never work? then let me help! i guarantee
   that my new book will turn you into a face detection ninja by the end
   of this weekend. [675]click here to give it a shot yourself.

   click here to master face detection

pyimagesearch gurus: now enrolling!

   the pyimagesearch gurus course is now enrolling! inside the course
   you'll learn how to perform:
     * automatic license plate recognition (anpr)
     * deep learning
     * face recognition
     * and much more!

   click the button below to learn more about the course, take a tour, and
   get 10 (free) sample lessons.

   take a tour & get 10 (free) lessons

hello! i   m adrian rosebrock.

   i'm an entrepreneur and ph.d who has launched two successful image
   search engines, [676]id my pill and [677]chic engine. i'm here to share
   my tips, tricks, and hacks i've learned along the way.

learn id161 in a single weekend.

   [678]become an opencv guru

   want to learn id161 & opencv? i can teach you in a single
   weekend. i know. it sounds crazy, but it   s no joke. my new book is your
   guaranteed, quick-start guide to becoming an opencv ninja. so why not
   give it a try? [679]click here to become a id161 ninja.

   click here to become an opencv ninja

subscribe via rss

   [680]pyimagesearch rss feed

   never miss a post! subscribe to the pyimagesearch rss feed and keep up
   to date with my image search engine tutorials, tips, and tricks
     * [681]popular

     * [682]raspbian stretch: install opencv 3 + python on your raspberry
       pi september 4, 2017
     * [683]install guide: raspberry pi 3 + raspbian jessie + opencv 3
       april 18, 2016
     * [684]home surveillance and motion detection with the raspberry pi,
       python, opencv, and dropbox june 1, 2015
     * [685]install opencv and python on your raspberry pi 2 and b+
       february 23, 2015
     * [686]ubuntu 16.04: how to install opencv october 24, 2016
     * [687]real-time id164 with deep learning and opencv
       september 18, 2017
     * [688]basic motion detection and tracking with python and opencv may
       25, 2015

   find me on [689]twitter, [690]facebook, and [691]linkedin.

      2019 pyimagesearch. all rights reserved.

   [tr?id=1465896023527386&ev=pageview&noscript=1]

   [email]
   [email]

references

   visible links
   1. http://feeds.feedburner.com/pyimagesearch
   2. https://www.pyimagesearch.com/comments/feed/
   3. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/feed/
   4. https://www.pyimagesearch.com/wp-json/oembed/1.0/embed?url=https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/
   5. https://www.pyimagesearch.com/wp-json/oembed/1.0/embed?url=https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/&format=xml
   6. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#navigation
   7. https://www.pyimagesearch.com/
   8. https://www.pyimagesearch.com/
   9. https://www.pyimagesearch.com/
  10. https://www.pyimagesearch.com/start-here-learn-computer-vision-opencv/
  11. https://www.pyimagesearch.com/practical-python-opencv/
  12. https://www.pyimagesearch.com/pyimagesearch-gurus/
  13. https://www.pyimagesearch.com/opencv-tutorials-resources-guides/
  14. https://www.pyimagesearch.com/free-opencv-computer-vision-deep-learning-crash-course/
  15. https://www.pyimagesearch.com/about/
  16. https://www.pyimagesearch.com/contact/
  17. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#top
  18. https://www.pyimagesearch.com/author/adrian/
  19. https://www.pyimagesearch.com/category/deep-learning-2/
  20. https://www.pyimagesearch.com/category/keras/
  21. https://www.pyimagesearch.com/category/tutorials/
  22. http://yysboutique.ca/product/ys-pokemon-stuffed-toy-bulbasaur/
  23. https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/
  24. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/
  25. https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/
  26. https://bulbapedia.bulbagarden.net/wiki/bulbasaur_(pok  mon)
  27. https://bulbapedia.bulbagarden.net/wiki/charmander_(pok  mon)
  28. https://bulbapedia.bulbagarden.net/wiki/squirtle_(pok  mon)
  29. https://bulbapedia.bulbagarden.net/wiki/pikachu_(pok  mon)
  30. https://bulbapedia.bulbagarden.net/wiki/mewtwo_(pok  mon)
  31. https://www.pyimagesearch.com/wp-content/uploads/2018/04/smallervggnet_model.png
  32. https://arxiv.org/abs/1409.1556
  33. https://www.pyimagesearch.com/2017/09/25/configuring-ubuntu-for-deep-learning-with-python/
  34. https://www.pyimagesearch.com/2017/09/27/setting-up-ubuntu-16-04-cuda-gpu-for-deep-learning-with-python/
  35. https://www.pyimagesearch.com/2017/09/29/macos-for-deep-learning-with-python-tensorflow-and-keras/
  36. https://www.pyimagesearch.com/2017/09/20/pre-configured-amazon-aws-deep-learning-ami-with-python/
  37. https://www.pyimagesearch.com/2018/03/21/my-review-of-microsofts-deep-learning-virtual-machine/
  38. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
  39. https://www.pyimagesearch.com/wp-content/uploads/2018/04/smallervggnet_model.png
  40. https://github.com/jrosebr1/imutils
  41. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
  42. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
  43. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
  44. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
  45. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
  46. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
  47. https://bulbapedia.bulbagarden.net/wiki/bulbasaur_(pok  mon)
  48. http://yysboutique.ca/product/ys-pokemon-stuffed-toy-bulbasaur/
  49. https://bulbapedia.bulbagarden.net/wiki/mewtwo_(pok  mon)
  50. https://shukuenshinobi.com/2016/09/22/pokemon-mewtwo-and-greninja-hero-figure-review/
  51. https://bulbapedia.bulbagarden.net/wiki/pikachu_(pok  mon)
  52. https://www.lelong.com.my/pokemon-pikachu-soft-toys-35cm-yenzenvision-i5356985-2007-01-sale-i.htm
  53. https://bulbapedia.bulbagarden.net/wiki/squirtle_(pok  mon)
  54. https://mikitzune.com/collaboration-pokemon-forever-at-kiddyland/
  55. https://bulbapedia.bulbagarden.net/wiki/charmander_(pok  mon)
  56. https://en.wikipedia.org/wiki/list_of_pok  mon
  57. https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/
  58. https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/
  59. https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html
  60. https://www.pyimagesearch.com/2018/01/29/scalable-keras-deep-learning-rest-api/
  61. https://www.pyimagesearch.com/2018/02/05/deep-learning-production-keras-redis-flask-apache/
  62. https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/
  63. https://www.pyimagesearch.com/tag/convolutional-neural-network/
  64. https://www.pyimagesearch.com/tag/deep-learning/
  65. https://www.pyimagesearch.com/tag/machine-learning/
  66. https://www.pyimagesearch.com/tag/neural-nets/
  67. https://www.pyimagesearch.com/tag/pokedex/
  68. https://www.pyimagesearch.com/tag/pokemon/
  69. https://www.pyimagesearch.com/tag/python/
  70. https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/
  71. https://www.pyimagesearch.com/2018/04/23/running-keras-models-on-ios-with-coreml/
  72. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456920
  73. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456920
  74. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456949
  75. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456949
  76. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456924
  77. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456924
  78. http://none/
  79. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456937
  80. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456937
  81. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456947
  82. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
  83. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456947
  84. http://none/
  85. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456985
  86. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-456985
  87. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457041
  88. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457041
  89. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457147
  90. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457147
  91. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457463
  92. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457463
  93. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457638
  94. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
  95. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
  96. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457638
  97. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477850
  98. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477850
  99. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478080
 100. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
 101. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478080
 102. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457080
 103. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457080
 104. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457142
 105. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457142
 106. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457106
 107. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457106
 108. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457139
 109. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/
 110. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 111. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457139
 112. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457108
 113. https://www.pyimagesearch.com/2017/10/16/raspberry-pi-deep-learning-object-detection-with-opencv/
 114. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457108
 115. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457137
 116. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457137
 117. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457293
 118. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457293
 119. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457369
 120. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457369
 121. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457224
 122. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457224
 123. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457380
 124. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457380
 125. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457273
 126. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457273
 127. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457376
 128. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457376
 129. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457286
 130. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457286
 131. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457375
 132. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 133. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457375
 134. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457348
 135. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457348
 136. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457363
 137. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457363
 138. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457437
 139. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457437
 140. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457488
 141. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457488
 142. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457634
 143. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 144. https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/
 145. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457634
 146. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457351
 147. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457351
 148. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457362
 149. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457362
 150. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457476
 151. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457476
 152. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457635
 153. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457635
 154. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457644
 155. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457644
 156. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457645
 157. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457645
 158. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457657
 159. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457657
 160. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457668
 161. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457668
 162. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458287
 163. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458287
 164. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457648
 165. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457648
 166. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457656
 167. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457656
 168. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457704
 169. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457704
 170. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457746
 171. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457746
 172. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458238
 173. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 174. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458238
 175. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457844
 176. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457844
 177. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458237
 178. https://www.pyimagesearch.com/2018/04/23/running-keras-models-on-ios-with-coreml/
 179. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458237
 180. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457966
 181. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-457966
 182. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458236
 183. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 184. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458236
 185. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497719
 186. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497719
 187. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497841
 188. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497841
 189. https://blog.sinhallc.com/
 190. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458017
 191. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458017
 192. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458235
 193. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458235
 194. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458374
 195. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458374
 196. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458478
 197. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 198. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458478
 199. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458403
 200. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458403
 201. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458477
 202. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458477
 203. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458428
 204. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458428
 205. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458479
 206. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458479
 207. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458457
 208. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458457
 209. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458476
 210. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458476
 211. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458656
 212. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458656
 213. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458671
 214. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458671
 215. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458797
 216. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458797
 217. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458658
 218. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458658
 219. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458689
 220. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458689
 221. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458865
 222. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458865
 223. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458712
 224. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458712
 225. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458863
 226. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458863
 227. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458794
 228. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458794
 229. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458798
 230. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458798
 231. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458864
 232. https://github.com/ardamavi/intel-movidius-ncs-keras
 233. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458864
 234. http://peshmerge.io/
 235. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458820
 236. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458820
 237. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458862
 238. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 239. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458862
 240. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459203
 241. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459203
 242. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458956
 243. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458956
 244. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458959
 245. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 246. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-458959
 247. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459381
 248. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459381
 249. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459466
 250. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459466
 251. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459499
 252. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
 253. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459499
 254. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459520
 255. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459520
 256. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459765
 257. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459765
 258. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459567
 259. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459567
 260. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459762
 261. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459762
 262. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459829
 263. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459829
 264. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460313
 265. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460313
 266. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459571
 267. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459571
 268. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459756
 269. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459756
 270. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459923
 271. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459923
 272. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460317
 273. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460317
 274. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459572
 275. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459572
 276. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459755
 277. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459755
 278. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459924
 279. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459924
 280. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460310
 281. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460310
 282. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477995
 283. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477995
 284. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478069
 285. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478069
 286. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459723
 287. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459723
 288. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459742
 289. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459742
 290. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459859
 291. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459859
 292. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460315
 293. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460315
 294. http://no/
 295. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460006
 296. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460006
 297. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460303
 298. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460303
 299. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460012
 300. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460012
 301. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460311
 302. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460311
 303. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460152
 304. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460152
 305. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460312
 306. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460312
 307. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460345
 308. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460345
 309. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460662
 310. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 311. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460662
 312. http://arunponnusamy.com/
 313. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460787
 314. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460787
 315. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461009
 316. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461009
 317. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460184
 318. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460184
 319. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462175
 320. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462175
 321. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460299
 322. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460299
 323. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460307
 324. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460307
 325. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460316
 326. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460316
 327. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460318
 328. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 329. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460318
 330. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460326
 331. https://github.com/dannyjose
 332. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460454
 333. https://www.vision.ee.ethz.ch/datasets_extra/food-101/
 334. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460454
 335. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460656
 336. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 337. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460656
 338. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460499
 339. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460499
 340. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460649
 341. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460649
 342. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460882
 343. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-460882
 344. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461008
 345. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461008
 346. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461023
 347. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461023
 348. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461026
 349. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 350. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461026
 351. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461464
 352. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461464
 353. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461536
 354. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 355. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461536
 356. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461475
 357. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461475
 358. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461534
 359. https://www.pyimagesearch.com/2018/04/23/running-keras-models-on-ios-with-coreml/
 360. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461534
 361. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461745
 362. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461745
 363. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461752
 364. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-461752
 365. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462280
 366. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462280
 367. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462284
 368. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462284
 369. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462953
 370. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-462953
 371. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463333
 372. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463333
 373. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463181
 374. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463181
 375. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463322
 376. https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html
 377. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463322
 378. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463213
 379. https://drive.google.com/open?id=1ezd-eecsajyioazqklent3ei7u7vzhqq
 380. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463213
 381. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463320
 382. https://www.pyimagesearch.com/2016/09/26/a-simple-neural-network-with-python-and-keras/
 383. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463320
 384. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463308
 385. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463308
 386. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463313
 387. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-463313
 388. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-488501
 389. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-488501
 390. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-489023
 391. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-489023
 392. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465573
 393. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465573
 394. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465726
 395. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465726
 396. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465805
 397. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465805
 398. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467079
 399. https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/
 400. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467079
 401. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465943
 402. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-465943
 403. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467073
 404. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467073
 405. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467134
 406. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467134
 407. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467395
 408. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467395
 409. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467168
 410. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467168
 411. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467392
 412. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 413. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467392
 414. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467329
 415. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467329
 416. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467380
 417. https://keras.io/callbacks/#example-model-checkpoints
 418. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467380
 419. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467355
 420. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467355
 421. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467378
 422. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467378
 423. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467755
 424. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467755
 425. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467986
 426. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 427. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467986
 428. https://www.linkedin.com/in/victorliendo/
 429. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467481
 430. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-467481
 431. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468009
 432. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468009
 433. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468356
 434. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468356
 435. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468540
 436. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468540
 437. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468504
 438. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468504
 439. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468509
 440. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468509
 441. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468666
 442. https://github.com/thtrieu/darkflow/blob/master/id18/yolo.id18
 443. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468666
 444. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468801
 445. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-468801
 446. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-470110
 447. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-470110
 448. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-470628
 449. https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/
 450. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-470628
 451. http://farosikemas.tumblr.com/
 452. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471228
 453. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471228
 454. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471229
 455. https://www.pyimagesearch.com/2018/04/23/running-keras-models-on-ios-with-coreml/
 456. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471229
 457. http://www.anecdotes.in/
 458. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471599
 459. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471599
 460. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471638
 461. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471638
 462. http://www.anecdotes.in/
 463. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471693
 464. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471693
 465. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471999
 466. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 467. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471999
 468. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471850
 469. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471850
 470. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471978
 471. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-471978
 472. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-473769
 473. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-473769
 474. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-473868
 475. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-473868
 476. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474189
 477. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474189
 478. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474384
 479. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474384
 480. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474202
 481. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474202
 482. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474381
 483. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 484. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-474381
 485. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475007
 486. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475007
 487. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475157
 488. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-459520
 489. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475157
 490. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475582
 491. https://arxiv.org/pdf/1803.10039.pdf
 492. https://arxiv.org/pdf/1805.01328.pdf
 493. https://github.com/mrharicot/monodepth
 494. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475582
 495. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475981
 496. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475981
 497. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475880
 498. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475880
 499. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475945
 500. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-475945
 501. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476064
 502. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476064
 503. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476444
 504. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476444
 505. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476084
 506. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476084
 507. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476752
 508. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476752
 509. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476092
 510. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476092
 511. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476750
 512. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476750
 513. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476102
 514. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476102
 515. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476747
 516. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476747
 517. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476900
 518. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-476900
 519. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477505
 520. https://www.pyimagesearch.com/pyimagesearch-gurus/
 521. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477505
 522. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477918
 523. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-477918
 524. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478073
 525. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 526. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478073
 527. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478275
 528. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478275
 529. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478689
 530. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478689
 531. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478981
 532. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-478981
 533. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481373
 534. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481373
 535. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-485435
 536. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-485435
 537. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-485772
 538. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-485772
 539. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500645
 540. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500645
 541. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-479096
 542. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-479096
 543. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481363
 544. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 545. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481363
 546. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-479965
 547. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-479965
 548. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481295
 549. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481295
 550. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481972
 551. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-481972
 552. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482165
 553. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482165
 554. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482186
 555. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482186
 556. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482209
 557. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482209
 558. http://delusionalinsanity.com/portfolio/
 559. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482374
 560. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482374
 561. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482819
 562. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482819
 563. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482490
 564. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482490
 565. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482815
 566. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482815
 567. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482755
 568. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482755
 569. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482789
 570. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-482789
 571. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483510
 572. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483510
 573. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483542
 574. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 575. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483542
 576. http://google.pt/
 577. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483589
 578. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483589
 579. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483596
 580. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 581. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-483596
 582. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487475
 583. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487475
 584. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487858
 585. https://www.pyimagesearch.com/2018/04/23/running-keras-models-on-ios-with-coreml/
 586. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487858
 587. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487544
 588. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487544
 589. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487853
 590. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 591. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-487853
 592. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-492112
 593. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-492112
 594. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-492853
 595. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-492853
 596. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-493801
 597. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-493801
 598. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-493890
 599. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 600. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-493890
 601. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-494918
 602. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-494918
 603. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-495137
 604. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-495137
 605. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-495958
 606. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-495958
 607. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496693
 608. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496693
 609. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496557
 610. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496557
 611. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496638
 612. https://www.pyimagesearch.com/2017/12/18/keras-deep-learning-raspberry-pi/
 613. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496638
 614. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496981
 615. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-496981
 616. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497073
 617. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497073
 618. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497449
 619. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-497449
 620. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500691
 621. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500691
 622. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-501350
 623. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-501350
 624. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500001
 625. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500001
 626. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500267
 627. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 628. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500267
 629. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500602
 630. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500602
 631. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-501355
 632. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-501355
 633. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500317
 634. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500317
 635. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500901
 636. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-500901
 637. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-501330
 638. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-501330
 639. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-502732
 640. https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python
 641. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-502732
 642. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-502821
 643. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 644. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-502821
 645. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-504927
 646. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-504927
 647. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-504957
 648. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 649. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-504957
 650. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-505660
 651. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-505660
 652. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506578
 653. https://www.pyimagesearch.com/2018/04/23/running-keras-models-on-ios-with-coreml/
 654. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506578
 655. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506038
 656. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506038
 657. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506553
 658. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506553
 659. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506788
 660. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-506788
 661. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-507860
 662. https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html
 663. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-507860
 664. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-510228
 665. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-510228
 666. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-510594
 667. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 668. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#comment-510594
 669. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#respond
 670. https://app.monstercampaigns.com/c/mdoijtrmex7bpm0rp2hn/
 671. https://app.monstercampaigns.com/c/mdoijtrmex7bpm0rp2hn/
 672. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 673. https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/
 674. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-face-detection
 675. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-face-detection
 676. http://www.idmypill.com/
 677. http://www.chicengine.com/
 678. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-single-weekend
 679. https://www.pyimagesearch.com/practical-python-opencv/?src=sidebar-single-weekend
 680. http://feeds.feedburner.com/pyimagesearch
 681. https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-id98s/#tab-pop
 682. https://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/
 683. https://www.pyimagesearch.com/2016/04/18/install-guide-raspberry-pi-3-raspbian-jessie-opencv-3/
 684. https://www.pyimagesearch.com/2015/06/01/home-surveillance-and-motion-detection-with-the-raspberry-pi-python-and-opencv/
 685. https://www.pyimagesearch.com/2015/02/23/install-opencv-and-python-on-your-raspberry-pi-2-and-b/
 686. https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/
 687. https://www.pyimagesearch.com/2017/09/18/real-time-object-detection-with-deep-learning-and-opencv/
 688. https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/
 689. https://twitter.com/pyimagesearch
 690. https://www.facebook.com/pyimagesearch
 691. http://www.linkedin.com/pub/adrian-rosebrock/2a/873/59b

   hidden links:
 693. https://www.pyimagesearch.com/wp-content/uploads/2018/04/id98_keras_header.jpg
 694. https://www.pyimagesearch.com/wp-content/uploads/2018/04/id98_keras_dataset.jpg
 695. https://www.pyimagesearch.com/wp-content/uploads/2018/04/id98_keras_smallervggnet.png
 696. https://www.pyimagesearch.com/wp-content/uploads/2018/04/id98_keras_plot.png
 697. https://www.pyimagesearch.com/wp-content/uploads/2018/04/charmander_result_01.jpg
 698. https://www.pyimagesearch.com/wp-content/uploads/2018/04/bulbasaur_result_01.jpg
 699. https://www.pyimagesearch.com/wp-content/uploads/2018/04/mewtwo_result_01.jpg
 700. https://www.pyimagesearch.com/wp-content/uploads/2018/04/pikachu_result_01.jpg
 701. https://www.pyimagesearch.com/wp-content/uploads/2018/04/squirtle_result_01.jpg
 702. https://www.pyimagesearch.com/wp-content/uploads/2018/04/charmander_result_02.jpg
