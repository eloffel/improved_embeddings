   [1]

linkedin

     * [2]sign in
     * [3]join now

   complete guide to build convnet http-based application using tensorflow
   and flask restful python api

  complete guide to build convnet http-based application using tensorflow and
                            flask restful python api

   published on may 1, 2018may 1, 2018     28 likes     3 comments

   [4]ahmed gad

[5]ahmed gad[6]follow

job seeker. fritz/kdnuggets/tds contributor, t.a. & deep learning | machine
learning | id161 researcher

     * (button) like28
     * (button) comment3
     * [ ] share
          + (button) linkedin
          + (button) facebook
          + (button) twitter
       10

   this tutorial takes you along the steps required to create a
   convolutional neural network (id98/convnet) using tensorflow and get it
   into production by allowing remote access via a http-based application
   using flask restful api.

   this tutorial is ranked second among most shared posts in kdnuggets.com
   in the period from 15 to 20 may 2018. it received the silver badge.

   iframe: [7]about:blank

   iframe: [8]about:blank

   in this tutorial, a id98 is to be built using tensorflow nn (tf.nn)
   module. the id98 model architecture is created and trained and tested
   against the cifar10 dataset. to make the model remotely accessible, a
   flask web application is created using python to receive an uploaded
   image and return its classification label using http. anaconda3 is used
   in addition to tensorflow on windows with cpu support. this tutorial
   assumes you have a basic understanding of id98 such as layers, strides,
   and padding. also knowledge about python is required.

   the tutorial is summarized into the following steps:

   1.      preparing the environment by installing python, tensorflow,
   pycharm, and flask api.

   2.      downloading and preparing the cifar-10 dataset.

   3.      building the id98 computational graph using tensorflow.

   4.      training the id98.

   5.      saving the trained id98 model.

   6.      preparing the test data and restoring the trained id98 model.

   7.      testing the trained id98 model.

   8.      building the flask web application.

   9.      upload an image using html form.

   10.  creating helper html, javascript, and css files.

   11.  http-based remote accessing the trained model for prediction.

   1. installing python, tensorflow, pycharm, and flask api

   before starting building the project, it is required to prepare its
   environment. python is the first tool to start installing because the
   environment is fully dependent on it. if you already have the
   environment prepared, you can skip the first step.

   1.1 anaconda/python installation

   it is possible to install the native python distribution but it is
   recommended to use an all-in-one package such as anaconda because it
   does some stuff for you. in this project, anaconda 3 is used. for
   windows, the executable file can be downloaded from
   [9]https://www.anaconda.com/download/#windows. it could be installed
   easily.

   to ensure anaconda3 is installed properly, the cmd command (where
   python) could be issued as in figure 1. if anaconda3 is installed
   properly, its installation path will appear in the command output.

   figure 1

   [:0]

   1.2 tensorflow installation

   after installation python using anaconda3, next is to install
   tensorflow (tf). this tutorial uses tf on windows with cpu support. the
   installation instructions are found in this page
   [10]https://www.tensorflow.org/install/install_windows. this youtube
   video might be helpful ([11]https://youtu.be/msono20mrvu).

   tf installation steps are as follows:

   1) creating a conda environment for tf by invoking this command:
c:> conda create -n tensorflow pip python=3.5

   this creates an empty folder holding the virtual environment (venv) for
   tf installation. the venv is located under anaconda3 installation
   directory in this location (\anaconda3\envs\tensorflow).

   2) activating the venv for tensorflow installation using this command:
c:> activate tensorflow

   the above command tells that we are inside the venv and any library
   installation will be inside it. the command prompt is expected to be
   changed after this command to be (tensorflow)c:>. after getting into
   the directory, we are ready to install the library.

   3) after activating the venv, the cpu-only version of windows
   tensorflow could be installed by issuing this command:
(tensorflow)c:> pip install --ignore-installed --upgrade tensorflow

   to test whether tf is installed properly, we can try to import it as in
   figure 2. but remember before importing tf, its venv must be activated.
   testing it from the cmd, we need to issue the python command in order
   to be able to interact with python. because no error occurred in the
   import line, tf is successfully installed.

   figure 2

   [:0]

   1.3 pycharm python ide installation

   for this project, it is recommended to use a python ide rather than
   entering commands in cmd. the ide used in this tutorial is pycharm. its
   windows executable file could be downloaded from this page
   [12]https://www.jetbrains.com/pycharm/download/#section=windows. its
   installation instructions are pretty simple.

   after downloading and installation pycharm python ide, next is to link
   it with tf. this is done by setting its python interpreter to the
   installed python under the tf venv as in figure 3. this is done by
   opening the settings of the ide and choosing the project interpreter to
   the python.exe file installed inside the tf venv.

   figure 3

   [:0]

   1.4 flask installation

   the last tool to get installed is the flask restful api. it is a
   library to be installed using pip/conda installer under the tf venv
   using the following cmd command:
c:> pip install flask-api

   if not already installed, numpy and scipy should be installed inside
   the venv in order to be able to read and manipulate images.

   by installing anaconda (python), tensorflow, pycharm, and flask, we are
   ready to start building the project.

   2. downloading and preparing the cifar-10 dataset

   the python version of the 10 classes cifar dataset (cifar-10) could be
   downloaded from this page
   [13]https://www.cs.toronto.edu/~kriz/cifar.html. the dataset contains
   60,000 images divided into training and testing data. there are five
   files holding the training data where each file has 10,000 images. the
   images are rgb of size 32x32x3. the training files are named
   data_batch_1, data_batch_2, and so on. there is a single file holding
   the test data named test_batch with 10,000 images. a metadata file
   named batches.meta is available that holds the dataset classes labels
   which are airplane, automobile, bird, cat, deer, dog, frog, horse,
   ship, and truck.

   because each file in the dataset is a binary file, it should be decoded
   in order to retrieve the actual image data. for such reason, a function
   called unpickle_patch is created to do such job defined as follows:
def unpickle_patch(file):

    """

    decoding the binary file.

    :param file:file to decode it data.

    :return: dictionary of the file holding details including input data and out
put labels.

    """

    patch_bin_file = open(file, 'rb')#reading the binary file.

    patch_dict = pickle.load(patch_bin_file, encoding='bytes')#loading the detai
ls of the binary file into a dictionary.

    return patch_dict#returning the dictionary.

   the method accepts the binary file name and returns a dictionary
   holding details about such file. the dictionary holds the data for all
   10,000 samples within the file in addition to their labels.

   in order to decode the entire training data, a new function called
   get_dataset_images is created. that function accepts the dataset path
   and works only on the training data. as a result, it filters the files
   under this path and returns only files starting with data_batch_. the
   testing data is prepared later after building and training the id98.

   for each training file, it is decoded by calling the unpickle_patch
   function. based on the dictionary returned by such function, the
   get_dataset_images function returns both the images data and their
   class labels. the images data is retrieved from the    data    key and
   their class labels are retrieved from the    labels    key.

   because the images data are saved as 1d vector, it should be reshaped
   to be of 3 dimensions. this is because tensorflow accepts the images of
   such shape. for such reason, the get_dataset_images function accepts
   the number of rows/columns in addition to the number of channels in
   each image as arguments.

   the implementation of such function is as follows:
def get_dataset_images(dataset_path, im_dim=32, num_channels=3):

    """

    this function accepts the dataset path, reads the data, and returns it after
 being reshaped to match the requierments of the id98.

    :param dataset_path:path of the cifar10 dataset binary files.

    :param im_dim:number of rows and columns in each image. the image is expecte
d to be rectangular.

    :param num_channels:number of color channels in the image.

    :return:returns the input data after being reshaped and output labels.

    """

    num_files = 5#number of training binary files in the cifar10 dataset.

    images_per_file = 10000#number of samples withing each binary file.

    files_names = os.listdir(patches_dir)#listing the binary files in the datase
t path.

    """

    creating an empty array to hold the entire training data after being reshape
d.

    the dataset has 5 binary files holding the data. each binary file has 10,000
 samples. total number of samples in the dataset is 5*10,000=50,000.

    each sample has a total of 3,072 pixels. these pixels are reshaped to form a
 rgb image of shape 32x32x3.

    finally, the entire dataset has 50,000 samples and each sample of shape 32x3
2x3 (50,000x32x32x3).

    """

    dataset_array = numpy.zeros(shape=(num_files * images_per_file, im_dim, im_d
im, num_channels))

    #creating an empty array to hold the labels of each input sample. its size i
s 50,000 to hold the label of each sample in the dataset.

    dataset_labels = numpy.zeros(shape=(num_files * images_per_file), dtype=nump
y.uint8)

    index = 0#index variable to count number of training binary files being proc
essed.

    for file_name in files_names:

        """

        because the cifar10 directory does not only contain the desired training
 files and has some  other files, it is required to filter the required files.

        training files start by 'data_batch_' which is used to test whether the
file is for training or not.

        """

        if file_name[0:len(file_name) - 1] == "data_batch_":

            print("working on : ", file_name)

            """

            appending the path of the binary files to the name of the current fi
le.

            then the complete path of the binary file is used to decoded the fil
e and return the actual pixels values.

            """

            data_dict = unpickle_patch(dataset_path+file_name)

            """

            returning the data using its key 'data' in the dictionary.

            character b is used before the key to tell it is binary string.

            """

            images_data = data_dict[b"data"]

            #reshaping all samples in the current binary file to be of 32x32x3 s
hape.

            images_data_reshaped = numpy.reshape(images_data, newshape=(len(imag
es_data), im_dim, im_dim, num_channels))

            #appending the data of the current file after being reshaped.

            dataset_array[index * images_per_file:(index + 1) * images_per_file,
 :, :, :] = images_data_reshaped

            #appening the labels of the current file.

            dataset_labels[index * images_per_file:(index + 1) * images_per_file
] = data_dict[b"labels"]

            index = index + 1#incrementing the counter of the processed training
 files by 1 to accept new file.

    return dataset_array, dataset_labels#returning the training input data and o
utput labels.

   by preparing the training data, we can build and train the id98 model
   using tf.

   3. building the id98 computational graph using tensorflow

   the computational graph of the id98 is created inside a function called
   create_id98. it creates a stack of convolution (conv), relu, max
   pooling, dropout, and fully connected (fc) layers and returns the
   results of the last fully connected layer. the output of each layer is
   the input to the next layer. this requires consistency between the
   sizes of outputs and inputs of neighboring layers. note that for each
   conv, relu, and max pooling layers, there are some of parameters to get
   specified such as strides across each dimension and padding.
def create_id98(input_data, num_classes, keep_prop):

    """

    builds the id98 architecture by stacking conv, relu, pool, dropout, and fully
 connected layers.

    :param input_data:patch data to be processed.

    :param num_classes:number of classes in the dataset. it helps determining th
e number of outputs in the last fully connected layer.

    :param keep_prop:id203 of dropping neurons in the dropout layer.

    :return: last fully connected layer.

    """

    #preparing the first convolution layer.

    filters1, conv_layer1 = create_conv_layer(input_data=input_data, filter_size
=5, num_filters=4)

    """

    applying relu activation function over the conv layer output.

    it returns a new array of the same shape as the input array.

    """

    relu_layer1 = tensorflow.nn.relu(conv_layer1)

    print("size of relu1 result : ", relu_layer1.shape)

    """

    max pooling is applied to the relu layer result to achieve translation invar
iance.

    it returns a new array of a different shape from the the input array relativ
e to the strides and kernel size used.

    """

    max_pooling_layer1 = tensorflow.nn.max_pool(value=relu_layer1,

                                                ksize=[1, 2, 2, 1],

                                                strides=[1, 1, 1, 1],

                                                padding="valid")

    print("size of maxpool1 result : ", max_pooling_layer1.shape)



    #similar to the previous conv-relu-pool layers, new layers are just stacked
to complete the id98 architecture.

    #conv layer with 3 filters and each filter is of sisze of 5x5.

    filters2, conv_layer2 = create_conv_layer(input_data=max_pooling_layer1, fil
ter_size=7, num_filters=3)

    relu_layer2 = tensorflow.nn.relu(conv_layer2)

    print("size of relu2 result : ", relu_layer2.shape)

    max_pooling_layer2 = tensorflow.nn.max_pool(value=relu_layer2,

                                                ksize=[1, 2, 2, 1],

                                                strides=[1, 1, 1, 1],

                                                padding="valid")

    print("size of maxpool2 result : ", max_pooling_layer2.shape)



    #conv layer with 2 filters and a filter sisze of 5x5.

    filters3, conv_layer3 = create_conv_layer(input_data=max_pooling_layer2, fil
ter_size=5, num_filters=2)

    relu_layer3 = tensorflow.nn.relu(conv_layer3)

    print("size of relu3 result : ", relu_layer3.shape)

    max_pooling_layer3 = tensorflow.nn.max_pool(value=relu_layer3,

                                                ksize=[1, 2, 2, 1],

                                                strides=[1, 1, 1, 1],

                                                padding="valid")

    print("size of maxpool3 result : ", max_pooling_layer3.shape)



    #adding dropout layer before the fully connected layers to avoid overfitting
.

    flattened_layer = dropout_flatten_layer(previous_layer=max_pooling_layer3, k
eep_prop=keep_prop)



    #first fully connected (fc) layer. it accepts the result of the dropout laye
r after being flattened (1d).

    fc_resultl = fc_layer(flattened_layer=flattened_layer, num_inputs=flattened_
layer.get_shape()[1:].num_elements(),

                          num_outputs=200)

    #second fully connected layer accepting the output of the previous fully con
nected layer. number of outputs is equal to the number of dataset classes.

    fc_result2 = fc_layer(flattened_layer=fc_resultl, num_inputs=fc_resultl.get_
shape()[1:].num_elements(),

                          num_outputs=num_classes)

    print("fully connected layer results : ", fc_result2)

    return fc_result2#returning the result of the last fc layer.

   because the convolution layer applies the convolution operation between
   the input data and the set of filters used, the create_id98 function
   accepts the input data as an input argument. such data is what returned
   by the get_dataset_images function. the convolution layer is created
   using the create_conv_layer function. the create_conv_layer function
   accepts the input data, filter size, and number of filters and returns
   the result of convolving the input data with the set of filters. the
   set of filters have their size set according to the depth of the input
   images. the create_conv_layer is defined as follows:
def create_conv_layer(input_data, filter_size, num_filters):

    """

    builds the id98 convolution (conv) layer.

    :param input_data:patch data to be processed.

    :param filter_size:#number of rows and columns of each filter. it is expecte
d to have a rectangular filter.

    :param num_filters:number of filters.

    :return:the last fully connected layer of the network.

    """

    """

    preparing the filters of the conv layer by specifiying its shape.

    number of channels in both input image and each filter must match.

    because number of channels is specified in the shape of the input image as t
he last value, index of -1 works fine.

    """

    filters = tensorflow.variable(tensorflow.truncated_normal(shape=(filter_size
, filter_size, tensorflow.cast(input_data.shape[-1], dtype=tensorflow.int32), nu
m_filters),

                                                              stddev=0.05))

    print("size of conv filters bank : ", filters.shape)



    """

    building the convolution layer by specifying the input data, filters, stride
s along each of the 4 dimensions, and the padding.

    padding value of 'valid' means the some borders of the input image will be l
ost in the result based on the filter size.

    """

    conv_layer = tensorflow.nn.conv2d(input=input_data,

                                      filter=filters,

                                      strides=[1, 1, 1, 1],

                                      padding="valid")

    print("size of conv result : ", conv_layer.shape)

    return filters, conv_layer#returing the filters and the convolution layer re
sult.

   another argument is the id203 of keeping neurons in the dropout
   layer. it specifies how much neurons are dropped by the dropout layer.
   the dropout layer is implemented using the dropout_flatten_layer
   function as shown below. such function returns a flattened array that
   will be the input to the fully connected layer.
def dropout_flatten_layer(previous_layer, keep_prop):

    """

    applying the dropout layer.

    :param previous_layer: result of the previous layer to the dropout layer.

    :param keep_prop: id203 of keeping neurons.

    :return: flattened array.

    """

    dropout = tensorflow.nn.dropout(x=previous_layer, keep_prob=keep_prop)

    num_features = dropout.get_shape()[1:].num_elements()

    layer = tensorflow.reshape(previous_layer, shape=(-1, num_features))#flatten
ing the results.

    return layer

   because the last fc layer should have number of output neurons equal to
   the number of dataset classes, the number of dataset classes is used as
   another input argument to the create_id98 function. the fully connected
   layer is created using the fc_layer function. such function accepts the
   flattened result of the dropout layer, the number of features in such
   flattened result, and number of output neurons from such fc layer.
   based on number of inputs and outputs, a weights tensor is created
   which get then multiplied by the flattened layer to get the returned
   result of the fc layer.
def fc_layer(flattened_layer, num_inputs, num_outputs):

    """

    uilds a fully connected (fc) layer.

    :param flattened_layer: previous layer after being flattened.

    :param num_inputs: number of inputs in the previous layer.

    :param num_outputs: number of outputs to be returned in such fc layer.

    :return:

    """

    #preparing the set of weights for the fc layer. it depends on the number of
inputs and number of outputs.

    fc_weights = tensorflow.variable(tensorflow.truncated_normal(shape=(num_inpu
ts, num_outputs),

                                                              stddev=0.05))

    #id127 between the flattened array and the set of weights.

    fc_resultl = tensorflow.matmul(flattened_layer, fc_weights)

    return fc_resultl#output of the fc layer (result of id127).

   the computational graph after being visualized using tensorboard is
   shown in figure 4.

   figure 4

   [:0]

   4. training the id98

   after building the computational graph of the id98, next is to train it
   against the previously prepared training data. the training is done
   according to the following code. the code starts by preparing the path
   of the dataset and preparing it into a placeholder. note that the path
   should be changed to be suitable to your system. then it calls the
   previously discussed functions. the predictions of the trained id98 is
   used to measure the cost of the network which is to be minimized using
   the id119 optimizer. note: some of the tensors have a name
   which is helpful for retrieving such tensors later when testing the
   id98.
#nnumber of classes in the dataset. used to specify number of outputs in the las
t fully connected layer.

num_datatset_classes = 10

#number of rows & columns in each input image. the image is expected to be recta
ngular used to reshape the images and specify the input tensor shape.

im_dim = 32

#number of channels in rach input image. used to reshape the images and specify
the input tensor shape.

num_channels = 3



#directory at which the training binary files of the cifar10 dataset are saved.

patches_dir = "c:\\users\\dell\\downloads\\compressed\\cifar-10-python\\cifar-10
-batches-py\\"

#reading the cifar10 training binary files and returning the input data and outp
ut labels. output labels are used to test the id98 prediction accuracy.

dataset_array, dataset_labels = get_dataset_images(dataset_path=patches_dir, im_
dim=im_dim, num_channels=num_channels)

print("size of data : ", dataset_array.shape)



"""

input tensor to hold the data read above. it is the entry point of the computati
onal graph.

the given name of 'data_tensor' is useful for retreiving it when restoring the t
rained model graph for testing.

"""

data_tensor = tensorflow.placeholder(tensorflow.float32, shape=[none, im_dim, im
_dim, num_channels], name='data_tensor')

"""

tensor to hold the outputs label.

the name "label_tensor" is used for accessing the tensor when tesing the saved t
rained model after being restored.

"""

label_tensor = tensorflow.placeholder(tensorflow.float32, shape=[none], name='la
bel_tensor')



#the id203 of dropping neurons in the dropout layer. it is given a name fo
r accessing it later.

keep_prop = tensorflow.variable(initial_value=0.5, name="keep_prop")



#building the id98 architecure and returning the last layer which is the fully co
nnected layer.

fc_result2 = create_id98(input_data=data_tensor, num_classes=num_datatset_classes
, keep_prop=keep_prop)



"""

predicitions probabilities of the id98 for each training sample.

each sample has a id203 for each of the 10 classes in the dataset.

such tensor is given a name for accessing it later.

"""

softmax_propabilities = tensorflow.nn.softmax(fc_result2, name="softmax_probs")



"""

predicitions labels of the id98 for each training sample.

the input sample is classified as the class of the highest id203.

axis=1 indicates that maximum of values in the second axis is to be returned. th
is returns that maximum class id203 fo each sample.

"""

softmax_predictions = tensorflow.argmax(softmax_propabilities, axis=1)



#cross id178 of the id98 based on its calculated probabilities.

cross_id178 = tensorflow.nn.softmax_cross_id178_with_logits(logits=tensorflo
w.reduce_max(input_tensor=softmax_propabilities, reduction_indices=[1]),

                                                                labels=label_ten
sor)

#summarizing the cross id178 into a single value (cost) to be minimized by the
 learning algorithm.

cost = tensorflow.reduce_mean(cross_id178)

#minimizng the network cost using the id119 optimizer with a learning
 rate is 0.01.

error = tensorflow.train.gradientdescentoptimizer(learning_rate=.01).minimize(co
st)



#creating a new tensorflow session to process the computational graph.

sess = tensorflow.session()

#wiriting summary of the graph to visualize it using tensorboard.

tensorflow.summary.filewriter(logdir="./log/", graph=sess.graph)

#initializing the variables of the graph.

sess.run(tensorflow.global_variables_initializer())



"""

because it may be impossible to feed the complete data to the id98 on normal mach
ines, it is recommended to split the data into a number of patches.

a percent of traning samples is used to create each path. samples for each path
can be randomly selected.

"""

num_patches = 5#number of patches

for patch_num in numpy.arange(num_patches):

    print("patch : ", str(patch_num))

    percent = 80 #percent of samples to be included in each path.

    #getting the input-output data of the current path.

    shuffled_data, shuffled_labels = get_patch(data=dataset_array, labels=datase
t_labels, percent=percent)

    #data required for id98 operation. 1)input images, 2)output labels, and 3)dro
pout id203

    id98_feed_dict = {data_tensor: shuffled_data,

                     label_tensor: shuffled_labels,

                     keep_prop: 0.5}

    """

    training the id98 based on the current patch.

    id98 error is used as input in the run to minimize it.

    softmax predictions are returned to compute the classification accuracy.

    """

    softmax_predictions_, _ = sess.run([softmax_predictions, error], feed_dict=c
nn_feed_dict)

    #calculating number of correctly classified samples.

    correct = numpy.array(numpy.where(softmax_predictions_ == shuffled_labels))

    correct = correct.size

    print("correct predictions/", str(percent * 50000/100), ' : ', correct)

   rather than feeding the entire training data to the id98, the data is
   divided into set of patches and patch by patch will feed the network
   using a loop. each patch contains subset of the training data. the
   patches are returned using the get_patch function. such function
   accepts the input data, labels, and percent of samples to be returned
   from such data. it then returns subset of the data according to the
   input percent.
def get_patch(data, labels, percent=70):

    """

    returning patch to train the id98.

    :param data: complete input data after being encoded and reshaped.

    :param labels: labels of the entire dataset.

    :param percent: percent of samples to get returned in each patch.

    :return: subset of the data (patch) to train the id98 model.

    """

    #using the percent of samples per patch to return the actual number of sampl
es to get returned.

    num_elements = numpy.uint32(percent*data.shape[0]/100)

    shuffled_labels = labels#temporary variable to hold the data after being shu
ffled.

    numpy.random.shuffle(shuffled_labels)#randomly reordering the labels.

    """

    the previously specified percent of the data is returned starting from the b
eginning until meeting the required number of samples.

    the labels indices are also used to return their corresponding input images
samples.

    """

    return data[shuffled_labels[:num_elements], :, :, :], shuffled_labels[:num_e
lements]

   5. saving the trained id98 model

   after training the id98, the model is saved for reuse later for testing
   it in another python script. you should also change the path where the
   model is saved to be suitable to your system.
#saving the model after being trained.

saver = tensorflow.train.saver()

save_model_path = "c:\\model\\"

save_path = saver.save(sess=sess, save_path=save_model_path+"model.ckpt")

print("model saved in : ", save_path)

   6. preparing the test data and restoring the trained id98 model

   before testing the trained model, it is required to prepare the test
   data and restore the previously trained model. test data preparation is
   similar to what happened with the training data except that there is
   just a single binary file to be decoded. the test file is decoded
   according to the modified get_dataset_images function. this function
   calls the unpickle_patch function exactly as what done before with
   training data.
def get_dataset_images(test_path_path, im_dim=32, num_channels=3):

    """

    similar to the one used in training except that there is just a single testi
ng binary file for testing the cifar10 trained models.

    """

    print("working on testing patch")

    data_dict = unpickle_patch(test_path_path)

    images_data = data_dict[b"data"]

    dataset_array = numpy.reshape(images_data, newshape=(len(images_data), im_di
m, im_dim, num_channels))

    return dataset_array, data_dict[b"labels"]

   7. testing the trained id98 model.

   after preparing the test data and restoring the trained model, we can
   start testing the model according to the following code. what worth
   mentioning is that our goal is to just return the network predictions
   for the input samples. this is why the tf session runs to return just
   the predictions. when training the id98, the session runs to minimize
   the cost. in testing, we are not interested in minimizing the cost
   anymore. another interesting point is that the keep id203 of the
   dropout layer is now set to 1. that means do not drop any node. this is
   because we are just using the pre-trained model after settling on what
   nodes to drop. now we just use what the model did before and not
   interested in making modification to it by dropping other nodes.
#dataset path containing the testing binary file to be decoded.

patches_dir = "c:\\users\\dell\\downloads\\compressed\\cifar-10-python\\cifar-10
-batches-py\\"

dataset_array, dataset_labels = get_dataset_images(test_path_path=patches_dir +
"test_batch", im_dim=32, num_channels=3)

print("size of data : ", dataset_array.shape)



sess = tensorflow.session()



#restoring the previously saved trained model.

saved_model_path = 'c:\\users\\dell\\desktop\\model\\'

saver = tensorflow.train.import_meta_graph(saved_model_path+'model.ckpt.meta')

saver.restore(sess=sess, save_path=saved_model_path+'model.ckpt')



#initalizing the varaibales.

sess.run(tensorflow.global_variables_initializer())



graph = tensorflow.get_default_graph()



"""

restoring previous created tensors in the training phase based on their given te
nsor names in the training phase.

some of such tensors will be assigned the testing input data and their outcomes
(data_tensor, label_tensor, and keep_prop).

others are helpful in assessing the model prediction accuracy (softmax_propabili
ties and softmax_predictions).

"""

softmax_propabilities = graph.get_tensor_by_name(name="softmax_probs:0")

softmax_predictions = tensorflow.argmax(softmax_propabilities, axis=1)

data_tensor = graph.get_tensor_by_name(name="data_tensor:0")

label_tensor = graph.get_tensor_by_name(name="label_tensor:0")

keep_prop = graph.get_tensor_by_name(name="keep_prop:0")



#keep_prop is equal to 1 because there is no more interest to remove neurons in
the testing phase.

feed_dict_testing = {data_tensor: dataset_array,

                     label_tensor: dataset_labels,

                     keep_prop: 1.0}

#running the session to predict the outcomes of the testing samples.

softmax_propabilities_, softmax_predictions_ = sess.run([softmax_propabilities,
softmax_predictions],

                                                      feed_dict=feed_dict_testin
g)

#assessing the model accuracy by counting number of correctly classified samples
.

correct = numpy.array(numpy.where(softmax_predictions_ == dataset_labels))

correct = correct.size

print("correct predictions/10,000 : ", correct)

   8. building the flask web application

   after training the id98 model, we can add it to a http server and allow
   users to use it online. user will upload an image using a http client.
   the uploaded image will be received by the http server or more
   specifically by a flask web application. such application will predict
   the class label of the image based on the trained model and finally
   returns the class label back to the http client. such discussion is
   summarized in figure 5.

   figure 5

   [:0]

import flask



#creating a new flask web application. it accepts the package name.

app = flask.flask("cifar10_flask_web_app")



"""

to activate the web server to receive requests, the application must run.

a good practice is to check whether the file is whether the file called from an
external python file or not.

if not, then it will run.

"""

if __name__ == "__main__":

    """

    in this example, the app will run based on the following properties:

    host: localhost

    port: 7777

    debug: flag set to true to return debugging information.

    """

    app.run(host="localhost", port=7777, debug=true)

   currently, there is no functions the server provide. the first thing
   the server should do is to allow the user to upload an image. when the
   user visits the root url of the application, the application do
   nothing. the application can redirect the user to an html page at which
   the user could upload an image. to do that, the application has a
   function called redirect_upload to redirect the user to a page for
   uploading an image. what lets this function to get executed after the
   user visits the root of the app is the routing created using the
   following line:
app.add_url_rule(rule="/", endpoint="homepage", view_func=redirect_upload)

   this line says that if the user visits the root of the app (marked as
   "/"), then the viewer function (redirect_upload) will be called. such
   function do nothing except rendering a html page called
   upload_image.html. such page is located under the special templates
   directory of the server. a page inside the templates directory is
   rendered by calling the render_template function. note that there is an
   attribute called endpoint which makes it easy to reuse the same route
   multiple times without hard coding it.
def redirect_upload():

    """

    a viewer function that redirects the web application from the root to a html
 page for uploading an image to get classified.

    the html page is located under the /templates directory of the application.

    :return: html page used for uploading an image. it is 'upload_image.html' in
 this exmaple.

    """

    return flask.render_template(template_name_or_list="upload_image.html")

"""

creating a route between the homepage url (http://localhost:7777) to a viewer fu
nction that is called after getting to such url.

endpoint 'homepage' is used to make the route reusable without hard-coding it la
ter.

"""

app.add_url_rule(rule="/", endpoint="homepage", view_func=redirect_upload)

   the screen of the html page rendered is shown in figure 6.

   figure 6

   [:0]

   here is the html code of such page. it is a simple form that allows the
   user to upload an image file. when submitting such form, a post http
   message is to be returned to the url [14]http://localhost:7777/upload/.
<!doctype html>

<html lang="en">

<head>

    <link rel="stylesheet" type="text/css" href="{{url_for(endpoint='static', fi
lename='project_styles.css')}}">

    <meta charset="utf-8">

    <title>upload image</title>

</head>

<body>

<form enctype="multipart/form-data" method="post" action="http://localhost:7777/
upload/">

    <center>

    <h3>select cifar10 image to predict its label.</h3>

    <input type="file" name="image_file" accept="image/*"><br>

    <input type="submit" value="upload">

    </center>

</form>

</body>

</html>

   after returning back to the server from the html form, the viewer
   function that is associated with the url specified in the form action
   attribute will be called which is the upload_image function. such
   function gets the image selected by the user and saves it to the
   server.
def upload_image():

    """

    viewer function that is called in response to getting to the 'http://localho
st:7777/upload' url.

    it uploads the selected image to the server.

    :return: redirects the application to a new page for predicting the class of
 the image.

    """

    #global variable to hold the name of the image file for reuse later in predi
ction by the 'id98_predict' viewer functions.

    global secure_filename

    if flask.request.method == "post":#checking of the http method initiating th
e request is post.

        img_file = flask.request.files["image_file"]#getting the file name to ge
t uploaded.

        secure_filename = werkzeug.secure_filename(img_file.filename)#getting a
secure file name. it is a good practice to use it.

        img_path = os.path.join(app.root_path, secure_filename)#preparing the fu
ll path under which the image will get saved.

        img_file.save(img_path)#saving the image in the specified path.

        print("image uploaded successfully.")

        """

        after uploading the image file successfully, next is to predict the clas
s label of it.

        the application will fetch the url that is tied to the html page respons
ible for prediction and redirects the browser to it.

        the url is fetched using the endpoint 'predict'.

        """

        return flask.redirect(flask.url_for(endpoint="predict"))

    return "image upload failed."

"""

creating a route between the url (http://localhost:7777/upload) to a viewer func
tion that is called after navigating to such url.

endpoint 'upload' is used to make the route reusable without hard-coding it late
r.

the set of http method the viewer function is to respond to is added using the '
methods' argument.

in this case, the function will just respond to requests of method of type post.

"""

app.add_url_rule(rule="/upload/", endpoint="upload", view_func=upload_image, met
hods=["post"])

   after uploading the image successfully to the server, we are ready to
   read the image and predict its class label using the previously trained
   id98 model. for such reason, the upload_image function redirects the
   application to the viewer function that is responsible for predicting
   the class label of an image. such viewer function is reached by its
   endpoint as specified in this line:
return flask.redirect(flask.url_for(endpoint="predict"))

   the method associated with endpoint="predict" will be called which is
   the id98_predict function. such method reads the image and checks
   whether it matches the dimensions of the cifar-10 dataset which is
   32x32x3. if the image matches the specifications of the cifar-10
   dataset, then it will be passed to a function responsible for making
   prediction as in the following line:
predicted_class = cifar10_id98_predict_image.main(img)


   the main function responsible for predicting the class label of an
   image is defined as shown below. it restores the trained model and runs
   a session that returns the predicted class of the image. the predicted
   class is returned back to the flask web application.
def id98_predict():

    """

    reads the uploaded image file and predicts its label using the saved pre-tra
ined id98 model.

    :return: either an error if the image is not for cifar10 dataset or redirect
s the browser to a new page to show the prediction result if no error occurred.

    """

    """

    setting the previously created 'secure_filename' to global.

    this is because to be able invoke a global variable created in another funct
ion, it must be defined global in the caller function.

    """

    global secure_filename

    #reading the image file from the path it was saved in previously.

    img = scipy.misc.imread(os.path.join(app.root_path, secure_filename))



    """

    checking whether the image dimensions match the cifar10 specifications.

    cifar10 images are rgb (i.e. they have 3 dimensions). it number of dimenions
 was not equal to 3, then a message will be returned.

    """

    if(img.ndim) == 3:

        """

        checking if the number of rows and columns of the read image matched cif
ar10 (32 rows and 32 columns).

        """

        if img.shape[0] == img.shape[1] and img.shape[0] == 32:

            """

            checking whether the last dimension of the image has just 3 channels
 (red, green, and blue).

            """

            if img.shape[-1] == 3:

                """

                passing all conditions above, the image is proved to be of cifar
10.

                this is why it is passed to the predictor.

                """

                predicted_class = cifar10_id98_predict_image.main(img)

                """

                after predicting the class label of the input image, the predict
ion label is rendered on an html page.

                the html page is fetched from the /templates directory. the html
 page accepts an input which is the predicted class.

                """

                return flask.render_template(template_name_or_list="prediction_r
esult.html", predicted_class=predicted_class)

            else:

                # if the image dimensions do not match the cifar10 specification
s, then an html page is rendered to show the problem.

                return flask.render_template(template_name_or_list="error.html",
 img_shape=img.shape)

        else:

            # if the image dimensions do not match the cifar10 specifications, t
hen an html page is rendered to show the problem.

            return flask.render_template(template_name_or_list="error.html", img
_shape=img.shape)

    return "an error occurred."#returned if there is a different error other tha
n wrong image dimensions.

"""

creating a route between the url (http://localhost:7777/predict) to a viewer fun
ction that is called after navigating to such url.

endpoint 'predict' is used to make the route reusable without hard-coding it lat
er.

"""

app.add_url_rule(rule="/predict/", endpoint="predict", view_func=id98_predict)


   the main function responsible for predicting the class label of an
   image is defined as shown below. it restores the trained model and runs
   a session that returns the predicted class of the image. the predicted
   class is returned back to the flask web application.
def main(img):

    """

    the 'main' method accepts an input image array of size 32x32x3 and returns i
ts class label.

    :param img:rgb image of size 32x32x3.

    :return:predicted class label.

    """

    #dataset path containing a binary file with the labels of classes. useful to
 decode the prediction code into a significant textual label.

    patches_dir = "c:\\cifar-10-python\\cifar-10-batches-py\\"

    dataset_array = numpy.random.rand(1, 32, 32, 3)

    dataset_array[0, :, :, :] = img



    sess = tensorflow.session()



    #restoring the previously saved trained model.

    saved_model_path = 'c:\\model\\'

    saver = tensorflow.train.import_meta_graph(saved_model_path+'model.ckpt.meta
')

    saver.restore(sess=sess, save_path=saved_model_path+'model.ckpt')



    #initalizing the varaibales.

    sess.run(tensorflow.global_variables_initializer())



    graph = tensorflow.get_default_graph()



    """

    restoring previous created tensors in the training phase based on their give
n tensor names in the training phase.

    some of such tensors will be assigned the testing input data and their outco
mes (data_tensor, label_tensor, and keep_prop).

    others are helpful in assessing the model prediction accuracy (softmax_propa
bilities and softmax_predictions).

    """

    softmax_propabilities = graph.get_tensor_by_name(name="softmax_probs:0")

    softmax_predictions = tensorflow.argmax(softmax_propabilities, axis=1)

    data_tensor = graph.get_tensor_by_name(name="data_tensor:0")

    label_tensor = graph.get_tensor_by_name(name="label_tensor:0")

    keep_prop = graph.get_tensor_by_name(name="keep_prop:0")



    #keep_prop is equal to 1 because there is no more interest to remove neurons
 in the testing phase.

    feed_dict_testing = {data_tensor: dataset_array,

                         keep_prop: 1.0}

    #running the session to predict the outcomes of the testing samples.

    softmax_propabilities_, softmax_predictions_ = sess.run([softmax_propabiliti
es, softmax_predictions],

                                                          feed_dict=feed_dict_te
sting)

    label_names_dict = unpickle_patch(patches_dir + "batches.meta")

    dataset_label_names = label_names_dict[b"label_names"]

    return dataset_label_names[softmax_predictions_[0]].decode('utf-8')

   the returned class label of the image will be rendered on a new html
   page named prediction_result.html as instructed by the id98_predict
   function in this line as in figure 7.

   figure 7

   [:0]

   note that the flask app uses the jinja2 template engine that allows the
   html page to accept input arguments. the input argument passed in this
   case is predicted_class=predicted_class.
return flask.render_template(template_name_or_list="prediction_result.html", pre
dicted_class=predicted_class)

   the html code of such page is as follows.
<!doctype html>

<html lang="en">

<head>

    <link rel="stylesheet" type="text/css" href="{{url_for(endpoint='static', fi
lename='project_styles.css')}}">

    <script type="text/javascript" src="{{url_for(endpoint='static', filename='r
esult.js')}}"></script>

    <meta charset="utf-8">

    <title>prediction result</title>

</head>

<body onload="show_alert('{{predicted_class}}')">

<center><h1>predicted class label : <span>{{predicted_class}}</span></h1>

    <br>

    <a href="{{url_for(endpoint='homepage')}}"><span>return to homepage</span>.<
/a>

</center>

</body>

</html>

   it is a template that is filled by the predicted class of the image
   which is passes as an argument to the html page as in this part of the
   code:
<span>{{predicted_class}}</span>

   for more information about the flask restful api, you can visit such
   tutorial [15]https://www.tutorialspoint.com/flask/index.htm.

   the complete project is available at github in this link:
   [16]https://github.com/ahmedfgad/cifar10id98flask

   [17]ahmed gad

[18]ahmed gad

job seeker. fritz/kdnuggets/tds contributor, t.a. & deep learning | machine
learning | id161 researcher

   [19]follow

   3 comments
   article-comment__guest-image
   [20]sign in to leave your comment
   show more comments.
     __________________________________________________________________

more from ahmed gad

   [21]27 articles
   from y=x to building a complete id158

[22]from y=x to building a complete artificial   

   march 29, 2019

   feature reduction using genetic algorithm with python

[23]feature reduction using genetic algorithm   

   january 29, 2019

   id158s optimization using genetic algorithm with
   python

[24]id158s optimization   

   january 24, 2019

     *    2019
     * [25]about
     * [26]user agreement
     * [27]privacy policy
     * [28]cookie policy
     * [29]copyright policy
     * [30]brand policy
     * [31]manage subscription
     * [32]community guidelines
     * [ ]
          + (button) bahasa indonesia
          + (button) bahasa malaysia
          + (button)   e  tina
          + (button) dansk
          + (button) deutsch
          + (button) english
          + (button) espa  ol
          + (button)             
          + (button) fran  ais
          + (button)          
          + (button) italiano
          + (button)             
          + (button) nederlands
          + (button)          
          + (button) norsk
          + (button) polski
          + (button) portugu  s
          + (button) rom  n  
          + (button)               
          + (button) svenska
          + (button) tagalog
          + (button)                      
          + (button) t  rk  e
          + (button)               
       languagelanguage

references

   1. https://www.linkedin.com/?trk=header_logo
   2. https://www.linkedin.com/uas/login?trk=header_signin
   3. https://www.linkedin.com/start/join?trk=header_join
   4. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_image
   5. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_title
   6. https://www.linkedin.com/uas/login?session_redirect=https://www.linkedin.com/pulse/complete-guide-build-convnet-http-based-application-using-ahmed-gad&trk=author-info__follow-button
   7. about:blank
   8. about:blank
   9. https://www.anaconda.com/download/#windows
  10. https://www.tensorflow.org/install/install_windows
  11. https://youtu.be/msono20mrvu
  12. https://www.jetbrains.com/pycharm/download/#section=windows
  13. https://www.cs.toronto.edu/~kriz/cifar.html
  14. http://localhost:7777/upload/
  15. https://www.tutorialspoint.com/flask/index.htm
  16. https://github.com/ahmedfgad/cifar10id98flask
  17. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_image
  18. https://eg.linkedin.com/in/ahmedfgad?trk=author_mini-profile_title
  19. https://www.linkedin.com/uas/login?session_redirect=https://www.linkedin.com/pulse/complete-guide-build-convnet-http-based-application-using-ahmed-gad&trk=author-info__follow-button-bottom
  20. https://www.linkedin.com/uas/login?session_redirect=https://www.linkedin.com/pulse/complete-guide-build-convnet-http-based-application-using-ahmed-gad&trk=article-reader_leave-comment
  21. https://www.linkedin.com/today/author/ahmedfgad
  22. https://www.linkedin.com/pulse/from-yx-building-complete-artificial-neural-network-ahmed-gad?trk=related_artice_from y=x to building a complete id158_article-card_title
  23. https://www.linkedin.com/pulse/feature-reduction-using-genetic-algorithm-ahmed-gad?trk=related_artice_feature reduction using genetic algorithm with python_article-card_title
  24. https://www.linkedin.com/pulse/artificial-neural-networks-optimization-using-genetic-ahmed-gad?trk=related_artice_id158s optimization using genetic algorithm with python_article-card_title
  25. https://press.linkedin.com/about-linkedin?trk=article_reader_footer_footer-about
  26. https://www.linkedin.com/legal/user-agreement?trk=article_reader_footer_footer-user-agreement
  27. https://www.linkedin.com/legal/privacy-policy?trk=article_reader_footer_footer-privacy-policy
  28. https://www.linkedin.com/legal/cookie-policy?trk=article_reader_footer_footer-cookie-policy
  29. https://www.linkedin.com/legal/copyright-policy?trk=article_reader_footer_footer-copyright-policy
  30. https://brand.linkedin.com/policies?trk=article_reader_footer_footer-brand-policy
  31. https://www.linkedin.com/psettings/guest-controls?trk=article_reader_footer_footer-manage-sub
  32. https://www.linkedin.com/help/linkedin/answer/34593?lang=en&trk=article_reader_footer_footer-community-guide
