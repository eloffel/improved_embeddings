[1]createmomo

   [2]home [3]archives
   ____________________ (button)    
   [4]2017-09-12

crf layer on the top of bilstm - 1

outline

   the article series will include:
     * introduction - the general idea of the crf layer on the top of
       bilstm for id39 tasks
     * a detailed example - a toy example to explain how crf layer works
       step-by-step
     * chainer implementation - a chainer implementation of the crf layer

     who could be the readers of this article series?
     this article series is for students or someone else who is the
     beginner of natural language processing or any other ai related
     areas, i hope you can find what you do want to know from my
     articles. moreover, please be free to provide any comments or
     suggestions to improve the series.

prior knowledge

   the only thing you need to know is what is id39. if
   you do not know neural networks, crf or any other related knowledge,
   please do not worry about that. i will explain everything as intuitive
   as possible.

1. introduction

   for a id39 task, neural network based methods are
   very popular and common. for example, this [5]paper[1] proposed a
   bilstm-crf id39 model which used word and character
   embeddings. i will take the model in this paper for an example to
   explain how crf layer works.

   if you do not know the details of bilstm and crf, just remember they
   are two different layers in a id39 model.

1.1 before we start

   we assume that, we have a dataset in which we have two entity types,
   person and organization. therefore, in fact, in our dataset, we have 5
   entity labels:
     * b-person
     * i- person
     * b-organization
     * i-organization
     * o

   furthermore, $ x $ is a sentence which includes 5 words,
   $w_0$,$w_1$,$w_2$,$w_3$,$w_4$. what is more, in sentence $x$,
   [$w_0$,$w_1$] is a person entity, [$w_3$] is an organization entity and
   others are    o   .

1.2 bilstm-crf model

   i will give a brief introduction of this model.

   as shown in the picture below:
     * firstly, every word in sentence $x$ is represented as a vector
       which includes the word   s character embedding and id27.
       the character embedding is initialized randomly. the id27
       usually is from a pre-trained id27 file. all the
       embeddings will be fine-tuned during the training process.
     * second, the inputs of bilstm-crf model are those embeddings and the
       outputs are predicted labels for words in sentence $x$.

   figure 1.1: bilstm-crf model

   although, it is not necessary to know the details of bilstm layer, in
   order to understand the crf layer more easily, we have to know what is
   the meaning of the output of bilstm layer.

   figure 1.2: the meaning of outputs of bilstm layer

   the picture above illustrates that the outputs of bilstm layer are the
   scores of each label. for example, for $w_0$   the outputs of bilstm node
   are 1.5 (b-person), 0.9 (i-person), 0.1 (b-organization), 0.08
   (i-organization) and 0.05 (o). these scores will be the inputs of the
   crf layer.

   then, all the scores predicted by the bilstm blocks are fed into the
   crf layer. in the crf layer, the label sequence which has the highest
   prediction score would be selected as the best answer.

1.3 what if we do not have the crf layer

   you may have found that, even without the crf layer, in other words, we
   can train a bilstm id39 model as shown in the
   following picture.
   figure 1.3: the bilstm model with out crf layer output correct labels
   because the outputs of bilstm of each word are the label scores. we can
   select the label which has the highest score for each word.

   for instance, for $w_0$,    b-person   , has the highest score (1.5),
   therefore we can select    b-person    as its best predicted label. in the
   same way, we can choose    i-person    for $w_1$,    o    for $w_2$,
      b-organization    for $w_3$ and    o    for $w_4$.

   although we can get correct labels for sentence $x$ in this example,
   but it is not always like that. try again for the following example in
   the picture below.
   figure 1.4: the bilstm model with out crf layer output some invalid
   label sequences
   obviously, the outputs are invalid this time,    i-organization i-person   
   and    b-organization i-person   .

1.4 crf layer can learn constrains from training data

   the crf layer could add some constrains to the final predicted labels
   to ensure they are valid. these constrains can be learned by the crf
   layer automatically from the training dataset during the training
   process.

   the constrains could be:
     * the label of the first word in a sentence should start with    b-    or
          o   , not    i-   
     *    b-label1 i-label2 i-label3 i-      , in this pattern, label1, label2,
       label3     should be the same named entity label. for example,
          b-person i-person    is valid, but    b-person i-organization    is
       invalid.
     *    o i-label    is invalid. the first label of one named entity should
       start with    b-    not    i-   , in other words, the valid pattern should
       be    o b-label   
     *    

   with these useful constrains, the number of invalid predicted label
   sequences will decrease dramatically.

next

   in the next section, i will analyze the crf id168 to explain
   how or why the crf layer can learn those constrains mentioned above
   from training dataset.

   looking forward to seeing you soon!

references

   [1] lample, g., ballesteros, m., subramanian, s., kawakami, k. and
   dyer, c., 2016. neural architectures for id39.
   arxiv preprint arxiv:1603.01360.
   [6]https://arxiv.org/abs/1603.01360

     when you reprint or distribute this article, please include the
     original link address.

   share [7]comments
   [8]newer
   crf layer on the top of bilstm - 2
   please enable javascript to view the [9]comments powered by disqus.

archives

     * [10]january 2019
     * [11]january 2018
     * [12]december 2017
     * [13]november 2017
     * [14]october 2017
     * [15]september 2017

recent posts

     * [16]table of contents
     * [17]probabilistic id114 revision notes
     * [18]super machine learning revision notes
     * [19]my life
     * [20]crf layer on the top of bilstm - 8

      2019 createmomo
   powered by [21]hexo
   [22]home [23]archives

references

   visible links
   1. https://createmomo.github.io/
   2. https://createmomo.github.io/
   3. https://createmomo.github.io/archives
   4. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/
   5. https://arxiv.org/abs/1603.01360
   6. https://arxiv.org/abs/1603.01360
   7. http://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#disqus_thread
   8. https://createmomo.github.io/2017/09/23/crf_layer_on_the_top_of_bilstm_2/
   9. https://disqus.com/?ref_noscript
  10. https://createmomo.github.io/archives/2019/01/
  11. https://createmomo.github.io/archives/2018/01/
  12. https://createmomo.github.io/archives/2017/12/
  13. https://createmomo.github.io/archives/2017/11/
  14. https://createmomo.github.io/archives/2017/10/
  15. https://createmomo.github.io/archives/2017/09/
  16. https://createmomo.github.io/2019/01/07/table-of-contents/
  17. https://createmomo.github.io/2019/01/07/probabilistic-graphical-models-revision-notes/
  18. https://createmomo.github.io/2018/01/23/super-machine-learning-revision-notes/
  19. https://createmomo.github.io/2018/01/17/my-life/
  20. https://createmomo.github.io/2017/12/07/crf-layer-on-the-top-of-bilstm-8/
  21. http://hexo.io/
  22. https://createmomo.github.io/
  23. https://createmomo.github.io/archives

   hidden links:
  25. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#outline
  26. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#prior-knowledge
  27. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#1-introduction
  28. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#1-1-before-we-start
  29. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#1-2-bilstm-crf-model
  30. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#1-3-what-if-we-do-not-have-the-crf-layer
  31. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#1-4-crf-layer-can-learn-constrains-from-training-data
  32. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#next
  33. https://createmomo.github.io/2017/09/12/crf_layer_on_the_top_of_bilstm_1/#references
