   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    comprehensive & practical inferential statistics
   guide for data science comments feed [4]alternate [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]business analytics [94]comprehensive & practical
   inferential statistics guide for data science

   [95]business analytics

comprehensive & practical inferential statistics guide for data science

   [96]nss, january 31, 2017

introduction

   statistics is one of the key fundamental skills required for data
   science. any expert in data science would surely recommend learning /
   upskilling yourself in statistics.

   however, if you go out and look for resources on statistics, you will
   see that a lot of them tend to focus on the mathematics. they will
   focus on derivation of formulas rather than simplifying the concept. i
   believe, statistics can be understood in very simple and practical
   manner. that is why i have created this guide.

   in this guide, i will take you through inferential statistics, which
   is one of the most important concepts in statistics for data science. i
   will take you through all the related concepts of inferential
   statistics and their practical applications.

   this guide would act as a comprehensive resource to learn inferential
   statistics. so, go through the guide, section by section. work through
   the examples and develop your statistics skills for data science.

   read on!


table of contents

    1. why we need inferential statistics?
    2. pre-requisites
    3. sampling distribution and central limit theorem
    4. hypothesis testing
    5. types of error in hypothesis testing
    6. t-tests
    7. different types of t-test
    8. anova
    9. chi-square goodness of fit
   10. regression and anova
   11. coefficient of determination (r-squared)


1. why do we need inferential statistics?

   suppose, you want to know the average salary of data science
   professionals in india. which of the following methods can be used to
   calculate it?
    1. meet every data science professional in india. note down their
       salaries and then calculate the total average?
    2. or hand pick a number of professionals in a city like gurgaon. note
       down their salaries and use it to calculate the indian average.

   well, the first method is not impossible but it would require an
   enormous amount of resources and time. but today, companies want to
   make decisions swiftly and in a cost-effective way, so the first method
   doesn   t stand a chance.

   on the other hand, second method seems feasible. but, there is a
   caveat. what if the population of gurgaon is not reflective of the
   entire population of india? there are then good chances of you making a
   very wrong estimate of the salary of indian data science professionals.

   now, what method can be used to estimate the average salary of all data
   scientists across india?

enter inferential statistics

   in simple language, inferential statistics is used to draw id136s
   beyond the immediate data available.

   with the help of inferential statistics, we can answer the following
   questions:
     * making id136s about the population from the sample.
     * concluding whether a sample is significantly different from the
       population. for example, let   s say you collected the salary details
       of data science professionals in bangalore. and you observed that
       the average salary of bangalore   s data scientists is more than the
       average salary across india. now, we can conclude if the difference
       is statistically significant.
     * if adding or removing a feature from a model will really help to
       improve the model.
     * if one model is significantly better than the other?
     * hypothesis testing in general.

   i am sure by now you must have got a gist of why inferential statistics
   is important. i will take you through the various techniques & concepts
   involved in inferential statistics. but first, let   s discuss what are
   the prerequisites for understanding inferential statistics.


2. pre-requisites

   to begin with inferential statistics, one must have a good grasp over
   the following concepts:
    1. id203
    2. basic knowledge of id203 distributions
    3. descriptive statistics

   if you are not comfortable with either of the three concepts mentioned
   above, you must go through them before proceeding further.

   throughout the entire article, i will be using a few terminologies
   quite often. so, here is a brief description of them:
     * statistic     a single measure of some attribute of a sample. for eg:
       mean/median/mode of a sample of data scientists in bangalore.
     * population statistic     the statistic of the entire population in
       context. for eg: population mean for the salary of the entire
       population of data scientists across india.
     * sample statistic     the statistic of a group taken from a
       population. for eg: mean of salaries of all data scientists in
       bangalore.
     * standard deviation     it is the amount of variation in the
       population data. it is given by   .
     * standard error     it is the amount of variation in the sample data.
       it is related to standard deviation as   /   n, where, n is the sample
       size.


3. sampling distribution and central limit theorem

   suppose, you note down the salary of any 100 random data science
   professionals in gurgaon, calculate the mean and repeat the procedure
   for say like 200 times (arbitrarily).

   when you plot a frequency graph of these 200 means, you are likely to
   get a curve similar to the one below.

   [sampling_dist.png]

   this looks very much similar to the normal curve that you studied in
   the descriptive statistics. this is called sampling distribution or the
   graph obtained by plotting sample means. let us look at a more formal
   description of a sampling distribution.

   a sampling distribution is a id203 distribution of a statistic
   obtained through a large number of samples drawn from a specific
   population.

   a sampling distribution behaves much like a normal curve and has some
   interesting properties like :
     * the shape of the sampling distribution does not reveal anything
       about the shape of the population. for example, for the above
       sampling distribution, the population distribution may look like
       the below graph.

   [sample_7.png]

   population distribution
     * sampling distribution helps to estimate the population statistic.

   but how ?

   this will be explained using a very important theorem in statistics    
   the central limit theorem.


3.1 central limit theorem

   it states that when plotting a sampling distribution of means, the mean
   of sample means will be equal to the population mean. and the sampling
   distribution will approach a normal distribution with variance equal
   to   /   n where    is the standard deviation of population and n is the
   sample size.

   points to note:
    1. central limit theorem holds true irrespective of the type of
       distribution of the population.
    2. now, we have a way to estimate the population mean by just making
       repeated observations of samples of a fixed size.
    3. greater the sample size, lower the standard error and greater the
       accuracy in determining the population mean from the sample mean.

   this seemed too technical isn   t it? let   s break this down to understand
   this point by point.
    1. this means     no matter the shape of the population distribution, be
       it bi-modal, right skewed etc. the shape of the sampling
       distribution will remain the same (remember the normal curve- bell
       shaped). this gives us a mathematical advantage to estimate the
       population statistic     no matter the shape of the population.
    2. the number of samples have to be sufficient (generally more than
       50) to satisfactorily achieve a normal curve distribution. also,
       care has to be taken to keep the sample size fixed since any change
       in sample size will change the shape of the sampling distribution
       and it will no longer be bell shaped.
    3. as we increase the sample size, the sampling distribution squeezes
       from both sides giving us a better estimate of the population
       statistic since it lies somewhere in the middle of the sampling
       distribution (generally). the below image will help you visualize
       the effect of sample size on the shape of distribution.

   [sample_8.png]

   now, since we have collected the samples and plotted their means, it is
   important to know where the population mean lies with respect to a
   particular sample mean and how confident can we be about it. this
   brings us to our next topic     confidence interval.


3.2 confidence interval

   the confidence interval is a type of interval estimate from the
   sampling distribution which gives a range of values in which the
   population statistic may lie. let us understand this with the help of
   an example.

   [sampling_3.png]

   we know that 95% of the values lie within 2 (1.96 to be more accurate)
   standard deviation of a normal distribution curve. so, for the above
   curve, the blue shaded portion represents the confidence interval for a
   sample mean of 0.

   formally, confidence interval is defined as,

   [image_11.png]

   whereas,   = the sample mean

   = z value for desired confidence level   

      = the population standard deviation

   for an alpha value of 0.95 i.e 95% confidence interval, z=1.96.

   now there is one more term which you should be familiar with, margin of
   error.  it is given as {(z.  )/   n} and defined as the sampling error by
   the surveyor or the person who collected the samples. that means, if a
   sample mean lies in the margin of error range then, it might be
   possible that its actual value is equal to the population mean and the
   difference is occurring by chance. anything outside margin of error is
   considered statistically significant.

   and it is easy to infer that the error can be both positive and
   negative side. the whole margin of error on both sides of the sample
   statistic constitutes the confidence interval. numerically, c.i is
   twice of margin of error.

   the below image will help you better visualize margin of error and
   confidence interval.

   [sampling_4.png]

   the shaded portion on horizontal axis represents the confidence
   interval and half of it is margin of error which can be in either
   direction of x (bar).

   interesting points to note about confidence intervals:
    1. confidence intervals can be built with difference degrees of
       confidence suitable to a user   s needs like 70 %, 90% etc.
    2. greater the sample size, smaller the confidence interval, i.e more
       accurate determination of population mean from the sample means.
    3. there are different confidence intervals for different sample
       means. for example, a sample mean of 40 will have a difference
       confidence interval from a sample mean of 45.
    4. by 95% confidence interval, we do not mean that     the id203
       of a population mean to lie in an interval is 95%. instead, 95% c.i
       means that 95% of the interval estimates will contain the
       population statistic.

   many people do not have right knowledge about confidence interval and
   often interpret it incorrectly. so, i would like you to take your time
   visualizing the 4th argument and let it sink in.


3.3 practical example

   calculate the 95% confidence interval for a sample mean of 40 and
   sample standard deviation of 40 with sample size equal to 100.

   solution:

   we know, z-value for 95% c.i is 1.96. hence, confidence interval (c.i)
   is calculated as:

   c.i= [{x(bar)     (z*s/   n)},{x(bar)     (z*s/   n)}]

   c.i = [{40-(1.96*40/10},{ 40+(1.96*40/10)}]

   c.i = [32.16, 47.84]


4. hypothesis testing

   before i get into the theoretical explanation, let us understand
   hypothesis testing by using a simple example.

   example: class 8th has a mean score of 40 marks out of 100. the
   principal of the school decided that extra classes are necessary in
   order to improve the performance of the class. the class scored an
   average of 45 marks out of 100 after taking extra classes. can we be
   sure whether the increase in marks is a result of extra classes or is
   it just random?

   hypothesis testing lets us identify that. it lets a sample statistic to
   be checked against a population statistic or statistic of another
   sample to study any intervention etc. extra classes being the
   intervention in the above example.

   hypothesis testing is defined in two terms     null hypothesis and
   alternate hypothesis.
     * null hypothesis being the sample statistic to be equal to the
       population statistic. for eg: the null hypothesis for the above
       example would be that the average marks after extra class are same
       as that before the classes.
     * alternate hypothesis for this example would be that the marks after
       extra class are significantly different from that before the class.

   hypothesis testing is done on different levels of confidence and makes
   use of z-score to calculate the id203. so for a 95% confidence
   interval, anything above the z-threshold for 95% would reject the null
   hypothesis.

   points to be noted:
    1. we cannot accept the null hypothesis, only reject it or fail to
       reject it.
    2. as a practical tip, null hypothesis is generally kept which we want
       to disprove. for eg: you want to prove that students performed
       better after taking extra classes on their exam. the null
       hypothesis, in this case, would be that the marks obtained after
       the classes are same as before the classes.


5. types of errors in hypothesis testing

   now we have defined a basic hypothesis testing framework. it is
   important to look into some of the mistakes that are committed while
   performing hypothesis testing and try to classify those mistakes if
   possible.

   now, look at the null hypothesis definition above. what we notice at
   the first look is that it is a statement subjective to the tester like
   you and me and not a fact. that means there is a possibility that the
   null hypothesis can be true or false and we may end up committing some
   mistakes on the same lines.

   there are two types of errors that are generally encountered while
   conducting hypothesis testing.
     * type i error: look at the following scenario     a male human tested
       positive for being pregnant. is it even possible? this surely looks
       like a case of false positive. more formally, it is defined as the
       incorrect rejection of a true null hypothesis. the null hypothesis,
       in this case, would be     male human is not pregnant.
     * type ii error: look at another scenario where our null hypothesis
       is     a male human is pregnant and the test supports the null
       hypothesis.  this looks like a case of false negative. more
       formally it is defined as the acceptance of a false null
       hypothesis.

   the below image will summarize the types of error :

   [errors.jpg]


6. t-tests

   t-tests are very much similar to the z-scores, the only difference
   being that instead of the population standard deviation, we now use the
   sample standard deviation. the rest is same as before, calculating
   probabilities on basis of t-values.

   the sample standard deviation is given as:

   [eq_2.png]

   where n-1 is the bessel   s correction for estimating the population
   parameter.

   another difference between z-scores and t-values are that t-values are
   dependent on degree of freedom of a sample. let us define what degree
   of freedom is for a sample.

   the degree of freedom      it is the number of variables that have the
   choice of having more than one arbitrary value. for example, in a
   sample of size 10 with mean 10, 9 values can be arbitrary but the 1oth
   value is forced by the sample mean.

   points to note about the t-tests:
    1. greater the difference between the sample mean and the population
       mean, greater the chance of rejecting the null hypothesis. why? (we
       discussed this above.)
    2. greater the sample size, greater the chance of rejection of null
       hypothesis.


7. different types of t-tests

7.1 1-sample t-test

   this is the same test as we described above. this test is used to:
     * determine whether the mean of a group differs from the specified
       value.
     * calculate a range of values that are likely to include the
       population mean.

   for eg: a pizza delivery manager may perform a 1-sample t-test whether
   their delivery time is significantly different from that of the
   advertised time of 30 minutes by their competitors.

   [eq_3.png]

   where, x(bar) = sample mean

      = population mean

   s = sample standard deviation

   n = sample size


7.2 paired t-test

   paired t-test is performed to check whether there is a difference in
   mean after a treatment on a sample in comparison to before. it checks
   whether the null hypothesis: the difference between the means is zero,
   can be rejected or not.

   [screenshot-13.png]


   the above example suggests that the null hypothesis should not be
   rejected and that there is no significant difference in means before
   and after the intervention since p-value is not less than the alpha
   value (o.o5) and t stat is not less than t-critical. the excel sheet
   for the above exercise is available [97]here.

   [eq_4.png]

   where, d (bar) = mean of the case wise difference between before and
   after,

   [image_1.png] = standard deviation of the difference

    n = sample size.


7.3 2-sample t-test

   this test is used to determine:
     * determine whether the means of two independent groups differ.
     * calculate a range of values that is likely to include the
       difference between the population means.

   [eq_41.png]

   the above formula represents the 2 sample t-test and can be used in
   situations like to check whether two machines are producing the same
   output. the points to be noted for this test are:
    1. the groups to be tested should be independent.
    2. the groups    distribution should not be highly skewed.

   where, x1 (bar) = mean of the first group

      = represents 1st group sample standard deviation

   = represents the 1st group sample size.


7.4 practical example

   we will understand how to identify which t-test to be used and then
   proceed on to solve it. the other t-tests will follow the same
   argument.

   example: a population has mean weight of 68 kg. a random sample of size
   25 has a mean weight of 70 with standard deviation =4. identify
   whether this sample is representative of the population?

step 0: identifying the type of t-test

   number of samples in question = 1

   number of times the sample is in study = 1

   any intervention on sample = no

   recommended t-test = 1- sample t-test.

   had there been 2 samples, we would have opted for 2-sample t-test and
   if there would have been 2 observations on the same sample, we would
   have opted for paired t-test.`


step 1: state the null and alternate hypothesis

   null hypothesis: the sample mean and population mean are same.

   alternate hypothesis: the sample mean and population mean are
   different.


step 2: calculate the appropriate test statistic

   df = 25-1 =24

   t= (70-68)/(4/   25) = 2.5

   now, for a 95% confidence level, t-critical (two-tail) for rejecting
   null hypothesis for 24 d.f is 2.06 . hence, we can reject the null
   hypothesis and conclude that the two means are different.

   you can use the t-test calculator [98]here.


8. anova

   anova (analysis of variance) is used to check if at least one of two or
   more groups have statistically different means. now, the question
   arises     why do we need another test for checking the difference of
   means between independent groups? why can we not use multiple t-tests
   to check for the difference in means?

   the answer is simple. multiple t-tests will have a compound effect on
   the error rate of the result. performing t-test thrice will give an
   error rate of ~15% which is too high, whereas anova keeps it at 5% for
   a 95% confidence interval.

   to perform an anova, you must have a continuous response variable and
   at least one categorical factor with two or more levels. anova requires
   data from approximately normally distributed populations with equal
   variances between factor levels. however, anova procedures work quite
   well even if the normality assumption has been violated unless one or
   more of the distributions are highly skewed or if the variances are
   quite different.

   anova is measured using a statistic known as f-ratio. it is defined as
   the ratio of mean square (between groups) to the mean square (within
   group).

   mean square (between groups) = sum of squares (between groups) / degree
   of freedom (between groups)

   mean square (within group) = sum of squares (within group) / degree of
   freedom (within group)

   [screenshot-from-2017-01-20-04-38-39.png]

   here, p = represents the number of groups

   n = represents the number of observations in a group

   =  represents the mean of a particular group

   x (bar) = represents the mean of all the observations

   now, let us understand the degree of freedom for within group and
   between groups respectively.

   between groups : if there are k groups in anova model, then k-1 will be
   independent. hence, k-1 degree of freedom.

   within groups : if n represents the total observations in anova (   n
   over all groups) and k are the number of groups then, there will be k
   fixed points. hence, n-k degree of freedom.


8.1 steps to perform anova

    1. hypothesis generation
         1. null hypothesis : means of all the groups are same
         2. alternate hypothesis : mean of at least one group is different
    2. calculate within group and between groups variability
    3. calculate f-ratio
    4. calculate id203 using f-table
    5. reject/fail to reject null hypothesis

   there are various other forms of anova too like two-way anova, manova,
   ancova etc. but one-way anova suffices the requirements of this course.

   practical applications of anova in modeling are:
    1. identifying whether a categorical variable is relevant to a
       continuous variable.
    2. identifying whether a treatment was effective to the model or not.


8.2 practical example

   suppose there are 3 chocolates in town and their sweetness is
   quantified by some metric (s). data is collected on the three
   chocolates. you are given the task to identify whether the mean
   sweetness of the 3 chocolates are different. the data is given as
   below:

                                                                    type a
                      type b                   type c
   [screenshot-from-2017-01-20-04-43-12.png]
   here, first we have calculated the sample mean and sample standard
   deviation for you.

   now we will proceed step-wise to calculate the f-ratio (anova
   statistic).

step 1: stating the null and alternate hypothesis

   null hypothesis: mean sweetness of the three chocolates are same.

   alternate hypothesis: mean sweetness of at least one of the chocolates
   is different.

step 2: calculating the appropriate anova statistic

   in this part, we will be calculating ss(b), ss(w), ss(t) and then move
   on to calculate ms(b) and ms(w). the thing to note is that,

   total sum of squares [ss(t)] = between sum of squares [ss(b)] + within
   sum of squares [ss(w)].

   so, we need to calculate any two of the three parameters using the data
   table and formulas given above.

   as, per the formula above, we need one more statistic i.e grand mean
   denoted by x(bar) in the formula above.

   x bar = (643+655+702+469+427+525+484+456+402)/9 = 529.22

   ss(b)=[3*(666.67-529.22)^2]+
   [3*(473.67-529.22)^2]+[3*(447.33-529.22)^2] = 86049.55

   ss (w) = [(643-666.67)^2+(655-666.67)^2+(702-666.67)^2] +
   [(469-473.67)^2+(427-473.67)^2+(525-473.67)^2] +
   [(484-447.33)^2+(456-447.33)^2+(402-447.33)^2]= 10254

   ms(b) = ss(b) / df(b) = 86049.55 / (3-1) = 43024.78

   ms(w) = ss(w) / df(w) = 10254/(9-3) = 1709

   f-ratio = ms(b) / ms(w) = 25.17 .

   now, for a 95 % confidence level, f-critical to reject null hypothesis
   for degrees of freedom(2,6) is 5.14 but we have 25.17 as our f-ratio.

   so, we can confidently reject the null hypothesis and come to a
   conclusion that at least one of the chocolate has a mean sweetness
   different from the others.

   you can use the f-calculator [99]here.

   note: anova only lets us know the means for different groups are same
   or not. it doesn   t help us identify which mean is different.to know
   which group mean is different, we can use another test know as least
   significant difference test.


9. chi-square goodness of fit test

   sometimes, the variable under study is not a continuous variable but a
   categorical variable. chi-square test is used when we have one single
   categorical variable from the population.

   let us understand this with help of an example. suppose a company that
   manufactures chocolates, states that they manufacture 30% dairy milk,
   60% temptation and 10% kit-kat. now suppose a random sample of 100
   chocolates has 50 dairy milk, 45 temptation and 5 kitkats. does this
   support the claim made by the company?

   let us state our hypothesis first.

   null hypothesis: the claims are true

   alternate hypothesis: the claims are false.

   chi-square test is given by:

   [chi-square-formula.jpg]

   where, = sample or observed values

     = population values

   the summation is taken over all the levels of a categorical variable.

     = [n * ]  expected value of a level (i) is equal to the product of
   sample size and percentage of it in the population.

   let us now calculate the expected values of all the levels.

   e (dairy milk)= 100 * 30% = 30

   e (temptation) = 100 * 60% =60

   e (kitkat) = 100 * 10% = 10

   calculating chi-square = [(50-30)^2/30+(45-60)^2/60+(5-10)^2/10] =19.58


   now, checking for p (chi-square >19.58) using [100]chi-square
   calculator, we get p=0.0001. this is significantly lower than the
   alpha(0.05).

   so we reject the null hypothesis.


10. regression and anova

   if you have studied some basic machine learning algorithms, the first
   algorithm that you must have studied is regression. if we  recall those
   lessons of regression, what we generally do is calculate the weights
   for features present in the model to better predict the output
   variable. but finding the right set of feature weights or features for
   that matter is not always possible.

   it is highly likely that that the existing features in the model are
   not fit for explaining the trend in dependent variable or the feature
   weights calculated fail at explaining the trend in dependent variable.
   what is important is knowing the degree to which our model is
   successful in explaining the trend (variance) in dependent variable.

   enter anova.

   with the help of anova techniques, we can analyse a model performance
   very much like we analyse samples for being statistically different or
   not.

   but with regression things are not easy. we do not have mean of any
   kind to compare  or sample as such but we can find good alternatives in
   our regression model which can substitute for mean and sample.

   sample in case of regression is a regression model itself with
   pre-defined features and feature weights whereas mean is replaced by
   variance(of both dependent and independent variables).

   through our anova test we would like to know the amount of variance
   explained by the independent variables in dependent variable vs the
   amount of variance that was left unexplained.

   it is intuitive to see that larger the unexplained variance(trend) of
   the dependent variable smaller will be the ratio and less effective is
   our regression model. on the other hand, if we have a large explained
   variance then it is easy to see that our regression model was
   successful in explaining the variance in the dependent variable and
   more effective is our model. the ratio of explained variance uand
   unexplained variance is called f-ratio.

   let us now define these explained and unexplained variances to find the
   effectiveness of our model.

   1. regression (explained) sum of squares     it is defined as the amount
   of variation explained by the regression model in the dependent
   variable.

   mathematically, it is calculated as:

   {\text{ess}}=\sum _{{i=1}}^{n}\left({\hat {y}}_{i}-{\bar
   {y}}\right)^{2}.

   where,  [hat] = predicted value and

   y(bar) = mean of the actual y values.

   interpreting regression sum of squares    

   if our model is a good model for the problem at hand then it would
   produce an output which has distribution as same to the actual
   dependent variable. i.e it would be able to capture the inherent
   variation in the dependent variable.

   2. residual sum of squares     it is defined as the amount of variation
   independent variable which is not explained by the regression model.

   mathematically, it is calculated as:

   {\displaystyle rss=\sum _{i=1}^{n}(y_{i}-f(x_{i}))^{2}}

   where,  = actual    y     value

   f(x) = predicted value

   interpretation of residual sum of squares    

   it can be interpreted as the amount by which the predicted values
   deviated from the actual values. large deviation would indicate that
   the model failed at predicting the correct values for the dependent
   variable.

   let us now  work out f-ratio step by step. we will be making using of
   the hypothesis testing framework described above to test the
   significance of the model.

   while calculating the f-ratio care has to be taken to incorporate the
   effect of degree of freedom. mathematically, f-ratio is the ratio of
   [regression sum of squares/df(regression)] and [residual sum of
   squares/df(residual)].

   we will be understanding the entire concept using an example and
   [101]this excel sheet.

step 0: state the null and alternate hypothesis

   null hypothesis: the model is unable to explain the variance in the
   dependent variable (y).

   alternate hypothesis: the model is able to explain the variance in
   dependent variable (y)


step 1:

   calculate the regression equation for x and y using excel   s in-built
   tool.


step 2:

   predict the values of y for each row of data.


step 3:

   calculate y(mean)     mean of the actual y values which in this case
   turns out to be 0.4293548387.


step 4:

   calculate the regression sum of squares using the above-mentioned
   formula. it turned out to be 2.1103632473

   the degree of freedom for regression equation is 1, since we have only
   1 independent variable.


step 5:

   calculate the residual sum of squares using the above-mentioned
   formula. it turned out to be 0.672210946.

   degree of freedom for residual = total degree of freedom     degree of
   freedom(regression)

   =(62-1)     1 = 60


step 6:

   f-ratio = (2.1103632473/1)/(0.672210946/60) = 188.366

   now, for 95% confidence, f-critical to reject null hypothesis for 1,60
   degrees of freedom in 4. but we have f-ratio as 188, so we can safely
   reject the null hypothesis and conclude that model explains variation
   to a large extent.


11. coefficient of determination (r-square)

   it is defined as the ratio of the amount of variance explained by the
   regression model to the total variation in the data. it represents the
   strength of correlation between two variables.

   we already calculated the regression ss and residual ss. total ss is
   the sum of regression ss and residual ss.

   total ss = 2.1103632473+ 0.672210946 = 2.78257419

   co-efficient of determination = 2.1103632473/2.78257419 = 0.7588


12. correlation coefficient

   this is another useful statistic which is used to determine the
   correlation between two variables. it is simply the square root of
   coefficient of determination and ranges from -1 to 1 where 0 represents
   no correlation and 1 represents positive strong correlation while -1
   represents negative strong correlation.


end notes

   so, this guide comes to an end with explaining all the theory along
   with practical implementations of various inferential statistics
   concepts. this guide has been created with a hypothesis testing
   framework and i hope this would be one stop solution for a quick
   inferential statistics guide.

   if you have any doubts or questions, feel free to drop your comments
   below. and in case if i have missed out any of the concepts, add them
   below. the rest of the readers and i would definitely like to know.

[102]learn, [103]compete, hack and [104]get hired

   you can also read this article on analytics vidhya's android app
   [105]get it on google play

share this:

     * [106]click to share on linkedin (opens in new window)
     * [107]click to share on facebook (opens in new window)
     * [108]click to share on twitter (opens in new window)
     * [109]click to share on pocket (opens in new window)
     * [110]click to share on reddit (opens in new window)
     *

like this:

   like loading...

related articles

   [ins: :ins]

   tags : [111]advanced statistics, [112]anova, [113]anova analysis,
   [114]applied statistics, [115]basic statistics, [116]central limit
   theorem, [117]chi-square, [118]classical regression, [119]confidence
   interval, [120]correlation, [121]inferential statistics,
   [122]linear-regression, [123]normal distribution, [124]r-squared,
   [125]sample distributio, [126]t-tests
   next article

basics of id203 for data science explained with examples

   previous article

45 questions to test a data scientist on basics of deep learning (along with
solution)

[127]nss

   i am a perpetual, quick learner and keen to explore the realm of data
   analytics and science. i am deeply excited about the times we live in
   and the rate at which data is being generated and being transformed as
   an asset. i am well versed with a few tools for dealing with data and
   also in the process of learning some other tools and knowledge required
   to exploit data.
     *

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [128]discussion portal to get your queries resolved

19 comments

     * [129]michael thompson says:
       [130]january 31, 2017 at 4:56 am
       in terms of the comparison between the sampling distribution and
       underlying population distribution, it would probably be helpful to
       those who need this level of training, that population distribution
       with two modes (peaks) will either come about when there are two
       (possibly more) sources of what you are measuring, with different
       means (and different volumes produced) or a shift in the mean over
       time. while the sample is almost certainly taken over a shorter
       time, and as such probably will not exhibit a bi-modal
       distribution, except when it is caused by two sources.
       [131]reply
     * sundar ramamurthy says:
       [132]january 31, 2017 at 6:38 am
       this is what they teach in iit madras , great lakes. as corporate
       training. kudos nss
       [133]reply
          + nss says:
            [134]february 1, 2017 at 12:15 pm
            @sundar thank you for the appreciation. i am glad that i was
            of help.
            [135]reply
     * nss says:
       [136]january 31, 2017 at 8:34 am
       @michael   . i agree with most of all you said and thank you for
       contributing but i am not confirm about the part where you
       mentioned that sources need to be different. as a classic natural
       example, the size of worker weaver ants exhibits bi-modal
       distribution with a single source if i am correct.
       correct me if i am wrong.
       [137]reply
     * sashikant dwivedi says:
       [138]january 31, 2017 at 9:01 am
       hi nss,
       at many places you have used p instead of alpha(0.05) which is the
       significance level.
       for eg:
       now, checking for p (chi-square >19.58) using chi-square
       calculator, we get p=0.0001. this is significantly lower than the p
       = 0.05
       am i right or am i missing something here.
       thanks
       sashikant
       [139]reply
          + nss says:
            [140]february 1, 2017 at 12:14 pm
            no, you are not missing anything. by p=0.05, i meant
            alpha(p<=0.05). thanks for bringing this up. i will make the
            necessary corrections.
            [141]reply
     * [142]hunaidkhan pathan says:
       [143]january 31, 2017 at 3:09 pm
       superb article nss, very helpful .
       [144]reply
          + nss says:
            [145]february 1, 2017 at 12:11 pm
            @hunaidkhan thank you. i am glad that i was of help.
            [146]reply
     * keith potter says:
       [147]january 31, 2017 at 6:15 pm
       non-parametric testing is a significant omission when discussing
       statistics. you have a very good parametric discussion, but the
       problem with parametric statistics is that they require stringent
       assumptions that may not be accurate for the data. this is where
       non-parametric statistics excels. well done overall.
       [148]reply
          + nss says:
            [149]february 1, 2017 at 12:10 pm
            @keith potter looks like you gave my next topic to right on:
            non-parametric statistics.
            and i agree with you on the limitations of parametric
            statistics.
            [150]reply
     * josh says:
       [151]january 31, 2017 at 7:49 pm
       is this available as a pdf
       [152]reply
     * [153]swethapriya says:
       [154]february 1, 2017 at 11:19 am
       the way you have stated everything above is quite awesome. keep
       blogging like this. thanks a lot.it was helpful to us to learn more
       and useful to teach others.this like valuable information is very
       interesting to read,thanks for sharing this impressive
       [155]reply
          + nss says:
            [156]february 1, 2017 at 12:08 pm
            i am glad it was of help swethapriya.
            [157]reply
     * poonam lata says:
       [158]february 10, 2017 at 5:45 am
       thank you so much for this blog. this was indeed helpful!
       [159]reply
     * sri says:
       [160]february 10, 2017 at 11:31 pm
       thanks a lot. this is very helpful.
       [161]reply
     * anirudh shah says:
       [162]february 12, 2017 at 6:25 pm
       thanks..this sure is a one stop shop for inferential statistics
       [163]reply
     * anksg says:
       [164]april 16, 2017 at 4:44 am
       great article.
       [165]reply
     * piush says:
       [166]may 24, 2017 at 3:56 pm
       thanks for the article.
       [167]reply
     * [168]shivam bansal says:
       [169]december 4, 2017 at 1:36 pm
       hey nss, thanks for sharing this excellent article.
       [170]reply

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-06] [171]srk       3924
   2    [2.jpg?date=2019-04-06] [172]mark12    3510
   3    [3.jpg?date=2019-04-06] [173]nilabha   3261
   4    [4.jpg?date=2019-04-06] [174]nitish007 3237
   5    [5.jpg?date=2019-04-06] [175]tezdhar   3082
   [176]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [177]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [178]understanding support vector machine algorithm from examples
       (along with code)
     * [179]essentials of machine learning algorithms (with python and r
       codes)
     * [180]a complete tutorial to learn data science with python from
       scratch
     * [181]7 types of regression techniques you should know!
     * [182]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [183]a simple introduction to anova (with applications in excel)
     * [184]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [185]top 5 machine learning github repositories and reddit discussions
   from march 2019

[186]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [187]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[188]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [189]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[190]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [191]16 opencv functions to start your id161 journey (with
   python code)

[192]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [193][ds-finhack.jpg]

   [194][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [195]about us
     * [196]our team
     * [197]career
     * [198]contact us
     * [199]write for us

   [200]about us
   [201]   
   [202]our team
   [203]   
   [204]careers
   [205]   
   [206]contact us

data scientists

     * [207]blog
     * [208]hackathon
     * [209]discussions
     * [210]apply jobs
     * [211]leaderboard

companies

     * [212]post jobs
     * [213]trainings
     * [214]hiring hackathons
     * [215]advertising
     * [216]reach us

   don't have an account? [217]sign up here.

join our community :

   [218]46336 [219]followers
   [220]20224 [221]followers
   [222]followers
   [223]7513 [224]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [225]privacy policy
     * [226]terms of use
     * [227]refund policy

   don't have an account? [228]sign up here

   iframe: [229]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [230](button) join now

   subscribe!

   iframe: [231]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [232](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/business-analytics/
  94. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/
  95. https://www.analyticsvidhya.com/blog/category/business-analytics/
  96. https://www.analyticsvidhya.com/blog/author/nss/
  97. https://drive.google.com/open?id=0byavlbzuj2tgq0m0u2lvznzuams
  98. http://www.danielsoper.com/statcalc/calculator.aspx?id=98
  99. http://stattrek.com/online-calculator/f-distribution.aspx
 100. http://stattrek.com/online-calculator/chi-square.aspx
 101. https://drive.google.com/file/d/0byavlbzuj2tgv0rdm0forkq3yw8/view
 102. https://www.analyticsvidhya.com/blog
 103. https://datahack.analyticsvidhya.com/
 104. https://www.analyticsvidhya.com/jobs/#/user/
 105. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 106. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/?share=linkedin
 107. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/?share=facebook
 108. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/?share=twitter
 109. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/?share=pocket
 110. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/?share=reddit
 111. https://www.analyticsvidhya.com/blog/tag/advanced-statistics/
 112. https://www.analyticsvidhya.com/blog/tag/anova/
 113. https://www.analyticsvidhya.com/blog/tag/anova-analysis/
 114. https://www.analyticsvidhya.com/blog/tag/applied-statistics/
 115. https://www.analyticsvidhya.com/blog/tag/basic-statistics/
 116. https://www.analyticsvidhya.com/blog/tag/central-limit-theorem/
 117. https://www.analyticsvidhya.com/blog/tag/chi-square/
 118. https://www.analyticsvidhya.com/blog/tag/classical-regression/
 119. https://www.analyticsvidhya.com/blog/tag/confidence-interval/
 120. https://www.analyticsvidhya.com/blog/tag/correlation/
 121. https://www.analyticsvidhya.com/blog/tag/inferential-statistics/
 122. https://www.analyticsvidhya.com/blog/tag/linear-regression/
 123. https://www.analyticsvidhya.com/blog/tag/normal-distribution/
 124. https://www.analyticsvidhya.com/blog/tag/r-squared/
 125. https://www.analyticsvidhya.com/blog/tag/sample-distributio/
 126. https://www.analyticsvidhya.com/blog/tag/t-tests/
 127. https://www.analyticsvidhya.com/blog/author/nss/
 128. https://discuss.analyticsvidhya.com/
 129. http://www.manukau.ac.nz/about-us/our-faculties/business-and-information-technology/more-information-for-students/lecturer-profiles/michael-thompson
 130. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121881
 131. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121881
 132. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121886
 133. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121886
 134. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121960
 135. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121960
 136. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121893
 137. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121893
 138. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121895
 139. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121895
 140. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121959
 141. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121959
 142. http://none/
 143. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121917
 144. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121917
 145. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121958
 146. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121958
 147. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121927
 148. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121927
 149. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121957
 150. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121957
 151. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121931
 152. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121931
 153. http://www.dentistree.in/
 154. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121954
 155. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121954
 156. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121956
 157. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-121956
 158. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-122453
 159. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-122453
 160. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-122490
 161. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-122490
 162. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-122571
 163. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-122571
 164. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-126958
 165. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-126958
 166. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-129130
 167. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-129130
 168. http://shivambansal.com/
 169. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-146204
 170. https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/#comment-146204
 171. https://datahack.analyticsvidhya.com/user/profile/srk
 172. https://datahack.analyticsvidhya.com/user/profile/mark12
 173. https://datahack.analyticsvidhya.com/user/profile/nilabha
 174. https://datahack.analyticsvidhya.com/user/profile/nitish007
 175. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 176. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 177. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 178. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 179. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 180. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 181. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 182. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 183. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 184. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 185. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 186. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 187. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 188. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 189. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 190. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 191. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 192. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 193. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 194. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 195. http://www.analyticsvidhya.com/about-me/
 196. https://www.analyticsvidhya.com/about-me/team/
 197. https://www.analyticsvidhya.com/career-analytics-vidhya/
 198. https://www.analyticsvidhya.com/contact/
 199. https://www.analyticsvidhya.com/about-me/write/
 200. http://www.analyticsvidhya.com/about-me/
 201. https://www.analyticsvidhya.com/about-me/team/
 202. https://www.analyticsvidhya.com/about-me/team/
 203. https://www.analyticsvidhya.com/about-me/team/
 204. https://www.analyticsvidhya.com/career-analytics-vidhya/
 205. https://www.analyticsvidhya.com/about-me/team/
 206. https://www.analyticsvidhya.com/contact/
 207. https://www.analyticsvidhya.com/blog
 208. https://datahack.analyticsvidhya.com/
 209. https://discuss.analyticsvidhya.com/
 210. https://www.analyticsvidhya.com/jobs/
 211. https://datahack.analyticsvidhya.com/users/
 212. https://www.analyticsvidhya.com/corporate/
 213. https://trainings.analyticsvidhya.com/
 214. https://datahack.analyticsvidhya.com/
 215. https://www.analyticsvidhya.com/contact/
 216. https://www.analyticsvidhya.com/contact/
 217. https://datahack.analyticsvidhya.com/signup/
 218. https://www.facebook.com/analyticsvidhya/
 219. https://www.facebook.com/analyticsvidhya/
 220. https://twitter.com/analyticsvidhya
 221. https://twitter.com/analyticsvidhya
 222. https://plus.google.com/+analyticsvidhya
 223. https://in.linkedin.com/company/analytics-vidhya
 224. https://in.linkedin.com/company/analytics-vidhya
 225. https://www.analyticsvidhya.com/privacy-policy/
 226. https://www.analyticsvidhya.com/terms/
 227. https://www.analyticsvidhya.com/refund-policy/
 228. https://id.analyticsvidhya.com/accounts/signup/
 229. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 230. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 231. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 232. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 234. https://www.facebook.com/analyticsvidhya
 235. https://twitter.com/analyticsvidhya
 236. https://plus.google.com/+analyticsvidhya/posts
 237. https://in.linkedin.com/company/analytics-vidhya
 238. https://www.analyticsvidhya.com/blog/2017/02/basic-id203-data-science-with-examples/
 239. https://www.analyticsvidhya.com/blog/2017/01/must-know-questions-deep-learning/
 240. https://www.analyticsvidhya.com/blog/author/nss/
 241. https://in.linkedin.com/in/neeraj-singh-sarwan-a84b6965
 242. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 243. https://www.facebook.com/analyticsvidhya/
 244. https://twitter.com/analyticsvidhya
 245. https://plus.google.com/+analyticsvidhya
 246. https://plus.google.com/+analyticsvidhya
 247. https://in.linkedin.com/company/analytics-vidhya
 248. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 249. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 250. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 251. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 252. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 253. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 254. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 255. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 256. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 257. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 258. javascript:void(0);
 259. javascript:void(0);
 260. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 261. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 262. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 263. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 264. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 265. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 266. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 267. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 268. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 269. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f01%2fcomprehensive-practical-guide-inferential-statistics-data-science%2f&linkname=comprehensive%20%26amp%3b%20practical%20inferential%20statistics%20guide%20for%20data%20science
 270. javascript:void(0);
 271. javascript:void(0);
