community

   news
   beta
   tutorials
   cheat sheets
   open courses
   podcast - dataframed
   chat
   new

datacamp

   official blog
   tech thoughts
   (button)
   search
   [1](button)
   log in
   (button)
   create account
   (button)
   share an article
   (button)
   back to tutorials
   tutorials
   [2]0
   37
   37
   lars hulstaert
   january 19th, 2018
   must read
   machine learning

id21: leverage insights from big data

   in this tutorial, you   ll see what id21 is, what some of
   its applications are and why it is critical skill as a data scientist.

   this blog post will introduce the concept of 'id21' and
   how it is used in machine learning applications. id21 is
   not a machine learning model or technique; it is rather a 'design
   methodology' within machine learning. another type of 'design
   methodology' is, for example, active learning.

   [transfer-learning_2x_hjrupn.png]

   a next blog post will explain how you can use active learning in
   conjunction with id21 to optimally leverage existing (and
   new) data. in a broad sense, machine learning applications that
   leverage external information to improve the performance or
   generalisation capabilities use id21.

id21: a definition

   the general idea of id21 is to use knowledge learned from
   tasks for which a lot of labelled data is available in settings where
   only little labelled data is available. creating labelled data is
   expensive, so optimally leveraging existing datasets is key.

   in a traditional machine learning model, the primary goal is to
   generalise to unseen data based on patterns learned from the training
   data. with id21, you attempt to kickstart this
   generalisation process by starting from patterns that have been learned
   for a different task. essentially, instead of starting the learning
   process from a (often randomly initialised) blank sheet, you start from
   patterns that have been learned to solve a different task.

   transfer of knowledge and patterns is possible in a wide variety of
   domains. today's post will illustrate id21 by looking at
   several examples of these different domains. the goal is to incentivise
   data scientists to experiment with id21 in their machine
   learning projects and to make them aware of the advantages and
   disadvantages.

   there are three reasons why i believe a good understanding of transfer
   learning is a critical skill as a data scientist:
     * id21 is essential in any kind of learning. humans are
       not taught every single task or problem in order to be successful
       at it. everyone gets into situations that have never been
       encountered, and we still manage to solve problems in an ad-hoc
       manner. the ability of learning from a large number of experiences,
       and exporting 'knowledge' into new environments is exactly what
       id21 is all about. from this perspective, transfer
       learning and generalisation are highly similar on a conceptual
       level. the main distinction is that id21 is often used
       for 'transferring knowledge across tasks, instead of generalising
       within a specific task'. id21 is thus intrinsically
       connected to the idea of generalisation that is necessary in all
       machine learning models.
     * id21 is key to ensure the breakthrough of deep
       learning techniques in a large number of small-data settings. deep
       learning is pretty much everywhere in research, but a lot of
       real-life scenarios typically do not have millions of labelled data
       points to train a model. deep learning techniques require massive
       amounts of data in order to tune the millions of parameters in a
       neural network. especially in the case of supervised learning, this
       means that you need a lot of (highly expensive) labelled data.
       labelling images sounds trivial, but for example in natural
       language processing (nlp), expert knowledge is required to create a
       large labelled dataset. the id32 for example, a
       part-of-speech tagging corpus, was 7 years in the making and
       required close cooperation of trained linguists. id21
       is one way of reducing the required size of datasets in order for
       neural networks to be a viable option. other viable options are
       moving towards more probabilistically inspired models, which
       typically are better suited to deal with limited data sets.
     * id21 has significant advantages as well as drawbacks.
       understanding these drawbacks is vital for successful machine
       learning applications. transfer of knowledge is only possible when
       it is 'appropriate'. exactly defining what appropriate means in
       this context is not easy, and experimentation is typically
       required. you should not trust a toddler that drives around in a
       toy car to be able to ride a ferrari. the same principle holds for
       id21: although hard to quantify, there is an upper
       limit to id21. it is not a solution that fits all
       problem cases.

   [capture2_d8mxzm.png] [capture_wcejeo.png]

     caption: being able to distinguish lines and shapes (left) from an
   image makes it easier to determine if something is a 'car' than having
     to start from the raw pixel values. id21 allows you to
   leverage learned patterns from other id161 models. different
      approaches exist to represent words in nlp (a id27 like
   representation on the left and a bow like representation on the right).
      with id21 a machine learning model can leverage the
              relationships that exist between different words.

general concepts in id21

the requirements of id21

   id21, as the name states, requires the ability to transfer
   knowledge from one domain to another. id21 can be
   interpreted on a high level, that is, nlp model architectures can be
   re-used in sequence prediction problems, since a lot of nlp problems
   can inherently be reduced to sequence prediction problems. transfer
   learning can also be interpreted on a low level, where you are actually
   reusing parameters from one model in a different model (skip-gram,
   continuous bag-of-words, etc.). the requirements of id21
   are on one hand problem specific and on the other one model specific.
   the next two sections will discuss respectively a high level and low
   level approach to id21. although you will typically find
   these concepts with different names in literature, the overarching
   concept of id21 is still present.

id72

   in id72, you train a model on different tasks at the
   same time. typically, deep learning models are used as they can be
   adapted flexibly.

   [transfer_learning2_rue3zk.png]

   the network architecture is adapted in such a way that the first layers
   are used across different tasks, followed with different task-specific
   layers and outputs for the different tasks. the general idea is that by
   training a network on different tasks, the network will generalise
   better, as the model is required to perform well on tasks for which
   similar 'knowledge' or 'processing' is required.

   an example in the case of natural language processing is a model for
   which the end goal is to perform entity recognition. instead of
   training the model purely on the entity recognition task, you also use
   it to perform part of speech classification, next word prediction, ...
   as such, the model wil benefit from the structure learned from those
   tasks and the different datasets. i highly recommend [3]this blog by
   sebastian rude and [4]this blog, which both tackle id72
   to learn more about id72.

featuriser

   one of the great advantages of a deep learning model is that feature
   extraction is 'automatic'. based on the labelled data and
   id26, the network is able to determine the useful features
   for a task. the network 'figures out' what part of the input is
   important in order to, for example, classify an image. this means that
   the manual job of feature definition is abstracted away. deep learning
   networks can be reused in other problems, as the type of features that
   are extracted, are often useful for other problems as well. essentialy,
   in a featuriser you use the first layers of the network to determine
   the useful feature, but you dont use the output of the network, as it
   is too task-specific.

   id21 featurizer

   given that deep learning systems are good at feature extraction, how
   can you reuse existing networks to perform feature extraction for other
   tasks? it is possible to feed a data sample into the network, and take
   one of the intermediate layers in the network as output. this
   intermediate layer can be interpreted as a fixed length, processed
   representation of raw data. typically, the concept of a featuriser is
   used in the context of id161. images are then fed into a
   pre-trained network (for example, vgg or alexnet) and a different
   machine learning method is used on the new data representation.
   extracting an intermediate layer as a representation of the image
   significantly reduces the original data size, making them more amenable
   for traditional machine learning techniques (for example, logistic
   regression or id166s work better with a small representation of an image,
   such as dimension 128, compared to the original, for example,
   128x128=16384 dimension).

applications of id21

nlp

   [5]one of my previous blog posts discussed how a lot of nlp pipelines
   nowadays use id27s. these id27s are a more
   informative way of representing words, compared to one-hot encodings.
   they are widely used, and different variants exist. typically these
   variants differ in the corpus they originate from, such as wikipedia,
   news articles, etc., and the differences in the embedding models. it is
   important to understand the background of these models and corpuses in
   order to know whether id21 with id27s is
   sensible. people typically wouldn't call the use of id27s
   id21, yet i disagree, given the similarity with transfer
   learning with id161. essentially, using id27s means
   that you are using a featuriser or the embedding network to convert
   words to vectors.

   even though id97 is already 4 years old, it is still a very
   influential id27 approach. recent approaches on the other
   hand such as [6]fasttext have made id27s available in a large
   number of languages. embeddings from id97 or fasttext are a
   significant step forwards compared to bag-of-words approaches.
   nevertheless, their usefulness is typically determined by the problem
   domain.

   imagine you are building a news recommendation service for sales
   people. the sales people want to receive news on companies that could
   be interested in the product they are selling. the vocabulary that is
   used in news articles is typically fairly generic or general, meaning
   that a vocabulary is used that is often supported by most word
   embeddings (depending on the corpus they are trained on). in addition,
   if you have the sales people collect the news articles they read for a
   couple of weeks, then you immediately have a large labelled corpus at
   your hands. by being able to reuse id27s it is possible that
   the recommendation engine will perform significantly better.

   on the other hand, imagine that you have to perform topic
   classification on legal contracts. not just any type of legal
   contracts, but french legal contracts in the context of competition
   law. these type of datasets are typically not labelled, or only a
   limited set of labeled documents are available. the next section will
   describe why out-of-the-box id21 will only get you so far
   in this case:
     * out-of-vocabulary (oov) words are words that have not been seen
       during the training. while id97 and fasttext are trained on,
       for example, wikipedia or other corpuses, the vocabulary that is
       used is finite. during training, words that didn't occur frequently
       have often been left out. that means that it is possible that
       domain-specific words from legal contracts in competition law are
       therefore not supported. when using pre-trained id27s,
       you typically check for oov words and replace them with the unk
       token (unknown word token) and all these words are assigned the
       same vector. this is highly ineffective if the corpus is domain
       specific, given that the domain specific words typically carry a
       lot of meaning. if most of the (meaning-carrying) words are
       replaced by unk tokens, than the model will not be able to learn a
       lot.
     * an alternative to the standard pre-trained id27s is to
       fine-tune the embeddings on a large unsupervised set of documents.
       note that this is only an option if a large set of documents is
       available. this means that if you have a large corpus on
       competition law, you could train the id27s for the
       domain-specific words, by starting from pre-trained id27s
       for the other, more general words. typically, starting for
       pre-trained id27s will speed up the whole process, and
       will make training your own id27s easier. note that it is
       still harder using id27s out-of-the-box and requires some
       knowledge on how to prepare the corpus for id27 training.

   i highly advise you to read this excellent blog post on [7]the current
   state of id27s. taking into account the problems and
   solutions mentioned in this blog post is key to creating robust nlp
   systems and id27s when working with limited amounts of data.

   gensim, spacy and fasttext are three great frameworks that allow you to
   quickly use id27s in your machine learning application. in
   addition, they also support the training of custom id27s.
   check out this [8]gensim, this [9]spacy or this [10]fasttext tutorial
   to get to know more!

id21 in id161

   deep learning methods have led to significant successes in computer
   vision. instead of having to define problem specific features manually,
   for example, histogram of oriented gradients (hog) features, histogram
   features, etc., deep learning allows practitioners to train models that
   take raw images as input. the original complexity of feature definition
   has now shifted towards the complexity of defining the network. while
   architectures are often reused, there is no single strategy in
   composing network architectures. typically, deep learning techniques
   have been invented and applied in research settings on enormous
   datasets (such as [11]id163 or [12]ms coco). to increase performance
   on these large datasets, researchers have come up with network
   architectures with increasing depth and complexity. these architectures
   result in models with millions of parameters that are (typically) not
   scalable to small image datasets. training an architecture such as
   residential network (resnet) or vgg net on a dataset with less than
   5,000 images will simply lead to significant overfitting. the recent
   deep learning trend has lead to significant advancements, yet it seems
   data scientists with only small datasets have been left in the cold.

   as it turns out, deep learning networks learn hierarchical feature
   representations (see [13]this blog post by distill). this means that
   the lower level layers learn low level features, such as edges, whereas
   the higher level layers learn higher level, yet uninterpretable
   concepts, such as shapes. this idea of hierarchical feature
   representations also occurs when the network is trained on different
   datasets, indicating that they can be reused in different problem
   domains.

   two approaches are used when using id21 on id161
   problems.
     * first, if a fair amount of pictures (>1,000 images per class) is
       available, you can initialise a new model with the weights of a
       model trained on a different dataset. during training, you will
       then keep a number of layers fixed (typically the first
       convolutional layers) and you optimise the parameters of the higher
       level layers. the goal is to reduce the number of parameters that
       need to be optimised, while reusing the lower level layers. the
       lower level layers are most likely to be similar regardless of the
       problem domain, and the model has to freedom of combining higher
       level layers together, specific to the problem.
     * second, if only a really small number of pictures is available
       (<1,000), retraining an existing model will most likely still lead
       to overfitting in most cases. the number of parameters that needs
       to be optimised would simply be too large with respect to to the
       number of images. regardless, as long as the data is visually
       similar to the images in a large dataset, than a large pre-trained
       network (trained on that large dataset) can be used as a
       featuriser. more specifically, you remove the last n layers of a
       large network (typically n=1 or n=2), and use the output of the
       large pre-trained network as feature representation of the images.
       this is again based on the assumption that the first layers in the
       pre-trained network learn problem independent features. these
       features can then be used with, for example, an id166 or logistic
       regression, similar to the traditional id161 approach.
       instead of having to manually define the features however, the
       pre-trained network is used as featuriser.

   the [14]api of keras allows you to load pre-trained networks and keep
   several of the layers fixed during training. in the next section i will
   again discuss two use cases, respectively one where id21
   is useful, and another where it isn't.

   imagine working in wildlife preservation, and you want to classify the
   different animals that appear on a live camera feed. especially if you
   are trying the monitor species that are near extinction, it is possible
   that you won't be able to gather a lot of labelled data. given that the
   pre-trained networks are often trained on wide domain of concepts
   (ranging from food, to animals and objects), using a pre-trained
   network as a featuriser or as initialiser is definitely an option.

   on the other hand, imagine you need to analyse radiography images for
   oncologists. these images are not your typical cat-dog images, as they
   are the output of a scan which was performed on a patient. these
   images, although converted to rgb images, are typically in greyshades
   to illustrate the results of the scan. although a pre-trained network
   is able to detect shapes and edges from rgb images, they will most
   likely have difficulty detecting those on radiography images as those
   are not in the training data of the pre-trained model. in addition, in
   medical scenario's, the amount of labelled data is typically low.
   several techniques exist to leverage (the potentially abundant)
   unlabelled data, but they typically require more work and finetuning.
   typically, these techniques attempt to pre-train the weights of the
   classification network, by iteratively training each layer to
   reconstruct the images (using convolutional and deconvolutional
   layers). a combination of these techniques and pre-trained network is
   often used to improve convergence.

   both methods in id161 mentioned above rely on an important
   assumption: patterns extracted in the original dataset are useful in
   the context of the new dataset. this usefulness is hard to quantify,
   yet it is an important assumption to take into account. seismic,
   hyperspectral or even medical imagery shows limited similarity with the
   images in id163. determining which traffic sign an image contains
   however, relies on fairly similar patterns. understanding the computer
   vision problem domain is crucial to successfully applying computer
   vision. by knowing the background of models (datasets, techniques,
   etc.) that are used in id21, you can avoid wasting time
   during experimentation and focus on finetuning those models that might
   make the difference.
   37
   37
   [15]0
   (button)
   post a comment

   [16]subscribe to rss
   [17]about[18]terms[19]privacy

   want to leave a comment?

references

   visible links
   1. https://www.datacamp.com/users/sign_in
   2. https://www.datacamp.com/community/tutorials/transfer-learning#comments
   3. http://ruder.io/multi-task/
   4. http://ruder.io/multi-task-learning-nlp/index.html
   5. https://www.datacamp.com/community/tutorials/lda2vec-topic-model
   6. https://research.fb.com/fasttext/
   7. https://ruder.io/multi-task-learning-nlp/index.html
   8. https://radimrehurek.com/gensim/tut1.html
   9. https://spacy.io/usage/vectors-similarity#section-custom
  10. https://github.com/facebookresearch/fasttext#obtaining-word-vectors-for-out-of-vocabulary-words
  11. http://www.image-net.org/
  12. http://cocodataset.org/#home
  13. https://distill.pub/2017/feature-visualization/
  14. https://keras.io/visualization/
  15. https://www.datacamp.com/community/tutorials/transfer-learning#comments
  16. https://www.datacamp.com/community/rss.xml
  17. https://www.datacamp.com/about
  18. https://www.datacamp.com/terms-of-use
  19. https://www.datacamp.com/privacy-policy

   hidden links:
  21. https://www.datacamp.com/
  22. https://www.datacamp.com/community
  23. https://www.datacamp.com/community/tutorials
  24. https://www.datacamp.com/community/data-science-cheatsheets
  25. https://www.datacamp.com/community/open-courses
  26. https://www.datacamp.com/community/podcast
  27. https://www.datacamp.com/community/chat
  28. https://www.datacamp.com/community/blog
  29. https://www.datacamp.com/community/tech
  30. https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/transfer-learning
  31. https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/transfer-learning
  32. https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/transfer-learning
  33. https://www.datacamp.com/profile/larshulstaert
  34. https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/transfer-learning
  35. https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/transfer-learning
  36. https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/transfer-learning
  37. https://www.facebook.com/pages/datacamp/726282547396228
  38. https://twitter.com/datacamp
  39. https://www.linkedin.com/company/datamind-org
  40. https://www.youtube.com/channel/uc79gv3myp6zkiswyemeik9a
