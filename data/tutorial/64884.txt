   #[1]machine learning center at georgia tech    feed [2]machine learning
   center at georgia tech    comments feed [3]machine learning center at
   georgia tech    learning to represent words by how they   re spelled
   comments feed [4]the minds of the new machines | research horizons |
   georgia tech   s research news [5]from object interactions to
   fine-grained video understanding [6]alternate [7]alternate [8]machine
   learning center at georgia tech [9]wordpress.com

   [10]skip to content
   [11]ml@gt

[12]machine learning center at georgia tech

an interdisciplinary research center

   (button) menu
     * [13]home
     * [14]about
     * [15]leadership
     * [16]faculty
     * [17]contact

learning to represent words by how they   re spelled

   [18]march 18, 2018march 18, 2018

   a fundamental question in natural language processing (nlp) is how to
   represent words. if we have a paragraph we want to [19]translate, or a
   product review we want to [20]determine whether is positive or
   negative, or a question we want to [21]answer, ultimately the easiest
   building block to start from is the individual word. the main problem
   of this approach is that treating each word as just a symbol loses a
   lot of information. how can we tell from such a representation that the
   relationship between the symbol page and the symbol paper is not the
   same as that between page and moon?

   some popular [22]techniques exist that try to learn an abstract
   representation which identifies these relationships and preserves them.
   in essence, what these methods do is go over a huge body of text (a
   corpus), like the entire english wikipedia, word by word, and come up
   with a representation assigned to each word. using mathematical
   operations over these resulting representations, our model can then
   know that page is very    similar    to paper, dog is similar to cat, to
   kennel and to the verb bark, and so on. these methods are strong enough
   to also represent analogies: the    difference    between man and woman is
   very similar to that between king and queen.

   pinter_mimick_blogpost

   these representations go a long way in helping our end-goal, be it
   machine translation or review classification or anything else (we call
   these the downstream tasks). they can be used as input for a new system
   that is trained to perform them. but now a new problem arises, id30
   from the fact that language is both (a) big, and (b) [23]constantly
   growing. a paragraph in our downstream task is more likely than not to
   contain a word we never saw in the wikipedia text, or was too rare to
   save a representation for. this out-of-vocabulary, or oov, could be a
   new word (blockchain), a typo, a highly-technical term, in some
   languages even regular inflections (in bulgarian, for example, some
   verbs have more than 600 theoretical forms. in hebrew and arabic,
   prepositions like    in    and    for    are attached to the following word).

   how do we deal with this unseen word problem? one common approach is to
   learn a single representation for all unknown words (this can be done
   while training the original representations: once in a while, we    tell   
   a wikipedia word that now it   s an unknown, and train that
   representation instead of the actual word   s), but this is rather
   drastic. in a [24]paper published last year at emnlp [1], we developed
   a method that suggests a representation for an unseen word by
   generalizing only on the known representations (the output of the
   wikipedia traversal, but before the downstream task). the only signal
   we have available at this point is the way words are spelled, so that
   is exactly what we use as our input. basically we    pretend    that the
   representations were trained based on the spelling (rather than on the
   wikipedia corpus) and train an appropriate model. when we see an
   unknown word in our downstream task, we know how it is spelled, and
   thus can apply the model to guess a representation for that as well.
   ideally, we   ve captured enough information at the training phase to
   make a guess that   s more helpful than a single guess for all words.

   in our paper we show this is indeed the case. in addition to some
   sensible nearest-neighbor results (see figure), we present results on
   the downstream task of part-of-speech tagging, showing improvements on
   nearly all of 23 languages tested. the method proved particularly
   successful in languages that feature many inflections, reinforcing the
   conclusion that important characteristics are present in the way words
   are spelled in these languages.
   pinter_mimick_fig01

   some nearest-neighbor examples from our trained model.    oov    means
      out-of-vocabulary   , or unseen word.

   [written by yuval pinter]

   [1] yuval pinter, robert guthrie, jacob eisenstein. [25]mimicking word
   embeddings using subword id56s. in proceedings of the conference on
   empirical methods in natural language processing (emnlp), 2017.

share this:

     * [26]twitter
     * [27]facebook
     *

like this:

   like loading...

related

   posted in: [28]uncategorized

post navigation

   [29] the minds of the new machines | research horizons | georgia tech   s
   research news
   [30]from object interactions to fine-grained video understanding

2 thoughts on    learning to represent words by how they   re spelled   

    1.
   [31]                    says:
       [32]march 19, 2018 at 4:02 pm
       [33]reply
       reblogged this on [34]                       .
       [35]likelike
    2. pingback: [36]data science newsletter     march 22, 2018 |
       sports.bradstenger.com

leave a reply [37]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *
     *
     *

   [38]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [39]log out /
   [40]change )
   google photo

   you are commenting using your google account. ( [41]log out /
   [42]change )
   twitter picture

   you are commenting using your twitter account. ( [43]log out /
   [44]change )
   facebook photo

   you are commenting using your facebook account. ( [45]log out /
   [46]change )
   [47]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   post comment

   search for: ____________________ search

     * [48]twitter
     * [49]instagram

   [50]create a website or blog at wordpress.com


   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   post to
   [51]cancel reblog post

   iframe: [52]likes-master

   %d bloggers like this:

references

   visible links
   1. https://mlatgt.blog/feed/
   2. https://mlatgt.blog/comments/feed/
   3. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/feed/
   4. https://mlatgt.blog/2018/03/15/the-minds-of-the-new-machines-research-horizons-georgia-techs-research-news/
   5. https://mlatgt.blog/2018/04/02/from-object-interactions-to-fine-grained-video-understanding/
   6. https://public-api.wordpress.com/oembed/?format=json&url=https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/&for=wpcom-auto-discovery
   7. https://public-api.wordpress.com/oembed/?format=xml&url=https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/&for=wpcom-auto-discovery
   8. https://mlatgt.blog/osd.xml
   9. https://s1.wp.com/opensearch.xml
  10. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/#content
  11. https://mlatgt.blog/
  12. https://mlatgt.blog/
  13. https://mlatgt.blog/
  14. https://mlatgt.blog/about/
  15. https://mlatgt.blog/leadership/
  16. https://mlatgt.blog/faculty/
  17. https://mlatgt.blog/contact/
  18. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/
  19. https://en.wikipedia.org/wiki/machine_translation
  20. https://en.wikipedia.org/wiki/sentiment_analysis
  21. https://en.wikipedia.org/wiki/question_answering
  22. https://www.tensorflow.org/tutorials/id97
  23. https://twitter.com/nyt_first_said
  24. http://www.aclweb.org/anthology/d17-1010
  25. http://www.aclweb.org/anthology/d17-1010
  26. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/?share=twitter
  27. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/?share=facebook
  28. https://mlatgt.blog/category/uncategorized/
  29. https://mlatgt.blog/2018/03/15/the-minds-of-the-new-machines-research-horizons-georgia-techs-research-news/
  30. https://mlatgt.blog/2018/04/02/from-object-interactions-to-fine-grained-video-understanding/
  31. http://blazinghyphens.wordpress.com/
  32. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/#comment-243
  33. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/?replytocom=243#respond
  34. https://blazinghyphens.wordpress.com/2018/03/19/learning-to-represent-words-by-how-theyre-spelled/
  35. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/?like_comment=243&_wpnonce=70475aed1b
  36. https://sports.bradstenger.com/newsletters/data-science-newsletter/2018/03/22/data-science-newsletter-march-22-2018/
  37. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/#respond
  38. https://gravatar.com/site/signup/
  39. javascript:highlandercomments.doexternallogout( 'wordpress' );
  40. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/
  41. javascript:highlandercomments.doexternallogout( 'googleplus' );
  42. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/
  43. javascript:highlandercomments.doexternallogout( 'twitter' );
  44. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/
  45. javascript:highlandercomments.doexternallogout( 'facebook' );
  46. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/
  47. javascript:highlandercomments.cancelexternalwindow();
  48. http://www.twitter.com/mlatgt
  49. http://www.instagram.com/mlatgeorgiatech
  50. https://wordpress.com/?ref=footer_custom_svg
  51. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/
  52. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
  54. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/#comment-form-guest
  55. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/#comment-form-load-service:wordpress.com
  56. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/#comment-form-load-service:twitter
  57. https://mlatgt.blog/2018/03/18/learning-to-represent-words-by-how-theyre-spelled/#comment-form-load-service:facebook
