   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    a comprehensive beginner   s guide to create a time
   series forecast (with codes in python) comments feed [4]alternate
   [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]python [94]a comprehensive beginner   s guide to create a
   time series forecast (with codes in python)

   [95]python[96]time series

a comprehensive beginner   s guide to create a time series forecast (with codes
in python)

   [97]aarshay jain, february 6, 2016

introduction

   [98]time series (referred as ts from now) is considered to be one of
   the less known skills in the [99]data science space (even i had little
   clue about it a couple of days back). i set myself on a journey to
   learn the basic steps for solving a time series problem and here i am
   sharing the same with you. these will definitely help you get a decent
   model in any future project you take up!

   [100]time series, time series python

   before going through this article, i highly recommend reading [101]a
   complete tutorial on time series modeling in r and taking the [102]free
   time series forecasting course. it focuses on fundamental concepts and
   i will focus on using these concepts in solving a problem end-to-end
   along with codes in [103]python. many resources exist for time series
   in r but very few are there for python so i   ll be using python in this
   article.

   our journey would go through the following steps:
    1. what makes time series special?
    2. loading and handling time series in pandas
    3. how to check stationarity of a time series?
    4. how to make a time series stationary?
    5. forecasting a time series


1. what makes time series special?

   as the name suggests, ts is a collection of data points collected at
   constant time intervals. these are analyzed to determine the long term
   trend so as to forecast the future or perform some other form of
   analysis. but what makes a ts different from say a regular regression
   problem? there are 2 things:
    1. it is time dependent. so the basic assumption of a linear
       regression model that the observations are independent doesn   t hold
       in this case.
    2. along with an increasing or decreasing trend, most ts have some
       form of seasonality trends, i.e. variations specific to a
       particular time frame. for example, if you see the sales of a
       woolen jacket over time, you will invariably find higher sales in
       winter seasons.

   because of the inherent properties of a ts, there are various steps
   involved in analyzing it. these are discussed in detail below. lets
   start by loading a ts object in python. we   ll be using the popular
   airpassengers data set which can be downloaded [104]here.

   please note that the aim of this article is to familiarize you with the
   various techniques used for ts in general. the example considered here
   is just for illustration and i will focus on coverage a breadth of
   topics and not making a very accurate forecast.


2. loading and handling time series in pandas

   pandas has dedicated libraries for handling ts objects, particularly
   the datatime64[ns] class which stores time information and allows us to
   perform some operations really fast. lets start by firing up the
   required libraries:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
%matplotlib inline
from matplotlib.pylab import rcparams
rcparams['figure.figsize'] = 15, 6

   now, we can load the data set and look at some initial rows and data
   types of the columns:
data = pd.read_csv('airpassengers.csv')
print data.head()
print '\n data types:'
print data.dtypes

   [105]1. dataload 1

   the data contains a particular month and number of passengers
   travelling in that month. but this is still not read as a ts object as
   the data types are    object    and    int   . in order to read the data as a
   time series, we have to pass special arguments to the read_csv command:
dateparse = lambda dates: pd.datetime.strptime(dates, '%y-%m')
data = pd.read_csv('airpassengers.csv', parse_dates=['month'], index_col='month'
,date_parser=dateparse)
print data.head()

   [106]2. dataload 2

   let   s understand the arguments one by one:
    1. parse_dates: this specifies the column which contains the date-time
       information. as we say above, the column name is    month   .
    2. index_col: a key idea behind using pandas for ts data is that the
       index has to be the variable depicting date-time information. so
       this argument tells pandas to use the    month    column as index.
    3. date_parser: this specifies a function which converts an input
       string into datetime variable. be default pandas reads data in
       format    yyyy-mm-dd hh:mm:ss   . if the data is not in this format,
       the format has to be manually defined. something similar to the
       dataparse function defined here can be used for this purpose.

   now we can see that the data has time object as index and #passengers
   as the column. we can cross-check the datatype of the index with the
   following command:
data.index

   [107]3. index type

   notice the dtype=   datetime[ns]    which confirms that it is a datetime
   object. as a personal preference, i would convert the column into a
   series object to prevent referring to columns names every time i use
   the ts. please feel free to use as a dataframe is that works better for
   you.

   ts = data[   #passengers   ] ts.head(10)

   [108]4. series

   before going further, i   ll discuss some indexing techniques for ts
   data. lets start by selecting a particular value in the series object.
   this can be done in following 2 ways:
#1. specific the index as a string constant:
ts['1949-01-01']

#2. import the datetime library and use 'datetime' function:
from datetime import datetime
ts[datetime(1949,1,1)]

   both would return the value    112    which can also be confirmed from
   previous output. suppose we want all the data upto may 1949. this can
   be done in 2 ways:
#1. specify the entire range:
ts['1949-01-01':'1949-05-01']

#2. use ':' if one of the indices is at ends:
ts[:'1949-05-01']

   both would yield following output:

   [109]5. index range

   there are 2 things to note here:
    1. unlike numeric indexing, the end index is included here. for
       instance, if we index a list as a[:5] then it would return the
       values at indices     [0,1,2,3,4]. but here the index    1949-05-01   
       was included in the output.
    2. the indices have to be sorted for ranges to work. if you randomly
       shuffle the index, this won   t work.

   consider another instance where you need all the values of the year
   1949. this can be done as:
ts['1949']

   [110]6. index year

   the month part was omitted. similarly if you all days of a particular
   month, the day part can be omitted.

   now, lets move onto the analyzing the ts.


3. how to check stationarity of a time series?

   a ts is said to be stationary if its statistical properties such as
   mean, variance remain constant over time. but why is it important? most
   of the ts models work on the assumption that the ts is stationary.
   intuitively, we can sat that if a ts has a particular behaviour over
   time, there is a very high id203 that it will follow the same in
   the future. also, the theories related to stationary series are more
   mature and easier to implement as compared to non-stationary series.

   stationarity is defined using very strict criterion. however, for
   practical purposes we can assume the series to be stationary if it has
   constant statistical properties over time, ie. the following:
    1. constant mean
    2. constant variance
    3. an autocovariance that does not depend on time.

   i   ll skip the details as it is very clearly defined in [111]this
   article. lets move onto the ways of testing stationarity. first and
   foremost is to simple plot the data and analyze visually. the data can
   be plotted using following command:
plt.plot(ts)

   [112]7. ts

   it is clearly evident that there is an overall increasing trend in the
   data along with some seasonal variations. however, it might not always
   be possible to make such visual id136s (we   ll see such cases
   later). so, more formally, we can check stationarity using the
   following:
    1. plotting rolling statistics: we can plot the moving average or
       moving variance and see if it varies with time. by moving
       average/variance i mean that at any instant    t   , we   ll take the
       average/variance of the last year, i.e. last 12 months. but again
       this is more of a visual technique.
    2. dickey-fuller test: this is one of the statistical tests for
       checking stationarity. here the null hypothesis is that the ts is
       non-stationary. the test results comprise of a test statistic and
       some critical values for difference confidence levels. if the    test
       statistic    is less than the    critical value   , we can reject the
       null hypothesis and say that the series is stationary. refer
       [113]this article for details.

   these concepts might not sound very intuitive at this point. i
   recommend going through the prequel article. if you   re interested in
   some theoretical statistics, you can refer introduction to time series
   and forecasting by brockwell and davis. the book is a bit stats-heavy,
   but if you have the skill to read-between-lines, you can understand the
   concepts and tangentially touch the statistics.

   back to checking stationarity, we   ll be using the rolling statistics
   plots along with dickey-fuller test results a lot so i have defined a
   function which takes a ts as input and generated them for us. please
   note that i   ve plotted standard deviation instead of variance to keep
   the unit similar to mean.
from statsmodels.tsa.stattools import adfuller
def test_stationarity(timeseries):

    #determing rolling statistics
    rolmean = pd.rolling_mean(timeseries, window=12)
    rolstd = pd.rolling_std(timeseries, window=12)

    #plot rolling statistics:
    orig = plt.plot(timeseries, color='blue',label='original')
    mean = plt.plot(rolmean, color='red', label='rolling mean')
    std = plt.plot(rolstd, color='black', label = 'rolling std')
    plt.legend(loc='best')
    plt.title('rolling mean & standard deviation')
    plt.show(block=false)

    #perform dickey-fuller test:
    print 'results of dickey-fuller test:'
    dftest = adfuller(timeseries, autolag='aic')
    dfoutput = pd.series(dftest[0:4], index=['test statistic','p-value','#lags u
sed','number of observations used'])
    for key,value in dftest[4].items():
        dfoutput['critical value (%s)'%key] = value
    print dfoutput

   the code is pretty straight forward. please feel free to discuss the
   code in comments if you face challenges in grasping it.

   let   s run it for our input series:
test_stationarity(ts)

   though the variation in standard deviation is small, mean is
   clearly increasing with time and this is not a stationary series. also,
   the test statistic is way more than the critical values. note that the
   signed values should be compared and not the absolute values.

   next, we   ll discuss the techniques that can be used to take this ts
   towards stationarity.


4. how to make a time series stationary?

   though stationarity assumption is taken in many ts models, almost none
   of practical time series are stationary. so statisticians have figured
   out ways to make series stationary, which we   ll discuss now. actually,
   its almost impossible to make a series perfectly stationary, but we try
   to take it as close as possible.

   lets understand what is making a ts non-stationary. there are 2 major
   reasons behind non-stationaruty of a ts:
   1. trend     varying mean over time. for eg, in this case we saw that on
   average, the number of passengers was growing over time.
   2. seasonality     variations at specific time-frames. eg people might
   have a tendency to buy cars in a particular month because of pay
   increment or festivals.

   the underlying principle is to model or estimate the trend and
   seasonality in the series and remove those from the series to get a
   stationary series. then statistical forecasting techniques can be
   implemented on this series. the final step would be to convert the
   forecasted values into the original scale by applying trend and
   seasonality constraints back.

   note: i   ll be discussing a number of methods. some might work well in
   this case and others might not. but the idea is to get a hang of all
   the methods and not focus on just the problem at hand.

   let   s start by working on the trend part.


estimating & eliminating trend

   one of the first tricks to reduce trend can be transformation. for
   example, in this case we can clearly see that the there is a
   significant positive trend. so we can apply transformation which
   penalize higher values more than smaller values. these can be taking a
   log, square root, cube root, etc. lets take a log transform here for
   simplicity:
ts_log = np.log(ts)
plt.plot(ts_log)

   [114]9. ts log

   in this simpler case, it is easy to see a forward trend in the data.
   but its not very intuitive in presence of noise. so we can use some
   techniques to estimate or model this trend and then remove it from the
   series. there can be many ways of doing it and some of most commonly
   used are:
    1. aggregation     taking average for a time period like monthly/weekly
       averages
    2. smoothing     taking rolling averages
    3. polynomial fitting     fit a regression model

   i will discuss smoothing here and you should try other techniques as
   well which might work out for other problems. smoothing refers to
   taking rolling estimates, i.e. considering the past few instances.
   there are can be various ways but i will discuss two of those here.

moving average

   in this approach, we take average of    k    consecutive values depending
   on the frequency of time series. here we can take the average over the
   past 1 year, i.e. last 12 values. pandas has specific functions defined
   for determining rolling statistics.
moving_avg = pd.rolling_mean(ts_log,12)
plt.plot(ts_log)
plt.plot(moving_avg, color='red')

   [115]10. smooth 1

   the red line shows the rolling mean. lets subtract this from the
   original series. note that since we are taking average of last 12
   values, rolling mean is not defined for first 11 values. this can be
   observed as:
ts_log_moving_avg_diff = ts_log - moving_avg
ts_log_moving_avg_diff.head(12)

   [116]10.5 missing rolling

   notice the first 11 being nan. lets drop these nan values and check the
   plots to test stationarity.
ts_log_moving_avg_diff.dropna(inplace=true)
test_stationarity(ts_log_moving_avg_diff)

   this looks like a much better series. the rolling values appear to be
   varying slightly but there is no specific trend. also, the test
   statistic is smaller than the 5% critical values so we can say with 95%
   confidence that this is a stationary series.

   however, a drawback in this particular approach is that the time-period
   has to be strictly defined. in this case we can take yearly averages
   but in complex situations like forecasting a stock price, its difficult
   to come up with a number. so we take a    weighted moving average    where
   more recent values are given a higher weight. there can be many
   technique for assigning weights. a popular one is exponentially
   weighted moving average where weights are assigned to all the previous
   values with a decay factor. find details [117]here. this can be
   implemented in pandas as:
expwighted_avg = pd.ewma(ts_log, halflife=12)
plt.plot(ts_log)
plt.plot(expwighted_avg, color='red')


   [118]12. smooth 2

   note that here the parameter    halflife    is used to define the amount of
   exponential decay. this is just an assumption here and would depend
   largely on the business domain. other parameters like span and center
   of mass can also be used to define decay which are discussed in the
   link shared above. now, let   s remove this from series and check
   stationarity:
ts_log_ewma_diff = ts_log - expwighted_avg
test_stationarity(ts_log_ewma_diff)

   this ts has even lesser variations in mean and standard deviation in
   magnitude. also, the test statistic is smaller than the 1% critical
   value, which is better than the previous case. note that in this case
   there will be no missing values as all values from starting are given
   weights. so it   ll work even with no previous values.


eliminating trend and seasonality

   the simple trend reduction techniques discussed before don   t work in
   all cases, particularly the ones with high seasonality. lets discuss
   two ways of removing trend and seasonality:
    1. differencing     taking the differece with a particular time lag
    2. decomposition     modeling both trend and seasonality and removing
       them from the model.

differencing

   one of the most common methods of dealing with both trend and
   seasonality is differencing. in this technique, we take the difference
   of the observation at a particular instant with that at the previous
   instant. this mostly works well in improving stationarity. first order
   differencing can be done in pandas as:
ts_log_diff = ts_log - ts_log.shift()
plt.plot(ts_log_diff)

   [119]14. ts diff

   this appears to have reduced trend considerably. lets verify using our
   plots:
ts_log_diff.dropna(inplace=true)
test_stationarity(ts_log_diff)

   we can see that the mean and std variations have small variations with
   time. also, the dickey-fuller test statistic is less than the 10%
   critical value, thus the ts is stationary with 90% confidence. we can
   also take second or third order differences which might get even better
   results in certain applications. i leave it to you to try them out.

decomposing

   in this approach, both trend and seasonality are modeled separately and
   the remaining part of the series is returned. i   ll skip the statistics
   and come to the results:
from statsmodels.tsa.seasonal import seasonal_decompose
decomposition = seasonal_decompose(ts_log)

trend = decomposition.trend
seasonal = decomposition.seasonal
residual = decomposition.resid

plt.subplot(411)
plt.plot(ts_log, label='original')
plt.legend(loc='best')
plt.subplot(412)
plt.plot(trend, label='trend')
plt.legend(loc='best')
plt.subplot(413)
plt.plot(seasonal,label='seasonality')
plt.legend(loc='best')
plt.subplot(414)
plt.plot(residual, label='residuals')
plt.legend(loc='best')
plt.tight_layout()

   [120]16. decompose

   here we can see that the trend, seasonality are separated out from data
   and we can model the residuals. lets check stationarity of residuals:
ts_log_decompose = residual
ts_log_decompose.dropna(inplace=true)
test_stationarity(ts_log_decompose)

   the dickey-fuller test statistic is significantly lower than the 1%
   critical value. so this ts is very close to stationary. you can try
   advanced decomposition techniques as well which can generate better
   results. also, you should note that converting the residuals into
   original values for future data in not very intuitive in this case.


5. forecasting a time series

   we saw different techniques and all of them worked reasonably well for
   making the ts stationary. lets make model on the ts after differencing
   as it is a very popular technique. also, its relatively easier to add
   noise and seasonality back into predicted residuals in this case.
   having performed the trend and seasonality estimation techniques, there
   can be two situations:
    1. a strictly stationary series with no dependence among the values.
       this is the easy case wherein we can model the residuals as white
       noise. but this is very rare.
    2. a series with significant dependence among values. in this case we
       need to use some statistical models like arima to forecast the
       data.

   let me give you a brief introduction to arima. i won   t go into the
   technical details but you should understand these concepts in detail if
   you wish to apply them more effectively. arima stands for
   auto-regressive integrated moving averages. the arima forecasting for a
   stationary time series is nothing but a linear (like a linear
   regression) equation. the predictors depend on the parameters (p,d,q)
   of the arima model:
    1. number of ar (auto-regressive) terms (p): ar terms are just lags of
       dependent variable. for instance if p is 5, the predictors for x(t)
       will be x(t-1)   .x(t-5).
    2. number of ma (moving average) terms (q): ma terms are lagged
       forecast errors in prediction equation. for instance if q is 5, the
       predictors for x(t) will be e(t-1)   .e(t-5) where e(i) is the
       difference between the moving average at i^th instant and actual
       value.
    3. number of differences (d): these are the number of nonseasonal
       differences, i.e. in this case we took the first order difference.
       so either we can pass that variable and put d=0 or pass the
       original variable and put d=1. both will generate same results.

   an importance concern here is how to determine the value of    p    and
      q   . we use two plots to determine these numbers. lets discuss them
   first.
    1. autocorrelation function (acf): it is a measure of the correlation
       between the the ts with a lagged version of itself. for instance at
       lag 5, acf would compare series at time instant    t1         t2    with
       series at instant    t1-5         t2-5    (t1-5 and t2 being end points).
    2. partial autocorrelation function (pacf): this measures the
       correlation between the ts with a lagged version of itself but
       after eliminating the variations already explained by the
       intervening comparisons. eg at lag 5, it will check the correlation
       but remove the effects already explained by lags 1 to 4.

   the acf and pacf plots for the ts after differencing can be plotted as:
#acf and pacf plots:
from statsmodels.tsa.stattools import acf, pacf
lag_acf = acf(ts_log_diff, nlags=20)
lag_pacf = pacf(ts_log_diff, nlags=20, method='ols')
#plot acf:
plt.subplot(121)
plt.plot(lag_acf)
plt.axhline(y=0,linestyle='--',color='gray')
plt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')
plt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')
plt.title('autocorrelation function')
#plot pacf:
plt.subplot(122)
plt.plot(lag_pacf)
plt.axhline(y=0,linestyle='--',color='gray')
plt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')
plt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')
plt.title('partial autocorrelation function')
plt.tight_layout()

   [121]6. acf pcf final

   in this plot, the two dotted lines on either sides of 0 are the
   confidence interevals. these can be used to determine the    p    and    q   
   values as:
    1. p     the lag value where the pacf chart crosses the upper confidence
       interval for the first time. if you notice closely, in this case
       p=2.
    2. q     the lag value where the acf chart crosses the upper confidence
       interval for the first time. if you notice closely, in this case
       q=2.

   now, lets make 3 different arima models considering individual as well
   as combined effects. i will also print the rss for each. please note
   that here rss is for the values of residuals and not actual series.

   we need to load the arima model first:
from statsmodels.tsa.arima_model import arima

   the p,d,q values can be specified using the order argument of arima
   which take a tuple (p,d,q). let model the 3 cases:

ar model

model = arima(ts_log, order=(2, 1, 0))
results_ar = model.fit(disp=-1)
plt.plot(ts_log_diff)
plt.plot(results_ar.fittedvalues, color='red')
plt.title('rss: %.4f'% sum((results_ar.fittedvalues-ts_log_diff)**2))

   [122]18. model ar

ma model

model = arima(ts_log, order=(0, 1, 2))
results_ma = model.fit(disp=-1)
plt.plot(ts_log_diff)
plt.plot(results_ma.fittedvalues, color='red')
plt.title('rss: %.4f'% sum((results_ma.fittedvalues-ts_log_diff)**2))

   [123]19. model ma

combined model

model = arima(ts_log, order=(2, 1, 2))
results_arima = model.fit(disp=-1)
plt.plot(ts_log_diff)
plt.plot(results_arima.fittedvalues, color='red')
plt.title('rss: %.4f'% sum((results_arima.fittedvalues-ts_log_diff)**2))

   [124]20. model both

   here we can see that the ar and ma models have almost the same rss but
   combined is significantly better. now, we are left with 1 last step,
   i.e. taking these values back to the original scale.

taking it back to original scale

   since the combined model gave best result, lets scale it back to the
   original values and see how well it performs there. first step would be
   to store the predicted results as a separate series and observe it.
predictions_arima_diff = pd.series(results_arima.fittedvalues, copy=true)
print predictions_arima_diff.head()

   notice that these start from    1949-02-01    and not the first month. why?
   this is because we took a lag by 1 and first element doesn   t have
   anything before it to subtract from. the way to convert the
   differencing to log scale is to add these differences consecutively to
   the base number. an easy way to do it is to first determine the
   cumulative sum at index and then add it to the base number. the
   cumulative sum can be found as:
predictions_arima_diff_cumsum = predictions_arima_diff.cumsum()
print predictions_arima_diff_cumsum.head()


   [125]22. cumsum

   you can quickly do some back of mind calculations using previous output
   to check if these are correct. next we   ve to add them to base number.
   for this lets create a series with all values as base number and add
   the differences to it. this can be done as:
predictions_arima_log = pd.series(ts_log.ix[0], index=ts_log.index)
predictions_arima_log = predictions_arima_log.add(predictions_arima_diff_cumsum,
fill_value=0)
predictions_arima_log.head()

   [126]23. add cumsum

   here the first element is base number itself and from thereon the
   values cumulatively added. last step is to take the exponent and
   compare with the original series.
predictions_arima = np.exp(predictions_arima_log)
plt.plot(ts)
plt.plot(predictions_arima)
plt.title('rmse: %.4f'% np.sqrt(sum((predictions_arima-ts)**2)/len(ts)))

   [127]24. final plot

   finally we have a forecast at the original scale. not a very good
   forecast i would say but you got the idea right? now, i leave it upto
   you to refine the methodology further and make a better solution.


projects

   now, its time to take the plunge and actually play with some other real
   datasets. so are you ready to take on the challenge? test the
   techniques discussed in this post and accelerate your learning in time
   series analysis with the following practice problems:
   [128]practice problem: food demand forecasting challenge forecast the
   demand of meals for a meal delivery company
   [129]practice problem: time series analyses forecast the passenger
   traffic for an intra-city rail system


end notes

   through this article i have tried to give you a standard approach for
   solving time series problem. this couldn   t have come at a better time
   as today is our [130]mini datahack which will challenge you to solve a
   similar problem. we   ve covered concepts of stationarity, how to take a
   time series closer to stationarity and finally forecasting the
   residuals. it was a long journey and i skipped some statistical details
   which i encourage you to refer using the suggested material. if you
   don   t want to copy-paste, you can download the ipython notebook with
   all the codes from my [131]github repository.

   i hope this article will help you achieve a good first solution today.
   all the best guys!

   did you like the article? how helpful was it in the hackathon today?
   somethings bothering you which you wish to discuss further? please feel
   free to post a comment and i   ll be more than happy to discuss.

note     the discussions of this article are going on at av   s discuss
portal. [132]join here!

   you can also read this article on analytics vidhya's android app
   [133]get it on google play

share this:

     * [134]click to share on linkedin (opens in new window)
     * [135]click to share on facebook (opens in new window)
     * [136]click to share on twitter (opens in new window)
     * [137]click to share on pocket (opens in new window)
     * [138]click to share on reddit (opens in new window)
     *

related articles

   [ins: :ins]

   tags : [139]arima, [140]forecasting analytics, [141]pandas, [142]time
   series, [143]time series analysis, [144]time series forecasting
   next article

what i learnt about time series analysis in 3 hour mini datahack?

   previous article

mini datahack and the tactics of the three    last man standing   !

[145]aarshay jain

   aarshay is a ml enthusiast, pursuing ms in data science at columbia
   university, graduating in dec 2017. he is currently exploring the
   various ml techniques and writes articles for av to share his knowledge
   with the community.
     *
     *
     *
     *

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [146]discussion portal to get your queries resolved

72 comments

     * dr.d.k.samuel says:
       [147]february 6, 2016 at 10:02 am
       real thanks for a post which met my need
          + aarshay jain says:
            [148]february 6, 2016 at 10:04 am
            i   m glad you liked it     
     * satish says:
       [149]february 7, 2016 at 3:17 pm
       thanks for great explanation related to timeseries. what is
       difference between holtwinters and arima forcast?
          + shan says:
            [150]february 8, 2016 at 6:09 am
            holtwinters is double exponential smoothening method. arima,
            forecasts by identifying p,d,q component of a series. hope it
            helps.
               o aarshay jain says:
                 [151]february 8, 2016 at 6:51 am
                 to add to shan, holtwinters uses a weighted average of
                 past values while arima uses both past values and past
                 errors. you can find more details here:
                 [152]https://www.google.co.in/url?sa=t&rct=j&q=&esrc=s&so
                 urce=web&cd=2&ved=0ahukewiugkxcx-fkahxic44khttpdyuqfggjma
                 e&url=http%3a%2f%2fwww.ons.gov.uk%2fons%2fguide-method%2f
                 ukcemga%2fukcemga-publications%2fpublications%2farchive%2
                 ffrom-holt-winters-to-arima-modelling   measuring-the-impac
                 t-on-forecasting-errors-for-components-of-quarterly-estim
                 ates-of-public-service-output.pdf&usg=afqjcngmyzfvb-_gdss
                 4lktgw4vvzgbc_w&sig2=9pnseabic_4oxc2knwmhnw&cad=rja
          + tl says:
            [153]april 11, 2016 at 12:59 am
            holt winters (at least the additive model) is a special case
            of arima model (a seasonal arima model). that would be an
            arima(p,d,q)(p,d,q) where the second parentheses contains the
            seasonal effects. i would additionally recommend checking out
            any of rob hyndman   s work on arima modeling, i find it to be
            very accessible.
     * shan says:
       [154]february 7, 2016 at 6:12 pm
       hi..
       thanks. for an informative article.
       i am eager to know on followings :
       a) how can we identify what should be nlags value to test with
       lag_acf = acf(ts_log_diff, nlags=20)
       lag_pacf = pacf(ts_log_diff, nlags=20, method=   ols   )
       b) how can we forecast for future time points (say 12 time points
       ahead).
       can we use followings still ?
       predictions_arima_log = pd.series(ts_log.ix[0], index=ts_log.index)
       predictions_arima_log =
       predictions_arima_log.add(predictions_arima_diff_cumsum,fill_value=
       0)
       ts_log is not available for future points.
       c) in one of the article ( a complete tutorial on time series
       modeling in r,) referred by you ,
       while performing adf says
       adf.test(diff(log(airpassengers)), alternative=   stationary   , k=0)
       what is k , and how can we identify the value of k while performing
       the test..
       while performing arima says :
       fit <- arima(log(airpassengers), c(0, 1, 1),seasonal = list(order =
       c(0, 1, 1), period = 12)))
       we can identify the (p,d,q) from acf pacf plots .
       please explain parameter seasonal = list(order = c(0, 1, 1)
       what values should we pass in seasonal parameter and how to
       identify it.
       it will be helpful if you guide on above.. thanks in anticipation.
          + aarshay jain says:
            [155]february 8, 2016 at 6:52 am
            hi shan,
            thanks for reaching out. please find my responses below:
            a) so the    nlags    doesn   t affect the output values. i just
            specifies how many values to display. so you can start with a
            small number and if you don   t find the crossing point within
            that, you can increase maximum upto the number of observations
            in data.
            b) arima has a specific function for forecasting values. the
               results_arima    variable here is of the type    arimaresults   
            which has a    predict    function. you can check the details as    
            [156]http://statsmodels.sourceforge.net/devel/generated/statsm
            odels.tsa.arima_model.armaresults.predict.html#statsmodels.tsa
            .arima_model.armaresults.predict
            please feel free to get back to me in case you face challenges
            in implementing this. you can also start a thread in the
            discussion forum which will allow more freedom of expression
            while discussing     
            c) i   m not much experienced with r so let me read the code
            syntax. i   ll get back to you on this.
            cheers!
               o chirag bhatia says:
                 [157]july 15, 2016 at 5:48 am
                 hi aarshay
                 i am trying to predict future values on same airpassenger
                 data but i am not getting correct results. i may miss
                 some parameters while predicting. please help me. i am
                 stuck from past 2 days. my code is:
                 import pandas as pd
                 import numpy as np
                 from statsmodels.tsa.arima_model import arima
                 import matplotlib.pylab as plt
                 data_1 = pd.read_csv(   airpassengers.csv   )
                 avg= data_1[   #passengers   ]
                 avg=list(avg)
                 res = pd.series(avg,
                 index=pd.to_datetime(data_1[   month   ],format=   %y-%m   ))
                 ts=np.log(res)
                 ts_diff = ts     ts.shift()
                 ts_diff.dropna(inplace=true)
                 r = arima(ts,(2,1,2))
                 r = r.fit(disp=-1)
                 pred = r.predict(start=   1961-01   ,end=   1970-01   )
                 dates = pd.date_range(   1961-01   ,   1970-01   ,freq=   m   )
                 # print dates
                 predictions_arima_diff = pd.series(pred, copy=true)
                 predictions_arima_diff_cumsum =
                 predictions_arima_diff.cumsum()
                 predictions_arima_log = pd.series(ts.ix[0])
                 predictions_arima_log=predictions_arima_log.add(predictio
                 ns_arima_diff_cumsum,fill_value=0)
                 predictions_arima = np.exp(predictions_arima_log)
                 plt.plot(res)
                 plt.plot(predictions_arima)
                 # plt.title(   rmse: %.4f   %
                 np.sqrt(sum((predictions_arima-ts1)**2)/len(ts)))
                 plt.show()
                 print predictions_arima.head()
                 print ts.head()
          + aarshay jain says:
            [158]february 8, 2016 at 12:32 pm
            hi shan,
            i guess you have started a separate discussion thread for your
            query    c   . lets continue the discussion there. for others
            who   re reading this and interested in exploring further,
            please check out this link:
            [159]http://discuss.analyticsvidhya.com/t/seasonal-parameter-i
            n-arima-and-adf-test/7385/1
            cheers!
     * amitsethia says:
       [160]february 13, 2016 at 12:23 pm
       thanks aarshay for this write up. it is also recommended to not to
       go for combined models as p & q used together will nullify their
       impact on the model, hence, it is either a moving average or auto
       correlation along with differences, but here combined model has
       given the best results. can you please correct my understanding
       around combined models.
          + aarshay jain says:
            [161]february 13, 2016 at 12:50 pm
            i haven   t read that p & q should not be combined. it   s
            actually appears counter intuitive because if this was the
            case then arima should not exist in the first place. can you
            throw some light on why do you believe that they cancel out
            the effect of one another?
     * aayush kumar singha says:
       [162]february 29, 2016 at 10:58 pm
       hi!
       the article is the best available on time series with python with
       great external links too for those who want to understand the stat
       behind also.
       i would like to request to please extend this article to predict
       out-of-sample data range also with different models to depict the
       better ones as you did for eliminating trend (taking rolling
       average and ewma).
       that will make it all fully fledged time-series article.
       thanks in advance.
          + aarshay jain says:
            [163]march 1, 2016 at 8:46 am
            hi ayush!
            thanks for your valuable feedback. yes i think that component
            is necessary. but instead of extending this article, i   ll
            probably write a separate post taking another case study. i   m
            a bit crunched for bandwidth but you can expect it sometime in
            this month. stay tuned!
     * michael says:
       [164]march 13, 2016 at 5:49 pm
       thanks for the excellent article. i have 2 clarifications
       1) in the estimating & eliminating trend step, i have negative
       numbers. could you please tell me what transformations could i
       apply. log and sqrt returns nan?
       2) also, test_stationarity(ts_log_decompose,nlags=10) while
       executing specifies nlags not defined.
       thanks in advance.
          + aarshay jain says:
            [165]march 13, 2016 at 6:12 pm
            hi michael,
            thanks for reaching out. regarding your queries:
            1. you can try scaling up your values and then applying
            transformations. also, you might want to check if log
            transformation is actually required in your case. you can try
            a cube root as well.
            2. please remove the nlags argument and then run the code.
            i   ve updated the code above as well.
     * will welch says:
       [166]march 14, 2016 at 1:34 am
       nice article, you rarely see this range of models discussed in one
       place
       and in such a hands-on way.
       for anyone doing seasonal decomposition in python, i   d like to
       shamelessly
       plug my `seasonal` package (pypi or
       [167]https://github.com/welch/seasonal) in
       addition to statsmodels seasonal_decompose. `seasonal` offers some
       richer
       and more robust detrending possibilities, and will also estimate
       your model   s
       periodicity for you (convenient in a dev-ops setting with thousands
       of streams
       at hand). it also includes a robust periodogram for visualizing the
       periodicities
       in your data.
          + aarshay jain says:
            [168]march 14, 2016 at 5:58 am
            thanks will for sharing your library. it   ll be helpful for
            everyone.
     * alon star says:
       [169]march 24, 2016 at 7:38 pm
       can you please explain what is the dftest[0:4]?
          + aarshay jain says:
            [170]march 25, 2016 at 6:26 am
            the adfuller function returns a list with many values. i   m
            picking the first 4 using [0:4]. i   ve used the 5th value
            separately. you might want to print the dftest variable and
            you   ll know.
     * lbert says:
       [171]april 10, 2016 at 5:53 am
       can we use this method for decimal data? why the program gave me an
       error of    valueerror: you must specify a freq or x must be a pandas
       object with a timeseries index   ?
          + aarshay jain says:
            [172]april 11, 2016 at 6:59 am
            i don   t think it is a decimal error. please check whether your
            index is a timeseries object.
     * [173]cloga says:
       [174]april 14, 2016 at 9:54 am
       hi aarshay jain,
       one more question,
       when you fit model , you use ts_log as sampel, ie. model =
       arima(ts_log, order=(2, 1, 2)) , but when you predict you use
       predict value as diff value : predictions_arima_diff =
       pd.series(results_arima.fittedvalues, copy=true), is
       results_arima.fittedvalues return log value or diff value?
       thank you for your time.
          + aarshay jain says:
            [175]april 14, 2016 at 10:53 am
            actually while calling arima i have set order = (2,1,2). here
            the middle argument 1 means that arima will automatically take
            a difference of 1 while making predictions.
               o [176]cloga says:
                 [177]april 15, 2016 at 2:31 am
                 got it thank you!
     * ayodeji olufemi ayotunde says:
       [178]april 19, 2016 at 12:44 am
       what an excellent article on time series, more grease to your
       elbow. but the question is, is this method a package of analyzing
       time series related data or what? and can   t we do the same on spss
       and have the same simple method as this? however, i have to commend
       you a lot for this wonderful presentation. god will continue to
       increase your knowledge.
          + aarshay jain says:
            [179]april 19, 2016 at 5:09 am
            thanks ayodeji!
            i   m not sure about spss and sorry i didn   t get your questions
                what do you mean    is this method a package of analyzing time
            series related data   ? please elaborate.
     * andrew says:
       [180]april 22, 2016 at 4:47 am
       hi aarshay jain
       i   ve tried the dickey-fuller test code with different dataset and
       then an error shown up like this:
       valueerror: too many values to unpack
       please give an advice
       thank you
          + aarshay jain says:
            [181]april 25, 2016 at 5:50 pm
            please share the code..
          + dennis says:
            [182]may 27, 2016 at 1:41 am
            andrew, your are probably passing in a dataframe instead of a
            series, in the code aarshay wrote up for the dftest.
            specifically here: dftest = adfuller(timeseries.unstack(),
            autolag=   aic   )
            note the .unstack() that i added     transforming the df into a
            series     when i also encountered the same error.
     * tanvir says:
       [183]april 23, 2016 at 8:10 pm
       hello,
       i am struggling on a question.
       here, forecast is sowing upto 1960-12-01. now based on the current
       measure, i want to forecast the upcoming years for example
       1961-01-01 to 1965-12-01.
       how can i do this ?
     * anirban dhar says:
       [184]may 3, 2016 at 6:45 pm
       thanks aarshay for this detailed and illustrative posts.
       one concern, the decomposition is not working for 12 months [of a
       single year] data.
       eg. in airpassengers.csv if i take only the records of 1949 it
       fails to decompose giving below error:
       file
          c:\anirban\install\anaconda3\lib\site-packages\statsmodels\tsa\sea
       sonal.
       py   , line 88, in seasonal_decompose
       trend = convolution_filter(x, filt)
       file
          c:\anirban\install\anaconda3\lib\site-packages\statsmodels\tsa\fil
       ters\f
       iltertools.py   , line 289, in convolution_filter
       result = signal.convolve(x, filt, mode=   valid   )
       file
          c:\anirban\install\anaconda3\lib\site-packages\scipy\signal\signal
       tools.
       py   , line 470, in convolve
       return correlate(volume, kernel[slice_obj], mode)
       file
          c:\anirban\install\anaconda3\lib\site-packages\scipy\signal\signal
       tools.
       py   , line 160, in correlate
       _check_valid_mode_shapes(in1.shape, in2.shape)
       file
          c:\anirban\install\anaconda3\lib\site-packages\scipy\signal\signal
       tools.
       py   , line 72, in _check_valid_mode_shapes
          in1 should have at least as many items as in2 in    
       valueerror: in1 should have at least as many items as in2 in every
       dimension for
          valid    mode.
       i think this is somehow related to the filter but not able to nail
       it since i am too novice.
       please note     the code is exact replica of yours
       any help will be appreciated, thanks again     
     * [185]bawasir ki dawa says:
       [186]may 6, 2016 at 12:47 pm
       great blog post, thanks for sharing this post.
       [187]bawaseer ka ayurvedic ilaj
          + aarshay jain says:
            [188]may 6, 2016 at 5:56 pm
            you are welcome     
     * sk says:
       [189]may 16, 2016 at 7:06 pm
       how to do the prediction for the future?
       start = len(ts)
       end = len(ts)+14
       y_forecast = np.exp(results_arima.predict(start, end))
       this does not provide good results.
       would you please expand your code and description to include one
       month ahead forecast?
     * prakha shrivastava says:
       [190]may 19, 2016 at 10:59 am
       hi
       thank you for sharing this post. i have one question: time series
       in pandas does only work with csv file because i want to forecast
       my database values for next 6 months. i did connect the python with
       mysql database. i.e i have data in python with dataset not in csv
       file.so how can i used time series forecasting method. if you
       provide me code it will be huge help for me.
          + prakhar shrivastava says:
            [191]may 25, 2016 at 12:45 pm
            this problem is done   . by using data =
            pd.read_sql_query(cur,con).
     * prakhar shrivastava says:
       [192]may 25, 2016 at 12:32 pm
       in dicket-fuller test my came results of dickey-fuller test:
       test statistic -2.287864
       p-value 0.175912
       #lags used 11.000000
       number of observations used 215.000000
       critical value (1%) -3.461136
       critical value (10%) -2.573986
       critical value (5%) -2.875079
       dtype: float64
       my p value is so less? its means my data is not normal ox not not
       suited to this model?
          + prakhar shrivastava says:
            [193]may 27, 2016 at 9:24 am
            this problem is also done.
          + satya chandu says:
            [194]july 1, 2016 at 12:31 am
            if test static (-2.287864) is greater than critical value
            (-3.46, -2.57, -2.87) then we can   t reject the null
            hypothesis, the series is stationary. that said it is still
            non-stationary. if you increase the i value in arima model,
            perhaps above condition may meet and you may get the good
            forecast values.
     * dennis says:
       [195]may 27, 2016 at 1:43 am
       hi aarshay,
       i really enjoyed this but running on python 3, i   ve encountered a
       couple errors on the last portion.
          plt.title(   rss: %.4f   %
       sum((results_ma.fittedvalues-ts_log_diff)**2))
       pandas\tslib.pyx in pandas.tslib.timestamp.__radd__
       (pandas\tslib.c:14048)()
       pandas\tslib.pyx in pandas.tslib._timestamp.__add__
       (pandas\tslib.c:19022)()
       valueerror: cannot add integral value to timestamp without offset.   
       googling around it seems that its a bug in statsmodel but if i was
       wondering perhaps if you or someone else ported it to python 3?
       thanks
     * prakhar shrivastava says:
       [196]may 27, 2016 at 9:23 am
       thank you for this post. i find error in model = arima(ts_log,
       order=(2, 1, 0))
       and i unable to find the error.please me
     * prakhar shrivastava says:
       [197]june 1, 2016 at 2:29 pm
       thank you for this example. i have one problem. when i tried to put
       model in my program its said
       valueerror: given a pandas object and the index does not contain
       dates but in my dataset date is there.
       data = pd.read_sql_query(cur,con, index_col=   datum   ,
       coerce_float=true, params=none)
       i dont know what is problem with this?
     * sean stanislaw says:
       [198]june 3, 2016 at 5:08 am
       i still prefer gretl for building time series and econometric
       models easy to use its an open source just download and go
     * yuer says:
       [199]june 10, 2016 at 1:09 am
       hi, thank you for your sharing.
       i am using this model to predict play number of a song.
       when i input data with    data = pd.read_csv(   00play.csv   ,
       parse_dates=   data   , index_col=   data   ,date_parser=dateparse)   
       there are some error    typeerror: only booleans, lists, and
       dictionaries are accepted for the    parse_dates    parameter   
       if i delete this parameter parse_dates, is there any influence?
       using data without parameter parse_dates, when making
       seasonal_decompose, another error is    valueerror: freq d not
       understood. please report if you think this in error.   
       please give an advice
       thank you
     * jitendra says:
       [200]june 12, 2016 at 4:00 pm
       hi can you give me an idea in case of multiple time series
       forecasting
     * jie says:
       [201]june 19, 2016 at 3:59 am
       really liked this post. thank you very much for sharing.
     * bom says:
       [202]june 23, 2016 at 5:09 pm
       how to deal with the tendency of irregular time series data(data
       with different time interval)?
     * satya chandu says:
       [203]june 27, 2016 at 10:58 pm
       hi,
       this is a very good blog and very useful. i could follow the entire
       process. but i did not understand how to forecast for next 12
       months from the last value. in the current case the last value is
       1960-12, i need to forecast till 1961-12 (12 values). how can i do
       that in the following code? it would be great if you kindly add
       that process and update this article.
       predictions_arima_log = pd.series(ts_log.ix[0], index=ts_log.index)
       predictions_arima_log =
       predictions_arima_log.add(predictions_arima_diff_cumsum,fill_value=
       0)
     * aaditya says:
       [204]june 28, 2016 at 7:23 am
       hi aarshay,
       first of all thanks for this brilliant post.
       i am following a similar approach for forecasting a minute   s data
       using previous hours data. i am using forecast function in
       statsmodels along with arima model. calculating the p, q and d
       using the approach you mentioned in your post.
       however, i am facing a few problems:
       1. at times the arima throws an error for ar or ma parameter .
       2. arima in python takes a lot of time. similar code in r takes
       less than 30 minutes for forecasting a months data. am i missing
       something or arima in python is inherently slow?
       3. i get id113 not converging warning almost every-time, why is that
       so.
       4. arima does not allow d value more than two, however, at times
       adfuller results in d value more than two. what should be done in
       this case.
       looking forward to your suggestions.
       thanks,
       aaditya
     * satya chandu says:
       [205]june 28, 2016 at 4:21 pm
       hi arshay,
       this is very useful article. i got a small doubt about forecasting
       values. how can i get the forecast values from the following code?
       suppose i want to print for next 1 year, how can i do that?
       thanks,
       satya
       predictions_arima_log = pd.series(ts_log.ix[0], index=ts_log.index)
       predictions_arima_log =
       predictions_arima_log.add(predictions_arima_diff_cumsum,fill_value=
       0)
     * shantanu saha says:
       [206]july 5, 2016 at 7:07 pm
       thank you for such a detailed post. i was wondering what if the
       data was in country-level? how can we deal with such time series
       data then?
     * evelyn says:
       [207]july 8, 2016 at 5:50 pm
       for this code line:
       data = pd.read_csv(   airpassengers.csv   , parse_dates=   month   ,
       index_col=   month   ,date_parser=dateparse)
       does it work? i got error message in my anaconda python 2.7 because
       python can   t identify    month    as a list of month column value for
       parameter parse_dates, so i changed to [   month   ], it works.
       could anyone confirm it in python 3? thanks.
     * michael francis says:
       [208]july 11, 2016 at 4:44 pm
          valueerror: cannot add integral value to timestamp without
       offset.    i keep getting this error whenever i use the arima
       function and i was wondering if you could tell me what this means
       and how i could fix it. im using the same data and steps as the
       example above.
     * florent says:
       [209]july 18, 2016 at 4:58 pm
       thanks for this great article, it greatly helped me get started
       with time series forecasting.
       what would be the additional steps if you wanted to make a more
       accurate forecast?
     * abs says:
       [210]july 20, 2016 at 9:22 am
       really nice post,
       my question is how would different would the second part of the
       problem be if you were to use decomposing instead of differecing
       for forecasting the time-series?
     * shreyak tiwari says:
       [211]july 20, 2016 at 11:53 am
       can someone please explain while creating arima models you are
       using ts_log ( just a log time series) but while calculating rss
       you are using ts_log_diff . am i missing something here ?
     * mayank satnalika says:
       [212]july 26, 2016 at 7:03 am
       hey i   m a newbie in machine learning and wanted sort out an issue:
       what type of problems can be classified under time forecasting
       problem. many tutorials begin with predicting stock prices for next
       few days, so is it a time forecast problem. also is the bike
       sharing demand question from kaggle a part of time forecasting
       question as we are given the demand for some dates and we need to
       predict demand for upcoming days.
     * bhuvaneshwaran says:
       [213]august 17, 2016 at 7:22 am
       how to select which model is better one for our data? is there any
       parameters in data to select models ?
     * jarad says:
       [214]august 25, 2016 at 4:15 am
       this is literally the best article i   ve ever seen on time-series
       analysis with python. very well explained. i wish the statsmodels
       documentation was this good (they give you the tools but don   t show
       you how to use them!).
       i am very confused about acf and pacf and how to read the charts to
       determine the proper p an q. you concluded that p and q are both 2
       and you mention    upper confidence level   . i don   t see the lines
       crossing the upper-confidence level dashed line at point 2 in acf
       or pacf. is this a typo?
       if not a typo, can you explain?
     * jarad says:
       [215]august 26, 2016 at 6:22 am
       i wonder what your thoughts are on doing a decomposition, then
       performing arima forecasting on each component (trend, seasonality,
       residual), then re-scaling back. is this a sound method/approach? i
       did this and the prediction line looks like what i   d expect. i   m
       just wondering if this is a common practice.
     * anil says:
       [216]august 29, 2016 at 7:55 pm
       hi aarshey.. great article. i have tested the code and working
       fine, however, i am not getting the years in x axis, i tried
       different date parse methods, but no luck. how did you get year
       values in x axis where as parse method converting month column as
       string in %y-%m-%d format?
     * yassir says:
       [217]september 2, 2016 at 3:00 pm
       i got confused on many points: 1- we do many transformations to get
       stationarity data and every transformation we get data with good
       stationarity and on the example, you got the best stationary after
       applying the decomposing, then why did you use the ts_log_diff and
       ts_log data with acf,pacf and arima instead of using the
       decomposing data !? 2- i did see many styles for acf and pacf one
       like continuous graph and another one like pins, which one i should
       go for it? 3- what is the best and easiest way to detect ar and ma
       by acf and pacf? some tutorials mention about every arima model has
       a special acf and pacf pattern and others mention about the
       intersection between the lags and the confidence upper line! 4-is
       there any way to automate the step of getting the ar and ma instead
       of trying to investigate the acf and pacf plots?
     * alex debie says:
       [218]september 21, 2016 at 12:59 am
       thanks alot for the information, i learned a ton. im just a little
       confused now that i have this model how to use it to predict the
       next point in time
     * dwiti basu says:
       [219]september 26, 2016 at 6:31 am
       hi i am getting this error when i am writing the following codes,
       can anyone help?
       date1= lambda dates: pd.datetime.strptime(dates,    %y-%m   )
       dataset= pd.read_csv(   airpassangers.csv   , parse_dates=   month   ,
       index_col=   month   ,date_parser=date1)
       this is what i am getting:
       ========
       date1= lambda dates: pd.datetime.strptime(dates,    %y-%m-%d   )
       dataset= pd.read_csv(   airpassangers.csv   , parse_dates=   month   ,
       index_col=   month   ,date_parser=date1)
       traceback (most recent call last):
       file       , line 1, in
       dataset= pd.read_csv(   airpassangers.csv   , parse_dates=   month   ,
       index_col=   month   ,date_parser=date1)
       file
          c:\users\dwiti.b\appdata\local\continuum\anaconda2\lib\site-packag
       es\pandas\io\parsers.py   , line 562, in parser_f
       return _read(filepath_or_buffer, kwds)
       file
          c:\users\dwiti.b\appdata\local\continuum\anaconda2\lib\site-packag
       es\pandas\io\parsers.py   , line 315, in _read
       parser = textfilereader(filepath_or_buffer, **kwds)
       file
          c:\users\dwiti.b\appdata\local\continuum\anaconda2\lib\site-packag
       es\pandas\io\parsers.py   , line 645, in __init__
       self._make_engine(self.engine)
       file
          c:\users\dwiti.b\appdata\local\continuum\anaconda2\lib\site-packag
       es\pandas\io\parsers.py   , line 799, in _make_engine
       self._engine = cparserwrapper(self.f, **self.options)
       file
          c:\users\dwiti.b\appdata\local\continuum\anaconda2\lib\site-packag
       es\pandas\io\parsers.py   , line 1202, in __init__
       parserbase.__init__(self, kwds)
       file
          c:\users\dwiti.b\appdata\local\continuum\anaconda2\lib\site-packag
       es\pandas\io\parsers.py   , line 893, in __init__
       kwds.pop(   parse_dates   , false))
       file
          c:\users\dwiti.b\appdata\local\continuum\anaconda2\lib\site-packag
       es\pandas\io\parsers.py   , line 873, in _validate_parse_dates_arg
       raise typeerror(msg)
       typeerror: only booleans, lists, and dictionaries are accepted for
       the    parse_dates    parameter
     * dennis says:
       [220]october 3, 2016 at 10:42 am
       thank you for this post. however do you have any tutorials on stock
       price prediction using id158s?
     * leo says:
       [221]october 4, 2016 at 5:09 am
       this is not a complete guide. this can be something to get you
       started. time series analysis is not that limited.

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-06] [222]srk       3924
   2    [2.jpg?date=2019-04-06] [223]mark12    3510
   3    [3.jpg?date=2019-04-06] [224]nilabha   3261
   4    [4.jpg?date=2019-04-06] [225]nitish007 3237
   5    [5.jpg?date=2019-04-06] [226]tezdhar   3082
   [227]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [228]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [229]understanding support vector machine algorithm from examples
       (along with code)
     * [230]essentials of machine learning algorithms (with python and r
       codes)
     * [231]a complete tutorial to learn data science with python from
       scratch
     * [232]7 types of regression techniques you should know!
     * [233]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [234]a simple introduction to anova (with applications in excel)
     * [235]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [236]top 5 machine learning github repositories and reddit discussions
   from march 2019

[237]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [238]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[239]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [240]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[241]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [242]16 opencv functions to start your id161 journey (with
   python code)

[243]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [244][ds-finhack.jpg]

   [245][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [246]about us
     * [247]our team
     * [248]career
     * [249]contact us
     * [250]write for us

   [251]about us
   [252]   
   [253]our team
   [254]   
   [255]careers
   [256]   
   [257]contact us

data scientists

     * [258]blog
     * [259]hackathon
     * [260]discussions
     * [261]apply jobs
     * [262]leaderboard

companies

     * [263]post jobs
     * [264]trainings
     * [265]hiring hackathons
     * [266]advertising
     * [267]reach us

   don't have an account? [268]sign up here.

join our community :

   [269]46336 [270]followers
   [271]20222 [272]followers
   [273]followers
   [274]7513 [275]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [276]privacy policy
     * [277]terms of use
     * [278]refund policy

   don't have an account? [279]sign up here

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [280](button) join now

   subscribe!

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [281](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/python-2/
  94. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/
  95. https://www.analyticsvidhya.com/blog/category/python-2/
  96. https://www.analyticsvidhya.com/blog/category/time-series/
  97. https://www.analyticsvidhya.com/blog/author/aarshay/
  98. http://courses.analyticsvidhya.com/courses/creating-time-series-forecast-using-python?utm_source=blog&utm_medium=timeseriesforecastcomprehensivearticle
  99. http://courses.analyticsvidhya.com/courses/introduction-to-data-science-2?utm_source=blog&utm_medium=timeseriesforecastcomprehensivearticle
 100. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2016/02/a-comprehensive-beginner   s-guide-to-create-a-time-series-forecast-with-codes-in-python.png
 101. https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/
 102. http://courses.analyticsvidhya.com/courses/creating-time-series-forecast-using-python?utm_source=blog&utm_medium=timeseriesforecastcomprehensivearticle
 103. http://courses.analyticsvidhya.com/courses/introduction-to-data-science-2?utm_source=blog&utm_medium=timeseriesforecastcomprehensivearticle
 104. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/airpassengers.csv
 105. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/1.-dataload-1.png
 106. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/2.-dataload-2.png
 107. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/3.-index-type.png
 108. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/4.-series.png
 109. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/5.-index-range.png
 110. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/6.-index-year.png
 111. https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/
 112. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/7.-ts.png
 113. https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/
 114. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/9.-ts-log.png
 115. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/10.-smooth-1.png
 116. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/10.5-missing-rolling.png
 117. http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions
 118. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/12.-smooth-2.png
 119. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/14.-ts-diff.png
 120. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/16.-decompose.png
 121. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/6.-acf-pcf-final.png
 122. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/18.-model-ar.png
 123. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/19.-model-ma.png
 124. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/20.-model-both.png
 125. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/22.-cumsum.png
 126. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/23.-add-cumsum.png
 127. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/24.-final-plot.png
 128. https://datahack.analyticsvidhya.com/contest/genpact-machine-learning-hackathon-1/?utm_source=time-series-forecasting-codes-python&utm_medium=blog
 129. https://datahack.analyticsvidhya.com/contest/practice-problem-time-series-2/?utm_source=time-series-forecasting-codes-python&utm_medium=blog
 130. http://datahack.analyticsvidhya.com/contest/mini-datahack
 131. https://github.com/aarshayj/analytics_vidhya/tree/master/articles
 132. https://discuss.analyticsvidhya.com/t/discussions-for-article-a-comprehensive-beginners-guide-to-create-a-time-series-forecast-with-codes-in-python/65783?u=jalfaizy
 133. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 134. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/?share=linkedin
 135. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/?share=facebook
 136. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/?share=twitter
 137. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/?share=pocket
 138. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/?share=reddit
 139. https://www.analyticsvidhya.com/blog/tag/arima/
 140. https://www.analyticsvidhya.com/blog/tag/forecasting-analytics/
 141. https://www.analyticsvidhya.com/blog/tag/pandas/
 142. https://www.analyticsvidhya.com/blog/tag/time-series/
 143. https://www.analyticsvidhya.com/blog/tag/time-series-analysis/
 144. https://www.analyticsvidhya.com/blog/tag/time-series-forecasting/
 145. https://www.analyticsvidhya.com/blog/author/aarshay/
 146. https://discuss.analyticsvidhya.com/
 147. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105271
 148. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105272
 149. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105327
 150. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105357
 151. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105358
 152. https://www.google.co.in/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0ahukewiugkxcx-fkahxic44khttpdyuqfggjmae&url=http://www.ons.gov.uk/ons/guide-method/ukcemga/ukcemga-publications/publications/archive/from-holt-winters-to-arima-modelling--measuring-the-impact-on-forecasting-errors-for-components-of-quarterly-estimates-of-public-service-output.pdf&usg=afqjcngmyzfvb-_gdss4lktgw4vvzgbc_w&sig2=9pnseabic_4oxc2knwmhnw&cad=rja
 153. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109273
 154. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105332
 155. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105359
 156. http://statsmodels.sourceforge.net/devel/generated/statsmodels.tsa.arima_model.armaresults.predict.html#statsmodels.tsa.arima_model.armaresults.predict
 157. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-113494
 158. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105373
 159. http://discuss.analyticsvidhya.com/t/seasonal-parameter-in-arima-and-adf-test/7385/1
 160. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105619
 161. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-105623
 162. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-106400
 163. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-106425
 164. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-107267
 165. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-107270
 166. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-107299
 167. https://github.com/welch/seasonal
 168. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-107313
 169. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-108176
 170. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-108224
 171. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109243
 172. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109280
 173. http://www.cloga,info/
 174. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109445
 175. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109454
 176. http://www.cloga,info/
 177. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109489
 178. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109660
 179. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109664
 180. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109830
 181. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-110007
 182. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111506
 183. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-109922
 184. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-110390
 185. http://rajherbals.com/arshoher-bawasir-ki-dawa.html
 186. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-110515
 187. http://rajherbals.com/arshoher-bawasir-ki-dawa.html
 188. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-110533
 189. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111065
 190. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111179
 191. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111437
 192. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111435
 193. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111519
 194. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112881
 195. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111507
 196. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111518
 197. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111696
 198. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-111794
 199. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112070
 200. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112152
 201. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112372
 202. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112604
 203. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112764
 204. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112783
 205. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-112798
 206. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-113125
 207. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-113228
 208. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-113333
 209. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-113624
 210. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-113719
 211. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-113723
 212. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-114036
 213. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-114897
 214. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-115111
 215. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-115149
 216. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-115299
 217. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-115462
 218. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-116262
 219. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-116483
 220. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-116715
 221. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/#comment-116749
 222. https://datahack.analyticsvidhya.com/user/profile/srk
 223. https://datahack.analyticsvidhya.com/user/profile/mark12
 224. https://datahack.analyticsvidhya.com/user/profile/nilabha
 225. https://datahack.analyticsvidhya.com/user/profile/nitish007
 226. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 227. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 228. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 229. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 230. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 231. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 232. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 233. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 234. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 235. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 236. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 237. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 238. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 239. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 240. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 241. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 242. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 243. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 244. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 245. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 246. http://www.analyticsvidhya.com/about-me/
 247. https://www.analyticsvidhya.com/about-me/team/
 248. https://www.analyticsvidhya.com/career-analytics-vidhya/
 249. https://www.analyticsvidhya.com/contact/
 250. https://www.analyticsvidhya.com/about-me/write/
 251. http://www.analyticsvidhya.com/about-me/
 252. https://www.analyticsvidhya.com/about-me/team/
 253. https://www.analyticsvidhya.com/about-me/team/
 254. https://www.analyticsvidhya.com/about-me/team/
 255. https://www.analyticsvidhya.com/career-analytics-vidhya/
 256. https://www.analyticsvidhya.com/about-me/team/
 257. https://www.analyticsvidhya.com/contact/
 258. https://www.analyticsvidhya.com/blog
 259. https://datahack.analyticsvidhya.com/
 260. https://discuss.analyticsvidhya.com/
 261. https://www.analyticsvidhya.com/jobs/
 262. https://datahack.analyticsvidhya.com/users/
 263. https://www.analyticsvidhya.com/corporate/
 264. https://trainings.analyticsvidhya.com/
 265. https://datahack.analyticsvidhya.com/
 266. https://www.analyticsvidhya.com/contact/
 267. https://www.analyticsvidhya.com/contact/
 268. https://datahack.analyticsvidhya.com/signup/
 269. https://www.facebook.com/analyticsvidhya/
 270. https://www.facebook.com/analyticsvidhya/
 271. https://twitter.com/analyticsvidhya
 272. https://twitter.com/analyticsvidhya
 273. https://plus.google.com/+analyticsvidhya
 274. https://in.linkedin.com/company/analytics-vidhya
 275. https://in.linkedin.com/company/analytics-vidhya
 276. https://www.analyticsvidhya.com/privacy-policy/
 277. https://www.analyticsvidhya.com/terms/
 278. https://www.analyticsvidhya.com/refund-policy/
 279. https://id.analyticsvidhya.com/accounts/signup/
 280. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 281. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 283. https://www.facebook.com/analyticsvidhya
 284. https://twitter.com/analyticsvidhya
 285. https://plus.google.com/+analyticsvidhya/posts
 286. https://in.linkedin.com/company/analytics-vidhya
 287. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/1.-dfuller-ts.png
 288. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/2.-dfuller-smooth-1.png
 289. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/3.-dfuller-smooth-2.png
 290. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/4.-dfuller-diff.png
 291. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/5.-dfuller-decompose.png
 292. https://www.analyticsvidhya.com/wp-content/uploads/2016/02/21.-check-output.png
 293. https://datahack.analyticsvidhya.com/contest/genpact-machine-learning-hackathon-1/?utm_source=complete-tutorial-learn-data-science-python-scratch-2&utm_medium=blog
 294. https://www.analyticsvidhya.com/blog/2016/02/hand-learn-time-series-3-hours-mini-datahack/
 295. https://www.analyticsvidhya.com/blog/2016/02/secrets-winners-signature-hackathon-last-man-standing/
 296. https://www.analyticsvidhya.com/blog/author/aarshay/
 297. https://www.analyticsvidhya.com/cdn-cgi/l/email-protection#dbbabaa9a8b3baa2b1bab2b59bbcb6bab2b7f5b8b4b6
 298. https://in.linkedin.com/in/aarshayjain
 299. https://github.com/aarshayj
 300. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/aarshay
 301. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 302. https://www.facebook.com/analyticsvidhya/
 303. https://twitter.com/analyticsvidhya
 304. https://plus.google.com/+analyticsvidhya
 305. https://plus.google.com/+analyticsvidhya
 306. https://in.linkedin.com/company/analytics-vidhya
 307. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 308. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 309. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 310. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 311. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 312. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 313. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 314. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 315. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 316. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 317. javascript:void(0);
 318. javascript:void(0);
 319. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 320. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 321. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 322. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 323. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 324. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 325. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 326. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 327. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 328. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f02%2ftime-series-forecasting-codes-python%2f&linkname=complete%20guide%20to%20create%20a%20time%20series%20forecast%20%28with%20codes%20in%20python%29
 329. javascript:void(0);
 330. javascript:void(0);
