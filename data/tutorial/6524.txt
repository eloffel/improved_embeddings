   #[1]giuseppe bonaccorso    feed [2]giuseppe bonaccorso    comments feed
   [3]giuseppe bonaccorso    pca with rubner-tavan networks comments feed
   [4]alternate [5]alternate

[6]giuseppe bonaccorso

   artificial intelligence     machine learning     data science
   (button)

     * [7]blog
     * [8]books
     * [9]resume / cv
     * [10]bonaccorso   s law
     * [11]essays
     * [12]contact
     * [13]testimonials
     * [14]gallery
     * [15]disclaimer

     * [16]blog
     * [17]books
     * [18]resume / cv
     * [19]bonaccorso   s law
     * [20]essays
     * [21]contact
     * [22]testimonials
     * [23]gallery
     * [24]disclaimer

pca with rubner-tavan networks

   [25]09/25/201712/04/2017[26]deep learning, [27]machine learning,
   [28]machine learning algorithms addenda, [29]neural networks,
   [30]python[31]no comments

   one of the most interesting effects of [32]pca (principal component
   analysis) is to decorrelate the input covariance matrix c, by computing
   the eigenvectors and operating a base change using a matrix v:


   the eigenvectors are sorted in descending order considering the
   corresponding eigenvalue, therefore cpca is a diagonal matrix where the
   non-null elements are   1 >=   2 >=   3 >=     >=   n. by selecting the top p
   eigenvalues, it   s possible to operate a id84 by
   projecting the samples in the new sub-space determined by the p top
   eigenvectors (it   s possible to use gram-schmidt orthoid172 if
   they don   t have a unitary length). the standard pca procedure works
   with a bottom-up approach, obtaining the decorrelation of c as a final
   effect, however, it   s possible to employ neural networks, imposing this
   condition as an optimization step. one the most effective model has
   been proposed by rubner and tavan (and it   s named after them). its
   generic structure is:

   where we suppose that n (input-dimensionality) << m
   (output-dimensionality). the output of the network can be computed as:


   where v (n    n) is a lower-triangular matrix with all diagonal elements
   to 0 and w has a shape (n    m). moreover, it   s necessary to store the
   y(t) in order to compute y(t+1). this procedure must be repeated until
   the output vector has been stabilized. in general after k < 10
   iterations, the modifications are under a threshold of 0.0001, however,
   it   s important to check this value in every real application.

   the training process is managed with two update rules:

   the first one is hebbian based on the oja   s rule, while the second is
   anti-hebbian because its purpose is to reduce the correlation between
   output units. in fact, without the id172 factor, the update is
   in the form dw = -  y(i)y(k), so to reduce the synaptic weight when two
   output units are correlated (same sign).

   if the matrix v is kept upper-triangular, it   s possible to vectorize
   the process. there are also other variants, like the f  ldi  k network,
   which adopts a symmetric v matrix, so to add the contribution of all
   other units to y(i). however, the rubner-tavan model seems more similar
   to the process adopted in a sequential pca, where the second component
   is computed as orthogonal to the first and so forth until the last one.

   the example code is based on the mnist dataset provided by scikit-learn
   and adopts a fixed a number of cycles to stabilize the output. the code
   is also available in this [33]gist:
   view the code on [34]gist.

   see also:

[35]ml algorithms addendum: hebbian learning     giuseppe bonaccorso

     hebbian learning is one the most famous learning theories, proposed
     by the canadian psychologist donald hebb in 1949, many years before
     his results were confirmed through neuroscientific experiments.

share:

     * [36]click to share on twitter (opens in new window)
     * [37]click to share on facebook (opens in new window)
     * [38]click to share on linkedin (opens in new window)
     * [39]click to share on pocket (opens in new window)
     * [40]click to share on tumblr (opens in new window)
     * [41]click to share on reddit (opens in new window)
     * [42]click to share on pinterest (opens in new window)
     * [43]click to share on skype (opens in new window)
     * [44]click to share on whatsapp (opens in new window)
     * [45]click to share on telegram (opens in new window)
     * [46]click to email this to a friend (opens in new window)
     * [47]click to print (opens in new window)
     *

you can also be interested in these articles:

   [48]hebb[49]neural networks[50]pca[51]python[52]scikit-learn

post navigation

   [53]hopfield networks addendum: brain-state-in-a-box model
   [54]linearly separable? no? for me it is! a brief introduction to
   kernel methods

leave a reply [55]cancel reply

   iframe: [56]jetpack_remote_comment

follow me

     * [57]linkedin
     * [58]twitter
     * [59]facebook
     * [60]github
     * [61]instagram
     * [62]amazon
     * [63]medium
     * [64]rss

search articles

   ____________________ (button)

latest blog posts

     * [65]machine learning algorithms     second edition 08/28/2018
     * [66]recommendations and user-profiling from implicit feedbacks
       07/10/2018
     * [67]are recommendations really helpful? a brief non-technical
       discussion 06/29/2018
     * [68]a book that every data scientist should read 06/22/2018
     * [69]mastering machine learning algorithms 05/24/2018

subscribe to this blog

   join 2,190 other subscribers

   email ____________________

   subscribe

follow me on twitter

   [70]my tweets

   copyright    2019 [71]giuseppe bonaccorso. all rights reserved.
   [72]privacy policy - [73]cookie policy

   send to email address ____________________ your name
   ____________________ your email address ____________________
   _________________________ loading send email [74]cancel
   post was not sent - check your email addresses!
   email check failed, please try again
   sorry, your blog cannot share posts by email.

references

   visible links
   1. https://www.bonaccorso.eu/feed/
   2. https://www.bonaccorso.eu/comments/feed/
   3. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/feed/
   4. https://www.bonaccorso.eu/wp-json/oembed/1.0/embed?url=https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/
   5. https://www.bonaccorso.eu/wp-json/oembed/1.0/embed?url=https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/&format=xml
   6. https://www.bonaccorso.eu/
   7. https://www.bonaccorso.eu/blog/
   8. https://www.bonaccorso.eu/books/
   9. https://www.bonaccorso.eu/resume/
  10. https://www.bonaccorso.eu/bonaccorso-law/
  11. https://www.bonaccorso.eu/ai-cognitive-pychology-essays-italian/
  12. https://www.bonaccorso.eu/contact/
  13. https://www.bonaccorso.eu/testimonials/
  14. https://www.bonaccorso.eu/gallery/
  15. https://www.bonaccorso.eu/disclaimer/
  16. https://www.bonaccorso.eu/blog/
  17. https://www.bonaccorso.eu/books/
  18. https://www.bonaccorso.eu/resume/
  19. https://www.bonaccorso.eu/bonaccorso-law/
  20. https://www.bonaccorso.eu/ai-cognitive-pychology-essays-italian/
  21. https://www.bonaccorso.eu/contact/
  22. https://www.bonaccorso.eu/testimonials/
  23. https://www.bonaccorso.eu/gallery/
  24. https://www.bonaccorso.eu/disclaimer/
  25. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/
  26. https://www.bonaccorso.eu/category/machine-learning/deep-learning/
  27. https://www.bonaccorso.eu/category/machine-learning/
  28. https://www.bonaccorso.eu/category/machine-learning/machine-learning-algorithms-addenda/
  29. https://www.bonaccorso.eu/category/machine-learning/neural-networks/
  30. https://www.bonaccorso.eu/category/software/python/
  31. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/#comments
  32. https://en.wikipedia.org/wiki/principal_component_analysis
  33. https://gist.github.com/giuseppebonaccorso/2e015210f7e8f4a57996883be300aa5a
  34. https://gist.github.com/giuseppebonaccorso/2e015210f7e8f4a57996883be300aa5a
  35. https://www.bonaccorso.eu/2017/08/21/ml-algorithms-addendum-hebbian-learning/
  36. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=twitter
  37. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=facebook
  38. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=linkedin
  39. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=pocket
  40. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=tumblr
  41. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=reddit
  42. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=pinterest
  43. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=skype
  44. https://api.whatsapp.com/send?text=pca with rubner-tavan networks https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/
  45. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=telegram
  46. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/?share=email
  47. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/#print
  48. https://www.bonaccorso.eu/tag/hebb/
  49. https://www.bonaccorso.eu/tag/neural-networks/
  50. https://www.bonaccorso.eu/tag/pca/
  51. https://www.bonaccorso.eu/tag/python/
  52. https://www.bonaccorso.eu/tag/scikit-learn/
  53. https://www.bonaccorso.eu/2017/09/22/hopfield-networks-addendum-brain-state-box-model/
  54. https://www.bonaccorso.eu/2017/09/28/linearly-separable-no-for-me-it-is-a-brief-introduction-to-kernel-methods/
  55. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/#respond
  56. https://jetpack.wordpress.com/jetpack-comment/?blogid=100107841&postid=1424&comment_registration=0&require_name_email=1&stc_enabled=1&stb_enabled=1&show_avatars=1&avatar_default=gravatar_default&greeting=leave+a+reply&greeting_reply=leave+a+reply+to+%s&color_scheme=light&lang=en_us&jetpack_version=7.0.1&show_cookie_consent=10&has_cookie_consent=0&sig=473fcdb2a88fa68bb119f59b46ddd00a1a838828#parent=https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/
  57. https://www.linkedin.com/in/giuseppebonaccorso/
  58. https://twitter.com/giuseppeb/
  59. https://www.facebook.com/giuseppe.bonaccorso/
  60. https://github.com/giuseppebonaccorso/
  61. https://www.instagram.com/giuseppebonaccorso/
  62. https://www.amazon.com/author/giuseppebonaccorso
  63. https://medium.com/@giuseppe.bonaccorso
  64. https://www.bonaccorso.eu/feed/
  65. https://www.bonaccorso.eu/2018/08/28/machine-learning-algorithms-second-edition/
  66. https://www.bonaccorso.eu/2018/07/10/recommendations-user-profiling-implicit-feedbacks/
  67. https://www.bonaccorso.eu/2018/06/29/recommendations-really-helpful-brief-non-technical-discussion/
  68. https://www.bonaccorso.eu/2018/06/22/a-book-that-every-data-scientist-should-read/
  69. https://www.bonaccorso.eu/2018/05/24/mastering-machine-learning-algorithms/
  70. https://twitter.com/giuseppeb
  71. https://www.bonaccorso.eu/
  72. https://www.iubenda.com/privacy-policy/331721
  73. https://www.iubenda.com/privacy-policy/331721/cookie-policy
  74. https://www.bonaccorso.eu/2017/09/25/pca-rubner-tavan-networks/#cancel

   hidden links:
  76. https://www.bonaccorso.eu/category/machine-learning/machine-learning-algorithms-addenda/
