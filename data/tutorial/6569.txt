   #[1]rss

[2]thiago marzag  o

   data, code, etc

     * [3]home
     * [4]about
     * [5]publications
     * [6]code
     * [7]talks & slides
     * [8]teaching
     * [9]committees
     * [10]resources
     * [11]index

webscraping with selenium - part 2

   14 nov 2013

   in [12]part 1 we learned how to locate page elements and how to
   interact with them. here we will learn how to do deal with dynamic
   names and how to download things with selenium.

   handling dynamic names

   in part 1 we submitted a search on lexisnexis academic. we will now
   retrieve the search results.

   the results page of lexisnexis academic looks like this:

   our first task is to switch to the default frame of the page.
browser.switch_to_default_content()

   now we need to click the    download documents    button (it   s the one that
   looks like a floppy disk; it   s right above the search results). we
   already know how to do that with selenium: right-click the element,
   inspect its html code, scroll up to see what frame contains it, use all
   this information to locate the element and interact with it. we   ve
   learned all that in part 1. by following that recipe we find that the
      download documents    button is inside the frame named
      fr_resultsnav~resultsmaxgrouptemplate0.6175091262270153   , which in
   turn is inside the frame named    mainframe   . so our first instinct is to
   do this:
browser.switch_to_frame('mainframe')
browser.switch_to_frame('fr_resultsnav~resultsmaxgrouptemplate0.6175091262270153
')
browser.find_element_by_css_selector('img[alt=\"download documents\"]').click()

   except it won   t work here.

   here is the problem: that
   fr_resultsnav~resultsmaxgrouptemplate0.6175091262270153 frame has a
   different name every time you do a new search. so your code will miss
   it and crash (which is precisely what lexisnexis wants to happen, since
   they don   t care for webscrapers).

   what are we to do then? here the solution is simple. that frame name
   always changes, but only partially: it always begins with
   fr_resultsnav. so we can look for the frame that contains fr_resultsnav
   in its name.
browser.switch_to_frame('mainframe')
dyn_frame = browser.find_element_by_xpath('//frame[contains(@name, "fr_resultsna
v")]')

   our dyn_frame object contains the full frame name as an attribute,
   which we can then extract and store.
framename = dyn_frame[0].get_attribute('name')

   now we can finally move to that frame and click the    download
   documents    button.
browser.switch_to_frame(framename)
browser.find_element_by_css_selector('img[alt=\"download documents\"]').click()

   great! we have solved the dynamic name problem.

   notice the sequence here: first we move to    mainframe    and then we move
   to fr_resultsnav~resultsmaxgrouptemplate   . the sequence is important:
   we need to move to the parent frame before we can move to the child
   frame. if we try to move to fr_resultsnav~resultsmaxgrouptemplate   
   directly that won   t work.

   now, what if the entire name changed? what would we do then?

   in that case we could use the position of the frame. if you inspect the
   html code of the page you will see that inside    mainframe    we have
   eight different frames and that fr_resultsnav~resultsmaxgrouptemplate   
   is the 6th. as long as that position remains constant we can do this:
browser.switch_to_frame('mainframe.5.child')
browser.find_element_by_css_selector('img[alt=\"download documents\"]').click()

   in other words, we can switch to a frame based on its position. here we
   are selecting the 6th child frame of    mainframe    - whatever its name
   is. (as it is usually the case in python the indexing starts from zero,
   so the index of the 6th item is 5, not 6).

   switching windows

   once we click the    download documents    button lexisnexis will launch a
   pop-up window.

   we need to navigate to that window. to do that we will need the
   browser.window_handles object, which (as its name suggests) contains
   the handles of all the open windows. the pop-up window we want is the
   second window we opened in the browser, so its index is 1 in the
   browser.window_handles object (remember, python indexes from zero).
   switching windows, in turn, is similar to switching frames:
   browser.switch_to_window(). putting it all together:
browser.switch_to_window(browser.window_handles[1])

   that pop-up window contains a bunch of forms and buttons, but all we
   want to do here is choose the format in which we want our results to
   be. let   s say we want them to be in a plain text file.
browser.find_element_by_xpath('//select[@id="delfmt"]/option[text()="text"]').cl
ick()

   finally we click the    download    button.
browser.find_element_by_css_selector('img[alt=\"download\"]').click()

   so far so good.

   downloading with selenium

   once we click the    download    button lexisnexis shoves all the search
   results into a file and gives us a link to it.

   now we are in a bit of a pickle. let me explain why.

   when you click that link (whether manually or programmatically) your
   browser opens a dialog box asking you where you want to save that file.
   that is a problem here because selenium can make your browser interact
   with webpages but cannot make your browser interact with itself. in
   other words, selenium cannot make your browser change its bookmarks,
   switch to incognito mode, or (what matters here) interact with dialog
   boxes.

   i know, this sounds preposterous, but here is a bit of context:
   selenium was conceived as a testing tool, not as a webscraping tool.
   selenium   s primary purpose is to help web developers automate tests on
   the sites they develop. now, web developers can only control what the
   website does; they cannot control how your computer reacts when you
   click a download link. so to web developers it doesn   t matter that
   selenium can   t interact with dialog boxes.

   in other words, selenium wasn   t created for us. it   s a great
   webscraping tool - the best one i   ve found so far. i can   t imagine how
   you would even submit a search on lexisnexis using urllib or httplib,
   let alone retrieve the search results. but, yes, we are not selenium   s
   target audience. but just hang in there and everything will be
   allright.

   ok, enough context - how can we solve the problem? there are a number
   of solutions (some better than the others) and i will talk about each
   of them in turn.

   solution #1: combine lexisnexis with some os command

   if you are on a linux system you can simply use wget to get the file.
   wget is not a python module, it is a linux command for getting files
   from the web. for instance, to download r   s source code you open the
   terminal and do
wget http://cran.stat.ucla.edu/src/base/r-3/r-3.0.2.tar.gz

   the trick here is to find the url behind the link lexisnexis generates.
   that link is dynamically generated, so it changes every time we do a
   new search. it looks like this:
<a href="/lnacui2api/delivery/downloaddoc.do?filesize=5000&amp;dnldfilepath=%2fl
-n%2fshared%2fprod%2fdiscus%2fqds%2frepository%2fdocs%2f6%2f43%2f2827%3a43673043
6%2fformatted_doc&amp;zipdelivery=false&amp;dnldfilename=all_english_language_ne
ws2013-11-12_22-26.txt&amp;jobhandle=2827%3a436730436">all_english_language_news
2013-11-12_22-26.txt</a>

   if you stare at this html code long enough you will see some structure
   in it. yes, it changes every time we do a new search, but some parts of
   it change in a predictable way. the news source
   (all_english_language_news) is always there. so are the date
   (   2013-11-12   ) and the hour (   22-26   ) of the request. and so is the
   file extension (   .txt   ). we can use this structure to retrieve the url.
   for instance, we can use the    .txt    extension to do that, like this:
results_url = browser.find_element_by_partial_link_text('.txt').get_attribute('h
ref')

   now we have our url. on to wget then. this is an os command, so first
   we need to import python   s os module.
import os # this line should go in the beginning of your script, for good style

   now we execute wget.
os.system('wget {}'.format(results_url))

   and voil  , the file is downloaded to your computer.

   if you are on a mac you can use curl instead (or install wget from
   macports). there must be something similar for windows as well, just
   google around a bit.

   i know, platform-specific solutions are bad. i tried using urllib2 and
   requests but that didn   t work. what i got back was not the text file i
   had requested but some html gibberish instead.

   solution #2: set a default download folder

   this one doesn   t always work. i only show it for the sake of
   completeness.

   here you set a default download folder. that way the browser will
   automatically send all downloads to that folder, without opening up any
   dialog boxes (in theory, at least). here is the code:
chrome_options = webdriver.chromeoptions()
prefs = {'download.default_directory': '/users/yourname/desktop/lexisnexis_resul
ts/'}
chrome_options.add_experimental_option('prefs', prefs)
browser = webdriver.chrome(executable_path = path_to_chromedriver, chrome_option
s = chrome_options)

   (i stole this code from [13]here.)

   it looks like a great solution, but often it simply doesn   t work at
   all. i   ve had trouble with it in chrome and i   ve also had trouble with
   a similar solution for firefox.

   this is not surprising. the chromeoptions capability is an experimental
   feature, as the code itself tells us (check the third line). remember:
   selenium wasn   t originally conceived for webscrapers, so it can   t make
   the browser interact with itself. the chromeoptions capability was not
   created by the selenium folks but by the chromedriver folks. hopefully
   these tools will eventually become reliable but we are not quite there
   yet.

   you may be thinking    what if i set the browser   s preferences manually?   
   it doesn   t work. the preferences you set manually are saved under your
   user profile and they are loaded every time you launch the browser but
   ignored when selenium launches the browser. so, no good (believe me,
   i   ve tried it).

   solution #3: improve selenium

   if you are feeling adventurous you could add download capabilities to
   selenium yourself. [14]this guy did it (he also argues that people
   shouldn   t download anything with selenium in the first place but he is
   talking to web developers, not to webscrapers, so never mind that). he
   uses java but i suppose that a python equivalent shouldn   t be too hard
   to produce.

   alas, that solution has 171 lines of code whereas the wget solution has
   only one line of code (two if you count import os), so i never bothered
   trying. but just because i was happy to settle for a quick-and-dirty
   workaround doesn   t mean everyone will be.

   solution #4: just don   t download at all

   if you happen to be webscraping lexisnexis academic there is yet
   another way: just have lexisnexis email the search results to you.

   code-wise there isn   t much novelty here. these lines remain the same:
browser.switch_to_default_content()
browser.switch_to_frame('mainframe')
dyn_frame = browser.find_element_by_xpath('//frame[contains(@name, "fr_resultsna
v")]')
framename = dyn_frame[0].get_attribute('name')
browser.switch_to_frame(framename)

   but then we click the    email documents    button instead of the    download
   documents    button.
browser.find_element_by_css_selector('img[alt=\"email documents\"]').click()

   we get a pop-up window very similar to the one we saw before.

   we switch to the new window.
browser.switch_to_window(browser.window_handles[1])

   we ask that the document be sent as an attachment and that it be in
   plain text format.
browser.find_element_by_xpath('//select[@id="sendas"]/option[text()="attachment"
]').click()
browser.find_element_by_xpath('//select[@id="delfmt"]/option[text()="text"]').cl
ick()

   we enter our email address.
browser.find_element_by_name('emailto').clear()
browser.find_element_by_name('emailto').send_keys('youremail@somedomain.com')

   we create a little note to help us remember what this search is about.
browser.find_element_by_id('emailnote').clear()
browser.find_element_by_id('emailnote').send_keys('balloon')

   and finally we send it.
browser.find_element_by_css_selector('img[alt=\"send\"]').click()

   that   s it. no platform-specific commands, no experimental features. the
   downside of this solution is that it is lexisnexis-specific.

   this is it for now. on the next post we will cover error handling (if
   you are coding along and getting error messages like
   nosuchelementexception or nosuchframeexception just hang in there; for
   now you can just add a time.sleep(15) statement before each window
   opens and that should do it; but i will show you better solutions). i
   will also show you how to make your code work for any number of search
   results in lexisnexis (the code we   ve seen so far only works when the
   number of results is 1 to 500; if there are 0 results or 500+ results
   the code will crash). in later posts we will cover some advanced
   topics, like using phantomjs as a browser.

   ([15]part 3)
   please enable javascript to view the [16]comments powered by disqus.

references

   visible links
   1. http://thiagomarzagao.com/atom.xml
   2. http://thiagomarzagao.com/
   3. http://thiagomarzagao.com/
   4. http://thiagomarzagao.com/about/
   5. http://thiagomarzagao.com/publications/
   6. http://thiagomarzagao.com/code/
   7. http://thiagomarzagao.com/talks & slides/
   8. http://thiagomarzagao.com/teaching/
   9. http://thiagomarzagao.com/committees/
  10. http://thiagomarzagao.com/resources/
  11. http://thiagomarzagao.com/index/
  12. http://thiagomarzagao.com/2013/11/12/webscraping-with-selenium-part-1/
  13. http://stackoverflow.com/questions/18026391/setting-chrome-preferences-w-selenium-webdriver-in-python/19024814#19024814
  14. http://ardesco.lazerycode.com/index.php/2012/07/how-to-download-files-with-selenium-and-why-you-shouldnt/
  15. http://thiagomarzagao.com/2013/11/15/webscraping-with-selenium-part-3/
  16. https://disqus.com/?ref_noscript

   hidden links:
  18. http://imgur.com/yi8rmqn
  19. http://imgur.com/zo3f2gx
  20. http://imgur.com/rout7nh
  21. http://imgur.com/aqjaqnr
