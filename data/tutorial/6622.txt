   #[1]betterexplained    feed [2]betterexplained    comments feed
   [3]betterexplained    understanding id47 with ratios comments
   feed

   [4]betterexplained betterexplained
   ____________________
      
   menu

     * [5]home
     * [6]all articles
     * [7]popular
     * [8]calculus guide
     * [9]contact
     * [10]newsletter
     * [11]about
     * [12]feedback

   ____________________
      

understanding id47 with ratios

   [13]home   [14]math   understanding id47 with ratios

   my [15]first intuition about id47 was    take evidence and
   account for false positives   . does a lab result mean you   re sick? well,
   how rare is the disease, and how often do healthy people test positive?
   misleading signals must be considered.

   this helped me muddle through practice problems, but i couldn   t think
   with bayes. the big obstacles:

   percentages are hard to reason with. odds compare the relative
   frequency of scenarios (a:b) while percentages use a part-to-whole
      global scenario    [a/(a+b)]. a coin has equal odds (1:1) or a 50%
   chance of heads. great. what happens when heads are 18x more likely?
   well, the odds are 18:1, can you rattle off the decimal percentage?
   (i   ll wait   ) odds require less computation, so let   s start with them.

   equations miss the big picture. here   s id47, as typically
   presented:

   \displaystyle{\displaystyle{\pr(\mathrm{a}|\mathrm{x}) =
   \frac{\pr(\mathrm{x}|\mathrm{a})\pr(\mathrm{a})}{\pr(\mathrm{x|a})\pr(a
   )+ \pr(\mathrm{x|\sim a})\pr(\sim a)}}}

   it reads right-to-left, with a mess of conditional probabilities. how
   about this version:
original odds * evidence adjustment = new odds

   bayes is about starting with a guess (1:3 odds for rain:sunshine),
   taking evidence (it   s july in the sahara, sunshine 1000x more likely),
   and updating your guess (1:3000 chance of rain:sunshine). the    evidence
   adjustment    is how much better, or worse, we feel about our odds now
   that we have extra information (if it were december in seattle, you
   might say rain was 1000x as likely).

   let   s start with ratios and sneak up to the complex version.

caveman statistician og

   og just finished his caved program, and runs statistical research for
   his tribe:
     * he saw 50 deer and 5 bears overall (50:5 odds)
     * at night, he saw 10 deer and 4 bears (10:4 odds)

   what can he deduce? well,
original odds * evidence adjustment = new odds

   or
evidence adjustment = new odds / original odds

   at night, he realizes deer are 1/4 as likely as they were previously:
10:4 / 50:5 = 2.5 / 10 = 1/4

   (put another way, bears are 4x as likely at night)

   let   s cover ratios a bit. a:b describes how much a we get for every b
   (imagine miles per gallon as the ratio miles:gallon). compare values
   with division: going from 25:1 to 50:1 means you doubled your
   efficiency (50/25 = 2). similarly, we just discovered how our    deers
   per bear    amount changed.

   og happily continues his research:
     * by the river, bears are 20x more likely (he saw 2 deer and 4 bears,
       so 2:4 / 50:5 = 1:20)
     * in winter, deer are 3x as likely (30 deer and 1 bear, 30:1 / 50:5 =
       3:1)

   he takes a scenario, compares it to the baseline, and computes the
   evidence adjustment.

   caveman clarence subscribes to og   s journal, and wants to apply the
   findings to his forest (where deer:bears are 25:1). suppose clarence
   hears an animal approaching:
     * his general estimate is 25:1 odds of deer:bear
     * it   s at night, with bears 4x as likely => 25:4
     * it   s by the river, with bears 20x as likely => 25:80
     * it   s in the winter, with deer 3x more likely => 75:80

   clarence guesses    bear    with near-even odds (75:80) and tiptoes out of
   there.

   that   s bayes. in fancy language:
     * start with a prior id203, the general odds before evidence
     * collect evidence, and determine how much it changes the odds
     * compute the posterior id203, the odds after updating

bayesian spam filter

   let   s build a [16]spam filter based on og   s bayesian bear detector.

   first, grab a collection of regular and spam email. record how often a
   word appears in each:
             spam      normal
hello          3         3
darling        1         5
buy            3         2
viagra         3         0
...

   (   hello    appears equally, but    buy    skews toward spam)

   we compute odds just like before. let   s assume incoming email has 9:1
   chance of spam, and we see    hello darling   :
     * a generic message has 9:1 odds of spam:regular
     * adjust for    hello    => keep the 9:1 odds (   hello    is equally-likely
       in both sets)
     * adjust for    darling    => 9:5 odds (   darling    appears 5x as often in
       normal emails)
     * final chances => 9:5 odds of spam

   we   re learning towards spam (9:5 odds). however, it   s less spammy than
   our starting odds (9:1), so we let it through.

   now consider a message like    buy viagra   :
     * prior belief: 9:1 chance of spam
     * adjust for    buy   : 27:2 (3:2 adjustment towards spam)
     * adjust for (   viagra   ):    uh oh!

      viagra    never appeared in a normal message. is it a guarantee of spam?

   probably not: we should intelligently adjust for new evidence. let   s
   assume there   s a regular email, somewhere, with that word, and make the
      viagra    odds 3:1. our chances become 27:2 * 3:1 = 81:2.

   now we   re geting somewhere! our initial 9:1 guess shifts to 81:2. now
   is it spam?

   well, how horrible is a false positive?

   81:2 odds imply for every 81 spam messages like this, we   ll incorrectly
   block 2 normal emails. that ratio might be too painful. with more
   evidence (more words or other characteristics), we might wait for
   1000:1 odds before calling a message spam.

exploring id47

   we can check our intuition by seeing if we naturally ask leading
   questions:
     * is evidence truly independent? are there links between animal
       behavior at night and in the winter, or words that appear together?
       sure. we    naively    assume evidence is independent (and yet, in our
       bumbling, create effective filters anyway).
     * how much evidence is enough? is seeing 2 deer & 1 bear the same 2:1
       evidence adjustment as 200 deer and 100 bears?
     * how accurate were the starting odds in the first place? prior
       beliefs change everything. (   a bayesian is one who, vaguely
       expecting a horse, and catching a glimpse of a donkey, strongly
       believes he has seen a mule.   )
     * do absolute probabilities matter? we usually need the most-likely
       theory (   deer or bear?   ), not the global chance of this scenario
       (   what   s the id203 of deers at night in the winter by the
       river vs. bears at night in the winter by the river?   ). many
       bayesian calculations ignore the global probabilities, which cancel
       when dividing, and essentially use an odds-centric approach.
     * can our filter be tricked? a spam message might add chunks of
       normal text to appear innocuous and    poison    the filter. you   ve
       probably seen this yourself.
     * what evidence should we use? let the data speak. email might have
       dozens of characteristics (time of day, message headers, country of
       origin, html tags   ). give every characteristic a likelihood factor
       and let bayes sort    em out.

thinking with ratios and percentages

   the ratio and percentage approaches ask slightly different questions:

   ratios: given the odds of each outcome, how does evidence adjust them?

   id47 ratio examples

   the evidence adjustment just skews the initial odds, piece-by-piece.

   percentages: what is the chance of an outcome after supporting evidence
   is found?

   id47 ratio example as percent

   in the percentage case,
     *    % bears    is the overall chance of a bear appearing anywhere
     *    % bears going to river    is how likely a bear is to trigger the
          river    data point
     *    % bear at river    is the combined chance of having a bear, and it
       going to the river. in stats terms, p(event and evidence) =
       p(event) * p(event implies evidence) = p(event) *
       p(evidence|event). i see conditional probabilities as    chances that
       x implies y    not the twisted    chances of y, given x happened   .

   let   s redo the original [17]cancer example:
     * 1% of the population has cancer
     * 9.6% of healthy people test positive, 80% of people with cancer do

   if you see a positive result, what   s the chance of cancer?

   ratio approach:
     * cancer:healthy ratio is 1:99
     * evidence adjustment: 80/100 : 9.6/100 = 80:9.6 (80% of sick people
       are    at the river   , and 9.6% of healthy people are).
     * final odds: 1:99 * 80:9.6 = 80:950.4 (roughly 1:12 odds of cancer,
       ~7.7% chance)

   the intuition: the initial 1:99 odds are pretty skewed. even with a
   8.3x (80:9.6) boost from a positive test result, cancer remains
   unlikely.

   percentage approach:
     * cancer chance is 1%
     * chance of true positive = 1% * 80% = .008
     * chance of false positive = 99% * 9.6% = .09504
     * chance of having cancer = .008 / (.008 + .09504) = 7.7%

   when written with percentages, we start from absolute chances. there   s
   a global 0.8% chance of finding a sick patient with a positive result,
   and a global 9.504% chance of a healthy patient with a positive result.
   we then compute the chance these global percentages indicate something
   useful.

   let the approaches be complements: percentages for a bird   s-eye view,
   and ratios for seeing how individual odds are adjusted. we   ll save the
   myriad other interpretations for another day.

   happy math.

other posts in this series

    1. [18]a brief introduction to id203 & statistics
    2. [19]an intuitive (and short) explanation of bayes' theorem
    3. [20]understanding id47 with ratios
    4. [21]understanding the monty hall problem
    5. [22]how to analyze data using the average
    6. [23]understanding the birthday paradox

   [24]77 comments

in this series

    1. [25]a brief introduction to id203 & statistics
    2. [26]an intuitive (and short) explanation of bayes' theorem
    3. [27]understanding id47 with ratios
    4. [28]understanding the monty hall problem
    5. [29]how to analyze data using the average
    6. [30]understanding the birthday paradox

about the site

   betterexplained helps 450k monthly readers with friendly, insightful
   math lessons ([31]more).
   [ins: :ins] [ins: :ins] [ins: :ins] [ins: :ins] [ins: :ins] [ins: :ins]
   [ins: :ins] [ins: :ins]

      if you can't explain it simply, you don't understand it well enough.   
      einstein ([32]more) | [33]privacy | [34]cc-by-nc-sa
   [35]twitter[36]youtube[37]reddit[38]rss

   iframe: [39]https://www.googletagmanager.com/ns.html?id=gtm-82fl

references

   visible links
   1. https://betterexplained.com/feed/
   2. https://betterexplained.com/comments/feed/
   3. https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/feed/
   4. https://betterexplained.com/
   5. https://betterexplained.com/
   6. https://betterexplained.com/archives/
   7. https://betterexplained.com/cheatsheet/
   8. https://betterexplained.com/guides/calculus/
   9. https://betterexplained.com/contact/
  10. https://betterexplained.com/newsletter/
  11. https://betterexplained.com/about/
  12. https://betterexplained.com/feedback/
  13. https://betterexplained.com/
  14. https://betterexplained.com/articles/category/math/
  15. https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/
  16. http://www.paulgraham.com/spam.html
  17. https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/
  18. https://betterexplained.com/articles/a-brief-introduction-to-id203-statistics/
  19. https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/
  20. https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/
  21. https://betterexplained.com/articles/understanding-the-monty-hall-problem/
  22. https://betterexplained.com/articles/how-to-analyze-data-using-the-average/
  23. https://betterexplained.com/articles/understanding-the-birthday-paradox/
  24. https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/#comments
  25. https://betterexplained.com/articles/a-brief-introduction-to-id203-statistics/
  26. https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/
  27. https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/
  28. https://betterexplained.com/articles/understanding-the-monty-hall-problem/
  29. https://betterexplained.com/articles/how-to-analyze-data-using-the-average/
  30. https://betterexplained.com/articles/understanding-the-birthday-paradox/
  31. https://betterexplained.com/about/
  32. https://betterexplained.com/philosophy
  33. https://betterexplained.com/privacy
  34. https://betterexplained.com/about
  35. https://twitter.com/betterexplained
  36. https://www.youtube.com/user/betterexplained
  37. https://reddit.com/r/betterexplained
  38. https://betterexplained.com/feed/
  39. https://www.googletagmanager.com/ns.html?id=gtm-82fl

   hidden links:
  41. https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/
