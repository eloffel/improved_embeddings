   #[1]adam kosiorek

   [2]adam kosiorek

   [3]about

attention in neural networks and how to use it

   oct 14, 2017

   attention mechanisms in neural networks, otherwise known as neural
   attention or just attention, have recently attracted a lot of attention
   (pun intended). in this post, i will try to find a common denominator
   for different mechanisms and use-cases and i will describe (and
   implement!) two mechanisms of soft visual attention.

what is attention?

   informally, a neural attention mechanism equips a neural network with
   the ability to focus on a subset of its inputs (or features): it
   selects specific inputs. let be an input vector, a feature vector, an
   attention vector, an attention glimpse and an attention network with
   parameters . typically, attention is implemented as

   where is element-wise multiplication, while is an output of another
   neural network with parameters . we can talk about soft attention,
   which multiplies features with a (soft) mask of values between zero and
   one, or hard attention, when those values are constrained to be exactly
   zero or one, namely . in the latter case, we can use the hard attention
   mask to directly index the feature vector: (in matlab notation), which
   changes its dimensionality and now with .

   to understand why attention is important, we have to think about what a
   neural network really is: a function approximator. its ability to
   approximate different classes of functions depends on its architecture.
   a typical neural net is implemented as a chain of matrix
   multiplications and element-wise non-linearities, where elements of the
   input or feature vectors interact with each other only by addition.

   attention mechanisms compute a mask which is used to multiply features.
   this seemingly innocent extension has profound implications: suddenly,
   the space of functions that can be well approximated by a neural net is
   vastly expanded, making entirely new use-cases possible. why? while i
   have no proof, the intuition is following: the theory says that
   [4]neural networks are universal function approximators and can
   approximate an arbitrary function to arbitrary precision, but only in
   the limit of an infinite number of hidden units. in any practical
   setting, that is not the case: we are limited by the number of hidden
   units we can use. consider the following example: we would like to
   approximate the product of inputs. a feed-forward neural network can do
   it only by simulating multiplications with (many) additions (plus
   non-linearities), and thus it requires a lot of neural-network real
   estate. if we introduce multiplicative interactions, it becomes simple
   and compact.

   the above definition of attention as multiplicative interactions allow
   us to consider a broader class of models if we relax the constrains on
   the values of the attention mask and let . for example, [5]dynamic
   filter networks (dfn) use a filter-generating network, which computes
   filters (or weights of arbitrary magnitudes) based on inputs, and
   applies them to features, which effectively is a multiplicative
   interaction. the only difference with soft-attention mechanisms is that
   the attention weights are not constrained to lie between zero and one.
   going further in that direction, it would be very interesting to learn
   which interactions should be additive and which multiplicative, a
   concept explored in [6]a differentiable transition between additive and
   multiplicative neurons. the excellent [7]distill blog provides a great
   overview of soft-attention mechanisms.

visual attention

   attention can be applied to any kind of inputs, regardless of their
   shape. in the case of matrix-valued inputs, such as images, we can talk
   about visual attention. let be an image and an attention glimpse i.e.
   the result of applying an attention mechanism to the image .

hard attention

   hard attention for images has been known for a very long time: image
   cropping. it is very easy conceptually, as it only requires indexing.
   let and be coordinates in the image space; hard-attention can be
   implemented in python (or tensorflow) as
g = i[y:y+h, x:x+w]

   the only problem with the above is that it is non-differentiable; to
   learn the parameters of the model, one must resort to e.g. the
   score-function estimator (reinforce), briefly mentioned in my
   [8]previous post.

soft attention

   soft attention, in its simplest variant, is no different for images
   than for vector-valued features and is implemented exactly as in
   equation \ref{att}. one of the early uses of this types of attention
   comes from the paper called [9]show, attend and tell: aa the model
   learns to attend to specific parts of the image while generating the
   word describing that part.

   this type of soft attention is computationally wasteful, however. the
   blacked-out parts of the input do not contribute to the results but
   still need to be processed. it is also over-parametrised: sigmoid
   activations that implement the attention are independent of each other.
   it can select multiple objects at once, but in practice we often want
   to be selective and focus only on a single element of the scene. the
   two following mechanisms, introduced by [10]draw and [11]spatial
   transformer networks, respectively, solve this issue. they can also
   resize the input, leading to further potential gains in performance.

gaussian attention

   gaussian attention works by exploiting parametrised one-dimensional
   gaussian filters to create an image-sized attention map. let and be
   attention vectors, which specify which part of the image should be
   attended to in and axis, respectively. the attention masks can be
   created as .

   hard_gauss in the above figure, the top row shows , the column on the
   right shows and the middle rectangle shows the resulting . here, for
   the visualisation purposes, the vectors contain only zeros and ones. in
   practice, they can be implemented as vectors of one-dimensional
   gaussians. typically, the number of gaussians is equal to the spatial
   dimension and each vector is parametrised by three parameters: centre
   of the first gaussian , distance between centres of consecutive
   gaussians and the standard deviation of the gaussians . with this
   parametrisation, both attention and the glimpse are differentiable with
   respect to attention parameters, and thus easily learnable.

   attention in the above form is still wasteful, as it selects only a
   part of the image while blacking-out all the remaining parts. instead
   of using the vectors directly, we can cast them into matrices and ,
   respectively. now, each matrix has one gaussian per row and the
   parameter specifies distance (in column units) between centres of
   gaussians in consecutive rows. the glimpse is now implemented as

   i used this mechanism in [12]hart, my recent paper on
   biologically-inspired object tracking with id56s with attention. here is
   an example with the input image on the left hand side and the attention
   glimpse on the right hand side; the glimpse shows the box marked in the
   main image in green:
   [full_fig.png] [att_fig.png]

   the code below lets you create one of the above matrix-valued masks for
   a mini-batch of samples in tensorflow. if you want to create , you
   would call it as ay = gaussian_mask(u, s, d, h, h), where u, s, d are
   and , in that order and specified in pixels.
def gaussian_mask(u, s, d, r, c):
    """
    :param u: tf.tensor, centre of the first gaussian.
    :param s: tf.tensor, standard deviation of gaussians.
    :param d: tf.tensor, shift between gaussian centres.
    :param r: int, number of rows in the mask, there is one gaussian per row.
    :param c: int, number of columns in the mask.
    """
    # indices to create centres
    r = tf.to_float(tf.reshape(tf.range(r), (1, 1, r)))
    c = tf.to_float(tf.reshape(tf.range(c), (1, c, 1)))
    centres = u[np.newaxis, :, np.newaxis] + r * d
    column_centres = c - centres
    mask = tf.exp(-.5 * tf.square(column_centres / s))
    # we add eps for numerical stability
    normalised_mask = mask / (tf.reduce_sum(mask, 1, keep_dims=true) + 1e-8)
    return normalised_mask

   we can also write a function to directly extract a glimpse from the
   image:
def gaussian_glimpse(img_tensor, transform_params, crop_size):
    """
    :param img_tensor: tf.tensor of size (batch_size, height, width, channels)
    :param transform_params: tf.tensor of size (batch_size, 6), where params are
  (mean_y, std_y, d_y, mean_x, std_x, d_x) specified in pixels.
    :param crop_size): tuple of 2 ints, size of the resulting crop
    """
    # parse arguments
    h, w = crop_size
    h, w = img_tensor.shape.as_list()[1:3]
    split_ax = transform_params.shape.ndims -1
    uy, sy, dy, ux, sx, dx = tf.split(transform_params, 6, split_ax)
    # create gaussian masks, one for each axis
    ay = gaussian_mask(uy, sy, dy, h, h)
    ax = gaussian_mask(ux, sx, dx, w, w)
    # extract glimpse
    glimpse = tf.matmul(tf.matmul(ay, img_tensor, adjoint_a=true), ax)
    return glimpse

spatial transformer

   spatial transformer (stn) allows for much more general transformation
   that just differentiable image-cropping, but image cropping is one of
   the possible use cases. it is made of two components: a grid generator
   and a sampler. the grid generator specifies a grid of points to be
   sampled from, while the sampler, well, samples. the tensorflow
   implementation is particularly easy in [13]sonnet, a recent neural
   network library from [14]deepmind.
def spatial_transformer(img_tensor, transform_params, crop_size):
    """
    :param img_tensor: tf.tensor of size (batch_size, height, width, channels)
    :param transform_params: tf.tensor of size (batch_size, 4), where params are
  (scale_y, shift_y, scale_x, shift_x)
    :param crop_size): tuple of 2 ints, size of the resulting crop
    """
    constraints = snt.affinewarpconstraints.no_shear_2d()
    img_size = img_tensor.shape.as_list()[1:]
    warper = snt.affinegridwarper(img_size, crop_size, constraints)
    grid_coords = warper(transform_params)
    glimpse = snt.resampler(img_tensor[..., tf.newaxis], grid_coords)
    return glimpse

gaussian attention vs. spatial transformer

   both gaussian attention and spatial transformer can implement a very
   similar behaviour. how do we choose which to use? there are several
   nuances:
     * gaussian attention is an over-parametrised cropping mechanism: it
       requires six parameters, but there are only four degrees of freedom
       (y, x, height width). stn needs only four parameters.
     * i haven   t run any tests yet, but stn should be faster. it relies on
       linear interpolation at sampling points, while the gaussian
       attention has to perform two huge id127s. stn could
       be an order of magnitude faster (in terms of pixels in the input
       image).
     * gaussian attention should be (no tests run) easier to train. this
       is because every pixel in the resulting glimpse can be a convex
       combination of a relatively big patch of pixels of the source
       image, which (informally) makes it easier to find the cause of any
       errors. stn, on the other hand, relies on linear interpolation,
       which means that gradient at every sampling point is non-zero only
       with respect to the two nearest pixels in each axis.

a minimum working example

   let   s create a minimum working example of gaussian attention and stn.
   first, we need to import a few libraries, define sizes and create an
   input image and a crop.
import tensorflow as tf
import sonnet as snt
import numpy as np
import matplotlib.pyplot as plt

img_size = 10, 10
glimpse_size = 5, 5

# create a random image with a square
x = abs(np.random.randn(1, *img_size)) * .3
x[0, 3:6, 3:6] = 1
crop = x[0, 2:7, 2:7] # contains the square

   now, we need placeholders for tensorflow variables.
tf.reset_default_graph()

# placeholders
tx = tf.placeholder(tf.float32, x.shape, 'image')
tu = tf.placeholder(tf.float32, [1], 'u')
ts = tf.placeholder(tf.float32, [1], 's')
td = tf.placeholder(tf.float32, [1], 'd')
stn_params = tf.placeholder(tf.float32, [1, 4], 'stn_params')

   we can now define the tensorflow expression for gaussian attention and
   stn glimpses.
# gaussian attention
gaussian_att_params = tf.concat([tu, ts, td, tu, ts, td], -1)
gaussian_glimpse_expr = gaussian_glimpse(tx, gaussian_att_params, glimpse_size)

# spatial transformer
stn_glimpse_expr = spatial_transformer(tx, stn_params, glimpse_size)

   let   s run those expressions and plot them:
sess = tf.session()

# extract a gaussian glimpse
u = 2
s = .5
d = 1
u, s, d = (np.asarray([i]) for i in (u, s, d))
gaussian_crop = sess.run(gaussian_glimpse_expr, feed_dict={tx: x, tu: u, ts: s,
td: d})

# extract stn glimpse
transform = [.4, -.1, .4, -.1]
transform = np.asarray(transform).reshape((1, 4))
stn_crop = sess.run(stn_glimpse_expr, {tx: x, stn_params: transform})


# plots
fig, axes = plt.subplots(1, 4, figsize=(12, 3))

titles = ['input image', 'crop', 'gaussian att', 'stn']
imgs = [x, crop, gaussian_crop, stn_crop]
for ax, title, img in zip(axes, titles, imgs):
    ax.imshow(img.squeeze(), cmap='gray', vmin=0., vmax=1.)
    ax.set_title(title)
    ax.xaxis.set_visible(false)
    ax.yaxis.set_visible(false)

   attention examples

   you can find a jupyter notebook with the code used to create the above
   [15]here

closing thoughts

   attention mechanisms expand capabilities of neural networks: they allow
   approximating more complicated functions, or in more intuitive terms,
   they enable focusing on specific parts of the input. they have led to
   performance improvements in natural language benchmarks, as well as to
   entirely new capabilities such as image captioning, addressing in
   memory networks and neural programmers.

   i believe that the most important cases in which attention is useful
   have not been discovered yet. for example, we know that objects in
   videos are consistent and coherent, e.g. they do not disappear into
   thin air between frames. attention mechanisms can be used to express
   this consistency prior. how? stay tuned.

share this:

   [16]facebook [17]twitter [18]google+ [19]linkedin
   please enable javascript to view the [20]comments powered by disqus.

     * adam kosiorek
     * [21]adamk@robots.ox.ac.uk

     * [22]github
     * [23]linkedin

   generative timeseries modelling, but also attention, memory and other
   cool tricks.

references

   visible links
   1. http://akosiorek.github.io/feed.xml
   2. http://akosiorek.github.io/
   3. http://akosiorek.github.io/about/
   4. http://www.sciencedirect.com/science/article/pii/0893608089900208
   5. https://arxiv.org/abs/1605.09673
   6. https://arxiv.org/abs/1604.03736
   7. https://distill.pub/2016/augmented-id56s/
   8. http://akosiorek.github.io/ml/2017/09/03/implementing-air.html#estimating-gradients-for-discrete-variables
   9. https://arxiv.org/abs/1502.03044
  10. https://arxiv.org/abs/1502.04623
  11. https://arxiv.org/abs/1506.02025
  12. https://arxiv.org/abs/1706.09262
  13. https://github.com/deepmind/sonnet
  14. https://deepmind.com/
  15. https://github.com/akosiorek/akosiorek.github.io/tree/master/notebooks/attention_glimpse.ipynb
  16. https://www.facebook.com/sharer/sharer.php?u=http://akosiorek.github.io/ml/2017/10/14/visual-attention.html
  17. https://twitter.com/intent/tweet?text=attention in neural networks and how to use it&url=http://akosiorek.github.io/ml/2017/10/14/visual-attention.html
  18. https://plus.google.com/share?url=http://akosiorek.github.io/ml/2017/10/14/visual-attention.html
  19. https://www.linkedin.com/sharearticle?mini=true&url=http://akosiorek.github.io/ml/2017/10/14/visual-attention.html&title=attention in neural networks and how to use it&summary=&source=adam kosiorek
  20. https://disqus.com/?ref_noscript
  21. mailto:adamk@robots.ox.ac.uk
  22. https://github.com/akosiorek
  23. https://linkedin.com/in/adamkosiorek

   hidden links:
  25. http://akosiorek.github.io/ml/2017/10/14/visual-attention.html
