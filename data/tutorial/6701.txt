   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

how to train your self-driving car to steer

a step-by-step guide using small and efficient neural networks and a bit
of magic.

   [16]go to the profile of norman di palo
   [17]norman di palo (button) blockedunblock (button) followfollowing
   oct 10, 2017

   neural networks, and particularly deep learning research, have obtained
   many breakthroughs recently in the field of id161 and other
   important fields in computer science. among many different application,
   one technology that is currently on the rising is self-driving cars.
   everybody has heard of them, all the major company seem to invest
   heavily on this new-millenium gold rush. ai-powered cars that can take
   you anywhere while you spend your time, well, not driving. in this post
   i will show you how to train a neural network to steer autonomously
   using only images of the road ahead. you can find all the code,
   explained step-by-step, in this [18]jupyter notebook. you can also find
   a more detailed paper [19]here.
   [1*azwnjoaf_2vm9qg3dn9exa.jpeg]

   deep neural networks, especially in the field of id161,
   object recognition and so on, have often a lot of parameters, millions
   of them. this means that they   re heavy both computationally that on the
   memory of the device on which they   re running. if you   re an academic
   laboratory or a big company and you have your data centers and tons of
   gpus, that is not a problem. but if you only have an embedded system on
   a car that should drive in real-time, that could be a problem. that   s
   why i will focus on particular architectures that are very slim, fast
   and efficient. the main model that i used is the [20]squeezenet
   architecture. it   s a quite recent model that achieved remarkable
   performances on object recognition tasks with very few parameters, and
   weighting just some megabytes. i suggest to read this story along with
   the code, that is already quite well detailed, to further understand
   the concepts.

   the first thing that we need is a dataset, the core of most deep
   learning projects. luckily, there are a couple of datasets that work
   for us. we mostly need images recorded from hours of human driving into
   different settings (highways, cities). you can find one in the
   notebook. after having the dataset, we need to preprocess the data to
   make our algorithm work better. for example, we certainly cannot load
   the entire dataset into the ram, thus we need to design a generator,
   that is a particularly useful kind of function in python that allows to
   dynamically load a small batch of data, preprocess it, and then output
   it directly into our neural network. to help the network generalize
   better to every possible weather and light condition, we can modify the
   brightness of our images randomly. furthermore, we can crop the top
   slice of our images, since it contains mostly sky and other useless
   information for driving. this helps making the whole computation
   faster.
   [1*r26mcnm1pelpys4lc8dwla.png]
   nvidia model.

   after the preprocessing, we can start designing our networks. i used
   keras for that, making it quite readable. the first model is the nvidia
   model, a quite classical id98. after some convolutional layers, that
   extract visual features from our images, we have a flattening layers
   and then fully connected layers, that outputs a single real-valued
   number: our steering angle. you can see the details of the network in
   the code.

   if you   re training this network on a laptop, especially without gpu
   acceleration, you could need a whole day to train it. (but it   s worth
   the effort. probably.) after this relatively small training, you can
   see how the validation loss decreases remarkably, thus the network is
   really learning how to drive.

   this architecture can work in real-time on a laptop, and has around
   500.000 parameters. but we can do better and make an even smaller
   network. that   s where squeezenet comes along. that particular
   architecture is already slim, and i further shrinked it by lowering the
   number of convolutional features. the core of this architecture is the
   fire module, a very ingenious block of filters that can extract
   semantically important features using very few parameters, and with a
   small output. you can see the details of the network implementation in
   the code. the final layers were modified as well, since our task is a
   regression in the image space, while the network was initially designed
   for object recognition.
   [1*wto6iu1thcxhhccwcr9bhg.png]
   the fire module.

   using the same training setting as before, we can see how the training
   is faster, and the network achieves even better performances after
   around 10 epochs.

   you could argue that here we are predicting the steering angle based
   only on the current frame, while driving is a dynamical task, that
   depends on the previous frames too. that   s why the last model that i
   show here is a recurrent model. i added a recurrent layer to the output
   of one of the first densely connected layers of squeezenet: the network
   now takes as input 5 consecutive frames, and then the recurrent layers
   outputs a single real-valued number, the steering angle. surprisingly,
   the performances of this new architecture, even if it resembles more
   closely the human way of deciding how to steer, are not better compared
   to the previously seen architectures. memory-less and state-less
   architecture can thus drive quite well, computing the steering angle
   from a single frame, independently from others.

   and now, finally, a small video of our network in action. the script
   was taken from this [21]really cool repository. it shows real time
   driving of the car, and the steer is completely controlled by the
   network based on the street that it sees. pretty good, right?
   [1*uz9wn1gmbe83_pocpp4pea.gif]
   our self-driving car in action.

   we   ve trained our self-driving car to steer with quite simple
   architectures and techniques, obtaining remarkable results. i hope
   you   ve learned one trick or two from this post, the code and also the
   paper of the work. feel free to comment or get in touch!

     * [22]machine learning
     * [23]id101
     * [24]self driving cars
     * [25]deep learning
     * [26]artificial intelligence

   (button)
   (button)
   (button) 298 claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   [27]go to the profile of norman di palo

[28]norman di palo

   artificial intelligence and robotics student @ sapienza university of
   rome. currently ai research intern at curious ai, helsinki. twitter:
   [29]@normandipalo

     (button) follow
   [30]towards data science

[31]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 298
     * (button)
     *
     *

   [32]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [33]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/68c3d24bbcb7
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/how-to-train-your-self-driving-car-to-steer-68c3d24bbcb7&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/how-to-train-your-self-driving-car-to-steer-68c3d24bbcb7&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_nwatojeyzdnq---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@normandipalo?source=post_header_lockup
  17. https://towardsdatascience.com/@normandipalo
  18. https://github.com/normandipalo/self-driving-car-beta/blob/master/self-drivng-car-beta-clean.ipynb
  19. https://github.com/normandipalo/self-driving-car-beta/blob/master/selfdrivingcar_latex.pdf
  20. https://arxiv.org/pdf/1602.07360.pdf
  21. https://github.com/sullychen/autopilot-tensorflow
  22. https://towardsdatascience.com/tagged/machine-learning?source=post
  23. https://towardsdatascience.com/tagged/autonomous-cars?source=post
  24. https://towardsdatascience.com/tagged/self-driving-cars?source=post
  25. https://towardsdatascience.com/tagged/deep-learning?source=post
  26. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  27. https://towardsdatascience.com/@normandipalo?source=footer_card
  28. https://towardsdatascience.com/@normandipalo
  29. http://twitter.com/normandipalo
  30. https://towardsdatascience.com/?source=footer_card
  31. https://towardsdatascience.com/?source=footer_card
  32. https://towardsdatascience.com/
  33. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  35. https://medium.com/p/68c3d24bbcb7/share/twitter
  36. https://medium.com/p/68c3d24bbcb7/share/facebook
  37. https://medium.com/p/68c3d24bbcb7/share/twitter
  38. https://medium.com/p/68c3d24bbcb7/share/facebook
