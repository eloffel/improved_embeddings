   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

alphago, in context

   [9]go to the profile of andrej karpathy
   [10]andrej karpathy (button) blockedunblock (button) followfollowing
   may 31, 2017
   [1*b6aizqcgv7jumbzfeepdtg.png]

   update oct 18, 2017: [11]alphago zero was announced. this post refers
   to the previous version. 95% of it still applies.

   i had a chance to talk to several people about the recent [12]alphago
   matches with ke jie and others. in particular, most of the coverage was
   a mix of popular science + pr so the most common questions i   ve seen
   were along the lines of    to what extent is alphago a breakthrough?   ,
      how do researchers in ai see its victories?    and    what implications do
   the wins have?   . i thought i might as well serialize some of my
   thoughts into a post.

the cool parts

   alphago is made up of a number of relatively standard techniques:
   behavior cloning (supervised learning on human demonstration data),
   id23 (reinforce), value functions, and monte carlo
   tree search (mcts). however, the way these components are combined is
   novel and not exactly standard. in particular, alphago uses a sl
   (supervised learning) policy to initialize the learning of an rl
   (id23) policy that gets perfected with self-play,
   which they then estimate a value function from, which then plugs into
   mcts that (somewhat surprisingly) uses the (worse!, but more diverse)
   sl policy to sample rollouts. in addition, the policy/value nets are
   deep neural networks, so getting everything to work properly presents
   its own unique challenges (e.g. value function is trained in a tricky
   way to prevent overfitting). on all of these aspects, deepmind has
   executed very well. that being said, alphago does not by itself use any
   fundamental algorithmic breakthroughs in how we approach rl problems.
   [1*snqpzf8_jhog_npjl_bvhq.png]

on narrowness

   zooming out, it is also still the case that alphago is a narrow ai
   system that can play go and that   s it. the atari-playing agents from
   deepmind do not use the approach taken with alphago. the neural turing
   machine has little to do with alphago. the google datacenter
   improvements definitely do not use alphago. the google search engine is
   not going to use alphago. therefore, alphago does not generalize to any
   problem outside of go, but the people and the underlying neural network
   components do, and do so much more effectively than in the days of old
   ai where each demonstration needed repositories of specialized,
   explicit code.

convenient properties of go

   i wanted to expand on the narrowness of alphago by explicitly trying to
   list some of the specific properties that go has, which alphago
   benefits a lot from. this can help us think about what settings alphago
   does or does not generalize to. go is:
    1. fully deterministic. there is no noise in the rules of the game; if
       the two players take the same sequence of actions, the states along
       the way will always be the same.
    2. fully observed. each player has complete information and there are
       no hidden variables. for example, texas hold   em does not satisfy
       this property because you cannot see the cards of the other player.
    3. the action space is discrete. a number of unique moves are
       available. in contrast, in robotics you might want to instead emit
       continuous-valued torques at each joint.
    4. we have access to a perfect simulator (the game itself), so the
       effects of any action are known exactly. this is a strong
       assumption that alphago relies on quite strongly, but is also quite
       rare in other real-world problems.
    5. each episode/game is relatively short, of approximately 200
       actions. this is a relatively short time horizon compared to other
       rl settings which may involve thousands (or more) of actions per
       episode.
    6. the evaluation is clear, fast and allows a lot of trial-and-error
       experience. in other words, the agent can experience winning/losing
       millions of times, which allows is to learn, slowly but surely, as
       is common with deep neural network optimization.
    7. there are huge datasets of human play game data available to
       bootstrap the learning, so alphago doesn   t have to start from
       scratch.

example: alphago applied to robotics?

   [1*fpwo8wpq2pfrzlqsuvr8qa.png]

   having enumerated some of the appealing properties of go, let   s look at
   a robotics problem and see how well we could apply alphago to, for
   example, an [13]amazon picking challenge robot. it   s a little comical
   to even think about.
     * first, your (high-dimensional, continuous) actions are awkwardly
       /noisily executed by the robot   s motors (1,3 are violated).
     * the robot might have to look around for the items that are to be
       moved, so it doesn   t always sense all the relevant information and
       has to sometimes collect it on demand. (2 is violated)
     * we might have a physics simulator, but these are quite imperfect
       (especially for simulating things like contact forces); this brings
       its own set of non-trivial challenges (4 is violated).
     * depending on how abstract your action space is (raw torques ->
       positions of the gripper), a successful episode can be much longer
       than 200 actions (i.e. 5 depends on the setting). longer episodes
       add to the credit assignment problem, where it is difficult for the
       learning algorithm to distribute blame among the actions for any
       outcome.
     * it would be much harder for a robot to practice (succeed/fail) at
       something millions of times, because we   re operating in the real
       world. one approach might be to parallelize robots, but that can be
       quite expensive. also, a robot failing might involve the robot
       actually damaging itself. another approach would be to use a
       simulator and then transfer to the real world, but this brings its
       own set of new, non-trivial challenges in the domain transfer.
       lastly, in many cases evaluation is very non-trivial. for example,
       how do you automatically evaluate if a robot has succeeded in
       making an omelette? (6 is violated).
     * there is rarely a human data source with millions of demonstrations
       (so 7 is violated).

   in short, basically every single assumption that go satisfies and that
   alphago takes advantage of are violated, and any successful approach
   would look extremely different. more generally, some of go   s properties
   above are not insurmountable with current algorithms (e.g. 1,2,3), some
   are somewhat problematic (5,7), but some are quite critical to how
   alphago is trained but are rarely present in other real-world
   applications (4,6).

in conclusion

   while alphago does not introduce fundamental breakthroughs in ai
   algorithmically, and while it is still an example of narrow ai, alphago
   does symbolize alphabet   s ai power: in both the quantity/quality of the
   talent present in the company, the computational resources at their
   disposal, and the all in focus on ai from the very top.

   alphabet is making a large bet on ai, and it is a safe one. but i   m
   biased :)

   edit: the goal of this post is, as someone on reddit mentioned,
      quelling the ever resilient beliefs of the public that agi is right
   down the road   , and the target audience are people outside of ai who
   were watching alphago and would like a more technical commentary.

     * [14]machine learning
     * [15]alphago
     * [16]baduk
     * [17]artificial intelligence
     * [18]deep learning

   (button)
   (button)
   (button) 2.1k claps
   (button) (button) (button) 16 (button) (button)

     (button) blockedunblock (button) followfollowing
   [19]go to the profile of andrej karpathy

[20]andrej karpathy

   director of ai at tesla. previously research scientist at openai and
   phd student at stanford. i like to train deep neural nets on large
   datasets.

     * (button)
       (button) 2.1k
     * (button)
     *
     *

   [21]go to the profile of andrej karpathy
   never miss a story from andrej karpathy, when you sign up for medium.
   [22]learn more
   never miss a story from andrej karpathy
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/c47718cb95a5
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@karpathy/alphago-in-context-c47718cb95a5&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@karpathy/alphago-in-context-c47718cb95a5&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@karpathy?source=post_header_lockup
  10. https://medium.com/@karpathy
  11. https://deepmind.com/blog/alphago-zero-learning-scratch/
  12. https://www.theverge.com/2017/5/25/15689462/alphago-ke-jie-game-2-result-google-deepmind-china
  13. https://www.youtube.com/watch?v=3klzvwxomqs
  14. https://medium.com/tag/machine-learning?source=post
  15. https://medium.com/tag/alphago?source=post
  16. https://medium.com/tag/baduk?source=post
  17. https://medium.com/tag/artificial-intelligence?source=post
  18. https://medium.com/tag/deep-learning?source=post
  19. https://medium.com/@karpathy?source=footer_card
  20. https://medium.com/@karpathy
  21. https://medium.com/@karpathy
  22. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  24. https://medium.com/p/c47718cb95a5/share/twitter
  25. https://medium.com/p/c47718cb95a5/share/facebook
  26. https://medium.com/p/c47718cb95a5/share/twitter
  27. https://medium.com/p/c47718cb95a5/share/facebook
