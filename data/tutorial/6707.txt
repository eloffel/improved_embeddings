   #[1]natural language processing blog - atom [2]natural language
   processing blog - rss [3]natural language processing blog - atom

   [4]skip to main | [5]skip to sidebar

[6]natural language processing blog

   my biased thoughts on the fields of natural language processing (nlp),
   computational linguistics (cl) and related topics (machine learning,
   math, funding, etc.)

08 november 2016

[7]bias in ml, and teaching ai

   yesterday i gave a super duper high level 12 minutes presentation about
   some issues of bias in ai. i should emphasize (if it's not clear) that
   this is something i am not an expert in; most of what i know is by
   reading great papers by other people (there is a completely
   non-academic sample at the end of this post). this blog post is a
   variant of that presentation.
   structure: most of the images below are prompts for talking points,
   which are generally written below the corresponding image. i think i
   managed to link all the images to the original source (let me know if i
   missed one!).
   automated decision making is part of our lives
   to me, ai is largely the study of automated decision making, and the
   investment therein has been growing at a dramatic rate.
   [8][on_the_rise.jpg]
   [9]source: nature
   i'm currently teaching undergraduate artificial intelligence. the last
   time i taught this class was in 2012. the amount that's changed since
   there is incredible. automated decision making is now a part of
   basically everyone's life, and will only be more so over time. the
   investment is in the billions of dollars per year.
   things can go really badly
   if you've been paying attention to headlines even just over the past
   year, the number of high stakes settings in which automated decisions
   are being made is growing, and growing into areas that dramatically
   affect real people's real life, their well being, their safety, and
   their rights.
   [10][go_badly.png]
   this includes:
     * [11]predictive policing in oakland
     * [12]car systems that are unable to understand women
     * [13]discriminatory advertisements based on racially profiled name
       searches
     * [14]service availability for transportation (shout-out to
       [15]jennifer stark & [16]nick diakopolous here at umd!)
     * [17]housing discrimination (which is straight up illegal)
     * [18]prediction of criminality

   this is obviously just a sample of some of the higher profile work in
   this area, and while all of this is work in progress, even if there's
   no impact today (hard to believe for me) it's hard to imagine that this
   isn't going to be a major societal issue in the very near future.
   three (out of many) source of bias
   for the remainder, i want to focus on three specific ways that bias
   creeps in. the first i'll talk about more because we understand it
   more, and it's closely related to work that i've done over the past ten
   years or so, albeit in a different setting. these three are:
    1. data collection
    2. objective function
    3. feedback loops

   sample selection bias
   the standard way that machine learning works is to take some samples
   from a population you care about, run it through a machine learning
   algorithm, to produce a predictor.
   [19][sel_pop.png]
   the magic of statistics is that if you then take new samples from that
   same population, then, with high id203, the predictor will do a
   good job. this is true for basically all models of machine learning.
   the problem that arises is when your population samples are from a
   subpopulation (or different population) for those on which you're going
   to apply your predictor.
   [20][true_pop.png]
   both of my parents work in marketing research and have spent a lot of
   their respective careers doing focuses groups and surveys. a few years
   ago, my dad had a project working for a european company that made skin
   care products. they wanted to break into the us market, and hired him
   to conduct studies of what the us population is looking for in skin
   care. he told them that he would need to conduct four or five different
   studies to do this, which they gawked at. they wanted one study,
   perhaps in the midwest (cleveland or chicago). the problem is that skin
   care needs are very different in the southwest (moisturizer matters)
   and the northwest (not so much), versus the northeast and southeast.
   doing one study in chicago and hoping it would generalize to arizona
   and georgia is unrealistic.
   this problem is often known as sample selection bias in the statistics
   community. it also has other names, like covariate shift and domain
   adaptation depending on who you talk to.
   [21][heckman_cortes.png]
   one of the most influential pieces of work in this area is the 1979
   econometrica paper by james heckman, for which he won the 2000 nobel
   prize in economics. he's pretty happy about that! if you haven't read
   [22]this paper, you should: it's only about 7 pages long, it's not that
   difficult, and you won't believe the footnote in the last section.
   (sorry for the clickbait, but you really should read the paper.)
   there's been a ton of work in machine learning land over the past
   twenty years, much of which builds on heckman's original work. to
   highlight one specific paper: corinna cortes is the head of google
   research new york and has had a number of excellent papers on this
   topic over the past ten years. one in particular is [23]her 2013 paper
   in theoretical computer science (with mohri) which provides an
   amazingly in depth overview and new algorithms. also a highly
   recommended read.
   it's not just that error rate goes up
   when you move from one sample space (like the southwest) to another
   (like the northeast), you should first expect error rates to go up.
   because i wanted to run some experiments for this talk, here are some
   simple adaptation numbers for predicting sentiment on amazon reviews
   (data due to [24]mark dredze and colleagues). here we have four domains
   (books, dvds, electronics and kitchen appliances) which you should
   think as standins for the different regions of the us, or different
   demographic qualifiers.
   [25][cross_domain.png]
   the figure shows error rates when you train on one domain (columns) and
   test on another (rows). the error rates are normalized so that we have
   ones on the diagonal (actual error rates are about 10%). the
   off-diagonal shows how much additional error you suffer due to sample
   selection bias. in particular, if you're making predictions about
   kitchen appliances and don't train on kitchen appliances, your error
   rate can be more than two times what it would have been.
   but that's not all.
   [26][electronics.png]
   these data sets are balanced: 50% positive, 50% negative. if you train
   on electronics and make predictions on other domains, however, you get
   different false positive/false negative rates. this shows the number of
   test items predicted positively; you should expect it to be 50%, which
   basically is what happens in electronics and dvds. however, if you
   predict on books, you underpredict positives; while if you predict on
   kitchen, you overpredict positives.
   so not only do the error rates go up, but the way they are exhibited
   chances, too. this is closely related to issues of disparate impact,
   which have been studied recently by many people, for instance by
   [27]feldman, friedler, moeller, scheidegger and venkatasubramanian.
   what are we optimizing for
   one thing i've been trying to get undergrads in my ai class to think
   about is what are we optimizing for, and whether the thing that's being
   optimized for is what is best for us.
   [28][map.png]
   one of the first things you learn in a data structures class is how to
   do graph search, using simple techniques like breadth first search. in
   intro ai, you often learn more complex things like id67. a
   standard motivating example is how to find routes on a map, like the
   planning shown above for me to drive from home to work (which i never
   do because i don't have a car and it's slower than metro anyway!).
   we spend a lot of time proving optimality of algorithms in terms of
   shortest path costs, for fixed costs that have been given to us by
   who-knows-where. i challenged my ai class to come up with features that
   one might use to construct these costs. they started with relatively
   obvious things: length of that segment of road, wait time at lights,
   average speed along that road, whether the road is one-way, etc. after
   more pushing, they came up with other ideas, like how much gas mileage
   one gets on that road (either to save the environment or to save
   money), whether the area is    dangerous    (which itself is fraught with
   bias), what is the quality of the road (ill-repaired, new, etc.).
   you can tell that my students are all quite well behaved. i then asked
   them to be evil. suppose you were an evil company, how might you come
   up with path costs. then you get things like: maybe businesses have
   paid me to route more customers past their stores. maybe if you're
   driving the brand of car that my company owns or has invested it, i
   route you along better (or worse) roads. maybe i route you so as to
   avoid billboards from competitors.
   the point is: we don't know, and there's no strong reason to a priori
   assume that what the underlying system is optimizing for is my personal
   best interest. (i should note that i'm definitely not saying that
   google or any other company is doing any of these things: just that we
   should not assume that they're not.)
   [29][crrrcuit.png]
   a more nuanced example is that of a dating application for, e.g.,
   multi-colored robots. you can think of the color as representing any
   sort of demographic information you like: political leaning (as
   suggested by the red/blue choice here), sexual orientation, gender,
   race, religion, etc. for simplicity, let's assume there are way more
   blue robots than others, and let's assume that robots are at least
   somewhat homophilous: they tend to associate with other similar robots.
   if my objective function is something like    maximize number of swipe
   rights,    then i'm going to want to disproportionately show blue robots
   because, on average, this is going to increase my objective function.
   this is especially true when i'm predicting complex behaviors like
   robot attraction and love, and i don't have nearly enough features to
   do anywhere near a perfect matching. because red robots, and robots of
   other colors, are more rare in my data, my bottom line is not affected
   greatly by whether i do a good job making predictions for them or not.
   [30][vc.jpg] [31][palmer.jpg]
   i highly recommend reading [32]version control, a recent novel by
   dexter palmer. i especially recommend it if you have, or will, teach
   ai. it's fantastic.
   there is an interesting vignette that palmer describes (don't worry, no
   plot spoilers) in which a couple engineers build a dating service, like
   crrrcuit, but for people. in this thought exercise, the system's
   objective function is to help people find true love, and they are
   wildly successful. they get investors. the investors realize that when
   their product succeeds, they lose business. this leads to a more
   nuanced objective in which you want to match most people (to maintain
   trust), but not perfectly (to maintain client  le). but then, to make
   money, the company starts selling its data to advertisers. and
   different individuals' data may be more valuable: in particular,
   advertisers might be willing to pay a lot for data from members of
   underrepresented groups. this provides incentive to actively do a worse
   job than usual on such clients. in the book, this thought exercise
   proceeds by human reasoning, but it's pretty easy to see that if one
   set up, say, a id23 algorithm for predicting matches
   that had long term company profit as its objective function, it could
   learn something similar and we'd have no idea that that's what the
   system was doing.
   feedback loops
   [33]r[34]avi shroff recently visited the clip lab and talked about his
   work (with justin rao and shared goel) related to [35]stop and frisk
   policies in new york. the setup here is that the    stop and frisk    rule
   (in 2011, [36]over 685k people were stopped; this has subsequently been
   declared unconstitutional in new york) gave police officers the right
   to stop people with much lower thresholds than probable cause, to try
   to find contraband weapons or drugs. shroff and colleagues focused on
   weapons.
   they considered the following model: a police officer sees someone
   behaving strangely, and decide that they want to stop and frisk that
   person. before doing so, they enter a few values into their computer,
   and the computer either gives a thumbs up (go ahead and stop) or a
   thumbs down (let them live their life). one question was: can we cut
   down on the number of stops (good for individuals) while still finding
   most contraband weapons (good for society)?
   [37][shroff.png]
   in this figure, we can see that if the system thumbs downed 90% of
   stops (and therefore only 10% of people that police would have stopped
   get stopped), they are still able to recover about 50% of the weapons.
   with stopping only about 1/3 of individuals, they are able to recover
   75% of weapons. this is a massive reduction in privacy violations while
   still successfully keeping the majority of weapons off the streets.
   (side note: you might worry about sample selection bias here, because
   the models are trained on people that the policy did actually stop.
   shroff and colleagues get around this by the assumption i stated
   before: the model is only run on people who policy have already decided
   are suspicious and would have stopped and frisked anyway.)
   the question is: what happens if and when such a system is deployed in
   practice?
   the issue is that policy officers, like humans in general, are not
   stationary entities. their behavior changes over time, and it's
   reasonable to assume that their behavior would change when they get
   this new system. they might feed more people into the system (in
      hopes    of thumbs up) or feed fewer people into the system (having
   learned that the system is going to thumbs down them anyway). this is
   similar to how the sorts of queries people issue against web search
   engines change over time, partially because we learn to use the systems
   more effectively, and learn what to not consider asking a search engine
   to do for us because we know it will fail.
   now, once we've (hypothetically) deployed this system, it's collecting
   its own data, which is going to be fundamentally different from the
   data is was originally trained one. it can continually adapt, but we
   need good technology for doing this that takes into account the human
   behavior of the officers.
   wrap up and discussion
   there are many things that i didn't touch on above that i think are
   nonetheless really important. some examples:
    1. all the example    failure    cases i showed above have to do with race
       or (binary) gender. there are other things to consider, like sexual
       orientation, religion, political views, disabilities, family and
       child status, first language, etc. i tried and failed to find
       examples of such things, and would appreciate pointers. for
       instance, i can easily imagine that id103 error rates
       skyrocket when working for users with speech impairments, or with
       non-standard accents, or who speak a dialect of english that not
       the    status quo academic english.    i can also imagine that visual
       tracking of people might fail badly on people with motor
       impairments or who use a wheelchair.
    2. i am particularly concerned about less    visible    issues because we
       might not even know. the standard example here is: could a social
       media platform sway an election by reminding people who (it
       believes) belong to a particular political party to vote? how would
       we even know?
    3. we need to start thinking about qualifying our research better with
       respect to the populations we expect it to work on. when we pick a
       problem to work on, who is being served? when we pick a dataset to
       work on, who is being left out? a silly example is the curation of
       older datasets for id164 in id161, which (i
       understand) decided on which objects to focus on by asking five
       year old relatives of the researchers constructing the datasets to
       name all the objects they could see. as a result of socio-economic
       status (among other things), mouse means the thing that attaches to
       your computer, not the cute furry animal. more generally, when we
       say we've    solved    task x, does this really mean task x or does
       this mean task x for some specific population that we haven't even
       thought to identify (i.e.,    people like me    aka the [38]white guys
       problem)? and does    getting more data    really solve the
       problem---is more data always good data?
    4. i'm at least as concerned with machine-in-the-loop decision making
       as fully automated decision making. just because a human makes the
       final decision doesn't mean that the system cannot bias that human.
       for complex decisions, a system (think even just web search!) has
       to provide you with information that helps you decide, but what
       guarantees do we have that that information isn't going to be
       biased, either unintentionally or even intentionally. (i've also
       heard that, e.g., in predicting recidivism, machine-in-the-loop
       predictions are worse than fully automated decisions, presumably
       because of some human bias we don't understand.)

   if you've read this far, i hope you've found some things to think
   about. if you want more to read, here are some people whose work i
   like, who tweet about these topics, and for whom you can citation chase
   to find other cool work. it's a highly biased list.
     * [39]joanna bryson ([40]@j2bryson), who has been doing great work in
       ethics/ai for a long time and whose work on bias in language has
       given me tons of food for thought.
     * [41]kate crawford ([42]@katecrawford) studies the intersection
       between society and data, and has written excellent pieces on
       fairness.
     * [43]nick diakopoulos ([44]@ndiakopoulos), a colleague here at umd,
       studies computational journalism and algorithmic transparency.
     * [45]sorelle friedler ([46]@kdphd), a former phd student here at
       umd!, has done some of the initial work on learning without
       disparate impact.
     * [47]suresh venkatasubramanian ([48]@geomblog) has co-authored many
       of the papers with friedler, including work on lower bounds and
       impossibility results for fairness.
     * [49]hanna wallach ([50]@hannawallach) is the first name i think of
       for machine learning and computational social science, and has
       recently been working in the area of fairness.

   i'll also point to less biased sources. the [51]fairness,
   accountability and transparency in machine learning workshop takes
   place in new york city in a week and a half; check out the speakers and
   papers there. i also highly recommend the very long reading list on
   [52]critical algorithm studies, which covers more than just machine
   learning.

   posted by hal at [53]11/08/2016 05:06:00 pm

4 comments:

   [54]brendan o'connor said...
          re id103: here's a paper on aae
          http://static.googleusercontent.com/media/research.google.com/en
          //pubs/archive/42900.pdf

          [55]13 november, 2016 11:59 [56][icon_delete13.gif]

   anonymous said...
          update on one of the articles you linked ("prediction of
          criminality"). some independent researchers took a look at the
          original analysis and found it to be very flawed.
          reference: flores et.al., "false positives, false negatives, and
          false analyses: a rejoinder to "machine bias: there   s software
          used across the country to predict future criminals. and it   s
          biased against blacks."", federal probation journal, sep 2016
          http://www.uscourts.gov/statistics-reports/publications/federal-
          probation-journal/federal-probation-journal-september-2016

          [57]15 november, 2016 23:57 [58][icon_delete13.gif]

   [59]rajhans said...
          another related read:
          https://www.amazon.com/weapons-math-destruction-increases-inequa
          lity/dp/0553418815

          [60]19 november, 2016 12:57 [61][icon_delete13.gif]

   [62]hal said...
          thanks for all the pointers!

          [63]22 november, 2016 07:56 [64][icon_delete13.gif]

   [65]post a comment

   [66]newer post [67]older post [68]home
   subscribe to: [69]post comments (atom)

about me

   [70]my photo

   [71]hal

   [72]view my complete profile

labels

     * [73]acl (3)
     * [74]acs (2)
     * [75]advising (1)
     * [76]algorithms (2)
     * [77]bayesian (10)
     * [78]chunking (1)
     * [79]classification (1)
     * [80]id91 (3)
     * [81]community (26)
     * [82]conferences (45)
     * [83]coreference (1)
     * [84]data (2)
     * [85]discourse (3)
     * [86]id20 (5)
     * [87]evaluation (9)
     * [88]finite state methods (1)
     * [89]id114 (1)
     * [90]hiring (7)
     * [91]information retrieval (1)
     * [92]journals (3)
     * [93]id38 (1)
     * [94]linguistics (7)
     * [95]id168s (1)
     * [96]machine learning (45)
     * [97]machine translation (6)
     * [98]mcmc (1)
     * [99]news (4)
     * [100]online learning (2)
     * [101]papers (17)
     * [102]parsing (2)
     * [103]pl (1)
     * [104]poll (1)
     * [105]problems (12)
     * [106]questions (2)
     * [107]random (1)
     * [108]research (12)
     * [109]reviewing (2)
     * [110]sentiment (1)
     * [111]software (1)
     * [112]speech (1)
     * [113]statistics (3)
     * [114]id170 (5)
     * [115]summarization (4)
     * [116]survey (6)
     * [117]teaching (3)
     * [118]theory (1)
     * [119]topic models (1)

my blog list

     * [icon18_wrench_allbkg.png]
       [120]statistical modeling, causal id136, and social science
       [121]treatment interactions can be hard to estimate from data.
       5 hours ago
     * [icon18_wrench_allbkg.png]
       [122]computational complexity
       [123]cuckoo cycles
       1 day ago
     * [icon18_wrench_allbkg.png]
       [124]in theory
       [125]knuth prize to avi wigderson
       2 days ago
     * [icon18_wrench_allbkg.png]
       [126]daniel lemire's blog
       [127]science and technology links (march 30th 2019)
       6 days ago
     * [icon18_wrench_allbkg.png]
       [128]wadler's blog
       [129]pinker's thirteen rules for better writing
       1 week ago
     * [icon18_wrench_allbkg.png]
       [130]talking brains
       [131]postdoc positions in cognitive neuroscience of communication
       at the university of connecticut
       1 week ago
     * [icon18_wrench_allbkg.png]
       [132]the geomblog
       [133]on pc submissions at soda 2020
       1 week ago
     * [icon18_wrench_allbkg.png]
       [134]journal of statistical software
       [135]coclust: a python package for co-id91
       1 week ago
     * [icon18_wrench_allbkg.png]
       [136]what's new
       [137]uhlenbeck   s theorem on connections with small curvature
       2 weeks ago
     * [icon18_wrench_allbkg.png]
       [138]nuit blanche
       [139]ce soir, paris machine learning #5 season 6: explainable ai,
       unity challenge, ethical ai
       3 weeks ago
     * [icon18_wrench_allbkg.png]
       [140]machine learning (theory)
       [141]code submission should be encouraged but not compulsory
       5 weeks ago
     * [icon18_wrench_allbkg.png]
       [142]my biased coin
       [143]analco, sosa, soda post
       2 months ago
     * [icon18_wrench_allbkg.png]
       [144]gowers's weblog
       [145]how craig barton wishes he   d taught maths
       3 months ago
     * [icon18_wrench_allbkg.png]
       [146]the scala programming language
       [147]new course:    programming reactive systems   
       3 months ago
     * [icon18_wrench_allbkg.png]
       [148]my slice of pizza
       [149]thanksgiving hunger
       4 months ago
     * [icon18_wrench_allbkg.png]
       [150]earning my turns
       [151]august-september music
       6 months ago
     * [icon18_wrench_allbkg.png]
       [152]mathematics and computation
       [153]how to implement type theory in an hour
       7 months ago
     * [icon18_wrench_allbkg.png]
       [154]tombone's blog
       [155]deepfakes: ai-powered deception machines
       10 months ago
     * [icon18_wrench_allbkg.png]
       [156]tcs math - some mathematics of theoretical computer science
       [157]two pages of the book, stuck together
       11 months ago
     * [icon18_wrench_allbkg.png]
       [158]geeking with greg
       [159]two decades of amazon.com recommendations
       1 year ago
     * [icon18_wrench_allbkg.png]
       [160]logicomp
       [161]correctness by design vs. formal verification
       1 year ago
     * [icon18_wrench_allbkg.png]
       [162]xor's hammer
       [163]how is it even possible for a sailboat to sail into the wind?
       1 year ago
     * [icon18_wrench_allbkg.png]
       [164]michael nielsen
       [165]is there a tension between creativity and accuracy?
       1 year ago
     * [icon18_wrench_allbkg.png]
       [166]oddhead blog
       [167]algorithmic economics postdoc position at microsoft research,
       nyc
       3 years ago
     * [icon18_wrench_allbkg.png]
       [168]andy's math/cs page
       [169]making academic contacts (some thoughts for new researchers)
       4 years ago
     * [icon18_wrench_allbkg.png]
       [170]the statmt blog
       [171]easy parallel corpora from wikipedia
       4 years ago
     * [icon18_wrench_allbkg.png]
       [172]learning in vision
       [173]dual submissions -- busted!
       5 years ago
     * [icon18_wrench_allbkg.png]
       [174]webdiarios de motocicleta
       [175]presburger award
       6 years ago
     * [icon18_wrench_allbkg.png]
       [176]lingpipe blog
       [177]upgrading java classes with backward-compatible serialization
       8 years ago
     * [icon18_wrench_allbkg.png]
       [178]quantum algorithms
       [179]polynomial-time quantum algorithm for the simulation of
       chemical dynamics
       10 years ago
     * [icon18_wrench_allbkg.png]
       [180]mathematics weblog
       [181]a levels
       11 years ago
     * [icon18_wrench_allbkg.png]
       [182]structured learning
       [183]corrections to acl anthology urls
       11 years ago
     * [icon18_wrench_allbkg.png]
       [184]apperceptual
     * [icon18_wrench_allbkg.png]
       [185]mathematics weblog
     * [icon18_wrench_allbkg.png]
       [186]yw's machine learning blog
     * [icon18_wrench_allbkg.png]
       [187]undirected grad
     * [icon18_wrench_allbkg.png]
       [188]data wrangling
     * [icon18_wrench_allbkg.png]
       [189]ganesh swami
     * [icon18_wrench_allbkg.png]
       [190]mstatbiostat :
     * [icon18_wrench_allbkg.png]
       [191]the astrostat slog
     * [icon18_wrench_allbkg.png]
       [192]mainly data
     * [icon18_wrench_allbkg.png]
       [193]inductio ex machina
     * [icon18_wrench_allbkg.png]
       [194][lowerbounds, upperbounds]
     * [icon18_wrench_allbkg.png]
       [195]information engineering
     * [icon18_wrench_allbkg.png]
       [196]http://groundtruth.info/astrostat/slog/
     * [icon18_wrench_allbkg.png]
       [197]information retrieval
     * [icon18_wrench_allbkg.png]
       [198]bayesian analysis journal :: forthcoming articles

blog archive

     * [199]     [200]2018 (2)
          + [201]     [202]july (1)
          + [203]     [204]june (1)

     * [205]     [206]2017 (10)
          + [207]     [208]august (1)
          + [209]     [210]april (2)
          + [211]     [212]march (7)

     * [213]     [214]2016 (17)
          + [215]     [216]december (2)
          + [217]     [218]november (3)
               o [219]workshops and mini-conferences
               o [220]bias in ml, and teaching ai
               o [221]acl 2017 pc chairs blog
          + [222]     [223]august (4)
          + [224]     [225]july (4)
          + [226]     [227]june (2)
          + [228]     [229]may (1)
          + [230]     [231]march (1)

     * [232]     [233]2015 (7)
          + [234]     [235]december (1)
          + [236]     [237]october (3)
          + [238]     [239]september (2)
          + [240]     [241]june (1)

     * [242]     [243]2014 (14)
          + [244]     [245]november (2)
          + [246]     [247]october (2)
          + [248]     [249]september (1)
          + [250]     [251]july (3)
          + [252]     [253]june (2)
          + [254]     [255]may (2)
          + [256]     [257]april (2)

     * [258]     [259]2013 (4)
          + [260]     [261]september (1)
          + [262]     [263]july (1)
          + [264]     [265]june (1)
          + [266]     [267]april (1)

     * [268]     [269]2012 (7)
          + [270]     [271]december (2)
          + [272]     [273]september (2)
          + [274]     [275]june (1)
          + [276]     [277]february (2)

     * [278]     [279]2011 (16)
          + [280]     [281]december (1)
          + [282]     [283]october (2)
          + [284]     [285]september (2)
          + [286]     [287]july (2)
          + [288]     [289]may (1)
          + [290]     [291]april (2)
          + [292]     [293]march (3)
          + [294]     [295]february (1)
          + [296]     [297]january (2)

     * [298]     [299]2010 (29)
          + [300]     [301]november (2)
          + [302]     [303]october (2)
          + [304]     [305]september (4)
          + [306]     [307]august (6)
          + [308]     [309]july (1)
          + [310]     [311]june (2)
          + [312]     [313]april (5)
          + [314]     [315]february (3)
          + [316]     [317]january (4)

     * [318]     [319]2009 (34)
          + [320]     [321]december (2)
          + [322]     [323]november (3)
          + [324]     [325]october (1)
          + [326]     [327]september (3)
          + [328]     [329]august (3)
          + [330]     [331]july (2)
          + [332]     [333]june (8)
          + [334]     [335]may (2)
          + [336]     [337]april (3)
          + [338]     [339]march (3)
          + [340]     [341]february (2)
          + [342]     [343]january (2)

     * [344]     [345]2008 (37)
          + [346]     [347]december (3)
          + [348]     [349]november (2)
          + [350]     [351]september (2)
          + [352]     [353]august (1)
          + [354]     [355]july (4)
          + [356]     [357]june (7)
          + [358]     [359]may (4)
          + [360]     [361]april (4)
          + [362]     [363]march (4)
          + [364]     [365]february (3)
          + [366]     [367]january (3)

     * [368]     [369]2007 (58)
          + [370]     [371]december (3)
          + [372]     [373]november (5)
          + [374]     [375]october (3)
          + [376]     [377]september (4)
          + [378]     [379]august (4)
          + [380]     [381]july (4)
          + [382]     [383]june (5)
          + [384]     [385]may (7)
          + [386]     [387]april (8)
          + [388]     [389]march (2)
          + [390]     [391]february (6)
          + [392]     [393]january (7)

     * [394]     [395]2006 (78)
          + [396]     [397]december (1)
          + [398]     [399]november (5)
          + [400]     [401]october (10)
          + [402]     [403]september (4)
          + [404]     [405]august (6)
          + [406]     [407]july (8)
          + [408]     [409]june (5)
          + [410]     [411]may (11)
          + [412]     [413]april (7)
          + [414]     [415]march (6)
          + [416]     [417]february (6)
          + [418]     [419]january (9)

     * [420]     [421]2005 (6)
          + [422]     [423]december (6)

references

   visible links
   1. https://nlpers.blogspot.com/feeds/posts/default
   2. https://nlpers.blogspot.com/feeds/posts/default?alt=rss
   3. https://nlpers.blogspot.com/feeds/2076481043600522719/comments/default
   4. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html#main
   5. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html#sidebar
   6. https://nlpers.blogspot.com/
   7. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html
   8. http://www.nature.com/news/there-is-a-blind-spot-in-ai-research-1.20805
   9. http://www.nature.com/news/there-is-a-blind-spot-in-ai-research-1.20805
  10. https://1.bp.blogspot.com/-zekjdals-bq/wcjlagwq84i/aaaaaaaaaac/ciiolbabex82s3g_51jbiic3_d-s-8hwwcew/s1600/go_badly.png
  11. http://onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2016.00960.x/full
  12. http://www.autoblog.com/2011/05/31/women-voice-command-systems/
  13. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2208240
  14. https://www.washingtonpost.com/news/wonk/wp/2016/03/10/uber-seems-to-offer-better-service-in-areas-with-more-white-people-that-raises-some-tough-questions/
  15. http://towcenter.org/research/jennifer-stark/
  16. http://www.nickdiakopoulos.com/
  17. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
  18. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
  19. https://3.bp.blogspot.com/-oauipmxt-sa/wcjlayi3roi/aaaaaaaaaas/uu0tdwpwe68u6n8hxfdjug0k9cvkcorqacew/s1600/sel_pop.png
  20. https://1.bp.blogspot.com/-n3vdgfei8fg/wcjla9nzg4i/aaaaaaaaaa0/pmpiobiupdel7gxvrfpz9bm4-bdwtsfpqcew/s1600/true_pop.png
  21. https://2.bp.blogspot.com/-jwp-vksoa-u/wcjlaxe1zhi/aaaaaaaaaay/l1wuf6norf4de0jhbzdhflk-tw1ruwibwcew/s1600/heckman_cortes.png
  22. https://www.jstor.org/stable/1912352?seq=1#page_scan_tab_contents
  23. http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44193.pdf
  24. https://www.cs.jhu.edu/~mdredze/datasets/sentiment/
  25. https://2.bp.blogspot.com/-rnf4xnjuo9m/wcjlz-t8kii/aaaaaaaaaam/jyjcnv7m8us0ciywgnnatt8dhnz3h5psacew/s1600/cross_domain.png
  26. https://2.bp.blogspot.com/-0oqbwokfu30/wcjlz5ggkfi/aaaaaaaaaaq/5l1nmwfssycfrxggpr9iylccfrmz72uygcew/s1600/electronics.png
  27. https://arxiv.org/pdf/1412.3756.pdf
  28. https://2.bp.blogspot.com/-bllktvronm8/wcjlag_yy8i/aaaaaaaaaag/p4_fwwat61sqot3oxbtg4rjvxljrrlywqcew/s1600/map.png
  29. https://4.bp.blogspot.com/-c1lzsaruvp0/wcjlz0r_46i/aaaaaaaaaau/bn-lycuhwmqipqr2ex4ncckpjqpopghsqcew/s1600/crrrcuit.png
  30. https://3.bp.blogspot.com/-zzlq785voqq/wcjlblsmuri/aaaaaaaaaa4/sahdccwoooapsiwmnmspjxolxzu6fjzvwcew/s1600/vc.jpg
  31. https://2.bp.blogspot.com/-5f-ywrz5mdy/wcjlay1h4ai/aaaaaaaaaao/wsujpbpytho511mhwestacq0p8dzs_yaacew/s1600/palmer.jpg
  32. http://dexterpalmer.com/books/#version
  33. http://www.rshroff.com/
  34. http://www.rshroff.com/
  35. http://www.rshroff.com/uploads/6/2/3/5/62359383/frisky.pdf
  36. https://en.wikipedia.org/wiki/stop-and-frisk_in_new_york_city
  37. https://2.bp.blogspot.com/-2y_o6k0tgfg/wcjlaxohddi/aaaaaaaaaaw/qxb77xxy_mkrcr10upk8cqrsy3cjmvwfwcew/s1600/shroff.png
  38. http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html
  39. http://www.cs.bath.ac.uk/~jjb/
  40. http://twitter.com/j2bryson
  41. http://www.katecrawford.net/
  42. http://twitter.com/katecrawford
  43. http://www.nickdiakopoulos.com/
  44. http://twitter.com/ndiakopoulos
  45. http://sorelle.friedler.net/
  46. http://twitter.com/kdphd
  47. http://www.cs.utah.edu/~suresh
  48. http://twitter.com/geomblog
  49. http://dirichlet.net/
  50. http://twitter.com/hannawallach
  51. http://fatml.org/
  52. http://socialmediacollective.org/reading-lists/critical-algorithm-studies
  53. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html
  54. https://www.blogger.com/profile/01622411855846515340
  55. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html?showcomment=1479063549459#c357777909228311791
  56. https://www.blogger.com/delete-comment.g?blogid=19803222&postid=357777909228311791
  57. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html?showcomment=1479279443016#c9110070980886770224
  58. https://www.blogger.com/delete-comment.g?blogid=19803222&postid=9110070980886770224
  59. https://www.blogger.com/profile/09447934133580921215
  60. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html?showcomment=1479585464552#c3510866495904493234
  61. https://www.blogger.com/delete-comment.g?blogid=19803222&postid=3510866495904493234
  62. https://www.blogger.com/profile/02162908373916390369
  63. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html?showcomment=1479826571385#c7324287067127807708
  64. https://www.blogger.com/delete-comment.g?blogid=19803222&postid=7324287067127807708
  65. https://www.blogger.com/comment.g?blogid=19803222&postid=2076481043600522719
  66. https://nlpers.blogspot.com/2016/11/workshops-and-mini-conferences.html
  67. https://nlpers.blogspot.com/2016/11/acl-2017-pc-chairs-blog.html
  68. https://nlpers.blogspot.com/
  69. https://nlpers.blogspot.com/feeds/2076481043600522719/comments/default
  70. https://www.blogger.com/profile/02162908373916390369
  71. https://www.blogger.com/profile/02162908373916390369
  72. https://www.blogger.com/profile/02162908373916390369
  73. https://nlpers.blogspot.com/search/label/acl
  74. https://nlpers.blogspot.com/search/label/acs
  75. https://nlpers.blogspot.com/search/label/advising
  76. https://nlpers.blogspot.com/search/label/algorithms
  77. https://nlpers.blogspot.com/search/label/bayesian
  78. https://nlpers.blogspot.com/search/label/chunking
  79. https://nlpers.blogspot.com/search/label/classification
  80. https://nlpers.blogspot.com/search/label/id91
  81. https://nlpers.blogspot.com/search/label/community
  82. https://nlpers.blogspot.com/search/label/conferences
  83. https://nlpers.blogspot.com/search/label/coreference
  84. https://nlpers.blogspot.com/search/label/data
  85. https://nlpers.blogspot.com/search/label/discourse
  86. https://nlpers.blogspot.com/search/label/id20
  87. https://nlpers.blogspot.com/search/label/evaluation
  88. https://nlpers.blogspot.com/search/label/finite state methods
  89. https://nlpers.blogspot.com/search/label/id114
  90. https://nlpers.blogspot.com/search/label/hiring
  91. https://nlpers.blogspot.com/search/label/information retrieval
  92. https://nlpers.blogspot.com/search/label/journals
  93. https://nlpers.blogspot.com/search/label/id38
  94. https://nlpers.blogspot.com/search/label/linguistics
  95. https://nlpers.blogspot.com/search/label/id168s
  96. https://nlpers.blogspot.com/search/label/machine learning
  97. https://nlpers.blogspot.com/search/label/machine translation
  98. https://nlpers.blogspot.com/search/label/mcmc
  99. https://nlpers.blogspot.com/search/label/news
 100. https://nlpers.blogspot.com/search/label/online learning
 101. https://nlpers.blogspot.com/search/label/papers
 102. https://nlpers.blogspot.com/search/label/parsing
 103. https://nlpers.blogspot.com/search/label/pl
 104. https://nlpers.blogspot.com/search/label/poll
 105. https://nlpers.blogspot.com/search/label/problems
 106. https://nlpers.blogspot.com/search/label/questions
 107. https://nlpers.blogspot.com/search/label/random
 108. https://nlpers.blogspot.com/search/label/research
 109. https://nlpers.blogspot.com/search/label/reviewing
 110. https://nlpers.blogspot.com/search/label/sentiment
 111. https://nlpers.blogspot.com/search/label/software
 112. https://nlpers.blogspot.com/search/label/speech
 113. https://nlpers.blogspot.com/search/label/statistics
 114. https://nlpers.blogspot.com/search/label/id170
 115. https://nlpers.blogspot.com/search/label/summarization
 116. https://nlpers.blogspot.com/search/label/survey
 117. https://nlpers.blogspot.com/search/label/teaching
 118. https://nlpers.blogspot.com/search/label/theory
 119. https://nlpers.blogspot.com/search/label/topic models
 120. https://statmodeling.stat.columbia.edu/
 121. http://feedproxy.google.com/~r/statisticalmodelingcausalid136andsocialscience/~3/j8rzuoh8s7c/
 122. https://blog.computationalcomplexity.org/
 123. https://blog.computationalcomplexity.org/2019/04/cuckoo-cycles.html
 124. https://lucatrevisan.wordpress.com/
 125. https://lucatrevisan.wordpress.com/2019/04/02/knuth-prize-to-avi-wigderson/
 126. https://lemire.me/blog
 127. http://feedproxy.google.com/~r/daniel-lemire/atom/~3/tixpi8tsv6i/
 128. http://wadler.blogspot.com/
 129. http://wadler.blogspot.com/2019/03/pinkers-thirteen-rules-for-better.html
 130. http://www.talkingbrains.org/
 131. http://feedproxy.google.com/~r/talkingbrains/~3/spyqgdvyz_k/postdoc-positions-in-cognitive.html
 132. http://blog.geomblog.org/
 133. http://feedproxy.google.com/~r/thegeomblog/~3/ptrxnvy99dg/on-pc-submissions-at-soda-2020.html
 134. https://www.jstatsoft.org/index.php/jss
 135. https://www.jstatsoft.org/index.php/jss/article/view/v088i07
 136. https://terrytao.wordpress.com/
 137. https://terrytao.wordpress.com/2019/03/19/uhlenbecks-theorem-on-connections-with-small-curvature/
 138. http://nuit-blanche.blogspot.com/
 139. http://feedproxy.google.com/~r/blogspot/wcedd/~3/9nkbroe_apc/ce-soir-paris-machine-learning-5-season.html
 140. http://hunch.net/
 141. http://hunch.net/?p=11377237
 142. http://mybiasedcoin.blogspot.com/
 143. http://mybiasedcoin.blogspot.com/2019/01/analco-sosa-soda-post.html
 144. https://gowers.wordpress.com/
 145. https://gowers.wordpress.com/2018/12/22/how-craig-barton-wishes-hed-taught-maths/
 146. http://www.scala-lang.org/news/
 147. http://www.scala-lang.org/news/2018/12/20/programming-reactive-systems-course.html
 148. http://mysliceofpizza.blogspot.com/
 149. http://mysliceofpizza.blogspot.com/2018/11/thanksgiving-hunger.html
 150. https://www.earningmyturns.org/
 151. https://www.earningmyturns.org/2018/09/august-september-music.html
 152. http://math.andrej.com/
 153. http://math.andrej.com/2018/08/25/how-to-implement-type-theory-in-an-hour/
 154. http://www.computervisionblog.com/
 155. http://www.computervisionblog.com/2018/05/deepfakes-ai-powered-deception-machines.html
 156. https://tcsmath.wordpress.com/
 157. https://tcsmath.wordpress.com/2018/04/12/two-pages-of-the-book-stuck-together/
 158. http://glinden.blogspot.com/
 159. http://feedproxy.google.com/~r/geekingwithgreg/~3/8hdwr6fyrns/two-decades-of-amazoncom-recommendations.html
 160. http://logicomp.blogspot.com/
 161. http://logicomp.blogspot.com/2017/06/correctness-by-design-vs-formal.html
 162. https://xorshammer.com/
 163. https://xorshammer.com/2017/05/29/how-is-it-even-possible-for-a-sailboat-to-sail-into-the-wind/
 164. http://michaelnielsen.org/blog
 165. http://feedproxy.google.com/~r/michaelnielsen/wmna/~3/lkqmyjndcbs/
 166. http://blog.oddhead.com/
 167. http://blog.oddhead.com/2015/10/25/algorithmic-economics-postdoc-msr-nyc/
 168. http://andysresearch.blogspot.com/
 169. http://andysresearch.blogspot.com/2014/10/making-academic-contacts-some-thoughts.html
 170. http://statmt.blogspot.com/
 171. http://statmt.blogspot.com/2014/09/easy-parallel-corpora-from-wikipedia.html
 172. http://vimsu99.blogspot.com/
 173. http://vimsu99.blogspot.com/2014/03/dual-submissions-busted.html
 174. http://infoweekly.blogspot.com/
 175. http://infoweekly.blogspot.com/2012/05/presburger-award.html
 176. https://lingpipe-blog.com/
 177. http://lingpipe-blog.com/2010/05/04/upgrading-java-classes-backward-compatible-serialization/
 178. http://qualgorithms.blogspot.com/
 179. http://qualgorithms.blogspot.com/2008/12/polynomial-time-quantum-algorithm-for.html
 180. http://www.sixthform.info/maths
 181. http://www.sixthform.info/maths/?p=166
 182. http://structlearn.blogspot.com/
 183. http://structlearn.blogspot.com/2007/07/corrections-to-acl-anthology-urls.html
 184. http://apperceptual.wordpress.com/feed/
 185. http://sixthform.info/maths/b2rss2.php
 186. http://mehve.org/ywml/atom.xml
 187. http://undirectedgrad.blogspot.com/feeds/posts/default
 188. http://www.datawrangling.com/feed/
 189. http://ergodicity.iamganesh.com/feed/atom/
 190. https://www.lists.utah.edu/wws/rss/latest_d_read/mstatbiostat?count=20&for=10
 191. http://groundtruth.info/astrostat/slog/feed/
 192. http://feeds.feedburner.com/mainlydata
 193. http://conflate.net/inductio/feed/
 194. http://magic.aladdin.cs.cmu.edu/feed/atom/
 195. http://clair.si.umich.edu:8080/wordpress/?feed=atom
 196. http://groundtruth.info/astrostat/slog/
 197. http://ciir.cs.umass.edu/~fdiaz/irblog/?feed=atom
 198. http://ba.stat.cmu.edu/forthcoming.xml
 199. javascript:void(0)
 200. https://nlpers.blogspot.com/2018/
 201. javascript:void(0)
 202. https://nlpers.blogspot.com/2018/07/
 203. javascript:void(0)
 204. https://nlpers.blogspot.com/2018/06/
 205. javascript:void(0)
 206. https://nlpers.blogspot.com/2017/
 207. javascript:void(0)
 208. https://nlpers.blogspot.com/2017/08/
 209. javascript:void(0)
 210. https://nlpers.blogspot.com/2017/04/
 211. javascript:void(0)
 212. https://nlpers.blogspot.com/2017/03/
 213. javascript:void(0)
 214. https://nlpers.blogspot.com/2016/
 215. javascript:void(0)
 216. https://nlpers.blogspot.com/2016/12/
 217. javascript:void(0)
 218. https://nlpers.blogspot.com/2016/11/
 219. https://nlpers.blogspot.com/2016/11/workshops-and-mini-conferences.html
 220. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html
 221. https://nlpers.blogspot.com/2016/11/acl-2017-pc-chairs-blog.html
 222. javascript:void(0)
 223. https://nlpers.blogspot.com/2016/08/
 224. javascript:void(0)
 225. https://nlpers.blogspot.com/2016/07/
 226. javascript:void(0)
 227. https://nlpers.blogspot.com/2016/06/
 228. javascript:void(0)
 229. https://nlpers.blogspot.com/2016/05/
 230. javascript:void(0)
 231. https://nlpers.blogspot.com/2016/03/
 232. javascript:void(0)
 233. https://nlpers.blogspot.com/2015/
 234. javascript:void(0)
 235. https://nlpers.blogspot.com/2015/12/
 236. javascript:void(0)
 237. https://nlpers.blogspot.com/2015/10/
 238. javascript:void(0)
 239. https://nlpers.blogspot.com/2015/09/
 240. javascript:void(0)
 241. https://nlpers.blogspot.com/2015/06/
 242. javascript:void(0)
 243. https://nlpers.blogspot.com/2014/
 244. javascript:void(0)
 245. https://nlpers.blogspot.com/2014/11/
 246. javascript:void(0)
 247. https://nlpers.blogspot.com/2014/10/
 248. javascript:void(0)
 249. https://nlpers.blogspot.com/2014/09/
 250. javascript:void(0)
 251. https://nlpers.blogspot.com/2014/07/
 252. javascript:void(0)
 253. https://nlpers.blogspot.com/2014/06/
 254. javascript:void(0)
 255. https://nlpers.blogspot.com/2014/05/
 256. javascript:void(0)
 257. https://nlpers.blogspot.com/2014/04/
 258. javascript:void(0)
 259. https://nlpers.blogspot.com/2013/
 260. javascript:void(0)
 261. https://nlpers.blogspot.com/2013/09/
 262. javascript:void(0)
 263. https://nlpers.blogspot.com/2013/07/
 264. javascript:void(0)
 265. https://nlpers.blogspot.com/2013/06/
 266. javascript:void(0)
 267. https://nlpers.blogspot.com/2013/04/
 268. javascript:void(0)
 269. https://nlpers.blogspot.com/2012/
 270. javascript:void(0)
 271. https://nlpers.blogspot.com/2012/12/
 272. javascript:void(0)
 273. https://nlpers.blogspot.com/2012/09/
 274. javascript:void(0)
 275. https://nlpers.blogspot.com/2012/06/
 276. javascript:void(0)
 277. https://nlpers.blogspot.com/2012/02/
 278. javascript:void(0)
 279. https://nlpers.blogspot.com/2011/
 280. javascript:void(0)
 281. https://nlpers.blogspot.com/2011/12/
 282. javascript:void(0)
 283. https://nlpers.blogspot.com/2011/10/
 284. javascript:void(0)
 285. https://nlpers.blogspot.com/2011/09/
 286. javascript:void(0)
 287. https://nlpers.blogspot.com/2011/07/
 288. javascript:void(0)
 289. https://nlpers.blogspot.com/2011/05/
 290. javascript:void(0)
 291. https://nlpers.blogspot.com/2011/04/
 292. javascript:void(0)
 293. https://nlpers.blogspot.com/2011/03/
 294. javascript:void(0)
 295. https://nlpers.blogspot.com/2011/02/
 296. javascript:void(0)
 297. https://nlpers.blogspot.com/2011/01/
 298. javascript:void(0)
 299. https://nlpers.blogspot.com/2010/
 300. javascript:void(0)
 301. https://nlpers.blogspot.com/2010/11/
 302. javascript:void(0)
 303. https://nlpers.blogspot.com/2010/10/
 304. javascript:void(0)
 305. https://nlpers.blogspot.com/2010/09/
 306. javascript:void(0)
 307. https://nlpers.blogspot.com/2010/08/
 308. javascript:void(0)
 309. https://nlpers.blogspot.com/2010/07/
 310. javascript:void(0)
 311. https://nlpers.blogspot.com/2010/06/
 312. javascript:void(0)
 313. https://nlpers.blogspot.com/2010/04/
 314. javascript:void(0)
 315. https://nlpers.blogspot.com/2010/02/
 316. javascript:void(0)
 317. https://nlpers.blogspot.com/2010/01/
 318. javascript:void(0)
 319. https://nlpers.blogspot.com/2009/
 320. javascript:void(0)
 321. https://nlpers.blogspot.com/2009/12/
 322. javascript:void(0)
 323. https://nlpers.blogspot.com/2009/11/
 324. javascript:void(0)
 325. https://nlpers.blogspot.com/2009/10/
 326. javascript:void(0)
 327. https://nlpers.blogspot.com/2009/09/
 328. javascript:void(0)
 329. https://nlpers.blogspot.com/2009/08/
 330. javascript:void(0)
 331. https://nlpers.blogspot.com/2009/07/
 332. javascript:void(0)
 333. https://nlpers.blogspot.com/2009/06/
 334. javascript:void(0)
 335. https://nlpers.blogspot.com/2009/05/
 336. javascript:void(0)
 337. https://nlpers.blogspot.com/2009/04/
 338. javascript:void(0)
 339. https://nlpers.blogspot.com/2009/03/
 340. javascript:void(0)
 341. https://nlpers.blogspot.com/2009/02/
 342. javascript:void(0)
 343. https://nlpers.blogspot.com/2009/01/
 344. javascript:void(0)
 345. https://nlpers.blogspot.com/2008/
 346. javascript:void(0)
 347. https://nlpers.blogspot.com/2008/12/
 348. javascript:void(0)
 349. https://nlpers.blogspot.com/2008/11/
 350. javascript:void(0)
 351. https://nlpers.blogspot.com/2008/09/
 352. javascript:void(0)
 353. https://nlpers.blogspot.com/2008/08/
 354. javascript:void(0)
 355. https://nlpers.blogspot.com/2008/07/
 356. javascript:void(0)
 357. https://nlpers.blogspot.com/2008/06/
 358. javascript:void(0)
 359. https://nlpers.blogspot.com/2008/05/
 360. javascript:void(0)
 361. https://nlpers.blogspot.com/2008/04/
 362. javascript:void(0)
 363. https://nlpers.blogspot.com/2008/03/
 364. javascript:void(0)
 365. https://nlpers.blogspot.com/2008/02/
 366. javascript:void(0)
 367. https://nlpers.blogspot.com/2008/01/
 368. javascript:void(0)
 369. https://nlpers.blogspot.com/2007/
 370. javascript:void(0)
 371. https://nlpers.blogspot.com/2007/12/
 372. javascript:void(0)
 373. https://nlpers.blogspot.com/2007/11/
 374. javascript:void(0)
 375. https://nlpers.blogspot.com/2007/10/
 376. javascript:void(0)
 377. https://nlpers.blogspot.com/2007/09/
 378. javascript:void(0)
 379. https://nlpers.blogspot.com/2007/08/
 380. javascript:void(0)
 381. https://nlpers.blogspot.com/2007/07/
 382. javascript:void(0)
 383. https://nlpers.blogspot.com/2007/06/
 384. javascript:void(0)
 385. https://nlpers.blogspot.com/2007/05/
 386. javascript:void(0)
 387. https://nlpers.blogspot.com/2007/04/
 388. javascript:void(0)
 389. https://nlpers.blogspot.com/2007/03/
 390. javascript:void(0)
 391. https://nlpers.blogspot.com/2007/02/
 392. javascript:void(0)
 393. https://nlpers.blogspot.com/2007/01/
 394. javascript:void(0)
 395. https://nlpers.blogspot.com/2006/
 396. javascript:void(0)
 397. https://nlpers.blogspot.com/2006/12/
 398. javascript:void(0)
 399. https://nlpers.blogspot.com/2006/11/
 400. javascript:void(0)
 401. https://nlpers.blogspot.com/2006/10/
 402. javascript:void(0)
 403. https://nlpers.blogspot.com/2006/09/
 404. javascript:void(0)
 405. https://nlpers.blogspot.com/2006/08/
 406. javascript:void(0)
 407. https://nlpers.blogspot.com/2006/07/
 408. javascript:void(0)
 409. https://nlpers.blogspot.com/2006/06/
 410. javascript:void(0)
 411. https://nlpers.blogspot.com/2006/05/
 412. javascript:void(0)
 413. https://nlpers.blogspot.com/2006/04/
 414. javascript:void(0)
 415. https://nlpers.blogspot.com/2006/03/
 416. javascript:void(0)
 417. https://nlpers.blogspot.com/2006/02/
 418. javascript:void(0)
 419. https://nlpers.blogspot.com/2006/01/
 420. javascript:void(0)
 421. https://nlpers.blogspot.com/2005/
 422. javascript:void(0)
 423. https://nlpers.blogspot.com/2005/12/

   hidden links:
 425. https://www.blogger.com/email-post.g?blogid=19803222&postid=2076481043600522719
 426. https://www.blogger.com/post-edit.g?blogid=19803222&postid=2076481043600522719&from=pencil
 427. https://www.blogger.com/profile/01622411855846515340
 428. https://www.blogger.com/profile/09447934133580921215
 429. https://www.blogger.com/profile/02162908373916390369
 430. https://nlpers.blogspot.com/2016/11/bias-in-ml-and-teaching-ai.html
 431. https://www.blogger.com/rearrange?blogid=19803222&widgettype=profile&widgetid=profile1&action=editwidget&sectionid=sidebar
 432. https://www.blogger.com/rearrange?blogid=19803222&widgettype=label&widgetid=label1&action=editwidget&sectionid=sidebar
 433. https://www.blogger.com/rearrange?blogid=19803222&widgettype=bloglist&widgetid=bloglist1&action=editwidget&sectionid=sidebar
 434. https://www.blogger.com/rearrange?blogid=19803222&widgettype=blogarchive&widgetid=blogarchive1&action=editwidget&sectionid=sidebar
 435. https://www.blogger.com/rearrange?blogid=19803222&widgettype=html&widgetid=html1&action=editwidget&sectionid=footer
