   #[1]on the way to vision... id161    feed [2]on the way to
   vision... id161    comments feed [3]on the way to vision...
   id161    id143s with python comments feed [4]kd-tree
   and nearest neighbor (nn) search (2d case) [5]alternate [6]alternate
   [7]on the way to vision... id161 [8]wordpress.com

   [9]on the way to vision    id161
   "life did not intend to make us perfect. whoever is perfect belongs in
   a museum." (erich maria remarque)
   [10]skip to content
     * [11]blog
     * [12]about me
     * [13]projects
          + [14]automated driving
          + [15]xperience
          + [16]intellact
          + [17]garnics
          + [18]paco-plus
     * [19]publications
     * [20]talks
     * [21]teaching

   [22]    kd-tree and nearest neighbor (nn) search (2d case)

[23]id143s with python

   posted on [24]may 25, 2015 by [25]salzis

   [26]fork me on github

   id143s comprise a broad family of sequential monte carlo
   (smc) algorithms for approximate id136 in partially observable
   markov chains. the objective of a id143 is to estimate the
   posterior density of the state variables given the observation
   variables. a generic id143 estimates the posterior
   distribution of the hidden states using the observation measurement
   process.

   [27]figure_title

   comparing to histogram filters and kalman filters: id143s
   usually operate on continuous state space, can represent arbitrary
   multimodal distributions, they are approximate as histogram and kalman
   filters as well. the biggest advantage of id143s is that they
   are quite straightforward for programming.

   in the current post we will consider a id143 used for a
   continuous localization problem. python code shown below has been
   introduced by sebastian thrun on his lecture about    id143s   
   in [28]udacity online class. here it is explained in detail and
   extended by visualization tools. in this example the robot lives in a
   2-dimensional world with size 100 x 100 meters. the world in the
   current example is cyclic. there are 8 landmarks in the world. the
   robot can turn, move straightforward after the turn, and measure
   distances to eight landmarks in the world by sensors on board.

from math import *
import random
import matplotlib.pyplot as plt

# landmarks which can be sensed by the robot (in meters)
landmarks = [[20.0, 20.0], [20.0, 80.0], [20.0, 50.0],
             [50.0, 20.0], [50.0, 80.0], [80.0, 80.0],
             [80.0, 20.0], [80.0, 50.0]]

# size of one dimension (in meters)
world_size = 100.0


   for modeling the robot we will use the robotclass with the following
   attributes and functions:

class robotclass:
    &quot;&quot;&quot; class for the robot model used in this demo &quot;&quot;&
quot;

    def __init__(self):

        self.x = random.random() * world_size           # robot's x coordinate
        self.y = random.random() * world_size           # robot's y coordinate
        self.orientation = random.random() * 2.0 * pi   # robot's orientation

        self.forward_noise = 0.0   # noise of the forward movement
        self.turn_noise = 0.0      # noise of the turn
        self.sense_noise = 0.0     # noise of the sensing


   the robot can move and sense the environment. robot   s initial position
   in the world can be set by:

def set(self, new_x, new_y, new_orientation):
    &quot;&quot;&quot; set robot's initial position and orientation
    :param new_x: new x coordinate
    :param new_y: new y coordinate
    :param new_orientation: new orientation
    &quot;&quot;&quot;

    if new_x &lt; 0 or new_x &gt;= world_size:
        raise valueerror('x coordinate out of bound')
    if new_y &lt; 0 or new_y &gt;= world_size:
        raise valueerror('y coordinate out of bound')
    if new_orientation &lt; 0 or new_orientation &gt;= 2 * pi:
        raise valueerror('orientation must be in [0..2pi]')

    self.x = float(new_x)
    self.y = float(new_y)
    self.orientation = float(new_orientation)


   noise parameters can be set by:

def set_noise(self, new_forward_noise, new_turn_noise, new_sense_noise):
    &quot;&quot;&quot; set the noise parameters, changing them is often useful i
n id143s
    :param new_forward_noise: new noise value for the forward movement
    :param new_turn_noise:    new noise value for the turn
    :param new_sense_noise:  new noise value for the sensing
    &quot;&quot;&quot;

    self.forward_noise = float(new_forward_noise)
    self.turn_noise = float(new_turn_noise)
    self.sense_noise = float(new_sense_noise)


   the robot senses its environment receiving distance to eight landmarks.
   obviously there is always some measurement noise which is modelled here
   as an added gaussian with zero mean (which means there is a certain
   chance to be too short or too long and this id203 is covered by
   gaussian):

def sense(self):
    &quot;&quot;&quot; sense the environment: calculate distances to landmarks
    :return measured distances to the known landmarks
    &quot;&quot;&quot;

    z = []

    for i in range(len(landmarks)):
        dist = sqrt((self.x - landmarks[i][0]) ** 2 + (self.y - landmarks[i][1])
 ** 2)
        dist += random.gauss(0.0, self.sense_noise)
        z.append(dist)

    return z


   to move the robot we will use:

def move(self, turn, forward):
    &quot;&quot;&quot; perform robot's turn and move
    :param turn:    turn command
    :param forward: forward command
    :return robot's state after the move
    &quot;&quot;&quot;

    if forward &lt; 0:
        raise valueerror('robot cannot move backwards')

    # turn, and add randomness to the turning command
    orientation = self.orientation + float(turn) + random.gauss(0.0, self.turn_n
oise)
    orientation %= 2 * pi

    # move, and add randomness to the motion command
    dist = float(forward) + random.gauss(0.0, self.forward_noise)
    x = self.x + (cos(orientation) * dist)
    y = self.y + (sin(orientation) * dist)

    # cyclic truncate
    x %= world_size
    y %= world_size

    # set particle
    res = robotclass()
    res.set(x, y, orientation)
    res.set_noise(self.forward_noise, self.turn_noise, self.sense_noise)

    return res


   to calculate gaussian id203:

@staticmethod
def gaussian(mu, sigma, x):
    &quot;&quot;&quot; calculates the id203 of x for 1-dim gaussian with m
ean mu and var. sigma
    :param mu:    distance to the landmark
    :param sigma: standard deviation
    :param x:     distance to the landmark measured by the robot
    :return gaussian value
    &quot;&quot;&quot;

    # calculates the id203 of x for 1-dim gaussian with mean mu and var. s
igma
    return exp(- ((mu - x) ** 2) / (sigma ** 2) / 2.0) / sqrt(2.0 * pi * (sigma
** 2))


   the next function we will need to assign a weight to each particle
   according to the current measurement. see the text below for more
   details. it uses effectively a gaussian that measures how far away the
   predicted measurements would be from the actual measurements. note that
   for this function you should take care of measurement noise to prevent
   division by zero. such checks are skipped here to keep the code as
   short and compact as possible.

def measurement_prob(self, measurement):
    &quot;&quot;&quot; calculate the measurement id203: how likely a measu
rement should be
    :param measurement: current measurement
    :return id203
    &quot;&quot;&quot;

    prob = 1.0

    for i in range(len(landmarks)):
        dist = sqrt((self.x - landmarks[i][0]) ** 2 + (self.y - landmarks[i][1])
 ** 2)
        prob *= self.gaussian(dist, self.sense_noise, measurement[i])
    return prob


   the next piece of code demonstrates how to use robot   s class:
# create a robot
myrobot = robotclass()
print myrobot

# set noise parameters
myrobot.set_noise(5., .1, 5.)

# set robot's initial position and orientation
myrobot.set(30., 50., pi/2.)
print myrobot

# clockwise turn and move
myrobot = myrobot.move(-pi/2., 15.)
print myrobot

print myrobot.sense()

# clockwise turn again and move
myrobot = myrobot.move(-pi/2., 10.)
print myrobot

print myrobot.sense()

print ''
print ''

   now we create a robot with a random orientation at a random location in
   the world and let it move:
# create a robot for the id143 demo
myrobot = robotclass()
myrobot = myrobot.move(0.1, 5.0)

   let   s print information about our robot and get measurements to the
   landmarks:
print 'z = ', z
print 'myrobot = ', myrobot

   our id143 will maintain a set of 1000 random guesses
   (particles) where the robot might be. each guess (or particle) is a
   vector containing (x,y) coordinates and a heading direction which is an
   angle relative to the x axis. now we create a list of 1000 particles:
# create a set of particles
n = 1000  # number of particles
p = []    # list of particles

for i in range(n):
    x = robotclass()
    x.set_noise(0.05, 0.05, 5.0)
    p.append(x)

   for each particle we simulate robot motion. each of our particles will
   first turn by 0.1 and move 5 meters. a current measurement vector is
   applied to every particle from the list.
steps = 50  # id143 steps

for t in range(steps):

    # move the robot and sense the environment after that
    myrobot = myrobot.move(0.1, 5.)
    z = myrobot.sense()

    # now we simulate a robot motion for each of
    # these particles
    p2 = []

    for i in range(n):
        p2.append( p[i].move(0.1, 5.) )

    p = p2

   the closer a particle to a correct position, the more likely will be
   the set of measurements given this position. the mismatch of the actual
   measurement and the predicted measurement leads to a so-called
   importance weight. it tells us how important that specific particle is.
   the larger the weight, the more important it is. according to this each
   of our particles in the list will have a different weight depending on
   a specific robot   s measurement. some will look very plausible, others
   might look very implausible.
    # generate particle weights depending on robot's measurement
    w = []

    for i in range(n):
        w.append(p[i].measurement_prob(z))

   after that we let these particles survive randomly, but the id203
   of survival will be proportional to the weights. it means that
   particles with large weights will survive at a higher proportion as
   compared small ones. this procedure is called    resampling   . after the
   resampling phase particles with large weights very likely live on,
   while particles with small weights likely have died out. particles
   which are very consistent with the sensor measurement survive at a
   higher id203, and particles with lower importance weight tend to
   die out.

   the final step of the id143 algorithm consists in sampling
   particles from the list p with a id203 which is proportional to
   its corresponding w value. particles in p having a large weight in w
   should be drawn more frequently than the ones with a small value. and
   this is the most tricky part in the entire demo. check sebastian
   thrun   s lecture about the id143s from the course    artificial
   intelligence for robots    for more details. now we construct a new
   particle set p3 , so that the particles in p3 are drawn from p
   according to importance weights w . this piece of code uses a trick
   from sebastian thrun   s lecture representing all particles and
   importance weights as a big wheel. here is a pseudo-code of the
   resampling step:
while w[index] &lt; beta:
    beta = beta - w[index]
    index = index + 1
    select p[index]

   which turns to be the following in python:

        # resampling with a sample id203 proportional
        # to the importance weight
        p3 = []

        index = int(random.random() * n)
        beta = 0.0
        mw = max(w)

        for i in range(n):
            beta += random.random() * 2.0 * mw

            while beta &gt; w[index]:
                beta -= w[index]
                index = (index + 1) % n

            p3.append(p[index])

        # here we get a set of co-located particles
        p = p3


   at every iteration we want to see the overall quality of the solution,
   for this we will use the following function:

def evaluation(r, p):
    &quot;&quot;&quot; calculate the mean error of the system
    :param r: current robot object
    :param p: particle set
    :return mean error of the system
    &quot;&quot;&quot;

    sum = 0.0

    for i in range(len(p)):

        # the second part is because of world's cyclicity
        dx = (p[i].x - r.x + (world_size/2.0)) % \
             world_size - (world_size/2.0)
        dy = (p[i].y - r.y + (world_size/2.0)) % \
             world_size - (world_size/2.0)
        err = sqrt(dx**2 + dy**2)
        sum += err

    return sum / float(len(p))


   it computes the average error of each particle relative to the robot
   pose. we call this function at the end of each iteration:

        # here we get a set of co-located particles
        p = p3

        print 'step = ', t, ', evaluation = ', evaluation(myrobot, p)


   for the better understanding how the id143 proceeds from
   iteration to iteration i have implemented for you the following
   visualization function:

def visualization(robot, step, p, pr, weights):
    &quot;&quot;&quot; visualization
    :param robot:   the current robot object
    :param step:    the current step
    :param p:       list with particles
    :param pr:      list of resampled particles
    :param weights: particle weights
    &quot;&quot;&quot;

    plt.figure(&quot;robot in the world&quot;, figsize=(15., 15.))
    plt.title('id143, step ' + str(step))

    # draw coordinate grid for plotting
    grid = [0, world_size, 0, world_size]
    plt.axis(grid)
    plt.grid(b=true, which='major', color='0.75', linestyle='--')
    plt.xticks([i for i in range(0, int(world_size), 5)])
    plt.yticks([i for i in range(0, int(world_size), 5)])

    # draw particles
    for ind in range(len(p)):

        # particle
        circle = plt.circle((p[ind].x, p[ind].y), 1., facecolor='#ffb266', edgec
olor='#994c00', alpha=0.5)
        plt.gca().add_patch(circle)

        # particle's orientation
        arrow = plt.arrow(p[ind].x, p[ind].y, 2*cos(p[ind].orientation), 2*sin(p
[ind].orientation), alpha=1., facecolor='#994c00', edgecolor='#994c00')
        plt.gca().add_patch(arrow)

    # draw resampled particles
    for ind in range(len(pr)):

        # particle
        circle = plt.circle((pr[ind].x, pr[ind].y), 1., facecolor='#66ff66', edg
ecolor='#009900', alpha=0.5)
        plt.gca().add_patch(circle)

        # particle's orientation
        arrow = plt.arrow(pr[ind].x, pr[ind].y, 2*cos(pr[ind].orientation), 2*si
n(pr[ind].orientation), alpha=1., facecolor='#006600', edgecolor='#006600')
        plt.gca().add_patch(arrow)

    # fixed landmarks of known locations
    for lm in landmarks:
        circle = plt.circle((lm[0], lm[1]), 1., facecolor='#cc0000', edgecolor='
#330000')
        plt.gca().add_patch(circle)

    # robot's location
    circle = plt.circle((robot.x, robot.y), 1., facecolor='#6666ff', edgecolor='
#0000cc')
    plt.gca().add_patch(circle)

    # robot's orientation
    arrow = plt.arrow(robot.x, robot.y, 2*cos(robot.orientation), 2*sin(robot.or
ientation), alpha=0.5, facecolor='#000000', edgecolor='#000000')
    plt.gca().add_patch(arrow)

    plt.savefig(&quot;figure_&quot; + str(step) + &quot;.png&quot;)
    plt.close()


   all particles will be drawn in orange, resampled particles in green,
   the robot in blue and fixed landmarks of known locations in red. let   s
   have a look at the output after the first iteration of the particle
   filter:

   [29]figure_0

   as we can see, initial discrete guesses (or particles), where the robot
   might be, are uniformly spread in the world. but after resampling only
   those particles survive which are consistent with the robot
   measurement. let us apply more iterations and see which particles will
   survive:

   [30]figure_1

   [31]figure_2

   [32]figure_3

   [33]figure_4

   [34]figure_5

   [35]figure_6

   [36]figure_7

   [37]figure_8

   [38]figure_9

   as we can see, particles inconsistent with the robot measurements tend
   to die out and only a correct set of particles survives.

   [39]figure_10

   additional / recommended literature to id143s:

   thrun, s. id143s in robotics. proceedings of the 17th annual
   conference on uncertainty in ai (uai), 2002.

   thrun, s., burgard, w., fox, d. probabilistic robotics (part i, chapter
   4). 2006.

   best wishes and enjoy id143s in python,
   alexey
   advertisements

share this:

     * [40]print
     * [41]email
     *
     *
     * [42]tweet
     *

like this:

   like loading...
   this entry was posted in [43]uncategorized. bookmark the [44]permalink.
   [45]    kd-tree and nearest neighbor (nn) search (2d case)

3 responses to id143s with python

    1. salonisharma27 says:
       [46]may 22, 2017 at 7:34 am
       hello sir,
       i went through your code and tried to implement it.there is very
       small mistake in one of the line.the gaussian method you have
       declared     def gaussian(mu, sigma, x):     ,you have forgotten to
       declare the first argument as self. without declaring that instance
       , the program throws error once build.
       thank you for writing this code, it was quite useful to understand
       the id143. i am currently trying to implement it on my
       project.
       regards
       [47]reply
          + [48]salzis says:
            [49]june 2, 2017 at 5:55 am
            hi, thanks a lot for your comment and pointing me to that
            line. i will take care of it:-) i   m going to put all python
            codes into ipython notebooks soon.
            cheers,
            alexey
            [50]reply
    2. mercy peter says:
       [51]september 26, 2017 at 4:33 pm
       hi alexey,
       thanks for this post, the visualization piece was very helpful to
       see id143ing in action.
       you may need to add the id172 step under the section #
       generate particle weights depending on robot   s measurement.
       thanks,
       mercy
       [52]reply

leave a reply [53]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *

       iframe: [54]googleplus-sign-in

     *
     *

   [55]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [56]log out /
   [57]change )
   google photo

   you are commenting using your google account. ( [58]log out /
   [59]change )
   twitter picture

   you are commenting using your twitter account. ( [60]log out /
   [61]change )
   facebook photo

   you are commenting using your facebook account. ( [62]log out /
   [63]change )
   [64]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   post comment

     * continental ag
       continental ag
     * continental teves ag
       continental teves ag standort frankfurt am main, germany
     * georg-august-universit  t
       georg-august-universit  t g  ttingen, germany
     * national research nuclear university mephi
       national research nuclear university mephi, moscow, russia
     * my profile on google scholar
     * search for: ____________________ search
       advertisements

   [65]on the way to vision    id161
   [66]create a free website or blog at wordpress.com.


   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   post to
   [67]cancel reblog post

   send to email address ____________________ your name
   ____________________ your email address ____________________
   _________________________
   loading send email [68]cancel
   post was not sent - check your email addresses!
   email check failed, please try again
   sorry, your blog cannot share posts by email.

   close and accept privacy & cookies: this site uses cookies. by
   continuing to use this website, you agree to their use.
   to find out more, including how to control cookies, see here:
   [69]cookie policy

   iframe: [70]likes-master

   %d bloggers like this:

references

   visible links
   1. https://salzis.wordpress.com/feed/
   2. https://salzis.wordpress.com/comments/feed/
   3. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/feed/
   4. https://salzis.wordpress.com/2014/06/28/kd-tree-and-nearest-neighbor-nn-search-2d-case/
   5. https://public-api.wordpress.com/oembed/?format=json&url=https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/&for=wpcom-auto-discovery
   6. https://public-api.wordpress.com/oembed/?format=xml&url=https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/&for=wpcom-auto-discovery
   7. https://salzis.wordpress.com/osd.xml
   8. https://s1.wp.com/opensearch.xml
   9. https://salzis.wordpress.com/
  10. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#content
  11. https://salzis.wordpress.com/
  12. https://salzis.wordpress.com/biography/
  13. https://salzis.wordpress.com/projects/
  14. https://salzis.wordpress.com/projects/automated-driving/
  15. https://salzis.wordpress.com/projects/xperience/
  16. https://salzis.wordpress.com/projects/intellact/
  17. https://salzis.wordpress.com/projects/garnics/
  18. https://salzis.wordpress.com/projects/paco-plus/
  19. https://salzis.wordpress.com/publications/
  20. https://salzis.wordpress.com/talks/
  21. https://salzis.wordpress.com/teaching/
  22. https://salzis.wordpress.com/2014/06/28/kd-tree-and-nearest-neighbor-nn-search-2d-case/
  23. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  24. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  25. https://salzis.wordpress.com/author/salzis/
  26. https://github.com/aabramovrepo
  27. https://salzis.files.wordpress.com/2015/02/figure_title.png
  28. https://www.udacity.com/
  29. https://salzis.files.wordpress.com/2015/02/figure_0.png
  30. https://salzis.files.wordpress.com/2015/02/figure_1.png
  31. https://salzis.files.wordpress.com/2015/02/figure_2.png
  32. https://salzis.files.wordpress.com/2015/02/figure_3.png
  33. https://salzis.files.wordpress.com/2015/02/figure_4.png
  34. https://salzis.files.wordpress.com/2015/02/figure_5.png
  35. https://salzis.files.wordpress.com/2015/02/figure_6.png
  36. https://salzis.files.wordpress.com/2015/02/figure_7.png
  37. https://salzis.files.wordpress.com/2015/02/figure_8.png
  38. https://salzis.files.wordpress.com/2015/02/figure_9.png
  39. https://salzis.files.wordpress.com/2015/02/figure_10.png
  40. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#print
  41. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/?share=email
  42. https://twitter.com/share
  43. https://salzis.wordpress.com/category/uncategorized/
  44. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  45. https://salzis.wordpress.com/2014/06/28/kd-tree-and-nearest-neighbor-nn-search-2d-case/
  46. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#comment-140
  47. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/?replytocom=140#respond
  48. https://salzis.wordpress.com/
  49. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#comment-141
  50. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/?replytocom=141#respond
  51. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#comment-145
  52. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/?replytocom=145#respond
  53. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#respond
  54. https://public-api.wordpress.com/connect/?googleplus-sign-in=https://salzis.wordpress.com&color_scheme=light
  55. https://gravatar.com/site/signup/
  56. javascript:highlandercomments.doexternallogout( 'wordpress' );
  57. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  58. javascript:highlandercomments.doexternallogout( 'googleplus' );
  59. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  60. javascript:highlandercomments.doexternallogout( 'twitter' );
  61. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  62. javascript:highlandercomments.doexternallogout( 'facebook' );
  63. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  64. javascript:highlandercomments.cancelexternalwindow();
  65. https://salzis.wordpress.com/
  66. https://wordpress.com/?ref=footer_website
  67. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/
  68. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#cancel
  69. https://automattic.com/cookies
  70. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
  72. https://salzis.wordpress.com/
  73. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#comment-form-guest
  74. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#comment-form-load-service:wordpress.com
  75. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#comment-form-load-service:twitter
  76. https://salzis.wordpress.com/2015/05/25/particle-filters-with-python/#comment-form-load-service:facebook
  77. http://www.conti-online.com/
  78. http://www.conti-online.com/
  79. http://www.uni-goettingen.de/
  80. https://mephi.ru/eng/
  81. https://scholar.google.de/citations?user=viu35raaaaaj&hl=de&oi=ao
