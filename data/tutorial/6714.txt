   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]becoming human: artificial intelligence magazine
     * [9]     consulting
     * [10]     tutorials
     * [11]       submit an article
     * [12]     communities
     * [13]     our bot
     __________________________________________________________________

detecting lane lines         udacity sdcnd

   [14]go to the profile of david clark
   [15]david clark (button) blockedunblock (button) followfollowing
   feb 22, 2017

   project #1 in the udacity self-driving car nanodegree

project overview

   project #1 for udacity   s self-driving car nanodegree (sdcnd) is about
   creating a pipeline that detects lane lines in images. while the
   pipeline is created for a single image, it can be applied to video
   footage by breaking the video down into frames, passing the frames
   through the pipeline, and then reconstructing the video.

   my code for this project is publicly available and can be found here:
   [16]https://github.com/sealedsaint/carnd-term1-p1

my pipeline

   my pipeline consists of the following six major steps:
    1. grayscale
    2. gaussian blur
    3. canny edge detection
    4. region of interest         create vertices
    5. hough transform         average lines
    6. draw lines

   let   s use the image below as our original:
   [0*dcptvwx8rqkw4m9k.]
   the image we start with. image this as a single video frame.

   grayscale

   the first thing we do with the raw image is convert it to grayscale.
   not only does this reduce the amount of data and complexity we are
   dealing with, but it also benefits other steps like step #3, canny edge
   detection.
   [0*hmwqygzibqwqq91n.]
   our original image converted to grayscale.

   gaussian blur

   before edge detection, we want to smooth out the image some. applying a
   gaussian blur will cut down on visual noise and ensure that only the
   sharpest edges get through.
   [0*j66abvtcpxwimiqu.]
   the gaussian blur is very slight         it   s hardly different from the
   original grayscale.

   canny edge detection

   personally, i find the result of this step really neat. canny edge
   detection is an algorithm that measures the change in connected pixel
   values (the gradients). we use it to turn our image into pure black and
   white where white represents the largest gradients         the most drastic
   changes in connected pixel values. these represent our    edges    in the
   original image.
   [0*pjvao9lag6obua2l.]
   canny edge detection looks pretty neat.

   region of interest         create vertices

   if we are only looking for lane lines, we certainly don   t care about
   all of these edges. we apply a region of interest that allows us to
   ignore white pixels where lane lines shouldn   t be (in the top of the
   image, for example).

   the region of interest function calls another important
   function         create vertices. i wrote the create vertices function as an
   alternative to hard-coding the coordinates for the region of interest.
   if the car is cresting a hill or coming out of a valley, the horizon of
   the road will change vertically. similarly, if the road is turning, the
   lane lines will veer to the right or left. the create vertices function
   will dynamically determine the region of interest on a per-image basis,
   accounting for these varying conditions. in a nutshell, it works by
   searching from the bottom-center of the image (where the lane will be)
   outward until it encounters lines. the region is then set at these
   discovered points, plus a little bit of buffer to include the lines.
   [0*mlzty9eenm3thfaw.]
   we only care about the general bottom-center of the image         where the
   lane is.

   hough transform         average lines

   after we have our regioned-out edges from the canny algorithm, we pass
   the image through a hough transform. in a basic sense, the hough
   transform will scan the image and detect where pixels form lines. if we
   set our parameters correctly, this will return our lane lines.

   the reality is it   s hard to get single solid lane lines out of a hough
   transform, especially when one of the lines is dashed. even the solid
   lane lines are often made of multiple hough lines. i created the
   average lines function to take the line information output by the hough
   transform and reduce it down to two lines         our ideal lane lines. this
   mostly works by comparing the slopes of the lines. we ignore lines with
   slopes too horizontal         those won   t be lane lines. we then group the
   lines by positive and negative slopes         our right and left lane lines.
   from that separate line information we average the points together and
   extrapolate out to the top of our region of interest and the bottom of
   the screen. this gives us two solid lane lines (per project specs).

   (my average lines function is my version of altering the draw_lines()
   function. i left the draw function as-is because it made sense to keep
   it only as a drawing function.)

   draw lines

   the last step is simple and boring         we simply draw the final lines
   onto the original image. this pipeline draws lane lines onto a single
   image, so for videos each frame is passed through this pipeline and
   returned         forming a new video with marked lane lines.
   [0*dkirvadkgxnua7oi.]
   lane lines are detected!

   here   s a look at some video footage with my drawn lane lines         the
   final product:

   iframe: [17]/media/0138abda7028fa872018f37919c3b9fd?postid=b52bf36193cb

   here   s the final product         video footage of detected lane lines.

the pipeline   s shortcomings

   i did my best to reduce specific dependencies in my pipeline (such as
   certain image resolutions). one of the ways i did this was to include
   the create vertices function as part of the region detection process.
   ironically, while create vertices is great at dynamically handling
   various situations, it   s also one of the weakest points of my pipeline.
   the algorithm isn   t super smart, so the smallest of edges in the middle
   of the road (if detected through canny edge detection) will severely
   limit the region of interest, usually causing lane lines to go
   completely undetected.

possible pipeline improvements

   given that my create vertices function which dynamically determines the
   region of interest is probably my pipeline   s weakest point, i think
   something different should be done there. with some more data, i think
   hard-coding a larger region of interest to account for various
   driving/terrain scenarios might be appropriate. or perhaps a simpler
   approach of altering a standard region of interest based on driving
   data (like steering angle) might work well.

   i also wonder if filtering the original image down to white and yellow
   at the very beginning would improve the process a lot. if we can make
   the assumption that lane lines are always white or yellow this could
   help quite a bit, it seems.

   iframe: [18]/media/c43026df6fee7cdb1aab8aaf916125ea?postid=b52bf36193cb

   [1*bqlrszfhjemf4q7pyrlgng.gif]
   [19][1*2f7oqe2ajk1ksrhkmd9zmw.png]
   [20][1*v-ppfkswhbvlwwamsvhhwg.png]
   [21][1*wt2auqisieaozxj-i7brdq.png]

     * [22]sdcnd
     * [23]opencv
     * [24]self driving cars
     * [25]udacity
     * [26]image processing

   (button)
   (button)
   (button) 60 claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   [27]go to the profile of david clark

[28]david clark

     (button) follow
   [29]becoming human: artificial intelligence magazine

[30]becoming human: artificial intelligence magazine

   latest news, info and tutorials on artificial intelligence, machine
   learning, deep learning, big data and what it means for humanity.

     * (button)
       (button) 60
     * (button)
     *
     *

   [31]becoming human: artificial intelligence magazine
   never miss a story from becoming human: artificial intelligence
   magazine, when you sign up for medium. [32]learn more
   never miss a story from becoming human: artificial intelligence
   magazine
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://becominghuman.ai/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/b52bf36193cb
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://becominghuman.ai/detecting-lane-lines-udacity-sdcnd-b52bf36193cb&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://becominghuman.ai/detecting-lane-lines-udacity-sdcnd-b52bf36193cb&source=--------------------------nav_reg&operation=register
   8. https://becominghuman.ai/?source=logo-lo_koonjcppyv4m---5e5bef33608a
   9. https://becominghuman.ai/artificial-intelligence-software-developers-af09386dc05d
  10. https://becominghuman.ai/tagged/tutorial
  11. https://becominghuman.ai/write-for-us-48270209de63
  12. https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c
  13. http://m.me/becominghumanai
  14. https://becominghuman.ai/@sealedsaint?source=post_header_lockup
  15. https://becominghuman.ai/@sealedsaint
  16. https://github.com/sealedsaint/carnd-term1-p1
  17. https://becominghuman.ai/media/0138abda7028fa872018f37919c3b9fd?postid=b52bf36193cb
  18. https://becominghuman.ai/media/c43026df6fee7cdb1aab8aaf916125ea?postid=b52bf36193cb
  19. https://medium.com/becoming-human/artificial-intelligence-communities-c305f28e674c
  20. https://upscri.be/8f5f8b
  21. https://medium.com/becoming-human/write-for-us-48270209de63
  22. https://becominghuman.ai/tagged/sdcnd?source=post
  23. https://becominghuman.ai/tagged/opencv?source=post
  24. https://becominghuman.ai/tagged/self-driving-cars?source=post
  25. https://becominghuman.ai/tagged/udacity?source=post
  26. https://becominghuman.ai/tagged/image-processing?source=post
  27. https://becominghuman.ai/@sealedsaint?source=footer_card
  28. https://becominghuman.ai/@sealedsaint
  29. https://becominghuman.ai/?source=footer_card
  30. https://becominghuman.ai/?source=footer_card
  31. https://becominghuman.ai/
  32. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  34. https://medium.com/p/b52bf36193cb/share/twitter
  35. https://medium.com/p/b52bf36193cb/share/facebook
  36. https://medium.com/p/b52bf36193cb/share/twitter
  37. https://medium.com/p/b52bf36193cb/share/facebook
