   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]becoming human: artificial intelligence magazine
     * [9]     consulting
     * [10]     tutorials
     * [11]       submit an article
     * [12]     communities
     * [13]     our bot
     __________________________________________________________________

advanced lane-detection for self-driving cars

project #4 in udacity   s self-driving car nanodegree

   [14]go to the profile of david clark
   [15]david clark (button) blockedunblock (button) followfollowing
   may 24, 2017

   project #4 in the [16]udacity self-driving car program involves using
   id161 and machine learning techniques to identify road lanes
   and lane features from a vehicle   s dash-cam.

   my code for this project is publicly available and can be found
   [17]here.

   this is part of a series. you can also read about my [18]first,
   [19]second, and [20]third projects if you missed them!

overview: the pipeline

   the goal of this project is to develop a pipeline. given an image of
   the road, the pipeline should draw onto the image the features it
   identifies about the road   s lane and lines. the lane-detection pipeline
   i developed consists of the following steps:
    1. pre-step: calibrate the camera
    2. undistort the image
    3. threshold the image using gradients and colors
    4. apply a perspective transform (warp) to view the image from
       top-down
    5. identify the lane lines in the warped image
    6. draw features back onto the original image

   the pre-step, calibrating the camera, is performed only once (assuming
   all the images are taken from the same camera). all the other steps are
   performed on each image.

   let   s look at each of these steps one-by-one.

calibrate the camera

      calibrating the camera    really means accounting for the distortion in
   an image introduced by the camera   s lens. this is done using multiple
   images of checkerboard patters, which should have straight lines.
   examining how the checkerboard patterns are distorted (not straight)
   allows us to precisely identify how the camera lens is distorting
   images         which means we can undistort them.
   [0*fs8lhlbnzmspl2nj.jpg]
   a distorted image of a checkerboard pattern placed on a wall. these
   lines should be straight   .

undistort the image

   once the camera is    calibrated,    we simply need to apply the knowledge
   gained to undistort images. this is important because it will restore
   the straightness of lines, helping to identify lane lines later in the
   pipeline. the difference between the distorted and undistorted images
   is clear. the bent lines are now straight.
   [0*c2vq85c0rkor878p.jpg]
   while the very top and left still don   t seem perfect, it   s a whole lot
   better now!

threshold the image

   thresholding is a method of isolating the pixels we are interested in.
   this can be done using a combination of gradient and color filters.
   here   s what a thresholded image looks like next to the original.
   [0*sqcruhxghmggampe.jpg]
   [0*9kcbjdygitwzptsx.jpg]
   the original road image and a thresholded image. i applied
   pixel-gradient and color threshold filters to narrow down the pixels of
   interest (lane lines).

perspective transform

   while undistorting and thresholding help isolate the important
   information, we can further isolate that information by looking only at
   the portion of the image we care about         the road. to focus in on the
   road-portion of the image we shift our perspective to a top-down view
   of the road in front of the car. while we don   t gain any extra
   information from this step, it   s much easier to isolate lane lines and
   measure things like curvature from this perspective.
   [0*hx5kj32xnji3jwxa.jpg]
   [0*orvwfbmr5xy2gtzl.jpg]
   the thresholded image (left), and the same image with a top-down
   perspective shift (right).

identify the lane lines

   from the top-down perspective we can easily identify the lane lines.
   below you can see the lane lines identified by a sliding window search.
   the green boxes represent the windows where we colored the lane lines.
   as the windows search upward they recenter to the average pixel
   position so they    follow    the lines. the colored lines will be drawn
   back onto the original image.
   [0*zivntwttl7qn5ri9.jpg]
   a sliding window search identifies each of the lane lines.

drawing onto the original image

   finally, we take all this information we gathered and draw the results
   back onto the original image. the blue and red lines we identified
   above are present, and the space between them is colored green to show
   the lane. the calculated right/left lane curvature and center-lane
   offset are shown in the top-left of the image as well. (these values
   would be useful when telling a self-driving car how to steer.)
   [0*brmauirpwoi-qegc.jpg]
   final output         lane and lines drawn onto original image along with
   curvature and offset measures.

applying the pipeline to videos

   while the pipeline processes single images, it can easily be applied to
   processing videos by separating the video into frames and processing
   each frame individually.

   i applied my pipeline to three different videos: the normal project
   video, a challenge video, and a harder challenge video.

   iframe: [21]/media/cddc19d02abac2c56f0d15c02d1768c1?postid=9579e1f057ef

   normal project video.

   iframe: [22]/media/54b53ecebd9e6c8b94b1dc435919e583?postid=9579e1f057ef

   challenge project video.

   iframe: [23]/media/1ec7c145efffcdbdf063db09279ba8ae?postid=9579e1f057ef

   harder challenge video.

   iframe: [24]/media/c43026df6fee7cdb1aab8aaf916125ea?postid=9579e1f057ef

   [1*bqlrszfhjemf4q7pyrlgng.gif]
   [25][1*2f7oqe2ajk1ksrhkmd9zmw.png]
   [26][1*v-ppfkswhbvlwwamsvhhwg.png]
   [27][1*wt2auqisieaozxj-i7brdq.png]

     * [28]self driving cars
     * [29]udacity
     * [30]id161
     * [31]lane detection
     * [32]artificial intelligence

   (button)
   (button)
   (button) 17 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [33]go to the profile of david clark

[34]david clark

     (button) follow
   [35]becoming human: artificial intelligence magazine

[36]becoming human: artificial intelligence magazine

   latest news, info and tutorials on artificial intelligence, machine
   learning, deep learning, big data and what it means for humanity.

     * (button)
       (button) 17
     * (button)
     *
     *

   [37]becoming human: artificial intelligence magazine
   never miss a story from becoming human: artificial intelligence
   magazine, when you sign up for medium. [38]learn more
   never miss a story from becoming human: artificial intelligence
   magazine
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://becominghuman.ai/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/9579e1f057ef
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://becominghuman.ai/advanced-lane-detection-for-self-driving-cars-9579e1f057ef&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://becominghuman.ai/advanced-lane-detection-for-self-driving-cars-9579e1f057ef&source=--------------------------nav_reg&operation=register
   8. https://becominghuman.ai/?source=logo-lo_4bdspmttocud---5e5bef33608a
   9. https://becominghuman.ai/artificial-intelligence-software-developers-af09386dc05d
  10. https://becominghuman.ai/tagged/tutorial
  11. https://becominghuman.ai/write-for-us-48270209de63
  12. https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c
  13. http://m.me/becominghumanai
  14. https://becominghuman.ai/@sealedsaint?source=post_header_lockup
  15. https://becominghuman.ai/@sealedsaint
  16. https://www.udacity.com/drive
  17. https://github.com/sealedsaint/carnd-term1-p4
  18. https://becominghuman.ai/detecting-lane-lines-udacity-sdcnd-b52bf36193cb
  19. https://becominghuman.ai/classifying-traffic-signs-728744d3deac
  20. https://becominghuman.ai/end-to-end-self-driving-car-using-behavioral-cloning-5cad2610522c
  21. https://becominghuman.ai/media/cddc19d02abac2c56f0d15c02d1768c1?postid=9579e1f057ef
  22. https://becominghuman.ai/media/54b53ecebd9e6c8b94b1dc435919e583?postid=9579e1f057ef
  23. https://becominghuman.ai/media/1ec7c145efffcdbdf063db09279ba8ae?postid=9579e1f057ef
  24. https://becominghuman.ai/media/c43026df6fee7cdb1aab8aaf916125ea?postid=9579e1f057ef
  25. https://medium.com/becoming-human/artificial-intelligence-communities-c305f28e674c
  26. https://upscri.be/8f5f8b
  27. https://medium.com/becoming-human/write-for-us-48270209de63
  28. https://becominghuman.ai/tagged/self-driving-cars?source=post
  29. https://becominghuman.ai/tagged/udacity?source=post
  30. https://becominghuman.ai/tagged/computer-vision?source=post
  31. https://becominghuman.ai/tagged/lane-detection?source=post
  32. https://becominghuman.ai/tagged/artificial-intelligence?source=post
  33. https://becominghuman.ai/@sealedsaint?source=footer_card
  34. https://becominghuman.ai/@sealedsaint
  35. https://becominghuman.ai/?source=footer_card
  36. https://becominghuman.ai/?source=footer_card
  37. https://becominghuman.ai/
  38. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  40. https://medium.com/p/9579e1f057ef/share/twitter
  41. https://medium.com/p/9579e1f057ef/share/facebook
  42. https://medium.com/p/9579e1f057ef/share/twitter
  43. https://medium.com/p/9579e1f057ef/share/facebook
