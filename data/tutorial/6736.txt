   #[1]pete warden's blog    feed [2]pete warden's blog    comments feed
   [3]pete warden's blog    how do id98s deal with position differences?
   comments feed [4]the joy of an indian paradox [5]deep learning is
   eating software [6]alternate [7]alternate [8]pete warden's blog
   [9]wordpress.com

   search ____________________ search

[10]pete warden's blog

ever tried. ever failed. no matter. try again. fail again. fail better.

   (button) menu
   [11]skip to content
     * [12]home
     * [13]about

how do id98s deal with position differences?

   [14]october 29, 2017 by [15]pete warden in [16]uncategorized [17]4
   comments

   an engineer who   s learning about using convolutional neural networks
   for image classification just asked me an interesting question; how
   does a model know how to recognize objects in different positions in an
   image? since this actually requires quite a lot of explanation, i
   decided to write up my notes here in case they help some other people
   too.

   here   s two example images showing the problem that my friend was
   referring to:

   id98 position 0

   if you   re trying to recognize all images with the sun shape in them,
   how do you make sure that the model works even if the sun can be at any
   position in the image? it   s an interesting problem because there are
   really three stages of enlightenment in how you perceive it:
     * if you haven   t tried to program computers, it looks simple to solve
       because our eyes and brain have no problem dealing with the
       differences in positioning.
     * if you have tried to solve similar problems with traditional
       programming, your heart will probably sink because you   ll know both
       how hard dealing with input differences will be, and [18]how tough
       it can be to explain to your clients why it   s so tricky.
     * as a certified deep learning guru, you   ll sagely stroke your beard
       and smile, safe in the knowledge that your networks will take such
       trivial issues in their stride.

   my friend is at the third stage of enlightenment, but is smart enough
   to realize that there are few accessible explanations of why id98s cope
   so well. i don   t claim to have any novel insights myself, but over the
   last few years of working with image models i have picked up some ideas
   from experience, and heard folklore passed down through the academic
   family tree, so i want to share what i know. i would welcome links to
   good papers on this, since i   m basing a lot of this on hand-wavey
   engineering intuition, so please do help me improve the explanation!

   the starting point for understanding this problem is that networks
   aren   t naturally immune to positioning issues. i first ran across this
   when i took networks trained on the [19]id163 collection of photos,
   and ran them on phones. the history of id163 itself is fascinating.
   originally, google image search was used to find candidate images from
   the public web by searching for each class name, and then researchers
   went through the candidates to weed out any that were incorrect. my
   friend tom white has been having fun digging through the resulting data
   for anomalies, and found some fascinating oddities like [20]a large
   number of female models showing up in the garbage truck category! you
   should also check out [21]andrej karpathy   s account of trying to label
   id163 pictures by hand to understand more about its characteristics.

   the point for our purposes is that all the images in the training set
   are taken by people and published on websites that rank well in web
   searches. that means they tend to be more professional than a random
   snapshot, and in particular they usually have the subject of the image
   well-framed, near the center, taken from a horizontal angle, and taking
   up a lot of the picture. by contrast, somebody pointing a phone   s live
   camera at an object to try out a classifier is more likely to be at an
   odd angle, maybe from above, and may only have part of the object in
   frame. this meant that models trained on id163 had much worse
   perceived performance when running on phones than the published
   accuracy statistics would suggest, because the training data was so
   different than what they were given by users. you can still see this
   for yourself if you install [22]the tensorflow classify application on
   android. it isn   t bad enough to make the model useless on mobile
   phones, since there   s still usually some framing by users, but it   s a
   much more serious problem on robots and similar devices. since their
   camera positioning is completely arbitrary, id163-trained models
   will often struggle seriously. i usually recommend developers of those
   applications look out for their own training sets captured on similar
   devices, since there are also often other differences like fisheye
   lenses.

   even still, within id163 there is still a lot of variance in
   positioning, so how do networks cope so well? part of the secret is
   that training often includes [23]adding artificial offsets to the
   inputs, so that the network has to learn to cope with these
   differences.

   id98 position 1

   before each image is fed into the network, it can be randomly cropped.
   because all inputs are squashed to a standard size (often around
   200  200 or 300  300), this has the effect of randomizing the positioning
   and scale of objects within each picture, as well as potentially
   cutting off sections of them. the network is still punished or rewarded
   for its answers, so to get good performance it has to be able to guess
   correctly despite these differences. this explains why networks learn
   to cope with positioning changes, but not how.

   to delve into that, i have to dip into a bit of folklore and analogy. i
   don   t have research to back up what i   m going to offer as an
   explanation, but in my experiments and discussions with other
   practitioners, it seems pretty well accepted as a working theory.

   ever since the seminal alexnet, id98   s have been organized as
   consecutive layers feeding data through to a final classification
   operation. we think about the initial layers as being edge detectors,
   looking for very basic pixel patterns, and then each subsequent layer
   takes those as inputs and guesses higher and higher level concepts as
   you go deeper. you can see this most easily if you view the filters for
   the first layer of a typical network:

   [24]caffenet_learned_filters

   [25]image by evan shelhamer from caffenet

   what this shows are the small patterns that each filter is looking for.
   some of them are edges in different orientations, others are colors or
   corners. unfortunately we can   t visualize later layers nearly as
   simply, though [26]jason yosinski and others have some great resources
   if you do want to explore that topic more.

   here   s a diagram to try to explain the concepts involved:

   id98 position 2

   what it   s trying to show is that the first layer is looking for very
   simple pixel patterns in the image, like horizontal edges, corners, or
   patches of solid color. these are similar to the filters shown in the
   caffenet illustration just above. as these are run across the input
   image, they output a heat map highlighting where each pattern matches.

   the tricky bit to understand is what happens in the second layer. the
   heatmap for each simple filter in the first layer is put into a
   separate channel in the activation layer, so the input to the second
   layer typically has over a hundred channels, unlike the three or four
   in a typical image. what the second layer is looking for is more
   complex patterns in these heatmaps combined together. in the diagram
   we   re trying to recognize one petal of the sun. we know that this has a
   sharp corner on one end, and nearby will be a vertical line, and the
   center will be filled with yellow. each one of these individual
   characteristics is represented by one channel in the input activation
   layer, and the second layer   s filter for    petal facing left    looks for
   parts of the images where all three occur together. in areas of the
   image where only one or two are present, nothing is output, but where
   all three are there the output of the second layer will show high
   activation.

   just like with the first layer, there are many filters in the second
   layer, and you can think of each one as representing a higher-level
   concept like    petal facing up   ,    petal facing right   , and others. this
   is harder to visualize, but results in an activation layer with many
   channels, each representing one of those concepts.

   as you go deeper into the network, the concepts get higher and higher
   level. for example, the third or fourth layer here might activate
   yellow circles surrounded by petals, by combining the relevant input
   channels. from that representation it   s fairly easy to write a simple
   classifier that spots whenever a sun is present. of course real-world
   classifiers don   t represent concepts nearly as cleanly as i   ve laid out
   above, since they learn how to break down the problem themselves rather
   than being supplied with human-friendly components, but the same basic
   ideas hold.

   this doesn   t explain how the network deals with position differences
   though. to understand that, you need to know about another common
   design trait of id98s for image classification. as you go deeper into a
   network, the number of channels will typically increase, but the size
   of the image will shrink. this shrinking is done using pooling layers,
   traditionally with average pooling but more commonly using maximum
   pooling these days. either way, the effect is pretty similar.

   max pooling

   here you can see that we take an image and shrink it in half. for each
   output pixel, we look at a 2  2 input patch and choose the maximum
   value, hence the name maximum pooling. for average pooling, we take the
   mean of the four values instead.

   this sort of pooling is applied repeatedly as values travel through the
   network. this means that by the end, the image size may have shrunk
   from 300  300 to 13  13. this shrinkage also means that the number of
   position variations that are possible has shrunk a lot. in terms of the
   example above, there are only 13 possible horizontal rows for a sun
   image to appear in, and only 13 vertical columns. any smaller position
   differences are hidden because the activations will be merged into the
   same cell thanks to max pooling. this makes the problem of dealing with
   positional differences much more manageable for the final classifier,
   since it only has to deal with a much simpler representation than the
   original image.

   this is my explanation for how image classifiers typically handle
   position changes, but what about similar problems like offsets in
   audio? i   ve been intrigued by the recent rise of    dilated    or    atrous   
   convolutions that offer an alternative to pooling. just like max
   pooling, these produce a smaller output image, but they do it within
   the context of the convolution itself. rather than sampling adjacent
   input pixels, they look at samples separated by a stride, which can
   potentially be quite large. this gives them the ability to pull
   non-local information into a manageable form quite quickly, and are
   part of the magic of deepmind   s [27]wavenet paper, giving them the
   ability to tackle a time-based problem using convolution rather than
   recurrent neural networks.

   i   m excited by this because id56s are a pain to accelerate. if you   re
   dealing with a batch size of one, as is typical with real-time
   applications, then most of the compute is matrix time vector
   multiplications, with the equivalent of fully-connected layers. since
   every weight is only used once, the calculations are memory bound
   rather than compute bound as is typically the case with convolutions.
   hence i have my fingers crossed that this becomes more common in other
   domains!

   anyway, thanks for making it this far. i hope the explanation is
   helpful, and i look forward to hearing ideas on improving it in the
   comments or [28]on twitter.

share this:

     * [29]twitter
     * [30]facebook
     *

like this:

   like loading...

related

post navigation

   [31]   the joy of an indian paradox
   [32]deep learning is eating software   

4 responses

    1. pingback: [33]position differences and convolutional neural
       networks     curated sql
    2. pingback: how do id98s deal with position differences?     bipin's
       blogs
    3.
   jihao liu says:
       [34]december 17, 2017 at 2:43 pm
       spatial transformer networks, i think the network in this paper is
       very helpful.
       [35]reply
    4. pingback: [36]how do id98s deal with position differences?     the
       data science wanderer

leave a reply [37]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *
     *
     *

   [38]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [39]log out /
   [40]change )
   google photo

   you are commenting using your google account. ( [41]log out /
   [42]change )
   twitter picture

   you are commenting using your twitter account. ( [43]log out /
   [44]change )
   facebook photo

   you are commenting using your facebook account. ( [45]log out /
   [46]change )
   [47]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   [ ] notify me of new posts via email.

   post comment

follow @petewarden on twitter

   [48]my tweets

     * [49]rss - posts

recent posts

     * [50]scaling machine learning models to embedded devices
     * [51]launching tensorflow lite for microcontrollers
     * [52]will compression be machine learning   s killer app?
     * [53]what does it take to train deep learning models on-device?
     * [54]what image classifiers can do about unknown objects

recent comments

   [55]nico galoppo (@ngalo    on [56]launching tensorflow lite for   
   [57]warning     may contai    on [58]launching tensorflow lite for   
   [59]nanda.dash on [60]cross-compiling tensorflow for   
   [61]launching tensorflow    on [62]launching tensorflow lite for   
   [63]mark towfiq (@towfiq    on [64]launching tensorflow lite for   

archives

     * [65]march 2019
     * [66]october 2018
     * [67]july 2018
     * [68]june 2018
     * [69]may 2018
     * [70]april 2018
     * [71]march 2018
     * [72]february 2018
     * [73]january 2018
     * [74]december 2017
     * [75]november 2017
     * [76]october 2017
     * [77]august 2017
     * [78]july 2017
     * [79]june 2017
     * [80]may 2017
     * [81]april 2017
     * [82]january 2017
     * [83]december 2016
     * [84]september 2016
     * [85]may 2016
     * [86]april 2016
     * [87]march 2016
     * [88]february 2016
     * [89]november 2015
     * [90]october 2015
     * [91]september 2015
     * [92]august 2015
     * [93]may 2015
     * [94]april 2015
     * [95]march 2015
     * [96]january 2015
     * [97]december 2014
     * [98]november 2014
     * [99]october 2014
     * [100]september 2014
     * [101]august 2014
     * [102]july 2014
     * [103]june 2014
     * [104]may 2014
     * [105]april 2014
     * [106]march 2014
     * [107]february 2014
     * [108]january 2014
     * [109]december 2013
     * [110]november 2013
     * [111]october 2013
     * [112]september 2013
     * [113]august 2013
     * [114]july 2013
     * [115]june 2013
     * [116]may 2013
     * [117]april 2013
     * [118]march 2013
     * [119]february 2013
     * [120]january 2013
     * [121]november 2012
     * [122]october 2012
     * [123]august 2012
     * [124]july 2012
     * [125]june 2012
     * [126]may 2012
     * [127]april 2012
     * [128]march 2012
     * [129]february 2012
     * [130]january 2012
     * [131]december 2011
     * [132]november 2011
     * [133]october 2011
     * [134]september 2011
     * [135]august 2011
     * [136]july 2011
     * [137]june 2011
     * [138]may 2011
     * [139]april 2011
     * [140]march 2011
     * [141]february 2011
     * [142]january 2011
     * [143]december 2010
     * [144]november 2010
     * [145]october 2010
     * [146]september 2010
     * [147]august 2010
     * [148]july 2010
     * [149]june 2010
     * [150]may 2010
     * [151]april 2010
     * [152]march 2010
     * [153]february 2010
     * [154]january 2010
     * [155]december 2009
     * [156]november 2009
     * [157]october 2009
     * [158]september 2009
     * [159]august 2009
     * [160]july 2009
     * [161]june 2009
     * [162]may 2009
     * [163]april 2009
     * [164]march 2009
     * [165]february 2009
     * [166]january 2009
     * [167]december 2008
     * [168]november 2008
     * [169]october 2008
     * [170]september 2008
     * [171]august 2008
     * [172]july 2008
     * [173]june 2008
     * [174]may 2008
     * [175]april 2008
     * [176]march 2008
     * [177]february 2008
     * [178]january 2008
     * [179]december 2007
     * [180]november 2007
     * [181]october 2007
     * [182]september 2007
     * [183]august 2007
     * [184]july 2007
     * [185]june 2007
     * [186]may 2007
     * [187]april 2007
     * [188]march 2007
     * [189]december 2006
     * [190]november 2006
     * [191]october 2006
     * [192]september 2006
     * [193]august 2006

[194]pete warden's blog

footer menu

     * [195]home
     * [196]about

   [197]blog at wordpress.com.
   [198]   


   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   post to
   [199]cancel reblog post

   iframe: [200]likes-master

   %d bloggers like this:

references

   visible links
   1. https://petewarden.com/feed/
   2. https://petewarden.com/comments/feed/
   3. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/feed/
   4. https://petewarden.com/2017/10/27/the-joy-of-an-indian-paradox/
   5. https://petewarden.com/2017/11/13/deep-learning-is-eating-software/
   6. https://public-api.wordpress.com/oembed/?format=json&url=https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/&for=wpcom-auto-discovery
   7. https://public-api.wordpress.com/oembed/?format=xml&url=https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/&for=wpcom-auto-discovery
   8. https://petewarden.com/osd.xml
   9. https://s1.wp.com/opensearch.xml
  10. https://petewarden.com/
  11. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#content
  12. https://petewarden.com/
  13. https://petewarden.com/about/
  14. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/
  15. https://petewarden.com/author/petewarden/
  16. https://petewarden.com/category/uncategorized/
  17. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#comments
  18. https://xkcd.com/1425/
  19. http://www.image-net.org/
  20. https://twitter.com/dribnet/status/874389135577853952
  21. http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-id163/
  22. http://ci.tensorflow.org/view/nightly/job/nightly-android/lastsuccessfulbuild/artifact/out/tensorflow_demo.apk
  23. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#l1284
  24. https://devblogs.nvidia.com/parallelforall/deep-learning-computer-vision-caffe-cudnn/
  25. https://devblogs.nvidia.com/parallelforall/deep-learning-computer-vision-caffe-cudnn/
  26. http://yosinski.com/deepvis
  27. https://deepmind.com/blog/wavenet-generative-model-raw-audio/
  28. https://twitter.com/petewarden
  29. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/?share=twitter
  30. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/?share=facebook
  31. https://petewarden.com/2017/10/27/the-joy-of-an-indian-paradox/
  32. https://petewarden.com/2017/11/13/deep-learning-is-eating-software/
  33. https://curatedsql.com/2017/10/30/position-differences-and-convolutional-neural-networks/
  34. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#comment-109270
  35. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/?replytocom=109270#respond
  36. https://thedatasciencewanderer.wordpress.com/2018/06/12/how-do-id98s-deal-with-position-differences/
  37. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#respond
  38. https://gravatar.com/site/signup/
  39. javascript:highlandercomments.doexternallogout( 'wordpress' );
  40. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/
  41. javascript:highlandercomments.doexternallogout( 'googleplus' );
  42. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/
  43. javascript:highlandercomments.doexternallogout( 'twitter' );
  44. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/
  45. javascript:highlandercomments.doexternallogout( 'facebook' );
  46. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/
  47. javascript:highlandercomments.cancelexternalwindow();
  48. https://twitter.com/petewarden
  49. https://petewarden.com/feed/
  50. https://petewarden.com/2019/03/27/scaling-machine-learning-models-to-embedded-devices/
  51. https://petewarden.com/2019/03/07/launching-tensorflow-lite-for-microcontrollers/
  52. https://petewarden.com/2018/10/16/will-compression-be-machine-learnings-killer-app/
  53. https://petewarden.com/2018/10/04/what-does-it-take-to-train-deep-learning-models-on-device/
  54. https://petewarden.com/2018/07/06/what-image-classifiers-can-do-about-unknown-objects/
  55. http://twitter.com/ngaloppo
  56. https://petewarden.com/2019/03/07/launching-tensorflow-lite-for-microcontrollers/comment-page-1/#comment-133125
  57. http://blog.ouseful.info/2019/03/15/warning-may-contain-traces-of-ai/
  58. https://petewarden.com/2019/03/07/launching-tensorflow-lite-for-microcontrollers/comment-page-1/#comment-133058
  59. http://makemypi.wordpress.com/
  60. https://petewarden.com/2017/08/20/cross-compiling-tensorflow-for-the-raspberry-pi/comment-page-1/#comment-132764
  61. https://makemypi.wordpress.com/2019/03/14/launching-tensorflow-lite-for-microcontrollers/
  62. https://petewarden.com/2019/03/07/launching-tensorflow-lite-for-microcontrollers/comment-page-1/#comment-132763
  63. http://twitter.com/towfiq
  64. https://petewarden.com/2019/03/07/launching-tensorflow-lite-for-microcontrollers/comment-page-1/#comment-132694
  65. https://petewarden.com/2019/03/
  66. https://petewarden.com/2018/10/
  67. https://petewarden.com/2018/07/
  68. https://petewarden.com/2018/06/
  69. https://petewarden.com/2018/05/
  70. https://petewarden.com/2018/04/
  71. https://petewarden.com/2018/03/
  72. https://petewarden.com/2018/02/
  73. https://petewarden.com/2018/01/
  74. https://petewarden.com/2017/12/
  75. https://petewarden.com/2017/11/
  76. https://petewarden.com/2017/10/
  77. https://petewarden.com/2017/08/
  78. https://petewarden.com/2017/07/
  79. https://petewarden.com/2017/06/
  80. https://petewarden.com/2017/05/
  81. https://petewarden.com/2017/04/
  82. https://petewarden.com/2017/01/
  83. https://petewarden.com/2016/12/
  84. https://petewarden.com/2016/09/
  85. https://petewarden.com/2016/05/
  86. https://petewarden.com/2016/04/
  87. https://petewarden.com/2016/03/
  88. https://petewarden.com/2016/02/
  89. https://petewarden.com/2015/11/
  90. https://petewarden.com/2015/10/
  91. https://petewarden.com/2015/09/
  92. https://petewarden.com/2015/08/
  93. https://petewarden.com/2015/05/
  94. https://petewarden.com/2015/04/
  95. https://petewarden.com/2015/03/
  96. https://petewarden.com/2015/01/
  97. https://petewarden.com/2014/12/
  98. https://petewarden.com/2014/11/
  99. https://petewarden.com/2014/10/
 100. https://petewarden.com/2014/09/
 101. https://petewarden.com/2014/08/
 102. https://petewarden.com/2014/07/
 103. https://petewarden.com/2014/06/
 104. https://petewarden.com/2014/05/
 105. https://petewarden.com/2014/04/
 106. https://petewarden.com/2014/03/
 107. https://petewarden.com/2014/02/
 108. https://petewarden.com/2014/01/
 109. https://petewarden.com/2013/12/
 110. https://petewarden.com/2013/11/
 111. https://petewarden.com/2013/10/
 112. https://petewarden.com/2013/09/
 113. https://petewarden.com/2013/08/
 114. https://petewarden.com/2013/07/
 115. https://petewarden.com/2013/06/
 116. https://petewarden.com/2013/05/
 117. https://petewarden.com/2013/04/
 118. https://petewarden.com/2013/03/
 119. https://petewarden.com/2013/02/
 120. https://petewarden.com/2013/01/
 121. https://petewarden.com/2012/11/
 122. https://petewarden.com/2012/10/
 123. https://petewarden.com/2012/08/
 124. https://petewarden.com/2012/07/
 125. https://petewarden.com/2012/06/
 126. https://petewarden.com/2012/05/
 127. https://petewarden.com/2012/04/
 128. https://petewarden.com/2012/03/
 129. https://petewarden.com/2012/02/
 130. https://petewarden.com/2012/01/
 131. https://petewarden.com/2011/12/
 132. https://petewarden.com/2011/11/
 133. https://petewarden.com/2011/10/
 134. https://petewarden.com/2011/09/
 135. https://petewarden.com/2011/08/
 136. https://petewarden.com/2011/07/
 137. https://petewarden.com/2011/06/
 138. https://petewarden.com/2011/05/
 139. https://petewarden.com/2011/04/
 140. https://petewarden.com/2011/03/
 141. https://petewarden.com/2011/02/
 142. https://petewarden.com/2011/01/
 143. https://petewarden.com/2010/12/
 144. https://petewarden.com/2010/11/
 145. https://petewarden.com/2010/10/
 146. https://petewarden.com/2010/09/
 147. https://petewarden.com/2010/08/
 148. https://petewarden.com/2010/07/
 149. https://petewarden.com/2010/06/
 150. https://petewarden.com/2010/05/
 151. https://petewarden.com/2010/04/
 152. https://petewarden.com/2010/03/
 153. https://petewarden.com/2010/02/
 154. https://petewarden.com/2010/01/
 155. https://petewarden.com/2009/12/
 156. https://petewarden.com/2009/11/
 157. https://petewarden.com/2009/10/
 158. https://petewarden.com/2009/09/
 159. https://petewarden.com/2009/08/
 160. https://petewarden.com/2009/07/
 161. https://petewarden.com/2009/06/
 162. https://petewarden.com/2009/05/
 163. https://petewarden.com/2009/04/
 164. https://petewarden.com/2009/03/
 165. https://petewarden.com/2009/02/
 166. https://petewarden.com/2009/01/
 167. https://petewarden.com/2008/12/
 168. https://petewarden.com/2008/11/
 169. https://petewarden.com/2008/10/
 170. https://petewarden.com/2008/09/
 171. https://petewarden.com/2008/08/
 172. https://petewarden.com/2008/07/
 173. https://petewarden.com/2008/06/
 174. https://petewarden.com/2008/05/
 175. https://petewarden.com/2008/04/
 176. https://petewarden.com/2008/03/
 177. https://petewarden.com/2008/02/
 178. https://petewarden.com/2008/01/
 179. https://petewarden.com/2007/12/
 180. https://petewarden.com/2007/11/
 181. https://petewarden.com/2007/10/
 182. https://petewarden.com/2007/09/
 183. https://petewarden.com/2007/08/
 184. https://petewarden.com/2007/07/
 185. https://petewarden.com/2007/06/
 186. https://petewarden.com/2007/05/
 187. https://petewarden.com/2007/04/
 188. https://petewarden.com/2007/03/
 189. https://petewarden.com/2006/12/
 190. https://petewarden.com/2006/11/
 191. https://petewarden.com/2006/10/
 192. https://petewarden.com/2006/09/
 193. https://petewarden.com/2006/08/
 194. https://petewarden.com/
 195. https://petewarden.com/
 196. https://petewarden.com/about/
 197. https://wordpress.com/?ref=footer_blog
 198. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#page
 199. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/
 200. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
 202. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/
 203. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#comment-form-guest
 204. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#comment-form-load-service:wordpress.com
 205. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#comment-form-load-service:twitter
 206. https://petewarden.com/2017/10/29/how-do-id98s-deal-with-position-differences/#comment-form-load-service:facebook
 207. http://twitter.com/ngaloppo
 208. http://blog.ouseful.info/2019/03/15/warning-may-contain-traces-of-ai/
 209. http://makemypi.wordpress.com/
 210. https://makemypi.wordpress.com/2019/03/14/launching-tensorflow-lite-for-microcontrollers/
 211. http://twitter.com/towfiq
