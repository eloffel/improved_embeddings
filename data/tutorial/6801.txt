   #[1]facebook research    feed [2]facebook research    comments feed
   [3]alternate [4]alternate

   [5]skip to content

   iframe: [6]https://www.googletagmanager.com/ns.html?id=gtm-wspss3d

   [7]facebook research
   search ____________________ (button) submit
   [8]toggle search (button)

     * [9]research areas (button) show dropdown menu
          + [10]ar/vr
          + [11]connectivity
          + [12]computational photography & intelligent cameras
          + [13]id161
          + [14]data science
          + [15]economics & computation
          + [16]facebook ai research
          + [17]human computer interaction & ux
          + [18]machine learning
          + [19]natural language processing & speech
          + [20]security & privacy
          + [21]systems & networking
     * [22]publications
     * [23]people
     * [24]academic programs (button) show dropdown menu
          + [25]facebook fellowship program
          + [26]research awards
          + [27]research collaborations
          + [28]research award recipients
          + [29]visiting researchers and postdocs
     * [30]downloads & projects
     * [31]careers
     * [32]blog

   search ____________________ (button) submit
   [33]close search

   september 7, 2017

facebook and microsoft introduce new open ecosystem for interchangeable ai
frameworks

   by: [34]joaquin qui  onero candela

   facebook and microsoft are today introducing open neural network
   exchange (onnx) format, a standard for representing deep learning
   models that enables models to be transferred between frameworks. onnx
   is the first step toward an open ecosystem where ai developers can
   easily move between state-of-the-art tools and choose the combination
   that is best for them.

   when developing learning models, engineers and researchers have many ai
   frameworks to choose from. at the outset of a project, developers have
   to choose features and commit to a framework. many times, the features
   chosen when experimenting during research and development are different
   than the features desired for shipping to production. many
   organizations are left without a good way to bridge the gap between
   these operating modes and have resorted to a range of creative
   workarounds to cope, such as requiring researchers work in the
   production system or translating models by hand.

   we developed onnx together with microsoft to bridge this gap and to
   empower ai developers to choose the framework that fits the current
   stage of their project and easily switch between frameworks as the
   project evolves. caffe2, pytorch, and cognitive toolkit will all be
   releasing support for onnx in september, which will allow models
   trained in one of these frameworks to be exported to another for
   id136. we invite the community to join the effort and support onnx
   in their ecosystem. enabling interoperability between different
   frameworks and streamlining the path from research to production will
   help increase the speed of innovation in the ai community.

onnx at facebook

   onnx is an important part of our deep learning approach here at
   facebook. in facebook   s ai teams (fair and aml), we are continuously
   trying to push the frontier of ai and develop better algorithms for
   learning. when we have a breakthrough, we   d like to make the better
   technologies available to people as soon as possible in our
   applications. with onnx, we are focused on bringing the worlds of ai
   research and products closer together so that we can innovate and
   deploy faster.

   people experimenting with new models, and particularly those in
   research, want maximum flexibility and expressiveness in writing neural
   networks     ranging from dynamic neural networks to supporting gradients
   of gradients, while keeping a bread-and-butter convnet performant.
   researchers also want to iterate rapidly, which means that they need
   excellent tooling for interactive development and debugging. pytorch
   has been built to push the limits of research frameworks, to unlock
   researchers from the constraints of a platform and allow them to
   express their ideas easier than before.

   conversely, product pipelines run training and id136 every day on
   massive amounts of new data, while keeping the model largely constant.
   carefully micro-optimizing the code specific to the product   s
   particular model, by doing tricks such as quantization and writing
   carefully hand-tuned code saves resources. [gg1] caffe2 has been built
   with products, mobile, and extreme performance in mind. the internals
   of caffe2 are flexible and highly optimized, so we can ship bigger and
   better models into underpowered hardware using every trick in the book.

   with onnx, we can get the best of both worlds. we can now export models
   for many common neural networks from pytorch and deploy them on caffe2.
   this is the first step in enabling us to rapidly move our latest
   research developments into production. over the coming months, we will
   be enhancing onnx and releasing improvements to caffe2 and pytorch that
   enable them to interoperate more deeply.

how it works

   to implement onnx support, we had to make changes to both pytorch and
   caffe2 and also unify operators between the frameworks. in caffe2, this
   process was similar to adding a translator because caffe2 already had a
   static graph representation built-in. in pytorch, neural networks are
   specified as programs rather than explicit graphs, which posed a bigger
   challenge. in order to extract a graph from the program, we developed a
   tracer, which    traces   , i.e. records, the execution of the program as
   it runs. tracing the program eliminates complexity and makes it easier
   to translate into a graph representation.

   to see how it works, consider the following piece of code:
x = y * 2
if somecomplicatedfunction():
  z = x + y
else:
  z = x * y

   to directly export this code, onnx would have to support conditionals
   and somecomplicatedfunction(); in effect, becoming a general purpose
   programming language. however, in many deep learning models, the result
   of somecomplicatedfunction() is always the same during id136. for
   example, in pytorch conditionals are often some computation on the
   sizes or dimensions of input tensors. in these cases, a single trace
   through the code would be far simpler and can easily be represented in
   onnx:
#somecomplicatedfunction() == true
x = y * 2
z = x + y

   currently, our tracer works with many common neural networks, but not
   some of the more advanced programs in pytorch such as those with
   dynamic flow control. over time, we will enhance onnx and the tracer to
   support these programs, so that developers can leverage full
   flexibility of pytorch with the high-performance robust deployment
   capabilities of caffe2.

what   s next

   we are releasing the newest versions of caffe2 and pytorch with onnx
   support today. we hope that you   re as excited as we are about the new
   features! they are at an early stage, so we hope that you   ll check them
   out and submit your feedback and improvements. we   ll continue to evolve
   onnx, pytorch, caffe2 to make sure developers have the latest tools for
   ai, so expect more updates soon!

getting started with onnx

   [35]onnx
   [36]caffe2
   [37]pytorch
   [38]super resolution tutorial
   [39]microsoft blog


   areas: [40]facebook ai research facebook ai research [41]machine
   learning machine learning

related content

   [42]

   blog

open-sourcing pytorch-biggraph for faster embeddings of extremely large
graphs

   april 2, 2019
   [43]

   blog

turing award presented to yann lecun, geoffrey hinton and yoshua bengio

   march 27, 2019
   [44]

   blog

q&a with facebook ai residents tatiana likhomanenko and siddharth karamcheti

   march 15, 2019
   [45]

   blog

facebook ai researchers share perspectives on diversity on international
women   s day

   march 8, 2019

   iframe:
   [46]https://www.facebook.com/plugins/page.php?href=https%3a%2f%2fwww.fa
   cebook.com%2facademics&tabs&width=340&height=70&small_header=true&adapt
   _container_width=true&hide_cover=true&show_facepile=false&appid

     * [47]rss feed
     * [48]about
     * [49]careers
     * [50]privacy
     * [51]cookies
     * [52]terms
     * [53]help

   facebook    2019

   to help personalize content, tailor and measure ads, and provide a
   safer experience, we use cookies. by clicking or navigating the site,
   you agree to allow our collection of information on and off facebook
   through cookies. learn more, including about available controls:
   [54]cookies policy

references

   1. https://research.fb.com/feed/
   2. https://research.fb.com/comments/feed/
   3. https://research.fb.com/wp-json/oembed/1.0/embed?url=https://research.fb.com/facebook-and-microsoft-introduce-new-open-ecosystem-for-interchangeable-ai-frameworks/
   4. https://research.fb.com/wp-json/oembed/1.0/embed?url=https://research.fb.com/facebook-and-microsoft-introduce-new-open-ecosystem-for-interchangeable-ai-frameworks/&format=xml
   5. https://research.fb.com/facebook-and-microsoft-introduce-new-open-ecosystem-for-interchangeable-ai-frameworks/#content
   6. https://www.googletagmanager.com/ns.html?id=gtm-wspss3d
   7. https://research.fb.com/
   8. javascript:void(0)
   9. https://research.fb.com/research-areas/
  10. https://research.fb.com/category/augmented-reality-virtual-reality/
  11. https://research.fb.com/category/connectivity/
  12. https://research.fb.com/category/computational-photography-and-intelligent-cameras/
  13. https://research.fb.com/category/computer-vision/
  14. https://research.fb.com/category/data-science/
  15. https://research.fb.com/category/economics-and-computation/
  16. https://research.fb.com/category/facebook-ai-research
  17. https://research.fb.com/category/human-computer-interaction-and-ux/
  18. https://research.fb.com/category/machine-learning/
  19. https://research.fb.com/category/natural-language-processing-and-speech/
  20. https://research.fb.com/category/security-and-privacy/
  21. https://research.fb.com/category/systems-and-networking/
  22. https://research.fb.com/publications/
  23. https://research.fb.com/people/
  24. https://research.fb.com/programs/
  25. https://research.fb.com/programs/fellowship/
  26. https://research.fb.com/programs/research-awards/
  27. https://research.fb.com/programs/research-collaborations/
  28. https://research.fb.com/programs/faculty-awards
  29. https://research.fb.com/programs/post-docs-and-sabbaticals/
  30. https://research.fb.com/downloads/
  31. https://research.fb.com/careers/
  32. https://research.fb.com/blog/
  33. javascript:void(0)
  34. https://research.fb.com/people/quinonero-candela-joaquin/
  35. https://github.com/onnx
  36. https://caffe2.ai/
  37. http://pytorch.org/
  38. http://pytorch.org/tutorials/advanced/super_resolution_with_caffe2.html
  39. https://www.microsoft.com/en-us/cognitive-toolkit/blog/2017/09/microsoft-facebook-create-open-ecosystem-ai-model-interoperability/
  40. https://research.fb.com/category/facebook-ai-research/
  41. https://research.fb.com/category/machine-learning/
  42. https://ai.facebook.com/blog/open-sourcing-pytorch-biggraph-for-faster-embeddings-of-extremely-large-graphs/
  43. https://research.fb.com/turing-award-presented-to-yann-lecun-geoffrey-hinton-and-yoshua-bengio/
  44. https://research.fb.com/qa-with-facebook-ai-residents-tatiana-likhomanenko-and-siddharth-karamcheti/
  45. https://research.fb.com/facebook-ai-researchers-share-perspectives-on-diversity-on-international-womens-day/
  46. https://www.facebook.com/plugins/page.php?href=https://www.facebook.com/academics&tabs&width=340&height=70&small_header=true&adapt_container_width=true&hide_cover=true&show_facepile=false&appid
  47. https://research.fb.com/feed/
  48. https://www.facebook.com/facebook
  49. https://www.facebook.com/careers/university/
  50. https://www.facebook.com/about/privacy
  51. https://www.facebook.com/help/cookies
  52. https://www.facebook.com/policies
  53. https://www.facebook.com/help
  54. https://www.facebook.com/policies/cookies/
