   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

ai planning historical developments

   [16]go to the profile of ryan shrott
   [17]ryan shrott (button) blockedunblock (button) followfollowing
   sep 4, 2017
   [1*gotctj9mzxmwx4wjzpnoca.jpeg]
   ai agent planning puzzle ([18]credit)

   in this article, i will examine three major developments in the field
   of ai planning research. for each development, i will provide a short
   summary of the original paper along with appropriate examples to
   demonstrate several use cases. i will begin by describing a general
   framework, strips, under which all planning problems can be formulated.
   i will then examine two state of the art algorithms which work under
   the strips formulation. instead of greedily searching for a solution
   from the start, the graphplan algorithm constructs a planning graph
   object which can be used to obtain a solution. a planning graph object
   can also be used for automating heuristics for any planning problem
   specified in the strips framework. finally, i will examine an algorithm
   which uses a heuristic search planner to automate the production of
   effective heuristics. the final algorithm was the winner of the aips98
   planning contest in 1998.

development 1: strips (1971)

   in 1971, richard fikes and nils nilsson at stanford research institute
   developed a new approach to the application of theorem proving in
   problem solving [1]. the model attempts to find a sequence of operators
   in a space of world models to transform the initial world model into a
   model in which the goal state exists. it attempts to model the world as
   a set of first-order predicate formulas and is designed to work with
   models consisting of a large number of formulas.

   in the strips formulation, we assume that there exists a set of
   applicable operators which transform the world model into some other
   world model. the task of the problem solver is to find a sequence of
   operators which transform the given initial problem into one that
   satisfies the goal conditions. operators are the basic elements from
   which a solution is built. each operator corresponds to an action
   routine whose execution causes the agent to take certain actions. in
   strips, the process of theorem proving and searching are separated
   through a space of world models.

   formally, the problem space for strips is defined by the initial world
   model, the set of available operators and their effects on world
   models, and the goal statement. the available operators are grouped
   into families called schemata. each operator is defined by a
   description consisting of two main parts: the effects the operator has
   and conditions under which the operator is applicable. a problem is
   said to be solved when strips produces a world model that satisfies the
   goal statement.

   let us now consider an example of applying the strips language to an
   air cargo transport system using a planning search agent. suppose we
   have an initial state of cargo 1 at sfo, cargo 2 at jfk, plane 1 at sfo
   and plane 2 at jfk. now suppose we want to formulate an optimal plan to
   transport cargo 1 to jfk and cargo 2 to sfo. summarizing this problem
   description, we have:

   init(at(c1, sfo)     at(c2, jfk)
        at(p1, sfo)     at(p2, jfk)
        cargo(c1)     cargo(c2)
        plane(p1)     plane(p2)
        airport(jfk)     airport(sfo))
   goal(at(c1, jfk)     at(c2, sfo))

   we can write a function that formally defines this formulation as
   follows:
def air_cargo_p1() -> aircargoproblem:
    cargos = ['c1', 'c2']
    planes = ['p1', 'p2']
    airports = ['jfk', 'sfo']
    pos = [expr('at(c1, sfo)'),
           expr('at(c2, jfk)'),
           expr('at(p1, sfo)'),
           expr('at(p2, jfk)'),
           ]
    neg = [expr('at(c2, sfo)'),
           expr('in(c2, p1)'),
           expr('in(c2, p2)'),
           expr('at(c1, jfk)'),
           expr('in(c1, p1)'),
           expr('in(c1, p2)'),
           expr('at(p1, jfk)'),
           expr('at(p2, sfo)'),
           ]
    init = fluentstate(pos, neg)
    goal = [expr('at(c1, jfk)'),
            expr('at(c2, sfo)'),
            ]
    return aircargoproblem(cargos, planes, airports, init, goal)

   the aircargoproblem class would be initialized as follows:
class aircargoproblem(problem):
    def __init__(self, cargos, planes, airports, initial: fluentstate, goal: lis
t):
        """:param cargos: list of str
            cargos in the problem
        :param planes: list of str
            planes in the problem
        :param airports: list of str
            airports in the problem
        :param initial: fluentstate object
            positive and negative literal fluents (as expr) describing initial s
tate
        :param goal: list of expr
            literal fluents required for goal test
        """
        self.state_map = initial.pos + initial.neg
        self.initial_state_tf = encode_state(initial, self.state_map)
        problem.__init__(self, self.initial_state_tf, goal=goal)
        self.cargos = cargos
        self.planes = planes
        self.airports = airports
        self.actions_list = self.get_actions()

   we use the get_actions method to instantiate a list of all
   action/operator objects which can act on the states. there are three
   types of actions we can take in this air cargo problem: load, unload
   and fly. the get_actions class method collect all such possible
   actions.

   to define the operators which can act on a certain state, we can define
   the actions class method as follows:
def actions(self, state: str) -> list:
 """ return the actions that can be executed in the given state.
:param state: str
 state represented as t/f string of mapped fluents (state variables)
            e.g. 'ftttff'
        :return: list of action objects
        """
        # todo implement
        possible_actions = []
        kb = propkb()
        kb.tell(decode_state(state, self.state_map).pos_sentence())
        for action in self.actions_list:
              is_possible = true
              for clause in action.precond_pos:
                if clause not in kb.clauses:
                    is_possible = false
              for clause in action.precond_neg:
                if clause in kb.clauses:
                    is_possible = false
              if is_possible:
                possible_actions.append(action)

        return possible_actions

   the action method effectively outputs a list of possible actions by
   checking if the preconditions of the action are in the set of clauses
   specified by the input state. we also need to define a method for
   applying an action to a given state. the result of executing action a
   in state s is defined as a state s    which is represented by the set of
   fluents formed by starting with s, removing the fluents that appear as
   negative literals in the action   s effects and adding the fluents that
   are positive literals in the action   s effects.
def result(self, state: str, action: action):
        """ return the state that results from executing the given
        action in the given state. the action must be one of
        self.actions(state).
:param state: state entering node
        :param action: action applied
        :return: resulting state after action
        """
        # todo implement
        new_state = fluentstate([], [])
        old_state = decode_state(state, self.state_map)

        for fluent in old_state.pos:
            if fluent not in action.effect_rem:
                new_state.pos.append(fluent) # add positive fluents which are in
 the old state and should not be removed

        for fluent in action.effect_add:
            if fluent not in new_state.pos:
                new_state.pos.append(fluent) # add positive fluents which should
 be added and have not already been added

        for fluent in old_state.neg:
            if fluent not in action.effect_add:
                new_state.neg.append(fluent) # add negative fluents which are in
 the old state and should not be added

        for fluent in action.effect_rem:
            if fluent not in new_state.neg:
                new_state.neg.append(fluent) # add negative fluents which should
 be removed but have not already been removed from the negative state

        return encode_state(new_state, self.state_map)

   finally, we need to define the goal test method which provides a
   boolean value indicating whether the goal state is satisfied.
def goal_test(self, state: str) -> bool:
        """ test the state to see if goal is reached
:param state: str representing state
        :return: bool
        """
        kb = propkb()
        kb.tell(decode_state(state, self.state_map).pos_sentence())
        for clause in self.goal:
            if clause not in kb.clauses:
                return false
        return true

   this class provides an example of a strips formulation. in particular,
   we have specified the initial state, the goal state and a set of
   actions which specify preconditions and postconditions. a plan for this
   planning instance is a sequence of operators that can execute from the
   initial state and lead to a goal state. we can use progression search
   algorithms to form optimal plans for this example problem. using
   breadth-first-search on this problem, the optimal plan would be
   load(c2, p2, jfk), load(c1, p1, sfo), fly(p2, jfk, sfo), unload(c2, p2,
   sfo), fly(p1, sfo, jfk), unload(c1, p1, jfk).

development 2: planning graphs (1997)

   in 1997, avrium blum and merrick furst at carnegie mellon developed a
   new approach to planing in strips-like domains [2]. it involved
   constructing and analyzing a brand new object called a planning graph.
   they developed a routine called graphplan which obtains the solution to
   the planning problem using a planning graph construct.

   the idea is that rather than greedily searching, we first create a
   planning graph object. the planning graph is useful because it
   inherently encodes useful constraints explicitly, thereby reducing the
   search overhead in the future. planning graphs can be constructed in
   polynomial time and have polynomial size. on the other hand, the state
   space search is exponential and is much more work to build. planning
   graphs are not only based on domain information, but also the goals and
   initial conditions of the problem and an explicit notion of time.

   planning graphs have similar features to id145 problem
   solvers. the graphplan algorithm uses a planning graph to guide its
   search for a plan. the algorithm guarantees that the shortest plan will
   be found (similar to bfs).

   edges in a planning graph represent relations between actions and
   propositions. if a valid plan does exist in the strips formulation,
   then that plan must exist as a subgraph of the planning graph. another
   essential feature of planning graphs involve specifying mutually
   exclusive (mutex) relationships. two actions are mutex if no valid plan
   could possibly contain both, and two states are mutex if no valid plan
   could make both simultaneously true. exclusion relationships propagate
   intuitively useful facts about the problem throughout the graph.

   the graphplan algorithm operates on the planning graph as follows:
   start with a planning graph that only encodes the initial conditions.
   in stage i, graphplan take the the planning graph from state i-1 and
   extends it one time step and then searches the extended planning graph
   for a valid plan of length i. if it finds a solution, then it halts,
   otherwise it continues to the next stage. any plan that the algorithm
   finds is a legal plan and it will always find a plan if one exists. the
   algorithm also has a termination guarantee that is not provided by most
   planners.

   let   s now construct a basic planning graph object and use it solve the
   air cargo problem above. i leave out low level implementation details
   to reduce the length of this article. as always, the code is hosted on
   my github. we initialize the structure as follows:
class planninggraph():
    """
    a planning graph as described in chapter 10 of the aima text. the planning
    graph can be used to reason about
    """
def __init__(self, problem: problem, state: str, serial_planning=true):
        """
        :param problem: planningproblem (or subclass such as aircargoproblem or
havecakeproblem)
        :param state: str (will be in form tfttff... representing fluent states)
        :param serial_planning: bool (whether or not to assume that only one act
ion can occur at a time)
        instance variable calculated:
            fs: fluentstate
                the state represented as positive and negative fluent literal li
sts
            all_actions: list of the planningproblem valid ground actions combin
ed with calculated no-op actions
            s_levels: list of sets of pgnode_s, where each set in the list repre
sents an s-level in the planning graph
            a_levels: list of sets of pgnode_a, where each set in the list repre
sents an a-level in the planning graph
        """
        self.problem = problem
        self.fs = decode_state(state, problem.state_map)
        self.serial = serial_planning
        self.all_actions = self.problem.actions_list + self.noop_actions(self.pr
oblem.state_map)
        self.s_levels = []
        self.a_levels = []
        self.create_graph()

   the create_graph method is as follows:
def create_graph(self):
        """ build a planning graph as described in russell-norvig 3rd ed 10.3 or
 2nd ed 11.4
the s0 initial level has been implemented for you.  it has no parents and includ
es all of
        the literal fluents that are part of the initial state passed to the con
structor.  at the start
        of a problem planning search, this will be the same as the initial state
 of the problem.  however,
        the planning graph can be built from any state in the planning problem
this function should only be called by the class constructor.
:return:
            builds the graph by filling s_levels[] and a_levels[] lists with nod
e sets for each level
        """
        # the graph should only be built during class construction
        if (len(self.s_levels) != 0) or (len(self.a_levels) != 0):
            raise exception(
                'planning graph already created; construct a new planning graph
for each new state in the planning sequence')
# initialize s0 to literals in initial state provided.
        leveled = false
        level = 0
        self.s_levels.append(set())  # s0 set of s_nodes - empty to start
        # for each fluent in the initial state, add the correct literal pgnode_s
        for literal in self.fs.pos:
            self.s_levels[level].add(pgnode_s(literal, true))
        for literal in self.fs.neg:
            self.s_levels[level].add(pgnode_s(literal, false))
        # no mutexes at the first level
# continue to build the graph alternating a, s levels until last two s levels co
ntain the same literals,
        # i.e. until it is "leveled"
        while not leveled:
            self.add_action_level(level)
            self.update_a_mutex(self.a_levels[level])
level += 1
            self.add_literal_level(level)
            self.update_s_mutex(self.s_levels[level])
if self.s_levels[level] == self.s_levels[level - 1]:
                leveled = true

   the mutex methods are left as an exercise to the reader. another
   application of a planning graph is in heuristic estimation. we can
   estimate the cost of achieving any subgoal from state s as the level at
   which the goal first appears in the planning graph. if we assume that
   all the subgoals are independent we can simply estimate the total goal
   cost as the sum of subgoal costs as given in the planning graph. this
   heuristic would be implemented in the planning graph class as follows:
def h_levelsum(self) -> int:
        """the sum of the level costs of the individual goals (admissible if goa
ls independent)
:return: int
        """
        level_sum = 0
        goals = [pgnode_s(g, true) for g in self.problem.goal]
        # for each goal in the problem, determine the level cost, then add them
together
        for g in goals:
            if g not in self.s_levels[-1]:
                # the problem is unsolvable
                print('unsolvable')
                level_sum = float('inf')
                break
            else:
                for level, s in enumerate(self.s_levels):
                    if g in s:
                        level_sum += level
                        break
        return level_sum

   we can call this method within the aircargoproblem class as follows:
def h_pg_levelsum(self, node: node):
        """this heuristic uses a planning graph representation of the problem
        state space to estimate the sum of all actions that must be carried
        out from the current state in order to satisfy each individual goal
        condition.
        """
        # requires implemented planninggraph class
        pg = planninggraph(self, node.state)
        pg_levelsum = pg.h_levelsum()
        return pg_levelsum

   using this heuristic, we can very efficiently solve complex planning
   problems using the a* algorithm. i considered much more complex
   planning problems with several heuristics and found that the level_sum
   heuristic significantly outperformed (in terms of time and space
   complexity) all standard search algorithms including a* with relaxed
   problem heuristics.

development 3: heuristic search planner (hsp) (1998)

   hsp is based on the idea of heuristic search. a heuristic search
   provides an estimate of the distance to the goal. in domain independent
   planning, heuristics need to be derived from the representation of
   actions and goals. a common way to derive a heuristic function is to
   solve a relaxed version of the problem. the main issue is that often
   the relaxed problem heuristic computation is np-hard.

   the hsp algorithm instead estimates the optimal value of the relaxed
   problem. the algorithm transforms the problem into a heuristic search
   by automatically extracting heuristics from the strips encodings.

   the algorithm works iteratively by generating states by the actions
   whose preconditions held in the previous state set [3]. each time an
   action is applied, a measure g is updated, which aims to estimate the
   number of steps involved in achieving a subgoal. for example, suppose p
   were a subgoal. we initialize g to zero and then when an action with
   preconditions c = r_1, r_2,   ,r_n is applied, we update g as follows:
   [1*dog_02ruay3lvbjlds3jjg.png]

   it can be shown that the procedure explained above is equivalent to
   computing the function:
   [1*323x5frmmr_9luc1c6rhlq.png]

   where c         >p stands for the actions that assert p and have
   preconditions c = r_1, r_2,   ,r_n. then if we let g be the set of goal
   states, the final heuristic function would be as follows:
   [1*9mdagokd-9_vcmx-_62tlw.png]

   note that we assume that all subgoals are independent it may be the
   case that the heuristic is not admissible: this usually works well in
   practice. this hsp method is useful because it allows us to generalize
   a heuristic computation to any general strips problem formulation.

conclusion

   the developments discussed in this article constitute 3 major
   advancements in the field of ai planning. the strips formulation gave
   researchers a general framework from which more advanced languages
   could be built. the planning graph construct was a revolutionary data
   structure which gave a whole new perspective on optimal planning
   techniques. finally, the hsp algorithm gives an automated approach for
   determining heuristics to general planning problems.

   that   s all folks         if you   ve made it this far, please comment below and
   add me on [19]linkedin.

   my github is [20]here.

references

   [1] [21]strips paper

   [2] [22]graphplan paper

   [3] [23]hsp paper

     * [24]artificial intelligence
     * [25]machine learning
     * [26]programming
     * [27]data science
     * [28]towards data science

   (button)
   (button)
   (button) 254 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [29]go to the profile of ryan shrott

[30]ryan shrott

   equity desk quant at bmo capital markets
   [31]https://github.com/ryanshrott

     (button) follow
   [32]towards data science

[33]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 254
     * (button)
     *
     *

   [34]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [35]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/edcd9f24c991
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/ai-planning-historical-developments-edcd9f24c991&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/ai-planning-historical-developments-edcd9f24c991&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_4k49lr9ikigf---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@ryanshrott?source=post_header_lockup
  17. https://towardsdatascience.com/@ryanshrott
  18. http://www.dog-gmbh.de/de/blog/archiv/
  19. https://www.linkedin.com/in/ryanshrott/
  20. https://github.com/ryanshrott
  21. http://ai.stanford.edu/~nilsson/onlinepubs-nils/publishedpapers/strips.pdf
  22. https://www.cs.cmu.edu/~avrim/papers/graphplan.pdf
  23. https://bonetblai.github.io/reports/aips98-competition.pdf
  24. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  25. https://towardsdatascience.com/tagged/machine-learning?source=post
  26. https://towardsdatascience.com/tagged/programming?source=post
  27. https://towardsdatascience.com/tagged/data-science?source=post
  28. https://towardsdatascience.com/tagged/towards-data-science?source=post
  29. https://towardsdatascience.com/@ryanshrott?source=footer_card
  30. https://towardsdatascience.com/@ryanshrott
  31. https://github.com/ryanshrott
  32. https://towardsdatascience.com/?source=footer_card
  33. https://towardsdatascience.com/?source=footer_card
  34. https://towardsdatascience.com/
  35. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  37. https://medium.com/p/edcd9f24c991/share/twitter
  38. https://medium.com/p/edcd9f24c991/share/facebook
  39. https://medium.com/p/edcd9f24c991/share/twitter
  40. https://medium.com/p/edcd9f24c991/share/facebook
