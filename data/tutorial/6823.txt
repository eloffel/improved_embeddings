   #[1]github [2]recent commits to beholder:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]21
     * [35]star [36]468
     * [37]fork [38]20

[39]chrisranderson/[40]beholder

   [41]code [42]issues 23 [43]pull requests 1 [44]projects 1 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   a tensorboard plugin for visualizing arbitrary tensors in a video as
   your network trains.
   [47]tensorboard [48]visualization [49]tensorflow [50]neural-networks
   [51]video
     * [52]123 commits
     * [53]5 branches
     * [54]0 releases
     * [55]fetching contributors

    1. [56]python 79.1%
    2. [57]html 20.9%

   (button) python html
   branch: master (button) new pull request
   [58]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/c
   [59]download zip

downloading...

   want to be notified of new releases in chrisranderson/beholder?
   [60]sign in [61]sign up

launching github desktop...

   if nothing happens, [62]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [63]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [64]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [65]download the github extension for visual studio
   and try again.

   (button) go back
   [66]@chrisranderson
   [67]chrisranderson [68]update readme.md
   latest commit [69]91771bf feb 7, 2019
   [70]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [71]beholder [72]small file reading fix for python 3. travis try 4. aug
   27, 2017
   [73]readme-images
   [74].gitignore [75]fix slow issue with tf.contrib.util.make_ndarray.
   aug 4, 2017
   [76].pylintrc
   [77].travis.yml [78]travis try 3. aug 27, 2017
   [79]readme.md [80]update readme.md feb 6, 2019
   [81]workspace
   [82]setup.py

readme.md

beholder is now part of [83]tensorboard as of [84]this pull request, and is
now maintained by the tensorboard team. see [85]this comment for the latest
information on how to use beholder with your project.
     __________________________________________________________________

beholder

   good news: beholder is on track to be merged into tensorboard. see
   [86]this issue for discussion and [87]this milestone for issues related
   to the merge.

   [88]beholder demo video

   beholder is a tensorboard plugin for viewing frames of a video while
   your model trains. it comes with tools to visualize the parameters of
   your network, visualize arbitrary arrays like gradients,

   [89]gradient example

   activations from a convolutional layer,

   [90]conv activation example

   or frames that you've already created:

   [91]frame example

   [92]i made a demo video you can watch, but you can find similar
   information in this readme.

installation

build and run tensorboard

   as tensorboard's third party plugin system currently functions, you
   need to build a different version of tensorboard from scratch to use
   this plugin.
    1. [93]install bazel. tested with bazel 0.5.1 and 0.5.3. one test with
       0.2.2b did not work.
    2. clone the repository: git clone
       https://github.com/chrisranderson/beholder.git
    3. cd beholder
    4. install beholder: pip install .
    5. build tensorboard (this may take a while): bazel build
       beholder/tensorboard_x
    6. run the newly built tensorboard:
       ./bazel-bin/beholder/tensorboard_x/tensorboard_x
       --logdir=/tmp/beholder-demo
    7. navigate to [94]http://localhost:6006

install a nightly build of tensorflow

   this repository uses a version of tensorboard that is newer than the
   one that comes with tensorflow. that version of tensorboard relies on a
   nightly build of tensorflow. you can find nightly builds on [95]the
   tensorflow readme, and pip install <wheel_file> to install, or use pip
   install tf-nightly to get a nightly build of the cpu only version.

run the demo

   bazel build beholder/demos/demo && ./bazel-bin/beholder/demos/demo/demo

quick start

   before your train loop, instantiate a beholder:
from beholder.beholder import beholder
visualizer = beholder(session=sess,
                      logdir=log_directory)

   in your train loop, trigger an update:
visualizer.update() # visualizes tf.trainable_variables() by default

   update takes two optional parameters: arrays expects a list of
   arbitrary numpy arrays (like gradients or activations returned from
   sess.run) and frame expects a 2d numpy array:
evaluated_tensors = session.run([var1, var2, var3])
example_frame = np.random.randint(1, 255, (100, 100))
visualizer.update(arrays=evaluated_tensors, frame=example_frame)

visualization guide

array visualization

   each array is reshaped to fit in a rectangular box called a section.
   sections are composed of groups of pixels called blocks that represent
   individual values in the original array. when tf.trainable_variables()
   is selected, the lower the section is in the image, the deeper it is in
   the network.

   not all values of large arrays will be shown unless the show all data
   option is selected (with the exception of [96]oddly shaped arrays).
   [97]here's an example frame when show all data is enabled on a vgg
   network variant. you'll need to download it to view the image at full
   scale.

1d arrays (e.g. biases)

   [98]bias each block in this section represents an individual value in
   the array.

2d arrays (e.g. fully connected layers)

   [99]fully connected each row represents weights attached to the same
   input node, each column represents weights attached to the same output
   node. bias values immediately below correspond to the output node in
   the column immediately above them.

4d arrays (e.g. convolution layers)

   [100]convolution layer

   4d layers are assumed to be convolution weights. here's a zoomed in
   version of the top left corner, with some areas highlighted:

   [101]convolution layer zoomed in

   the orange 3x3 chunk is a single channel of a kernel. rows of chunks
   (in yellow) correspond to the same input channel. columns of chunks (in
   red) correspond to output channels. if the shape of your weight matrix
   is (2, 3, 256, 512), there will be 256 rows and 512 columns of 2x3
   blocks (assuming the show all data option is selected).

   using the current values option, you can determine whether there is
   high information content in your kernels. if the network has finished
   training and you have many columns that look similar, you might be able
   to conclude that there are redundancy issues and you can decrease the
   layer size.

   if the shape of the network "looks like" a 4d activation (if shape[0]
   != shape[1] and shape[1] == shape[2]) from a conv layer rather than a
   weight array, i reshape it differently: [102]conv activation example

other arrays

   other arrays will be flattened and reshaped so that each block is
   approximately square. if show all data is selected, some values still
   may not be shown. rather than pad the final row with zeros, i truncate
   it.

toolbar controls

values

   [103]values options
     * tf.trainable_variables(): visualize
       sess.run(tf.trainable_variables()), the parameters of the network.
     * b.update(arrays=[2d_arrays]): b is an instance of beholder.
       visualize whatever arrays you pass into the update function. useful
       for visualizing gradients or activations.
     * b.update(frame=2d_array): b is an instance of beholder. displays
       whatever image (as a numpy array) you give it. will be scaled to
       [0, 255]. 2d_array can also be a function that returns a frame (to
       prevent creating the frame while this option isn't selected). this
       option can be useful when the output of your network is an image
       (e.g. image gans or style transfer).
     * show all data: by default, arrays are truncated when they are
       visualized to save on computation costs. if this option is
       selected, it shows a minimum of one pixel per parameter.
       interesting, but can be very costly. updates per second can be set
       to zero to avoid calculating frames while you take a closer look at
       the current frame, allowing your model to train quickly again.

mode

   [104]mode options
     * current values: displays the current values of the current arrays.
     * variance over train steps: keeps track of array values over time,
       and displays the variance of array values. this option might be
       used to visualize vanishing gradients: if the all sections option
       is selected, and there is a lot more white at the bottom than the
       top, maybe you need to change your activation function, or use
       batch norm or something. :)
     * variance timesteps: when variance is computed, this determines the
       number of time steps to compute variance over. for example, if
       variance timesteps is 20, beholder will keep track of array values
       over the last 20 times that update is called (not the last 20 train
       steps, necessarily), and compute variance across those 20 sets of
       arrays.

image scaling

   [105]image scaling
     * per section: black is the lowest value in that section, white is
       the highest value in that section.
     * all sections: black is the lowest value across all sections, white
       is the highest value across all sections.

updates per second

   [106]updates per second

   updates per second: determines how often the current option is
   computed. for example, if updates per second is 10 and
   tf.trainable_variables() is selected, it will compute a visualization
   for that option only at a maximum of 10 times per second.

   it can be useful to set this option to 0 when you aren't looking at the
   visualization, or would like to pause and look at a frame. the
   visualization will not be computed, allowing your model to train at
   full speed (some small things including a disk read still happen, but
   they are small operations).

recording

   [107]start recording

   if ffmpeg is installed, it streams frames to ffmpeg until you click
   stop recording, and it saves an mp4 in <logdir>/plugins/beholder.

   if ffmpeg is not installed, it saves pngs to
   <logdir>/plugins/beholder/video-frames-<timestamp>.

   whether ffmpeg is installed or not, a new recording starts whenever the
   shape of the visualization changes. for example, if
   b.update(arrays=[2d_arrays]) is selected when you start recording, and
   the image displayed is 768x1500, and you switch to
   b.update(frame=2d_array) and the image displayed is 400x400, a new
   recording will start.

feedback

   please let me hear your thoughts/complaints/suggestions/success
   stories/unrelated banter. [108]submit an issue, or [109]send me a
   direct message on twitter (you don't need to follow me to send me a
   message).

hiring?

   i'm graduating soon with my master's degree in computer science, and
   i'll be available for full-time work in january (2018). if you or
   someone you know is hiring software engineers and may be interested,
   please let me know at [110]chris.anderson@byu.net.

     *    2019 github, inc.
     * [111]terms
     * [112]privacy
     * [113]security
     * [114]status
     * [115]help

     * [116]contact github
     * [117]pricing
     * [118]api
     * [119]training
     * [120]blog
     * [121]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [122]reload to refresh your
   session. you signed out in another tab or window. [123]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/chrisranderson/beholder/commits/master.atom
   3. https://github.com/chrisranderson/beholder#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/chrisranderson/beholder
  32. https://github.com/join
  33. https://github.com/login?return_to=/chrisranderson/beholder
  34. https://github.com/chrisranderson/beholder/watchers
  35. https://github.com/login?return_to=/chrisranderson/beholder
  36. https://github.com/chrisranderson/beholder/stargazers
  37. https://github.com/login?return_to=/chrisranderson/beholder
  38. https://github.com/chrisranderson/beholder/network/members
  39. https://github.com/chrisranderson
  40. https://github.com/chrisranderson/beholder
  41. https://github.com/chrisranderson/beholder
  42. https://github.com/chrisranderson/beholder/issues
  43. https://github.com/chrisranderson/beholder/pulls
  44. https://github.com/chrisranderson/beholder/projects
  45. https://github.com/chrisranderson/beholder/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/tensorboard
  48. https://github.com/topics/visualization
  49. https://github.com/topics/tensorflow
  50. https://github.com/topics/neural-networks
  51. https://github.com/topics/video
  52. https://github.com/chrisranderson/beholder/commits/master
  53. https://github.com/chrisranderson/beholder/branches
  54. https://github.com/chrisranderson/beholder/releases
  55. https://github.com/chrisranderson/beholder/graphs/contributors
  56. https://github.com/chrisranderson/beholder/search?l=python
  57. https://github.com/chrisranderson/beholder/search?l=html
  58. https://github.com/chrisranderson/beholder/find/master
  59. https://github.com/chrisranderson/beholder/archive/master.zip
  60. https://github.com/login?return_to=https://github.com/chrisranderson/beholder
  61. https://github.com/join?return_to=/chrisranderson/beholder
  62. https://desktop.github.com/
  63. https://desktop.github.com/
  64. https://developer.apple.com/xcode/
  65. https://visualstudio.github.com/
  66. https://github.com/chrisranderson
  67. https://github.com/chrisranderson/beholder/commits?author=chrisranderson
  68. https://github.com/chrisranderson/beholder/commit/91771bf48602039e13425f59d9dd7c9d01d2ef89
  69. https://github.com/chrisranderson/beholder/commit/91771bf48602039e13425f59d9dd7c9d01d2ef89
  70. https://github.com/chrisranderson/beholder/tree/91771bf48602039e13425f59d9dd7c9d01d2ef89
  71. https://github.com/chrisranderson/beholder/tree/master/beholder
  72. https://github.com/chrisranderson/beholder/commit/cea87b37f680dec24cbc43aad236b87f9870ed57
  73. https://github.com/chrisranderson/beholder/tree/master/readme-images
  74. https://github.com/chrisranderson/beholder/blob/master/.gitignore
  75. https://github.com/chrisranderson/beholder/commit/7d91a81b9bad4dc5db772f8d33fe6ab2858c50a3
  76. https://github.com/chrisranderson/beholder/blob/master/.pylintrc
  77. https://github.com/chrisranderson/beholder/blob/master/.travis.yml
  78. https://github.com/chrisranderson/beholder/commit/6b493363cec744aa06f4eeef94746da4c4ba751e
  79. https://github.com/chrisranderson/beholder/blob/master/readme.md
  80. https://github.com/chrisranderson/beholder/commit/91771bf48602039e13425f59d9dd7c9d01d2ef89
  81. https://github.com/chrisranderson/beholder/blob/master/workspace
  82. https://github.com/chrisranderson/beholder/blob/master/setup.py
  83. https://github.com/tensorflow/tensorboard
  84. https://github.com/tensorflow/tensorboard/pull/613
  85. https://github.com/tensorflow/tensorboard/pull/613
  86. https://github.com/chrisranderson/beholder/issues/33
  87. https://github.com/chrisranderson/beholder/milestone/1
  88. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/demo.gif
  89. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/gradient-example.png
  90. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/conv-activation-example.png
  91. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/frame-example.png
  92. https://www.youtube.com/watch?v=06hjer0ox5k
  93. https://docs.bazel.build/versions/master/install.html
  94. http://localhost:6006/
  95. https://github.com/tensorflow/tensorflow#installation
  96. https://github.com/chrisranderson/beholder#other-arrays
  97. https://github.com/chrisranderson/beholder/blob/master/readme-images/convolutional-activations.png
  98. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/bias.png
  99. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/fc-layer.png
 100. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/conv-layer.png
 101. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/conv-layer-zoom.png
 102. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/conv-activation-example.png
 103. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/values.png
 104. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/mode.png
 105. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/image-scaling.png
 106. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/updates-per-second.png
 107. https://raw.githubusercontent.com/chrisranderson/beholder/master/readme-images/start-recording.png
 108. https://github.com/chrisranderson/beholder/issues/new
 109. https://twitter.com/chrisdotio
 110. mailto:chris.anderson@byu.net
 111. https://github.com/site/terms
 112. https://github.com/site/privacy
 113. https://github.com/security
 114. https://githubstatus.com/
 115. https://help.github.com/
 116. https://github.com/contact
 117. https://github.com/pricing
 118. https://developer.github.com/
 119. https://training.github.com/
 120. https://github.blog/
 121. https://github.com/about
 122. https://github.com/chrisranderson/beholder
 123. https://github.com/chrisranderson/beholder

   hidden links:
 125. https://github.com/
 126. https://github.com/chrisranderson/beholder
 127. https://github.com/chrisranderson/beholder
 128. https://github.com/chrisranderson/beholder
 129. https://help.github.com/articles/which-remote-url-should-i-use
 130. https://github.com/chrisranderson/beholder#beholder-is-now-part-of-tensorboard-as-of-this-pull-request-and-is-now-maintained-by-the-tensorboard-team-see-this-comment-for-the-latest-information-on-how-to-use-beholder-with-your-project
 131. https://github.com/chrisranderson/beholder#beholder
 132. https://github.com/chrisranderson/beholder#installation
 133. https://github.com/chrisranderson/beholder#build-and-run-tensorboard
 134. https://github.com/chrisranderson/beholder#install-a-nightly-build-of-tensorflow
 135. https://github.com/chrisranderson/beholder#run-the-demo
 136. https://github.com/chrisranderson/beholder#quick-start
 137. https://github.com/chrisranderson/beholder#visualization-guide
 138. https://github.com/chrisranderson/beholder#array-visualization
 139. https://github.com/chrisranderson/beholder#1d-arrays-eg-biases
 140. https://github.com/chrisranderson/beholder#2d-arrays-eg-fully-connected-layers
 141. https://github.com/chrisranderson/beholder#4d-arrays-eg-convolution-layers
 142. https://github.com/chrisranderson/beholder#other-arrays
 143. https://github.com/chrisranderson/beholder#toolbar-controls
 144. https://github.com/chrisranderson/beholder#values
 145. https://github.com/chrisranderson/beholder#mode
 146. https://github.com/chrisranderson/beholder#image-scaling
 147. https://github.com/chrisranderson/beholder#updates-per-second
 148. https://github.com/chrisranderson/beholder#recording
 149. https://github.com/chrisranderson/beholder#feedback
 150. https://github.com/chrisranderson/beholder#hiring
 151. https://github.com/
