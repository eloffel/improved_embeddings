   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]intuition machine
     * [9]patterns
     * [10]methodology
     * [11]strategy
     * [12]deep learning playbook
     __________________________________________________________________

exploration, exploitation and imperfect representation in deep learning

   go to the profile of carlos e. perez
   [13]carlos e. perez (button) blockedunblock (button) followfollowing
   oct 7, 2017
   [1*yxdwgac1m5vpk9w-w8wyfg.jpeg]
   credit: [14]https://unsplash.com/photos/uspjzzywxo4

   the algorithms of learning can be coarsely abstracted as being a
   balance of exploration and exploitation. a balanced strategy is
   followed in the pursuit of a fitter representation. this representation
   can either be one that improves a model that is being learned or can be
   at the meta-level where it improves the algorithm that learns better
   models.

   in exploitation, an automation greedily pursues a path of learning that
   provides immediate rewards. in exploration however, an automation must
   decide to forego an immediate reward and select instead a directionless
   exploration with the intent of discovering a greater reward elsewhere.
   the strategy to select one over the other is sometimes referred to as
      regret minimization   . as a side, jeff bezos has a very human
   interpretation of this strategy:

        okay, now i   m looking back on my life. i want to have minimized the
     number of regrets i have.    i knew that when i was 80 i was not going
     to regret having tried this. i was not going to regret trying to
     participate in this thing called the internet that i thought was
     going to be a really big deal. i knew that if i failed i wouldn   t
     regret that, but i knew the one thing i might regret is not ever
     having tried. i knew that that would haunt me every day, and so,
     when i thought about it that way it was an incredibly easy
     decision.   

   it is also related to the idea of counterfactual regret minimization
   (cfr). this method is used by [15]libratus a poker playing machine that
   has bested professional players. cfr is applicable in domains with
   [16]imperfect-information. in short, the strategy of selecting
   exploration over exploitation is relevant to domains with imperfect
   information.

   stochastic id119 (sgd), [17]the workhorse learning algorithm
   of deep learning, are algorithms that employ exploitation as its
   fundamental motivation. sgd works only for networks that are composed
   of differentiable layers. convergence happens because there will be
   regimes in the parameter space that guarantee convergence of iterative
   affine transformations. this is well known in other fields such as
   [18]control theory (known as method of adjoints) as well as in chaos
   theory (iterated function systems).

   however, exploration features are shoe-horned into classic gradient
   descent through different kinds of randomness. examples of these are,
   the randomness in how training examples are presented, noise terms in
   the gradient, dropout and batch id172. when we examine [19]the
   two phases of gradient decent, we realize that the first phase is
   dominated by exploitation behavior. this is where we see a high signal
   to noise ratio, and the convergence is rapid. in this phase, second
   order methods that exploit the natural gradient (see: fisher
   information matrix) will converge much faster. a recent method known as
   the [20]kronecker factorization (k-fac) that approximates the fim has
   shown to exhibit 20   30 times less iterations than traditional first
   order methods.

   in the compressive phase, exploration will dominate and randomization
   methods facilitate these explorations. in this regime, the gradients
   [21]carry negligible information and thus the convergence is extremely
   slow. this is where representation compression occurs. the elusive goal
   of generalization is achieved through the compression of
   representation. we can explore many interpretations as to [22]what
   generalization actually means, but ultimately, it boils down to the
   shortest expression that can accurately capture the behavior of an
   observed environment.

   evolutionary algorithms (aka id107) occupy the space of
   exploration approaches. in deep learning, evolution algorithms are
   usually been employed in [23]searching for architectures. it is a more
   sophisticated version of hyper-parameter optimization in that instead
   of juggling constants like learning rates, the search algorithm juggles
   the composition of each layer of a network. it is used as the outer
   loop of the learning algorithm. the thing though about evolutionary
   algorithms is that serendipitous discovery is fundamental. in short, it
   works only when you are lucky.

   either method or a combination of both can lead to a fitter
   representation. let   s deconstruct the idea of representations. in a
   previous post, i discuss [24]3 different dimensions of intelligences
   that are being developed ( computational, adaptive and social). the
   claim is that these are different kinds of intelligences. what is
   apparently obvious is that the domains in which they operate are
   different from each other. so form will have to follow function. the
   methods and architectures that are developed for each kind of
   intelligence are going to be different from each other. one dimension
   of representation is obviously the domain in which it is applicable.

   there is of course a question whether we should explore different kinds
   of representations. i mean this at a more general level. in deep
   learning, there are all kinds of different neural embeddings. these
   embeddings are vector representations of semantics. these vector spaces
   are learned over the course of training. these vectors are supposed to
   represent an invariant form of the actual concept. one major difficulty
   of deep learning systems is that these representations are extremely
   entangled. the fact that they are entangled can explain why deep
   learning systems have zero conceptual understanding of what they
   predict. understanding requires the creation of concepts, if concepts
   cannot be factored out, then what does that imply for understanding? it
   is important to realize, that there are many cases where understanding
   is not needed for competence.

   i will argue that alphago doesn   t understand go in the same way as
   humans. humans understand go by creating their own concepts behind the
   strategies they employ. alphago doesn   t have an understanding of these
   concepts. rather, it has memory and the statistics of billions of moves
   and their consequences.

   the concepts that exist as part of a representation may exists in 3
   forms. a generalizations, a prototype or an exemplar. deep learning
   focuses on creating generalizations through the capture of an invariant
   representation. this is why, data augmentation is a best-practice
   approach. so when working with images, images are rotated, cropped,
   de-saturated etc.. this trains the network to ignore these variations.
   in addition, convolution networks are designed to ignore image
   translations (i.e. difference in locations). the reason dl systems
   require many training sets is that it needs to    see    enough variations
   so that it can learn what to ignore and what to continue to keep
   relevant. perhaps however that the requirement for invariances is too
   high and we should seek something less demanding in the form of
   equivariances.

   in the realm of few-shot or zero-shot learning, where an automation
   must learn something by seeing it only once or a few times, then there
   is zero opportunity to discover invariances. an automation only has a
   few examples to create a prototype, that is representative of the
   entire class. so there needs to be some prior model that is capable of
   performing the appropriate similarity calculation. the system must know
   how to determine if an example is similar to a prototype.

   even worse, if its just one example, then there isn   t really a class
   and the system has to deduce a generalization. the implication of the
   latter is that, an automation requires that an internal model existing
   prior to any deduction.so we have here three kinds of models. a
   model-free representation (learned through induction), a representation
   for a similarity algorithm and a rich representation that can drive
   deduction (or abduction).

   it is interesting that the human mind is able to recall unusual
   configurations, yet be unable to recall finer details. this is an
   example of attempts of people to draw the apple logo:
   [1*5n9yizpzxgguu_c-qpjufq.png]
   source: [25]https://www.signs.com/branded-in-memory/

   meanwhile dl networks, that have zero understanding of an image, are
   much better at recreating images than average humans:
   [1*opqo0btv6i124b0s_wakkw.png]
   source: [26]http://www.evolvingai.org/files/nguyen2016synthesizing.pdf
   not the apple logo, but very accurate renditions of apples.

   not many people have the ability to visualize in their head an image
   and recreate it properly via a drawing. i   m unsure if this is a
   weakness in their articulation skills or that the details of an object
   aren   t actually captured by the brain. in fact, human   s are typically
   blind in many contexts:
   [1*qgkjrxl3p3nsuyiuo6vjhw.gif]
   it is easy to not detect the change in the two photos above
   [27]http://nivea.psycho.univ-paris5.fr/

   another illustration of    inattentional blindness   :

   iframe: [28]/media/0d54b4fe1379bf9b75f26dd0fb692e68?postid=9472b67fdecd

   the human mind simply does not have the same kind of photographic
   memory that a machine has. its capacity is simply limited and requires
   throwing out a lot of information away so as to cope with information
   overload.

   in a [29]previous post, we explored how model-free and model-based
   cognition can be interleaved in the process of learning. exploration
   and exploitation can also be interleaved in learning. however, both
   sets are orthogonal. as in sgd, you can have a model-free algorithm
   that uses both exploration and exploitation. you can also have
   model-based algorithms that explore or exploit. that is, there are at
   least three dimensions that are described here. one dimension is on the
   axis of exploration to exploitation. the second dimension is if the
   learning process is driven by a explicit model or not. the third
   dimension is the nature of the learned representation itself.

   [30]bridging the semantic gap is still an extreme challenge.

   .
   [1*klghw8y2ldrko117bnqswq.png]
   explore deep learning: [31]artificial intuition: the unexpected deep
   learning revolution
   [1*j9kar_3vwdjk8twhtmxc0g.png]
   exploit deep learning: [32]the deep learning ai playbook

     * [33]machine learning
     * [34]deep learning
     * [35]artificial intelligence

   (button)
   (button)
   (button) 298 claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of carlos e. perez

[36]carlos e. perez

   medium member since feb 2018

   author of artificial intuition and the deep learning playbook    
   linkedin.com/in/ceperez

     (button) follow
   [37]intuition machine

[38]intuition machine

   deep learning patterns, methodology and strategy

     * (button)
       (button) 298
     * (button)
     *
     *

   [39]intuition machine
   never miss a story from intuition machine, when you sign up for medium.
   [40]learn more
   never miss a story from intuition machine
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/9472b67fdecd
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://medium.com/intuitionmachine/exploration-exploitation-and-imperfect-representation-in-deep-learning-9472b67fdecd&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://medium.com/intuitionmachine/exploration-exploitation-and-imperfect-representation-in-deep-learning-9472b67fdecd&source=--------------------------nav_reg&operation=register
   8. https://medium.com/intuitionmachine?source=logo-lo_yrykc5lmbwqd---d777623c68cf
   9. https://medium.com/intuitionmachine/tagged/design-patterns
  10. https://medium.com/intuitionmachine/tagged/agile-methodology
  11. https://medium.com/intuitionmachine/tagged/strategy
  12. https://deeplearningplaybook.com/
  13. https://medium.com/@intuitmachine
  14. https://unsplash.com/photos/uspjzzywxo4
  15. https://www.wired.com/2017/02/libratus
  16. https://arxiv.org/abs/1603.01121
  17. https://medium.com/intuitionmachine/the-deeply-suspicious-nature-of-id26-9bed5e2b085e
  18. https://en.wikipedia.org/wiki/control_theory
  19. https://medium.com/intuitionmachine/the-peculiar-behavior-of-deep-learning-loss-surfaces-330cb741ec17
  20. https://arxiv.org/abs/1602.01407v2
  21. https://arxiv.org/pdf/1703.07950v2.pdf
  22. https://medium.com/intuitionmachine/rethinking-generalization-in-deep-learning-ec66ed684ace
  23. https://medium.com/intuitionmachine/machines-that-search-for-deep-learning-architectures-c88ae0afb6c8
  24. https://medium.com/intuitionmachine/deep-learning-system-zero-intuition-and-rationality-c07bd134dbfb
  25. https://www.signs.com/branded-in-memory/
  26. http://www.evolvingai.org/files/nguyen2016synthesizing.pdf
  27. http://nivea.psycho.univ-paris5.fr/
  28. https://medium.com/media/0d54b4fe1379bf9b75f26dd0fb692e68?postid=9472b67fdecd
  29. https://medium.com/intuitionmachine/the-coordination-of-intuition-and-rational-thought-bb4b9e3e1ac8
  30. https://medium.com/intuitionmachine/the-first-rule-of-agi-is-bc8725d21530
  31. https://gumroad.com/products/ihdj
  32. https://gumroad.com/products/wrbus
  33. https://medium.com/tag/machine-learning?source=post
  34. https://medium.com/tag/deep-learning?source=post
  35. https://medium.com/tag/artificial-intelligence?source=post
  36. https://medium.com/@intuitmachine
  37. https://medium.com/intuitionmachine?source=footer_card
  38. https://medium.com/intuitionmachine?source=footer_card
  39. https://medium.com/intuitionmachine
  40. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  42. https://medium.com/@intuitmachine?source=post_header_lockup
  43. https://medium.com/p/9472b67fdecd/share/twitter
  44. https://medium.com/p/9472b67fdecd/share/facebook
  45. https://medium.com/@intuitmachine?source=footer_card
  46. https://medium.com/p/9472b67fdecd/share/twitter
  47. https://medium.com/p/9472b67fdecd/share/facebook
