intro

     * [1]about this site
     * [2]what can you do with ai?
     * [3]how we picked our examples

guides

     * [4]a little history
     * [5]defining ai terms
     * [6]giving your software ai superpowers
     * [7]natural language processing
     * [8]id161
     * [9]training your own models
     * [10]neural network architectures
     * [11]ways in which machines learn
     * [12]code: (re-)training a model
     * [13]code: adding ai to your mobile app

where to next?

     * [14]software and services
     * [15]datasets
     * [16]videos, tutorials, and blogs
     * [17]books, papers, and research

   menu

training your own models

   if you've played with the examples from the previous sections on nlp
   and vision recognition, you've seen the power of apis. send in a
   picture, get a list of objects in that picture; send in a sentence, and
   get the emotional tilt of that sentence, or get the sentence back in
   another language. magic.

   just as with other areas of software development, sometimes the api you
   need doesn't exist and you'll have to write your own code. a common
   starting point for ai programming is to select a machine learning
   algorithm, train it with data (see [18]this medium post for a set of
   strategies for getting data, and then expose that trained model via
   apis to the rest of your code can call.

   there are a [19]large [20]setof [21]machine learning algorithms with
   fun names such as id90, id79, support vector
   machines, id28, and so on. each algorithm is best suited
   for a specific situation depending on how much data you have, how many
   "features" or dimensions of data you can feed the algorithms, how
   sparse or dense the data set is, and so on. sometimes it's hard to
   figure out which algorithm to use, and you will have to try a few
   different algorithms (and combinations of algorithms) to see how they
   do.

   here are a few good starting points to picking the right ml algorithm
   to solve your specific problem:
     * [22]how to choose machine learning algorithms for microsoft azure
       machine learning
     * [23]stack overflow answer to "when to choose which machine learning
       classifer?"
     * scikit-learn documentation: [24]choosing the right estimator

   deep learning is a class of machine learning that has gotten a lot of
   well-deserved attention in recent years because it's working to solve a
   wide variety of ai problems in vision, natural language processing, and
   many others. also, in contrast with many of the other machine learning
   algorithms where data scientists or software engineers have to figure
   out which features will lead to good predictions, deep learning
   approaches figure out the features themselves.

   for example, let's say you were using id75s to try to
   predict the price of a home like trulia does. with most machine
   learning approaches, you'd have to figure out "features" (think of them
   as factors that will drive price like how big the house is, when the
   house was built, the price of nearby houses, the number of bedrooms and
   bathrooms, and so forth). with deep learning, you don't pick the
   features. the algorithms essentially find the features for you in the
   data.

   for both these reasons (namely, (1) it's working and (2) it figures out
   features on its own), we'll spend the rest of the time in this playbook
   digging into deep learning. but before we continue, this tweet is spot
   on:
   true tweet about machine learning

   we'd encourage you to try potentially simpler, admittedly less
   glamorous algorithms before deep learning. sometimes a linear
   regression is all you need.

deep learning

   having said that, deep learning algorithms are incredibly powerful and
   getting amazing results across many different domains. professor
   christopher manning, a longtime veteran of nlp research at stanford,
   says in his [25]introductory lecture for "cs natural language
   processing with deep learning" that "in the length of my lifetime, i'd
   actually say it's unprecedented [for] a field to progress so quickly".

   deep learning id206 were originally inspired
   by the way neurons in the brain work, but most researchers today will
   tell you that brains and neural networks used in software like
   tensorflow are very different. but if you are interested in the history
   of how we got here, check out these excellent resources which we've
   ordered by depth, from most concise to most comprehensive, for your
   reading pleasure.
     * andrew l. beam, [26]deep learning 101
     * andrey kruenkov, [27]a "brief" of neural nets and deep learning
     * haohan wang and bhiksha raj, [28]on the origin of deep learning
       provide a good historical overview, explaining concepts including
       the math
     * jurgen schmidhuber, [29]deep learning in neural networks: an
       overview provides the most comprehensive and technically dense
       overview

why "deep"?

   by the way, why do we call it "deep learning"? it's called deep
   learning because the underlying algorithms work on data structure that
   looks like a graph of connected nodes, and the nodes are organized into
   layers. data goes into the left-most nodes, and the output comes out
   the right hand side. between the input and output nodes, there are many
   layers of other nodes; hence, the network is "deep". this [30]diagram
   from nvidia does a good job of illustrating the concept:
   why is deep learning "deep"?

   to learn more:
     * watch legend jeff dean from the google brain team lecture on
       [31]large-scale deep learning for intelligent computer systems
     * read michael nielsen's excellent ebook and website [32]neural
       networks and deep learning

why now?

   you might be wondering why this revolution is happening now given that
   some of the original ideas date back to the 1950s. the short answer is
   a common one in technology: bountiful and inexpensive compute, storage,
   and data. andrew ng shares this conceptual graph illustrating how the
   effectiveness of deep learning improves as you feed it more data and
   more computing resources:
   why is deep learning working now?

   while the fundamental ideas are generally the same, the scale at which
   we are using them has changed, and that has brought quantitatively
   different (and better) results, in part because we can now test ideas
   we couldn't test before. scale constraints created a barrier to
   evolution. as cloud computing has made large-scale experiments
   possible, the techniques have evolved and improved significantly.

   professor geoff hinton (google and university of toronto) discussed why
   previous approaches failed. the first two reasons he identifies have to
   do with scale ("our labeled datasets were thousands of times too small
   ") and compute capabilities ("our computers were millions of times too
   slow") which clearly don't speak only to the speed of processors but
   compute capacity in general (ie., including processor, memory, storage,
   networking).
    1. [33]vision
    2. [34]neural network architectures

   [35]follow @a16z on github [36]fork a16z/ai on github

references

   visible links
   1. http://aiplaybook.a16z.com/docs/intro/getting-started
   2. http://aiplaybook.a16z.com/docs/intro/survey-goals
   3. http://aiplaybook.a16z.com/docs/intro/survey-parameters
   4. http://aiplaybook.a16z.com/docs/guides/ai
   5. http://aiplaybook.a16z.com/docs/guides/ai-terms
   6. http://aiplaybook.a16z.com/docs/guides/ai-using
   7. http://aiplaybook.a16z.com/docs/guides/nlp
   8. http://aiplaybook.a16z.com/docs/guides/vision
   9. http://aiplaybook.a16z.com/docs/guides/dl
  10. http://aiplaybook.a16z.com/docs/guides/dl-architectures
  11. http://aiplaybook.a16z.com/docs/guides/dl-learning
  12. http://aiplaybook.a16z.com/docs/guides/dl-start
  13. http://aiplaybook.a16z.com/docs/guides/dl-app
  14. http://aiplaybook.a16z.com/docs/reference/software
  15. http://aiplaybook.a16z.com/docs/reference/datasets
  16. http://aiplaybook.a16z.com/docs/reference/links
  17. http://aiplaybook.a16z.com/docs/reference/bibliography
  18. https://medium.com/@muellerfreitag/10-data-acquisition-strategies-for-startups-47166580ee48
  19. http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/
  20. http://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html
  21. https://en.wikipedia.org/wiki/machine_learning
  22. https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-algorithm-choice
  23. http://stackoverflow.com/questions/2595176/when-to-choose-which-machine-learning-classifier
  24. http://scikit-learn.org/stable/tutorial/machine_learning_map/
  25. https://www.youtube.com/watch?v=oqq-w_63ugq&list=pl3fw7lu3i5jsnh1rnuwq_tcylnr7ekre6
  26. http://beamandrew.github.io/deeplearning/2017/02/23/deep_learning_101_part1.html
  27. http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/
  28. https://arxiv.org/pdf/1702.07800.pdf
  29. https://arxiv.org/pdf/1404.7828.pdf
  30. https://devblogs.nvidia.com/parallelforall/accelerate-machine-learning-cudnn-deep-neural-network-library/
  31. https://www.youtube.com/watch?v=4hqb3tdk01k
  32. http://neuralnetworksanddeeplearning.com/index.html
  33. http://aiplaybook.a16z.com/docs/guides/vision
  34. http://aiplaybook.a16z.com/docs/guides/dl-architectures
  35. https://github.com/a16z
  36. https://github.com/a16z/ai/fork

   hidden links:
  38. http://aiplaybook.a16z.com/
  39. http://aiplaybook.a16z.com/
