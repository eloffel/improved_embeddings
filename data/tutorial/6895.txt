   #[1]github [2]recent commits to rainbow-parser:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]3
     * [35]star [36]13
     * [37]fork [38]0

[39]shashiongithub/[40]rainbow-parser

   [41]code [42]issues 0 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   the rainbow parser
     * [47]12 commits
     * [48]1 branch
     * [49]0 releases
     * [50]fetching contributors

    1. [51]c++ 41.8%
    2. [52]roff 27.7%
    3. [53]matlab 18.1%
    4. [54]shell 5.8%
    5. [55]makefile 5.3%
    6. [56]python 1.1%
    7. other 0.2%

   (button) c++ roff matlab shell makefile python other
   branch: master (button) new pull request
   [57]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/s
   [58]download zip

downloading...

   want to be notified of new releases in shashiongithub/rainbow-parser?
   [59]sign in [60]sign up

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [62]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [63]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [64]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [65]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [66]decode
   [67]example-data
   [68]example-output/spectral_naacl_feat-0_rare-5_t-pos_nt-pos
   [69]scripts
   [70]train
   [71]readme.md
   [72]rainbow-parser-logo.png

readme.md

[73][rainbow-parser-logo.png] the rainbow parser, version 0.1

synopsis

   this project includes code for training and decoding with
   latent-variable id140 (l-pid18s). it
   includes training algorithms such as the expectation-maximization
   algorithm of matsuzaki et al. (2005) and the spectral algorithms of
   cohen et al. (2013) and narayan and cohen (2015; 2016). (see references
   below.) decoding is done using a cky chart parser with pruning.

some things to consider

     * the l-pid18 formalism used is described by cohen et al. (2014). more
       specifically, there are two types of rules: lexical rules a -> x
       where a is a preterminal and x is a word and binary rules a -> b c
       where a, b, c are nonterminals or preterminals. as such, the
       grammar is in a restricted chomsky normal form, where there is a
       distinction between internal nonterminals and preterminals. the
       internal nonterminals are also called interminals. the root of a
       derivation tree can only be an interminal.
     * because of the restrictions above on the grammar, this parser
       cannot parse single-word sentences. it requires at least two words
       in order to parse.
     * the code is written in a combination of c++ (decoder and em
       algorithm) and java with matlab (spectral training algorithms). the
       decoder was written in c++ to optimize for speed. the training
       algorithms require matlab 15 or above.
     * the training algorithm using id106 (matlab code) can be
       multithreaded. however, this has been reported to create problems
       on some machines. if your code abruptly aborts sometimes because of
       the multithreading of the nonterminal calculations, remove the
       multithreading support by changing the .m files in the
       train/src/source directory: all "parfor" directives should be
       changed to "for", and all "parpool" and "delete(parobject)"
       commands should be commented out.

installation

    1. change directory to the decode/ directory, then run "./configure"
       followed by "make". this should compile a binary called lpid18parser
       in the src/ directory. this binary is the main driver behind the
       decoder. you need a c++ compiler that supports the "-std=c++0x"
       flag.
    2. change directory to the train/ directory, then run "python
       config.py". this should create a file called javaclasspath.txt with
       absolute paths for the .jar files in the package.

running the trainer (spectral)

   the trainer resides in the train/src directory. you need matlab15 to
   run it, and you usually need to run it from the src/ directory. there
   is a file called
set_global_parameters.m

   that contains all the settings for the algorithm (except for the
   smoothing parameters). see the file itself for the options you have
   with training. then check out
run_clusterestimation_algorithm.m

   and
run_spectralestimation_algorithm.m

   which are the main execution files for the id91 algorithm of
   narayan and cohen (2015) and the spectral algorithm of cohen et al.
   (2013). these files also contain the settings for the smoothing
   parameters as specified in cohen et al. (2013).

   once you have run the trainer, there will be several files created in
   the output directory:
    1. grammar-prune.txt - this is the grammar with no latent states that
       is estimated from the data and should be used as prune-grammar for
       decoding.
    2. train.vocab.parsing - this is the vocabulary file that should be
       used as vocab-file below for decoding.
    3. the grammar that was estimated will reside in a directory that
       starts with "standard". if you used the default matlab file, it
       will have a specific signature that looks like
       grammar-2d3e6bb2-c021-4349-9058-ca75bde3ccdb.txt.

   note that you do not have to re-generate the svd and the inside-outside
   files every time from scratch, these can be calculated only once, and
   then re-used for other grammar estimations. see the .m files for more
   information.

   for vocab-threshold, use the same number you used in the
   set_global_parameters.m file as obj_globalparam.rarewordcutoff.

   please note that the matlab/java code binarizes the trees and also
   collapses unary rules into a single node. this means that the grammar
   that you get may use a different set of nonterminals than in the
   original treebank. the binarization process is based on the code from
   the berkeley parser with some added code for collapsing the unary
   rules.

running the trainer (expectation-maximization)

   the em algorithm code is more impoverished, and runs in c++. it is part
   of the decode/ directory source files, as a matter of fact.

   you can run it by typing from the scripts/ directory
python lpid18em.py [treebank-file] [output-prefix-grammar-file] [vocab-file] [voc
ab-threshold] [latent-state-number] [iterations-number] [scale-factor]

   where
     * treebank-file is an input treebank which will be binarized by using
       norm-trees.sh in the scripts/ directory.
     * output-prefix-grammar-file is an output prefix for outputting all
       the intermediate files such as the grammar files after each
       iteration and other files.
     * vocab-file is a vocabulary file in the same format created by the
       spectral trainer (so you can use a vocabulary file from there), or
       alternatively, create a file with all words in the training set and
       their counts, separated by space. unfortunately, the em code does
       not generate a vocabulary file on its own.
     * vocab-threshld is the cutoff x before a word is replaced by its
       part-of-speech (preterminal) tag (if its count <= x).
     * latent-state-number is the number of latent states to use with all
       nonterminals in the input treebank.
     * iterations-number is the number of iterations to run the em
       algorithm.
     * scale-factor does not have to be specified, the default is 1.5. it
       helps when the em algorithm underflows (the probabilities get too
       small). see trick in code -- basically all preterminal rules are
       multiplied by scale-factor.

   several files are generated by the em execution, if successful. the
   grammar files (suffix gra), a prune grammar file (no latent states
   id113, relative frequency, grammar) and the
   vocabulary file (copied from input). any of the grammar files at each
   iteration, the vocabulary file and the prune grammar can be used with
   the decoder as specified below.

running the decoder

   to parse, use lpid18parser.py in the scripts/ directory.

   you can run it by typing from the scripts/ directory
python lpid18parser.py [sentence-file] [grammar-file] [prune-grammar] [vocab-file
] [vocab-threshold] [prune-threshold]

   where
     * sentence-file is just a pre-tokenized sentence file (one sentence
       per line, words/tokens separated by space).
     * grammar-file is the grammar file you want to use from one of the
       training algorithms
     * prune-grammar is the grammar file used for pruning the chart. it is
       important for speed, and you always have to specify one.
     * vocab-file is the vocabulary file created based on the training set
       by the training algorithm.
     * vocab-threshold is the threshold you used in the training algorithm
       in the .m parameter file (or the threshold you used with the em
       algorithm).
     * prune-threshold is the minimal value for an item on the chart to
       have so it is not pruned. use 0 if you don't want to use pruning
       (but you still have to specify a prune grammar, which is
       automatically generated by the training algorithms). this defaults
       to 1e-4 if not specified.

   the python script calls the main binary lpid18parser driver, and outputs
   the parses to the standard output. if it cannot parse a sentence for
   some reason, it will output "( )". all trees are output in standard
   bracketing format such as in the id32.

   note that the lpid18parser.py script uses ^ as a special symbol for the
   different tokens. if the parser sees a token x^y, it will only take x
   to be the word to be parsed. y will be treated as the pos tag of the
   word.

   new note: it is now necessary to specify sentence tokens as x^y, where
   both x and y are specified. this is necessary because unknown words
   used to be replaced by their corresponding pos tags, and if an
   underspecified pos tag is used for such words, the parser may fail on
   the sentence.

normalizing treebanks

   the algorithms implemented in this project all assume a binary trees
   with preterminals. the treebanks that often come in practice do not
   have to contain binary trees. we also include two scripts for
   binarizing and debinarizing treebanks. both of them are in the scripts/
   directory.

   to binarize trees use:
./norm-trees.sh --originalparsetrees [original-treebank-filename] --normalisedpa
rsetrees [output-in-binarized-form-filename]

   to debinarize trees use:
./denorm-trees.sh --normalisedparsetrees [original-treebank-in-binarized-form-fi
lename] --denormalisedparsetrees [output-in-debinarized-form-filename]

   note that all grammars that are generated with the code in this project
   output binarized trees when parsed with.

authors

   the rainbow parser was written by shashi narayan and shay cohen at the
   university of edinburgh. we thank the members of the cohort for testing
   and debugging some of this code ([74]http://cohort.inf.ed.ac.uk). all
   of the code is based on the references as specified below.

   we encourage contributions to this project, and can be reached at
   [75]shashi.narayan@ed.ac.uk or [76]scohen@inf.ed.ac.uk for discussions.

demo

   if you are interested in seeing a demo of the different grammars
   estimated for different languages, as described in narayan and cohen
   (2016), see: [77]http://cohort.inf.ed.ac.uk/lpid18viewer/index.php.
   also, if you would like to see the benchmark results of running this
   code on different treebanks, see
   [78]http://cohort.inf.ed.ac.uk/lpid18.html. this page also includes
   downloadable models that can be used with the decoder.

references

    1. spectral learning of latent-variable pid18s, shay b. cohen, karl
       stratos, michael collins, dean p. foster and lyle ungar, in acl
       2012
    2. experiments with spectral learning of latent-variable pid18s, shay
       b. cohen, karl stratos, michael collins, dean p. foster and lyle
       ungar, in naacl 2013
    3. spectral learning of latent-variable pid18s: algorithms and sample
       complexity, shay b. cohen, karl stratos, michael collins, dean p.
       foster and lyle ungar, in jmlr 2014
    4. diversity in spectral learning for natural language parsing, shashi
       narayan and shay b. cohen, in emnlp 2015
    5. optimizing spectral learning for parsing, shashi narayan and shay
       b. cohen, in acl 2016

license

   copyright (c) 2017, shashi narayan and shay cohen. all rights reserved.

   redistribution and use in source and binary forms, with or without
   modification, is permitted.

   this software is provided by the copyright holders and contributors "as
   is" and any express or implied warranties, including, but not limited
   to, the implied warranties of merchantability and fitness for a
   particular purpose are disclaimed. in no event shall the copyright
   holder or contributors be liable for any direct, indirect, incidental,
   special, exemplary, or consequential damages (including, but not
   limited to, procurement of substitute goods or services; loss of use,
   data, or profits; or business interruption) however caused and on any
   theory of liability, whether in contract, strict liability, or tort
   (including negligence or otherwise) arising in any way out of the use
   of this software, even if advised of the possibility of such damage.

   note that this project includes jar files from several other projects:
     * berkeleyparser.jar - the berkeley parser (used for preprocessing
       treebank trees in java)
     * colt.jar - used for matrix calculations
     * commons-cli-1.2.jar - apache commons used for general routines
     * trove.jar - trove, used for working with data structures.

   these are provided separately perhaps with a different license. they
   are provided in this project to avoid version mismatch when downloading
   them.

     *    2019 github, inc.
     * [79]terms
     * [80]privacy
     * [81]security
     * [82]status
     * [83]help

     * [84]contact github
     * [85]pricing
     * [86]api
     * [87]training
     * [88]blog
     * [89]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [90]reload to refresh your
   session. you signed out in another tab or window. [91]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/shashiongithub/rainbow-parser/commits/master.atom
   3. https://github.com/shashiongithub/rainbow-parser#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/shashiongithub/rainbow-parser
  32. https://github.com/join
  33. https://github.com/login?return_to=/shashiongithub/rainbow-parser
  34. https://github.com/shashiongithub/rainbow-parser/watchers
  35. https://github.com/login?return_to=/shashiongithub/rainbow-parser
  36. https://github.com/shashiongithub/rainbow-parser/stargazers
  37. https://github.com/login?return_to=/shashiongithub/rainbow-parser
  38. https://github.com/shashiongithub/rainbow-parser/network/members
  39. https://github.com/shashiongithub
  40. https://github.com/shashiongithub/rainbow-parser
  41. https://github.com/shashiongithub/rainbow-parser
  42. https://github.com/shashiongithub/rainbow-parser/issues
  43. https://github.com/shashiongithub/rainbow-parser/pulls
  44. https://github.com/shashiongithub/rainbow-parser/projects
  45. https://github.com/shashiongithub/rainbow-parser/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/shashiongithub/rainbow-parser/commits/master
  48. https://github.com/shashiongithub/rainbow-parser/branches
  49. https://github.com/shashiongithub/rainbow-parser/releases
  50. https://github.com/shashiongithub/rainbow-parser/graphs/contributors
  51. https://github.com/shashiongithub/rainbow-parser/search?l=c++
  52. https://github.com/shashiongithub/rainbow-parser/search?l=roff
  53. https://github.com/shashiongithub/rainbow-parser/search?l=matlab
  54. https://github.com/shashiongithub/rainbow-parser/search?l=shell
  55. https://github.com/shashiongithub/rainbow-parser/search?l=makefile
  56. https://github.com/shashiongithub/rainbow-parser/search?l=python
  57. https://github.com/shashiongithub/rainbow-parser/find/master
  58. https://github.com/shashiongithub/rainbow-parser/archive/master.zip
  59. https://github.com/login?return_to=https://github.com/shashiongithub/rainbow-parser
  60. https://github.com/join?return_to=/shashiongithub/rainbow-parser
  61. https://desktop.github.com/
  62. https://desktop.github.com/
  63. https://developer.apple.com/xcode/
  64. https://visualstudio.github.com/
  65. https://github.com/shashiongithub/rainbow-parser/tree/e204b00bd70641ae09d35e81db7f388c477ab44d
  66. https://github.com/shashiongithub/rainbow-parser/tree/master/decode
  67. https://github.com/shashiongithub/rainbow-parser/tree/master/example-data
  68. https://github.com/shashiongithub/rainbow-parser/tree/master/example-output/spectral_naacl_feat-0_rare-5_t-pos_nt-pos
  69. https://github.com/shashiongithub/rainbow-parser/tree/master/scripts
  70. https://github.com/shashiongithub/rainbow-parser/tree/master/train
  71. https://github.com/shashiongithub/rainbow-parser/blob/master/readme.md
  72. https://github.com/shashiongithub/rainbow-parser/blob/master/rainbow-parser-logo.png
  73. https://github.com/shashiongithub/rainbow-parser/blob/master/rainbow-parser-logo.png
  74. http://cohort.inf.ed.ac.uk/
  75. mailto:shashi.narayan@ed.ac.uk
  76. mailto:scohen@inf.ed.ac.uk
  77. http://cohort.inf.ed.ac.uk/lpid18viewer/index.php
  78. http://cohort.inf.ed.ac.uk/lpid18.html
  79. https://github.com/site/terms
  80. https://github.com/site/privacy
  81. https://github.com/security
  82. https://githubstatus.com/
  83. https://help.github.com/
  84. https://github.com/contact
  85. https://github.com/pricing
  86. https://developer.github.com/
  87. https://training.github.com/
  88. https://github.blog/
  89. https://github.com/about
  90. https://github.com/shashiongithub/rainbow-parser
  91. https://github.com/shashiongithub/rainbow-parser

   hidden links:
  93. https://github.com/
  94. https://github.com/shashiongithub/rainbow-parser
  95. https://github.com/shashiongithub/rainbow-parser
  96. https://github.com/shashiongithub/rainbow-parser
  97. https://help.github.com/articles/which-remote-url-should-i-use
  98. https://github.com/shashiongithub/rainbow-parser#-the-rainbow-parser-version-01
  99. https://github.com/shashiongithub/rainbow-parser#synopsis
 100. https://github.com/shashiongithub/rainbow-parser#some-things-to-consider
 101. https://github.com/shashiongithub/rainbow-parser#installation
 102. https://github.com/shashiongithub/rainbow-parser#running-the-trainer-spectral
 103. https://github.com/shashiongithub/rainbow-parser#running-the-trainer-expectation-maximization
 104. https://github.com/shashiongithub/rainbow-parser#running-the-decoder
 105. https://github.com/shashiongithub/rainbow-parser#normalizing-treebanks
 106. https://github.com/shashiongithub/rainbow-parser#authors
 107. https://github.com/shashiongithub/rainbow-parser#demo
 108. https://github.com/shashiongithub/rainbow-parser#references
 109. https://github.com/shashiongithub/rainbow-parser#license
 110. https://github.com/
