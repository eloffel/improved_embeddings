   #[1]delip rao    feed [2]delip rao    comments feed [3]delip rao    a
   billion words and the limits of id38 comments feed [4]is
   id26 necessary? [5]the two tribes of language researchers
   [6]alternate [7]alternate

   [view?authtoken=zrgb&authtype=name&id=aaiaaabljmybxj3jdlzgsynkrd8qbcmar
   4z5sv4]

[8]navigation

   [9]delip rao

   [10]home
     * [11]home
     * [12]about

   [13]return to content

a billion words and the limits of id38

   by [14]delip on september 23, 2016 in [15]deep learning, [16]natural
   language processing

   [view?authtoken=zrgb&authtype=name&id=aaiaaabljmybxj3jdlzgsynkrd8qbcmar
   4z5sv4]

   in this post, i will talk about language models, when (and when not) to
   use lstms for id38, and some state of the art results.
   while i mostly discuss the    [17]exploring limits    paper, i   m adding a
   few things elementary (for some) here for completeness sake. the
   exploring limits paper is not new, but i think it   s a good illustration
   of how deep sequence models should be used in practice. this is bigger
   than my usual posts, but hey we are exploring limits here. ok, running
   out of italics now.

   one can say the [18]id163 corpus, in part, fueled the modern (deep
   learning based) id161 research due to its sheer size that
   allowed models to regularize better and kaggleification of the
   engineering behind the tasks. the [19]billion word corpus (lm1b
   hereafter) aims to be that for id38. a billion words is
   not big for id38 (for e.g., google translate folks
   routinely use several orders more for training their lms), but having a
   largish common corpus is always a nice idea. just as image/object
   recognition is a small sliver of id161, so is language
   modeling for natural language processing. and like object recognition,
   it   s a primitive task that allows one to learn representations for
   atomic units     such as words     that could be used in many upstream
   tasks.

   one of the problems with natural language is, like vision, it is hard
   to pinpoint the definition of    understanding   . in some ways, it is
   harder than id161. for example, if i show you this image, you
   can probably tell it is, mostly, of a cow.

   cow

   but with words and sentences, things get complicated. one
   prerequisite to understanding language is making sure the sentence or
   phrase we are reading or generating at least looks like the language we
   see (as sampled by the corpus) in daily life     i.e., what is the
   id203 of seeing that sequence. sometimes people describe language
   modeling as the id203 of predicting the next word given a
   sequence. with a little bit of id203 math, you can convince
   yourself that these are just two ways of looking at the same thing. so,
   a (probabilistic) language model will tell you how *likely* some
   sentence or phrase can be modulo lm errors. sometimes people attribute
   more to this likeliness and hallucinate their models are syntactic or
   semantic or    creative   . for example, if you have a partial sentence as:

   i eat my soup with _________

   and your lm completes this partial sentence with:

   1.    a spoon        you could hallucinate that your lm is doing semantic
   understanding.
   2.    a pillow        that   s semantically garbage. but you could be kind to
   your model and say,    oh it   s grammatically correct, so my lm is
   producing grammatically valid sentences.   
   3.    my mind        that   s rubbish too, except there will be some folks who
   will brand this as    creative ai   , and say    look, our models are
   creative in their answers   . we saw some of that nonsense happening with
   image captioning.
   4.    the the        now you would probably say,    that   s unfortunate.
   probably the training data didn   t have enough contexts with soup and
   eat.    (seeing nonsensical lm output is not uncommon with oovs and long
   tail of the vocabulary; we will visit this later).

   so, a language model scores likelihood of some sentence or a fragment
   w.r.t a corpus it has been trained on. no more. no less. decades of
   id38 research could be summarized by innovations in the
   sources of data used, the amount of data used, and modeling techniques
   used. the latter depending on the former two factors more closely than
   researchers will claim in their papers. the lm1b corpus further
   exercises the [20]empirically well-founded narrative that more data
   will lead to better language models     the notion of    better    as
   measured by [21]perplexity which itself is a questionable metric. it   s
   important however to note that improvements in perplexity doesn   t
   always mean an improvement in the upstream task, esp. when you notice
   small improvements. big improvements in perplexity, however, should be
   taken seriously (as a rule of thumb, for id38, consider
      small    as < 5 and    big    as > 10 points).

   earlier this year, google brain published a paper that showed massive
   improvements in perplexity on the lm1b corpus in a paper titled,
      [22]exploring the limits of id38   . this paper is
   impressive because:

   1. it knocks perplexity on lm1b all the way down to 23.7 (in ensemble
   or 30.0 if you consider just their single best model).
   2. afaik, it is the first pure lstm model to do that, i.e. without
   interpolating with an ngram model     not that it   s advisable to do, but
   i   m jumping the gun again.
   3. it shows how char id98 inputs could be used to control the lstm model
   sizes     not sure if it   s the first paper to use char id98s explicitly
   for that purpose, but it   s a useful trick.

   to put the performance gains in perspective, a standard interpolated
   [23]kneser-ney [24]5-gram model (kn5) gives you 67.6 perplexity for
   around 1.8 billion params (floats). their single bi-layer
   lstm-id98 model with perplexity 30.0 has just over a 1 billion params.
   that   s more than 55% reduction in perplexity and over 44% fewer
   parameters! impressive indeed.

   with such improvements staring at you, shouldn   t you always be using an
   lstm? the answer, unfortunately, is not that simple. so let me list out
   some of the pros and cons (data for some of the charts below come from
   cantab research):

id56-based models

   these include recurrent neural nets, and gated variants like lstms and
   grus.

   1. captures long range history instead of being fixed-order markov

   typical id165 based language model makes a fixed-order markov
   assumption     a word relies only on a fixed length history in the past.
   p(w_i | w_{i-1} ... w_1) = p(w_i | w_{i-1} ... w_{i-n+1})

   with lstms, this context could, in theory, be unbounded, but in
   practice go over the extents of the sentence. one could argue that
   adding more context can provide better language models even for
   count-based models. let   s see how this does with a regular id165 model
   with kneser-ney smoothing:

   kn-diffk

   so just by throwing in more context in an id165 model, we observe
   diminishing returns in the reduction of test set perplexity. going from
   a [25]bigram to a trigram model gives a huge win. however going from
   trigrams to higher order ngrams plateaus improvements while drastically
   increasing the size of the models. this effect is noticeable between
   the 4-gram and 5-gram models in the figure above.

   the id165 models, like most other ml models, improve with data.
   however, the improvement asymptotes quickly. in fact, if you
   interpolate from the 5-gram curve, getting even around a perplexity of
   60 will require around a trillion words. a consequence of this is the
   lm will easily be several hundred gigabytes, and becomes impossible to
   deploy on most servers.

   2. competitive perplexity

   ever since tom  s mikolov published his results on [26]id56 language
   models, we know id56s beat id165s hands down with increasing data size.

   knvid56 kneser-ney 5-gram vs. id56 (different #states) on lm1b


   and this effect is pronounced when more states are added.
   id56-states-perplex many of the difficulties in recurrent neural network
   training are now reasonably understood, and gated architectures (lstms
   and grus) are de jure for sequence modeling because of their robustness
   than vanilla id56s.

   3 . can control/limit number of parameters in the id56

   an excellent demonstration of the exploring limits paper is how to
   model to tradeoff between model performance and the number of
   parameters in a sequence model.

   lm1b_params_perplex

   a trick i found useful is to use character id98 to model word inputs as
   a means to reduce parameter sizes of sequence models. another paper
   that explore this in the context of id38 is by [27]yoon
   kim and friends,    [28]character aware id38   , where they
   claim up to 60% reduction in parameters. this is a better motivation of
   charid98s than, say for text classification.

   4. id56-based models do well on rare words

   my favorite graph (somewhat unexpected for me) from the exploring
   limits paper is one where they show the difference in id178 of their
   best lstm model (a 2 layer lstm with id98 inputs) and kn5 for words of
   increasing rarity.

   201-rare-words


id165 models

   1.  super fast to train     at least an order of magnitude fewer hours
   needed to train.
   2.  works well for small quantities of data. with the right
   smoothing/priors, you could make this work decently with a fraction of
   the data. let   s say if the government comes to you asking to build a
   language model in [29]dari or [30]pashto, and you have just a few
   hundred thousand words, you really cannot do better than using an
   id165 model and a visit to your friendly neighborhood linguistics
   department. (using those languages as an example; quite sure, given the
   interest, by now we have enough data for those languages).
   3. still, the best option to use in combination: even when you have
   tonnes of data, you want to use the id165 model in combination, as
   they usually give better results, when interpolated, than using just
   the lstm model alone. even when you add more states to your lstm, you
   will continue to get better performance interpolating with a 5-gram
   model. another case in point is the [31]id103 system from
   msr that   s making the news now for getting the best word error rate:
   they use an id165 interpolated id56 model too.

   the exploring limits paper counters this argument. they suggest id165
   interpolation is not necessary and with careful tuning it is possible
   to find an lstm+id98 architecture that will provide competitive results
   as an interpolated model. that   s just an exercise in exploring limits
   of your patience or your gpu infrastructure.

   i   m going to leave you all with a decision tree of what to do when
   faced with building lms in your startups, if lms are a means to an end
   for the problem you are solving.

   201-lm-flow


about delip

       (science     products)
   [32]view all posts by delip    

   [33]deep learning, [34]id38, [35]lstm, [36]nlp, [37]id56,
   [38]sequence modeling
   [39]is id26 necessary?
   [40]the two tribes of language researchers

      2016 delip rao. all rights reserved.

references

   1. http://deliprao.com/feed
   2. http://deliprao.com/comments/feed
   3. http://deliprao.com/archives/201/feed
   4. http://deliprao.com/archives/191
   5. http://deliprao.com/archives/218
   6. http://deliprao.com/wp-json/oembed/1.0/embed?url=http://deliprao.com/archives/201
   7. http://deliprao.com/wp-json/oembed/1.0/embed?url=http://deliprao.com/archives/201&format=xml
   8. http://deliprao.com/archives/201#navigation
   9. http://deliprao.com/
  10. http://deliprao.com/
  11. http://deliprao.com/
  12. http://deliprao.com/d
  13. http://deliprao.com/archives/201#top
  14. http://deliprao.com/archives/author/8272pwpadmin
  15. http://deliprao.com/archives/category/data-science/deep-learning
  16. http://deliprao.com/archives/category/data-science/natural-language-processing
  17. https://arxiv.org/abs/1602.02410
  18. http://image-net.org/
  19. http://arxiv.org/abs/1312.3005
  20. http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf
  21. https://en.wikipedia.org/wiki/perplexity
  22. https://arxiv.org/abs/1602.02410
  23. https://en.wikipedia.org/wiki/kneser   ney_smoothing
  24. https://en.wikipedia.org/wiki/language_model#id165_models
  25. https://www.eecis.udel.edu/~trnka/cisc889-11s/files/jelinek91trigrams.pdf
  26. http://id56lm.org/
  27. http://www.people.fas.harvard.edu/~yoonkim/
  28. http://arxiv.org/abs/1508.06615
  29. https://en.wikipedia.org/wiki/dari_language
  30. https://en.wikipedia.org/wiki/pashto
  31. http://arxiv.org/abs/1609.03528
  32. http://deliprao.com/archives/author/8272pwpadmin
  33. http://deliprao.com/archives/tag/deep-learning
  34. http://deliprao.com/archives/tag/language-modeling
  35. http://deliprao.com/archives/tag/lstm
  36. http://deliprao.com/archives/tag/nlp
  37. http://deliprao.com/archives/tag/id56
  38. http://deliprao.com/archives/tag/sequence-modeling
  39. http://deliprao.com/archives/191
  40. http://deliprao.com/archives/218
