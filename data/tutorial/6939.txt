   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

overview of gans (id3) - part i

   [16]go to the profile of zak jost
   [17]zak jost (button) blockedunblock (button) followfollowing
   oct 25, 2017

   the purpose of this article series is to provide an overview of gan
   research and explain the nature of the contributions. i   m new to this
   area myself, so this will surely be incomplete, but hopefully it can
   provide some quick context to other newbies.

   for part i we   ll introduce gans at a high level and summarize the
   original paper. feel free to skip to part ii if you   re already familiar
   with the basics. it   s assumed you   re familiar with the basics of neural
   networks.

background

   what is meant by generative? at a high level, a generative model means
   you have mapped the id203 distribution of the data itself. in the
   case of images, that means you have a id203 for every possible
   combination of pixel values. this also means you can generate new data
   points by sampling from this distribution (i.e. choosing combinations
   with large id203). if you   re in a id161 domain, that
   means your model can create new images from scratch. here, for example,
   is a generated face.
   [1*dmbycakmugpiqujwu7jnsw.png]

   in case this hasn   t totally sunk in yet: this is not a real person,
   it   s a computer-invented face. a gan can do this because it was given a
   lot of images of faces to learn from and that resulted in a id203
   distribution. this image is one point taken from that distribution.
   with generative models you can create new stuff that didn   t previously
   exist. audio, text, images   etc. very, very cool stuff.

the original gan

   the [18]original paper by ian goodfellow, et al outlined the basic
   approach, built the theoretical foundation and gave some example
   benchmarks.

   gans did not invent generative models, but rather provided an
   interesting and convenient way to learn them. they are called
      adversarial    because the problem is structured such that two entities
   are competing against one another, and both of those entities are
   machine learning models.

   this is best explained with an example. let   s say you want to build a
   face-image generator. you start by feeding in a bunch of random numbers
   to a system, and it adds them and multiplies them and applies fancy
   functions. at the end of this, it outputs a brightness value for each
   pixel. this is your generative model         you give it noise and it
   generates data. now, let   s say you do this 10 different times and get
   10 different fake images.

   next, you grab 10 images of real faces. then, you feed both the fake
   and real images into a different model called the discriminator. its
   job is to output a number for each input image which tells you the
   id203 that the image is real. in the beginning, the generated
   samples are just noise, so you might think this would be easy, but the
   discriminator is just as bad because it hasn   t learned anything yet
   either.
   [1*e1f3tapp4imj6pwqm5ioiq.png]

   for each mistake on a fake image, the discriminator gets penalized and
   the generator gets a rewarded. the discriminator is also penalized or
   rewarded based on classifying the real images correctly. this is why
   they   re called adversarial         the discriminator   s loss is the
   generator   s gain. over time, the competition leads to mutual
   improvement.

   finally, the word    networks    is used because the authors use a neural
   network for modeling both the generator and discriminator. this is
   awesome because it provides an easy framework for using the
   penalties/rewards to tweak the network parameters such that they learn:
   the familiar back-propagation.

theoretical foundations

   i won   t recreate all the gory details of the paper, but it   s worth
   mentioning they show both:
     * the optimization objective v(d,g) results in the generator
       id203 distribution exactly matching the true id203
       distribution. this means your fake examples are perfect and
       indistinguishable from real examples.

   [1*yt6flwsuur8rrb3gwr_1xw.png]
     * the authors    gradient ascent/descent training algorithm converges
       to this optimum. so you not only know what you need to do, but how
       to do it.

   [1*wnsjz9zks3dv3nw36rtefq.png]

   to build intuition, in the above optimization objective v(d,g), the
   term d(x) is the discriminator   s answer to the question: what   s the
   id203 that input x is from the real data set? if you plug g(z) in
   to this function, it   s the discriminator   s guess when you give it fake
   data. if you consider d and g separately you   ll see that g wants v(d,g)
   to be small and d wants this to be large. this motivates the gradient
   ascent/descent technique in the algorithm. [the e means    expectation   ,
   which is just an average. the subscript shows you which id203
   distribution you   re averaging over, either the real data or the noise
   that the generator turns into fake images].

   however, their provided proof doesn   t directly apply since we   re
   indirectly optimizing these id203 distributions by optimizing
   parameters of a neural networks, but it   s nice to know that the
   foundation has theoretical guarantees.

results

   it   s worth noting that it   s difficult to quantify the quality of fake
   data. how does one judge the improvement in fake-face generation? that
   aside, they have state of the art performance when it comes to
   generating realistic images, which is driving a lot of the buzz. images
   generally look less blurry than alternative approaches.

   although huge advancements have been made since the original paper
   (which will be covered in part ii), here are some examples from it:
   [1*qwq0_7la6g2j1hdzvgmpzw.png]

problems

   the biggest problems with the original gan implementation are:
     * training difficultly. sometimes the models will never learn
       anything or converge to a local minima.
     *    mode collapse   , which is where the generator essentially outputs
       the same thing over and over.

   these problems are addressed by refinements to the architecture and
   will be presented in future posts.

conclusion

   ultimately, this framework allows us to use the normally supervised
   learning approach of neural networks in an unsupervised way. this is
   because our labels are trivial to generate since we know which data
   came from the training set and which data were generated. it   s worth
   noting that in the above images of hand-written digits, the digit
   labels themselves were not used during training. despite this, the
   generator and discriminator are both able to learn useful
   representations of the data, as demonstrated by the generator   s
   capability of mimicking the data.

   in part ii we   ll discuss how to fix many of the training problems as
   well as make big improvements in realistic image generation.

     * [19]machine learning
     * [20]artificial intelligence
     * [21]neural networks
     * [22]data science

   (button)
   (button)
   (button) 823 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [23]go to the profile of zak jost

[24]zak jost

   research scientist at amazon aws. father. husband.

     (button) follow
   [25]towards data science

[26]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 823
     * (button)
     *
     *

   [27]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [28]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/ac78ec775e31
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/overview-of-gans-generative-adversarial-networks-part-i-ac78ec775e31&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/overview-of-gans-generative-adversarial-networks-part-i-ac78ec775e31&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_xzgonpor8ijt---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@zjost85?source=post_header_lockup
  17. https://towardsdatascience.com/@zjost85
  18. https://arxiv.org/abs/1406.2661
  19. https://towardsdatascience.com/tagged/machine-learning?source=post
  20. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  21. https://towardsdatascience.com/tagged/neural-networks?source=post
  22. https://towardsdatascience.com/tagged/data-science?source=post
  23. https://towardsdatascience.com/@zjost85?source=footer_card
  24. https://towardsdatascience.com/@zjost85
  25. https://towardsdatascience.com/?source=footer_card
  26. https://towardsdatascience.com/?source=footer_card
  27. https://towardsdatascience.com/
  28. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  30. https://medium.com/p/ac78ec775e31/share/twitter
  31. https://medium.com/p/ac78ec775e31/share/facebook
  32. https://medium.com/p/ac78ec775e31/share/twitter
  33. https://medium.com/p/ac78ec775e31/share/facebook
