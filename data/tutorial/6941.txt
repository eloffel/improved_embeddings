   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    40 must know questions to test a data scientist
   on id84 techniques comments feed [4]alternate
   [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]machine learning [94]40 must know questions to test a data
   scientist on id84 techniques

   [95]machine learning

40 must know questions to test a data scientist on id84
techniques

   [96]ankit gupta, march 20, 2017

introduction

   have you come across a dataset with hundreds of columns and wondered
   how to build a predictive model on it? or have come across a situation
   where a lot of variables might be correlated? it is difficult to escape
   these situations while working on real life problems.

   thankfully, id84 techniques come to our rescue
   here. id84 is an important technique in data
   science. it is a must have skill set for any data scientist. to test
   your knowledge in id84 techniques, we are conducted
   this skill test. these questions include topics like principal
   component analysis (pca), id167 and lda.

   [97]check out more challenging competitions coming up here

   a total of 582 people participated in this skill test. the questions
   varied from theoretical to practical.

   if you missed taking the test, here is your opportunity for you to find
   out how many questions you could have answered correctly.

   read on!


overall scores

   below is the distribution of scores, this will help you evaluate your
   performance:

   you can access your performance [98]here. more than 180 people
   participated in the skill test and the highest score was 34. here are a
   few statistics about the distribution.

   overall distribution

   mean score: 19.52

   median score: 20

   mode score: 19


useful resources

   [99]beginners guide to learn dimension reduction techniques

   [100]practical guide to principal component analysis (pca) in r &
   python

   [101]comprehensive guide on id167 algorithm with implementation in r &
   python

questions & answers

   1) imagine, you have 1000 input features and 1 target feature in a
   machine learning problem. you have to select 100 most important
   features based on the relationship between input features and the
   target features.

   do you think, this is an example of id84?

   a. yes

   b. no

   solution: (a)



   2) [ true or false ] it is not necessary to have a target variable for
   applying id84 algorithms.

   a. true

   b. false

   solution: (a)

   lda is an example of supervised id84 algorithm.


   3) i have 4 variables in the dataset such as     a, b, c & d. i have
   performed the following actions:

   step 1: using the above variables, i have created two more variables,
   namely e = a + 3 * b and f = b + 5 * c + d.

   step 2: then using only the variables e and f i have built a random
   forest model.

   could the steps performed above represent a id84
   method?

   a. true

   b. false

   solution: (a)

   yes, because step 1 could be used to represent the data into 2 lower
   dimensions.


   4) which of the following techniques would perform better for reducing
   dimensions of a data set?

   a. removing columns which have too many missing values

   b. removing columns which have high variance in data

   c. removing columns with dissimilar data trends

   d. none of these

   solution: (a)

   if a columns have too many missing values, (say 99%) then we can remove
   such columns.


   5) [ true or false ] id84 algorithms are one of the
   possible ways to reduce the computation time required to build a model.

   a. true

   b. false

   solution: (a)

   reducing the dimension of data will take less time to train a model.


   6) which of the following algorithms cannot be used for reducing the
   dimensionality of data?

   a. id167

   b. pca

   c. lda false

   d. none of these

   solution: (d)

   all of the algorithms are the example of id84
   algorithm.


   7) [ true or false ] pca can be used for projecting and visualizing
   data in lower dimensions.

   a. true

   b. false

   solution: (a)

   sometimes it is very useful to plot the data in lower dimensions. we
   can take the first 2 principal components and then visualize the data
   using scatter plot.


   8) the most popularly used id84 algorithm is
   principal component analysis (pca). which of the following is/are true
   about pca?
    1. pca is an unsupervised method
    2. it searches for the directions that data have the largest variance
    3. maximum number of principal components <= number of features
    4. all principal components are orthogonal to each other

   a. 1 and 2

   b. 1 and 3

   c. 2 and 3

   d. 1, 2 and 3

   e. 1,2 and 4

   f. all of the above

   solution: (f)

   all options are self explanatory.


   9) suppose we are using id84 as pre-processing
   technique, i.e, instead of using all the features, we reduce the data
   to k dimensions with pca. and then use these pca projections as our
   features. which of the following statement is correct?

   a. higher    k    means more id173

   b. higher    k    means less id173

   c. can   t say

   solution: (b)

   higher k would lead to less smoothening as we would be able to preserve
   more characteristics in data, hence less id173.


   10) in which of the following scenarios is id167 better to use than pca
   for id84 while working on a local machine with
   minimal computational power?

   a. dataset with 1 million entries and 300 features

   b. dataset with 100000 entries and 310 features

   c. dataset with 10,000 entries and 8 features

   d. dataset with 10,000 entries and 200 features

   solution: (c)

   id167 has quadratic time and space complexity. thus it is a very heavy
   algorithm in terms of system resource utilization.


   11) which of the following statement is true for a id167 cost function?

   a. it is asymmetric in nature.

   b. it is symmetric in nature.

   c. it is same as the cost function for sne.

   solution: (b)

   cost function of sne is asymmetric in nature. which makes it difficult
   to converge using gradient decent. a symmetric cost function is one of
   the major differences between sne and id167.


   question 12

   imagine you are dealing with text data. to represent the words you are
   using id27 (id97). in id27, you will end up
   with 1000 dimensions. now, you want to reduce the dimensionality of
   this high dimensional data such that, similar words should have a
   similar meaning in nearest neighbor space.in such case, which of the
   following algorithm are you most likely choose?

   a. id167

   b. pca

   c. lda

   d. none of these

   solution: (a)

   id167 stands for t-distributed stochastic neighbor embedding which
   consider the nearest neighbours for reducing the data.


   13) [true or false] id167 learns non-parametric mapping.

   a. true

   b. false

   solution: (a)

   id167 learns a non-parametric mapping, which means that it does not
   learn an explicit function that maps data from the input space to the
   map. for more information read from this [102]link.


   14) which of the following statement is correct for id167 and pca?

   a. id167 is linear whereas pca is non-linear

   b. id167 and pca both are linear

   c. id167 and pca both are nonlinear

   d. id167 is nonlinear whereas pca is linear

   solution: (d)

   option d is correct. read the explanation from this [103]link


   15) in id167 algorithm, which of the following hyper parameters can be
   tuned?

   a. number of dimensions

   b. smooth measure of effective number of neighbours

   c. maximum number of iterations

   d. all of the above

   solution: (d)

   all of the hyper-parameters in the option can tuned.


   16) what is of the following statement is true about id167 in
   comparison to pca?

   a. when the data is huge (in size), id167 may fail to produce better
   results.

   b. t-nse always produces better result regardless of the size of the
   data

   c. pca always performs better than id167 for smaller size data.

   d. none of these

   solution: (a)

   option a is correct


   17) xi and xj are two distinct points in the higher dimension
   representation, where as yi & yj are the representations of xi and xj
   in a lower dimension.

   1. the similarity of datapoint xi to datapoint xj is the conditional
   id203 p (j|i) .

   2. the similarity of datapoint yi to datapoint yj is the conditional
   id203 q (j|i) .

   which of the following must be true for perfect representation of xi
   and xj in lower dimensional space?

   a. p (j|i) = 0 and q (j|i) = 1

   b. p (j|i) < q (j|i)

   c. p (j|i) = q (j|i)

   d. p (j|i) > q (j|i)

   solution: (c)

   the conditional probabilities for similarity of two points must be
   equal because similarity between the points must remain unchanged in
   both higher and lower dimension for them to be perfect representations.


   18) which of the following is true about lda?

   [104][image_18.jpg]
   a. lda aims to maximize the distance between class and minimize the
   within class distance

   b. lda aims to minimize both distance between class and distance within
   class

   c. lda aims to minimize the distance between class and maximize the
   distance within class

   d. lda aims to maximize both distance between class and distance within
   class

   solution: (a)

   option a is correct.


   19) in which of the following case lda will fail?

   a. if the discriminatory information is not in the mean but in the
   variance of the data

   b. if the discriminatory information is in the mean but not in the
   variance of the data

   c. if the discriminatory information is in the mean and variance of the
   data

   d. none of these

   solution: (a)

   option a is correct


   20) which of the following comparison(s) are true about pca and lda?
    1. both lda and pca are linear transformation techniques
    2. lda is supervised whereas pca is unsupervised
    3. pca maximize the variance of the data, whereas lda maximize the
       separation between different classes,

   a. 1 and 2

   b. 2 and 3

   c. 1 and 3

   d. only 3

   e. 1, 2 and 3

   solution: (e)

   all of the options are correct


   21) what will happen when eigenvalues are roughly equal?

   a. pca will perform outstandingly

   b. pca will perform badly

   c. can   t say

   d.none of above

   solution: (b)

   when all eigen vectors are same in such case you won   t be able to
   select the principal components because in that case all principal
   components are equal.


   22) pca works better if there is?
    1. a linear structure in the data
    2. if the data lies on a curved surface and not on a flat surface
    3. if variables are scaled in the same unit

   a. 1 and 2

   b. 2 and 3

   c. 1 and 3

   d. 1 ,2 and 3

   solution: (c)

   option c is correct


   23) what happens when you get features in lower dimensions using pca?
    1. the features will still have interpretability
    2. the features will lose interpretability
    3. the features must carry all information present in data
    4. the features may not carry all information present in data

   a. 1 and 3

   b. 1 and 4

   c. 2 and 3

   d. 2 and 4

   solution: (d)

   when you get the features in lower dimensions then you will lose some
   information of data most of the times and you won   t be able to
   interpret the lower dimension data.


   24) imagine, you are given the following scatterplot between height and
   weight.

   [105][image_24.jpg] select the angle which will capture maximum
   variability along a single axis?

   a. ~ 0 degree

   b. ~ 45 degree

   c. ~ 60 degree

   d. ~ 90 degree

   solution: (b)

   option b has largest possible variance in data.


   25) which of the following option(s) is / are true?
    1. you need to initialize parameters in pca
    2. you don   t need to initialize parameters in pca
    3. pca can be trapped into local minima problem
    4. pca can   t be trapped into local minima problem

   a. 1 and 3

   b. 1 and 4

   c. 2 and 3

   d. 2 and 4

   solution: (d)

   pca is a deterministic algorithm which doesn   t have parameters to
   initialize and it doesn   t have local minima problem like most of the
   machine learning algorithms has.


   question context 26

   the below snapshot shows the scatter plot of two features (x1 and x2)
   with the class information (red, blue). you can also see the direction
   of pca and lda.

   [106][image_cont_26.jpg] 26) which of the following method would result
   into better class prediction?

   a. building a classification algorithm with pca (a principal component
   in direction of pca)

   b. building a classification algorithm with lda

   c. can   t say

   d. none of these

   solution: (b)

   if our goal is to classify these points, pca projection does only more
   harm than good   the majority of blue and red points would land
   overlapped on the first principal component.hence pca would confuse the
   classifier.


   27) which of the following options are correct, when you are applying
   pca on a image dataset?
    1.
         1. it can be used to effectively detect deformable objects.
         2. it is invariant to affine transforms.
         3. it can be used for lossy image compression.
         4. it is not invariant to shadows.

   a. 1 and 2

   b. 2 and 3

   c. 3 and 4

   d. 1 and 4

   solution: (c)

   option c is correct


   28) under which condition svd and pca produce the same projection
   result?

   a. when data has zero median

   b. when data has zero mean

   c. both are always same

   d. none of these

   solution: (b)

   when the data has a zero mean vector, otherwise you have to center the
   data first before taking svd.


   question context 29

   consider 3 data points in the 2-d space: (-1, -1), (0,0), (1,1).

   [107][image_291.jpg] 29) what will be the first principal component for
   this data?
    1. [     2 /2 ,     2/ 2 ]
    2. (1/     3, 1/     3)
    3. ([ -    2/ 2 ,     2/ 2 ])
    4. (- 1/     3,     1/     3)

   a. 1 and 2

   b. 3 and 4

   c. 1 and 3

   d. 2 and 4

   solution: (c)

   the first principal component is v = [     2 /2 ,     2/ 2 ] t (you
   shouldn   t really need to solve any svd or eigenproblem to see this).
   note that the principal component should be normalized to have unit
   length. (the negation v = [        2/ 2 ,         2/ 2 ] t is also correct.)


   30) if we project the original data points into the 1-d subspace by the
   principal component [     2 /2,     2 /2 ] t. what are their coordinates in
   the 1-d subspace?

   a. (        2 ), (0), (    2)

   b. (    2 ), (0), (    2)

   c. (     2 ), (0), (-    2)

   d. (-    2 ), (0), (-    2)

   solution: (a)

   the coordinates of three points after projection should be z1 = x t 1 v
   = [   1,    1][     2/ 2 ,     2 /2 ] t =         2, z2 = x t 2 v = 0, z3 = x t 3 v
   =     2.


   31) for the projected data you just obtained projections ( (        2 ),
   (0), (    2) ). now if we represent them in the original 2-d space and
   consider them as the reconstruction of the original data points, what
   is the reconstruction error? context: 29-31:

   a. 0%

   b. 10%

   c. 30%

   d. 40%

   solution: (a)

   the reconstruction error is 0, since all three points are perfectly
   located on the direction of the first principal component. or, you can
   actually calculate the reconstruction: z1   v.

   x  1 =         2  [     2/ 2 ,     2/2 ] t = [   1,    1]t
   x  2 = 0*[0, 0]t = [0,0] x  3 =     2* [1, 1]t = [1,1]

   which are exactly x1, x2, x3.


   32) in lda, the idea is to find the line that best separates the two
   classes. in the given image which of the following is a good
   projection?[108] [image32.jpg]
   a. ld1

   b. ld2

   c. both

   d. none of these

   solution: (a)

   ld1 is a good projection because it best separates the class.


   question context 33

   pca is a good technique to try, because it is simple to understand and
   is commonly used to reduce the dimensionality of the data. obtain the
   eigenvalues   1       2                       n and plot.

   [109][image33.jpg]

   to see how f(m) increases with m and takes maximum value 1 at m = d. we
   have two graph given below:[110] [image33_b.jpg]

   33) which of the above graph shows better performance of pca? where m
   is first m principal components and d is total number of features?

   a. left

   b. right

   c. any of a and b

   d. none of these

   solution: (a)

   pca is good if f(m) asymptotes rapidly to 1. this happens if the first
   eigenvalues are big and the remainder are small. pca is bad if all the
   eigenvalues are roughly equal. see examples of both cases in figure.


   34) which of the following option is true?

   a. lda explicitly attempts to model the difference between the classes
   of data. pca on the other hand does not take into account any
   difference in class.

   b. both attempt to model the difference between the classes of data.

   c. pca explicitly attempts to model the difference between the classes
   of data. lda on the other hand does not take into account any
   difference in class.

   d. both don   t attempt to model the difference between the classes of
   data.

   solution: (a)

   options are self explanatory.


   35) which of the following can be the first 2 principal components
   after applying pca?
    1. (0.5, 0.5, 0.5, 0.5) and (0.71, 0.71, 0, 0)
    2. (0.5, 0.5, 0.5, 0.5) and (0, 0, -0.71, -0.71)
    3. (0.5, 0.5, 0.5, 0.5) and (0.5, 0.5, -0.5, -0.5)
    4. (0.5, 0.5, 0.5, 0.5) and (-0.5, -0.5, 0.5, 0.5)

   a. 1 and 2

   b. 1 and 3

   c. 2 and 4

   d. 3 and 4

   solution: (d)

   for the first two choices, the two loading vectors are not orthogonal.


   36) which of the following gives the difference(s) between the logistic
   regression and lda?
    1. if the classes are well separated, the parameter estimates for
       id28 can be unstable.
    2. if the sample size is small and distribution of features are normal
       for each class. in such case, id156 is more
       stable than id28.

   a. 1

   b. 2

   c. 1 and 2

   d. none of these

   solution: (c)

   refer this [111]video


   37) which of the following offset, do we consider in pca?[112]
   [image_37.jpg]
   a. vertical offset

   b. perpendicular offset

   c. both

   d. none of these

   solution: (b)

   we always consider residual as vertical offsets. perpendicular offset
   are useful in case of pca


   38) imagine you are dealing with 10 class classification problem and
   you want to know that at most how many discriminant vectors can be
   produced by lda. what is the correct answer?

   a. 20

   b. 9

   c. 21

   d. 11

   e. 10

   solution: (b)

   lda produces at most c     1 discriminant vectors. you may refer this
   [113]link for more information.


   question context 39

   the given dataset consists of images of    hoover tower    and some other
   towers. now, you want to use pca (eigenface) and the nearest neighbour
   method to build a classifier that predicts whether new image depicts
      hoover tower    or not. the figure gives the sample of your input
   training images.

   [114][image_context39.jpg]

   39) in order to get reasonable performance from the    eigenface   
   algorithm, what pre-processing steps will be required on these images?
    1. align the towers in the same position in the image.
    2. scale or crop all images to the same size.

   a. 1

   b. 2

   c. 1 and 2

   d. none of these

   solution: (c)

   both the statements are correct.


   40) what are the optimum number of principle components in the below
   figure ?

   [115][image_40.jpg]
   a. 7

   b. 30

   c. 40

   d. can   t say

   solution: (b)

   we can see in the above figure that the number of components = 30 is
   giving highest variance with lowest number of components. hence option
      b    is the right answer.

end notes

   i hope you enjoyed taking the test and found the solutions helpful. the
   test focused on conceptual as well as practical knowledge
   of id84.

   if you have any doubts in the questions above, let us know through
   comments below. also, if you have any suggestions or improvements you
   think we should make in the next skill test, you can let us know by
   dropping your feedback in the comments section. also, checkout
   [116]datafest 2017.

[117]learn, [118]compete, hack and [119]get hired!

   you can also read this article on analytics vidhya's android app
   [120]get it on google play

share this:

     * [121]click to share on linkedin (opens in new window)
     * [122]click to share on facebook (opens in new window)
     * [123]click to share on twitter (opens in new window)
     * [124]click to share on pocket (opens in new window)
     * [125]click to share on reddit (opens in new window)
     *

like this:

   like loading...

related articles

   [ins: :ins]

   tags : [126]dimensionality, [127]lda, [128]pca, [129]principal
   components analysis, [130]reducing dimensionality, [131]id167,
   [132]id167 in python
   next article

senior analyst     dashboard and analytics     hyderabad (1- 4+ years of
experience)

   previous article

team lead, data quality- gurgaon, india (3+ years of experience)

[133]ankit gupta

   ankit is currently working as a data scientist at ubs who has solved
   complex data mining problems in many domains. he is eager to learn more
   about data science and machine learning algorithms.
     *
     *
     *

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [134]discussion portal to get your queries resolved

6 comments

     * pratima joshi says:
       [135]march 21, 2017 at 7:23 am
       hi,
       i think the answers and explanations of questions 10 and 11 are not
       in sync. please revisit and correct.
       [136]reply
          + [137]ankit gupta says:
            [138]march 21, 2017 at 8:33 am
            hi pratima,
            thanks for noticing!
            i change the explanation of question number 10 which was
            addressing some other issue. answers for questions 10 and 11
            are remain same
            best regards,
            ankit gupta
            [139]reply
     * marvin says:
       [140]march 21, 2017 at 4:57 pm
       hi ,
       could it be that in question 33 solution and explanation are
       contradicting or did i get it wrong?
       [141]reply
          + [142]ankit gupta says:
            [143]march 22, 2017 at 3:28 am
            hi marvin,
            explanation is correct but solution was incorrectly marked.
            thanks for noticing
            best!
            ankit gupta
            [144]reply
     * [145]                                          40                        (         ) -                 says:
       [146]june 7, 2017 at 9:28 pm
       [   ]             >>> [   ]
       [147]reply
     * keyuri says:
       [148]july 17, 2017 at 8:18 pm
       answer for the q.20 should be c because both lda and pca are
       unsupervised methods.
       [149]reply

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-05] [150]srk       3924
   2    [2.jpg?date=2019-04-05] [151]mark12    3510
   3    [3.jpg?date=2019-04-05] [152]nilabha   3261
   4    [4.jpg?date=2019-04-05] [153]nitish007 3237
   5    [5.jpg?date=2019-04-05] [154]tezdhar   3082
   [155]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [156]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [157]understanding support vector machine algorithm from examples
       (along with code)
     * [158]essentials of machine learning algorithms (with python and r
       codes)
     * [159]a complete tutorial to learn data science with python from
       scratch
     * [160]7 types of regression techniques you should know!
     * [161]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [162]a simple introduction to anova (with applications in excel)
     * [163]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [164]top 5 machine learning github repositories and reddit discussions
   from march 2019

[165]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [166]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[167]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [168]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[169]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [170]16 opencv functions to start your id161 journey (with
   python code)

[171]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [172][ds-finhack.jpg]

   [173][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [174]about us
     * [175]our team
     * [176]career
     * [177]contact us
     * [178]write for us

   [179]about us
   [180]   
   [181]our team
   [182]   
   [183]careers
   [184]   
   [185]contact us

data scientists

     * [186]blog
     * [187]hackathon
     * [188]discussions
     * [189]apply jobs
     * [190]leaderboard

companies

     * [191]post jobs
     * [192]trainings
     * [193]hiring hackathons
     * [194]advertising
     * [195]reach us

   don't have an account? [196]sign up here.

join our community :

   [197]46336 [198]followers
   [199]20224 [200]followers
   [201]followers
   [202]7513 [203]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [204]privacy policy
     * [205]terms of use
     * [206]refund policy

   don't have an account? [207]sign up here

   iframe: [208]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [209](button) join now

   subscribe!

   iframe: [210]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [211](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/machine-learning/
  94. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/
  95. https://www.analyticsvidhya.com/blog/category/machine-learning/
  96. https://www.analyticsvidhya.com/blog/author/facebook_user_4/
  97. https://datahack.analyticsvidhya.com/contest/all/
  98. https://datahack.analyticsvidhya.com/contest/skilltest-dimensionality-reduction/lb
  99. https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/
 100. https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/
 101. https://www.analyticsvidhya.com/blog/2017/01/id167-implementation-r-python/
 102. https://lvdmaaten.github.io/tsne/
 103. https://www.analyticsvidhya.com/blog/2017/01/id167-implementation-r-python/
 104. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06064954/image_18.jpg
 105. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06064637/image_24.jpg
 106. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06064252/image_cont_26.jpg
 107. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/17140918/image_291.jpg
 108. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06062621/image32.jpg
 109. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06062911/image33.jpg
 110. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06062945/image33_b.jpg
 111. https://www.youtube.com/watch?v=rfrgig1hm3m
 112. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06062131/image_37.jpg
 113. https://books.google.co.in/books?id=mggrcaaaqbaj&pg=pa110&lpg=pa110&dq=lda+produce+at+most+c-1+feature+projections&source=bl&ots=ohybplx4ij&sig=3wkobzaafzzplfsf6mxgh3wfl0i&hl=en&sa=x&ved=0ahukewizxltq-trsahuls48khvjfchyq6aeiudaj#v=onepage&q&f=false
 114. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06061642/image_context39.jpg
 115. https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06061851/image_40.jpg
 116. https://www.analyticsvidhya.com/datafest-2017/
 117. https://www.analyticsvidhya.com/blog
 118. https://datahack.analyticsvidhya.com/
 119. https://www.analyticsvidhya.com/jobs/#/user/
 120. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 121. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/?share=linkedin
 122. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/?share=facebook
 123. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/?share=twitter
 124. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/?share=pocket
 125. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/?share=reddit
 126. https://www.analyticsvidhya.com/blog/tag/dimensionality/
 127. https://www.analyticsvidhya.com/blog/tag/lda/
 128. https://www.analyticsvidhya.com/blog/tag/pca/
 129. https://www.analyticsvidhya.com/blog/tag/principal-components-analysis/
 130. https://www.analyticsvidhya.com/blog/tag/reducing-dimensionality/
 131. https://www.analyticsvidhya.com/blog/tag/id167/
 132. https://www.analyticsvidhya.com/blog/tag/id167-in-python/
 133. https://www.analyticsvidhya.com/blog/author/facebook_user_4/
 134. https://discuss.analyticsvidhya.com/
 135. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125309
 136. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125309
 137. https://www.facebook.com/app_scoped_user_id/1107394225967405/
 138. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125312
 139. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125312
 140. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125325
 141. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125325
 142. https://www.facebook.com/app_scoped_user_id/1107394225967405/
 143. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125335
 144. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-125335
 145. http://hadoopdoc.com/2017/06/08/                                          40             %
 146. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-129968
 147. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-129968
 148. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-132277
 149. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/#comment-132277
 150. https://datahack.analyticsvidhya.com/user/profile/srk
 151. https://datahack.analyticsvidhya.com/user/profile/mark12
 152. https://datahack.analyticsvidhya.com/user/profile/nilabha
 153. https://datahack.analyticsvidhya.com/user/profile/nitish007
 154. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 155. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 156. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 157. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 158. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 159. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 160. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 161. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 162. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 163. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 164. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 165. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 166. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 167. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 168. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 169. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 170. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 171. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 172. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 173. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 174. http://www.analyticsvidhya.com/about-me/
 175. https://www.analyticsvidhya.com/about-me/team/
 176. https://www.analyticsvidhya.com/career-analytics-vidhya/
 177. https://www.analyticsvidhya.com/contact/
 178. https://www.analyticsvidhya.com/about-me/write/
 179. http://www.analyticsvidhya.com/about-me/
 180. https://www.analyticsvidhya.com/about-me/team/
 181. https://www.analyticsvidhya.com/about-me/team/
 182. https://www.analyticsvidhya.com/about-me/team/
 183. https://www.analyticsvidhya.com/career-analytics-vidhya/
 184. https://www.analyticsvidhya.com/about-me/team/
 185. https://www.analyticsvidhya.com/contact/
 186. https://www.analyticsvidhya.com/blog
 187. https://datahack.analyticsvidhya.com/
 188. https://discuss.analyticsvidhya.com/
 189. https://www.analyticsvidhya.com/jobs/
 190. https://datahack.analyticsvidhya.com/users/
 191. https://www.analyticsvidhya.com/corporate/
 192. https://trainings.analyticsvidhya.com/
 193. https://datahack.analyticsvidhya.com/
 194. https://www.analyticsvidhya.com/contact/
 195. https://www.analyticsvidhya.com/contact/
 196. https://datahack.analyticsvidhya.com/signup/
 197. https://www.facebook.com/analyticsvidhya/
 198. https://www.facebook.com/analyticsvidhya/
 199. https://twitter.com/analyticsvidhya
 200. https://twitter.com/analyticsvidhya
 201. https://plus.google.com/+analyticsvidhya
 202. https://in.linkedin.com/company/analytics-vidhya
 203. https://in.linkedin.com/company/analytics-vidhya
 204. https://www.analyticsvidhya.com/privacy-policy/
 205. https://www.analyticsvidhya.com/terms/
 206. https://www.analyticsvidhya.com/refund-policy/
 207. https://id.analyticsvidhya.com/accounts/signup/
 208. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 209. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 210. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 211. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 213. https://www.facebook.com/analyticsvidhya
 214. https://twitter.com/analyticsvidhya
 215. https://plus.google.com/+analyticsvidhya/posts
 216. https://in.linkedin.com/company/analytics-vidhya
 217. https://datahack.analyticsvidhya.com/contest/skilltest-dimensionality-reduction/lb
 218. https://www.analyticsvidhya.com/blog/2017/03/senior-analyst-dashboard-and-analytics-hyderabad-1-4-years-of-experience/
 219. https://www.analyticsvidhya.com/blog/2017/03/team-lead-data-quality-gurgaon-india-3-years-of-experience/
 220. https://www.analyticsvidhya.com/blog/author/facebook_user_4/
 221. https://www.linkedin.com/in/ankit-gupta-84b737ba?trk=nav_responsive_tab_profile
 222. https://github.com/anki1909
 223. https://www.analyticsvidhya.com/blog/2017/03/questions-dimensionality-reduction-data-scientist/ankit.gupta968
 224. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 225. https://www.facebook.com/analyticsvidhya/
 226. https://twitter.com/analyticsvidhya
 227. https://plus.google.com/+analyticsvidhya
 228. https://plus.google.com/+analyticsvidhya
 229. https://in.linkedin.com/company/analytics-vidhya
 230. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 231. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 232. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 233. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 234. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 235. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 236. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 237. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 238. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 239. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 240. javascript:void(0);
 241. javascript:void(0);
 242. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 243. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 244. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 245. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 246. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 247. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 248. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 249. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 250. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 251. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f03%2fquestions-dimensionality-reduction-data-scientist%2f&linkname=40%20must%20know%20questions%20to%20test%20a%20data%20scientist%20on%20dimensionality%20reduction%20techniques
 252. javascript:void(0);
 253. javascript:void(0);
