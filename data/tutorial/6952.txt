   #[1]lewis gavin - big data & software engineer

   [2]privacy policy

   [3][5639779?v=3&s=96]

[4]lewis gavin

   big data & software engineer

   [5]craft beer blog [6]blog [7]about

like craft beers? (button) check out my craft beer blog

   [ins: :ins]
   _______________________________________________________________________
   search
   google
   custom search
   [ins: :ins]

   written on february 21, 2017
   author: [8]lewis gavin
   [9]follow [10]share

face recognition with deep learning

   face recognition with deep learning

   in my previous two posts i looked at [11]detecting faces within images
   and then [12]data prep to extract the face from the image and align it
   so that regardless of the rotation of the face, the facial features
   were always aligned centrally.

   in this post i will be preparing a number of images of myself and also
   brad pitt. the goal will be to train a deep learning model on these
   images to see if it can detect the difference between us when presented
   with a new image.

   it   s sort of a catch-22. if all goes well the model will be able to
   recognise me or brad pitt successfully. on the other hand, if it can do
   this easily, it probably means i look nothing like brad pitt!

deep learning - what is it?

   machine learning and deep learning are quite overloaded terms. they are
   seen as the silver bullet that can solve any problem, easily, without
   much effort. however it isn   t always so simple. in order to build a
   model you need to understand what it is you are exactly looking for,
   what parameters are available, how much training data is available, how
   reliable is it etc.

   deep learning is a strand of machine learning that concentrates on
   neural networks. that is programming and building a model that is
   inspired by the human brain. [13]adam geitgey has a great post that
   will explain neural networks a lot better than i ever could.

   for this post, deep learning will be used to produce points called
   embeddings (explained later). these points describe the image of the
   face. it   s goal in our case, given images for two sets of people, is to
   ensure the points (embeddings) it produces are very similar for faces
   of the same person but very different than the faces of the other
   person.
    1. make sure all points produced for images of brad pitt   s face are
       similar.
    2. make sure all points produced for images of my face are similar.
    3. make sure points produced for images of brad pitt are as different
       as possible to points produced for images of my face.

   this will then allow us to train a [14]classification model to tell the
   two sets of images apart.

building some training data

   the first step was to get some more data. i didn   t want to spend
   forever digging and downloading images so i initially trialled it with
   3 images of brad and 3 images of myself, just to prove the concept.

   i run each of the images through the face_skew.py python application i
   wrote in the [15]previous post. this gave me a total of 6 aligned
   images.

   me and brad pitt with face skew

   i stored these images in a folder called aligned_faces each within
   their own sub directory.

   ./aligned_faces/me/ ./aligned_faces/bradp/

building embeddings

   now i had prepped my data, it was time to build the embeddings.

   remember that these embeddings are a set of 128 points that are
   produced by the neural network. these points are similar for the same
   faces and different from the faces of others. the 128 point embeddings
   process was developed out of some research at [16]google. building a
   deep learning model to do this is time consuming and requires some
   beefy graphics cards. to overcome this, i have used a pre-trained model
   from [17]openface.

   they provide some helper code along with the model that helped me
   generate my embeddings. you will need to make sure you have python
   installed with the sklearn and pandas libraries, along with [18]dlib,
   [19]opencv and openface(https://github.com/cmusatyalab/openface)
   installed too.

   once you have all that installed, go into the openface base directory,
   then into a folder called batch-recognise.

   from here i run the following commands to build the embeddings for my
   aligned faces.
./main.lua -outdir ~/facerecognition/embeddings/ -data ~/facerecognition/aligned
_faces/

   in the outdir this should produce 2 files: labels.csv and reps.csv.
   these contain the image paths for the input images and a row of 128
   points for each image respectively.

   success! i have run my images against a deep learning model and
   produced some output

   you may notice a trend when dealing with [20]machine learning
   applications. most of the work is in the data prep and getting the data
   into a format the is machine readable. in our case here, it was taking
   image data and converting it to a numerical representation. before
   classifying textual data for sentiment analytics we have to do the same
   thing.

   once completed, all that remained was building a simple classifier to
   do the    recognition   .

recognising faces - do i look like brad pitt?

   if you want a more advanced approach to this step, you could train your
   own classification model to classify the embeddings. however within the
   openface directory, they kindly provided an example python classifier
   that uses a [21]support vector machine algorithm.

   from the openface base directory, go into the directory named demos.

   to train the classifier i ran the following:
$ python classifier.py train ~/facerecognition/embeddings

   now within your embeddings file, you should have a pickle file that
   contains your generated id166.

   to test it, i simply obtained two extra images that were different to
   the ones i used to train the model. one of myself and the other of brad
   pitt.

   i ran them through and obtained the following results:
$ python classifier.py infer ~/facerecognition/embeddings/classifier.pkl /media/
sf_shared/test_image_me.jpg

=== /media/sf_shared/test_image_me.jpg ===
predict me with 0.86 confidence.

$ python classifier.py infer ~/facerecognition/embeddings/classifier.pkl /media/
sf_shared/test_image_bradp.jpeg

=== /media/sf_shared/test_image_bradp.jpeg ===
predict bradp with 0.73 confidence.


wrap up

   in conclusion, unfortunately, even with a training data set of just 3
   images, the model was able to easily tell me and brad pitt apart! i
   should have seen it coming really.

   it did however seem to work with just that small sample of data. this
   was a great intro to get me started with understanding the power of
   deep learning and how it works. it   s important to read around on the
   subject as well as just copying a pasting the commands though, to at
   least gain some understanding of how the model worked.

   in the future i   ll be looking at trying to build my own deep learning
   model from scratch.
   [22]tweet

   iframe:
   [23]//rcm-eu.amazon-adsystem.com/e/cm?t=lewgav-21&o=2&p=12&l=ur1&catego
   ry=ce&banner=1v0fqhhjgzt8anfj30r2&f=ifr

   [ins: :ins]
   [ins: :ins]
   sign up for my weekly newsletter and keep up to date
   with the worlds of big data and software engineering!
   ____________________
   ____________________
   subscribe

   previous: [24]   image data prep for deep learning model
   next: [25]ideas for a morning routine to encourage success   

   [ins: :ins]

   please enable javascript to view the [26]comments powered by disqus.

references

   visible links
   1. http://www.lewisgavin.co.uk/feed.xml
   2. https://www.lewisgavin.co.uk/privacy_policy.html
   3. http://www.lewisgavin.co.uk/
   4. http://www.lewisgavin.co.uk/
   5. http://www.lewisgavin.co.uk/beermeupplease
   6. http://www.lewisgavin.co.uk/
   7. http://www.lewisgavin.co.uk/about
   8. http://twitter.com/gavlaaaaaaaa
   9. https://twitter.com/gavlaaaaaaaa
  10. https://twitter.com/share
  11. http://www.lewisgavin.co.uk/facerecognition
  12. http://www.lewisgavin.co.uk/imagedataprep
  13. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.7nppi8lvx
  14. http://www.lewisgavin.co.uk/machine-learning-basics/
  15. http://www.lewisgavin.co.uk/imagedataprep
  16. http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1a_089.pdf
  17. https://github.com/cmusatyalab/openface
  18. https://pypi.python.org/pypi/dlib#downloads
  19. http://docs.opencv.org/3.2.0/da/df6/tutorial_py_table_of_contents_setup.html
  20. http://www.lewisgavin.co.uk/tag/machine learning/
  21. http://www.lewisgavin.co.uk/machine-learning-id166/
  22. https://twitter.com/share
  23. http://rcm-eu.amazon-adsystem.com/e/cm?t=lewgav-21&o=2&p=12&l=ur1&category=ce&banner=1v0fqhhjgzt8anfj30r2&f=ifr
  24. http://www.lewisgavin.co.uk/imagedataprep/
  25. http://www.lewisgavin.co.uk/morningroutine/
  26. http://disqus.com/?ref_noscript

   hidden links:
  28. mailto:lewisdgavin@gmail.com
  29. http://github.com/gavlaaaaaaaa
  30. http://instagram.com/gavlaaaaaaaa
  31. http://linkedin.com/in/lewisdgavin
  32. http://twitter.com/gavlaaaaaaaa
  33. http://stackoverflow.com/users/2462678/gavlaaaaaaaa
