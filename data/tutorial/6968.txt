   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]stats and bots
     * [9]data science
     * [10]analytics
     * [11]startups
     * [12]bots
     * [13]design
     * [14]subscribe
     * [15]     cube.js framework
     __________________________________________________________________

chatbots with machine learning: building neural conversational agents

using machine learning approaches to build smart chatbots

   [16]go to the profile of dmitry persiyanov
   [17]dmitry persiyanov (button) blockedunblock (button) followfollowing
   sep 12, 2017

   have you ever talked to siri, alexa, or cortana to set up an alarm,
   call friends, or arrange a meeting? many people may agree that despite
   their usefulness in common and routine tasks, it   s difficult to force
   conversational agents to talk on general, sometimes philosophical
   topics.

   the [18]statsbot team invited a data scientist, dmitry persiyanov, to
   explain how to fix this issue with neural conversational models and
   build chatbots using machine learning.
   [1*rui3njlh3cfpdeqiyfaiwg.jpeg]

   interacting with the machine via natural language is one of the
   requirements for general artificial intelligence. this field of ai is
   called dialogue systems, spoken dialogue systems, or chatbots. the
   machine needs to provide you with an informative answer, maintain the
   context of the dialogue, and be indistinguishable from the human
   (ideally).

   in practice, the last requirement is not reachable yet, but luckily,
   humans are ready to talk with robots if they are helpful, sometimes
   funny, and interesting interlocutors.

     there are two major types of dialogue systems: goal-oriented (siri,
     alexa, cortana, etc.) and general conversation (microsoft tay bot).

   the former help people to solve everyday problems using natural
   language, while the latter attempt to talk with people on a wide range
   of topics.

   in this post, i will give you a comparative overview of general
   conversation dialogue systems based on deep neural networks. i will
   describe main architecture types and ways to advance them. also, there
   will be a lot of links to papers, tutorials, and implementations.

   i hope this post will eventually become the entry point for everyone
   who wants to create chatbots with machine learning. if you read this
   post till the end, you will be ready to train your own conversational
   model. ready?

   go ahead :)

     i   m going to refer to recurrent neural networks and id27s,
     so you should know how they work in order to easily follow the
     article. for those who need to refresh their knowledge, i   ve
     prepared great tutorials at the end of the article for you.

generative and selective models

   general conversation models can be simply divided into two major
   types         generative and selective (or ranking) models. also, hybrid
   models are possible. but the common thing is that such models conceive
   several sentences of dialogue context and predict the answer for this
   context. in the picture below, you can see the illustration of such
   systems.
   [1*opz3v2jitmyw1swieb-vsw.png]

     throughout this post, when i say    network consumes a sequence of
     words    or    words are passed to id56,    i mean that id27s are
     passed to the network, not word ids.

note on dialogue data representation

   before going deeper, we should discuss what dialogue datasets look
   like. all models described below are trained on pairs (context, reply).
   context is several sentences (maybe one) which preceded the reply. the
   sentence is just a sequence of tokens from its vocabulary.
   [1*nil6jzgxvaubmfiname2sg.png]

   for better understanding, look at the table. there is a batch of three
   samples extracted from raw dialogue between two persons:

   - hi!
   - hi there.
   - how old are you?
   - twenty-two. and you?
   - me too! wow!

   note the    <eos>    (end-of-sequence) token at the end of each sentence in
   the batch. this special token helps neural networks to understand
   sentence bounds and update its internal state wisely.

     some models may use additional meta information from data, such as
     speaker id, gender, emotion, etc.

   now, we are ready to move on to discussing generative models.

generative models

   we start with the simplest conversational model, based on the paper
      [19]a neural conversational model.   
   [0*yqu4pqfv48awt8bk.]
   [20]illustration source

   for modeling dialogue, this paper deployed a sequence-to-sequence
   (id195) framework which emerged in the neural [21]machine translation
   field and was successfully adapted to dialogue problems. the
   architecture consists of two id56s with different sets of parameters.
   the left one (corresponding to a-b-c tokens) is called the encoder,
   while the right one (corresponding to <eos>-w-x-y-z tokens) is called
   the decoder.

how does the encoder work?

   the encoder id56 conceives a sequence of context tokens one at a time
   and updates its hidden state. after processing the whole context
   sequence, it produces a final hidden state, which incorporates the
   sense of context and is used for generating the answer.

how does the decoder work?

   the goal of the decoder is to take context representation from the
   encoder and generate an answer. for this purpose, a softmax layer over
   vocabulary is maintained in the decoder id56. at each time step, this
   layer takes the decoder hidden state and outputs a id203
   distribution over all words in its vocabulary.

   here is how reply generation works:
    1. initialize decoder hidden state with final encoder hidden state
       (h_0).
    2. pass <eos> token as first input to the decoder and update hidden
       state (h_1)
    3. sample (or take one with max id203) first word (w_1) from
       softmax layer (using h_1).
    4. pass this word as input, update hidden state (h_1 -> h_2) and
       generate new word (w_2).
    5. repeat step 4 until <eos> token is generated or maximum answer
       length is exceeded.

   [0*57nngk4onau07g8x.]
   reply generation in decoder, for those who prefers formulas instead of
   words. here, w_t is the sampled word on time step t; theta are decoder
   parameters, phi are dense layers parameters, g represents dense layers,
   p-hat is a id203 distribution over vocabulary at time step t.

   using argmax while generating a reply, one will always get the same
   answer when utilizing the same context (argmax is deterministic, while
   sampling is stochastic).

   the process i   ve described above is only the model id136 part, but
   there is also the model training part, which works in a slightly
   different way         at each decoding step, we use the correct word y_t
   instead of the generated one (w_t) as the input. in other words, at
   training time, the decoder consumes a correct reply sequence, but with
   the last token removed and the <eos> token prepended.
   [0*8jspghqvhboexfh1.]
   illustration of decoder id136 phase. output at previous time step
   is fed as input at current time step.

   the goal is to maximize id203 of a correct next word on each time
   step. more simply, we ask the network to predict the next word in the
   sequence by providing it with a correct prefix. training is performed
   via maximum likelihood training, which leads to classical cross-id178
   loss:
   [0*pnumpbfgjatjoot8.]
   here, y_t is a correct word in reply at time step t.

modifications of generative models

   now we have a basic understanding of sequence-to-sequence framework.
   how do we add more generalization power to such models? there are a
   bunch of ways:
    1. add more layers to encoder or/and decoder id56s.
    2. use a bidirectional encoder. there is no way to make the decoder
       bidirectional due to its forward generation structure.
    3. experiment with embeddings. you can pre-initialize id27s
       or learn them from scratch together with the model.
    4. use a more advanced reply generation procedure         beamsearch. the
       idea is to not generate a reply    greedily    (by taking argmax for
       the next word) but consider the id203 of longer chains of
       words and choose among them.
    5. make your encoder or/and decoder be convolutional. convnets might
       work much faster than id56s because they can be parallelized
       efficiently.
    6. use an attention mechanism. attention was initially introduced in
       id4 papers, and has become a very popular
       and powerful technique.
    7. pass the final encoder state at each time step to the decoder. the
       decoder sees the final encoder state only once and then may forget
       it. a good idea is to pass it to the decoder along with word
       embedding.
    8. different encoder/decoder state sizes. the model i described above
       requires the encoder and decoder to have the same hidden state size
       (because we initialize the decoder state with the final encoder   s
       state). you can get rid of this requirement by adding a projection
       (dense) layer from the encoder final state to the initial decoder
       state.
    9. use characters instead of words or byte pair encoding for building
       vocabulary. character-level models are worth considering as they
       work faster because of a smaller vocabulary and they can understand
       words which are not in their vocabulary. byte pair encoding (bpe)
       is the best of both worlds. the idea is to find the most frequent
       pairs of tokens in a sequence and merge them into one token.

problems with generative models

   later, i   ll give you links to popular implementations so you can train
   your own dialogue models. but now i   d like to warn you of some common
   problems with generative models you can face.

generic responses

   generative models trained via maximum likelihood tend to predict high
   id203 for general replies such as    okay,       no,       yes,    and    i
   don   t know    for a wide range of contexts. there are some works dealing
   with this problem by:
     * [22]changing the objective function at model id136 phase;
     * [23]introducing artificial metrics and using them as rewards while
       training id195 model as id23 agent.

reply inconsistency / how to incorporate metadata

   the second major problem with id195 models is that they can generate
   inconsistent replies for paraphrased contexts but with the same sense:
   [0*o6ncn-kokzpd8hd2.]
   [24]illustration source

   the most cited work dealing with it is    [25]a persona-based neural
   conversation model.    authors used speaker ids for each utterance in
   order to generate an answer, which conditioned not only on encoder
   state, but also on speaker embedding. speaker embeddings are learned
   from scratch along with the model.
   [0*e6gdgbaarevp2utw.]
   [26]illustration source

   using this idea, you can augment your model with the different metadata
   you have. for example, if you know the tense of utterance
   (past/present/future), you can generate replies in different tenses at
   id136 time! you can adjust the personality of the replier (gender,
   age, mood) or reply properties (tense, sentiment, question/not
   question, etc.) while you have such data to train models on.

for your practice

   i promised you links to id195 models implementations in different
   frameworks, and here they are.

tensorflow

     * [27]google   s official implementation
     * [28]two more implementations which you may find more comfortable to
       work with pytorch (id195 for translation, but you can use the
       same code for dialogues)
     * [29]translation with id195 (you may use the same code but with
       dialogue data)
     * [30]implementation from ibm

keras

     * [31]popular implementation with good api

papers & guides

     * [32]a tutorial on sequence-to-sequence chatbots
     * attention mechanism
       - [33]bahdanau   s attention
       - [34]luong   s attention
       - [35]state-of-the-art on machine translation task using multi-head
       attention + feedforward networks.
       - [36]tutorial on attention in id56s
     * [37]byte pair encoding paper
     * [38]convs2s paper

diving into selective models

   getting done with generative models, let   s understand how selective
   neural conversational models work (they are often referred to as dssm,
   which stands for deep semantic similarity model).

   instead of estimating id203 p(reply | context; w), selective
   models learn similarity function         sim(reply, context; w), where a
   reply is one of the elements in a predefined pool of possible answers
   (see illustration below).

   the intuition is that the network takes context and a candidate reply
   as inputs and returns the confidence of how appropriate they are to
   each other.
   [1*vxs7ke1y9baxua3cc9fatg.png]

   the selective (or ranking, or dssm) network consists of two    towers   :
   the first for the context and the second for the reply. each tower may
   have any architecture you want. the tower takes its input and embeds it
   in semantic vector space (vectors r and c on the illustration). then,
   the similarity between context and reply vectors is computed, i.e.
   using cosine similarity c^t*r/(||c||*||r||).

   at id136 time, we can calculate the similarity between given
   context and all possible answers and choose the one with maximum
   similarity.

   in order to train the model, we use triplet loss. triplet loss is
   defined on triplets (context, reply_correct, reply_wrong) and is equal
   to:
   [0*2fpinyqexee3pwde.]
   triplet loss for selective models. it   s very similar to max-margin loss
   in id166.

   what is reply_wrong? it is also called    negative    sample (reply_correct
   is called    positive   ) and in the simplest case, it is a random reply
   from the pool of answers. so, by minimizing such loss we learn
   similarity function in a ranking way where absolute values aren   t
   informative. but remember that at the id136 phase we only need to
   compare scores for all replies and choose one with the maximum score.

   you may dive deeper into dssms at a special [39]microsoft project page.
   there are not many open-source implementations such as with generative
   models, however you may refer to the [40]tutorial which implements a
   selective model on tensorflow.

sampling schemes in selective models

   you may ask, why should we just take a random sample from a dataset?
   maybe it is a good idea to use a more complex sampling scheme? that   s
   true. if you look closer, you may realize that the number of triplets
   is o(n  ), so it   s important to choose negatives properly, because we
   can   t go through all of them (big data, you know).

   for example, we could sample k random negative replies from the pool,
   score them, and choose the one with the maximum score as our negative.
   this scheme is called    hard negative    mining. if you want to dig
   deeper, read the paper    [41]sampling matters in deep embedding
   learning.   

generative vs selective: pros and cons

   at this moment, we have an understanding of how both generative and
   selective models work. but which type do you choose? it fully depends
   on your needs. the table below is here to help you with the decision.
   [1*8c4cnasuuoel3vt3ohtjig.png]

the hardest part is evaluation

   one of the most important questions is how to evaluate neural
   conversational models. there are many automatic metrics which are used
   to evaluate chatbots with machine learning:
     * precision/recall/accuracy for selective models
     * perplexity/loss value for generative models
     * id7/meteor scores from machine translation

   but [42]some recent research works have shown that all such metrics are
   poorly correlated with human judgement of appropriateness of the reply
   for a given context.

   for example, suppose you have the context    is [43]statsbot disrupting
   the way we work with data?    and reply    it surely does.    in your
   dataset. but your model replies to this context with something like,
      it   s definitely true.    all metrics shown above will give a low score
   for such an answer, but we can see that this answer is as good as your
   data provides.
   [0*x_6w6prt7s0oj9ax.]
   [44]illustration source

   therefore, the most proper way today is to perform human evaluation of
   your models using your target metric, then choosing the best model.
   yes, this seems like an expensive process (you need to use something
   like amazon mechanical turk for evaluation models), but at this current
   time we don   t have anything better. anyway, the research community
   [45]goes this direction.

why don   t we see them in our smartphones?

   finally, we are ready to create the most powerful and intelligent
   conversational model, the [46]general artificial intelligence, right?
   if this was so, companies like apple, amazon, and google, which have
   thousands of researchers, would have already deployed them along with
   their personal assistant products.

   despite a lot of work in this area, neural dialogue systems are not
   ready to talk with humans in open-domain and provide them with
   informative/funny/helpful answers. but as for closed-domain (technical
   support or q&a systems, for example) [47]there are success stories.

tutorials on id56 and id27s

recurrent neural networks

     * [48]definitive tutorial with illustrations and code
     * [49]one of the most cited tutorials with experiments and great
       explanations

id27s

     * [50]text classifier algorithms
     * [51]great definitive guide on embeddings with illustrations
     * [52]tensorflow   s tutorial with code examples

conclusion

   conversational models may seem difficult to grasp at first (and not
   only at first). i advise you to read the original papers which i gave
   links to. also, there is a [53]pool which contains many essential
   papers on dialogue systems.

   when you   re ready to practice, choose some simple architecture, take
   [54]one of the popular datasets or mine your own (twitter, reddit, or
   whatever) and train a conversational model on it.

   iframe: [55]/media/02231cd5403151a2a463e36cc3b88462?postid=e83698b1a91e

you   d also like:

   [56]text classifier algorithms in machine learning
   key text classification algorithms with use cases and
   tutorialsblog.statsbot.co
   [57]data scientist resume projects
   machine learning problems set to build a data scientist cv without work
   experienceblog.statsbot.co
   [58]google analytics audit checklist and tools
   auditing a google analytics setup like a problog.statsbot.co

     * [59]machine learning
     * [60]data science
     * [61]chatbots
     * [62]chatbot development
     * [63]chatbot design

   (button)
   (button)
   (button) 2.3k claps
   (button) (button) (button) 12 (button) (button)

     (button) blockedunblock (button) followfollowing
   [64]go to the profile of dmitry persiyanov

[65]dmitry persiyanov

   teaching    alice    personal assistant at yandex. rl enthusiast. pursuing
   master   s degree at mipt.

     (button) follow
   [66]stats and bots

[67]stats and bots

   data stories on machine learning and analytics. from statsbot   s makers.

     * (button)
       (button) 2.3k
     * (button)
     *
     *

   [68]stats and bots
   never miss a story from stats and bots, when you sign up for medium.
   [69]learn more
   never miss a story from stats and bots
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://blog.statsbot.co/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/e83698b1a91e
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://blog.statsbot.co/chatbots-machine-learning-e83698b1a91e&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://blog.statsbot.co/chatbots-machine-learning-e83698b1a91e&source=--------------------------nav_reg&operation=register
   8. https://blog.statsbot.co/?source=logo-lo_iawxhmalx22b---cfc9f21a543a
   9. https://blog.statsbot.co/datascience/home
  10. https://blog.statsbot.co/analytics/home
  11. https://blog.statsbot.co/startups/home
  12. https://blog.statsbot.co/bots/home
  13. https://blog.statsbot.co/design/home
  14. https://blog.statsbot.co/statsbot-digest-b0d7372f842a
  15. https://cube.dev/
  16. https://blog.statsbot.co/@dmitry.persiyanov?source=post_header_lockup
  17. https://blog.statsbot.co/@dmitry.persiyanov
  18. http://statsbot.co/?utm_source=blog&utm_medium=article&utm_campaign=chatbot_ml
  19. https://arxiv.org/abs/1506.05869
  20. https://arxiv.org/abs/1506.05869
  21. https://blog.statsbot.co/machine-learning-translation-96f0ed8f19e4
  22. https://arxiv.org/abs/1510.03055
  23. https://arxiv.org/abs/1606.01541
  24. https://arxiv.org/abs/1506.05869
  25. https://arxiv.org/abs/1603.06155
  26. https://arxiv.org/abs/1506.05869
  27. https://github.com/google/id195
  28. https://github.com/jayparks/tf-id195
  29. https://github.com/spro/practical-pytorch/blob/master/id195-translation/id195-translation.ipynb
  30. https://github.com/ibm/pytorch-id195
  31. https://github.com/farizrahman4u/id195
  32. http://suriyadeepan.github.io/2016-12-31-practical-id195/
  33. https://arxiv.org/abs/1409.0473
  34. https://arxiv.org/abs/1508.04025
  35. https://arxiv.org/abs/1706.03762
  36. http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/
  37. https://arxiv.org/abs/1508.07909
  38. https://arxiv.org/abs/1705.03122
  39. http://www.sigdial.org/workshops/conference17/proceedings/pdf/sigdial48.pdf
  40. http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/
  41. https://arxiv.org/abs/1706.07567
  42. https://arxiv.org/abs/1603.08023
  43. http://statsbot.co/?utm_source=blog&utm_medium=article&utm_campaign=chatbot_ml
  44. https://arxiv.org/abs/1603.08023
  45. https://arxiv.org/abs/1707.06875
  46. https://blog.statsbot.co/3-types-of-artificial-intelligence-4fb7df20fdd8
  47. https://arxiv.org/abs/1703.09439
  48. http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-id56s/
  49. http://karpathy.github.io/2015/05/21/id56-effectiveness/
  50. https://blog.statsbot.co/text-classifier-algorithms-in-machine-learning-acc115293278
  51. http://ruder.io/word-embeddings-1/
  52. https://www.tensorflow.org/tutorials/id97
  53. https://github.com/l706077/dnn-dialogue-system-papers
  54. https://github.com/karthikncode/nlp-datasets
  55. https://blog.statsbot.co/media/02231cd5403151a2a463e36cc3b88462?postid=e83698b1a91e
  56. https://blog.statsbot.co/text-classifier-algorithms-in-machine-learning-acc115293278
  57. https://blog.statsbot.co/data-scientist-resume-projects-806a74388ae6
  58. https://blog.statsbot.co/google-analytics-audit-checklist-and-tools-fca7df2f2e7a
  59. https://blog.statsbot.co/tagged/machine-learning?source=post
  60. https://blog.statsbot.co/tagged/data-science?source=post
  61. https://blog.statsbot.co/tagged/chatbots?source=post
  62. https://blog.statsbot.co/tagged/chatbot-development?source=post
  63. https://blog.statsbot.co/tagged/chatbot-design?source=post
  64. https://blog.statsbot.co/@dmitry.persiyanov?source=footer_card
  65. https://blog.statsbot.co/@dmitry.persiyanov
  66. https://blog.statsbot.co/?source=footer_card
  67. https://blog.statsbot.co/?source=footer_card
  68. https://blog.statsbot.co/
  69. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  71. https://blog.statsbot.co/text-classifier-algorithms-in-machine-learning-acc115293278
  72. https://blog.statsbot.co/data-scientist-resume-projects-806a74388ae6
  73. https://blog.statsbot.co/google-analytics-audit-checklist-and-tools-fca7df2f2e7a
  74. https://medium.com/p/e83698b1a91e/share/twitter
  75. https://medium.com/p/e83698b1a91e/share/facebook
  76. https://medium.com/p/e83698b1a91e/share/twitter
  77. https://medium.com/p/e83698b1a91e/share/facebook
