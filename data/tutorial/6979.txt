   #[1]rare technologies    feed [2]rare technologies    comments feed
   [3]rare technologies    translation matrix: how to connect    embeddings   
   in different languages? comments feed [4]alternate [5]alternate

   [tr?id=1761346240851963&ev=pageview&noscript=1]

   iframe: [6]https://www.googletagmanager.com/ns.html?id=gtm-t2pcjld

   [7]pragmatic machine learning rare technologies [8]navigation

     * [9]services
     * [10]products
          + [11]pii tools
          + [12]scaletext
     * [13]corporate training
          + [14]overview
          + [15]python best practices
          + [16]practical machine learning
          + [17]topic modelling
          + [18]deep learning in practice
     * [19]for students
          + [20]open source
          + [21]incubator
          + [22]competitions
     * [23]company
          + [24]careers
          + [25]our team
     * [26]blog
     * [27]contact
     * [28]search

     * [29]services
     * [30]products
          + [31]pii tools
          + [32]scaletext
     * [33]corporate training
          + [34]overview
          + [35]python best practices
          + [36]practical machine learning
          + [37]topic modelling
          + [38]deep learning in practice
     * [39]for students
          + [40]open source
          + [41]incubator
          + [42]competitions
     * [43]company
          + [44]careers
          + [45]our team
     * [46]blog
     * [47]contact
     * [48]search

translation matrix: how to connect    embeddings    in different languages?

   [49]ji xiaohong 2017-09-13[50] gensim, [51]student incubator

   this is a blog post by one of our incubator students, ji xiaohong. ji
   worked on the problem of aligning differently trained id27s
   (such as id97), which is useful in applications such as machine
   translation or tracking language evolution within the same language.

   i was working on the translation matrix project, an idea originally
   proposed by mikolov et al in 2013 [2], from gensim   s [52]wiki page of
   project ideas. the project is designed to exploit similarities among
   languages for machine translation. the technique can automate the
   process of generating dictionaries and phrase tables [2]. a translation
   matrix is trained to learn a linear projection between vector spaces
   that represent different languages (or just different embedding spaces
   in general). the representation of languages can be using either the
   distributed skip-gram or continuous bag-of-words model [3].

   the translation matrix works by assuming the entity of each two
   languages share similarities in the geometric arrangement in both space
   (i.e. the relative position is similar in their spaces). we can
   visualize it in two dimensional coordinates. from figure 1 we can
   visualize the vectors (all the vectors were projected down to two
   dimensions using pca) for numbers in english and italian. you can
   easily see that those word have similar geometric arrangement in both
   space.
   screenshot-from-2017-09-04-171351

   figure 1. the relative position of each word.

   with this assumption, the main algorithm learns a linear mapping from
   the source language representation to the target language
   representation. during translation, it project the input word to be
   translated into the target space, and returns words with a
   representation closest in the target space.

   here is an example of the usage of translation matrix. we   ll be
   training our model using the english -> italian word pairs from the
   opus collection (which can be download from this [53]link). this corpus
   contains 5000 word pairs.
from gensim.models import translation_matrix
from gensim.models import keyedvectors

train_file = 'opus_en_it_europarl_train_5k.txt'
with utils.smart_open(train_file, 'r') as f:
word_pair = [tuple(utils.to_unicode(line).strip().split()) for line in f]

# load the source language word vector
# the pre-trained model can be download form this link(https://pan.baidu.com/s/1
nv3byel).
source_word_vec_file = 'en.200k.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt'
source_word_vec = keyedvectors.load_id97_format(source_word_vec_file, binary
=false)

# load the target language word vector
# the pre-trained model can be download form this link(https://pan.baidu.com/s/1
bop0p7d).
target_word_vec_file = 'it.200k.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt'
target_word_vec = keyedvectors.load_id97_format(target_word_vec_file, binary
=false)

# create translation matrix object
transmat = translation_matrix.translationmatrix(word_pair, source_word_vec, targ
et_word_vec)
transmat.train(word_pair)
print 'the shape of translation matrix is:', transmat.translation_matrix.shape

# translation the word
words = [('one', 'uno'), ('two', 'due'), ('three', 'tre'), ('four', 'quattro'),
('five', 'cinque')]
source_word, target_word = zip(*words)
translated_word = transmat.translate(source_word, 5)

   screenshot-from-2017-09-13-214440

   figure 2. you see two kind of color nodes, one for english and the
   other for italian. for the translation of word `five`, we return the
   top-3 most similar words: `[u   cinque   , u   quattro   , u   tre   ]`. we can see
   that in this case, the translation is quite convincing. see [2] for the
   research paper by mikolov et al.

   all the python commits i have done can be found [54]in this pull
   request. there   s a lot of discussion about the project in that pr. for
   a tutorial on the use of this new functionality, please refer to my
   [55]translation_matrix.ipynb notebook (now merged into gensim).

   finally, i would like to thank rare technologies for giving me the
   opportunity to participate in this incubator program and providing the
   experimental environment and hardware. and i do also really thank my
   mentor menshikh ivan, lev konstantinovskiy, gordon mohr and other
   community members for providing the kind guidance and support
   throughout the project. i learned a lot about design patterns, unit
   test, git and time management this summer!

   references:
     * [1]: [56]dinu g, lazaridou a, baroni m. improving zero-shot
       learning by mitigating the hubness problem. computer science, 2015,
       9284:135-151.
     * [2]: [57]mikolov t, le q v, sutskever i. exploiting similarities
       among languages for machine translation. computer science, 2013.
     * [3]: [58]mikolov, tomas, et al.    distributed representations of
       words and phrases and their compositionality.    advances in neural
       information processing systems. 2013.
     * [4]: [59]http://clic.cimec.unitn.it/%7egeorgiana.dinu/down/

   [60]student incubator[61]translation matrix[62]id97

author of post

   ji xiaohong

ji xiaohong's bio:

   student at the wuhan university. interested in machine learning. rare
   incubator student.

need expert consulting in ml and nlp?

   ________________________________________

   ________________________________________


   ________________________________________
   ________________________________________
   ________________________________________
   ________________________________________
   ________________________________________
   ________________________________________
   ________________________________________
   ________________________________________
   ________________________________________
   ________________________________________
   please leave this field empty. ________________________________________

   send

categories

   categories[select category___________]

archives

   archives [select month__]

recent posts

     * [63]export pii drill-down reports
     * [64]personal data analytics
     * [65]scanning office 365 for sensitive pii information
     * [66]pivoted document length normalisation
     * [67]sent2vec: an unsupervised approach towards learning sentence
       embeddings

stay ahead of the curve

get our latest tutorials, updates and insights delivered straight to your
inbox.

   ____________________

   ____________________

   subscribe
   ____________________
   1-2 times a month, if lucky. your information will not be shared.

   [68][footer-logo.png]
     * [69]services
     * [70]careers
     * [71]our team
     * [72]corporate training
     * [73]blog
     * [74]incubator
     * [75]contact
     * [76]competitions
     * [77]site map

   rare technologies [78][email protected] sv  tova 5, prague, czech
   republic [79](eu) +420 776 288 853
   type and press    enter    to search ____________________

references

   visible links
   1. https://rare-technologies.com/feed/
   2. https://rare-technologies.com/comments/feed/
   3. https://rare-technologies.com/translation-matrix-in-gensim-python/feed/
   4. https://rare-technologies.com/wp-json/oembed/1.0/embed?url=https://rare-technologies.com/translation-matrix-in-gensim-python/
   5. https://rare-technologies.com/wp-json/oembed/1.0/embed?url=https://rare-technologies.com/translation-matrix-in-gensim-python/&format=xml
   6. https://www.googletagmanager.com/ns.html?id=gtm-t2pcjld
   7. https://rare-technologies.com/
   8. https://rare-technologies.com/translation-matrix-in-gensim-python/
   9. https://rare-technologies.com/services/
  10. https://rare-technologies.com/translation-matrix-in-gensim-python/
  11. https://pii-tools.com/
  12. https://scaletext.com/
  13. https://rare-technologies.com/corporate-training/
  14. https://rare-technologies.com/corporate-training/
  15. https://rare-technologies.com/python-best-practices/
  16. https://rare-technologies.com/practical-machine-learning/
  17. https://rare-technologies.com/topic-modelling-training/
  18. https://rare-technologies.com/deep_learning_training/
  19. https://rare-technologies.com/incubator
  20. https://github.com/rare-technologies/
  21. https://rare-technologies.com/incubator/
  22. https://rare-technologies.com/competitions/
  23. https://rare-technologies.com/#braintrust
  24. https://rare-technologies.com/careers/
  25. https://rare-technologies.com/our-team/
  26. https://rare-technologies.com/blog/
  27. https://rare-technologies.com/contact/
  28. https://rare-technologies.com/translation-matrix-in-gensim-python/
  29. https://rare-technologies.com/services/
  30. https://rare-technologies.com/translation-matrix-in-gensim-python/
  31. https://pii-tools.com/
  32. https://scaletext.com/
  33. https://rare-technologies.com/corporate-training/
  34. https://rare-technologies.com/corporate-training/
  35. https://rare-technologies.com/python-best-practices/
  36. https://rare-technologies.com/practical-machine-learning/
  37. https://rare-technologies.com/topic-modelling-training/
  38. https://rare-technologies.com/deep_learning_training/
  39. https://rare-technologies.com/incubator
  40. https://github.com/rare-technologies/
  41. https://rare-technologies.com/incubator/
  42. https://rare-technologies.com/competitions/
  43. https://rare-technologies.com/#braintrust
  44. https://rare-technologies.com/careers/
  45. https://rare-technologies.com/our-team/
  46. https://rare-technologies.com/blog/
  47. https://rare-technologies.com/contact/
  48. https://rare-technologies.com/translation-matrix-in-gensim-python/
  49. https://rare-technologies.com/author/robotcator/
  50. https://rare-technologies.com/category/gensim/
  51. https://rare-technologies.com/category/student-incubator/
  52. https://github.com/rare-technologies/gensim/wiki/gsoc-2017-project-ideas
  53. https://pan.baidu.com/s/1nuiuqot
  54. https://github.com/rare-technologies/gensim/pull/1434
  55. https://github.com/rare-technologies/gensim/blob/develop/docs/notebooks/translation_matrix.ipynb
  56. https://arxiv.org/abs/1412.6568
  57. https://arxiv.org/abs/1309.4168
  58. https://arxiv.org/abs/1310.4546
  59. http://clic.cimec.unitn.it/~georgiana.dinu/down/
  60. https://rare-technologies.com/tag/student-incubator/
  61. https://rare-technologies.com/tag/translation-matrix/
  62. https://rare-technologies.com/tag/id97/
  63. https://rare-technologies.com/personal-data-reports/
  64. https://rare-technologies.com/pii_analytics/
  65. https://rare-technologies.com/pii-scan-o365-connector/
  66. https://rare-technologies.com/pivoted-document-length-normalisation/
  67. https://rare-technologies.com/sent2vec-an-unsupervised-approach-towards-learning-sentence-embeddings/
  68. https://rare-technologies.com/translation-matrix-in-gensim-python/
  69. https://rare-technologies.com/services/
  70. https://rare-technologies.com/careers/
  71. https://rare-technologies.com/our-team/
  72. https://rare-technologies.com/corporate-training/
  73. https://rare-technologies.com/blog/
  74. https://rare-technologies.com/incubator/
  75. https://rare-technologies.com/contact/
  76. https://rare-technologies.com/competitions/
  77. https://rare-technologies.com/sitemap
  78. https://rare-technologies.com/cdn-cgi/l/email-protection#7811161e17380a190a1d550c1d1b10161714171f111d0b561b1715
  79. tel:+420 776 288 853

   hidden links:
  81. https://rare-technologies.com/translation-matrix-in-gensim-python/#top
  82. https://www.facebook.com/raretechnologies
  83. https://twitter.com/raretechteam
  84. https://www.linkedin.com/company/6457766
  85. https://github.com/piskvorky/
  86. https://rare-technologies.com/feed/
