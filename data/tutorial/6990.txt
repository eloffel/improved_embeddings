   (button) toggle navigation [1]pan

     * [2]home
     * [3]pan @ clef 2010:
     * [4]about
     * [5]proceedings
     * [6]tasks
          + [7]plagiarism detection
          + [8]wikipedia vandalism detection

plagiarism detection

   2010

   the detection of plagiarism by hand is a laborious retrieval task---a
   task which can be aided or automatized. this evaluation task shall
   foster the development of new solutions in this respect.
   award
   [9]yahoo! research
   sponsor

   we are happy to announce the following overall winner of the 2nd
   international competition on plagiarism detection who will be awarded
   500,- euro sponsored by yahoo! research:
     * j. kasprzak and m. brandejs from masaryk university, czech republic

   congratulations!
   task

   given a set of suspicious documents and a set of source documents, the
   task is to find all plagiarized sections in the suspicious documents
   and, if available, the corresponding source sections.

   remark. this task combines both external plagiarism detection and
   intrinsic plagiarism detection, where the former refers to detecting
   plagiarized sections in a suspicious document and the corresponding
   source sections in a given set of source documents, and the latter
   refers to detecting plagiarized sections without comparing the
   suspicious document to any other documents, e.g., by detecting changes
   in writing style.
   training corpus

   to develop your approach, we provide you with a training corpus which
   comprises a set of suspicious documents and a set of source documents.
   a suspicious document may contain plagiarized passages, the source
   passages of which may or may not be present in one or more of the
   source documents.

   [10]learn more    [11]download corpus
   output

   for each suspicious document suspicious-documentxyz.txt found in the
   evaluation corpora, your plagiarism detector shall output an xml file
   suspicious-documentxyz.xml which contains meta information about all
   plagiarism cases detected within:
<document reference="suspicious-documentxyz.txt">
<feature
  name="detected-plagiarism"
  this_offset="5"
  this_length="1000"
  source_reference="suspicious-documentabc.txt"
  source_offset="100"
  source_length="1000"
/>
...
</document>

   the source_* attributes may be omitted in case no source document can
   be identified for a given detected plagiarized passage.

   the xml documents must be valid with respect to the xml schema found
   [12]here.
   performance measures

   performance will be measured using macro-averaged precision and recall,
   granularity, and the plagdet score, which is a combination of the first
   three measures. for your convenience, we provide a reference
   implementation of the measures written in python.

   [13]learn more    [14]download measures
   test corpus

   once you finished tuning your approach to achieve satisfying
   performance on the training corpus, you should run your software on the
   test corpus.

   during the competition, the test corpus does not contain ground truth
   data that reveals whether or not a suspicious document contains any
   plagiarized passages. to find out the performance of your software on
   the test corpus, you must collect the output its and submit it as
   described below.

   after the competition, the test corpus is updated to include the ground
   truth data. this way, you have all the neccessary data to evaluate your
   approach on your own, without submitting it's output, yet being
   comparable to those who took part in the competition.

   [15]download corpus
   submission

   to submit your test run for evaluation, we ask you to send a zip
   archive containing the output of your software when run on the test
   corpus to [16]pan@webis.de.

   should the zip archive be too large to be sent via mail, please upload
   it to a file hoster of your choosing and share a download link with us.
   results

   the following table lists the performances achieved by the
   participating teams:
   plagiarism detection performance
   plagdet participant
   0.7971 j. kasprzak and m. brandejs
   masaryk university, czech republic
   0.7090 d. zou, w. long, and z. ling
   south china university of technology, china
   0.6948 m. muhr, r. kern, m. zechner, and m. granitzer
   know-center graz, austria
   0.6209 c. grozea* and m. popescu  
   *fraunhofer first, germany
     university of bucharest, romania
   0.6066 g. oberreuter, g. l'huillier, s.a. r  os, and j.d. vel  squez
   university of chile, chile
   0.5851 d.a.r. torrej  n*^,   and j.m.m. ramos  
   *ies "jos   caballero", spain
     universidad de huelva, spain
   0.5191 r.c. pereira, v.p. moreira, and r. galante
   universidade federal do rio grande do sul, brazil
   0.5093 y. palkovskii, a. belov, and i. muzika
   zhytomyr state university and skyline, inc. ukraine
   0.4378 sobha l., pattabhi r.k r., vijay s.r., a. akilandeswari
   mit campus of anna university chennai, india
   0.2564 t. gottron
   universit  t koblenz-landau, germany
   0.2222 d. micol,   . ferr  ndez, and r. mu  oz
   university of alicante, spain
   0.2148 m.r. costa-juss  , r.e. banchs, j. grivolla, and j. codina
   barcelona media research center, spain
   0.2053 r.m.a. nawab, m. stevenson, and p. clough
   university of sheffield, uk
   0.2034 p. gupta and s. rao
   da-iict, india
   0.1375 c. vania and m. adriani
   universitas indonesia, indonesia
   0.0558 p. su  rez*, j.c. gonz  lez*^,  , and j. villena-rom  n*^,^
   *daedalus - data, decisions and language, spain
     universidad polit  cnica de madrid, spain
   ^universidad carlos iii de madrid, spain
   0.0195 s. alzahrani* and n. salim  
   *taif university, saudi arabia
     universiti teknologi malaysia, malaysia
   0.0008 a. iftene et al.
   university of iasi, romania

   a more detailed analysis of the detection performances can be found in
   the overview paper accompanying this task.

   [17]learn more   

task chair

   [18]martin potthast

   [19]martin potthast

   bauhaus-universit  t weimar

task committee

   [20]benno stein

   [21]benno stein

   bauhaus-universit  t weimar
   [22]andreas eiselt

   [23]andreas eiselt

   bauhaus-universit  t weimar
   [24]alberto barr  n-cede  o

   [25]alberto barr  n-cede  o

   universitat polit  cnica de val  ncia
   [26]paolo rosso

   [27]paolo rosso

   universitat polit  cnica de val  ncia

      pan.webis.de

references

   visible links
   1. https://pan.webis.de/index.html
   2. https://pan.webis.de/index.html
   3. https://pan.webis.de/clef10/pan10-web/index.html
   4. https://pan.webis.de/clef10/pan10-web/about.html
   5. https://pan.webis.de/clef10/pan10-web/proceedings.html
   6. https://pan.webis.de/clef10/pan10-web/plagiarism-detection.html
   7. https://pan.webis.de/clef10/pan10-web/plagiarism-detection.html
   8. https://pan.webis.de/clef10/pan10-web/wikipedia-vandalism-detection.html
   9. http://labs.yahoo.com/
  10. https://www.uni-weimar.de/medien/webis/publications/papers/stein_2010p.pdf#page=4
  11. https://www.uni-weimar.de/en/media/chairs/webis/corpora/corpus-pan-pc-09/
  12. https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-pc-09/document.xsd
  13. https://www.uni-weimar.de/medien/webis/publications/papers/stein_2010p.pdf#page=2
  14. https://pan.webis.de/sepln09/pan09-code/pan09-plagiarism-detection-performance-measures.py
  15. https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-10/pan10-data/pan10-plagiarism-detection-test-corpus-2010-05-17.zip
  16. mailto:pan@webis.de
  17. https://www.uni-weimar.de/medien/webis/publications/papers/stein_2010t.pdf#page=6
  18. https://www.uni-weimar.de/medien/webis/people
  19. https://www.uni-weimar.de/medien/webis/people
  20. http://www.webis.de/
  21. http://www.webis.de/
  22. https://www.uni-weimar.de/medien/webis/people
  23. https://www.uni-weimar.de/medien/webis/people
  24. http://users.dsic.upv.es/~lbarron/
  25. http://users.dsic.upv.es/~lbarron/
  26. http://users.dsic.upv.es/~prosso/
  27. http://users.dsic.upv.es/~prosso/

   hidden links:
  29. https://pan.webis.de/sepln09/pan09-web/plagiarism-detection.html
  30. https://pan.webis.de/clef11/pan11-web/plagiarism-detection.html
