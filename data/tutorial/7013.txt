   #[1]kdnuggets: analytics, big data, data mining and data science feed
   [2]kdnuggets    feed [3]kdnuggets    comments feed [4]kdnuggets   
   interpreting machine learning models: an overview comments feed [5]real
   world deep learning: neural networks for smart crops [6]how to job
   interview a data scientist

kdnuggets

     [7]subscribe to kdnuggets news  | [8]twitter    [9]facebook
   [10]linkedin  |  [11]contact
   ____________________ search
   [menu-30.png]
   [search-icon.png]
     * [12]software
     * [13]news/blog
     * [14]top stories
     * [15]opinions
     * [16]tutorials
     * [17]jobs
     * [18]companies
     * [19]courses
     * [20]datasets
     * [21]education
     * [22]certificates
     * [23]meetings
     * [24]webinars


   [25]kdnuggets home    [26]news    [27]2017    [28]nov    [29]tutorials,
   overviews    interpreting machine learning models: an overview
   ( [30]17:n43 )

gold blog interpreting machine learning models: an overview

   [31][prv.gif] previous post
   [32]next post [nxt.gif]


   tags: [33]interpretability, [34]machine learning, [35]modeling,
   [36]o'reilly

   this post summarizes the contents of a recent o'reilly article
   outlining a number of methods for interpreting machine learning models,
   beyond the usual go-to measures.
     __________________________________________________________________

   by [37]matthew mayo, kdnuggets.

   [38]an article on machine learning interpretation appeared on
   o'reilly's blog back in march, written by patrick hall, wen phan, and
   srisatish ambati, which outlined a number of methods beyond the usual
   go-to measures. by chance i happened back upon the article again over
   the weekend, and with a fresh read decided to share some of the ideas
   contained within. the article is a great (if lengthy) read, and
   recommend it to anyone who has the time.

   the article is organized as follows:
     * overview of the differing complexities of (machine learning)
       functions to be explained
     * overview of the scope of interpretability, local (small regions of
       conditional distributions) vs. global (entire conditional
       distributions)
     * a discussion of understanding and trust, and how traditional
       measures of understanding -- such as cross-validation and
       assessment plots -- often don't do enough to inspire trust in a
       model
     * a breakdown into 3 sections of interpretation techniques (the real
       meat of the article)

     part 1 includes approaches for seeing and understanding your data in
     the context of training and interpreting machine learning
     algorithms, part 2 introduces techniques for combining linear models
     and machine learning algorithms for situations where
     interpretability is of paramount importance, and part 3 describes
     approaches for understanding and validating the most complex types
     of predictive models.

   the deconstruction of the interpretability of each technique and group
   of techniques is the focus of the article, while this post is a summary
   of the techniques.


part 1: seeing your data


   this section starts the article off slowly, and points out some methods
   to perform visual data exploration beyond the more traditional.

     [t]here are many, many ways to visualize data sets. most of the
     techniques highlighted below help illustrate all of a data set in
     just two dimensions, not just univariate or bivariate slices of a
     data set (meaning one or two variables at a time). this is important
     in machine learning because most machine learning algorithms
     automatically model high-degree interactions between variables
     (meaning the effect of combining many i.e., more than two or three
     variables together).

   visualization techniques presented in this section include:
     * glyphs
     * correlation graphs
     * 2d projections, such as pca, mds, and id167
     * partial dependence plots
     * residual analysis

                                visualization
   a correlation graph representing loans made by a large financial firm.
            figure courtesy of patrick hall and the h2o.ai team.

   recommended questions to be asked to help determine the value of these
   visualization techniques (which are similarly asked of techniques in
   subsequent parts) include:
     * what complexity of functions can visualizations help interpret?
     * how do visualizations enhance understanding?
     * how do visualizations enhance trust?


part 2: using machine learning in regulated industry


   things get a bit more interesting here.

     the techniques presented in this section are newer types of linear
     models or models that use machine learning to augment traditional,
     linear modeling methods. these techniques are meant for
     practitioners who just can't use machine learning algorithms to
     build predictive models because of interpretability concerns.

   techniques outlined in this section include:
     * generalized additive models (gams)
     * quantile regression
     * building toward machine learning model benchmarks -- that is,
       employ a deliberate process when moving from traditional linear
       models toward machine learning algorithms, taking baby steps, and
       comparing performance and outcomes along the way, as opposed to
       jumping from a simple regression model into the deep end with black
       boxes
     * machine learning in traditional analytics processes -- this is the
       suggestion to use ml algorithms to augment analytical lifecycle
       processes for more accurate predictions, such as predicting linear
       model degredation
     * small, interpretable ensembles -- it's a foregone conclusion at
       this point that there is massive value in ensemble methods, in
       general, but employing simple such methods can potentially help
       boost both accuracy as well as interpretability.
     * [39]monotonicity constraints -- such constraints can possibly
       transform complex models into interpretable, nonlinear, montonic
       models

     monotonicity is very important for at least two reasons:
    1. monotonicity is often expected by regulators
    2. monotonicity enables consistent reason code generation

                              ensemble methods
      a diagram of a small, stacked ensemble. figure courtesy of vinod
                        iyengar and the h2o.ai team.


part 3: understanding complex machine learning models


   in my opinion, this is where things get especially interesting. i
   approach complex machine learning model interpretability as an advocate
   of automated machine learning, since i feel the two techniques are
   flipsides of the same coin: if we are going to be using automated
   techniques to generate models on the front-end, then devising and
   employing appropriate ways to simplify and understand these models on
   the back-end becomes of utmost importance.

   here are the approaches outlined for helping understand complex ml
   models within this article.

   surrogate models -- simply, a surrogate is a simple model which can be
   used to explain a more complex model. if the surrogate model is created
   by training, say, a simple id75 or a decision tree with
   original input data and predictions from the more complex model, the
   characteristics of the simple model can then be assumed to be an
   accurately descriptive stand-in of the more complex model. and it may
   not not be accurate at all.

   why, then, employ a surrogate model?

     surrogate models enhance trust when their coefficients, variable
     importance, trends, and interactions are in line with human domain
     knowledge and reasonable expectations of modeled phenomena.
     surrogate models can increase trust when used in conjunction with
     sensitivity analysis to test that explanations remain stable and in
     line with human domain knowledge, and reasonable expectations when
     data is lightly and purposefully perturbed, when interesting
     scenarios are simulated, or as data changes over time.

   local interpretable model-agnostic explanations (lime) -- lime is for
   building surrogate models based on a single observation

     an implementation of lime may proceed as follows. first, the set of
     explainable records are scored using the complex model. then, to
     interpret a decision about another record, the explanatory records
     are weighted by their closeness to that record, and an l1
     regularized linear model is trained on this weighted explanatory
     set. the parameters of the linear model then help explain the
     prediction for the selected record.

   maximum activation analysis -- a technique which looks to isolate
   particular instances which elicit a maximum response of some model
   hyperparameter

     in maximum activation analysis, examples are found or simulated that
     maximally activate certain neurons, layers, or filters in a neural
     network or certain trees in decision tree ensembles. for the
     purposes of maximum activation analysis, low residuals for a certain
     tree are analogous to high-magnitude neuron output in a neural
     network.

   so... lime, or maximum activation analysis, or both?

     lime, discussed above, helps explain the predictions of a model in
     local regions of the conditional distribution. maximum activation
     analysis helps enhance trust in localized, internal mechanisms of a
     model. the two make a great pair for creating detailed, local
     explanations of complex response functions.

   sensitivity analysis -- this technique helps to determine whether
   intentionally perturbed data, or similar data changes, modify model
   behavior and destabilizes the outputs; it is also useful for
   investigating model behavior for particular scenarios of interest or
   corner cases

   global variable importance measures -- typically the domain of
   tree-based models; a heuristic for determining varibale importance
   relates to the depth and frequency of a given variable's split point;
   higher and more frequent variables are decidedly more important

   for example:

     for a single decision tree, a variable's importance is
     quantitatively determined by the cumulative change in the splitting
     criterion for every node in which that variable was chosen as the
     best splitting candidate.

                     global variable importance measures
     an illustration of variable importance in a decision tree ensemble
         model. figure courtesy of patrick hall and the h2o.ai team.

   leave-one-covariate-out (loco) -- "model-agnostic generalization of
   mean accuracy decrease variable importance measures"; originally
   developed for regression models, but applicable more generally; the
   technique's goal is to determine the variable with the largest absolute
   impact on a given row -- by iteratively zeroing out variable values --
   which is determined to be the most important for that row's prediction

     how do variable importance measures enhance understanding?
     variable importance measures increase understanding because they
     tell us the most influential variables in a model and their relative
     rank.

   [40]treeinterpreter -- strictly a tree-based model (id90,
   id79, etc.) interpretation approach

     treeinterpreter simply outputs a list of the bias and individual
     contributions for a variable in a given model or the contributions
     the input variables in a single record make to a single prediction.

   i am currently experimenting with treeinterpreter and hope to soon
   share my experience.

   to reiterate, [41]this o'reilly article which i have superficially
   summarized merits a full reading if you have time, wherein it fleshes
   out the techniques of which i have only scratched the surface, and does
   a much better job than did i of weaving together how useful each
   technique is and what one should expect as a resultof its utilization.

   a thanks to patrick hall, wen phan, and srisatish ambati, the authors
   of this informative article.


   related:
     * [42]simplifying decision tree interpretability with python &
       scikit-learn
     * [43]the myth of model interpretability
     * [44]introduction to local interpretable model-agnostic explanations
       (lime)
     __________________________________________________________________

   [45][prv.gif] previous post
   [46]next post [nxt.gif]
     __________________________________________________________________

top stories past 30 days

                                              most popular
    1. [47]another 10 free must-read books for machine learning and data
       science
    2. [48]9 must-have skills you need to become a data scientist, updated
    3. [49]who is a typical data scientist in 2019?
    4. [50]the pareto principle for data scientists
    5. [51]what no one will tell you about data science job applications
    6. [52]19 inspiring women in ai, big data, data science, machine
       learning
    7. [53]my favorite mind-blowing machine learning/ai breakthroughs

                                                most shared
    1. [54]id158s optimization using genetic algorithm
       with python
    2. [55]who is a typical data scientist in 2019?
    3. [56]8 reasons why you should get a microsoft azure certification
    4. [57]the pareto principle for data scientists
    5. [58]r vs python for data visualization
    6. [59]how to work in data science, ai, big data
    7. [60]the deep learning toolset     an overview

[61]latest news

     * [62]download your datax guide to ai in marketing
     * [63]kdnuggets offer: save 20% on strata in london
     * [64]training a champion: building deep neural nets for big ...
     * [65]building a recommender system
     * [66]predict age and gender using convolutional neural netwo...
     * [67]top tweets, mar 27     apr 02: here is a great ex...

more recent stories

     * [68]top tweets, mar 27     apr 02: here is a great explanat...
     * [69]odsc east is selling out; odsc india announced
     * [70]accelerate ai and data science career expo, may 4, 2019
     * [71]grow your data career at datasciencego, san diego, sep 27-29
     * [72]getting started with nlp using the pytorch framework
     * [73]how to diy your data science education
     * [74]top 8 data science use cases in gaming
     * [75]kdnuggets 19:n13, apr 3: top 10 data scientist coding mista...
     * [76]make better data-driven business decisions
     * [77]top stories, mar 25-31: r vs python for data visualization;
       th...
     * [78]two predictive analytics world events in europe this fall
     * [79]7 qualities your big data visualization tools absolutely must
       ...
     * [80]yeshiva university: tenure-track faculty in ai and machine
       lea...
     * [81]which face is real?
     * [82]yeshiva university: program director / tenure track faculty
       me...
     * [83]top 10 coding mistakes made by data scientists
     * [84]uber   s case study at paw industry 4.0: machine learning ...
     * [85]xai     a data scientist   s mouthpiece
     * [86]what does gpt-2 think about the ai arms race?
     * [87]openclassrooms: data freelance online course creator
       [telecomm...

   [88]kdnuggets home    [89]news    [90]2017    [91]nov    [92]tutorials,
   overviews    interpreting machine learning models: an overview
   ( [93]17:n43 )
      2019 kdnuggets. [94]about kdnuggets.  [95]privacy policy. [96]terms
   of service

   [97]subscribe to kdnuggets news
   [98][tw_c48.png] [99]facebook [100]linkedin
   x
   [envelope.png] [101]get kdnuggets, a leading newsletter on ai, data
   science, and machine learning
   email: ______________________________
   sign up
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://www.kdnuggets.com/feed/
   2. https://www.kdnuggets.com/feed
   3. https://www.kdnuggets.com/comments/feed
   4. https://www.kdnuggets.com/2017/11/interpreting-machine-learning-models-overview.html/feed
   5. https://www.kdnuggets.com/2017/11/real-world-deep-learning-neural-networks-smart-crops.html
   6. https://www.kdnuggets.com/2017/11/how-job-interview-data-scientist.html
   7. https://www.kdnuggets.com/news/subscribe.html
   8. https://twitter.com/kdnuggets
   9. https://www.facebook.com/kdnuggets
  10. https://www.linkedin.com/groups/54257/
  11. https://www.kdnuggets.com/contact.html
  12. https://www.kdnuggets.com/software/index.html
  13. https://www.kdnuggets.com/news/index.html
  14. https://www.kdnuggets.com/news/top-stories.html
  15. https://www.kdnuggets.com/opinions/index.html
  16. https://www.kdnuggets.com/tutorials/index.html
  17. https://www.kdnuggets.com/jobs/index.html
  18. https://www.kdnuggets.com/companies/index.html
  19. https://www.kdnuggets.com/courses/index.html
  20. https://www.kdnuggets.com/datasets/index.html
  21. https://www.kdnuggets.com/education/index.html
  22. https://www.kdnuggets.com/education/analytics-data-mining-certificates.html
  23. https://www.kdnuggets.com/meetings/index.html
  24. https://www.kdnuggets.com/webcasts/index.html
  25. https://www.kdnuggets.com/
  26. https://www.kdnuggets.com/news/index.html
  27. https://www.kdnuggets.com/2017/index.html
  28. https://www.kdnuggets.com/2017/11/index.html
  29. https://www.kdnuggets.com/2017/11/tutorials.html
  30. https://www.kdnuggets.com/2017/n43.html
  31. https://www.kdnuggets.com/2017/11/real-world-deep-learning-neural-networks-smart-crops.html
  32. https://www.kdnuggets.com/2017/11/how-job-interview-data-scientist.html
  33. https://www.kdnuggets.com/tag/interpretability
  34. https://www.kdnuggets.com/tag/machine-learning
  35. https://www.kdnuggets.com/tag/modeling
  36. https://www.kdnuggets.com/tag/oreilly
  37. https://www.kdnuggets.com/author/matt-mayo
  38. https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning
  39. https://en.wikipedia.org/wiki/monotonic_function
  40. https://github.com/andosa/treeinterpreter
  41. https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning
  42. https://www.kdnuggets.com/2017/05/simplifying-decision-tree-interpretation-decision-rules-python.html
  43. https://www.kdnuggets.com/2015/04/model-interpretability-neural-networks-deep-learning.html
  44. https://www.kdnuggets.com/2016/08/introduction-local-interpretable-model-agnostic-explanations-lime.html
  45. https://www.kdnuggets.com/2017/11/real-world-deep-learning-neural-networks-smart-crops.html
  46. https://www.kdnuggets.com/2017/11/how-job-interview-data-scientist.html
  47. https://www.kdnuggets.com/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html
  48. https://www.kdnuggets.com/2018/05/simplilearn-9-must-have-skills-data-scientist.html
  49. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  50. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  51. https://www.kdnuggets.com/2019/03/data-science-job-applications.html
  52. https://www.kdnuggets.com/2019/03/women-ai-big-data-science-machine-learning.html
  53. https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html
  54. https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html
  55. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  56. https://www.kdnuggets.com/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html
  57. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  58. https://www.kdnuggets.com/2019/03/r-vs-python-data-visualization.html
  59. https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html
  60. https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html
  61. https://www.kdnuggets.com/news/index.html
  62. https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html
  63. https://www.kdnuggets.com/2019/04/strata-kdnuggets-offer-save-london.html
  64. https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html
  65. https://www.kdnuggets.com/2019/04/building-recommender-system.html
  66. https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html
  67. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  68. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  69. https://www.kdnuggets.com/2019/04/odsc-east-selling-out-india-announced.html
  70. https://www.kdnuggets.com/jobs/19/04-03-accelerate-ai-data-science-career-expo-2019.html
  71. https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html
  72. https://www.kdnuggets.com/2019/04/nlp-pytorch.html
  73. https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html
  74. https://www.kdnuggets.com/2019/04/top-8-data-science-use-cases-gaming.html
  75. https://www.kdnuggets.com/2019/n13.html
  76. https://www.kdnuggets.com/2019/04/psu-make-better-data-driven-business-decisions.html
  77. https://www.kdnuggets.com/2019/04/top-news-week-0325-0331.html
  78. https://www.kdnuggets.com/2019/04/paw-two-predictive-analytics-world-events-europe-fall.html
  79. https://www.kdnuggets.com/2019/04/7-qualities-big-data-visualization-tools.html
  80. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-faculty-ai-machine-learning.html
  81. https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html
  82. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-program-director-faculty-artificial-intelligence-machine-learning.html
  83. https://www.kdnuggets.com/2019/04/top-10-coding-mistakes-data-scientists.html
  84. https://www.kdnuggets.com/2019/04/paw-uber-case-study-machine-learning-enforce-mobile-performance.html
  85. https://www.kdnuggets.com/2019/04/xai-data-scientist.html
  86. https://www.kdnuggets.com/2019/04/gpt-2-think-about-ai-arms-race.html
  87. https://www.kdnuggets.com/jobs/19/04-01-openclassrooms-data-freelance-online-course-creator-b.html
  88. https://www.kdnuggets.com/
  89. https://www.kdnuggets.com/news/index.html
  90. https://www.kdnuggets.com/2017/index.html
  91. https://www.kdnuggets.com/2017/11/index.html
  92. https://www.kdnuggets.com/2017/11/tutorials.html
  93. https://www.kdnuggets.com/2017/n43.html
  94. https://www.kdnuggets.com/about/index.html
  95. https://www.kdnuggets.com/news/privacy-policy.html
  96. https://www.kdnuggets.com/terms-of-service.html
  97. https://www.kdnuggets.com/news/subscribe.html
  98. https://twitter.com/kdnuggets
  99. https://facebook.com/kdnuggets
 100. https://www.linkedin.com/groups/54257
 101. https://www.kdnuggets.com/news/subscribe.html

   hidden links:
 103. https://www.kdnuggets.com/
 104. https://www.kdnuggets.com/
