               rob hagiwara's monthly mystery spectrogram webzone

   welcome to the monthly mystery spectrogram webzone. these pages are rob
   hagiwara's professional web-space. for personal musings, please see
   [1]rob's blog.

   [2]navigation bar

   this is the how to page of the mystery spectrogram webzone. contents
   for this page:
     * [3]how do i read a spectrogram?
     * [4]sources and filters
     * [5]formants and vowels
     * [6]manner and place of articulation (plosives)
     * [7]fricatives
     * [8]nasals
     * [9]approximants
     * [10]etc.

   may 2009: fixed broken rollovers, miscellaneous text cleaning

   september 2007: updated menus and navigation

   may 2006: commentary about stuff that i plan to change, or would like
   some in put on, is interspersed throughout this version of the page, in
   this goofy text. depending on your browser, i think this is rendered in
   colo(u)r. general stuff changing throughout:
     * [del: fix unicode ipa symbol calls to uniform style (hex?) :del]
     * [del: re-do all figures with better original recordings and cleaner
       spectrograms :del]
     * [del: rollover formant markings for all figures :del]
     * [del: incorporate other rollover information (nasal poles/zeroes,
       duration) into text :del]
     * clean up text
     * separate sections onto separate pages for faster loading(? maybe
       vowels, obstruents and sonorant consonants? or vowels, consonants,
       and allophonic/prosodic stuff?)
     * beef up allophony section to include flapping, glottal stops and
       glottalization, nasality (nasal vowels and nasal taps?), and ...?

how do i read a spectrogram?

   the same way you get to carnegie hall: practice, practice, practice!

   first, read the chapter on acoustic analysis in ladefoged's a course in
   id102, or better yet take a course based on ladefoged's elements of
   acoustic id102 or johnson's acoustic and auditory id102. or you
   can just read this summary, but bear in mind there's going to be a lot
   left out, especially in the 'why' realm. then (as usual) learn by
   doing!

   the goal of this page is to provide just enough basic information for
   the novice to begin, perhaps with some guidance, the process of
   decoding the monthly mystery spectrogram. this page is not intended to
   be the last word in spectrographic analysis in general, nor even the
   last word on spectrogram reading. however, reasoning your way through a
   mystery spectrogram is very instructive, especially in relating
   acoustic events with (presumed) articulatory ones. that is, in relating
   physical sounds with speech production.

   if you're reading this, i assume you are familiar with basic
   articulatory id102, phonetic transcription, the international
   phonetic alphabet, and the surface phonology of 'general' north
   american english (i.e. phonemes and basic contrasts, and major
   allophonic variation such as vowel nasalization, nasal place
   assimilation, and so forth). i try to keep in mind that i have an
   international audience, but there are some details i just take to be
   'given' for english. someday if we do spectrograms of other languages,
   we'll have to adjust.

   i really recommend that beginners find someone to discuss
   spectrographic issues with. if you're doing spectrograms as part of a
   class, form a study group. if you're a 'civilian', form a club. or
   something. i'm toying with the idea of starting a yahoo group or
   something for us to do some discussions as 'community'. strong opinions
   anyone? unfortunately, i don't have time to answer in detail every
   e-mail i receive about specific spectrograms or sounds or features, but
   if you have a general question or suggestions, please feel free to
   [11]contact me.

   please note: my style sheet calls for this page to be rendered in
   either victor gaultney's gentium font, or in sil's sildoulosipaunicode.
   these fonts are (in my opinion) the best available freeware fonts for
   ipa-ing in unicode for the web. please see my list of [12]currently
   supported fonts for justification and links to download these fonts.

  so what is a spectrogram anyway?

   a sound spectrogram (or sonogram) is a visual representation of an
   acoustic signal. to oversimplify things a fair amount, a fast fourier
   transform is applied to an electronically recorded sound. this analysis
   essentially separates the frequencies and amplitudes of its component
   simplex waves. the result can then be displayed visually, with degrees
   of amplitude (represented light-to-dark, as in white=no energy,
   black=lots of energy), at various frequencies (usually on the vertical
   axis) by time (horizontal).

   depending on the size of the fourier analysis window, different levels
   of frequency/time resolution are achieved. a long window resolves
   frequency at the expense of time   the result is a narrow band
   spectrogram, which reveals individual harmonics (component
   frequencies), but smears together adjacent 'moments'. if a short
   analysis window is used, adjacent harmonics are smeared together, but
   with better time resolution. the result is a wide band spectrogram in
   which individual pitch periods appear as vertical lines (or
   striations), with formant structure. generally, wide band spectrograms
   are used in spectrogram reading because they give us more information
   about what's going on in the vocal tract, for reasons which should
   become clear as we go.

sources and filters

   we often talk about speech in terms of source-filter theory. put
   simply, we can view the vocal tract like a musical instrument. there's
   a part that actually makes sound (e.g. the string, the reed, or the
   vocal folds), and the part that 'shapes' the sound (e.g. the body of
   the violin, the horn of the clarinet, or the supralaryngeal
   articulators). in speech, this source of sound is provided primarily by
   the vibration of the vocal folds. from a mathematical standpoint, vocal
   fold vibration is complex, consisting of both a fundamental frequency
   and harmonics. because the harmonics always occur as integral multiples
   of the fundamental (x1, x2, x3, etc.   which phenomenon was
   mathematically proven by fourier, hence "fourier's theorem" and
   "fourier transform"), it turns out that the sensation of pitch of voice
   is correlated to both the fundamental frequency, and the distance
   between harmonics.

   the point is that vocal source isn't just one frequency, but many
   frequencies ranging from the fundamental all the way up to infinity, in
   principle, in integral multiples. just as white light is many
   frequencies of light all mixed up together, so is the vocal source a
   spectrum of acoustic energy, going from low frequencies (the
   fundamental) to high frequencies. in principle, there's some energy at
   all frequencies (although unless you're talking about an integral
   multiple of the fundamental, the amount will be zero).

   the energy provided by the source is then filtered or shaped by the
   body of the instrument. in essence, the filter sifts the energy of some
   harmonics out (or at least down) while boosting others. the analogy to
   light again is apt. if you pass a white light through a red filter, you
   end up removing (or lessening) the energy at the blue end of the
   spectrum, while leaving the red end of the spectrum untouched.
   depending on the filter, you might pass a band of energy in the red end
   and a band of energy in the green band, and something else. the 'color'
   of light that results will be different depending on which frequencies
   exactly get passed, and which ones get filtered.

   in speech, these different tonal qualities change depending on vocal
   tract configuration. what makes an [i] sound like an [i] is not
   something to do with the source, but the shape of the filter, boosting
   some frequencies and damping others, depending on the shape of the
   vocal tract. so the 'quality' of the vowel depends on the frequencies
   being passed through the acoustic filter (the vocal tract), just as the
   'color' of light depends on the frequencies being passed through the
   light filter.

   so, we can manipulate source characteristics (the relative frequency
   and amplitude of the fundamental   and some properties of some of the
   harmonics) at the larynx independently of filter characteristics (vocal
   tract shape). < a href="#figfilter">figure 1, is a spectrogram of me
   saying [ i    i    ] (i.e. "ee ah ee ah") continuously on a steady pitch.
   on the left, a wide band spectrogram shows the formants (darker bands
   running horizontally across the spectrogram) changing rapidly as my
   vocal tract moves between vowel configurations. (take a moment to
   notice that the wide band spectrogram is striated, and the horizontal
   formants are 'overlaid' over the basic pattern of vertical
   striationsn.) on the right, a narrow band spectrogram reveals that the
   harmonics   the complex frequencies provided by the source   are steady,
   i.e. the pitch throughout is flat. because some harmonics are stronger
   than others at any given moment, you can make out the formant structure
   even in the narrow band spectrogram. the filter function (the formant
   structure) is superimposed over the source structure.

   if you're still not sure what i mean by 'band' or 'formant', pass your
   mouse cursor over the figure. i've marked the center frequency, more or
   less, of each visible formant in the figure. look for the rollover icon
   in captions of spectrograms for extra information like this. depending
   on your hardware/software configuration, you should also be able to
   play the audio clip, by pressing the 'play' button in the figure
   caption.

   [13]1. changing filter, steady source
   figure 1. wide band (left) and narrow band (right) spectrograms,
   illustrating changing vowel quality with level pitch. rollover icon

   the other side of the source-filter coin is that you can vary the pitch
   (source) while keeping the the same filter. [14]figure 2 shows wide and
   narrow band spectrograms of me going [a  ], but wildly moving my voice
   up and down. the formants stay steady in the wide band spectrogram, but
   the spacing between the harmonics changes as the pitch does. (harmonics
   are always evenly spaced, so the higher the fundamental frequency    the
   pitch of my voice   the further apart the harmonics will be.)

   [15]2. steady filter, changing source
   figure 2. wide band (left) and (narrow band) spectrgrams of me saying
   [a  ], but with wild pitch changes. rollover icon

  a word on sources

   i like to divide the kinds of sources in speech into three categories:
   periodic voicing (or vibration of the vocal folds), non-voicing (which
   most people don't consider, but i like to distinguish it from my third
   category), and aperiodic noise (which results from turbulent airflow).

   voicing is represented on a wide band spectrogram by vertical
   striations, especially in the lowest frequencies. each vertical 'line'
   represents a single pulse of the vocal folds, a single puff of air
   moving through the glottis. we sometimes refer to a 'voicing bar', i.e.
   a row of striated energy in the very low frequencies, corresponding to
   the energy in the first and second harmonics (typically the strongest
   harmonics in speech). for men, this is about 100-150 hz, for women it
   can be anywhere between 150-250 hz, and of course there's lots of
   variation both within and between individuals. in a narrow band
   spectrogram, voicing results in harmonics, with again the lowest one or
   two being the strongest.

   non-voicing is basically silence, and doesn't show up as anything in a
   spectrogram. so while there isn't a lot going on during silence that we
   can see in a spectrogram, we can still tell the difference between
   voiced sounds (with a striated voicing bar) and voiceless sounds
   (without). and usually there's still air moving through the vocal
   tract, which can provide an alternative source of acoustic energy, via
   turbulence or 'noise'.

   on the other hand, it's worth distinguishing several glottal states
   that lead to non-voicing. typically, active devoicing, results from
   vocal fold abduction. the vocal folds are held wide apart and thus
   movement of air through the glottis doesn't cause the folds to vibrate.
   if the vocal folds are tightly adducted (brought together in the
   midline) and stiffened, the result is no air movement through the
   glottis, due to glottal closure. ideally, this is how a 'glottal stop'
   is produced. finally, the vocal folds may be in 'voicing position',
   loosely adducted and relatively slack. but if there is insufficient
   pressure below the glottis (or too much above the glottis) the air
   movement through the glottis won't be enough to drive vibration, and
   passive devoicing occurs.

   noise is random (rather than striated or harmonically organized)
   energy, and usually results from friction. in speech this friction is
   of two types. there's the turbulence generated by the air as it moves
   past the walls of the vocal tract, usually called 'channel frication'.
   this is just 'drag', resistance to the free flow of air. if the air is
   blown against (instead of across) an object, you get even more
   turbulence, which we sometimes call 'obstacle frication'. for instance,
   when we make an [s], a jet of air is blown against the front teeth   the
   sudden displacement results in a lot of turbulence, and therefore
   noise. in spectrograms, noise is 'snowy'. the energy is placed in
   frequency and amplitude more randomly rather than being organized
   neatly into striations or clear bands. (not to say they're aren't or
   can't be bands. they're just usually don't have 'edges' to the degree
   that formants do. or may.)

   we'll return to voicing and voicelessness below, after we deal with
   vowels.

so what's the deal with formants?

   a formant is a dark band on a wide band spectrogram, which corresponds
   to a vocal tract resonance. technically, it represents a set of
   adjacent harmonics which are boosted by a resonance in some part of the
   vocal tract. thus, different vocal tract shapes will produce different
   formant patterns, regardless of what the source is doing. consider the
   spectrograms in [16]figure 3, which represents the simplex vowels of
   american english (at least in my voice). in the top row are "beed, bid,
   bade, bed, bad" (i.e. [bid] [b  d] [be  d] [b  d] [b  d]). notice that as
   the vowels get lower in the 'vowel space', the first formant (formants
   are numbered from the bottom up) goes up. in the bottom row, the vowels
   raise from "bod" to "booed"   the f1 starts relatively high, and goes
   down indicating that the vowels start low and move toward high. the
   first formant correlates (inversely) to height (or directly to
   openness) of the vocal tract.

   now look at the next formant, f2. notice that the back, round vowels
   have a very low f2. notice that the vowel with the highest f2 is [i],
   which is the frontmost of the front vowels. f2 corresponds to backness
   and/or rounding, with fronter/unround vowels having higher f2s than
   backer/rounder vowels. it's actually much more complicated than that,
   but that will do for the beginner. if you're picky about facts or the
   math, take a class in acoustic id102.

   [17]3. the vowels
   figure 3. wide band spectrograms of the vowels of american english in a
   /b__d/ context. rollover icon
   top row, left to right: [i,   , e  ,   ,   ]. bottom row, left to right:
   [  ,   , o,   , u].

   there are a variety of studies showing various acoustic correlates of
   vowel quality, among them formant frequency, formant movement, and
   vowel duration. formant frequency (and movement) are probably the most
   important. so we can plot vowels in an f1xf2 vowel space, where f1
   corresponds (inversely) to height, and f2 corresponds (inversely) to
   backness and we'll end up with something like the standard
   'articulatory' vowel space.

   note that some of the vowels in figure 3 ([e  ] and [  ] especially) show
   more movement during the vowel (beyond just the transitions). whether
   that makes them diphthongs (or should be represented like diphthongs)
   i'll leave for somebody else to argue. but before we get too far, what
   would you imagine an [a  ] or [a  ] diphthong would look like?

   it's worth pointing out now that all the formants show consonant
   transitions at the edges. remember that the frequency of any given
   formant has to do with the size and shape of the vocal tract   as the
   vocal tract changes shape, so do the formants change frequency. so the
   way the formants move into and out of consonant closures and vowel
   'targets', is an important source of information about how the
   articulators are moving.

manner (and place) of articulation

   plosives (oral stops) involve a total occlusion of the vocal tract, and
   thus a 'complete' filter, i.e. no resonances being contributed by the
   vocal tract. the result a period of silence in the spectrogram, known
   as a 'gap'. a voiced plosive may have a low-frequency voicing bar of
   striations, usually thought of as the sound of voicing being
   transmitted through the flesh of the vocal tract. however, due to
   passive devoicing, it may not. and due to perseverative voicing even a
   'voiceless' plosive may show some vibration as the pressures equalize
   and before the vocal folds fully separate. but let's not get lost in
   too many details.

   generally we can think about the english plosives as occurring at three
   places of articulation   at the lips, behind the incisors, and at the
   velum (with some room to play around each). the bilabial plosives, [p]
   and [b] are articulated with the lower lip pressed against the upper
   lip. the coronal plosives [t,d] are made with the tongue blade pressing
   against the alveolar ridge (or thereabouts). [k] and [g] are described
   as 'dorsal' (meaning 'articulated with the tongue body') and 'velar'
   (meaning 'articulated against or toward the velum'), depending on your
   point of view. (i tend to use the 'dorsal' and 'velar' interchangeably,
   which is very bad. i use 'coronal' because it's more accurate than
   'alveolar', in the sense that everybody uses their tongue blade (if not
   the apex) for [t,d], but not everybody uses only their alveolar ridge.)

   that controversy aside, the thing to remember is that during a closure,
   there's no useful sound coming at you   there's basically silence. so
   while the gap tells you it's a plosive, the transitions into and out of
   the closure (i.e. in the surrounding vowels) are going to be the best
   source of information about place of articulation. [18]figure 4
   contains spectrograms of me saying 'bab' 'dad' and 'gag'.

   [19]4. place of articulation
   figure 4. spectrograms of "bab" "dad" and "gag". rollover icon .

   there's no voicing during the initial closure of any of these plosives,
   confirming what your teachers have always told you: "voiced" plosives
   in english aren't always fully voiced during closure. then suddenly,
   there's a burst of energy and the voicing begins, goes for a couple
   hundred milliseconds or so, followed by an abrupt loss of energy in the
   upper frequencies (above 400 hz or so), followed by another burst of
   energy, and some noise. the first burst of energy is the release of the
   initial plosive. notice the formants move or change following the
   burst, hold more or less steady during the middle of the vowel, and
   then move again into the following consonant. we know there's a closure
   because of the cessation of energy at most frequencies. the little blob
   of energy at the bottom is voicing, only transmitted through flesh
   rather than resonating in the vocal tract. look closely, and you'll see
   that it's striated, but very weak. the final burst is the release of
   the final plosive, and the last bit of noise is basically just residual
   stuff echoing around the vocal tract.

   take a look at those formant transitions out of and into each plosive.
   notice how the transitions in the f2 of 'bab' point down (i.e. the
   formant rises out of the plosive and falls into it again), where the f2
   of 'gag' points up? notice how in 'gag' the f2 and f3 start out and end
   close together? notice how the f3 of 'dad' points slightly up at the
   plosives? notice how the f1 always starts low, rises into the vowel,
   and then falls again.

   okay, these aren't necessarily the best examples, but basically,
   labials have downward pointing transitions (usually all visible
   formants, but especially f2 and f3), dorsals tend to have f2 and f3
   transitions that 'pinch' together (hence 'velar pinch'), and the the f3
   of coronals tends to point upward. the direction any transition points
   obviously is going to depend on the position of the formant for the
   vowel, so f2 of [t,d] might go up or down. a lot of people say coronal
   transitions point to about 1700 or 1800 hz, but that's going to depend
   a lot on speaker-individual factors. generally, i think of coronal f2
   transitions as pointing upward unless the f2 of the vowel is
   particularly high.

   another thing to notice is the burst energy. notice that the bursts for
   "dad" are darker (stronger) than the others. notice also that they get
   darker in the higher frequencies than the lower. the energy of the
   bursts in "gag" are concentrated in the f2/f3 region, and less in the
   higher frequencies. the burst of [b] is sort of broad   across all
   frequencies, but concentrated in the lower frequencies, if anywhere. so
   bursts and transitions also give you information about place.

   figure 4 also illustrates that in initial position, phonemic /b, d, g/
   tend to surface with no voicing during the closure, but a short voice
   onset time, i.e. as unaspirated [p, t, k]. in final position, they tend
   to surface as voiced, although there's room for variation here too.

fricatives

   frankly, fricatives are not my favorite. they're acoustically and
   aerodynamically complex, not to mention phonologically and phonetically
   volatile. there's not a lot you can say about them without getting way
   too complicated, but i'll try.

   fricatives, by definition, involve an occlusion or obstruction in the
   vocal tract great enough to produce noise (frication). frication noise
   is generated in two ways, either by blowing air against an object
   (obstacle frication) or moving air through a narrow channel into a
   relatively more open space (channel frication). in both cases,
   turbulence is created, but in the second case, it's turbulence caused
   by sudden 'freedom' to move sideways (keith johnson uses the terrific
   analogy of a road suddenly widening from two to four lanes, with a lot
   of sideways movement into the extra space), as opposed to air crashing
   around itself having bounced off an obstacle (keith's freeway analogy
   of a road narrowing from four lanes to two works here, but i don't
   really want to think about serious sibilance in this respect....)

   sibilant fricatives involve a jet of air directed against the teeth.
   while there is some (channel) turbulence, the greater proportion of
   actual noise is created by bouncing the jet of air against the upper
   teeth. the result is very high amplitude noise. non-sibilant fricatives
   are more likely 'pure' channel fricatives, particularly bilabial and
   labiodental fricatives, where there's not a lot of stuff in front to
   bounce the air off of.

   in [20]figure 5, there are spectrograms of the fricatives, extracted
   from a nonce word ("uffah", "ussah", etc.).

   [21]5. fricatives
   figure 5: top row, left to right: f, theta, s, esh. bottom row, left to
   right: v, eth, z, yogh. rollover icon

   let's start with the sibilants "s" and "sh", in the upper right of
   figure 5. they are by far the loudest fricatives. the darkest part of
   [s] noise is off the top of the spectrograms, even though these
   spectrograms have a greater frequency range than the others on this
   page. [s] is centered (darkest) above 8000 hz. the postalveolar "sh",
   on the other hand, while almost as dark, has most of its energy
   concentrated in the f3-f4 range. often, [s]s will have noise at all
   frequencies, where, as here, the noise for [  ] seems to drop off
   drastically below the peak (i.e. there's sometimes no noise below 1500
   or 2000 hz.) [z] and [  ] are distinguished from their voiceless
   counterparts by a) lesser amplitude of frication, b) shorter duration
   of frication and c) a voicing bar across the bottom. (remember,
   however, that a lot of underlyingly voiced fricatives in english have
   voiceless allophones. what other cues are there to underlying voicing?
   discuss.) take a good look at the voicing bar through the fricatives in
   the bottom row. you may never see a fully voiced fricative from me
   again.

   it's worth noting that f2 transitions are greater and higher with [  ]
   than with [s], and i seem to depress f4 slightly in [  ], but i don't
   know how consistent these markers are.

   labiodental and (inter)dental (nonsibilant) fricatives are notoriously
   difficult to distinguish, since they're made at about the same place in
   the vocal tract (i.e. the upper teeth), but with different active
   articulators. having established (in a mystery spectrogram) that a
   fricative isn't loud enough to be a sibilant, you can sometimes tell
   from transitions whether it is labiodental or interdental   labiodental
   will have labial-looking transitions, interdentals might have slightly
   more coronal looking transitions. but that's poor consolation   often
   underlying labiodental and interdental fricatives don't have a lot of
   noise in the spectrogram at all, looking more like approximants.
   sometimes, the lenite into approximants, or fortisize to stoppy-looking
   things. i hate fricatives.

   before moving on, we need to talk about [h]. [h] is always described as
   a glottal fricative, but since we know about channels and such, it's
   not clear where the noise actually comes from. aspiration noise, which
   is also [h]-like, is produced by moving a whole lot of air through a
   very open glottis. i heard a paper once where they described the
   spectrum of [h]-noise as 'epiglottal', implying that the air is being
   directed at the epiglottis as an obstacle. generally speaking, we don't
   think of the vocal cords moving together to form a 'channel' in [h],
   although breathy-voicing and voiced [h]s in english (as many
   intervocalic [h]s are produced) maybe be produced this way. so i don't
   know. what i do know about [h]s is that the noise is produced far
   enough back in the vocal tract that it excites all the forward
   cavities, so it's a lot like voicing in that respect. it's common to
   see 'formants' excited by noise rather than harmonics in spectrograms
   of [h]. certainly, the noise will be concentrated in the formant
   regions. compare the spectrograms in [22]figure 6.

   [23]6. [h]
   figure 6. spectrograms of "hee" "ha" and "who". rollover icon

   notice how different the frication looks in each spectrogram. in "hee",
   the noise is concentrated in f2, f3 and higher, with every little in
   the 1000 hz range. in "ha", in which f1 and f2 straddle 1000 hz, the
   [h] noise is right down there. in "who", there is a lot less amplitude
   to the noise between 2000 and 3000 hz, but there around f2 (around 1000
   hz) and lower, there's a great deal. you can even see f2 really clearly
   in the [h] of "who". so that's [h]. don't ask me. it's not very common
   in my spectrograms....

nasal stops

   nasals have some formant stucture, but are better identified by the
   relative 'zeroes' or areas of little or no spectral energy. in
   [24]figure 7, the final nasals have identifiable formants that are
   lesser in amplitude than in the vowel, and the regions between them are
   blank. nasality on vowels can result in broadening of the formant
   bandwidths (fuzzying the edges), and the introduction of zeroes in the
   vowel filter function. nasals can be tough, and i hope to get someone
   who knows more about them than i do to say something else useful about
   them. you can sometimes tell from the frequency of the nasal formant
   and zero what place of articulation was, but it's usually easier to
   watch the formant transitions. (this is particularly true of initial
   nasals; final nasals i usually don't worry about--if you can figure out
   the rest of the word, there's only three possible nasals it could end
   with.) (actually, being loose with the amount of information you
   actually have before you start trying to fit words to the spectrogram
   is one of the tricks to the whole operation.)

   [25]7. nasals
   figure 7. spectrograms of "dinner", "dimmer", "dinger". rollover icon

   the real trick to recognizing nasals stops is a) formant structure, but
   b) relatively lower-than-vowel amplitude. place of articulation can be
   determined by looking at the formant transitions (they are stops, after
   all), and sometimes, if you know the voice well, the formant/zero
   structure itself. comparing the spectrograms above, we can see that
   'dinger' (far right) has an f2/f3 'pinch'   the high f2 of [  ] moves up
   and seems to merge with the f3. in the nasal itself, the pole (nasal
   formant) is up in the neutral f3 region. 'dinner' (middle) has a pole
   about 1500 hz and a zero (a region of low amplitude) below it until you
   get down to about 500 hz again. the pole for [m] in 'dimmer' is lower,
   closer to 1000 hz, but there's still a zero between it and what we
   might call f1. note also that the transitions moving into the [m] of
   dinner are all sharply down-pointing, even in the higher formants, a
   very strong clue to labiality, if you're lucky enough to see it.

approximants

   in case you're not familiar with the term (generally attibuted to
   ladefoged's phonetic study of west african languages or as modified in
   catford's fundamental problems in id102), the approximants are
   non-vowel oral sonorants. in english, this amounts to /l, r, w, j/.
   they are characterized by formant structure (like vowels), but
   constrictions of about the degree of high vowels or slightly closer.
   generally there's no friction associated with them, but the underlying
   approximants can have fricative allophones, just as fricative phonemes
   can occasionally have frictionless (i.e. approximant) allophones.

   canonically, the english approximants are those consonants which have
   obvious vowel allophones. the classic examples are the [j-i] pair and
   the [w-u] pair. i have argued that [  ] is basically vowel-like in
   structure, i.e. that syllabic /r/ is the most basic allophone, but
   there are those who disagree. syllabic [l]s are all at least plausibly
   derived from underlying consonants, but i'm guessing that'll change in
   the next hundred years.

   [26]8. approximants
   figure 8. spectrograms of 'ball', 'bar', 'bough', 'buy'. rollover icon

   in [27]figure 8, the approximants are presented in coda/final position,
   where the formant transitions are easiest to discern. note that in all
   four words, the f1 is mid-to-high, indicating a more open constriction
   than with a typical high vowel. for /l/, the f2 is quite low,
   indicating a back tongue position   velarization of 'dark l' in english.
   the f3, on the other hand, is very high, higher than one ever sees
   unless the f2 is pushing it up out of the way. in "bar", the f3 comes
   way down, which is characteristics of [  ] in english. compare the
   position of the f3 in "bar" with that in "bough" and "buy", where the
   f3 is relatively unaffected by the constriction.

   in "bough", the f2 is very low, as the tongue position is relatively
   back and the lips are relatively rounded. note that the this has no
   effect on f3, so let it be known that lip rounding has minimum effect
   on f3. really. the next reviewer who brings up lip rounding without
   having some data to back it up is going to get it between the eyes.
   it's worth noting that the nuclear part of the diphthong is relatively
   front (as indicated by the f2 frequency in the first half of the
   diphthong) with the [a  ] than in [a  ]. in 'buy', the offglide has a
   clearly fronting (rising) f2.

common allophonic variation

   one of the absolutely characteristic features of american english is
   "flapping". this is when an underlying /t/ (and sometimes /d/), is
   repaced by something which sounds a lot like a tapped /r/ in languages
   with tapped /r/s. i refer the reader to susan banner-inouye's m.a. and
   ph.d. theses on the phonological and phonetic interpretations of
   flappy/tappy things in general. but the easiest thing to do is compare
   them. the spectrograms in [28]figure 9 are of me reading "a toe", "a
   doe" and "otto", with an aspirated /t/, voiced /d/ and a flap
   respectively.

   [29]9. plosives and a flap
   figure 9. spectrograms of "a toe", "a doe" and "otto". rollover icon

   note that for both proper plosives, there's a longish period of
   relative silence (with a voicing bar in the case of /d/), on the order
   a 100 ms. the actual length varies a lot, but notice how short the
   'closure' of the flapped case is in comparison. it's just a slight
   'interruption' of the normal flow, a momentary thing, not something
   that looks very forceful or controlled. it doesn't even really have any
   transitions of its own. the interruption is something on the order of
   three pulses long, between 10 and 30 ms. that's basically the biggest
   thing. sometimes they're longer, sometimes they're voiceless
   (occasionally even aspirated), but basically a flap will always be
   significantly shorter than a corresponding plosive.

   okay, so let's turn back to the proper plosives. notice the aspiration
   following the /t/, and the short vot following the /d/. note the
   dying-off voicing during the /d/ closure, presumably due to a build up
   of supralaryngeal pressure. (frankly, we're lucky to get any real
   voicing during the closure at all.)

   (other big allophonic categories i want to cover are nasalized vowels
   and rhoticized vowels, but i'm wondering how important they are at this
   level. remember that this is a primer, not the be-all and end-all work
   on spectrogram reading. also worth doing is some prosodic stuff, pitch
   and duration, amplitude and that kind of thing, as it relates to
   finding word and phrase boundaries in spectrogram reading. comments?)

is that it?

   well, obviously not. but it should be enough to get you started reading
   the monthly mystery spectrogram. we could go on and on about various
   things, but that's not the point right now. remember, identify the
   features you can, try to guess some words, hypothesize, and then see if
   you can use your hypotheses to fill in some of the features you're
   unsure about. do some lexical access, try some phrases, and see how
   well you do. reading spectrograms, like transcription, and so many
   other things can be taught in a short time, but takes a long time and
   experience to learn. but then that's why we're here, right?
     __________________________________________________________________

   robert hagiwara, ph.d.
   dept. of linguistics
   university of manitoba
   winnipeg, manitoba
   canada  r3t 5v5

           [30]current mystery - [31]solution - [32]past mysteries
                   [33]how to - [34]research - [35]courses
       [36]to the lab - [37]to the department - [38]to the university

                   support free speech

references

   1. http://blueteddyblog.blogspot.com/
   2. lynximgmap:https://home.cc.umanitoba.ca/~robh/howto.html#mapbase
   3. https://home.cc.umanitoba.ca/~robh/howto.html#intro
   4. https://home.cc.umanitoba.ca/~robh/howto.html#sftheory
   5. https://home.cc.umanitoba.ca/~robh/howto.html#formants
   6. https://home.cc.umanitoba.ca/~robh/howto.html#manner
   7. https://home.cc.umanitoba.ca/~robh/howto.html#frics
   8. https://home.cc.umanitoba.ca/~robh/howto.html#nasals
   9. https://home.cc.umanitoba.ca/~robh/howto.html#approxs
  10. https://home.cc.umanitoba.ca/~robh/howto.html#etc
  11. mailto:robh@cc.umanitoba.ca
  12. https://home.cc.umanitoba.ca/~robh/ipaulist.html
  13. https://home.cc.umanitoba.ca/~robh/howto.html
  14. https://home.cc.umanitoba.ca/~robh/howto.html#figsource
  15. https://home.cc.umanitoba.ca/~robh/howto.html
  16. https://home.cc.umanitoba.ca/~robh/howto.html#figvowels
  17. https://home.cc.umanitoba.ca/~robh/howto.html
  18. https://home.cc.umanitoba.ca/~robh/howto.html#figstops
  19. https://home.cc.umanitoba.ca/~robh/howto.html
  20. https://home.cc.umanitoba.ca/~robh/howto.html#figfrics
  21. https://home.cc.umanitoba.ca/~robh/howto.html
  22. https://home.cc.umanitoba.ca/~robh/howto.html#figh
  23. https://home.cc.umanitoba.ca/~robh/howto.html
  24. https://home.cc.umanitoba.ca/~robh/howto.html#fignasals
  25. https://home.cc.umanitoba.ca/~robh/howto.html
  26. https://home.cc.umanitoba.ca/~robh/howto.html
  27. https://home.cc.umanitoba.ca/~robh/howto.html#figapprox
  28. https://home.cc.umanitoba.ca/~robh/howto.html#figflap
  29. https://home.cc.umanitoba.ca/~robh/howto.html
  30. http://home.cc.umanitoba.ca/~robh/
  31. http://home.cc.umanitoba.ca/~robh/cursol.html
  32. http://home.cc.umanitoba.ca/~robh/archive.html
  33. http://home.cc.umanitoba.ca/~robh/howto.html
  34. http://home.cc.umanitoba.ca/~robh/research.html
  35. http://home.cc.umanitoba.ca/~robh/courses.html
  36. http://umanitoba.ca/faculties/arts/departments/linguistics/lab/
  37. http://umanitoba.ca/faculties/arts/departments/linguistics/
  38. http://umanitoba.ca/

[usemap]
https://home.cc.umanitoba.ca/~robh/howto.html#mapbase
   1. http://home.cc.umanitoba.ca/~robh/index.html
   2. http://home.cc.umanitoba.ca/~robh/cursol.html
   3. http://home.cc.umanitoba.ca/~robh/archive.html
   4. http://home.cc.umanitoba.ca/~robh/howto.html
   5. http://home.cc.umanitoba.ca/~robh/research.html
   6. http://home.cc.umanitoba.ca/~robh/courses.html
   7. http://umanitoba.ca/faculties/arts/departments/linguistics/lab/
   8. http://umanitoba.ca/faculties/arts/departments/linguistics/
   9. http://umanitoba.ca/
