   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

id3         part ii

   [16]go to the profile of zak jost
   [17]zak jost (button) blockedunblock (button) followfollowing
   nov 9, 2017

   in [18]part i of this series, the original gan paper was presented.
   although being clever and giving state of the art results at the time,
   much has been improved upon since. in this post i   ll talk about the
   contributions from the [19]deep convolutional-gan (dcgan) paper.

motivation

   part i concluded with an enumeration of some problems with gan. chief
   among them was training stability. dcgan makes significant
   contributions to this problem by giving specific network architecture
   recommendations.

   these recommendations are targeted toward the id161 domain,
   which has been one of the most successful application areas of deep
   learning. specifically, the use of convolutional layers.

dcgan

   let   s jump in to the architecture details. i   ll assume basic
   familiarity with convolutional layers. if you need this background,
   check out [20]this post. the recommended changes come directly from
   advances in the id161 literature.
    1. replace pooling layers with strided convolutions. historically,
       id98s used pooling layers to reduce dimensions. for instance, a 2x2
       max pooling layer would take a 2x2 array of pixels and map to one
       number, which is the max among them. a strided convolution can
       decrease the dimension by jumping multiple pixels between
       convolutions instead of sliding the kernel one-by-one. similarly,
       it can increase dimension by adding empty pixels between the real
       ones, called fractional-strided convolution. [21]this is a great
       resource for learning more about the details of strided
       convolutions, but the point is that this allows the network to
       learn it   s own spatial down- or up-sampling.
    2. remove fully connected layers and directly connect the output to
       the convolutional layers.
    3. batch id172. this re-scales the input at each layer to have
       a mean of zero and unit variance. it   s claimed this greatly helps
       the onset of model learning and helps avoid mode collapse. batch
       norm was not applied, however, to the generator output layer or the
       discriminator input layer (i.e. the image layers), as this led to
       instability.
    4. relu activation in the generator (except output layer which uses
       tanh), and leaky relu for discriminator. it   s claimed this helps
       learn to cover the color space more quickly.

   [1*qc_i7djqupchbrmecnpbyg.png]
   dcgan architecture for generator

   the generator is shown above, but the discriminator is essentially a
   mirror image. the 100-d noise input is fully connected the high level
   convolutional features. this layer then uses fractional-striding to
   double the size of the filters, but creates half the number. this
   process of doubling in size, halving the number is repeated until 128
   filters of size 32x32 are created. this is then upscaled to a 64x64
   image with 3 layers, representing the three color channels.

results

   here are some generated images of bedrooms after 5 epochs of training
   on the lsun bedrooms dataset. pretty cool.
   [1*2oulswlbvc1xn7iv9qa4tw.png]
   generated bedroom images

   to further demonstrate that the generator was learning meaningful, high
   level features, they did an experiment where they did    image
   arithmetic   .
   [1*u35fsj9ambqqnsyvvhdguq.png]

   here they have taken a man with glasses, subtracted out    man   -ness,
   added    female   -ness, and the results are a female with glasses. this
   suggests there are dedicated parts of the generator that control the
   presence of glasses and the gender. this was accomplished by doing
   these arithmetic operations on the generator noise input. so, you take
   the z-input vector for man with glasses, subtract the z-input vector
   for man with no glasses   etc. the resultant vector is then fed into the
   generator to come up with the desired image. multiple similar images
   were created by adding small, random changes to the input vector.

   a more systematic example of this was given by interpolating in the
   direction between faces that looked right and left. so you start with a
   vector representing right-looking faces and slowly move it in the
   direction of left-looking faces. this is the result:
   [1*oacm5mwjbaywfc5li1myww.png]

   this shows that by walking in the latent/noise-space z, you can have
   systematic control over features in the generated samples!

   finally, they also demonstrated the quality of the discriminator by
   removing the real/fake classifier and feeding the convolutional
   features into a new classifier         i.e. the discriminator was a feature
   extractor. if it   s true that useful, general features were learned,
   then it should be straight-forward to train a classifier by using these
   features. using cifar-10, which has 10 different image classes, it had
   competitive accuracy at 83%. interestingly, the dcgan was not trained
   on the cifar-10 dataset itself, but on id163-1k. this shows that the
   model learned general, useful features since it gave great performance
   on a totally different dataset.

problems

   one of the remaining problems is that the representation is entangled.
   this means the useful aspects of the input vector z are entangled with
   the raw noise. if one could separate the    latent code    from the noise,
   then generators would be more useful since you could control the output
   systematically and reliably without having to randomly walk the space.
   this problem and solution will be explored in part iii.

     * [22]machine learning
     * [23]deep learning
     * [24]data science
     * [25]neural networks

   (button)
   (button)
   (button) 253 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [26]go to the profile of zak jost

[27]zak jost

   research scientist at amazon aws. father. husband.

     (button) follow
   [28]towards data science

[29]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 253
     * (button)
     *
     *

   [30]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [31]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/6212f7755c1f
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/generative-adversarial-networks-part-ii-6212f7755c1f&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/generative-adversarial-networks-part-ii-6212f7755c1f&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_q3tumuoystvv---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@zjost85?source=post_header_lockup
  17. https://towardsdatascience.com/@zjost85
  18. https://medium.com/@zjost85/overview-of-gans-generative-adversarial-networks-part-i-ac78ec775e31
  19. https://arxiv.org/abs/1511.06434
  20. https://adeshpande3.github.io/a-beginner's-guide-to-understanding-convolutional-neural-networks-part-2/
  21. https://arxiv.org/abs/1603.07285
  22. https://towardsdatascience.com/tagged/machine-learning?source=post
  23. https://towardsdatascience.com/tagged/deep-learning?source=post
  24. https://towardsdatascience.com/tagged/data-science?source=post
  25. https://towardsdatascience.com/tagged/neural-networks?source=post
  26. https://towardsdatascience.com/@zjost85?source=footer_card
  27. https://towardsdatascience.com/@zjost85
  28. https://towardsdatascience.com/?source=footer_card
  29. https://towardsdatascience.com/?source=footer_card
  30. https://towardsdatascience.com/
  31. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  33. https://medium.com/p/6212f7755c1f/share/twitter
  34. https://medium.com/p/6212f7755c1f/share/facebook
  35. https://medium.com/p/6212f7755c1f/share/twitter
  36. https://medium.com/p/6212f7755c1f/share/facebook
