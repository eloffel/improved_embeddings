   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]archie.ai
   [7]archie.ai
   [8]sign in[9]get started
     __________________________________________________________________

a dozen times artificial intelligence startled the world

the best uses of generative models and how they work.

   [10]go to the profile of sumeet agrawal
   [11]sumeet agrawal (button) blockedunblock (button) followfollowing
   jul 31, 2017

   id3 (gans) are some of the most fascinating
   ways to    teach    computers to do human tasks.

   we   ve always heard that competition can boost performance, but now gans
   are taking    learning from competition    to an industrial scale.

   id3 are defined by ai entities (neural
   networks) that compete with each other to get better at their
   respective tasks.

   imagine a malware bot competing against a security bot, each
   relentlessly trying to execute its own objective (e.g. invade vs
   protect), and in this process, becoming better and better at its
   respective task.

   first coined by [12]ian goodfellow from the university of montreal,
   gans have recently shown us the power of    unsupervised learning    due to
   their widespread success.

so how do gans work?

   [1*yh3b1faro-bf6gu3kyzt4a.jpeg]
   [13]gans framework

   a gan has two competing neural network models. one of the network takes
   noise as input and generates samples (called the generator). the other
   network (the discriminator) receives samples from both the generator
   and the training data and is able to distinguish between the two
   sources.

   these two networks play a continuous game. in it, the generator learns
   to produce new samples to fool the discriminator who in turn gets
   better at distinguishing generated data from real data.

   these two networks are trained simultaneously, and after millions of
   rounds of    play    the generated samples become indistinguishable from
   the real data.

   in simple terms the generator is like a forger trying to produce some
   counterfeit material, and the discriminator is like the police trying
   to detect the forged items.

   since the entire process is automated and limited only by available
   computation power, gans can accomplish extraordinary feats.

   below are some of the coolest gan applications in action.

1. a look into a machine   s imagination.

   google   s deep dream creates psychedelic images.

   researchers at google brain have developed a way to visually represent
   what their neural network, googlenet,    thinks    of as the essence of
   objects.

   using this method, the gan produced some images that can be described
   as psychedelic in nature.

   these dream-like hallucinogenic images are the byproduct of
   deliberately over-processed images through an image classifying entity.
   the system involved in creating them has been dubbed    deep dream   .
   [1*a14-g2iapoprwrwx0yygyg.png]
   [14]deep dream generating psychedelic pictures from regular ones.
   [1*focnxryuhm4pm19g6bxkca.png]
   [15]example where the deep dream model exemplifies objects like towers,
   buildings and birds within the image.

   to make deep dream work, you give google deep dream an image, and it
   will start to look for    everything    it was trained to recognize. the
   neural network might find some resemblance of a dog, house, jellyfish,
   etc    in an image of something totally unrelated. like humans see
   objects in clouds. google deep dream then amplifies these found
   objects.

   for example, when you run the recognition network again, instead of
   saying    look, this is 40% certain that it   s a dog` it will modify the
   input image in such a way that the result will be    look, this is 60%
   certain it   s a dog   . this process is repeated till the input image is
   significantly transferred to look like a dog or any other object. as
   such, by gradually shifting from what it would classify as one image,
   to another, it creates otherworldly    in-between    images.

   google   s deep dream have reversed the conventional wisdom of giving the
   same input and generating an output to changing the input every time
   and to get an optimal output.

   sources & more info:

   [16]github, [17]blog

2. making a machine imitate humans

   imitating learning using gans

   a group of ai researchers wanted to come up with different approach to
   self-learn artificial agent as compared to the traditional reward based
   approach.

   they gave real demonstration data as an input to the agent, which the
   agent then learnt and tried to mimic the same actions.
   [1*s32s_ozvf7veffj-jkvjyw.gif]
   [18]a bot is trying to mimic running by imitating how an actual
   person runs.

   in this model, jonathan ho and stefano ermon presented a new approach
   for imitation learning. the standard id23 setting
   usually requires one to design a reward function that describes the
   desired behavior of the agent. however, in practice this can sometimes
   involve expensive trial-and-error processes to get the details right.
   instead, in imitation learning the agent learns from example
   demonstrations (for example provided by teleoperation in robotics or
   human actions), eliminating the need to design a reward function.

   sources & more info:

   [19]blog, [20]github

3. turning horses into zebras and winters into summers.

   image to image generation

   generating image from an image is an interesting application of
   generative networks. in an experiment, researchers were able to change
   the animal within a video (or the season within a picture, or other
   analogous tasks).

   the goal is to learn mapping between an input image and an output image
   using a training set of image pairs. however, in many situations,
   paired training data is not readily available. to overcome such an
   issue, two inverse mappings are used, and the outputs of each are made
   to be the same as the inputs of the other, thereby creating as full a
   relationship between the two images as possible with low amounts of
   data (unsupervised learning).

   some of the examples of this process are:
   [1*dwd0lvtbnu80uzm641gcbw.gif]
   [21]animal transfiguration         converting an image of horse to an image
   of zebra by detecting the moving horse in the video and superimposing
   zebra stripes on top of it.
   [1*ezbfyk7snyvynh4bbd7zyq.jpeg]
   [22]season transformation         changing season   s within the image such as
   from winter to summer or winter to spring and vice versa

   sources & more info:

   [23]page, [24]github

4. paintings drawn from sketches

   generating images from outlines

   realistic image manipulation is challenging because it requires
   modifying the image appearance in a user-controlled way, while
   preserving the realism of the result. this takes considerable skill,
   and an artist may have to train for years to do this on a consistent
   basis.

   iframe: [25]/media/b0086971cfd7a1ab2d326056793c37a0?postid=eae5005153db

   [26]gans able to generate realistic images from outlines.

   researchers created a model which when given an outline of an object,
   is able to identify the object as well as be able to generate a
   realistic image of that object.

   however in this[27] paper, the author proposes a method to learn the
   natural image manifold directly from data using a generative
   adversarial neural network. the model automatically adjusts the output
   keeping all edits as realistic as possible as well as all the
   manipulations are expressed in terms of constrained optimization and
   are applied in near-real time. the presented method can further be used
   for changing one image to look like the other, as well as generating
   novel imagery from scratch based on users    scribbles.

   sources & more info:

   [28]paper, [29]github, [30]page

5. images created from only text description.

   generative adversarial text to image synthesis

   automatic synthesis of realistic images from text is interesting and
   useful. recently, deep convolutional id3
   (dcgans) have begun to generate highly compelling images of specific
   categories, such as faces, album covers, and room interiors.

   the model is fed with sample data consisting of text with their
   corresponding images, and when a description of any object is provided,
   the model will try to generate an image out of the description.
   [1*jilusvgm0lpsvqixot757w.jpeg]
   [31]model has the capability to generate plausible images of birds and
   flowers from detailed text descriptions

   in this work, the text to image synthesis is obtained by first,
   learning the text features that captures the important visual details
   and secondly, use these features to synthesize a realistic image that
   can fool a human.

   sources & more info:

   [32]paper, [33]github

6. making computers learn through    curiosity   

   curiosity driven exploration of deep neural network

   in many real-world scenarios, external rewards to an [34]artificial
   agent are extremely sparse or absent altogether. as such, a passive
   program doesn   t get to evolve and learn because of this intrinsic
   nature.

   in such cases,    curiosity    can serve as a built-in reward signal to
   enable the agent to explore its environment and learn skills that might
   be useful later in its life         in these cases active learners do much
   better than passive ones.

   in such a model,    curiosity    is formulated as the error in an ai   s
   ability to predict the consequence of its own actions. the bot in such
   a world, can, of course, also learn through a reward system built by
   the programmer.

   think of this as being analogous to a small child. a small child
   without supervision has no knowledge of what will happen if he touches
   a hot stove, but once he has done so , he learns to not do so due to
   the pain and newfound knowledge of the causal relationship between
   touching the stove and feeling the said pain. curiosity drove him to
   explore, and the reward system labeled actions as good or bad.
   [1*aiki3wjsl_ruw9wa5xltqa.gif]
   [35]a game of retro snakes where the snake is learning to collect the
   green balls which increases its reward and learning to avoid red balls
   which decreases its reward through curiosity driven learning.

   curiosity driven learning is based on the following:

   1) sparse external reward, where curiosity allows for far fewer
   interactions with the environment to reach the goal

   2) exploration with no external reward, where curiosity pushes the
   agent to explore more efficiently

   3) generalization to unseen scenarios (e.g. new levels of the same
   game) where the knowledge gained from earlier experience helps the
   agent explore new places much faster than starting from scratch.

   this proposed approach can also be evaluated in the two game
   environments:[36] vizdoom and[37] super mario bros.

   sources & more info:

   [38]github, [39]paper, [40]website

7. ai designing games

   game ui design using gans

   the idea is that if we can generate convincing screenshots of imaginary
   video games, we could copy and paste bits of art from those screenshots
   and use it in our own.
   [1*adjcgrvsbkbhmdiihum1zw.png]
   [1*cf-ynh2up5ojlgyrahad8w.gif]
   [1*zz1wtfbkibz8oowpcuwvtw.png]
   [41]left         game background images given as input. middle         background
   images are generated as gans gets better and better. right         unique
   game tile sheets that can be used for new game creation

   the goal is to create a similar tile sheet for the game. to do that,
   program will gather a bunch of images from various games that already
   exists. after that, the program will generate new unique images that is
   made up of these bits of images. these images can then be used as a
   background for game creation!

   sources & more info:

   [42]blog

8. predicting what happens next in a video.

   generating videos with scene dynamics

   understanding object motion and scene dynamics are core problems in
   id161. for both video recognition tasks (e.g., action
   classification) and video generation tasks (e.g., future prediction), a
   model of how scenes transform is needed. however, creating a model of
   dynamics is challenging because there are vast number of ways that
   objects and scenes can change.

   iframe: [43]/media/1854e51bb227d103db51938164aa45ee?postid=eae5005153db

   [44]creating short future videos of train station, beach, babies and
   golf

   this is achieved using a model that is able to separate foreground from
   the background, which enforces that the background is stationary and
   the network learns which objects are moving and which are not.

   these videos are not real but they are    imagined    by a generative video
   model. while they are not photo-realistic, the motions are reasonable
   for the scene category they are trained on.

   sources & more info:

   [45]paper, [46]github, [47]page

9. generating realistic yet fake faces

   neural faces

      neural face    is an artificial intelligence which generates face images
   which are not real.

   neural face uses dcgans developed by facebook ai research team.
   [1*d5qjrfkeirogpsuydjkxla.gif]
   [48]unique human faces generated by gans

   the ai team, represented each image by a vector z that consists of 100
   real numbers ranging from 0 to 1.

   the generator then generates an image from the z vector using a
   [49]gaussian distribution by figuring out the distribution of human
   images. the generator learns to produce new face images to fool the
   discriminator who in turn gets better at distinguishing generated face
   images from real faces images.

   sources & more info:

   [50]github, [51]page

10. changing facial expressions & features in photos:

   vector arithmetic on faces using gans

   in an experiment, researchers were able to generate images of people
   with various facial expressions just by providing a system with sample
   images. for example, it could change a non-smiling face to a smiling
   face, add an object over the face, or accentuate certain features.
   [1*ufn3nwqkbpblvmbnmzwhcg.png]
   [52]using arithmetic manipulation we can convert a non smiling person   s
   image to a smiling image or can add glasses to an image without glasses

   the basic approach is: for each column of images represented as a
   vector(x), average each x to generate mean vectors y.

   arithmetic operations such as addition and subtraction are then
   performed on y vectors to create a single image, vector z (man with
   glasses - man without glasses + woman without glasses). the image
   vector z is then fed into the generator to produce the result as shown
   on the right-hand side of the image (smiling man or woman with
   glasses).
   [1*i965nrrezvfbpx6jecdd4a.png]
   [53]changing a left faced image to a right faced image.

   we can also convincingly model attributes such as rotation, scale, and
   position. to do so, we start by taking image samples of faces looking
   left and faces looking right. we then average them to create a turn
   image vector. then, by adding [54]interpolations along the axis to the
   image vector, we are able to apply this    transformation    to new faces.

   sources & more info:

   [55]github, [56]paper, [57]blog

   significance of gans for the future of ai and ml

conclusion:

   these are still early days for gans. the above examples, as impressive
   as they might be, still only scratch the surface of what is actually
   possible with this framework. for us engineers, it gives us a powerful
   way to train neural nets to accomplish any complex human task. gans
   prove that creativity is no longer a trait exclusive to humans.
     __________________________________________________________________

   additional resources on gans

   if you want to learn more in depth about generative models and dcgan,
   here are some more resources:

   1. [58]id3 in 50 lines of code by dev nag

   2. ian goodfellow   s[59] keynote on gans (more of a technical video)

   3. siraj raval   s [60]video tutorial on gans (short fun video)
   [1*5kxowas8gff4jxgims8gua.jpeg]

note:

   if you would like to know more about my work with ai/ml, check out
   [61]archie.ai

     * [62]artificial intelligence
     * [63]ai
     * [64]machine learning
     * [65]neural networks
     * [66]generative model

   (button)
   (button)
   (button) 692 claps
   (button) (button) (button) 5 (button) (button)

     (button) blockedunblock (button) followfollowing
   [67]go to the profile of sumeet agrawal

[68]sumeet agrawal

     (button) follow
   [69]archie.ai

[70]archie.ai

   ml & tech articles from the team behind archie.ai

     * (button)
       (button) 692
     * (button)
     *
     *

   [71]archie.ai
   never miss a story from archie.ai, when you sign up for medium.
   [72]learn more
   never miss a story from archie.ai
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/eae5005153db
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/archieai?source=avatar-lo_eb6pheux1kmp-4e8922a89498
   7. https://medium.com/archieai?source=logo-lo_eb6pheux1kmp---4e8922a89498
   8. https://medium.com/m/signin?redirect=https://medium.com/archieai/a-dozen-times-artificial-intelligence-startled-the-world-eae5005153db?imm_mid=0f5a8c&cmp=em-data-na-na-newsltr_ai_20170828&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/archieai/a-dozen-times-artificial-intelligence-startled-the-world-eae5005153db?imm_mid=0f5a8c&cmp=em-data-na-na-newsltr_ai_20170828&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@sumeetagrawal?source=post_header_lockup
  11. https://medium.com/@sumeetagrawal
  12. https://www.quora.com/in-what-way-are-adversarial-networks-related-or-different-to-adversarial-training/answer/ian-goodfellow
  13. https://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-generative-models-and-adversarial-training-upc-2016
  14. http://www3.cs.stonybrook.edu/~cse352/g15dream.pdf
  15. http://www3.cs.stonybrook.edu/~cse352/g15dream.pdf
  16. https://github.com/google/deepdream
  17. https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
  18. https://blog.openai.com/generative-models/
  19. https://blog.openai.com/generative-models/
  20. https://github.com/openai/imitation
  21. https://github.com/junyanz/pytorch-cyclegan-and-pix2pix
  22. https://github.com/junyanz/pytorch-cyclegan-and-pix2pix
  23. https://junyanz.github.io/cyclegan/
  24. https://github.com/junyanz/pytorch-cyclegan-and-pix2pix
  25. https://medium.com/media/b0086971cfd7a1ab2d326056793c37a0?postid=eae5005153db
  26. https://www.youtube.com/watch?v=9c4z6ysbgq0&feature=youtu.be
  27. https://arxiv.org/pdf/1609.03552v2.pdf
  28. https://arxiv.org/pdf/1609.03552v2.pdf
  29. https://github.com/junyanz/igan
  30. https://people.eecs.berkeley.edu/~junyanz/projects/gvm/
  31. https://github.com/reedscot/icml2016
  32. https://arxiv.org/pdf/1605.05396.pdf
  33. https://github.com/paarthneekhara/text-to-image
  34. https://en.wikipedia.org/wiki/intelligent_agent
  35. https://blog.openai.com/generative-models/
  36. http://vizdoom.cs.put.edu.pl/#scenarios
  37. https://en.wikipedia.org/wiki/super_mario_bros.
  38. https://github.com/pathak22/noreward-rl
  39. https://pathak22.github.io/noreward-rl/resources/icml17.pdf
  40. https://pathak22.github.io/noreward-rl/index.html#demovideo
  41. https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7
  42. https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7
  43. https://medium.com/media/1854e51bb227d103db51938164aa45ee?postid=eae5005153db
  44. https://github.com/cvondrick/videogan
  45. http://carlvondrick.com/tinyvideo/paper.pdf
  46. https://github.com/cvondrick/videogan
  47. http://carlvondrick.com/tinyvideo/
  48. https://github.com/carpedm20/dcgan-tensorflow
  49. https://en.wikipedia.org/wiki/gaussian_function
  50. https://github.com/carpedm20/dcgan-tensorflow
  51. http://carpedm20.github.io/faces/
  52. https://github.com/newmu/dcgan_code
  53. https://github.com/newmu/dcgan_code
  54. https://en.wikipedia.org/wiki/interpolation
  55. https://github.com/newmu/dcgan_code
  56. https://arxiv.org/pdf/1511.06434.pdf
  57. https://hackernoon.com/how-do-gans-intuitively-work-2dda07f247a1
  58. https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f
  59. https://channel9.msdn.com/events/neural-information-processing-systems-conference/neural-information-processing-systems-conference-nips-2016/generative-adversarial-networks
  60. https://www.youtube.com/watch?v=deyox6mt_as
  61. https://www.archie.ai/
  62. https://medium.com/tag/artificial-intelligence?source=post
  63. https://medium.com/tag/ai?source=post
  64. https://medium.com/tag/machine-learning?source=post
  65. https://medium.com/tag/neural-networks?source=post
  66. https://medium.com/tag/generative-model?source=post
  67. https://medium.com/@sumeetagrawal?source=footer_card
  68. https://medium.com/@sumeetagrawal
  69. https://medium.com/archieai?source=footer_card
  70. https://medium.com/archieai?source=footer_card
  71. https://medium.com/archieai
  72. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  74. https://medium.com/p/eae5005153db/share/twitter
  75. https://medium.com/p/eae5005153db/share/facebook
  76. https://medium.com/p/eae5005153db/share/twitter
  77. https://medium.com/p/eae5005153db/share/facebook
