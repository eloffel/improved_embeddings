tutorial on id108 

 

tutorial on id108 

igor baskin, gilles marcou and alexandre varnek 

facult   de chimie de strasbourg 

laboratoire d   infochimie 

4, rue blaise pascal, 67000 strasbourg, france 

 

tutorial on id108 ........................................................................................................... 1 

introduction ......................................................................................................................................... 2 

part 1. classification models. .............................................................................................................. 3 

1.  data and descriptors. ............................................................................................................... 3 

2.  files ......................................................................................................................................... 3 

3.  exercise 1: instability of interpretable rules ............................................................................ 3 

4.  exercise 2: id112 and boosting .......................................................................................... 5 

5.  exercise 3: id79..................................................................................................... 10 

6.  exercise 4: combining descriptor pools ................................................................................ 13 

part 2. regression models ................................................................................................................. 15 

1.  data and descriptors ............................................................................................................. 15 

2.  files ....................................................................................................................................... 15 

3.  exercise 5: individual mlr model ....................................................................................... 15 

4.  exercise 6: id112 of mlr models .................................................................................... 19 

5.  exercise 7: applying the random subspace method .............................................................. 22 

6.  exercise 8: additive regression based on slr models ......................................................... 26 

7.  exercise 9: stacking of models ............................................................................................. 29 

literature ........................................................................................................................................... 35 

appendix .............................................................................................................................................. 36 

1.  notes for windows .................................................................................................................... 36 

2.  notes for linux ......................................................................................................................... 36 

1 

 

tutorial on id108 

 

introduction 

this  tutorial  demonstrates  performance  of  ensemble  learning  methods  applied  to 
classification  and  regression  problems.  generally,  preparation  of  one  individual  model 
implies  (i)  a  dataset,  (ii)  initial  pool  of  descriptors,  and,  (iii)  a  machine-learning  approach. 
variation  of  any  of  these  items  can  be  used  to  generate  an  ensemble  of  models.  here,  we 
consider  the  following  ensemble  learning  approaches:  id112  and  boosting  (dataset 
variation),  random  subspace  (descriptors  variation)  and  stacking  (machine-learning  methods 
variation).  in  some  of  popular  approaches,  both  dataset  and  descriptors  vary  (e.g.,  random 
forest).  

in  all  calculations,  the  isida  descriptors  were  used.  they  represent  the  counts 
(occurrences)  of  some  fragments  in  a  molecular  graph.  three  types  of  fragments  are 
considered: sequences (type 1), unlimited augmented atoms (type 2) and restricted augmented 
atoms (type 3). a sequence is the shortest path connected two given atoms. for each type of 
sequence,  the  lower  (l)  and  upper  (u)  limits  for  the  number  of  constituent  atoms  must  be 
defined.  the  program  generates        intermediate        sequences  involving  n  atoms  (l=<n<=u) 
recording both atoms and bonds. unlimited augmented atom represents a selected atom with 
its  closest  environment.  restricted  augmented  atom  is  a  combination  of  types  1  and  2:  an 
atom  representing  an  origin  of  several  sequences  containing  from  l  to  u  atoms.  three  sub-
types, ab, a and b are defined for each class. they represent sequences of atoms and bonds 
(ab), of atoms only (a), or of bonds only (b).  

thus,  each  fragmentation  is  coded  by  the  pattern  txyylluu.  here,  x  is  an  integer 
describing  the  type  of  the  fragmentation  (1:  sequences;  2:  unlimited  augmented  atoms;  3: 
restricted augmented atoms), yy specifies the fragments content (aa: atoms only; ab: atoms 
and  bond;  bb:  bonds  only),  l  and  u  are  the  minimum  and  maximum  number  of  constituent 
atoms.  

the following id108 procedures are considered in the tutorial: 

  id112     combination of id64 and averaging used to decrease the variance 

part of prediction errors [2] 

  adaboost       the  most  well-known  boosting  algorithm  used  to  solve  classification 

problems [3] 

  random  subspace  method       combination  of  random  subsets  of  descriptors  and 

averaging of predictions [4] 

  id79     a method based on id112 (bootstrap aggregation, see definition of 
id112) models built using the random tree method, in which classification trees are 
grown on a random subset of descriptors [5]. 

2 

 

tutorial on id108 

 

  additive regression     a form of regression gradient boosting: it enhances performance 

of basic regression methods [6] 

  stacking - combines several machine learning methods using the stacking method [7, 

8]. 

the following individual machine learning methods (base learners [9]) are used: 

  jrip is  the weka implementation of the algorithm ripperk [10]. this  algorithm  uses 
incremental  reduced-error pruning in  order to  obtain a set  of classification rules;  k is 
the number of optimization cycles of rules sets. 

  multiple  linear  regression  (mlr)       classical  multiple  linear  regression  without 
descriptor selection, in  which for the sake of numeric stability the diagonal  elements 
of the variance-covariance matrix xtx are modified by adding a small 1.0e-8 number 
(actually a form of the ridge regression). 

  simple id75 (slr)     classical id75 on a single descriptor. 

  partial least squares (pls) 

  m5p     a kind of regression trees [11] 

 

part 1. classification models. 

1.  data and descriptors. 

the  dataset  for  this  tutorial  contains  27  ligands  of  acetylcholinesterase  (ache)  and  1000 
decoy compounds chosen from the bioinfo database [1]. this dataset is split into the training 
set  (15  actives  and  499  inactives)  and  the  test  set  (12  actives  and  501  inactives).  the 
t3abl2u3 fragments are used as descriptors.  

2.  files 

the following files are supplied for the tutorial: 

  train-ache.sdf/test-ache.sdf     molecular files for training/test set 

  train-ache-t3abl2u3.arff/test-ache-t3abl2u3.arff       descriptor 

and property values for the training/test set 

  ache-t3abl2u3.hdr     descriptors' identifiers 

3.  exercise 1: instability of interpretable rules 

3 

 

tutorial on id108 

 

in this exercise, we build individual models consisting of a set of interpretable rules. the goal 
is to demonstrate that the selected rules depend on any modification of the training data, e.g., 
the order of the data in the input file.  
 

step by step instructions 

important  note  for  windows  users:  during  installation,  the  arff  files  should  have  been  associated 
with  weka.  in  this  case,  it  is  highly  recommended  to  locate  and  double  click  on  the  file  train-
ache-t3abl2u3.arff and to skip the following three points. 

 

 

in the starting interface of weka, click on the button explorer. 

in  the  preprocess  tab,  click  on  the  button  open  file.  in  the  file  selection  interface, 
select the file train-ache-t3abl2u3.arff. 

the dataset is characterized in the current relation frame: the name, the number of instances, 
and the number of attributes (descriptors). the attributes frame allows user to modify the set 
of attributes using select and remove options. information about the selected attribute is given 
in the selected attribute frame in which a histogram depicts the attribute distribution. 

  click on the tab classify. 

 

 

into the test options frame, select supplied test set and click set....  

in  the  pop-up  window,  click  the  open  file...  button  and  select  the  test-ache-
t3abl2u3.arff file. then click close. 

  click  more  options...  then  in  the  pop-up  window  click  the  choose  button  near  output 

predictions and select csv. 

 

in the classifier frame, click chose, then select the jrip method. 

  click start to learn the model and apply this to the test set. right click on the last line 
of the result list frame and select save result buffer in the pop-up menu. name the file 
as jrip1.out. 

  use  isida/model  analyzer  to  visualize  both  confusion  matrix  and  structures  of  the 
compounds corresponding to different blocks of this matrix. here, on the           button 
and select the jrip1.out file and the test-ache.sdf file, then click to start.  

in the weka classifier output frame, check the model opened in isida/model analyzer. 
attributes  used  by  the  rules  are  given  the  ache-t3abl2u3.hdr  file  which  can  be 
opened with any text editor (wordpad preferred).  

in weka, return to the pre-process tab. 

4 

 

 

 

tutorial on id108 

  click  choose  and,  select  randomize  in  the  filters->unsupervised->instance  folder.  click 

apply. 

  return  to  classify  and  click  start. right  click  on  the  last  line  of  the  result  list  frame 
opens  the  pop-up  menu,  in  which  select  save  result  buffer.  name  the  file  as 
jrip2.out. 

  use  the  file  ache-t3abl2u3.hdr  and  isida/model  analyzer  to  analyze  the  rules. 

they are indeed rather different. 

 

 

conclusion.  one  can  conclude  that  the  data  reordering  is  sufficient  to  modify  the 
interpretable rules model.  

 

4.  exercise 2: id112 and boosting 

in  this  exercise,  we   ll  demonstrate  that  the  id112  approach  (i)  overcomes  the  instability 
problem  discovered  in  exercise  1,  and,  (ii)  allows  one  to  order  the  rules  according  to  their 
pertinence.  

  

step by step instructions 

id112 

step 1: preparation of one individual model. 

  click on the pre-process tab and then on the undo button. this restores the initial order 
of  the  compounds.  (this  is  an  alternative  of  reopening  the  input  file  train-ache-
t3abl2u3.arff). 

  click classify, then choose. 

  select classifiers->meta->id112. 

  click on the name of the method to the right of the choose button. in the configuration 
interface,  click  choose  then  select  classifiers->rules->jrip.  set  the  numiterations  to  1 
and click ok. 

this operation has created one individual model.  

  right-click on the line last line of the result list and select visualize threshold curve and 

then 1. 

 

5 

tutorial on id108 

 

the  roc  curve  is  plotted.  as  one  can  see,  the  roc  auc  value  (about  0.7)  is  rather  poor 
which means that a large portion of active compounds cannot be retrieved using only one rule 
set. 

  save  the  model  output.  right-click  on  the  last  line  of  the  result  list  and  select  save 

result buffer. name your file as jripbag1.out. 

 

step 2: preparation of ensemble of models. 

  produce  new  id112  models  using  3  and  8  models  by  repeating  the  previous  steps, 
setting  numiterations  to  3,  then  to  8.  save  the  corresponding  outputs  in  files 
jripbag3.out and jripbag8.out, respectively.  

one can see that roc auc for the consensus model increases up to 0.825 (see figure 1). 

figure 1. roc auc of the consensus 
model  as  a  function  the  number  of 
id112 iterations 

 

 

 

6 

tutorial on id108 

 

 
step  3  (optionally):  analysis  of  the  models:  retrieval  rate  as  a  function  of  the  confidence 
threshold. 

  use isida/model analyzer to open jripbag3.out and the test-ache.sdf file. 

  navigate through the false negative examples. 

the false negative examples are ordered according to the degree of consensus in the ensemble 
model. a few false negatives could be retrieved by changing the confidence threshold. on the 
other hand, this leads to the increase of the number of false positives.  

  repeat the analysis using the jripbag8.out file. 

as reflected by the better roc auc, it is now possible to retrieve maybe one false negative, 
but  at  a  lower  cost  in  terms  of  additional  false  positives.  the  confidence  of  prediction  has 
increased. in some sense, the model has become more discriminative. 

step 4 (optionally): analysis of the models: selecting of common rules. 

the goal is to select the rules which occur in, at least, two individual models. 

  open  the  jripbag3.out  in  an  editor  and  concatenate  all  the  rules  from  all  the 

models, then count how many of them are repeated. it should be one or two.  

  do the same for the file jripbag8.out. this time, it should be around ten. 

a  systematic  study  show  how  the     unique     rules  rate  in  the  ensemble  decreases  with  the 
number  of  id112  iterations  (figure  2).  each  id112  iteration  can  be  considered  as  a 
sampling of some rule distribution. the final set  of rules repeats more often those rules that 
are  most  probable.  when  the  sampling  is  sufficiently  representative,  the  ensemble  model 
converges toward a certain rules distribution. 

 

7 

tutorial on id108 

figure 2. rate of unique rules as a 
function of the number of id112 
iterations 

 

 

 

 

boosting 

another approach to leverage predictive accuracy of classifiers is boosting. 

  using weka, click on the classify tab.  

  click choose and select the method classifiers->meta->adaboostm1.  

  click adaboostm1 in the box to the right of the button. the configuration interface of 

the method appears. 

  click choose of this interface and select the method classifiers->meta->jrip.  

  set the numiterations to 1.  

  click on the button ok. 

  when  the  method  is  setup  click  start  to  build  an  ensemble  model  containing  one 

model only. 

  right-click  on  the  last  line  of  result  list  and  save  the  output  by  choosing  save  result 

buffer. name your file jripboost1.out. 

  repeat the experiment by setting the parameter  numiterations to 3 and to 8. save the 

outputs as jripboost3.out and jripboost8.out respectively. 

notice that the roc auc increases more and faster than that with id112. 

 

8 

tutorial on id108 

 

 

is  particularly 

it 
jripboost2.out and jripboost3.out with isida/model analyzer. 

interesting 

examine 

the 

to 

files  jripboost1.out, 

  open  the  files  jripboost1.out,  jripboost2.out  and  jripboost3.out  with 

isida/model analyzer. 

  compare  the  confidence  of  predictions  for  the  false  negative  examples  and  the  true 

negatives. 

using one model in the ensemble, it is impossible to recover any of the false negatives. notice 
that with three models, the confidence of predictions has slightly decreased but the roc auc 
has  increased.  it  is  possible  to  recover  almost  all  of  the  false  negatives,  still  discriminating 
most of the negative examples. as the number of boosting iterations increases, it generates a 
decision  surface  with  greater  margin.  new  examples  are  classified  with  greater  confidence 
and accuracy. on the other hand, the instances for which the id203 of error of individual 
models  is  high,  are  wrongly  classified  with  greater  confidence.  this  is  why,  with  8  models, 
some false negative cannot be retrieved. 

a systematic study of the roc auc illustrates this effect (figure 3). 

figure 3. roc auc as a function 
of the number of boosting 
iterations 

 

 

4.2. 

conclusion 

id112 and boosting are two methods transforming    weak    individual models in a    strong    
ensemble of models. in fact jrip is not a    weak    classifier. this somehow damps the effect of 
id108. 

generating  alternative  models  and  combining  them  can  be  achieved  in  different  ways.  it  is 
possible, for instance to select random subsets of descriptors.  

9 

 

tutorial on id108 

 

 

5.  exercise 3: id79 

goal:  to  demonstrate  the  ability  of  the  random  forest  method  to  produce  strong  predictive 
models. 

 

method.  the  random  forest  method  is  based  on  id112  (bootstrap  aggregation,  see 
definition  of  id112)  models  built  using  the  random  tree  method,  in  which  classification 
trees  are  grown  on  a  random  subset  of  descriptors  [5].  the  random  tree  method  can  be 
viewed as an implementation of the random  subspace method for the case of classification 
trees.  combining  two  ensemble  learning  approaches,  id112  and  random  space  method, 
makes  the  random  forest  method  very  effective  approach  to  build  highly  predictive 
classification models. 

 

computational procedure 

step 1: setting the parameters 

  click on the classify tab of weka. 

  make sure that the test set is supplied and that output predictions will be displayed in 

csv format. 

  click choose and select the method classifiers->tree->randomforest. 

  click on the word randomforest to the right of the button. a configuration interface 

appears. 

 

 

10 

tutorial on id108 

 

 

step 2: building a model based on a single random tree. 

  set the numtrees to 1, then click the button ok. 

  click start. 

this  setup  creates  a  id112  of  one  random  tree.  the  random  tree  is  grown  as  much  as 
possible  and  11  attributes  are  selected  at  random  to  grow  it.  results  should  be  rather  good 
already. 

 

 

 

  right click on the last line of the result list frame. 

  select save result buffer. save the output as rf1.out. 

step 3: building models based on several random trees. 

 

  build the id79 models based on 10 random trees. see below 

 

 

 

 

 

 

 

11 

tutorial on id108 

 

all statistical characteristics became considerably stronger 

  save the output as rf10.out 

  repeat the study for 100 trees. save result as rf100.out. 

 

  build id79 models for different numbers of trees, varying from 1 to 100. 

  build the plot roc auc vs. number of trees 

figure 4. roc auc as a function of 
the number of trees 

 

 

one  may  conclude  that  random  forest  outperforms  the  previous  id112  and  boosting 
methods. first,  a single fully  grown  and unpruned random  tree seems  as least  as useful  as a 
more  interpretable  small  set  of  rules.  second,  the  ensemble  model  is  saturated  later,  using 
more individual models; on another hand the maximal roc auc achieved is extremely high. 

 

  step 4. examine the file rf1.out, rf10.out and rf100.out using isida/model 

analyzer. 

this single tree forest does not provide any confidence value for the prediction. it is therefore 
impossible to modulate the decision of the model. when using 10 trees, most false negative 
can be retrieved accepting roughly one false positive for each of them. at last, using 100 trees 
in  the model, all the same false negatives can be retrieved at  the  cost  of accepting only one 

12 

 

tutorial on id108 

 

false positive. the last active compound can be retrieved only at the cost of accepting around 
40 false positives. 

 

6.  exercise 4: combining descriptor pools 

isida/model analyzer can be used also to combine different models. the file allid166.txt 
sum up the results of applying different id166 models, trained separately on different pools of 
descriptors.  the  file  contains  a  header  linking  it  to  a  sdf  file,  giving  indications  about  the 
number  of  classes  and  the  number  of  predictions  for  each  compound  and  weights  of  each 
individual model. these weights can be used to include or exclude individual models from the 
consensus:  a  model  is  included  if  its  corresponding  value  is  larger  than  0  and  not  included 
otherwise. next lines correspond to prediction results for each compound.  

in  each  line,  the  first  number  is  the  number  of  the  compound  in  the  sdf  file,  the  second 
number is an experimental class and the next columns are the individual predictions of each 
model.  optionally,  each  prediction  can  be  assigned  to  a  weight,  which  is  represented  by 
additional real numbers on each line. 

  open the allid166.txt file with isida/model analyzer. 

several models are accessible. it is possible to navigate among them using the buttons next 
and prev. it is also possible to use the list box between the buttons to select directly a model. 
the tick near the name of the model indicates that it will be included into the ensemble of 
models. it is possible to remove the tick in order to exclude the corresponding model. as can 
be seen, the overall balanced accuracy is above 0.8 with some individual models performing 
better than 0.9. 

  click  on  the  button  vote.  a  majority  vote  takes  place.  a  message  indicates  that  the 

results are saved in a file vote.txt. the proportion of vote is saved as well. 

  load  the  file  vote.txt  in  isida/model  analyzer  and  click  the  button  start.  the 

ensemble model seems to have a suboptimal balanced accuracy. 

  click on the headers of the columns of the confusion matrix to make appear column 

related statistics. recall, precision, f-measure and matthew's correlation coefficient 
(mcc) are computed for the selected class. the roc auc is computed and data are 
generated to plot the roc with any tool able to read csv format. 

as can be seen, accepting only 20 false positives, all active compounds are retrieved. it is 
possible to plot the roc as in the following figure (figure 4): 

 

13 

tutorial on id108 

figure 5. roc curve for exercise 4 

 

14 

 

 

tutorial on id108 

 

 

part 2. regression models 

 

in this part of tutorial, the explorer mode of the weka program is used. the tutorial includes 
the following steps: 

(1) building an individual mlr model,  

(2) performing id112 of mlr models,  

(3) applying the random subspace method to mlr models,  

(4) performing additive regression based on slr models, 

(5) performing stacking of models. 

 

1.  data and descriptors 

in the tutorial, we used aqueous solubility data (logs). the initial dataset has been randomly 
split  into  the  training  (818  compounds)  and  the  test  (817  compounds)  sets.  a  set  of  438 
isida  fragment  descriptors  (t1abl2u4)  were  computed  for  each  compound.  although  this 
particular  set  of  descriptors  is  not  optimal  for  building  the  best  possible  models  for  this 
property, however this set of descriptors allows for high speed of all calculations and makes it 
possible to demonstrate clearly the effect of id108. 

 

2.  files 

the following files are supplied for the tutorial: 

  train-logs.sdf/test-logs.sdf     molecular files for training and test sets 

  logs-t1abl2u4.hdr     descriptors identifiers 

  train-logs-t1abl2u4.arff/test-logs-t1abl2u4.arff       descriptor 

and property values for the train/test set 

3.  exercise 5: individual mlr model 

 

15 

tutorial on id108 

 

important  note  for  windows  users:  during  installation,  the  arff  files  should  have  been 
associated with weka. in this case, it is highly recommended to locate and double click on the 
file train-logs-t1abl2u4.arff, and to skip the following three points. 

  start weka. 

  press button explorer in the group applications. 

  press  button  open  file     and  select  the  train-logs-t1abl2u4.arff  file 
containing  descriptor  and  property  values  for  all  training  examples.  the  following 
window will pop up: 

 

 

 

  switch to the classification mode by clicking on the classify label. 

 

in the frame test options, select the option supplied test set. the window should look 
as the following: 

 

 

16 

tutorial on id108 

 

 

 

  press the button set    right to it. 

 

in the window that pops up press the button open file    and select the test-logs-
t1abl2u4.arff file containing descriptor and property values for the test set. press 
close to close this window. 

the aim of this part of the tutorial is to build a mlr model on the training set and test it using 
the specified test set. to do that: 

  click on the choose button in the panel classifier. the following window with the 

hierarchical tree of available machine learning methods appears: 

 

 

 

 

17 

tutorial on id108 

 

  choose the method weka->classifiers->functions->linearregression from the 

hierarchical tree. 

  click on the word linearregression. the weka.gui.genericobjecteditor window 

related to the mlr method, in which the method   s parameters can be settled, appears. 

  switch off the descriptor selection option by changing the option 

attributeselectionmethod to no attribute selection. the windows at the screen should 
be like these: 

 

 

 

  press ok to close the window. 

  click on the start button to run the mlr method. 

after the end of calculation the window of weka should look as follows: 

 

 

18 

tutorial on id108 

 

 

 

the predictive performance of the model, as estimated using the supplied external test set, is 
presented  at  the  right  panel.  one  can  see  that  the  correlation  coefficient  (between  predicted 
and  experimental  values  of  logs  on  the  test  set)  is  0.891,  mean  absolute  error  (mae)  of 
prediction  on  the  test  set  is  0.7173  logs  units,  the  root-mean-square  error  (rmse)  of 
prediction on the test set is 1.0068 logs units, the relative absolute error of prediction on the 
test set is 43.2988%, the root relative squared error of prediction on the test set is 47.4221%. 
all  these  characteristics  can  be  used  for  comparing  predictive  performances  of  different 
regression models. in this tutorial we will use the rmse error of prediction on the supplied 
external test set to compare predictive performances of regression models. 

 

4.  exercise 6: id112 of mlr models  

goal: to demonstrate the ability of id108 based on id112 to decrease prediction 
errors of mlr models.  

 

method. the id112 procedure consists of: (i) generating several samples from the original 
training set by drawing each compound with the same id203 with replacement (so-called 
id64), (ii) building a base learner (mlr in our case) model on each of the samples, 
(iii)  averaging  the  values  predicted  for  test  compounds  over  the  whole  ensemble  of  models 
[4]. this procedure is implemented in weka by means of a special    meta-classifier    with the 
name id112. 

19 

 

tutorial on id108 

 

 

computational procedure.  

step 1: setting the parameters. 

  click choose in the panel classifier.  

  choose  the  method  weka->classifiers->meta->id112  from  the  hierarchical  tree  of 

classifiers. 

  click on the word id112. the weka.gui.genericobjecteditor window related to the 
id112 procedure with default values of its parameters appears on the screen. notice 
that  the  default  classifier  for  the  id112  procedure  is  reptree,  a  sort  of  regression 
trees (see below). 

 

 

  change the classifier from reptree to mlr. 

o  click on the choose button near the word classifier. 

o  choose the method weka->classifiers->functions->linearregression from the 

hierarchical tree. 

o  click on the word linearregression. 

o  switch  off 

the  descriptor  selection  option  by  changing 

the  option 

attributeselectionmethod to no attribute selection. 

o  press ok to close the window. 

20 

 

 

tutorial on id108 

 

 

step 2: building a model based on a single id112 sample. 

  change  the  number  of  id112  iterations  to  1  by  editing  the  field  labeled 

numiterations (see below). 

 

 

  press ok to close the window. 

  click on the start button to run id112 with one mlr model. 

the following results are obtained (see the output panel): 

all statistical characteristics are worse in comparison with the individual model. in particular, 
the  rmse  rose  from  1.0068  to  1.3627.  this  could  be  explained  by  the  fact  that  the  dataset 
after resampling contains approximately 67% of unique examples, so approximately 33% of 
information does not take part in learning in a single id112 iteration.  

 

 

step 3: building models based on several id112 iterations. 

  click on id112.  

  set the number of iterations (near the label numiterations) to 10. 

21 

 

tutorial on id108 

 

  press ok to close the window. 

  click on the start button to run id112 with 10 iterations. 

the results are as follows: 

the  statistical  characteristics  (e.g.  rmse=0.9503)  become  better  than  those  of  both 
individual  mlr  model  (rmse=1.0068)  and  id112  with  a  single  mlr  model 
(rmse=1.3627). 

  repeat the study with the number of id112 iterations 5, 10, 15, 20, 30, 40, 50.  

 

  build the plot rmse vs. numiterations 

 

figure  6.  rmse  as  a  function  of 
the number of models.  

 

 

 

one  may  conclude  that  ensemble  learning  by  id112  mlr  models  leads  to  decrease  of 
prediction errors. 

 

 

5.  exercise 7: applying the random subspace method 

22 

tutorial on id108 

 

goal: to demonstrate the ability of id108 based on the random subspace approach 
to decrease prediction errors of mlr models.  

 

method.  the  random  subspace  procedure  consists  of:  (i)  random  selection  of  descriptors 
subsets from their initial pool, (ii) building a base learner (here, mlr) model on each of these 
subsets, (iii) application of each individual mlr model to a test set compound following by 
the  averaging  of  all  predictions  [4].  this  procedure  is  implemented  in  weka  in  the 
randomsubspace    meta-classifier   .  

 

computational procedure.  

step 1: setting the parameters. 

 

 

  click choose in the classifier panel.  

  on the hierarchical tree of classifiers, choose the method: 

weka->classifiers->meta->randomsubspace. 

  click on randomsubspace. notice that the default classifier for the random subspace 

procedure is reptree (see below). 

 

 

 

  change the classifier from reptree to mlr.  

23 

tutorial on id108 

 

o  click on the choose button near the word classifier. 

o  choose the method weka->classifiers->functions->linearregression from the 

hierarchical tree. 

o  click on linearregression. 

o  switch  off 

the  descriptor  selection  option  by  changing 

the  option 

attributeselectionmethod to no attribute selection. 

o  press ok to close the window. 

notice  that  the  default  value  0.5  for  subspacesize  means  that  for  each  model  only  50%  of 
descriptors  are  randomly  selected.  the  performance  of  the  random  subspace  methods 
significantly  depends  on  this  parameter.  here,  we  won   t  optimize  subspacesize,  its  default 
value 0.5 will be used in all calculations. 

 

step 2: building a model based on a single random subspace sample. 

  change  the  number  of  iterations  of  the  random  subspace  method  to  1  by  editing  the 

numiterations field (see below) 

 

 

 

  press ok to close the window. 

  click on the start button to run the random subspace procedure with one mlr model. 

the following results are obtained (see output panel): 

24 

 

tutorial on id108 

 

 

 

the model performance  (rmse = 1.1357) is less good than that obtained for the individual 
mlr model (rmse = 1. 0068, see exercise 5). this could be explained by reduction of the 
number of variables. indeed, only a half of the descriptor pool is used.  

step 3: building models based on a several random subspace samples. 

  click on randomsubspace. set the number of iterations (numiterations = 10). 

  press ok to close the window. 

  click on the start button to run the random subspace method with 10 iterations. 

the results should be as follows: 

 

 

the model performance becomes better compared to the previous calculation: rmse=0.9155. 

  repeat 

the  modeling  varying 

the  number  of 

random  subspace 

iterations: 

numiterations = 50, 100, 150, 200,. 300 and 400. 

  build the plot rmse vs numiterations 

 

 

25 

tutorial on id108 

figure 7. rmse as 
a  function  of  the 
number of models.  

 

 

 

 

one may conclude that the random space method involving ensemble mlr models leads to 
significant decrease of the prediction errors compared to one individual model. 

 

 

6.  exercise 8: additive regression based on slr models 

goal:  to  demonstrate  the  ability  of  additive  regression  (a  kind  of  regression  boosting)  to 
improve the performance of simple id75 (slr) models.  

method. additive regression enhances the performance of a base regression base method [6]. 
each  iteration  fits  a  model  to  the  residuals  left  on  the  previous  iteration.  prediction  is 
accomplished  by  summing  up  the  predictions  of  each  model.  reducing  the  shrinkage 
(learning rate) parameter, on one hand, helps to prevent overfitting and has a smoothing effect 
but, on the other hand, increases the learning time. default = 1.0, i.e. no shrinkage is applied. 
this  method  of  ensemble  learning  is  implemented  in  weka  in  additiveregression  meta-
classifier.  

 

computational procedure.  

step 1: setting the parameters. 

  click on choose in the classifier panel.  

 

26 

tutorial on id108 

  on the hierarchical tree of classifiers, choose the method: 

 weka->classifiers->meta->additiveregression. 

  click  on  additiveregression.  notice  that  the  default  classifier  (i.e.  machine  learning 

method) for the additive regression procedure is decisionstump (see below). 

 

 

 

 

  change the classifier from decisionstump to slr. 

o  click on the choose button near the word classifier. 

o  choose  the  method  weka->classifiers->functions->simplelinearregression 

from the hierarchical tree. 

notice  the  default  value  1.0  for  the  shrinkage  parameter.  this  means  that  we  are  not  doing 
shrinkage at this stage of tutorial. 

 

step 2: building a model based on a single iteration of the additive regression method. 

  change the number of iterations of the additive regression method to 1 by editing the 

field labeled numiterations (see below). 

 

 

27 

tutorial on id108 

 

 

 

  press ok to close the window. 

  click on the start button to run the additive regression procedure with one slr model 

(actually, an individual slr model). 

the following results are obtained (see output panel): 

the result is rather bad because the model has been built on only a single descriptor.  

 

step 3: building models based on a several random subspace samples. 

 

  repeat 

the  modeling  varying 

the  number  of  additive  regression 

iterations: 

numiterations = 10, 50, 100, 500, and 1000. 

  change  the  shrinkage  parameter  to  0.5  and  repeat  the  study  for  the  same  number  of 

iterations. 

  build the plot rmse vs. numiterations 

 

 

28 

tutorial on id108 

figure 8. rmse as a 
function of the number of 
models. 

 

 

 

one  may  conclude  that  the  ensemble  learning  by  using  the  additive  regression  method  with 
slr  models  leads  to  considerable  decrease  of  prediction  errors.  the  shrinkage  parameter 
helps to lower the prediction errors further. 

 

7.  exercise 9: stacking of models 

goal: to demonstrate the ability of stacking to improve predictive performance by combining 
three base classifiers: (i) partial least squares regression (pls), (ii) regression trees m5p, (iii) 
multiple id75 (mlr). 

 

method.  stacking  is  historically  one  of  the  first  ensemble  learning  methods.  it  combines 
several base classifiers, which can belong to absolutely different classes of machine learning 
methods, by means of a    meta-classifier    that takes as its inputs the output values of the base 
classifiers  [7,  8].  although  stacking  is  a  heuristic  method  and  does  not  guarantees 
improvement  in  all  cases,  in  many  practical  studies  it  shows  excellent  performance.  in  this 
tutorial we will use stacking to combine  

 

step 1: assessing the predictive performances of individual pls and m5p models (predictive 
performance of the mlr model has been assessed in this tutorial earlier see exercise 5). 

  assess  the  predictive  performance  of  the  pls  method  (with  the  default  number  of 

components 20).  

o  click on the choose button in the panel classifier.  

29 

 

tutorial on id108 

 

o  choose the method weka->classifiers->functions->plsclassifier from the 

hierarchical tree. 

o  click on the start button to run the pls method. 

the results are as follows: 

  assess the predictive performance of the m5p method. 

o  click on the choose button in the panel classifier.  

 

o  choose the method weka->classifiers->trees->m5p from the hierarchical tree. 

o  click on the start button to run the m5p method. 

the results are as follows: 

 

step 2: initialize the stacking method. 

 

 

 

  click on the choose button in the panel classifier.  

  choose  the  method  weka->classifiers->meta->stacking  from  the  hierarchical  tree  of 

classifiers. 

  click on the word stacking. the weka.gui.genericobjecteditor window related to the 
stacking  procedure  with  default  values  of  its  parameters  appears  on  the  screen  (see 
below).  

30 

tutorial on id108 

 

 

 

step 3: form a list of base classifiers.  

  click  on  the  field  containing  the  text     1  weka.classifiers.classifier     right  from  the 

label classifiers. 

a new window containing the list of currently selected classifiers pops up.  

 

  delete the zeror method by clicking on the delete button. 

  add the pls classifier to the empty list of classifiers. do the following: 

o  click on the choose button near the word classifier. 

o  choose  the  method  weka->classifiers->functions->plsclassifier  from  the 

hierarchical tree. 

o  click on the add button. 

  add the m5p method to the list of currently selected classifiers. do the following: 

o  click on the choose button near the word classifier. 

o  choose the method weka->classifiers->trees->m5p from the hierarchical tree. 

o  click on the add button. 

 

31 

tutorial on id108 

 

  add the mlr method to the list of currently selected classifiers. do the following: 

o  click on the choose button near the word classifier. 

o  choose the method weka->classifiers->functions->linearregression from the 

hierarchical tree.  

o  click on the word linearregression. 

o  switch  off 

the  descriptor  selection  option  by  changing 

the  option 

attributeselectionmethod to no attribute selection. 

o  press ok to close the window. 

o  click on the add button. 

at this stage the window should look like this: 

  close the window by clicking at the cross. 

 

 

step  4:  set  the  meta-classifier  for  the  stacking  method  to  be  the  multiple  linear  regression 
(mlr). do the following: 

o  click on the choose button near the word metaclassifier. 

o  choose the method weka->classifiers->functions->linearregression from the 

hierarchical tree.  

at this stage the weka.gui.genericobjecteditor window should be as follows: 

 

32 

tutorial on id108 

 

 

 

step  5:  run  stacking  of  methods  and  assess  the  predictive  performance  of  the  resulting 
ensemble model. 

  press ok to close the window. 

  click on the start button to run the stacking method. 

weka finds the following optimal combination of the base classifiers: 

the statistical results are as follows: 

 

 

step 6: repeat the study by adding 1-nn. repeat step 3 and: 

o  choose the method weka->classifiers->lazy->ibk from the hierarchical tree.  

the results become even better. 

 

33 

tutorial on id108 

 

 

 

the results for stacking are presented in table 1. 

learning algorithm 

r (correlation 

mae 

rmse 

mlr 

pls 

m5p 

1-nn 

stacking of mlr, 

pls, m5p 

stacking of mlr, 
pls, m5p, 1-nn 

coefficient) 

0.8910 

0.9171 

0.9176 

0.8455 

0.9366 

0.7173 

0.6384 

0.6152 

0.85 

0.5620 

1.0068 

0.8518 

0.8461 

1.1889 

0.7460 

0.9392 

0.537 

0.7301 

 

conclusion.  one  may  conclude  that  stacking  of  several  base  classifiers  has  led  to 
considerable  decrease  of  prediction  error  (rmse=0.730)  compared  to  that  for  the  best  base 
classifier (rmse=0.846).  

 

34 

tutorial on id108 

 

literature 

[1.] http://cheminfo.u-strasbg.fr:8080/bioinfo/91/db_search/index.jsp 

[2] leo breiman (1996). id112 predictors. machine learning. 24(2):123-140. 

[3] yoav freund, robert e. schapire: experiments with a new boosting algorithm. in: 
thirteenth international conference on machine learning, san francisco, 148-156, 1996. 

[4] tin kam ho (1998). the random subspace method for constructing decision forests. 
ieee transactions on pattern analysis and machine intelligence. 20(8):832-844. 

[5] leo breiman (2001). id79s. machine learning. 45(1):5-32. 

[6] j.h. friedman (1999). stochastic gradient boosting. computational statistics and data 
analysis. 38:367-378. 

[7] david h. wolpert (1992). stacked generalization. neural networks. 5:241-259. 

[8] a.k. seewald: how to make stacking better and faster while also taking care of an 
unknown weakness. in: nineteenth international conference on machine learning, 554-561, 
2002. 

[9] k. varmuza, p. filzmoser. introduction to multivariate statistical analysis in 
chemometrucs. crc press, 2009. 

[10] william w. cohen: fast effective rule induction. in: twelfth international conference 
on machine learning, 115-123, 1995. 

[11] ross j. quinlan: learning with continuous classes. in: 5th australian joint conference 
on artificial intelligence, singapore, 343-348, 1992. 

 

35 

tutorial on id108 

 

appendix 

1.  notes for windows 

on  windows,  weka  should  be  located  on  the  usual  program  launcher,  in  a  folder  weka-
version (e.g., weka-3-6-2).  

it  is  recommended  to  associate  weka  to  arff  files.  thus,  by  double  clicking  an  arff, 
weka/explorer will be launched and the default directory for loading and writing data will be 
set  to  the  same  directory  as  the  loaded  file.  otherwise,  the  default  directory  will  be  weka 
directory. 

if you want to change the default directory for datasets in weka, proceed as follows: 

  extract from the java archive weka.jar, the weka/gui/explorer/explorer.props 

file. it can be done using an archive program such as winrar or 7-zip. 

  copy  this  file  in  your  home  directory.  to  identify  your  home  directory,  type  the 

command echo %userprofile% in a dos command terminal. 

  edit the file explorer.props with wordpad. 

  change the line initialdirectory=%c by initialdirectory=c:/your/own/path 

if  you need to change the memory available for weka in the jvm,  you need to  edit the file 
runweka.ini  or  runweka.bat  in  the  installation  directory  of  weka  (root  privilege  may  be 
required).  change  the  line  maxheap=128m  by  maxheap=1024m.  you  cannot  assign  more  than 
1.4go to a jvm because of limitations of windows. 

 

2.  notes for linux 

to launch weka, open a terminal and type: 

java -jar /installation/directory/weka.jar. 

if  you  need  to  assign  additional  memory  to  the  jvm,  use  the  option  -xmmemorysizem, 
replacing  memorysize  by  the  required  size  in  megabytes.  for  instance  to  launch  weka  with 
1024 mo, type: 

java -jar -xm512m /installation/directory/weka.jar. 

 

36 

