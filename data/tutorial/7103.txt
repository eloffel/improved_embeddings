   #[1]github [2]recent commits to bayesgan:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]55
     * [35]star [36]961
     * [37]fork [38]162

[39]andrewgordonwilson/[40]bayesgan

   [41]code [42]issues 2 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   tensorflow code for the bayesian gan
   ([47]https://arxiv.org/abs/1705.09558) (nips 2017)
     * [48]7 commits
     * [49]1 branch
     * [50]0 releases
     * [51]fetching contributors
     * [52]view license

    1. [53]jupyter notebook 63.4%
    2. [54]python 36.6%

   (button) jupyter notebook python
   branch: master (button) new pull request
   [55]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/a
   [56]download zip

downloading...

   want to be notified of new releases in andrewgordonwilson/bayesgan?
   [57]sign in [58]sign up

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [61]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [62]download the github extension for visual studio
   and try again.

   (button) go back
   [63]@ysaatchi
   [64]ysaatchi [65]fixed bug with disc losses printing
   latest commit [66]ca06613 jul 30, 2018
   [67]permalink
   type         name         latest commit message  commit time
        failed to load latest commit information.
        [68]datasets
        [69]img
        [70]license
        [71]readme.md
        [72]bgan.py          [73]global refactor   feb 12, 2018
        [74]bgan_models.py
        [75]bgan_semi.py
        [76]bgan_synth.py
        [77]bgan_util.py
        [78]dcgan_ops.py
        [79]dcgan_utils.py
        [80]environment.yml
        [81]ml_dcgan.py
        [82]run_bgan.py
        [83]run_bgan_semi.py
        [84]synth.ipynb

readme.md

bayesian id3 in tensorflow

   this repository contains the tensorflow implementation of the
   [85]bayesian gan by yunus saatchi and andrew gordon wilson. this paper
   appears at nips 2017.

   please cite [86]our paper if you find this code useful in your
   research. the bibliographic information for the paper is
@inproceedings{saatciwilson,
  title={bayesian gan},
  author={saatci, yunus and wilson, andrew g},
  booktitle={advances in neural information processing systems},
  pages={3622--3631},
  year={2017}
}

contents

    1. [87]introduction
    2. [88]dependencies
    3. [89]training options
    4. [90]usage
         1. [91]installation
         2. [92]synthetic data
         3. [93]examples: mnist, cifar10, celeba, svhn
         4. [94]custom data

introduction

   in the bayesian gan we propose conditional posteriors for the generator
   and discriminator weights, and marginalize these posteriors through
   stochastic gradient hamiltonian monte carlo. key properties of the
   bayesian approach to gans include (1) accurate predictions on
   semi-supervised learning problems; (2) minimal intervention for good
   performance; (3) a probabilistic formulation for id136 in response
   to adversarial feedback; (4) avoidance of mode collapse; and (5) a
   representation of multiple complementary generative and discriminative
   models for data, forming a probabilistic ensemble.

                             [95][posterior.png]

   we illustrate a multimodal posterior over the parameters of the
   generator. each setting of these parameters corresponds to a different
   generative hypothesis for the data. we show here samples generated for
   two different settings of this weight vector, corresponding to
   different writing styles. the bayesian gan retains this whole
   distribution over parameters. by contrast, a standard gan represents
   this whole distribution with a point estimate (analogous to a single
   maximum likelihood solution), missing potentially compelling
   explanations for the data.

dependencies

   this code has the following dependencies (version number crucial):
     * python 2.7
     * tensorflow==1.0.0

   to install tensorflow 1.0.0 on linux please follow instructions at
   [96]https://www.tensorflow.org/versions/r1.0/install/.
     * scikit-learn==0.17.1

   you can install scikit-learn 0.17.1 with the following command
pip install scikit-learn==0.17.1

   alternatively, you can create a conda environment and set it up using
   the provided environment.yml file, as such:
conda env create -f environment.yml -n bgan

   then load the environment using
source activate bgan

usage

installation

    1. install the required dependencies
    2. clone this repository

synthetic data

   to run the synthetic experiment from the paper you can use bgan_synth
   script. for example, the following comand will train the bayesian gan
   (with d=100 and d=10) for 5000 iterations and store the results in
   <results_path>.
./bgan_synth.py --x_dim 100 --z_dim 10 --numz 10 --out <results_path>

   to run the ml gan for the same data run
./bgan_synth.py --x_dim 100 --z_dim 10 --numz 1 --out <results_path>

   bgan_synth has --save_weights, --out_dir, --z_dim, --numz,
   --wasserstein, --train_iter and --x_dim parameters. x_dim contolls the
   dimensionality of the observed data (x in the paper). for description
   of other parameters please see [97]training options.

   once you run the above two commands you will see the output of each
   100th iteration in <results_path>. so, for example, the bayesian gan's
   output at the 900th iteration will look like:

                      [98][pca_distribution_10_900.png]

   in contrast, the output of the standard gan (corresponding to numz=1,
   which forces ml estimation) will look like:

                      [99][pca_distribution_1_900.png]

   indicating clearly the tendency of mode collapse in the standard gan
   which, for this synthetic example, is completely avoided by the
   bayesian gan.

   to explore the sythetic experiment further, and to generate the
   jensen-shannon divergence plots, you can check out the notebook
   synth.ipynb.

unsupervised and semi-supervised learning on benchmark datasets

mnist, cifar10, celeba, svhn

   bayesian_gan_hmc script allows to train the model on standard and
   custom datasets. below we describe the usage of this script.

data preparation

   to reproduce the experiments on mnist, cifar10, celeba and svhn
   datasets you need to prepare the data and use a correct --data_path.
     * for mnist you don't need to prepare the data and can provide any
       --data_path;
     * for cifar10 please download and extract the python version of the
       data from [100]https://www.cs.toronto.edu/~kriz/cifar.html; then
       use the path to the directory containing cifar-10-batches-py as
       --data_path;
     * for svhn please download train_32x32.mat and test_32x32.mat files
       from [101]http://ufldl.stanford.edu/housenumbers/ and use the
       directory containing these files as your --data_path;
     * for celeba you will need to have opencv installed. you can find the
       download links for the data at
       [102]http://mmlab.ie.cuhk.edu.hk/projects/celeba.html. you will
       need to create celeba folder with anno and img_align_celeba
       subfolders. anno must contain the list_attr_celeba.txt and
       img_align_celeba must contain the .jpg files. you will also need to
       crop the images by running datasets/crop_faces.py script with
       --data_path <path> where <path> is the path to the folder
       containing celeba. when training the model, you will need to use
       the same <path> for --data_path;

unsupervised training

   you can run unsupervised learning by running the bayesian_gan_hmc
   script without --semi parameter. for example, use
./run_bgan.py --data_path <data_path> --dataset svhn --numz 10 --num_mcmc 2 --ou
t_dir
<results_path> --train_iter 75000 --save_samples --n_save 100

   to train the model on the svhn dataset. this command will run the
   method for 75000 iterations and save samples every 100 iterations. here
   <results_path> must lead to the directory where the results will be
   stored. see [103]data preparation section for an explanation of how to
   set <data_path>. see [104]training options section for a description of
   other training options.

       [105][svhn_1.png]      [106][svhn_2.png]      [107][svhn_3.png]

semi-supervised training

   to run the semi-supervised experiments you can use the run_bgan_semi.py
   script, which offers many options including the following:
     * --out_dir: path to the folder, where the outputs will be stored
     * --n_save: samples and weights are saved every n_save iterations;
       default 100
     * --z_dim: dimensionalit of z vector for generator; default 100
     * --data_path: path to the data; see [108]data preparation for a
       detailed discussion; this parameter is required
     * --dataset: can be mnist, cifar, svhn or celeb; default mnist
     * --batch_size: batch size for training; default 64
     * --prior_std: std of the prior distribution over the weights;
       default 1
     * --num_gen: same as j in the paper; number of samples of z to
       integrate it out for generators; default 1
     * --num_disc: same as j_d in the paper; number of samples of z to
       integrate it out for discriminators; default 1
     * --num_mcmc: same as m in the paper; number of mcmc nn weight
       samples per z; default 1
     * --lr: learning rate used by the adam optimizer; default 0.0002
     * --optimizer: optimization method to be used: adam
       (tf.train.adamoptimizer) or sgd (tf.train.momentumoptimizer);
       default adam
     * --n: number of labeled samples for semi-supervised learning
     * --train_iter: number of training iterations; default 50000
     * --save_samples: save generated samples during training
     * --save_weights: save weights during training
     * --random_seed: random seed; note that setting this seed does not
       lead to 100% reproducible results if gpu is used

   you can also run wgans with --wasserstein or train an ensemble of
   <num_dcgans> dcgans with --ml_ensemble <num_dcgans>. in particular you
   can train a dcgan with --ml.

   you can train the model in semi-supervised setting by running
   bayesian_gan_hmc with --semi option. use -n parameter to set the number
   of labeled examples to train on. for example, use
./run_bgan_semi.py --data_path <data_path> --dataset cifar --num_gen 10 --num_mc
mc 2
--out_dir <results_path> --train_iter 100000 --n 4000 --lr 0.0005

   to train the model on cifar10 dataset with 4000 labeled examples. this
   command will train the model for 100000 iterations and store the
   outputs in <results_path> folder.

                        [109][acc_vs_time_cifar.png]

   to train the model on mnist with 100 labeled examples you can use the
   following command.
./bayesian_gan_hmc.py --data_path <data_path>/ --dataset mnist --num_gen 10 --nu
m_mcmc 2
--out_dir <results_path> --train_iter 100000 -n 100 --semi --lr 0.0005

                        [110][acc_vs_time_mnist.png]

custom data

   to train the model on a custom dataset you need to define a class with
   a specific interface. suppose we want to train the model on the
   [111]digits dataset. this datasets consists of 8x8 images of digits.
   let's suppose that the data is stored in x_tr.npy, y_tr.npy, x_te.npy
   and y_te.npy files. we will assume that x_tr.npy and x_te.npy have
   shapes of the form (?, 8, 8, 1). we can then define the class
   corresponding to this dataset in bgan_util.py as follows.
class digits:

    def __init__(self):
        self.imgs = np.load('x_tr.npy')
        self.test_imgs = np.load('x_te.npy')
        self.labels = np.load('y_tr.npy')
        self.test_labels = np.load('y_te.npy')
        self.labels = one_hot_encoded(self.labels, 10)
        self.test_labels = one_hot_encoded(self.test_labels, 10)
        self.x_dim = [8, 8, 1]
        self.num_classes = 10

    @staticmethod
    def get_batch(batch_size, x, y):
        """returns a batch from the given arrays.
        """
        idx = np.random.choice(range(x.shape[0]), size=(batch_size,), replace=fa
lse)
        return x[idx], y[idx]

    def next_batch(self, batch_size, class_id=none):
        return self.get_batch(batch_size, self.imgs, self.labels)

    def test_batch(self, batch_size):
        return self.get_batch(batch_size, self.test_imgs, self.test_labels)

   the class must have next_batch and test_batch, and must have the imgs,
   labels, test_imgs, test_labels, x_dim and num_classes fields.

   now we can import the digits class in bayesian_gan_hmc.py
from bgan_util import digits

   and add the following lines to to the processing of --dataset
   parameter.
if args.dataset == "digits":
    dataset = digits()

   after this preparation is done, we can train the model with, for
   example,
./run_bgan_semi.py --data_path <any_path> --dataset digits --num_gen 10 --num_mc
mc 2
--out_dir <results path> --train_iter 100000 --save_samples

acknowledgements

   we thank pavel izmailov and ben athiwaratkun for help with stress
   testing this code and creating the tutorial.

     *    2019 github, inc.
     * [112]terms
     * [113]privacy
     * [114]security
     * [115]status
     * [116]help

     * [117]contact github
     * [118]pricing
     * [119]api
     * [120]training
     * [121]blog
     * [122]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [123]reload to refresh your
   session. you signed out in another tab or window. [124]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/andrewgordonwilson/bayesgan/commits/master.atom
   3. https://github.com/andrewgordonwilson/bayesgan#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/andrewgordonwilson/bayesgan
  32. https://github.com/join
  33. https://github.com/login?return_to=/andrewgordonwilson/bayesgan
  34. https://github.com/andrewgordonwilson/bayesgan/watchers
  35. https://github.com/login?return_to=/andrewgordonwilson/bayesgan
  36. https://github.com/andrewgordonwilson/bayesgan/stargazers
  37. https://github.com/login?return_to=/andrewgordonwilson/bayesgan
  38. https://github.com/andrewgordonwilson/bayesgan/network/members
  39. https://github.com/andrewgordonwilson
  40. https://github.com/andrewgordonwilson/bayesgan
  41. https://github.com/andrewgordonwilson/bayesgan
  42. https://github.com/andrewgordonwilson/bayesgan/issues
  43. https://github.com/andrewgordonwilson/bayesgan/pulls
  44. https://github.com/andrewgordonwilson/bayesgan/projects
  45. https://github.com/andrewgordonwilson/bayesgan/pulse
  46. https://github.com/join?source=prompt-code
  47. https://arxiv.org/abs/1705.09558
  48. https://github.com/andrewgordonwilson/bayesgan/commits/master
  49. https://github.com/andrewgordonwilson/bayesgan/branches
  50. https://github.com/andrewgordonwilson/bayesgan/releases
  51. https://github.com/andrewgordonwilson/bayesgan/graphs/contributors
  52. https://github.com/andrewgordonwilson/bayesgan/blob/master/license
  53. https://github.com/andrewgordonwilson/bayesgan/search?l=jupyter-notebook
  54. https://github.com/andrewgordonwilson/bayesgan/search?l=python
  55. https://github.com/andrewgordonwilson/bayesgan/find/master
  56. https://github.com/andrewgordonwilson/bayesgan/archive/master.zip
  57. https://github.com/login?return_to=https://github.com/andrewgordonwilson/bayesgan
  58. https://github.com/join?return_to=/andrewgordonwilson/bayesgan
  59. https://desktop.github.com/
  60. https://desktop.github.com/
  61. https://developer.apple.com/xcode/
  62. https://visualstudio.github.com/
  63. https://github.com/ysaatchi
  64. https://github.com/andrewgordonwilson/bayesgan/commits?author=ysaatchi
  65. https://github.com/andrewgordonwilson/bayesgan/commit/ca06613201e0882a21e53f18e71ecbff5eda7923
  66. https://github.com/andrewgordonwilson/bayesgan/commit/ca06613201e0882a21e53f18e71ecbff5eda7923
  67. https://github.com/andrewgordonwilson/bayesgan/tree/ca06613201e0882a21e53f18e71ecbff5eda7923
  68. https://github.com/andrewgordonwilson/bayesgan/tree/master/datasets
  69. https://github.com/andrewgordonwilson/bayesgan/tree/master/img
  70. https://github.com/andrewgordonwilson/bayesgan/blob/master/license
  71. https://github.com/andrewgordonwilson/bayesgan/blob/master/readme.md
  72. https://github.com/andrewgordonwilson/bayesgan/blob/master/bgan.py
  73. https://github.com/andrewgordonwilson/bayesgan/commit/78fd244a51d89d042e5e6bab4d17842ef53516fd
  74. https://github.com/andrewgordonwilson/bayesgan/blob/master/bgan_models.py
  75. https://github.com/andrewgordonwilson/bayesgan/blob/master/bgan_semi.py
  76. https://github.com/andrewgordonwilson/bayesgan/blob/master/bgan_synth.py
  77. https://github.com/andrewgordonwilson/bayesgan/blob/master/bgan_util.py
  78. https://github.com/andrewgordonwilson/bayesgan/blob/master/dcgan_ops.py
  79. https://github.com/andrewgordonwilson/bayesgan/blob/master/dcgan_utils.py
  80. https://github.com/andrewgordonwilson/bayesgan/blob/master/environment.yml
  81. https://github.com/andrewgordonwilson/bayesgan/blob/master/ml_dcgan.py
  82. https://github.com/andrewgordonwilson/bayesgan/blob/master/run_bgan.py
  83. https://github.com/andrewgordonwilson/bayesgan/blob/master/run_bgan_semi.py
  84. https://github.com/andrewgordonwilson/bayesgan/blob/master/synth.ipynb
  85. https://arxiv.org/abs/1705.09558
  86. https://arxiv.org/abs/1705.09558
  87. https://github.com/andrewgordonwilson/bayesgan#introduction
  88. https://github.com/andrewgordonwilson/bayesgan#dependencies
  89. https://github.com/andrewgordonwilson/bayesgan#training-options
  90. https://github.com/andrewgordonwilson/bayesgan#usage
  91. https://github.com/andrewgordonwilson/bayesgan#installation
  92. https://github.com/andrewgordonwilson/bayesgan#synthetic-data
  93. https://github.com/andrewgordonwilson/bayesgan#mnist-cifar10-celeba-svhn
  94. https://github.com/andrewgordonwilson/bayesgan#custom-data
  95. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/posterior.png
  96. https://www.tensorflow.org/versions/r1.0/install/
  97. https://github.com/andrewgordonwilson/bayesgan#training-options
  98. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/pca_distribution_10_900.png
  99. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/pca_distribution_1_900.png
 100. https://www.cs.toronto.edu/~kriz/cifar.html
 101. http://ufldl.stanford.edu/housenumbers/
 102. http://mmlab.ie.cuhk.edu.hk/projects/celeba.html
 103. https://github.com/andrewgordonwilson/bayesgan#data-preparation
 104. https://github.com/andrewgordonwilson/bayesgan#training-options
 105. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/svhn_1.png
 106. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/svhn_2.png
 107. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/svhn_3.png
 108. https://github.com/andrewgordonwilson/bayesgan#data-preparation
 109. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/acc_vs_time_cifar.png
 110. https://github.com/andrewgordonwilson/bayesgan/blob/master/img/acc_vs_time_mnist.png
 111. http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html
 112. https://github.com/site/terms
 113. https://github.com/site/privacy
 114. https://github.com/security
 115. https://githubstatus.com/
 116. https://help.github.com/
 117. https://github.com/contact
 118. https://github.com/pricing
 119. https://developer.github.com/
 120. https://training.github.com/
 121. https://github.blog/
 122. https://github.com/about
 123. https://github.com/andrewgordonwilson/bayesgan
 124. https://github.com/andrewgordonwilson/bayesgan

   hidden links:
 126. https://github.com/
 127. https://github.com/andrewgordonwilson/bayesgan
 128. https://github.com/andrewgordonwilson/bayesgan
 129. https://github.com/andrewgordonwilson/bayesgan
 130. https://help.github.com/articles/which-remote-url-should-i-use
 131. https://github.com/andrewgordonwilson/bayesgan#bayesian-generative-adversarial-networks-in-tensorflow
 132. https://github.com/andrewgordonwilson/bayesgan#contents
 133. https://github.com/andrewgordonwilson/bayesgan#introduction
 134. https://github.com/andrewgordonwilson/bayesgan#dependencies
 135. https://github.com/andrewgordonwilson/bayesgan#usage
 136. https://github.com/andrewgordonwilson/bayesgan#installation
 137. https://github.com/andrewgordonwilson/bayesgan#synthetic-data
 138. https://github.com/andrewgordonwilson/bayesgan#unsupervised-and-semi-supervised-learning-on-benchmark-datasets
 139. https://github.com/andrewgordonwilson/bayesgan#mnist-cifar10-celeba-svhn
 140. https://github.com/andrewgordonwilson/bayesgan#data-preparation
 141. https://github.com/andrewgordonwilson/bayesgan#unsupervised-training
 142. https://github.com/andrewgordonwilson/bayesgan#semi-supervised-training
 143. https://github.com/andrewgordonwilson/bayesgan#custom-data
 144. https://github.com/andrewgordonwilson/bayesgan#acknowledgements
 145. https://github.com/
