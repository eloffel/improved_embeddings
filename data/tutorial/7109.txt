   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

infogan         id3 part iii

   [16]go to the profile of zak jost
   [17]zak jost (button) blockedunblock (button) followfollowing
   nov 15, 2017

   in [18]part i the original gan paper was presented. [19]part ii gave an
   overview of dcgan, which greatly improved the performance and stability
   of gans. in this final part, the contributions of [20]infogan will be
   explored, which apply concepts from id205 to transform
   some of the noise terms into latent codes that have systematic,
   predictable effects on the outcome.

motivation

   as seen in the examples of part ii, one can do interesting and
   impressive things when doing arithmetic on the noise vector of the
   generator. in the example below from the dcgan paper, the input noise
   vectors of men with glasses are manipulated to give vectors that result
   in women with sunglasses once fed into the generator. this shows that
   there are structures in the noise vectors that have meaningful and
   consistent effects on the generator output.
   [1*u35fsj9ambqqnsyvvhdguq.png]

   however, there   s no systematic way to find these structures. the
   process is very manual: 1) generate a bunch of images, 2) find images
   that have the characteristic you want, 3) average together their noise
   vectors and hope that it captures the structure of interest.

   the only    knob to turn    to change the generator output is the noise
   input. and since it   s noise, there   s no intuition about how to modify
   it to get a desired effect. the question is:    what if you wanted an
   image of a man with glasses         how do you change the noise?    this is a
   problem because your representation is entangled. infogan tries to
   solve this problem and provide a disentangled representation.

   the idea is to provide a latent code, which has meaningful and
   consistent effects on the output. for instance, let   s say you   re
   working with the mnist hand-written digit dataset. you know there are
   10 digits, so it would be nice if you could use this structure by
   assigning part of the input to a 10-state discrete variable. the hope
   is that if you keep the code the same and randomly change the noise,
   you get variations of the same digit.
   [1*rn0gzxrdhmg7pnbraq70vq.png]
   entangled vs disentangled

infogan

   the way infogan approaches this problem is by splitting the generator
   input into two parts: the traditional noise vector and a new    latent
   code    vector. the codes are then made meaningful by maximizing the
   [21]mutual information between the code and the generator output.

theory

   this framework is implemented by merely adding a id173 term
   (red box) to the the original gan   s objective function.
   [1*rszxfx4_xcc-5z4lirndrq.png]

   lambda is the id173 constant and is typically just set to one.
   the i(c;g(z,c)) term is the mutual information between the latent code
   c and the generator output g(z,c).

   it   s not practical to calculate the mutual information explicitly, so a
   lower bound is approximated using standard variational arguments. this
   consists of introducing an    auxiliary    distribution q(c|x), which is
   modeled by a parameterized neural network, and is meant to approximate
   the real p(c|x). p(c|x) represents the likelihood of code c given the
   generated input x. they then use a re-parameterization trick to make it
   such that you can merely sample from a user-specified prior (i.e.
   uniform distribution) instead of the unknown posterior.
   [1*ntymbgnbt9rzhdll71-koa.png]
   [1*92l-ml_k7iqcpiwcvt7tiw.png]

   the regularizer term above translates to the following process: sample
   a value for the latent code c from a prior of your choice; sample a
   value for the noise z from a prior of your choice; generate x = g(c,z);
   calculate q(c|x=g(c,z)).

   the final form of the objective function is then given by this
   lower-bound approximation to the mutual information:
   [1*w2g0dfbqua52piy1snyvjq.png]

architecture

   as mentioned above, there   s now a second input to the generator: the
   latent code. the auxiliary distribution introduced in the theory
   section is modeled by another neural network, which really is just a
   fully connected layer tacked onto the last representation layer of the
   discriminator. the q network is essentially trying to predict what the
   code is (see nuance below). this is only used when feeding in fake
   input, since that   s the only time the code is known.
   [1*dxlgtv8lnitinvxomgzsag.png]
   infogan architecture. new components outlined in red.

   there   s one nuance here that can be difficult to understand. to
   calculate the id173 term, you don   t need an estimation of the
   code itself, but rather you need to estimate the likelihood of seeing
   that code for the given generated input. therefore, the output of q is
   not the code value itself, but instead the statistics of the
   distribution you chose to model the code. once you know the sufficient
   statistics of the id203 distribution, you can calculate the
   likelihood.

   for instance, if you have used a continuous valued code (i.e. between
   -1 and +1), you might model q(c|x) as a normal/gaussian distribution.
   in that case, q would output two values for this part of the code: the
   mean and standard deviation. once you know the mean and standard
   deviation you can calculate the likelihood q(c|x), which is what you
   need for the id173 term.

results

   initial results were reported by training on the mnist hand-written
   digit dataset. the authors specified a 10-state discrete code (hoping
   it would map to the hand-written digit value), as well as two
   continuous codes between -1 to +1. for comparison, they trained a
   regular gan with the same structure but did not use the id173
   term that maximizes the mutual information.

   the images below show a process where a particular noise vector is held
   constant (each row), but the latent code is changed (each column). in
   part a you see the discrete code consistently changing the digit. part
   b shows the regular gan having essentially no meaningful or consistent
   change.

   parts c and d show the continuous codes being changed for infogan. this
   clearly affects things like the tilt and width of the digit.
   interestingly, they actually change from -2 to +2 even though training
   only used values from -1 to +1, which shows that these codes
   meaningfully extrapolate.
   [1*kyyjnnunaoscjucbpql2aa.png]
   comparing infogan to regular gan when changing code values. from
   infogan paper.

   here are some results on face images. please see [22]the paper for
   additional results and explanation.
   [1*qa5zea2_tgngrvh38oclaw.png]
   results on 3d face model dataset
   [1*woukelmh_6shj6ykacqciq.png]
   results on celeba dataset

conclusion

   it   s worth stressing that it was never specified in advance that tilt
   or digit thickness would be useful to separate as codes. the infogan
   training procedure discovered these attributes by itself         i.e. in an
   unsupervised fashion. the only thing the research does is specify the
   structure of the latent code.

   we   ve seen that by simply adding a term that maximizes mutual
   information between part of the generator input and its output, the
   learning process disentangles meaningful attributes in the data and
   allocates them to this imposed latent code structure.

you do it

   i found the [23]original repo difficult to run since its dependencies
   are very old. i   ve [24]updated the code so that you can run with modern
   tensorflow apis (version 1.3.0).

keep digging

   in this 3 part series we   ve covered a few of the major contributions
   and seen gans do amazing things. even still, this barely scratches the
   surface. there are multiple github repos with a large and growing list
   of research papers. here   s [25]one, and here   s [26]another. this is an
   exciting area of research that   s only growing in maturity and
   effectiveness. if you find a particular paper you   d like reviewed here,
   feel free to drop a note in the comments.

     * [27]machine learning
     * [28]artificial intelligence
     * [29]deep learning
     * [30]neural networks
     * [31]id205

   (button)
   (button)
   (button) 430 claps
   (button) (button) (button) 2 (button) (button)

     (button) blockedunblock (button) followfollowing
   [32]go to the profile of zak jost

[33]zak jost

   research scientist at amazon aws. father. husband.

     (button) follow
   [34]towards data science

[35]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 430
     * (button)
     *
     *

   [36]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [37]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/380c0c6712cd
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/infogan-generative-adversarial-networks-part-iii-380c0c6712cd&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/infogan-generative-adversarial-networks-part-iii-380c0c6712cd&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_imrynzzriwq3---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@zjost85?source=post_header_lockup
  17. https://towardsdatascience.com/@zjost85
  18. https://medium.com/@zjost85/overview-of-gans-generative-adversarial-networks-part-i-ac78ec775e31
  19. https://towardsdatascience.com/generative-adversarial-networks-part-ii-6212f7755c1f
  20. https://arxiv.org/abs/1606.03657
  21. https://en.wikipedia.org/wiki/mutual_information
  22. https://arxiv.org/pdf/1606.03657.pdf
  23. https://github.com/openai/infogan
  24. https://github.com/zjost/infogan
  25. https://github.com/zhangqianhui/adversarialnetspapers
  26. https://github.com/nightrome/really-awesome-gan
  27. https://towardsdatascience.com/tagged/machine-learning?source=post
  28. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  29. https://towardsdatascience.com/tagged/deep-learning?source=post
  30. https://towardsdatascience.com/tagged/neural-networks?source=post
  31. https://towardsdatascience.com/tagged/information-theory?source=post
  32. https://towardsdatascience.com/@zjost85?source=footer_card
  33. https://towardsdatascience.com/@zjost85
  34. https://towardsdatascience.com/?source=footer_card
  35. https://towardsdatascience.com/?source=footer_card
  36. https://towardsdatascience.com/
  37. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  39. https://medium.com/p/380c0c6712cd/share/twitter
  40. https://medium.com/p/380c0c6712cd/share/facebook
  41. https://medium.com/p/380c0c6712cd/share/twitter
  42. https://medium.com/p/380c0c6712cd/share/facebook
