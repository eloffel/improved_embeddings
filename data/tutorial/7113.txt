   #[1]github [2]recent commits to lab-workshops:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]15
     * [35]star [36]40
     * [37]fork [38]39

[39]yaledhlab/[40]lab-workshops

   [41]code [42]issues 2 [43]pull requests 0 [44]projects 0 [45]wiki
   [46]insights
   branch: master
   (button) create new file [47]find file [48]history
   [49]lab-workshops/named-entity-recognition/
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [50]permalink
   type      name     latest commit message commit time
        [51]..
        failed to load latest commit information.
        [52]images
        [53]utils
        [54]readme.md

readme.md

id39

   id39 (ner) is the process of identifying "entities"
   (people, locations, organizations...) in unstructured text. ner is
   frequently used in data analysis because it helps one quickly identify
   the key agents within a corpus of texts. the guide below is meant to
   help you run ner on texts for your own research projects.

software requirements

   there are lots of packages and software solutions for running ner on
   corpora. one of the most popular is stanford's [55]corenlp package,
   which performs a wide variety of analytic techniques on input text
   files. the guide below will help you get set up to use stanford's
   corenlp on a machine you control.

   steps to install all required software:
    1. [56]download the corenlp software to your desktop
    2. [57]install the java development kit (jdk)
    3. [58]install the anaconda python distribution

getting started

   download stanford corenlp sourecode

   visit the [59]stanford corenlp homepage and click the big download
   button. once the download finishes, move the downloaded folder to your
   desktop and unzip it.

open a terminal

   once the three dependencies above are installed, you will want to open
   a terminal.
   operating system command
   osx type command+space_bar, type terminal, and hit enter
   [[60]screenshot]
   windows go to programs/apps -> anaconda3 -> anaconda prompt
   [[61]screenshot]

change terminal directories to the corenlp folder

   once you have a terminal, you will need to change the terminal's
   directory to your desktop. you can do so by running the following
   commands:
   operating system              command
   osx              cd ~/desktop
   windows          cd c:\users\your_username\desktop

   after executing the command above, you can move the terminal into the
   stanford corenlp folder by typing:
   operating system               command
   osx              cd stanford-corenlp-full-2017-06-09
   windows          cd stanford-corenlp-full-2017-06-09

   if you now type ls on osx or dir on windows, then hit enter, you should
   see a long list of files, one of which is named input.txt. if you don't
   see that file, raise your hand or close your terminal and repeat the
   steps above to get your terminal set up.

view the sample input file

   open the stanford corenlp directory on your desktop and double-click
   input.txt. you should see: "stanford university is located in
   california. it is a great university, founded in 1891."

   in the steps below, we'll run ner on this text to try and identify
   entities within the file.

run ner on the sample input file

   with your terminal in the corenlp folder, you can run ner on the sample
   input file by typing the following into your terminal and hitting
   enter:

   java -cp "*" -xmx2g edu.stanford.nlp.pipeline.stanfordcorenlp
   -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file input.txt

   this command does the following:
   command element function
   java ask your machine to submit code to your java interpreter
   -cp '*' add all jar files in your current directory to your classpath
   -xmx2g allocate 2 gigabytes of ram for this process
   edu.stanford...nlp specify the path to the main corenlp file
   [[62]source]
   -annotators ... enumerate the markup options to include in output
   [[63]read more]
   -file input.txt specify the input file to process

view the output

   you should see some some output text on your terminal. once this
   process finishes, open the input.txt.xml file in the stanford corenlp
   folder. opening this file should reveal a huge xml file with lots of
   markup. congratulations--you've just performed named entity
   recognition!

understanding corenlp output

   the output from the corenlp pipeline looks a bit like this:
<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="corenlp-to-html.xsl" type="text/xsl"?>
<root>
  <document>
    <sentences>
      <sentence id="1">
        <tokens>
          <token id="1">
            <word>stanford</word>
            <lemma>stanford</lemma>
            <characteroffsetbegin>0</characteroffsetbegin>
            <characteroffsetend>8</characteroffsetend>
            <pos>nnp</pos>
            <ner>organization</ner>
            <speaker>per0</speaker>
          </token>
          <token id="2">
            <word>university</word>
            <lemma>university</lemma>
            <characteroffsetbegin>9</characteroffsetbegin>
            <characteroffsetend>19</characteroffsetend>
            <pos>nnp</pos>
            <ner>organization</ner>
            <speaker>per0</speaker>
          </token>
        [...]
      [...]
    [...]
  [...]
</root>

   this xml document models an input document in the following way:

   the document contains sentences.
   each sentence contains tokens.
   each token contains word, lemma, pos, ner and other attributes.

   each token's word attribute refers to the raw input word (e.g. cats).
   each token's lemma attribute refers to the linguistic lemma of the
   input word (e.g. cat).
   each token's pos attribute identifies the word's part of speech.
   each token's ner attribute identifies whether the word contains an
   entity.

   most words will have an ner attribute of 0, which means the given word
   is not a named entity. if a word does contain an entity, however, its
   ner attribute will equal one of the following types of entities:
   person, location, organization, misc, money, number, ordinal, percent,
   date, time, duration, set.

   in the sample input.txt file, for example, both stanford and university
   have ner values of organization, as the two words identify a particular
   organization.

   given the above structure in the stanford output files, one can easily
   retrieve people, locations and organizations from an input set of
   texts.

annotating multiple files

   to process multiple files, you can create a file called input_files.txt
   that has the path to each file to be processed on a new line:
files_to_process/file1.txt
files_to_process/file2.txt
files_to_process/file3.txt

   if you have a folder with serveral files you with to process, you can
   list each file on a new line by running:
   operating system                    command
   osx              ls files_to_process/* > input_files.txt
   windows          dir files_to_process\* /s/b > input_files.txt

   you can then run the corenlp on this list of files by running:

   java -cp "../path/to/stanford-corenlp-full-2017-06-09/*" -xmx2g
   edu.stanford.nlp.pipeline.stanfordcorenlp -annotators
   tokenize,ssplit,pos,lemma,ner,parse,dcoref -filelist input_files.txt
   -outputdirectory corenlp_output

   nb: windows users will need to replace the / folder delimeter with \ in
   the command above.

sample application

   let's suppose we wish to perform ner on all of the [64]sherlock holmes
   tales. to do so, we would need to gain access to plain text copies of
   all the tales available here, and we'd want to place them all in a
   common directory. for now, let's download a sample of the holmes tales
   from [65]here and drag them into the corenlp folder on your desktop.

   once the sherlock_holmes_sample directory is in your corenlp folder,
   let's generate an input_files.txt using the commands mentioned above:
   operating system                       command
   osx              ls sherlock_holmes_sample/* > input_files.txt
   windows          dir sherlock_holmes_sample\* /s/b > input_files.txt

   now let's submit that list of files to the corenlp pipeline:

   java -cp "*" -xmx2g edu.stanford.nlp.pipeline.stanfordcorenlp
   -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -filelist
   input_files.txt -outputdirectory corenlp_output

   this will generate a folder called corenlp_output in your corenlp
   folder, and will store each processed file in that folder.

analyzing corenlp output

   given these output files, we can perform various kinds of analysis. one
   of the simplest kinds of analysis is to count the number of times each
   entity occurs. to do so, download [66]this file to your corenlp folder
   and save it as count_corenlp_entities.py.

   once that's all set, you can run:
python count_corenlp_entities.py corenlp_output/

   this will generate a file named ner_counts.txt that identifies the
   number of times each entity occurs in your dataset. et voila, you now
   have tabluar data you can visualize!

   to help others with the visualization task, we've built a simple
   application that visualizes the frequencies of entities identified by
   the stanford corenlp package. to do so, you can visit [67]this site and
   upload your ner_counts.txt file into the file uploader. this will
   generate a plot that looks something like this:

   [68]screenshot

     *    2019 github, inc.
     * [69]terms
     * [70]privacy
     * [71]security
     * [72]status
     * [73]help

     * [74]contact github
     * [75]pricing
     * [76]api
     * [77]training
     * [78]blog
     * [79]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [80]reload to refresh your
   session. you signed out in another tab or window. [81]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/yaledhlab/lab-workshops/commits/master.atom
   3. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/yaledhlab/lab-workshops/tree/master/named-entity-recognition
  32. https://github.com/join
  33. https://github.com/login?return_to=/yaledhlab/lab-workshops
  34. https://github.com/yaledhlab/lab-workshops/watchers
  35. https://github.com/login?return_to=/yaledhlab/lab-workshops
  36. https://github.com/yaledhlab/lab-workshops/stargazers
  37. https://github.com/login?return_to=/yaledhlab/lab-workshops
  38. https://github.com/yaledhlab/lab-workshops/network/members
  39. https://github.com/yaledhlab
  40. https://github.com/yaledhlab/lab-workshops
  41. https://github.com/yaledhlab/lab-workshops
  42. https://github.com/yaledhlab/lab-workshops/issues
  43. https://github.com/yaledhlab/lab-workshops/pulls
  44. https://github.com/yaledhlab/lab-workshops/projects
  45. https://github.com/yaledhlab/lab-workshops/wiki
  46. https://github.com/yaledhlab/lab-workshops/pulse
  47. https://github.com/yaledhlab/lab-workshops/find/master
  48. https://github.com/yaledhlab/lab-workshops/commits/master/named-entity-recognition
  49. https://github.com/yaledhlab/lab-workshops
  50. https://github.com/yaledhlab/lab-workshops/tree/d69bd8789c130acb270ea2b3cc23d974366d37f0/named-entity-recognition
  51. https://github.com/yaledhlab/lab-workshops
  52. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition/images
  53. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition/utils
  54. https://github.com/yaledhlab/lab-workshops/blob/master/named-entity-recognition/readme.md
  55. https://stanfordnlp.github.io/corenlp/
  56. https://stanfordnlp.github.io/corenlp/index.html#download
  57. http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
  58. https://www.anaconda.com/download/
  59. https://stanfordnlp.github.io/corenlp/index.html#download
  60. https://github.com/yaledhlab/lab-workshops/blob/master/named-entity-recognition/images/osx_terminal.png
  61. https://github.com/yaledhlab/lab-workshops/blob/master/named-entity-recognition/images/windows_terminal.png
  62. https://github.com/stanfordnlp/corenlp/blob/master/src/edu/stanford/nlp/pipeline/stanfordcorenlp.java
  63. https://stanfordnlp.github.io/corenlp/annotators.html
  64. https://sherlock-holm.es/ascii/
  65. https://s3-us-west-2.amazonaws.com/lab-workshops/sherlock_holmes_sample.zip
  66. https://gist.githubusercontent.com/duhaime/08f8ac4962f53c185e705189a3f6e9b5/raw/80dae809815d0311fa2e46fef8edecc75db41a5c/count_corenlp_entities.py
  67. https://bl.ocks.org/duhaime/raw/cd61b320bd5601cff5553f0820cf4dfa/
  68. https://github.com/yaledhlab/lab-workshops/blob/master/named-entity-recognition/images/ner_counts_preview.png
  69. https://github.com/site/terms
  70. https://github.com/site/privacy
  71. https://github.com/security
  72. https://githubstatus.com/
  73. https://help.github.com/
  74. https://github.com/contact
  75. https://github.com/pricing
  76. https://developer.github.com/
  77. https://training.github.com/
  78. https://github.blog/
  79. https://github.com/about
  80. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition
  81. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition

   hidden links:
  83. https://github.com/
  84. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition
  85. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition
  86. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition
  87. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#named-entity-recognition
  88. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#software-requirements
  89. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#getting-started
  90. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#open-a-terminal
  91. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#change-terminal-directories-to-the-corenlp-folder
  92. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#view-the-sample-input-file
  93. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#run-ner-on-the-sample-input-file
  94. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#view-the-output
  95. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#understanding-corenlp-output
  96. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#annotating-multiple-files
  97. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#sample-application
  98. https://github.com/yaledhlab/lab-workshops/tree/master/named-entity-recognition#analyzing-corenlp-output
  99. https://github.com/
