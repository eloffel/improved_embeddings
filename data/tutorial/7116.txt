   #[1]id136

   [2]id136

                                  [3]id136

   posts on machine learning, statistics, opinions on things i'm reading
   in the space

        [4]home

   november 16, 2017

                     a cookbook for machine learning: vol 1

   this was a busy week, i had no time to read anything new, so i'm
   sharing a note that i wrote for myself, for no other reason than to
   understand things better. it's a kind of cookbook of various
   "transformations" you can apply to a machine learning problem to
   eventually turn it into something we know how to solve: seeking stable
   attractors of a tractable vector field.

   the typical setup is: you have some model parameters $\theta$. you seek
   to optimize some objective criterion, but the optimization problem is
   intractable or hard in one of the ways listed below. you then apply the
   corresponding transformation to your problem if you can. if your
   problem is now one you can efficiently optimize, great. if not, you can
   recursively apply the transformations until it is.

   update: although i called this post a cookbook, as readers so rightly
   pointed out, it is too light on details to be considered a cookbook.
   consider it as a demonstration of a way of thinking about machine
   learning research as a compiler that compiles an abstract machine
   learning objective into the canonical optimization problem of finding
   stable attractors of a tractable vector field.

   for the first batch, i have written up the following problem
   transformations:
     * [5]variational bounds
     * [6]adversarial games
     * [7]evolution strategies
     * [8]convex relaxation

   there are many more transformations not included here, like the duality
   principle, half-quadratic splitting, lagrangian multipliers, etc. feel
   free to leave comments about what else i should include next.

variational bounds

    typical problem:

   my id168 $f(\theta)$ is intractable to compute, typically
   because it involves intractable marginalization. i can't evaluate it
   let alone minimize it.

    solution:

   let's construct a family of - typically differentiable - upper-bounds:
   $$ f(\theta) \leq \inf_\psi g(\theta, \psi),
   $$ and solve the optimization problem
   $$ \theta^\ast, \psi^\ast \leftarrow \operatorname{argmin}_{\theta,
   \psi} g(\theta, \psi) $$ instead. technically, once optimization is
   finished, you can discard the auxiliary parameter $\psi^\ast$ -
   although often turns out to be meaningful and useful in itself, often
   for approximate id136 such as the recognition model of vaes.

    tricks of the trade:

   jensen's inequality: the mean value of a convex function is never lower
   than the value of the convex function applied to the mean. generally
   appears in some variant of the standard evidence lower bound (elbo)
   derivation below:

   \begin{align} - \log p(x) &= - \log \int p(x,y) dy \\ &= - \log \int
   q(y\vert x) \frac{p(y,x)}{q(y\vert x)}dy \\ &\leq - \int q(y\vert x)
   \log \frac{p(y,x)}{q(y\vert x)} dy \end{align}

   reparametrization trick: in variational id136 we often encounter
   gradients of the form: $$ \frac{\partial}{\partial
   \theta_i}\mathbb{e}_{x \sim q_\theta}\left[f(x, q_\theta(x))\right], $$
   where the pdf of the variable appears in the integrand. if we can find
   a function $h:(\mathcal{e}, \theta)\mapsto \mathcal{x}$ which is
   differentiable w.r.t. its second argument, and id203 distribution
   $p_\epsilon$ over $\mathcal{e}$ which is easy to sample from, such that
   the following holds:
   $$ x = h(\epsilon, \theta), \epsilon \sim p_\epsilon \iff x \sim
   q_{\theta},
   $$ we can use the following reformulation of integrals we often
   encounter in variational upper bounds.
   $$ \frac{\partial}{\partial \theta_i}\mathbb{e}_{x \sim
   q_\theta}\left[f(x, q_\theta(x))\right] = \mathbb{e}_{\epsilon \sim
   p_\epsilon}\left[ \frac{\partial}{\partial \theta_i} f(h(\epsilon,
   \theta), q_\epsilon(h(\epsilon, \theta)))\right] $$ a monte carlo
   estimators to this expectation typically have substantially lower
   variance than reinforce estimators to the same quantity.

adversarial games

    typical problem:

   i can't estimate my id168 $f(\theta)$ directly from samples,
   typically because the id168 depends on the pdf of the data
   distribution or that of my model, or both.

    solution:

   we can sometimes construct an approximation so that
   $$ f(\theta) \approx h(\theta, \operatorname{argmin}_\psi g(\theta,
   \psi)),
   $$ and then we can solve the problem of finding a stable equilibrium of
   the two-player game where players minimize losses $g$ and $h$ with
   respect to $\psi$ and $\theta$, respectively.
   sometimes, the approximations may come in the form of lower-bounds,
   which is the case when $h=-g$:
   $$ f(\theta) \geq \sup_\psi g(\theta, \psi),
   $$ in which case we can solve the following minimax problem instead:
   $$ \theta^\ast \leftarrow \operatorname{argmin}_{\theta} \max_{\psi}
   g(\theta, \psi) $$

    tricks of the trade:

   bayes optimality in auxiliary tasks: when your id168 depends on
   densities of id203 distributions you can easily sample from,
   often you can construct an auxiliary task, whose bayes optimal solution
   depends on values of the densities in question. examples of auxiliary
   tasks are: binary classification for likelihood ratio estimation,
   denoising or score matching for estimating the score function.

   convex conjugate: in case your id168 involves convex functional
   of the densities (such as in f-divergences), you can transform your
   problem by re-expressing it in terms of the convex conjugate. the
   expression for $f$ in terms of its convex conjugate $f^{\ast}$ is:
   \begin{align} f(u) &= \sup_{v \in \operatorname{dom}(f^{\ast})} \{
   \langle u, v \rangle - f^{\ast}(v) \} \\
   &\geq \sup_{\psi} \{ \langle u, v_\psi \rangle - f(v_\psi) \},
   \end{align} note that if $u$ is a density function, then the inner
   product $\langle u,v_\psi\rangle$ is the expectation of $v_\psi$, which
   can be approximated by monte carlo sampling.

evolution strategies

    typical problem

   my $f(\theta)$ is easy to evaluate but hard to optimize, perhaps
   because it contains discrete operations, or the function is piecewise
   constant. id26 is not possible.

    solution

   observe that for any id203 distribution $p_\psi$ over $\theta$
   the following holds:
   $$ \min_{\theta}f(\theta) \leq \min_{\psi} \mathbb{e}_{\theta\sim
   p_\psi} f(\theta) $$ therefore in es we concentrate of the following
   optimization problem instead:
   $$ \psi^{\ast} \leftarrow \operatorname{argmin}_{\psi}
   \mathbb{e}_{\theta\sim p_\psi} f(\theta) $$ often, depending on the
   function $f$ and class of distributions $p_\psi$, a local minimum of
   $f$ can be recovered from a local minimum of $\psi$.

    tricks of the trade

   reinforce gradient estimator: it relies on the following trick $$
   \frac{\partial}{\partial \psi_i} \mathbb{e}_{\theta\sim
   p_\psi}[f(\theta)] = \mathbb{e}_{\theta \sim
   p_\psi}\left[\frac{\partial}{\partial \psi_i}\log
   p_\psi(\theta)f(\theta)\right], $$ where the rhs can be easily
   approximated by monte carlo. the variance of monte carlo reinforce
   estimators tends to be quite high.

convex relaxation

    typical problem

   my $f(\theta)$ is hard to optimize, because it has non-differentiable
   and non-convex components like the $\ell_0$-norm of a vector in sparse
   methods, or the heaviside step function in classification.

    solution

   replace the non-convex component by a convex approximation, turning
   your objective into a now typically convex $g$
   $$ f(\theta) \approx g(\theta)
   $$

    tricks of the trade:

   $\ell_1$ loss: in many sparse learning situations we wish to minimize
   counts of non-zero entries in a vector, which is known as $\ell_0$
   loss. you can typically replace this by the $\ell_1$ norm of the
   vector.

   hinge loss and large margin methods: the error rate of a binary
   classifier under zero-one loss, the objective is typically a piecewise
   constant function of the parameters of a classifier and is thus hard to
   optimize. we can replace the zero-one-loss with the hinge loss, which
   can be understood as a convex upper bound. the resulting optimization
   problem will have a tendency to maximize the classifier's margin.

     * [9]email
     * [10]facebook
     * [11]twitter
     * [12]linkedin
     * tumblr
     * [13]reddit
     * [14]google+
     * pinterest
     * [15]pocket

   please enable javascript to view the [16]comments powered by disqus.

      2019 id136. all rights reserved. powered by [17]ghost. [18]crisp
   theme by [19]kathy qian.

references

   visible links
   1. https://www.id136.vc/rss/
   2. https://www.id136.vc/
   3. https://www.id136.vc/
   4. https://www.id136.vc/
   5. https://www.id136.vc/design-patterns/#variationalupperbounds
   6. https://www.id136.vc/design-patterns/#adversarialgames
   7. https://www.id136.vc/design-patterns/#evolutionstrategies
   8. https://www.id136.vc/design-patterns/#convexrelaxation
   9. mailto:?subject=a cookbook for machine learning: vol 1&body=https://www.id136.vc/design-patterns/
  10. https://www.facebook.com/sharer/sharer.php?u=https://www.id136.vc/design-patterns/
  11. http://twitter.com/home?status=a cookbook for machine learning: vol 1 https://www.id136.vc/design-patterns/
  12. http://www.linkedin.com/sharearticle?mini=true&url=https://www.id136.vc/design-patterns/&title=a cookbook for machine learning: vol 1&summary=this was a busy week, i had no time to read anything new, so i'm sharing a note that i wrote for myself, for no other reason than to understand things better. it's a kind of cookbook of various
  13. http://www.reddit.com/submit?url=https://www.id136.vc/design-patterns/
  14. https://plus.google.com/share?url=https://www.id136.vc/design-patterns/
  15. https://getpocket.com/save?url=https://www.id136.vc/design-patterns/
  16. https://disqus.com/?ref_noscript
  17. http://ghost.org/
  18. https://github.com/kathyqian/crisp
  19. http://kathyqian.com/

   hidden links:
  21. https://www.id136.vc/design-patterns/
  22. https://twitter.com/fhuszar
  23. http://linkedin.com/in/username
  24. mailto:you@example.com
  25. https://www.id136.vc/rss
