   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]stats and bots
     * [9]data science
     * [10]analytics
     * [11]startups
     * [12]bots
     * [13]design
     * [14]subscribe
     * [15]     cube.js framework
     __________________________________________________________________

neural networks for beginners: popular types and applications

an introduction to neural networks learning

   [16]go to the profile of jay shah
   [17]jay shah (button) blockedunblock (button) followfollowing
   nov 16, 2017

   today, neural networks are used for solving many business problems such
   as sales forecasting, customer research, data validation, and risk
   management. for example, at [18]statsbot we apply neural networks for
   time series predictions, anomaly detection in data, and natural
   language understanding.

   in this post, we   ll explain what neural networks are, the main
   challenges for beginners of working on them, popular types of neural
   networks, and their applications. we   ll also describe how you can apply
   neural networks in different industries and departments.

         watch my webinar series on    [19]machine learning for
   beginners            aimed at helping machine learning/ai enthusiasts
   understand how to pursue their career, what lies ahead for them by
   interviewing several successful engineers.
   [1*xfa-g_bxeyyhyz3sli6m2g.jpeg]

the idea of how neural networks work

   recently there has been a great buzz around the words    neural network   
   in the field of computer science and it has attracted a great deal of
   attention from many people. but what is this all about, how do they
   work, and are these things really beneficial?

   essentially, neural networks are composed of layers of computational
   units called neurons, with connections in different layers. these
   networks transform data until they can classify it as an output. each
   neuron multiplies an initial value by some weight, sums results with
   other values coming into the same neuron, adjusts the resulting number
   by the neuron   s bias, and then normalizes the output with an activation
   function.
   [0*frlff7mtj86ecg02.]

iterative learning process

   a key feature of neural networks is an iterative learning process in
   which records (rows) are presented to the network one at a time, and
   the weights associated with the input values are adjusted each time.
   after all cases are presented, the process is often repeated. during
   this learning phase, the network trains by adjusting the weights to
   predict the correct class label of input samples.

   advantages of neural networks include their high tolerance to noisy
   data, as well as their ability to classify patterns on which they have
   not been trained. the most popular neural network algorithm is the
   [20]id26 algorithm.

   once a network has been structured for a particular application, that
   network is ready to be trained. to start this process, the initial
   weights (described in the next section) are chosen randomly. then the
   training (learning) begins.

   the network processes the records in the    training set    one at a time,
   using the weights and functions in the hidden layers, then compares the
   resulting outputs against the desired outputs. errors are then
   propagated back through the system, causing the system to adjust the
   weights for application to the next record.

   this process occurs repeatedly as the weights are tweaked. during the
   training of a network, the same set of data is processed many times as
   the connection weights are continually refined.

so what   s so hard about that?

   one of the challenges for beginners in learning neural networks is
   understanding what exactly goes on at each layer. we know that after
   training, each layer extracts higher and higher-level features of the
   dataset (input), until the final layer essentially makes a decision on
   what the input features refer to. how can it be done?

   instead of exactly prescribing which feature we want the network to
   amplify, we can let the network make that decision. let   s say we simply
   feed the network an arbitrary image or photo and let the network
   analyze the picture. we then pick a layer and ask the network to
   enhance whatever it detected. each layer of the network deals with
   features at a different level of abstraction, so the complexity of
   features we generate depends on which layer we choose to enhance.

popular types of neural networks and their usage

   in this post on neural networks for beginners, we   ll look at
   autoencoders, convolutional neural networks, and recurrent neural
   networks.

autoencoders

   this approach is based on the observation that random initialization is
   a bad idea and that pre-training each layer with an unsupervised
   learning algorithm can allow for better initial weights. examples of
   such unsupervised algorithms are id50. there are a few
   recent research attempts to revive this area, for example, using
   variational methods for probabilistic autoencoders.

   they are rarely used in practical applications. recently, batch
   id172 started allowing for even deeper networks, we could train
   arbitrarily deep networks from scratch using residual learning. with
   appropriate dimensionality and sparsity constraints, autoencoders can
   learn data projections that are more interesting than pca or other
   basic techniques.

   let   s look at the two interesting practical applications of
   autoencoders:

       in [21]data denoising a denoising autoencoder constructed using
   convolutional layers is used for efficient denoising of medical images.
   [0*kstpix2n_kekx2pz.]

   a stochastic corruption process randomly sets some of the inputs to
   zero, forcing the denoising autoencoder to predict missing (corrupted)
   values for randomly selected subsets of missing patterns.

       [22]id84 for data visualization attempts
   dimensional reduction using methods such as principle component
   analysis (pca) and t-distributed stochastic neighbor embedding (id167).
   they were utilized in conjunction with neural network training to
   increase model prediction accuracy. also, mlp neural network prediction
   accuracy depended greatly on neural network architecture,
   pre-processing of data, and the type of problem for which the network
   was developed.

convolutional neural networks

   convnets derive their name from the    convolution    operator. the primary
   purpose of convolution in the case of a convnet is to extract features
   from the input image. convolution preserves the spatial relationship
   between pixels by learning image features using small squares of input
   data. convnets have been successful in such fields as:
     * [23]identifying faces

   in the identifying faces work, they have used a id98 cascade for fast
   face detection. the detector evaluates the input image at low
   resolution to quickly reject non-face regions and carefully process the
   challenging regions at higher resolution for accurate detection.
   [0*xjacadaqdbcwnoco.]
   [24]illustration source

   calibration nets were also introduced in the cascade to accelerate
   detection and improve bounding box quality.
   [0*3v3ipnyisu70v6qq.]
   [25]illustration source
     * [26]self driving cars

   in the self driving cars project, depth estimation is an important
   consideration in autonomous driving as it ensures the safety of the
   passengers and of other vehicles. such aspects of id98 usage have been
   applied in projects like nvidia   s autonomous car.

   id98   s layers allow them to be extremely versatile because they can
   process inputs through multiple parameters. subtypes of these networks
   also include id50 (dbns). convolutional neural networks
   are traditionally used for image analysis and object recognition.
   [0*pecsauwwmhwmm3qo.]
   [27]illustration source

   and for fun, a link to use id98s to d[28]rive a car in a game simulator
   and predict steering angle.

recurrent neural networks

   id56s can be trained for sequence generation by processing real data
   sequences one step at a time and predicting what comes next. here is
   the guide on [29]how to implement such a model.

   assuming the predictions are probabilistic, novel sequences can be
   generated from a trained network by iteratively sampling from the
   network   s output distribution, then feeding in the sample as input at
   the next step. in other words, by making the network treat its
   inventions as if they were real, much like a person dreaming.
   [0*haqm5ah9bmh_jwmk.]

       [30]language-driven image generation

   can we learn to generate handwriting for a given text? to meet this
   challenge a soft window is convolved with the text string and fed as an
   extra input to the prediction network. the parameters of the window are
   output by the network at the same time as it makes the predictions, so
   that it dynamically determines an alignment between the text and the
   pen locations. put simply, it learns to decide which character to write
   next.
   [0*-md4zutnrhmi0jh2.]

       [31]predictions

   a neural network can be trained to produce outputs that are expected,
   given a particular input. if we have a network that fits well in
   modeling a known sequence of values, one can use it to predict future
   results. an obvious example is stock market prediction.

applying neural networks to different industries

   neural networks are broadly used for real world business problems such
   as sales forecasting, customer research, data validation, and risk
   management.

marketing

   target marketing involves market segmentation, where we divide the
   market into distinct groups of customers with different consumer
   behavior.

   neural networks are well-equipped to carry this out by segmenting
   customers according to basic characteristics including demographics,
   economic status, location, purchase patterns, and attitude towards a
   product. unsupervised neural networks can be used to automatically
   group and segment customers based on the similarity of their
   characteristics, while supervised neural networks can be trained to
   learn the boundaries between customer segments based on a group of
   customers.

retail & sales

   neural networks have the ability to simultaneously consider multiple
   variables such as market demand for a product, a customer   s income,
   population, and product price. forecasting of sales in supermarkets can
   be of great advantage here.

   if there is a relationship between two products over time, say within
   3   4 months of buying a printer the customer returns to buy a new
   cartridge, then retailers can use this information to contact the
   customer, decreasing the chance that the customer will purchase the
   product from a competitor.

banking & finance

   neural networks have been applied successfully to problems like
   derivative securities pricing and hedging, futures price forecasting,
   exchange rate forecasting, and stock performance. traditionally,
   statistical techniques have driven the software. these days, however,
   neural networks are the underlying technique driving the decision
   making.

medicine

   it is a trending research area in medicine and it is believed that they
   will receive extensive application to biomedical systems in the next
   few years. at the moment, the research is mostly on modelling parts of
   the human body and recognising diseases from various scans.

conclusion

   perhaps nns can, though, give us some insight into the    easy problems   
   of consciousness: how does the brain process environmental stimulation?
   how does it integrate information? but, the real question is, why and
   how is all of this processing, in humans, accompanied by an experienced
   inner life, and can a machine achieve such a self-awareness?

   it makes us wonder whether neural networks could become a tool for
   artists         a new way to remix visual concepts         or perhaps even shed a
   little light on the roots of the creative process in general.

   all in all, neural networks have made computer systems more useful by
   making them more human. so next time you think you might like your
   brain to be as reliable as a computer, think again         and be grateful
   you have such a superb neural network already installed in your head!

   i hope that this introduction to neural networks for beginners will
   help you build your first project with nns.

recommended sources for beginners

deep neural networks

     * [32]what is the difference between deep learning and usual machine
       learning?
     * [33]what is the difference between a neural network and a deep
       neural network?
     * [34]how is deep learning different from multilayer id88?

neural networks projects

     * [35]a classic example of mapping input to output image
     * [36]trying out face recognition on your own
     * [37]convolutional neural networks f0r visual recognition
     * [38]online stanford course on id98s

   iframe: [39]/media/02231cd5403151a2a463e36cc3b88462?postid=d99f2235efca

you   d also like:

   [40]how to get all your product launch metrics without leaving slack
   how we used statsbot to track our product launch
   metricsblog.statsbot.co
   [41]sql queries for funnel analysis
   a template for building sql funnel queriesblog.statsbot.co
   [42]how to reduce churn rate by handling stripe failed payments
   how we automated dunning managementblog.statsbot.co

     * [43]machine learning
     * [44]neural networks
     * [45]id158
     * [46]data science
     * [47]recurrent neural network

   (button)
   (button)
   (button) 806 claps
   (button) (button) (button) 2 (button) (button)

     (button) blockedunblock (button) followfollowing
   [48]go to the profile of jay shah

[49]jay shah

   learn. unlearn. relearn.

     (button) follow
   [50]stats and bots

[51]stats and bots

   data stories on machine learning and analytics. from statsbot   s makers.

     * (button)
       (button) 806
     * (button)
     *
     *

   [52]stats and bots
   never miss a story from stats and bots, when you sign up for medium.
   [53]learn more
   never miss a story from stats and bots
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://blog.statsbot.co/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/d99f2235efca
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://blog.statsbot.co/neural-networks-for-beginners-d99f2235efca&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://blog.statsbot.co/neural-networks-for-beginners-d99f2235efca&source=--------------------------nav_reg&operation=register
   8. https://blog.statsbot.co/?source=logo-lo_tgdt9wthkfee---cfc9f21a543a
   9. https://blog.statsbot.co/datascience/home
  10. https://blog.statsbot.co/analytics/home
  11. https://blog.statsbot.co/startups/home
  12. https://blog.statsbot.co/bots/home
  13. https://blog.statsbot.co/design/home
  14. https://blog.statsbot.co/statsbot-digest-b0d7372f842a
  15. https://cube.dev/
  16. https://blog.statsbot.co/@jaygshah22?source=post_header_lockup
  17. https://blog.statsbot.co/@jaygshah22
  18. https://statsbot.co/?utm_source=blog&utm_medium=article&utm_campaign=nn
  19. https://www.youtube.com/playlist?list=pl-oluyics0ck0qdpkuczeuxtq3mnwoff7
  20. http://neuralnetworksanddeeplearning.com/chap2.html
  21. https://pdfs.semanticscholar.org/b224/58b7194458bb8c8a3af4f1d8e8aa4c5b34cb.pdf
  22. http://colah.github.io/posts/2014-10-visualizing-mnist/
  23. https://github.com/mks0601/a-convolutional-neural-network-cascade-for-face-detection
  24. https://github.com/mks0601/a-convolutional-neural-network-cascade-for-face-detection
  25. https://github.com/mks0601/a-convolutional-neural-network-cascade-for-face-detection
  26. http://www.pitt.edu/~budny/papers/77.pdf
  27. http://www.pitt.edu/~budny/papers/77.pdf
  28. https://github.com/sjamthe/self-driving-car-nd-predict-steering-angle-with-id98
  29. http://peterroelants.github.io/posts/id56_implementation_part01/
  30. http://aclweb.org/anthology/w15-2712.pdf
  31. https://in.mathworks.com/help/nnet/ref/predict.html?requesteddomain=www.mathworks.com
  32. https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md
  33. http://stats.stackexchange.com/questions/182734/what-is-the-difference-between-a-neural-network-and-a-deep-neural-network?rq=1
  34. https://www.quora.com/how-is-deep-learning-different-from-multilayer-id88
  35. https://phillipi.github.io/pix2pix/
  36. http://www.face-rec.org/source-codes/
  37. http://cs231n.github.io/python-numpy-tutorial/
  38. http://cs231n.stanford.edu/syllabus.html
  39. https://blog.statsbot.co/media/02231cd5403151a2a463e36cc3b88462?postid=d99f2235efca
  40. https://blog.statsbot.co/product-launch-metrics-8c13b1630804
  41. https://blog.statsbot.co/sql-queries-for-funnel-analysis-35d5e456371d
  42. https://blog.statsbot.co/how-to-reduce-churn-rate-by-27-by-handling-stripe-failed-payments-e75892f8956c
  43. https://blog.statsbot.co/tagged/machine-learning?source=post
  44. https://blog.statsbot.co/tagged/neural-networks?source=post
  45. https://blog.statsbot.co/tagged/artificial-neural-network?source=post
  46. https://blog.statsbot.co/tagged/data-science?source=post
  47. https://blog.statsbot.co/tagged/recurrent-neural-network?source=post
  48. https://blog.statsbot.co/@jaygshah22?source=footer_card
  49. https://blog.statsbot.co/@jaygshah22
  50. https://blog.statsbot.co/?source=footer_card
  51. https://blog.statsbot.co/?source=footer_card
  52. https://blog.statsbot.co/
  53. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  55. https://blog.statsbot.co/product-launch-metrics-8c13b1630804
  56. https://blog.statsbot.co/sql-queries-for-funnel-analysis-35d5e456371d
  57. https://blog.statsbot.co/how-to-reduce-churn-rate-by-27-by-handling-stripe-failed-payments-e75892f8956c
  58. https://medium.com/p/d99f2235efca/share/twitter
  59. https://medium.com/p/d99f2235efca/share/facebook
  60. https://medium.com/p/d99f2235efca/share/twitter
  61. https://medium.com/p/d99f2235efca/share/facebook
