   #[1]github [2]recent commits to bambi:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]30
     * [35]star [36]377
     * [37]fork [38]27

[39]bambinos/[40]bambi

   [41]code [42]issues 29 [43]pull requests 1 [44]projects 0 [45]wiki
   [46]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [47]sign up
   bayesian model-building interface (bambi) in python.
     * [48]407 commits
     * [49]6 branches
     * [50]5 releases
     * [51]fetching contributors
     * [52]mit

    1. [53]python 98.8%
    2. [54]shell 1.2%

   (button) python shell
   branch: master (button) new pull request
   [55]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/b
   [56]download zip

downloading...

   want to be notified of new releases in bambinos/bambi?
   [57]sign in [58]sign up

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [61]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [62]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [63]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [64]bambi [65]fix test warnings ([66]#144[67]) mar 30, 2019
   [68]docs
   [69]examples [70]update notebooks ([71]#140[72]) mar 28, 2019
   [73]scripts
   [74].coveragerc [75]... sep 17, 2016
   [76].gitignore
   [77].travis.yml
   [78]contributing.md
   [79]changelog.md
   [80]license [81]now we have a license. which is important. because some
   misguided but    aug 24, 2016
   [82]readme.md
   [83]conf.py
   [84]requirements-dev.txt
   [85]requirements.txt
   [86]setup.id18
   [87]setup.py

readme.md

bambi

   bayesian model-building interface in python

status

     * [88]build status
     * [89]coverage status

overview

   bambi is a high-level bayesian model-building interface written in
   python. it's built on top of the [90]pymc3 probabilistic programming
   framework, and is designed to make it extremely easy to fit
   mixed-effects models common in social sciences settings using a
   bayesian approach.

installation

   bambi requires a working python interpreter (either 2.7+ or 3+). we
   recommend installing python and key numerical libraries using the
   [91]anaconda distribution, which has one-click installers available on
   all major platforms.

   assuming a standard python environment is installed on your machine
   (including pip), bambi itself can be installed in one line using pip:
pip install bambi

   alternatively, if you want the bleeding edge version of the package,
   you can install from github:
pip install git+https://github.com/bambinos/bambi.git

dependencies

   bambi requires working versions of numpy, pandas, matplotlib, patsy,
   pymc3, and theano. dependencies are listed in requirements.txt, and
   should all be installed by the bambi installer; no further action
   should be required.

table of contents

     * [92]quickstart
     * [93]user guide
          + [94]creating a model
          + [95]model specification
               o [96]formula-based specification
               o [97]incremental specification
               o [98]notes on fixed and random effects in bambi
               o [99]coding of categorical variables
          + [100]fitting the model
               o [101]building the model
          + [102]alternative back-ends
          + [103]specifying priors
               o [104]different ways of specifying priors
               o [105]a note on priors in stan
               o [106]mapping priors onto terms
          + [107]generalized linear mixed models
               o [108]families
          + [109]results
          + [110]accessing back-end objects

quickstart

   suppose we have data for a typical within-subjects psychology
   experiment with 2 experimental conditions. stimuli are nested within
   condition, and subjects are crossed with condition. we want to fit a
   model predicting reaction time (rt) from the fixed effect of condition,
   random intercepts for subjects, random condition slopes for students,
   and random intercepts for stimuli. we can fit this model and summarize
   its results as follows in bambi:
from bambi import model

# assume we already have our data loaded
model = model(data)
results = model.fit('rt ~ condition', random=['condition|subject', '1|stimulus']
, samples=5000, chains=2)
results[1000:].plot()
results[1000:].summary()

user guide

creating a model

   creating a new model in bambi is simple:
from bambi import model
import pandas as pd

# read in a tab-delimited file containing our data
data = pd.read_table('my_data.txt', sep='\t')

# initialize the model
model = model(data)

   typically, we'll initialize a bambi model by passing it a pandas
   dataframe as the only argument. we get back a model that we can
   immediately start adding terms to.

data format

   as with most mixed effect modeling packages, bambi expects data in
   "long" format--meaning that each row should reflect a single
   observation at the most fine-grained level of analysis. for example,
   given a model where students are nested into classrooms and classrooms
   are nested into schools, we would want data with the following kind of
   structure:
   student gender gpa class school
   1       f      3.4 1     1
   2       f      3.7 1     1
   3       m      2.2 1     1
   4       f      3.9 2     1
   5       m      3.6 2     1
   6       m      3.5 2     1
   7       f      2.8 3     2
   8       m      3.9 3     2
   9       f      4.0 3     2

model specification

   bambi provides a flexible way to specify models that makes it easy not
   only to specify the terms

formula-based specification

   models are specified in bambi using a formula-based syntax similar to
   what one might find in r packages like lme4 or nlme. a couple of
   examples that illustrate the breadth of models that can be easily
   specified in bambi:
# fixed effects only
results = model.fit('rt ~ attention + color')

# fixed effects and random intercepts for subject
results = model.fit('y ~ 0 + gender + condition*age', random=['1|subject'])

# multiple, complex random effects with both random slopes and random intercepts
results = model.fit('y ~ 0 + gender', random=['condition|subject', 'condition|si
te'])

   each of the above examples specifies a full model that will immediately
   be fitted using either pymc3 or stan (more on that below).

   notice how, in contrast to lme4 (but similar to nlme), fixed and random
   effects are specified separately in bambi. we describe the syntax and
   operators supported by each type of effect below; briefly, however, the
   fixed effects specification relies on [111]patsy, and [112]hence
   formulas are parsed almost exactly the same way [113]as in r. random
   effects terms must be specified one at a time.

incremental specification

   although models can be fit in one line, as above, an alternative
   approach that is more verbose but sometimes clearer is to enter one or
   more terms into the model incrementally. the add() method takes
   essentially the same arguments as the fit() method, but doesn't
   automatically start compiling and fitting the model.
from bambi import model, prior

# initialize model
model = model(data)

# continuous fixed effect (in this case, a binary indicator);
# will also add intercept automatically unless it is explicitly supppressed.
model.add('condition')

# categorical fixed effect, setting a narrow prior. we explicitly
# name the columns that should be interpreted as categoricals. note that
# if age_group is already represented as a categorical variable in the
# dataframe, the categorical argument is unnecessary. but it's good
# practice to be explicit about what the categorical variables are,
# as users sometimes inadvertently pass numeric columns that are
# intended to be treated as categorical variables, and bambi has
# no way of knowing this.
model.add('age_group', categorical=['age_group'], priors={'age_group': 'narrow'}
)

# random subject intercepts
model.add(random=['subj'], categorical=['subj'])

# random condition slopes distributed over subjects
model.add(random=['0+condition|subj'])

# add outcome variable
model.add('y ~ 0')

# fit the model and save results
results = model.fit()

   as the above example illustrates, the only mandatory argument to add is
   a string giving the name of the dataset column to use for the term. if
   no other arguments are specified, the corresponding variable will be
   modeled as a fixed effect with a normally-distributed prior (a detailed
   explanation of how priors are handled in bambi can be found below). the
   type of variable (i.e., categorical or continuous) will be determined
   based on the dtype of the column in the pandas dataframe, so it's a
   good idea to make sure all variables are assigned the correct dtype
   when you first read in the data. you can also force continuous
   variables to be treated as categorical factors by passing them as a
   list to the categorical argument (e.g., add_term('subject + condition +
   extraversion', categorical=['subject'])).

   to specify that a term should be modeled as a random effect, pass the
   formula to the random argument (e.g., random='1|subj'). the
   specification of random intercepts vs. slopes is handled as in other
   packages, or in the full specification passed to a single fit() call.
   for example, add(random=['1|site', '0+condition|subject']) would add
   random condition slopes distributed over subjects (without subject
   intercepts), as well as random intercepts for sites.

notes on fixed and random effects in bambi

   as noted above, bambi handles fixed and random effects separately. the
   fixed effects specification relies on the [114]patsy package, which
   supports nearly all of the standard formula operators handled in base
   r--including :, *, -, etc. unfortunately, patsy doesn't support
   grouping operators, so random effects are handled separately in bambi.
   all terms must be passed in as elements in a list (though each
   individual term can be as complex as a normal fixed effect
   specification). for example:
random_terms = [
    # random student intercepts
    '1|student',
    # random classroom intercepts
    '1|classroom',
    # random treatment slopes distributed over schools;school intercepts will al
so be automtically added
    'treatment|school',
    # a random set of subject slopes for each level of the combination of factor
s a and b, with subject intercepts excluded
    '0+a*b|subject'
]
model.add(random=random_terms)

coding of categorical variables

   when a categorical fixed effect with n levels is added to a model, by
   default, it is coded by n-1 dummy variables (i.e., reduced-rank
   coding). for example, suppose we write 'y ~ condition + age + gender',
   where condition is a categorical variable with 4 levels, and age and
   gender are continuous variables. then our model would contain an
   intercept term (added to the model by default, as in r), three
   dummy-coded variables (each contrasting the first level of condition
   with one of the subsequent levels), and continuous predictors for age
   and gender. suppose, however, that we would rather use full-rank coding
   of conditions. if we explicitly remove the intercept--as in 'y ~ 0 +
   condition + age + gender'--then we get the desired effect. now, the
   intercept is no longer included, and condition will be coded using 4
   dummy indicators--each one coding for the presence or absence of the
   respective condition, without reference to the other conditions.

   random effects are handled in a comparable way. when adding random
   intercepts, coding is always full-rank (e.g., when adding random
   intercepts for 100 schools, one gets 100 dummy-coded indicators coding
   each school separately, and not 99 indicators contrasting each school
   with the very first one). for random slopes, coding proceeds the same
   way as for fixed effects. the random effects specification
   ['condition|subject'] would add an intercept for each subject, plus n-1
   condition slopes (each coded with respect to the first, omitted, level
   as the referent). if we instead specify ['0+condition|subject'], we get
   n condition slopes and no intercepts.

fitting the model

   once a model is fully specified, we need to run the pymc3 or stan
   sampler to generate parameter estimates. if we're using the one-line
   fit() interface, sampling will begin right away (by default, using the
   pymc3 back-end):
model = model(data)
results = model.fit('rt ~ condition + gender + age', random='condition|subject')

   the above code will obtain 1,000 samples (the default value) and return
   them as a modelresults instance (for more details, see the [115]results
   section). in this case, the fit() method accepts optional keyword
   arguments to pass onto pymc3's sample() method, so any methods accepted
   by sample() can be specified here. we can also explicitly set the
   number of samples via the samples argument. for example, if we call
   fit('y ~ x1', samples=2000, chains=2), the pymc3 sampler will sample
   two chains in parallel, drawing 2,000 samples for each one. we could
   also specify starting parameter values, the step function to use, and
   so on (for full details, see the [116]pymc3 documentation).

   alternatively, if we're building our model incrementally, we can
   specify our model in steps, and only call fit() once the model is
   complete:
model = model(data)
model.add('food_type', categorical=['food_type'])
model.add(random='1|subject')
...
results = model.fit(samples=5000)

building the model

   when fit() is called, bambi internally performs two separate steps.
   first, the model is built or compiled, via a build() call. during the
   build, the pymc3 model is compiled by theano, in order to optimize the
   underlying theano graph and improve sampling efficiency. this process
   can be fairly time-consuming, depending on the size and complexity of
   the model. it's possible to build the model explicitly, without
   beginning the sampling process, by calling build() directly on the
   model:
model = model(data)
model.add('rt ~ condition + gender + age', random='condition|subject')
model.build()

   alternatively, the same result can be achieved using the run argument
   to fit():
model = model(data)
model.fit('rt ~ condition + gender + age', random='condition|subject', run=false
)

   in both of the above cases, sampling won't actually start until fit()
   is called (in the latter case, a second time). the only difference
   between the two above snippets is that the former will compile the
   model (note the explicit build() call) whereas the latter will not.

   building without sampling can be useful if we want to inspect the
   internal pymc3 model before we start the (potentially long) sampling
   process. once we're satisfied, and wish to run the sampler, we can then
   simply call model.fit(), and the sampler will start running.

alternative back-ends

   bambi defaults to using the nuts mcmc sampler implemented in the pymc3
   package for all model-fitting. however, bambi also supports the stan
   mcmc sampling package, via the [117]pystan interface. to switch from
   pymc3 to stan, all you have to do is specify backend='stan' in the fit
   call:
model = model(data)
results = model.fit('rt ~ condition + gender + age', random='condition|subject',
 backend='stan')

   from the user's standpoint, the change from pymc3 to stan (or vice
   versa) will usually be completely invisible. unless we want to muck
   around in the internals of the backends, the api is identical no matter
   which back-end we're using. this frees us up to easily compare
   different back-ends in terms of speed and/or estimates (assuming the
   sampler has converged, the two back-ends shoul produce virtually
   identical estimates for all models, but performance could theoretically
   differ).

which back-end should i use?

   pymc3 and stan are both under active and intensive development, so the
   pros and cons of using either back-end may change over time. however,
   as of this writing (march 2017), our general sense is that stan is
   typically faster than pymc3 (in terms of both compilation and sampling
   time), but offers less flexibility when called from bambi. the
   decreased flexibility is not due to inherent limitations in stan
   itself, but reflects the fact that pymc3 has the major advantage of
   being written entirely in python. this means that bambi is much more
   tightly integrated with pymc3, and users can easily take advantage of
   virtually all of pymc3's functionality. indeed, reaching into bambi for
   the pymc model and multitrace is trivial:
# initialize and fit bambi model
import bambi as bm
import pymc3 as pm
model = bm.model('data.csv')
results = model.fit(...)   # we fit some model

# grab the pymc3 model object and the fitted multitrace
pm_model = model.backend.model
pm_trace = model.backend.trace

# now we can use any pymc3 method that operates on multitraces
pm.traceplot(pm_trace)

   as [118]discussed below for details), a secondary benefit of using
   pymc3 rather than stan is that users have much greater flexibility
   regarding the choice of priors when using the former back-end.

   in general, then, our recommendation is that most users are better off
   sticking with the pymc3 back-end unless the model being fit is
   relatively large and involves no unusual priors, at which point it is
   worth experimenting with the stan back-end to see if significant speed
   gains can be obtained.

specifying priors

   bayesian id136 requires one to specify prior id203
   distributions that represent the analyst's belief (in advance of seeing
   the data) about the likely values of the model parameters. in practice,
   analysts often lack sufficient information to formulate well-defined
   priors, and instead opt to use "weakly informative" priors that mainly
   serve to keep the model from exploring completely pathological parts of
   the parameter space (e.g., when defining a prior on the distribution of
   human heights, a value of 3,000 cms should be assigned a id203 of
   exactly 0).

   by default, bambi will intelligently generate weakly informative priors
   for all model terms, by loosely scaling them to the observed data
   (details can be found in [119]this article. while the default priors
   will behave well in most typical settings, there are many cases where
   an analyst will want to specify their own priors--and in general, when
   informative priors are available, it's a good idea to use them.

different ways of specifying priors

   bambi provides two ways to specify a custom prior. first, one can
   manually specify only the scale of the prior, while retaining the
   default distribution. by default, bambi sets "weakly informative"
   priors on all fixed and random effects. priors are specified on a
   (generalized) partial correlation scale that quantifies the expected
   standardized contribution of each individual term to the outcome
   variable when controlling for other terms. the default "wide" setting
   sets the scale of a fixed effect prior to sqrt(1/3) = 0.577 on the
   partial correlation scale, which is the standard deviation of a flat
   prior from -1 to +1. this correlation-level scale value then gets
   translated to a normal prior at the slope level, centered on 0 by
   default, with a correspondingly wide variance. this process results in
   a weakly informative (rather than non-informative) prior distribution
   whose width can be tuned in a simple, intuitive way. more detailed
   information about how the default priors work can be found in [120]this
   technical paper.

   in cases where we want to keep the default prior distributions, but
   alter their scale, we can specify either a numeric scale value or pass
   the name of a predefined constant. for example:
model = model(data)
# add condition to the model as a fixed effect with a very wide prior
model.add('condition', prior='superwide')

# add random subject intercepts to the model, with a narrow prior on their stand
ard deviation
model.add(random='1|subject', prior=0.1)

   predefined named scales include "superwide" (scale = 0.8), "wide"
   (0.577; the default), "medium" (0.4), and "narrow" (0.2). the
   theoretical maximum scale value is 1.0, which specifies a distribution
   of partial correlations with half of the values at -1 and the other
   half at +1. scale values closer to 0 are considered more "informative"
   and tend to induce more shrinkage in the parameter estimates.

   the ability to specify prior scales this way is helpful, but also
   limited: we will sometimes find ourselves wanting to use something
   other than a normal distribution to model our priors. fortunately,
   bambi is built on top of pymc3, which means that we can seaid113ssly use
   any of the over 40 distribution classes defined in pymc3. we can
   specify such priors in bambi using the prior class, which initializes
   with a name argument (which must map on exactly to the name of a valid
   pymc3 distribution) followed by any of the parameters accepted by the
   corresponding distribution. for example:
from bambi import prior

# a laplace prior with mean of 0 and scale of 10
my_favorite_prior = prior('laplace', mu=0., b=10)

# set the prior when adding a term to the model;
# more details on this below.
priors = {'1|subject': my_favorite_prior}
results = model.fit('y ~ condition', random='1|subject', priors=priors)

   priors specified using the prior class can be nested to arbitrary
   depths--meaning, we can set any of a given prior's argument to point to
   another prior instance. this is particularly useful when specifying
   hierarchical priors on random effects, where the individual random
   slopes or intercepts are constrained to share a common source
   distribution:
subject_sd = prior('halfcauchy', beta=5)
subject_prior = prior('normal', mu=0, sd=subject_sd)
priors = {'1|subject': my_favorite_prior}
results = model.fit('y ~ condition', random='1|subject', priors=priors)

   the above prior specification indicates that the individual subject
   intercepts are to be treated as if they are randomly sampled from the
   same underlying normal distribution, where the variance of that normal
   distribution is parameterized by a separate hyperprior (a half-cauchy
   with beta = 5).

a note on priors in stan

   the above discussion assumes that one is using the pymc3 backend for
   model fitting. although custom priors can be specified using the same
   syntax when using the stan backend, the variety of supported prior
   distributions is much more limited (the technical reason for this is
   that the stan back-end requires us to explicitly add each distribution
   we wish to support, whereas the pymc3 backend is able to seaid113ssly and
   automatically use any distribution supported within pymc3). if you plan
   to use uncommon distributions for your priors, we encourage you to use
   the pymc3 back-end (which is also the default   so if you didn't
   explicitly specify the back-end, you're probably already using pymc3).
   note also that regardless of which backend you use, all prior
   distributions use the names found in pymc3, and not in stan or any
   other package (e.g., in stan, a half-cauchy prior is specified as a
   full cauchy prior with a lower bound of 0, but in bambi, you would use
   the pymc3 convention and pass a 'halfcauchy' prior).

mapping priors onto terms

   once we've defined custom priors for one or more term, we need to map
   them onto those terms in our model. bambi allows us to do this
   efficiently by passing a dictionary of term -> prior mappings in any
   fit() or add() call (and also via a separate set_priors() method on the
   model class). the keys of the dictionary the names of terms, and the
   values are the desired priors. there are also fixed and random
   arguments that make it easy to apply the same priors to all fixed or
   random effects in the model. some examples:
model = model(data)

# example 1: set each prior by name. note that we can set the same
# prior for multiple terms at once, by passing a tuple in the key.
priors = {
    'x1': 0.3,
    'x2': 'normal',
    ('x3', 'x4'): prior('zeroinflatedpoisson', theta=10, psi=0.5)
}
results = model.fit('y ~ x1 + x2', random=['1|x3', '1|x4'], priors=priors)

# example 2: specify priors for all fixed effects and all random effects,
# except for x1, which still gets its own custom prior.
priors = {'x1': 0.3, 'fixed': prior('normal', sd=100), 'random': 'wide'}
results = model.fit('y ~ x1 + x2', random=['1|x3', '1|x4'], priors=priors)

   notice how this interface allows us to specify terms either by name
   (including passing tuples as keys in cases where we want multiple terms
   to share the same prior), or by term type (i.e., to set the same prior
   on all fixed or random effects). if we pass both named priors and fixed
   or random effects defaults, the former will take precedence over the
   latter (in the above example, the prior for 'x1' will be 0.3).

   if we prefer, we can also set priors outside of the fit() (or add())
   calls, using the set_priors method:
# specify model but don't build/sample just yet
model.fit('y ~ x1 + x3 + x4', random='1|x2', run=false)

# specify priors   produces same result as in example 2 above
model.set_priors({'x1': 0.3}, fixed=prior('normal', sd=100), random='wide')

# now sample
results = model.fit(samples=5000)

   here we stipulate that terms x1 and x4 will use the same normal prior,
   x2 will use a different normal prior with a uniform hyperprior on its
   standard deviation, and all other fixed effects will use the default
   prior with a scale of 0.5.

   it's important to note that explicitly setting priors by passing in
   prior objects will disable bambi's default behavior of scaling priors
   to the data in order to ensure that they remain weakly informative.
   this means that if you specify your own prior, you have to be sure not
   only to specify the distribution you want, but also any relevant scale
   parameters. for example, the 0.5 in prior('normal', mu=0, sd=0.5) will
   be specified on the scale of the data, not the bounded partial
   correlation scale that bambi uses for default priors. this means that
   if your outcome variable has a mean value of 10,000 and a standard
   deviation of, say, 1,000, you could potentially have some problems
   getting the model to produce reasonable estimates, since from the
   perspective of the data, you're specifying an extremely strong prior.

generalized linear mixed models

   bambi supports the construction of mixed models with non-normal
   response distributions (i.e., generalized linear mixed models, or
   glmms). glmms are specified in the same way as lmms, except that the
   user must specify the distribution to use for the response, and
   (optionally) the link function with which to transform the linear model
   prediction into the desired non-normal response. the easiest way to
   construct a glmm is to simple set the family argument in the fit()
   call:
model = model(data)
results = model.fit('graduate ~ attendance_record + gpa', random='1|school', fam
ily='bernoulli')

   if no link argument is explicitly set (see below), the canonical link
   function (or an otherwise sensible default) will be used. the following
   table summarizes the currently available families and their associated
   links (the default is gaussian):
   family name response distribution default link
   gaussian    normal                identity
   bernoulli   bernoulli             logit
   poisson     poisson               log

families

   following the convention used in many r packages, the response
   distribution to use for a glmm is specified in a family class that
   indicates how the response variable is distributed, as well as the link
   function transforming the linear response to a non-linear one. although
   the easiest way to specify a family is by name, using one of the
   options listed in the table above, users can also create and use their
   own family, providing enormous flexibility (note, again, that custom
   specifications are only guaranteed to work with the pymc3 back-end;
   results may be unpredictable [121]when using stan). in the following
   example, we show how the built-in 'bernoulli' family could be
   constructed on-the-fly:
from bambi import family, prior
import theano.tensor as tt

# specify how the bernoulli p parameter is distributed
prior_p = prior('beta', alpha=2, beta=2)

# the response variable distribution
prior = prior('bernoulli', p=prior_p)

# set the link function. alternatively, we could just set
# the link to 'logit', since it's already built into bambi.
# note that we could pass in our own function here; the link
# function doesn't have to be predefined.
link = tt.nnet.sigmoid

# construct the family
new_fam = family('bernoulli', prior=prior, link=link, parent='p')

# now it's business as usual
model = model(data)
results = model.fit('graduate ~ attendance_record + gpa', random='1|school', fam
ily=new_fam)

   the above example produces results identical to simply setting
   family='bernoulli'.

   one (minor) complication in specifying a custom family is that the link
   function must be able to operate over theano tensors rather than numpy
   arrays, so you'll probably need to rely on tensor operations provided
   in theano.tensor (many of which are also wrapped by pymc3) when
   defining a new link.

results

   when a model is fitted, it returns a modelresults object (usually of
   subclass mcmcresults) containing methods for plotting and summarizing
   results. at present, functionality here is fairly limited; bambi only
   provides basic plotting and summarization tools.

plotting

   to visualize a pymc3-generated plot of the posterior estimates and
   sample traces for all parameters, simply call the mcmcresults object's
   .plot() method:
model = model(data)
results = model.fit('value ~ condition', random='1|uid', samples=1250, chains=4)
# drop the first 100 burn-in samples from each chain and plot
results[100:].plot()

   this produces a plot like the following: [122]sample trace plot

   more details on this plot are available in the [123]pymc3
   documentation.

summarizing

   if you prefer numerical summaries of the posterior estimates, you can
   use the .summary() method, which provides a pandas dataframe with some
   key summary and diagnostic info on the model parameters, such as the
   95% highest posterior density intervals:
results[100:].summary()

   [124]sample summary

   by default the .summary() method hides the random effects (which can
   easily clutter the output when there are many of them) and transformed
   variables of parameters that are used internally during the model
   estimation, but you can view all of these by adjusting the arguments to
   ranefs and transformed, respectively:
results[100:].summary(ranefs=true)
results[100:].plot(transformed=true)

   if you want to view summaries or plots for only specific parameters,
   you can pass a list of parameter names inside the brackets in addition
   to the slice operator:
# show the names of all parameters stored in the mcmcresults object
results.names

# these two calls are equivalent
results[100:, ['intercept', 'condition']].plot()
results[['intercept', 'condition'], 100:].plot()

   and if you want to access the mcmc samples directly, you can use the
   .to_df() method to retrieve the mcmc samples (after concatening any
   separate mcmc chains) in a nice, neat pandas dataframe:
results[100:].to_df(ranefs=true)

   you can find detailed, worked examples of fitting bambi models and
   working with the results in the example notebooks [125]here.

accessing back-end objects

   bambi is just a high-level interface to other statistical packages; as
   such, it uses other packages as computational back-ends. internally,
   bambi stores virtually all objects generated by backends like pymc3,
   making it easy for users to retrieve, inspect, and modify those
   objects. for example, the model class created by pymc3 (as opposed to
   the bambi class of the same name) is accessible from
   model.backend.model. for models fitted with a pymc3 sampler, the
   resulting multitrace object is stored in model.backend.trace (though it
   can also be accessed via bambi's modelresults instance).

     *    2019 github, inc.
     * [126]terms
     * [127]privacy
     * [128]security
     * [129]status
     * [130]help

     * [131]contact github
     * [132]pricing
     * [133]api
     * [134]training
     * [135]blog
     * [136]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [137]reload to refresh your
   session. you signed out in another tab or window. [138]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/bambinos/bambi/commits/master.atom
   3. https://github.com/bambinos/bambi#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/bambinos/bambi
  32. https://github.com/join
  33. https://github.com/login?return_to=/bambinos/bambi
  34. https://github.com/bambinos/bambi/watchers
  35. https://github.com/login?return_to=/bambinos/bambi
  36. https://github.com/bambinos/bambi/stargazers
  37. https://github.com/login?return_to=/bambinos/bambi
  38. https://github.com/bambinos/bambi/network/members
  39. https://github.com/bambinos
  40. https://github.com/bambinos/bambi
  41. https://github.com/bambinos/bambi
  42. https://github.com/bambinos/bambi/issues
  43. https://github.com/bambinos/bambi/pulls
  44. https://github.com/bambinos/bambi/projects
  45. https://github.com/bambinos/bambi/wiki
  46. https://github.com/bambinos/bambi/pulse
  47. https://github.com/join?source=prompt-code
  48. https://github.com/bambinos/bambi/commits/master
  49. https://github.com/bambinos/bambi/branches
  50. https://github.com/bambinos/bambi/releases
  51. https://github.com/bambinos/bambi/graphs/contributors
  52. https://github.com/bambinos/bambi/blob/master/license
  53. https://github.com/bambinos/bambi/search?l=python
  54. https://github.com/bambinos/bambi/search?l=shell
  55. https://github.com/bambinos/bambi/find/master
  56. https://github.com/bambinos/bambi/archive/master.zip
  57. https://github.com/login?return_to=https://github.com/bambinos/bambi
  58. https://github.com/join?return_to=/bambinos/bambi
  59. https://desktop.github.com/
  60. https://desktop.github.com/
  61. https://developer.apple.com/xcode/
  62. https://visualstudio.github.com/
  63. https://github.com/bambinos/bambi/tree/b69f3d7870b07276ab692df107892da5892df32b
  64. https://github.com/bambinos/bambi/tree/master/bambi
  65. https://github.com/bambinos/bambi/commit/c3b5d092c9f73a9568bc8fe563799436298dbdb9
  66. https://github.com/bambinos/bambi/pull/144
  67. https://github.com/bambinos/bambi/commit/c3b5d092c9f73a9568bc8fe563799436298dbdb9
  68. https://github.com/bambinos/bambi/tree/master/docs
  69. https://github.com/bambinos/bambi/tree/master/examples
  70. https://github.com/bambinos/bambi/commit/c7b93b4e145a5777fad96697202d28b430dab482
  71. https://github.com/bambinos/bambi/pull/140
  72. https://github.com/bambinos/bambi/commit/c7b93b4e145a5777fad96697202d28b430dab482
  73. https://github.com/bambinos/bambi/tree/master/scripts
  74. https://github.com/bambinos/bambi/blob/master/.coveragerc
  75. https://github.com/bambinos/bambi/commit/9e13ff11c281a0d3d9354fd65b49a11a3cc436f7
  76. https://github.com/bambinos/bambi/blob/master/.gitignore
  77. https://github.com/bambinos/bambi/blob/master/.travis.yml
  78. https://github.com/bambinos/bambi/blob/master/contributing.md
  79. https://github.com/bambinos/bambi/blob/master/changelog.md
  80. https://github.com/bambinos/bambi/blob/master/license
  81. https://github.com/bambinos/bambi/commit/e2d80fb7a605052e5423dedb8f14870f3dcd7efa
  82. https://github.com/bambinos/bambi/blob/master/readme.md
  83. https://github.com/bambinos/bambi/blob/master/conf.py
  84. https://github.com/bambinos/bambi/blob/master/requirements-dev.txt
  85. https://github.com/bambinos/bambi/blob/master/requirements.txt
  86. https://github.com/bambinos/bambi/blob/master/setup.id18
  87. https://github.com/bambinos/bambi/blob/master/setup.py
  88. https://travis-ci.org/bambinos/bambi
  89. https://coveralls.io/github/bambinos/bambi?branch=master
  90. https://github.com/pymc-devs/pymc3
  91. https://www.continuum.io/downloads
  92. https://github.com/bambinos/bambi#quickstart
  93. https://github.com/bambinos/bambi#user-guide
  94. https://github.com/bambinos/bambi#creating-a-model
  95. https://github.com/bambinos/bambi#model-specification
  96. https://github.com/bambinos/bambi#formula-based-specification
  97. https://github.com/bambinos/bambi#incremental-specification
  98. https://github.com/bambinos/bambi#notes-on-fixed-and-random-effects-in-bambi
  99. https://github.com/bambinos/bambi#coding-of-categorical-variables
 100. https://github.com/bambinos/bambi#fitting-the-model
 101. https://github.com/bambinos/bambi#building-the-model
 102. https://github.com/bambinos/bambi#alternative-back-ends
 103. https://github.com/bambinos/bambi#specifying-priors
 104. https://github.com/bambinos/bambi#different-ways-of-specifying-priors
 105. https://github.com/bambinos/bambi#a-note-on-priors-in-stan
 106. https://github.com/bambinos/bambi#mapping-priors-onto-terms
 107. https://github.com/bambinos/bambi#generalized-linear-mixed-models
 108. https://github.com/bambinos/bambi#families
 109. https://github.com/bambinos/bambi#results
 110. https://github.com/bambinos/bambi#accessing-back-end-objects
 111. http://patsy.readthedocs.io/en/latest/overview.html
 112. http://patsy.readthedocs.io/en/latest/formulas.html
 113. http://patsy.readthedocs.io/en/latest/r-comparison.html
 114. http://patsy.readthedocs.io/en/latest/overview.html
 115. https://github.com/bambinos/bambi#results
 116. https://pymc-devs.github.io/pymc3/api.html#pymc3.sampling.sample
 117. https://github.com/stan-dev/pystan
 118. https://github.com/bambinos/bambi#a-note-on-priors-in-stan
 119. https://arxiv.org/abs/1702.01201
 120. https://arxiv.org/abs/1702.01201
 121. https://github.com/bambinos/bambi#a-note-on-priors-in-stan
 122. https://github.com/bambinos/bambi/blob/master/bambi/docs/images/sample_traceplot.png
 123. http://pymc-devs.github.io/pymc3/notebooks/getting_started.html#posterior-analysis
 124. https://github.com/bambinos/bambi/blob/master/bambi/docs/images/sample_summary.png
 125. https://github.com/bambinos/bambi/blob/master/examples
 126. https://github.com/site/terms
 127. https://github.com/site/privacy
 128. https://github.com/security
 129. https://githubstatus.com/
 130. https://help.github.com/
 131. https://github.com/contact
 132. https://github.com/pricing
 133. https://developer.github.com/
 134. https://training.github.com/
 135. https://github.blog/
 136. https://github.com/about
 137. https://github.com/bambinos/bambi
 138. https://github.com/bambinos/bambi

   hidden links:
 140. https://github.com/
 141. https://github.com/bambinos/bambi
 142. https://github.com/bambinos/bambi
 143. https://github.com/bambinos/bambi
 144. https://help.github.com/articles/which-remote-url-should-i-use
 145. https://github.com/bambinos/bambi#bambi
 146. https://github.com/bambinos/bambi#status
 147. https://github.com/bambinos/bambi#overview
 148. https://github.com/bambinos/bambi#installation
 149. https://github.com/bambinos/bambi#dependencies
 150. https://github.com/bambinos/bambi#table-of-contents
 151. https://github.com/bambinos/bambi#quickstart
 152. https://github.com/bambinos/bambi#user-guide
 153. https://github.com/bambinos/bambi#creating-a-model
 154. https://github.com/bambinos/bambi#data-format
 155. https://github.com/bambinos/bambi#model-specification
 156. https://github.com/bambinos/bambi#formula-based-specification
 157. https://github.com/bambinos/bambi#incremental-specification
 158. https://github.com/bambinos/bambi#notes-on-fixed-and-random-effects-in-bambi
 159. https://github.com/bambinos/bambi#coding-of-categorical-variables
 160. https://github.com/bambinos/bambi#fitting-the-model
 161. https://github.com/bambinos/bambi#building-the-model
 162. https://github.com/bambinos/bambi#alternative-back-ends
 163. https://github.com/bambinos/bambi#which-back-end-should-i-use
 164. https://github.com/bambinos/bambi#specifying-priors
 165. https://github.com/bambinos/bambi#different-ways-of-specifying-priors
 166. https://github.com/bambinos/bambi#a-note-on-priors-in-stan
 167. https://github.com/bambinos/bambi#mapping-priors-onto-terms
 168. https://github.com/bambinos/bambi#generalized-linear-mixed-models
 169. https://github.com/bambinos/bambi#families
 170. https://github.com/bambinos/bambi#results
 171. https://github.com/bambinos/bambi#plotting
 172. https://github.com/bambinos/bambi#summarizing
 173. https://github.com/bambinos/bambi#accessing-back-end-objects
 174. https://github.com/
