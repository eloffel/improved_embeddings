   #[1]machine learning with chris

   [tr?id=267215900457044&ev=pageview&noscript=1]

   (button) toggle navigation [2]machine learning with chris
     * [3]home
     * [4]about
     * [5]contact

id98 in numpy

let's calculate id98 manually

   posted by chris hoyean song on november 26, 2017

id98 in numpy

   the purpose of this article is to understand internal calculations of
   id98(convolution neural network).

   most of ml applications are actively using id98(convolution neural
   network). it is quite easy to create a id98 layer thanks to google
   tensorflow. but, understanding its internal logic from scratch will
   help you to develop and improve your models.

   i found a great illustration of id98 in stanford cs231n lecture. so, i
   decided to use these inputs (7x7x3) and filter weights (3x3x3) as the
   initial values. also, i   ll derive the 1-step id98 result using
   tensorflow and numpy.

   png

   credit for this image goes to andrej karpathy.

1. setting up the initial values

   first, i   ll set the initial values for id98. we need input values x and
   weights w. the initial values of input values and weights are from the
   above image of stanford cs231n lecture.
import numpy as np
import tensorflow as tf
from tensorflow.python.framework import dtypes

# 1. setting up initial values

x = np.zeros((7, 7, 3))
x[:, :, 0] = np.mat(
    "0 0 0 0 0 0 0;0 0 1 0 1 0 0;0 2 1 0 1 2 0;0 0 2 0 0 1 0;0 2 0 1 0 0 0;0 0 0
 1 2 2 0;0 0 0 0 0 0 0"
).a
x[:, :, 1] = np.mat(
    "0 0 0 0 0 0 0;0 1 0 0 1 1 0;0 0 2 2 1 1 0;0 2 1 2 1 0 0;0 2 1 1 2 2 0;0 1 2
 0 2 2 0;0 0 0 0 0 0 0"
).a
x[:, :, 2] = np.mat(
    "0 0 0 0 0 0 0;0 2 1 1 1 1 0;0 2 2 1 2 1 0;0 1 1 0 2 2 0;0 2 1 2 2 0 0;0 1 2
 2 0 0 0;0 0 0 0 0 0 0"
).a

x = np.reshape(x, (1, 7, 7, 3))
# print("x:",x)

w = np.zeros((3, 3, 3, 2))
w[:, :, 0, 0] = np.mat("0 0 1;-1 1 1;0 1 0").a
w[:, :, 1, 0] = np.mat("1 1 1;0 1 1;0 1 0").a
w[:, :, 2, 0] = np.mat("-1 0 0;-1 1 1;0 -1 0").a

# w1 = np.zeros((3,3,3))
w[:, :, 0, 1] = np.mat("0 0 0;1 1 -1;-1 1 1").a
w[:, :, 1, 1] = np.mat("0 1 -1;1 1 -1;-1 1 -1").a
w[:, :, 2, 1] = np.mat("1 1 0;-1 -1 0;0 -1 1").a

stride = 2
scope = "conv_in_numpy"
act = tf.nn.relu  # activation
pad = 'valid'  # padding
nf = 2  # number of filters
rf = 3  # filter size
b = [1, 0]  # bias

np_o = np.zeros((1, 3, 3, 2))
s = stride


2. convolution in tensorflow

   on this step, i   ll get the 1-step id98 result using tensorflow.
# 2. id98 in tensorflow

print("--- convolution in tensorflow ---")

tf_x = tf.constant(x, dtype=dtypes.float32)

with tf.session() as sess:
    with tf.variable_scope(scope):
        nin = tf_x.get_shape()[3].value
        tf_w = tf.get_variable("w", [rf, rf, nin, nf], initializer=tf.constant_i
nitializer(w))
        tf_b = tf.get_variable(
            "b", [nf],
            initializer=tf.constant_initializer(b, dtype=dtypes.float32))
        tf_z = tf.nn.conv2d(
            tf_x, w, strides=[1, stride, stride, 1], padding=pad) + b
        tf_h = act(tf_z)
        sess.run(tf.global_variables_initializer())
        tf_o = sess.run(tf_z)
        print("tf_o0:\n", tf_o[0, :, :, 0])
        print("tf_o1:\n", tf_o[0, :, :, 1])

--- convolution in tensorflow ---
tf_o0:
 [[  6.   4.   3.]
 [ 13.   7.   4.]
 [ 10.   9.   5.]]
tf_o1:
 [[ -1.  -3.   1.]
 [  0.   6.   2.]
 [  1.  -3.  12.]]

3. convolution in numpy

   okay, it is time to calculate id98 manually. and its code is
   impressively simple.
# 3. id98 in numpy

print("--- convolution in numpy ---")

for z in range(nf):
    # print("z:", z)
    h_range = int((x.shape[2] - rf) / s) + 1  # (w - f + 2p) / s
    for _h in range(h_range):
        w_range = int((x.shape[1] - rf) / s) + 1  # (w - f + 2p) / s
        for _w in range(w_range):
            np_o[0, _h, _w, z] = np.sum(
                x[0, _h * s:_h * s + rf, _w * s:_w * s + rf, :] *
                w[:, :, :, z]) + b[z]

print("np_o0:\n", np_o[0, :, :, 0])
print("np_o1:\n", np_o[0, :, :, 1])

--- convolution in numpy ---
np_o0:
 [[  6.   4.   3.]
 [ 13.   7.   4.]
 [ 10.   9.   5.]]
np_o1:
 [[ -1.  -3.   1.]
 [  0.   6.   2.]
 [  1.  -3.  12.]]

   finally, we can check the results are same each other using the
   np.testing library.
np.testing.assert_almost_equal(tf_o, np_o)

4. references

     * id98 animation, andrej karpathy, stanford cs231n lecture :
       [6]https://cs231n.github.io/convolutional-networks/
     * (cover image) people with ocd know what to do, they just have
       trouble doing it, nicole wetsman, popular science :
       [7]https://www.popsci.com/ocd-understanding-compulsions

   iframe: [8]https://cs231n.github.io/assets/conv-demo/index.html

5. full source code

   here is the full source code on my gist.
     __________________________________________________________________

     * [9]    previous post
     * [10]next post    
     __________________________________________________________________

     *
     *
     *
     *
     *

   copyright    chris hoyean song 2019

references

   visible links
   1. http://chris-chris.ai/http://chris-chris.ai/feed.xml
   2. http://chris-chris.ai/
   3. http://chris-chris.ai/
   4. http://chris-chris.ai/about/
   5. http://chris-chris.ai/contact/
   6. https://cs231n.github.io/convolutional-networks/
   7. https://www.popsci.com/ocd-understanding-compulsions
   8. https://cs231n.github.io/assets/conv-demo/index.html
   9. http://chris-chris.ai/2017/11/06/pysc2-tutorial2/
  10. http://chris-chris.ai/2019/02/07/pysc2-tutorial3/

   hidden links:
  12. http://chris-chris.ai/feed.xml
  13. https://twitter.com/chrislovesai
  14. https://www.facebook.com/ai.chris.chris
  15. https://github.com/chris-chris
  16. mailto:sjhshy@gmail.com
