   #[1]machine learning with chris

   [tr?id=267215900457044&ev=pageview&noscript=1]

   (button) toggle navigation [2]machine learning with chris
     * [3]home
     * [4]about
     * [5]contact

starcraft ii rl tutorial 1

deepmind's starcraft ii rl environment

   posted by chris hoyean song on august 30, 2017

   so lately i   ve been really obsessed with id23, and
   finding that deepmind open-sourced the starcraft ii reinforcement
   learning environment to the public got me excited.

   [6]https://deepmind.com/blog/deepmind-and-blizzard-release-starcraft-ii
   -ai-research-environment/

   i   m a big fan of blizzard games, especially starcraft ii, so i saw the
   rl environment as a great opportunity to learn and also just have a lot
   of fun.

   after talking to some friends about this, i decided write up an intro
   tutorial for setting up the environment and training some models.

prerequisites

     * intellij ( or pycharm)
     * python3
     * starcraft ii (even starter pack is working)
     * git

   this tutorial is based on mac environment.

   on today   s article, we   ll run training scripts to solve the
   collectmineralshards mini-game using deep q-network.

   when we run the training script, you can see the training result like
   below.

   iframe: [7]https://www.youtube.com/embed/xpdqynnxako

tutorial outline

   1) install pysc2

   2) star & fork pysc2-examples

   3) clone pysc2-examples repository

   4) download mini-games starcraft ii maps

   5) install tensorflow, baselines libraries

   6) open the project with intellij ( or pycharm )

   7) run the training script

   8) run the pre-trained model

let's start!

1) install pysc2

   first of all, we   ll install pysc2 library.

   you can just type the commands on the terminal.

   (since we are using python3, you have to type pip3)

     pip3 install pysc2

   then you have your pysc2 installed.

2) star & fork pysc2-examples

   next, open the github link below.

   [8]https://github.com/chris-chris/pysc2-examples

   it   s the most important step! star my repository ;)

   alt text

   and fork it!

   alt text

3) clone pysc2-examples repository

   okay, let   s clone the project.

   you can clone this repository with this simple command.

     git clone https://github.com/chris-chris/pysc2-examples

   then you will see    pysc2-examples    directory on your computer.

4) download mini-games starcraft ii maps

   before running the training script, we have to download mini-games
   maps. and save these maps to starcraft ii/maps directory.

   [9]download mini-games maps

   i   m a mac user, and this is my starcraft ii maps location

   /applications/starcraft ii/maps/mini_games

   if you are a windows user, use can save the maps in starcraft
   ii/maps/mini_games directory.

   for linux users, save the maps in ~/starcraft ii/maps/mini_games
   directory.

5) install tensorflow, baselines libraries

   we need some more libraries! we need the google tensorflow and openai
   baselines libraries.

   you can install these libraries by typing the commands below.

     pip3 install tensorflow

     pip3 install baselines

   i implemented the reinforcement model using openai's baselines library.
   since openai   s baselines library depends on tensorflow we need to
   install tensorflow. i think openai   s baselines is the most beautiful
   implementation of deep q-network, which is why i   m using it!

   i expect most of you reading this article to already have installed
   tensorflow library :)

6) open the project with intellij ( or pycharm )

   by typing the commands below, the training will be started.

     python3 train_mineral_shards.py

   quick note! i strongly recommend that you develop your reinforcement
   learning on ide(integrated development environment). this is because
   i   m going to explain the detail environment variables using debug mode
   :) i   m currently running this project on intellij.

   execute intellij or pycharm. and open the project folder which we
   cloned.

   alt text

   and let   s set the project structure.

   select [file > project structure] menu.

   alt text

   and select python3 sdk on module sdk. if you cannot find the sdk, click
   [new...] button and add your python3 binary.

   alt text

7) run the training script

   and then, let   s run the trainig script.

   right click the train_mineral_shards.py and select [run
   'train_mineral_shards'] menu.

   alt text

   then you will see the logs on the console while executing starcraft ii.

   alt text

   this is the brief explanation of console logs.
     * steps : the number of commands that we sent to marines.
     * episodes : the number of games that we played.
     * mean 100 episode reward : mean rewards of last 100 episodes.
     * mean 100 episode min    : mean minerals of last 100 episodes.
     * % time spent exploring : the percentage of exploring (exploration &
       exploit)

   currently i set the train script to run 20,000,000 steps.

   (it takes soooooo much time, so if you want to run on your laptop, i   d
   recommend you to set the training steps to 500,000 something)

8) run the pre-trained model

   i coded the program to save the trained model to the mineral_shards.pkl
   file after all the training steps.

     act.save("mineral_shards.pkl")

   if you want to use this pre-trained model, you can just execute enjoy
   script :)

   right click the enjoy_mineral_shards.py and select [run
   'enjoy_mineral_shards'] menu.

   alt text

   then you can see the pre-trained agent of collectmineralshards map.

conclusion

   on this article, i just introduced the way you set your environment and
   train the model.

future tutorials

     * understand the deep q-network algorithm
     * understand the starcraft ii environment (observations & actions)
     * the way i developed deep q-network on starcraft ii mini-games.

   alt text
     __________________________________________________________________

     * [10]next post    
     __________________________________________________________________

     *
     *
     *
     *
     *

   copyright    chris hoyean song 2019

references

   visible links
   1. http://chris-chris.ai/http://chris-chris.ai/feed.xml
   2. http://chris-chris.ai/
   3. http://chris-chris.ai/
   4. http://chris-chris.ai/about/
   5. http://chris-chris.ai/contact/
   6. https://deepmind.com/blog/deepmind-and-blizzard-release-starcraft-ii-ai-research-environment/
   7. https://www.youtube.com/embed/xpdqynnxako
   8. https://github.com/chris-chris/pysc2-examples
   9. https://github.com/deepmind/pysc2/releases/download/v1.0/mini_games.zip
  10. http://chris-chris.ai/2017/10/10/lstm-layernorm-breakdown-eng/

   hidden links:
  12. http://chris-chris.ai/feed.xml
  13. https://twitter.com/chrislovesai
  14. https://www.facebook.com/ai.chris.chris
  15. https://github.com/chris-chris
  16. mailto:sjhshy@gmail.com
