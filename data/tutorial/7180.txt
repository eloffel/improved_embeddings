   #[1]the morning paper    feed [2]the morning paper    comments feed
   [3]the morning paper    opening the black box of deep neural networks
   via information     part i comments feed [4]matrix capsules with em
   routing [5]opening the black box of deep neural networks via
   information     part ii [6]alternate [7]alternate [8]the morning paper
   [9]wordpress.com

   [10]skip to content

   [11]the morning paper

an interesting/influential/important paper from the world of cs every weekday
morning, as selected by adrian colyer

     * [12]home
     * [13]about
     * [14]infoq qr editions
     * [15]subscribe
     * [16]privacy

opening the black box of deep neural networks via information     part i

   november 15, 2017
   tags: [17]deep learning

   [18]opening the black box of deep neural networks via information
   schwartz-viz & tishby, icri-ci 2017

   in my view, this paper fully justifies all of the excitement
   surrounding it. we get three things here: (i) a theory we can use to
   reason about what happens during deep learning, (ii) a study of dnn
   learning during training based on that theory, which sheds a lot of
   light on what is happening inside, and (iii) some hints for how the
   results can be applied to improve the efficiency of deep learning    
   which might even end up displacing sgd in the later phases of training.

     despite their great success, there is still no comprehensive
     understanding of the optimization process or the internal
     organization of dnns, and they are often criticized for being used
     as mysterious    black boxes   .

   i was worried that the paper would be full of impenetrable math, but
   with full credit to the authors it   s actually highly readable. it   s
   worth taking the time to digest what the paper is telling us, so i   m
   going to split my coverage into two parts, looking at the theory today,
   and the dnn learning analysis & visualisations tomorrow.

an id205 of deep learning

   consider the supervised learning problem whereby we are given inputs x
   \in x and we want to predict labels y \in y . inside the network we are
   learning some representation t(x) of the input patterns, that we hope
   enables good predictions. we also want good generalisation, not
   overfitting.

   think of a whole layer t as a single random variable. we can describe
   this layer by two distributions: the encoder p(t|x) and the decoder
   p(y|t) .

   so long as these transformations preserve information, we don   t really
   care which individual neurons within the layers encode which features
   of the input. we can capture this idea by thinking about the mutual
   information of t with the input x and the desired output y .

   given two random variables x and y , their mutual information i(x;y) is
   defined based on id205 as
   \displaystyle i(x;y) = h(x) - h(x|y)

   where h(x) is the id178 of x and h(x|y) is the conditional id178 of
   x given y .

     the mutual information quantifies the number of relevant bits that
     the input x contains about the label y , on average.

   if we put a hidden layer t between x and y then t is mapped to a point
   in the information plane with coordinates (i(x;t), i(t;y)) . the data
   processing inequality (dpi) result tells us that for any 3 variables
   forming a markov chain x \rightarrow y \rightarrow z we have i(x;y)
   \geq i(x;z) .

   so far we   ve just been considering a single hidden layer. to make a
   deep neural network we need lots of layers! we can think of a markov
   chain of k-layers, where t^i denotes the i^{th} hidden layer.

   in such a network there is a unique information path which satisfies
   the dpi chains:

   \displaystyle i(x;y) \geq i(t_1;y) \geq i(t_2;y) \geq ... \geq i(t_k;y)
   \geq i(\hat{y};y)

   and
   \displaystyle h(x) \geq i(x;t_1) \geq i(x;t_2) \geq ... \geq i(x;t_k)
   \geq i(x;\hat{y})

   now we bring in another property of mutual information; it is invariant
   in the face of invertible transformations:

   \displaystyle i(x;y) = i(\psi (x); \phi(y))

   for any invertible functions \psi and \phi .

   and this reveals that the same information paths can be realised in
   many different ways:

     since layers related by invertible re-parameterization appear in the
     same point, each information path in the plane corresponds to many
     different dnn   s , with possibly very different architectures.

information bottlenecks and optimal representations

   an optimal encoder of the mutual information i(x;y) would create a
   representation of a minimal sufficient statistic of x with respect to y
   . if we have a minimal sufficient statistic then we can decode the
   relevant information with the smallest number of binary questions.
   (that is, it creates the most compact encoding that still enables us to
   predict y as accurately as possible).

   the information bottleneck (ib) tradeoff [19]tishby et al. (1999)
   provides a computational framework for finding approximate minimal
   sufficient statistics. that is, the optimal tradeoff between the
   compression of x and the prediction of y .

     the information bottleneck tradeoff is formulated by the following
     optimization problem, carried independently for the distributions,
     p(t|x), p(t), p(y|t) , with the markov chain: y \rightarrow x
     \rightarrow t

   \displaystyle \min_{p(t|x),p(y|t),p(t)} \{ i(x;t) - \beta i(t;y)\}

   where the lagrange multiplier \beta determines the level of relevant
   information captured by the representation t, i(t;y) .

   the solution to this problem defines an information curve: a monotonic
   concave line of optimal representations that separates the achievable
   and unachievable regions in the information plane.

noise makes it all work

   section 2.4 contains a discussion on the crucial role of noise in
   making the analysis useful (which sounds kind of odd on first
   reading!). i don   t fully understand this part, but here   s the gist:

     the learning complexity is related to the number of relevant bits
     required from the input patterns x for a good enough prediction of
     the output label y , or the minimal i(x; \hat{x}) under a constraint
     on i(\hat{x}; y) given by the ib.

   without some noise (introduced for example by the use of sigmoid
   id180) the mutual information is simply the id178 h(y)
   independent of the actual function we   re trying to learn, and nothing
   in the structure of the points p(y|x) gives us any hint as to the
   learning complexity of the rule. with some noise, the function turns
   into a stochastic rule, and we can escape this problem. anyone with a
   lay-person   s explanation of why this works, please do post in the
   comments!

setting the stage for part ii

   with all this theory under our belts, we can go on to study the
   information paths of dnns in the information plane. this is possible
   when we know the underlying distribution p(x,y) and the encoder and
   decoder distributions p(t|x) and p(y|t) can be calculated directly.

     our two order parameters, i(t; x) and i(t;y) , allow us to visualize
     and compare different network architectures in terms of their
     efficiency in preserving the relevant information in p(x;y) .

   we   ll be looking at the following issues:
    1. what is sgd actually doing in the information plane?
    2. what effect does training sample size have on layers?
    3. what is the benefit of hidden layers?
    4. what is the final location of hidden layers?
    5. do hidden layers form optimal ib representations?

share this:

     * [20]twitter
     * [21]linkedin
     * [22]email
     * [23]print
     *

like this:

   like loading...

related

   from     [24]uncategorized
   [25]    matrix capsules with em routing
   [26]opening the black box of deep neural networks via information    
   part ii    
   21 comments [27]leave one    
    1. buriy [28]permalink
       november 15, 2017 2:46 pm
       have you found how to calculate this i(x,t_i) in practice, say, for
       mnist and fc layers?
       [29]reply
          + [30]adriancolyer [31]permalink*
            november 15, 2017 3:39 pm
            in section 2.5 of the paper, the authors describe the criteria
            under which this can be done. they only do so for a strictly
            controlled environment, leaving the more general case to
            future work     though they give some hints:    as proposed by
            tishby and zaslavsky (2015), we study the information paths of
            dnns in the information plane. this can be done when the
            underlying distribution, p (x, y ), is known and the encoder
            and decoder distributions p (t |x ) and p (y |t ) can be
            calculated directly. for    large real world    problems these
            distributions and mutual information values should be
            estimated from samples or by using other modeling assumptions.
            doing this is beyond the scope of this work, but we are
            convinced that our analysis and observations are general, and
            expect the dynamics phase transitions to become even sharper
            for larger networks, as they are inherently based on
            statistical ensemble properties. good overviews on methods for
            mutual information estimation can be found in paninski (2003)
            and kraskov et al. (2004).   
            [32]reply
               o buriy [33]permalink
                 november 24, 2017 1:09 pm
                 found this solution [34]https://arxiv.org/abs/1705.02436
                 from this link:
                 [35]https://openreview.net/forum?id=ry_wpg-a-
    2. andre [36]permalink
       november 15, 2017 3:33 pm
       thank you so much for reviewing this topic! you mention    if we put
       a hidden layer t between x and y then t is mapped to a point in the
       information plane with coordinates (i(x;t), i(t;y))   
       i   m not yet very familiar with id205 beyond id178.
       what does the information plane mean? and what does it mean to map
       a point in the information plane with some coordinates? this topic
       is really fascinating!
       [37]reply
          + [38]adriancolyer [39]permalink*
            november 15, 2017 3:37 pm
            by information plane here, the authors are referring (as i
            understand it!), to the 2d plane created with the mutual
            information between the input and the hidden layer on the
            x-axis, and the mutual information between the output and the
            hidden layer on the y-axis. another way of thinking about what
            this phrase means is just    when we think about what   s
            happening inside of the neural network in terms of
            information      . part ii (posted tomorrow) contains a number of
            example plots etc., that will hopefully help to make all this
            a little clearer.
            [40]reply
               o andre [41]permalink
                 november 15, 2017 3:44 pm
                 looking forward to it! thanks a lot for this review,
                 reading someone else   s perspective helps. i still need to
                 wrap my head around the whole idea of id205
    3. unohoo [42]permalink
       november 15, 2017 6:02 pm
       great post. do you know of any other blogs/podcasts/youtube
       channels doing something similar to your morning paper, or 2 minute
       papers on youtube but in other fields ?
       it   s a great idea, i   d love to be introduced the gist of papers
       from fields outside of computer science.
       [43]reply
    4. [44]allen tools [45]permalink
       november 16, 2017 5:08 pm
       about adding noise to a model, if it   s the same concept that i
       envision, you   d be adding extra bits to an existential set of data
       to generalize the data structure for pattern recognition. it might
       help to take an example, it   s like adding noise to a clear photo in
       photoshop, if you use the filter to add noise to a picture you see
       more blocked edges on the photo, this allows for more generalized
       manipulations of the image because extra bits are added onto the
       smooth edges. a graphics artist can add effects to an image because
       the separations become more distinct between objects.
       [46]reply
          + [47]allen tools [48]permalink
            november 16, 2017 5:11 pm
            i meant existing instead existential.
            [49]reply
    5. [50]david banville [51]permalink
       november 16, 2017 5:29 pm
       quote:        without some noise (introduced for example by the use of
       sigmoid id180)       
       i do not see how sigmoid functions could introduce noise by them
       selves. the way i see it is more: the noise is introduced by the
       random initialization of the parameters, the variance of this noise
       is then amplified by the sigmoid function (or any other
       non-linearity).
       [52]reply
          + paolo fazzini [53]permalink
            october 15, 2018 2:44 pm
            that part of the paper (not present in the researchgate
            version) is pretty foggy to me too. however, the way i
            **understand** it is that, yes, the noise is generated    by the
            sigmoids themselves    if you consider    noise    the various
            values of the sigmoid (wobbling between 0 and 1 as you
            evaluate the various input); that wobbling could be
            interpreted as a distance of an input x to the decision
            boundary and, at the same time, considered as noise as
            opposite to, for instance, a binary function that just labels
            as    0    or    1    depending on which side of the decision boundary
            an input lies.
            the reason (i think) for all this is to say that as the neural
            networks in the paper example are equipped with sigmoids, a
            theory based on information can tell us something about the
            classification complexity.
            not sure what is going to happen when a different nonlinearity
            is used at the neurons instead of a sigmoid. for instance, if
            a relu is used (as very common in deep networks) the distance
            concept doesn   t quite work: then i am unclear if insights on
            the classification complexity can be provided by an
            information-based approach.
            [54]reply
    6. [55]anmol chachra [56]permalink
       november 25, 2017 5:09 am
       can you please elaborate how invertible functions help us determine
       that same information path can be realized in many different ways?
       [57]reply
          + [58]adriancolyer [59]permalink*
            november 28, 2017 6:34 am
            here   s my interpretation: suppose we have a function g :: x ->
            x   , and a function h :: y -> y   . then the mutual information
            between x and y is the same as the mutual information between
            g(x) and h(y), iff those functions are invertible. that is, i
            can define g    :: x    -> x such that g   (g(x)) == x. intuitively
            to me this must be the case, since if the function is
            invertible (i can always go back to the original) it must be
            that i haven   t lost any information. and likewise the function
            g() can   t conjure up new information out of thin air!
            now, the functions g() and h() that i chose above are
            arbitrary. we could make lots of different choices of g() and
            h() so long as they retained the invertibility property. now
            think of those functions as transformations at a layer in the
            network, and we have lots of different potential networks that
            share the same properties in the information plane.
            [60]reply
    7. timherfurth87gmail.com [61]permalink
       december 6, 2017 4:10 pm
       hi,
       can anyone tell me why minimizing i(x,x   ) corresponds to (lossy)
       compression? couldn   t this just be that information is arbitrarily
          destroyed   ?
       [62]reply

trackbacks

    1. [63]opening the black box of deep neural networks via information    
       part ii | the morning paper
    2. [64]what happens in deep neural networks?     curated sql
    3. [65]on the information bottleneck theory of deep learning | the
       morning paper
    4. [66]a theory of the learnable | the morning paper
    5. [67]a theory of the learnable | digitators
    6. [68]a belief of the learnable     startupon.net
    7. [69]the information bottleneck: uncovering the secret of deep
       learning? - recast.ai blog

leave a reply [70]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *
     *
     *

   [71]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [72]log out /
   [73]change )
   google photo

   you are commenting using your google account. ( [74]log out /
   [75]change )
   twitter picture

   you are commenting using your twitter account. ( [76]log out /
   [77]change )
   facebook photo

   you are commenting using your facebook account. ( [78]log out /
   [79]change )
   [80]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   [ ] notify me of new posts via email.

   post comment

   this site uses akismet to reduce spam. [81]learn how your comment data
   is processed.
     * subscribe

                        [82][mail-new-icon.png?w=600]
      never miss an issue! the morning paper delivered straight to your
                                   inbox.
     * search
       ____________________
     * archives archives [select month________]
     * most read in the last few days
          + [83]ginseng: keeping secrets in registers when you distrust
            the operating system
          + [84]amazon aurora: design considerations for high throughput
            cloud-native id208
          + [85]establishing software root of trust unconditionally
          + [86]amazon aurora: on avoiding distributed consensus for i/os,
            commits, and membership changes
          + [87]the amazing power of word vectors
          + [88]calvin: fast distributed transactions for partitioned
            database systems
          + [89]on the criteria to be used in decomposing systems into
            modules
          + [90]neural ordinary differential equations
          + [91]applying the universal scalability law to organisations
          + [92]programming paradigms for dummies: what every programmer
            should know
     * rss
          + [93]rss - posts
          + [94]rss - comments
     * live on twitter[95]my tweets

   [96]blog at wordpress.com.

   send to email address ____________________ your name
   ____________________ your email address ____________________
   _________________________
   loading send email [97]cancel
   post was not sent - check your email addresses!
   email check failed, please try again
   sorry, your blog cannot share posts by email.

   iframe: [98]likes-master

   %d bloggers like this:

references

   visible links
   1. https://blog.acolyer.org/feed/
   2. https://blog.acolyer.org/comments/feed/
   3. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/feed/
   4. https://blog.acolyer.org/2017/11/14/matrix-capsules-with-em-routing/
   5. https://blog.acolyer.org/2017/11/16/opening-the-black-box-of-deep-neural-networks-via-information-part-ii/
   6. https://public-api.wordpress.com/oembed/?format=json&url=https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/&for=wpcom-auto-discovery
   7. https://public-api.wordpress.com/oembed/?format=xml&url=https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/&for=wpcom-auto-discovery
   8. https://blog.acolyer.org/osd.xml
   9. https://s1.wp.com/opensearch.xml
  10. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#content
  11. https://blog.acolyer.org/
  12. https://blog.acolyer.org/
  13. https://blog.acolyer.org/about/
  14. https://blog.acolyer.org/infoq-quarterly-review-editions/
  15. https://blog.acolyer.org/email-subs/
  16. https://blog.acolyer.org/privacy/
  17. https://blog.acolyer.org/tag/deep-learning/
  18. https://arxiv.org/abs/1703.00810
  19. https://arxiv.org/pdf/physics/0004057.pdf
  20. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?share=twitter
  21. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?share=linkedin
  22. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?share=email
  23. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#print
  24. https://blog.acolyer.org/category/uncategorized/
  25. https://blog.acolyer.org/2017/11/14/matrix-capsules-with-em-routing/
  26. https://blog.acolyer.org/2017/11/16/opening-the-black-box-of-deep-neural-networks-via-information-part-ii/
  27. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#respond
  28. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18078
  29. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18078#respond
  30. https://adriancolyer.wordpress.com/
  31. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18082
  32. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18082#respond
  33. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18530
  34. https://arxiv.org/abs/1705.02436
  35. https://openreview.net/forum?id=ry_wpg-a-
  36. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18080
  37. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18080#respond
  38. https://adriancolyer.wordpress.com/
  39. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18081
  40. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18081#respond
  41. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18083
  42. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18094
  43. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18094#respond
  44. http://allen.tools/
  45. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18142
  46. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18142#respond
  47. http://allen.tools/
  48. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18143
  49. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18143#respond
  50. https://www.facebook.com/app_scoped_user_id/10154918425867321/
  51. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18145
  52. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18145#respond
  53. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-32787
  54. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=32787#respond
  55. http://codeitplease.wordpress.com/
  56. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18546
  57. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18546#respond
  58. https://adriancolyer.wordpress.com/
  59. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-18673
  60. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=18673#respond
  61. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-19006
  62. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/?replytocom=19006#respond
  63. https://blog.acolyer.org/2017/11/16/opening-the-black-box-of-deep-neural-networks-via-information-part-ii/
  64. https://curatedsql.com/2017/11/17/what-happens-in-deep-neural-networks/
  65. https://blog.acolyer.org/2017/11/24/on-the-information-bottleneck-theory-of-deep-learning/
  66. https://blog.acolyer.org/2018/01/31/a-theory-of-the-learnable/
  67. https://digitators.com/a-theory-of-the-learnable/
  68. https://www.startupon.net/2018/01/31/a-belief-of-the-learnable/
  69. https://recast.ai/blog/information-bottleneck-uncovering-secret-deep-learning/
  70. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#respond
  71. https://gravatar.com/site/signup/
  72. javascript:highlandercomments.doexternallogout( 'wordpress' );
  73. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/
  74. javascript:highlandercomments.doexternallogout( 'googleplus' );
  75. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/
  76. javascript:highlandercomments.doexternallogout( 'twitter' );
  77. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/
  78. javascript:highlandercomments.doexternallogout( 'facebook' );
  79. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/
  80. javascript:highlandercomments.cancelexternalwindow();
  81. https://akismet.com/privacy/
  82. http://eepurl.com/bbzpm9
  83. https://blog.acolyer.org/2019/04/05/ginseng-keeping-secrets-in-registers-when-you-distrust-the-operating-system/
  84. https://blog.acolyer.org/2019/03/25/amazon-aurora-design-considerations-for-high-throughput-cloud-native-relational-databases/
  85. https://blog.acolyer.org/2019/04/03/establishing-software-root-of-trust-unconditionally/
  86. https://blog.acolyer.org/2019/03/27/amazon-aurora-on-avoiding-distributed-consensus-for-i-os-commits-and-membership-changes/
  87. https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/
  88. https://blog.acolyer.org/2019/03/29/calvin-fast-distributed-transactions-for-partitioned-database-systems/
  89. https://blog.acolyer.org/2016/09/05/on-the-criteria-to-be-used-in-decomposing-systems-into-modules/
  90. https://blog.acolyer.org/2019/01/09/neural-ordinary-differential-equations/
  91. https://blog.acolyer.org/2015/04/29/applying-the-universal-scalability-law-to-organisations/
  92. https://blog.acolyer.org/2019/01/25/programming-paradigms-for-dummies-what-every-programmer-should-know/
  93. https://blog.acolyer.org/feed/
  94. https://blog.acolyer.org/comments/feed/
  95. https://twitter.com/519408925733425153
  96. https://wordpress.com/?ref=footer_blog
  97. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#cancel
  98. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
 100. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-form-guest
 101. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-form-load-service:wordpress.com
 102. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-form-load-service:twitter
 103. https://blog.acolyer.org/2017/11/15/opening-the-black-box-of-deep-neural-networks-via-information-part-i/#comment-form-load-service:facebook
