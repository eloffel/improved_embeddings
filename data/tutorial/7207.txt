the large-scale structure of networks: 
probabilistic models, rich data, and 
mathematical limits

aaron clauset
@aaronclauset

computer science dept. & biofrontiers institute
university of colorado, boulder
external faculty, santa fe institute

   2017 aaron clauset 

hvr 6100150200250300scienti   c knowledge comes from :

experiment

theory

until the 20th century   

scienti   c knowledge comes from :

experiment

computation

theory

i have broad interests in complex systems :
   how are size and complexity related? [esp. in biology]
   how do macro-level patterns emerge from micro-level 
interactions? [esp. in biology and social systems]
   how can simple stochastic models be such effective 
descriptions of complex systems?
   what makes a system robust, resilient, or evolvable?
   how can computation help us understand complexity?

i have broad interests in complex systems :
   macroevolution of species sizes
   malaria genetics, recombination, and public health 
   con   ict, competition, terrorism, and war
   the "science of science", and origins of inequalities

exciting! but, science is really hard, so lots of

networks + data + statistics + simulations + algorithms

this talk

networks are cool
probabilistic generative models for networks
new algorithms for learning on networks + auxiliary data
mathematical limits to learning on networks

what are networks?

system / population

individuals / components

what are networks?
    an approach
    a mathematical representation
    provide structure to complexity
    structure above         
individuals / components 
    structure below              
system / population

}

-
$
,
+
*
)
'
)
(
'
&
$
%
$
#
"
!

22

18

2

1

20

3

7

5

14

12

8

4

13

6

17

11

10

28

31

32

9

29

25

26

24

30

34

33

27

15

16

19

21

23

 

 

adamic & glance 2005

what is "large-scale structure"?

what is "large-scale structure"?
    coarse-graining of topology
    network modules or communities = building blocks

network structure

coarse-graining

c

c

calculate alignment scores
convert to alignment indicators
remove short aligned regions

8

d

extract highly variable regions

d

9

600

ngdykekvsnnlraifnkiyenlndpklkkhyqkdapny

what is "large-scale structure"?
    coarse-graining of topology

assortative
edges within groups

disassortative
edges between groups

ordered

linear group hierarchy

core-periphery
dense core, sparse periphery

what is "large-scale structure"?
    a low-dimensional representation of complexity
    the "architecture of a complex system"
    useful because structure constrains dynamics :
epidemics, cascades, information    ow, social in   uence,   
mass transfer, regulation, etc.
can promote or discourage spreading processes
can increase or decrease ef   ciency, robustness, adaptability
can predict missing connections / metadata & future 
interactions / dynamics
    function follows form

    how do we infer large-scale structure?

probabilistic generative models for networks

probabilistic generative models for networks

a parametric id203 distribution over networks
general likelihood function :

pr(g|    )

pr(g |    ) =yij
pr         6=        = 0

assumptions about    structure    go into
consistency

lim
n!1

requires that edges be conditionally independent
       general classes of these models

pr(aij |    )
pr(aij |    )

edge generation function

shalizi & rinaldo, annals of statistics 41(2), 508-535 (2013)
jacobs & clauset, nips workshop (2014)

generation

0 1

0

1

2
0
0

a

l
i

g
n
m
e
n
t
 
p
o
s
i
t
i
o
n
 
t

4
0
0

6
0
0

2

3

4

l

i

e
x
t
r
a
c
t
 
h
g
h
y
 
v
a
r
i
a
b
e
 
r
e
g
o
n
s

l

i

5

6

7

8

9

d

stochastic block models
pr(aij | m, z)

   types of vertices,                         depends only on node types 
k

zi, zj
originally invented by sociologists [holland, laskey, leinhardt 1983]

1
6

6

1
3

n
g
d
y
k
e
k
v
s
n
n
l
r
a
i
f
k
k
i
y
d
a
l
e
d
t
v
k
e
t
y
k
d
d
p
n
y

n
g
d
y
k
k
k
v
s
n
n
l
k
t
i
f
k
k
i
y
d
a
l
k
d
t
v
k
e
t
y
k
d
d
p
n
y

n
g
d
y
k
e
k
v
s
n
n
l
r
a
i
f
n
k
i
y
e
n
l
n
d
p
k
l
k
k
h
y
q
k
d
a
p
n
y

many    avors now, including

binomial sbm [holland et al. 1983, wang & wong 1987]
simple assortative sbm [hofman & wiggins 2008]
mixed-membership sbm [airoldi et al. 2008] 
hierarchical sbm [clauset et al. 2006,2008, peixoto 2014]
fractal sbm [leskovec et al. 2005]
in   nite relational model [kemp et al. 2006]
degree-corrected sbm [karrer & newman 2011]
sbm + topic models [ball et al. 2011]
sbm + vertex covariates [mariadassou et al. 2010, newman & clauset 2016]
sbm + edge weights [aicher et al. 2013,2014, peixoto 2015]
bipartite sbm [larremore et al. 2014]
multilayer sbm [peixoto 2015, valles-catata et al. 2016]
dynamic sbm [basset et al. 2013, peel & clauset 2015, ghasemian et al. 2016, peixoto 2015]
and many others

jacobs & clauset, nips workshop (2014)

latent space models

nodes live in a latent space,                              depends only on proximity

originally invented by statisticians [hoff, raftery, handcock 2002]

pr(aij | f (xi, xj))

many    avors now, including

logistic function on vertex features [hoff et al. 2002]
social status / ranking [ball, newman 2013]
nonparametric metadata relations [kim et al. 2012]
multiplicative attribute graphs [kim & leskovec 2010]
nonparametric latent feature model [miller et al. 2009]
in   nite multiple memberships [morup et al. 2011]
1094
ecological niche model [williams et al. 2010, jacobs et al. 2015]
hyperbolic latent spaces [boguna et al. 2010]
springrank [larremore et al. 2017]
and many others

jacobs & clauset, nips workshop (2014)

figure 1. maximum likelihood estimates (a) and bayesian marginal

basic stochastic block model
zi 2 {1, . . . , k}
m

each vertex     has type                           (    vertex types or groups)
stochastic block matrix      of group-level connection probabilities
id203 that        are connected = 

k

i

i, j

mzi,zj

community = vertices with same pattern of inter-community connections

inferred m

c

d

9

c

calculate alignment scores
convert to alignment indicators
remove short aligned regions

extract highly variable regions

basic stochastic block model

likelihood function :

pr(g| z, m ) = y(i,j)2e
=yrs

(1   mzi,zj )

mzi,zj y(i,j)62e
r,s (1   mr,s)nsnr er,s
m er,s

(bernoulli edges)

bernoulli random graph 
with parameter mr,s

general stochastic block models

likelihood function :

pr(a| z,    , x) =yij

f (aij |    r(zi,zj ), xi, xj)

aij : value of adjacency
r
f
   a,   
x

: partition of adjacencies
: id203 function
: pattern for    -type adjacencies
: node attributes (metadata)

a

binomial = simple graphs
poisson = multi-graphs
normal = weighted graphs
etc.

   11

   21

   31

   41

   12

   22

   32

   42

   13

   23

   33

   43

   14

   24

   34

   44

general stochastic block models

naturally models many large-scale patterns

assortative, disassortative, ordered, core-periphery, and various mixtures of these

highly effective in practice

used in gene regulatory networks, protein networks, social networks, food webs, etc.

many nice mathematical features
    general de   nition of "community" or group
    learns from noisy or missing data
    naturally quanti   es uncertainty
    can compare models of large-scale structure [this pattern or that pattern?]
    can predict missing or spurious or future data [link or attribute prediction]
    easily augmentable with auxiliary data
    inferred block matrix is interpretable for science

new algorithms for auxiliary data

learning large-scale structure in networks with
    edge weights
    node attributes
    bipartite structure
    dynamic edges     change-point detection
    dynamic edges     community membership

aicher et al. j. complex networks 3(2), 221-248 (2015)
newman & clauset, nat. comms. 7, 11863 (2016)
peel et al. sci. adv. 3(5) e1602548 (2017)
larremore et al., phys. rev. e 90, 012805 (2014)
larremore et al. plos comp. bio. 9(10), e1003268 (2013)
peel & clauset, aaai (2015)
ghasemian et al. phys. rev. x 6, 031005 (2016)

the trouble with community detection

many networks include attributes or metadata on their nodes:

social networks
food webs
internet
protein interactions molecular weight, association with cancer, etc.

age, sex, ethnicity or race, etc.
feeding mode, species body mass, etc.
data capacity, physical location, etc.

metadata     is often used to evaluate the accuracy of community detection algs.

x

if community detection method         nds a partition      that correlates with     
x
then we say that      is good 

a

p

a

}

15 years of research like this

the trouble with community detection
often, groups found by community detection are meaningful
    allegiances or personal interests in social networks
    biological function in metabolic networks

but   

fortunato (2010), and adamic & glance (2005)
holme, huss & jeong (2003), and guimera & amaral (2005)

the trouble with community detection
often, groups found by community detection are meaningful
    allegiances or personal interests in social networks
    biological function in metabolic networks

but several recent studies claim these are the exception
    real networks either do not contain structural communities or  

communities exist but they do not correlate with metadata groups

fortunato (2010), and adamic & glance (2005)
holme, huss & jeong (2003), and guimera & amaral (2005)
leskovec et al. (2009), and yang & leskovec (2012), and hric, darst & fortunato (2014)

the trouble with community detection
hric, darst & fortunato (2014)
    evaluate by normalized mutual information

nmi(p, x)

{

"classic" data sets

maximum nmi between any partition layer of the metadata partitions and any layer returned by the community detection method

key idea

use metadata     to help select a partition                     that correlates with    , 
x
from among the exponential number of plausible partitions

p    2 {p}

x

image copyright bostongazette or maybe 20th century fox? gah

metadata-aware stochastic block model

given observed network      (adjacency matrix)
    model likelihood :

a

p (a|    ,  , x) =xs
=xs yu<v

network

metadata

p (a|    , s)p (s|  , x)

pauv

uv (1   puv)1 auvyu

 su,xu

    where      is a            matrix of community interaction parameters       , 
   st

   

and the sum is over all possible assignments

s

k     k

    we    t this model to data using expectation-maximization (em) to 

maximize                          w.r.t.      and

   

p (a|    ,  , x)

 

newman & clauset, nat. comms. 7, 11863 (2016)

real-world networks

1. high school social network: 795 students in a medium-sized 

american high school and its feeder middle school

2. marine food web: predator-prey interactions among 488 

species in weddell sea in antarctica

3. malaria gene recombinations: recombination events among 

297 var genes

4. facebook friendships: online friendships among 15,126 

harvard students and alumni

5. internet graph: peering relations among 46,676 autonomous 

systems

high school social network
795 students from an american high school + its feeder middle school

            {grade 7-12, ethnicity, gender}

x =

newman & clauset, nat. comms. 7, 11863 (2016)
add health network data, designed by udry, bearman & harris

high school social network
795 students from an american high school + its feeder middle school

x =

            {grade 7-12, ethnicity, gender}
    method    nds a good partition 

between high-school and 
middle-school
nmi = 0.881

    .
    without metadata:
nmi 2 [0.105, 0.384]

newman & clauset, nat. comms. 7, 11863 (2016)
add health network data, designed by udry, bearman & harris

high school social network
795 students from an american high school + its feeder middle school

x =

            {grade 7-12, ethnicity, gender}
    method    nds a good partition 

between blacks and whites 
(with others scattered among)
nmi = 0.820

    without metadata:
nmi 2 [0.120, 0.239]

newman & clauset, nat. comms. 7, 11863 (2016)
add health network data, designed by udry, bearman & harris

high school social network
795 students from an american high school + its feeder middle school

x =

            {grade 7-12, ethnicity, gender}
    method    nds no good 

partition between males/
females.                       
instead, chooses a mixture 
of grade/ethnicity partitions

nmi = 0.003

    without metadata:
nmi 2 [0.000, 0.010]

newman & clauset, nat. comms. 7, 11863 (2016)
add health network data, designed by udry, bearman & harris

mathematical limits to learning on network

    weighted > unweighted networks
    bipartite > uni-partite "projections"
    evolving communities > snapshot analysis
    detectability limits, node attributes & no free lunch

aicher et al. j. complex networks 3(2), 221-248 (2015)
newman & clauset, nat. comms. 7, 11863 (2016)
peel et al. sci. adv. 3(5) e1602548 (2017)
ghasemian et al. phys. rev. x 6, 031005 (2016)

mathematical limits to learning on network
for science, how methods fail is as important as how often they succeed 

    even if communities exist in a network, they may not be detectable
    is there a limit to detectability? can it be mitigated?

"planted" partitions : a toy model
    synthetic network with     "planted" communities
       xed mean degree
    parameterized strength of communities 

k

c

    = cout/cin

n/2

n/2

cin
n

cout
n

cout
n

cin
n

decelle et al.,  phys. rev. lett. 107, 065701 (2011)

obeying detailed balance with respect to the hamiltonian (8), starting with a random initial group assignment {qi}.
we see that q = 0 for cout/cin >   c. in other words, in this region both bp and mcmc converge to the factorized
state, where the marginals contain no information about the original assignment. for cout/cin <   c, however, the
overlap is positive and the factorized    xed point is not the one to which bp or mcmc converge.

in particular the right-hand side of fig. 1 shows the case of q = 4 groups with average degree c = 16, corresponding
to the benchmark of newman and girvan [9]. we show the large n results and also the overlap computed with
mcmc for size n = 128 which is the commonly used size for this benchmark. again, up to symmetry breaking,
marginalization achieves the best possible overlap that can be inferred from the graph by any algorithm. therefore,
when algorithms are tested for performance, their results should be compared to fig. 1 instead of to the common but
wrong expectation that the four groups are detectable for any    < 1.

"planted" partitions : a toy model

    one-parameter model     = cout/cin

n=500k, bp
n=70k, mcmc

q=2, c=3

undetectable

 1

 0.8

 0.6

 0.4

 0.2

p
a
l
r
e
v
o

)
y
c
a
r
u
c
c
a
(
 
p
a
l
r
e
v
o

easy

    = cout/cin
to detect

n=100k, bp
n=70k, mc
hard
n=128, mc
n=128, full bp
to detect

q=4, c=16

strong 

communities

random graph

undetectable

 0.3

 0.4

 0.5

 0.6

!= cout/cin

 0.7

 0.8

 0.9

 1

 0

 0

 0.2

decelle et al.,  phys. rev. lett. 107, 065701 (2011)

 0.4

 0.6

 0.8

 1

!= cout/cin

obeying detailed balance with respect to the hamiltonian (8), starting with a random initial group assignment {qi}.
we see that q = 0 for cout/cin >   c. in other words, in this region both bp and mcmc converge to the factorized
state, where the marginals contain no information about the original assignment. for cout/cin <   c, however, the
overlap is positive and the factorized    xed point is not the one to which bp or mcmc converge.

in particular the right-hand side of fig. 1 shows the case of q = 4 groups with average degree c = 16, corresponding
to the benchmark of newman and girvan [9]. we show the large n results and also the overlap computed with
mcmc for size n = 128 which is the commonly used size for this benchmark. again, up to symmetry breaking,
marginalization achieves the best possible overlap that can be inferred from the graph by any algorithm. therefore,
when algorithms are tested for performance, their results should be compared to fig. 1 instead of to the common but
wrong expectation that the four groups are detectable for any    < 1.

"planted" partitions : a toy model

    one-parameter model
    2nd order phase transition 

    = cout/cin

in detectability !!

c   pc

n=500k, bp
n=70k, mcmc
     

    accuracy goes to 0 for
c + pc(k   1)
    undetectability is 

information theoretic
    no algorithm can    

succeed below it

q=2, c=3

undetectable

 1

 0.8

 0.6

 0.4

 0.2

p
a
l
r
e
v
o

)
y
c
a
r
u
c
c
a
(
 
p
a
l
r
e
v
o

    = cout/cin

n=100k, bp
n=70k, mc
n=128, mc
n=128, full bp

q=4, c=16

strong 

communities

random graph

undetectable

 0.3

 0.4

 0.5

 0.6

!= cout/cin

 0.7

 0.8

 0.9

 1

 0

 0

 0.2

decelle et al.,  phys. rev. lett. 107, 065701 (2011)

 0.4

 0.6

 0.8

 1

!= cout/cin

"planted" partitions : a toy model

key insights
    undetectability = no algorithm can detect these communities (better than chance)
    when communities are strong, most algorithms succeed
    this limit is moderated in dynamic networks (ghasemian et al. 2016):              

detectability depends on sparsity    & community stability

   

 

 }

decelle et al.,  phys. rev. lett. 107, 065701 (2011)
ghasemian et al. phys. rev. x 6, 031005 (2016)

can node metadata help detectability?

    recall metadata+sbm :  p (a|    ,  , x) =xs
=xs yu<v

p (a|    , s)p (s|  , x)

metadata

network

pauv

uv (1   puv)1 auvyu

newman & clauset, nat. comms. 7, 11863 (2016)

can node metadata help detectability?

    recall metadata+sbm : 

    planted-partition model again, with
    mean degree
c = (cin + cout)/2
    metadata correlates with true group labels at rates
    vary strength of partition 
    undetectable if

p (a|    ,  , x) =xs
=xs yu<v
cin   cout    p2(cin + cout)

cin   cout

k = 2

p (a|    , s)p (s|  , x)

metadata

network

pauv

uv (1   puv)1 auvyu

    2 [0.5, 0.9]

cin
n

cout
n

cout
n

cin
n

newman & clauset, nat. comms. 7, 11863 (2016)

can node metadata help detectability?

when              , metadata isn   t useful and we recover regular sbm behavior

    = 0.5

s
e
d
o
n

i

 
d
e
n
g
s
s
a
 
y
l
t
c
e
r
r
o
c
 
f
o
 
n
o

i
t
c
a
r
f

1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5

weaker

undetectable

stronger
0.5
0.6
0.7
0.8
0.9

0

1

2

3

4

5

6

7
8
cin-cout

9 10 11 12 13 14 15

n = 10 000
newman & clauset, nat. comms. 7, 11863 (2016)

c = 8

can node metadata help detectability?

when              , metadata isn   t useful and we recover regular sbm behavior
when              , accuracy is better than either metadata or sbm alone

    = 0.5
    > 0.5

metadata also moderates 
the detectability limit

especially around the 
transition (marginally 
detectable or marginally 
undetectable patterns)

s
e
d
o
n

i

 
d
e
n
g
s
s
a
 
y
l
t
c
e
r
r
o
c
 
f
o
 
n
o

i
t
c
a
r
f

1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5

n = 10 000 c = 8
newman & clauset, nat. comms. 7, 11863 (2016)

weaker

undetectable

stronger
0.5
0.6
0.7
0.8
0.9

0

1

2

3

4

5

6

7
8
cin-cout

9 10 11 12 13 14 15

the ground truth about community detection

algorithm

f (g) ! c ?= m
communities

network

metadata

peel et al. sci. adv. 3(5) e1602548 (2017)

the ground truth about community detection

f (g) ! c ?= m

c     m

"this method works!"

peel et al. sci. adv. 3(5) e1602548 (2017)

the ground truth about community detection

f (g) ! c ?= m

c     m

c 6= m

"this method works!"

"this method stinks!"

peel et al. sci. adv. 3(5) e1602548 (2017)

the ground truth about community detection

there are 4 indistinguishable reasons why we might    nd                             :
f (g) = c 6= m

1. metadata      are unrelated to network structure

m

g

peel et al. sci. adv. 3(5) e1602548 (2017)

the ground truth about community detection

there are 4 indistinguishable reasons why we might    nd                             :
f (g) = c 6= m

1. metadata      are unrelated to network structure
2. metadata      and communities      capture different aspects of structure

m

m

g

c

social groups

leaders and followers

peel et al. sci. adv. 3(5) e1602548 (2017)

the ground truth about community detection

there are 4 indistinguishable reasons why we might    nd                             :
f (g) = c 6= m

m

1. metadata      are unrelated to network structure
2. metadata      and communities      capture different aspects of structure
3. network     has no community structure

m

g

c

g

peel et al. sci. adv. 3(5) e1602548 (2017)

the ground truth about community detection

there are 4 indistinguishable reasons why we might    nd                             :
f (g) = c 6= m

m

1. metadata      are unrelated to network structure
2. metadata      and communities      capture different aspects of structure
3. network     has no community structure
4. algorithm    is bad

m

g

g

c

f

peel et al. sci. adv. 3(5) e1602548 (2017)

"this method stinks!"

don   t try to find the ground truth

instead . . .  try to realize there is no ground truth

apparently, use of this meme dates me

the ground truth about community detection
1. theorem: no bijection between ground truth and communities

g(t ) ! g   g0(t 0)

2 different processes, on 2 different ground truths, 
can create the same observed network

performance de   ned as adjusted mutual information (ami), which is like nmi but adjusted for expected values
original nfl theorem:  wolpert, neural computation (1996)
proofs of these theorems is in peel et al. sci. adv. 3(5) e1602548 (2017)

the ground truth about community detection
1. theorem: no bijection between ground truth and communities

g(t ) ! g   g0(t 0)

2 different processes, on 2 different ground truths, 
can create the same observed network

2. theorem: no free lunch in community detection

f

no algorithm    has better performance than 
any other algorithm     , when averaged over 
all possible inputs

f0
{g}

!

good performance comes from matching 
algorithm    to its preferred subclass of 
f
networks 
{g0}     {g}

performance de   ned as adjusted mutual information (ami), which is like nmi but adjusted for expected values
original nfl theorem:  wolpert, neural computation (1996)
proofs of these theorems is in peel et al. sci. adv. 3(5) e1602548 (2017)

conclusions and outlook

conclusions and outlook

networks are cool                                                       
[ obviously, right? ]

conclusions and outlook

networks are cool                                                       
[ obviously, right? ]
powerful window into structure of complex systems          
[ structure + dynamics = function ]
new algorithms for exploiting rich data                          
[ connectivity + node annotations + edge weights + temporal information | link or label prediction | etc. ]
abundance of interesting science applications                              
[ genetics of malaria | systems biology of cancer | online social network assembly | etc. ]
but methods have fundamental limits:
    community detection typically unsupervised
    some supervision & auxiliary data = better id136s / predictions
    but no free lunch      specialized vs. general learning algorithms

conclusions and outlook
fun new projects:

    "stacking" algorithms for better    
link prediction
    "denoising" biological network 
metadata
    gathering all the network data in 
the world @ icon.colorado.edu
    what universal patterns exist? 
what patterns are domain speci   c? 
what algorithms work better on 
which data?

thanks to great collaborators :

papers, code, data

http://www.santafe.edu/~aaronc/

