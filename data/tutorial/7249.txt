neural networks 

anastasios tefas 

assistant professor 

department of informatics 

aristotle university of thessaloniki 

visiting research fellow in tampere university of technology 

 
 

bigdatafinance - 1 

26 aug 2016 

presentation outline 

    deep learning in big financial data analysis 
    what is deep learning 
    multilayer id88s 
    deep convolutional neural networks 
    recurrent neural networks 
    recent advances 
    conclusions 

bigdatafinance - 2 

26 aug 2016 

recent works on deep learning for 

financial data 

   

   

   

   

   

batres-estrada, b. (2015). deep learning for multivariate financial time series. abstract 
 
ding, x., zhang, y., liu, t., & duan, j. (2015, june). deep learning for event-driven stock 
prediction. in proceedings of the twenty-fourth international joint conference on artificial 
intelligence (icjai) (pp. 2327-2333). abstract 
 
dixon, m. f., klabjan, d., & bang, j. h. (2016). classification-based financial markets prediction 
using deep neural networks. available at ssrn 2756331. abstract 
 
fehrer, r., & feuerriegel, s. (2015). improving decision analytics with deep learning: the case of 
financial disclosures. arxiv preprint arxiv:1508.01993. abstract 
 
heaton, j. b., polson, n. g., & witte, j. h. (2016). deep portfolio theory. arxiv preprint 
arxiv:1605.07230. abstract 

bigdatafinance - 3 

26 aug 2016 

recent works on deep learning for 

financial data 

   

   

   

   

   

   

r  nnqvist, s., & sarlin, p. (2016). bank distress in the news: describing events through deep learning. arxiv 
preprint arxiv:1603.05670. abstract 
 
sharang, a., & rao, c. (2015). using machine learning for medium frequency derivative portfolio trading. arxiv 
preprint arxiv:1512.06228. abstract 
 
sirignano, j. a. (2016). deep learning for limit order books. arxiv preprint arxiv:1601.01987. abstract 
 
takeuchi, l., lee, y. (2013). applying deep learning to enhance momentum trading strategies in stocks. abstract 
 
xiong, r., nicholas, e. p., & shen, y. (2015). deep learning stock volatilities with google domestic trends. arxiv 
preprint arxiv:1512.04916. abstract 
 
zhu, c., yin, j., & li, q. (2014). a stock decision support system based on dbns. journal of computational 
information systems, 10(2), 883-893. abstract 

bigdatafinance - 4 

26 aug 2016 

case studies 

 
 
 
 
http://gregharris.info/a-survey-of-deep-learning-techniques-applied-to-trading/  

bigdatafinance - 5 

26 aug 2016 

case studies 

http://gregharris.info/a-survey-of-deep-learning-techniques-applied-to-trading/ 

    limit order book modeling 

    sirignano (2016) predicts changes in limit order 

books. he has developed a    spatial neural network    
that can take advantage of local spatial structure, is 
more interpretable, and more computationally 
efficient than a standard neural network for this 
purpose. he models the joint distribution of the best 
bid and ask at the time of the next state change. also, 
he models the joint distribution of the best bid and 
ask prices upon the change in either of them. 

bigdatafinance - 6 

26 aug 2016 

case studies 

price-based classification models 

    dixon et al. (2016) use a deep neural network to predict 

the sign of the price change over the next 5 minutes for 43 
commodity and forex futures. 
architecture     their input layer has 9,896 neurons for 
input features made up of lagged price differences and co-
movements between contracts. there are 5 learned fully-
connected layers. the first of the four hidden layers 
contains 1,000 neurons, and each subsequent layer tapers 
by 100 neurons. the output layer has 135 neurons (3 for 
each class {-1, 0, 1} times 43 contracts). 

 

bigdatafinance - 7 

26 aug 2016 

case study 

   

price-based classification models 

takeuchi and lee (2013) look to enhance the momentum effect by predicting 
which stocks will have higher or lower monthly returns than the median. 
architecture     they use an auto-encoder composed of stacked rbms to extract 
features from stock prices which they then pass to a feed-forward neural network 
classifier. each rbm consists of one layer of visible units and one layer of hidden 
units connected by symmetric links. the first layer has 33 units for input features 
from one stock at a time. for every month t, the features include the 12 monthly 
returns for month t-2 through t-13 and the 20 daily returns approximately 
corresponding to month t. they normalize each of the return features by 
calculating the z-score relative to the cross-section of all stocks for each month or 
day. the number of hidden units in the final layer of the encoder is sharply 
reduced, forcing id84. the output layer has 2 units, 
corresponding to whether the stock ended up above or below the median return 
for the month. final layer sizes are 33-40-4-50-2. 

bigdatafinance - 8 

26 aug 2016 

case study 

price-based classification models 
    batres-estrada (2015) predicts which s&p 500 stocks 

will have above-median returns for each given day, and 
his work appears to be heavily influenced by takeuchi 
and lee (2013). 
architecture     he uses a 3-layer dbn coupled to an 
mlp. he uses 400 neurons in each hidden layer, and he 
uses a sigmoid activation function. the output layer is a 
softmax layer with two output neurons for binary 
classification (above median or below). the dbn is 
composed of stacked rbms, each trained sequentially. 

bigdatafinance - 9 

26 aug 2016 

case study 

price-based classification models 
    sharang and rao (2015) use a dbn trained on technical indicators 

to trade a portfolio of us treasury note futures. 

    zhu et al. (2016) make trade decisions using oscillation box theory 

based on dbns. oscillation box theory says that a stock price will 
oscillate within a certain range in a period of time. if the price 
moves outside the range, then it enters into a new box. the authors 
try to predict the boundaries of the box. their trading strategy is to 
buy the stock when it breaks through the top boundary or sell it 
when it breaks through the bottom boundary. 
architecture     they use a dbn made up of stacked rbms and a 
final back-propagation layer. 

bigdatafinance - 10 

26 aug 2016 

case study 

text-based classification models 
    r  nnqvist and sarlin (2016) predict bank distress using news articles. 
specifically, they create a classifier to judge whether a given sentence 
indicates distress or tranquility. 
architecture     they use two neural networks in this paper. the first is for 
semantic pre-training to reduce dimensionality. for this, they run a sliding 
window over text, taking a sequence of 5 words and learning to predict 
the next word. they use a feed-forward topology where a projection layer 
in the middle provides the semantic vectors once the connection weights 
have been learned. the second neural network is for classification. instead 
of a million inputs (one for each word), they use 600 inputs from the 
learned semantic model. the first layer has 600 nodes, the middle layer 
has 50 rectified linear hidden nodes, and the output layer has 2 nodes 
(distress/tranquil). 

bigdatafinance - 11 

26 aug 2016 

case study 

text-based classification models 
    fehrer and feuerriegel (2015) train a model to 

predict german stock returns based on headlines. 
architecture     they use a recursive autoencoder 
with an additional softmax layer in each 
autoencoder for estimating probabilities. they 
perform three-class prediction {-1, 0, 1} for the 
following day   s return of the stock associated 
with the headline. 

bigdatafinance - 12 

26 aug 2016 

case study 

text-based classification models 

    ding et al. (2015) use structured information extracted from 

headlines to predict daily s&p 500 moves. headlines are processed 
with open ie to obtain structured event representations (actor, 
action, object, time). a neural tensor network learns the semantic 
compositionality over event arguments by combining them 
multiplicatively instead of only implicitly, as with standard neural 
networks. 
architecture     they combine short-term and long-term effects of 
events, using a id98 to perform semantic composition over the 
input event sequence. they use a max pooling layer on top of the 
convolutional layer, which makes the network retain only the most 
useful features produced by the convolutional layer. 

bigdatafinance - 13 

26 aug 2016 

case study 

volatility prediction 

    xiong et al. (2015) predict the daily volatility of 
the s&p 500, as estimated from open, high, low, 
close prices. 
architecture     they use a single lstm hidden 
layer consisting of one lstm block. for inputs 
they use daily s&p 500 returns and volatilities. 
they also include 25 domestic google trends, 
covering sectors and major areas of the economy. 

bigdatafinance - 14 

26 aug 2016 

case study 

portfolio optimization 

    heaton et al. (2016) attempt to create a portfolio that outperforms 
the biotech index ibb. they have the goal of tracking the index with 
few stocks and low validation error. they also try to beat the index 
by being anti-correlated during periods of large drawdowns. they 
don   t directly model the covariance matrix, rather it is trained in the 
deep architecture fitting procedure, which allows for nonlinearities. 
architecture     they use auto-encoding with id173 and 
relus. their auto-encoder has one hidden layer with 5 neurons. 

bigdatafinance - 15 

26 aug 2016 

where can i use deep neural 

networks? 

   

   
   

   

   
   

   

to extract feature vectors from time-series, text, multidimentional time-series, 
multi-modal data (news feeds + stock prices +    ) 
to classify the extracted feature vectors (buy, sell, stay). 
to predict/forecast an event after we have extract appropriate feature vectors 
(e.g., stock price, maximum gain/loss, etc) 
to correlate sequences finding how a series of events (e.g., in politics) affects the 
events in finance (e.g., stock trade). 
to detect/localize important/interesting behaviors in the time-series 
to make focused decisions based on id12 (where to look in the data in 
order to decide). 
to extract sentiments/concepts/trends from text (news, tweets, blogs, etc)  media 
data (radio, tv, youtube, etc) and social networks (facebook, tweeter, etc) 

bigdatafinance - 16 

26 aug 2016 

why should i use deep neural 

networks 

    general learning machines that learn based on (big) data. 
    there are models that are specialized to specific tasks 

(id98s, lstms, etc) 

    they have proven that they perform and generalize much 

better that other techniques for many difficult tasks (vision, 
speech, text, translation and general ai) 

    they are not yet fully applied to financial data (opportunity 

for novel and efficient publishable solutions) 

bigdatafinance - 17 

26 aug 2016 

bigdatafinance - 18 

26 aug 2016 

bigdatafinance - 19 

26 aug 2016 

 

bigdatafinance - 20 

26 aug 2016 

 

bigdatafinance - 21 

26 aug 2016 

 

bigdatafinance - 22 

26 aug 2016 

 

bigdatafinance - 23 

26 aug 2016 

 

bigdatafinance - 24 

26 aug 2016 

 

bigdatafinance - 25 

26 aug 2016 

 

bigdatafinance - 26 

26 aug 2016 

 

bigdatafinance - 27 

26 aug 2016 

 

bigdatafinance - 28 

26 aug 2016 

 

bigdatafinance - 29 

26 aug 2016 

 

bigdatafinance - 30 

26 aug 2016 

 

bigdatafinance - 31 

26 aug 2016 

 

bigdatafinance - 32 

26 aug 2016 

 

bigdatafinance - 33 

26 aug 2016 

 

bigdatafinance - 34 

26 aug 2016 

 

bigdatafinance - 35 

26 aug 2016 

 

bigdatafinance - 36 

26 aug 2016 

used material and useful resources 

    http://gregharris.info/a-survey-of-deep-learning-techniques-

applied-to-trading 

    http://vision.stanford.edu/teaching/cs231n/syllabus.html 
    http://www.deeplearningbook.org/ 
    http://www.iro.umontreal.ca/~bengioy/yoshua_en/talks.html 
    https://developer.nvidia.com/deep-learning-courses 
    http://arxiv.org/abs/1602.06561 
    http://www.slideshare.net/sebastienjehan/deeplearning-in-finance 
    http://deeplearning.net/tutorial/ 

bigdatafinance - 37 

26 aug 2016 

summary and conclusions 

    deep learning is one of the most powerful 

machine learning tool you have available 
nowadays. 

    you can find several deep learning methods that 

are well suited for your problem. 

    not much work in financial data analysis and thus 
good opportunity for novel work and publications 

bigdatafinance - 38 

26 aug 2016 

thank you 

 

questions 

bigdatafinance - 39 

26 aug 2016 

