   #[1]monkeylearn blog    feed [2]monkeylearn blog    comments feed
   [3]monkeylearn blog    a gentle guide to machine learning comments feed
   [4]alternate [5]alternate

   [6][yh5baeaaaaalaaaaaabaaeaaaibraa7]
   [7][yh5baeaaaaalaaaaaabaaeaaaibraa7]
   [8][yh5baeaaaaalaaaaaabaaeaaaibraa7]
   [9][yh5baeaaaaalaaaaaabaaeaaaibraa7]
   [10]subscribe

     * [11]use cases
     * [12]machine learning
     * [13]news
     * [14]subscribe
     *
     * ____________________ (button)

   [15]subscribe

   [16]try monkeylearn
   [17]machine learning

a gentle guide to machine learning

   ra  l garreta
   by [18]ra  l garreta
   [19]august 27, 2015    14 min read

a gentle guide to machine learning

   machine learning is a subfield within artificial intelligence that
   builds algorithms that allow computers to learn to perform tasks from
   data instead of being explicitly programmed.

   got it? we can make machines learn to do things! the first time i heard
   that, it blew my mind. that means that we can program computers to
   learn things by themselves!

   the ability of learning is one of the most important aspects of
   intelligence. translating that power to machines, sounds like a huge
   step towards making them more intelligent. and in fact, machine
   learning is the area that is making most of the progress in artificial
   intelligence today; being a trendy topic right now and pushing the
   possibility to have more intelligent machines.

   this post will try to give the novice reader a brief introduction to
   machine learning. i   ll give a general overview of important concepts,
   applications and challenges when working with machine learning. it   s
   not the goal of this post to give a formal or exhaustive description
   about the topic, but to give some initial concepts to invite the reader
   to continue investigating.

the real thing about machine learning

   alright, not all is as beautiful as it sounds, machine learning has its
   limits. still, we can   t build intelligent machines like data from star
   trek or hal 9000 from 2001 a space odyssey. however, we have plenty of
   examples of real world applications where machine learning works like a
   charm. the following are some of the most common categories of
   practical machine learning applications:

image processing

   image processing problems basically have to analyze images to get data
   or do some transformations. some examples are:
     * image tagging, like in facebook, when the algorithm automatically
       detects that your face or the face of your friends appear in a
       photo. basically a machine learning algorithm learns from the
       photos you manually tag.
     * id42 (ocr), when algorithms learn to
       transform a manuscript or scanned text document into a digital
       version. the algorithm has to learn to transform an image of a
       written character into the corresponding digital letter.
     * self-driving cars: part of the mechanisms that allow cars to drive
       by themselves use image processing. a machine learning algorithm
       learns where   s the edge of the road, if there   s a stop sign or a
       car is approaching by looking at each frame taken by a video
       camera.

text analysis

   text analysis are processes where we extract or classify information
   from text, like tweets, emails, chats, documents, etc. some popular
   examples are:
     * spam filtering, one of the most known and used text classification
       applications (assign a category to a text). spam filters learn to
       classify an email as spam or ham depending on the content and the
       subject.
     * [20]id31, another application of text classification
       where an algorithm must learn to classify an opinion as positive,
       neutral or negative depending on the mood expressed by the writer.
     * information extraction, from a text, learn to extract a particular
       piece of information or data, for example, extracting addresses,
       entities, keywords, etc.

data mining

   data mining is the process of discovering patterns or making
   predictions from data. the definition is a bit generic, but think of it
   as mining useful information from a huge table in a database. each
   row would be our training instances, and each column a feature. we may
   be interested in predicting a new column in that table based on the
   rest of the columns, or discover patterns to group the rows. for
   example:
     * anomaly detection: detect outliers, for example for credit card
       fraud detection, you could detect which transactions are outliers
       from the usual purchasing pattern of a user.
     * association rules: for example, in a supermarket or e-commerce
       site, you can discover customer purchasing habits by looking at
       which products are bought together. this information can be used
       for marketing purposes.
     * grouping: for example, in a saas platform, group users by their
       behavior or their profile.
     * predictions: predict a variable (column in a database) from the
       rest of the variables. for example, you could predict the credit
       score of new customers in a bank based by learning from the
       profiles and credit score of current customers.

video games & robotics

   video games and robotics have been a huge field where machine learning
   has been applied. in general, we have an agent (game character or
   robot) that has to move within an environment (a virtual environment in
   a video game or physical environment in the case of robots). machine
   learning then can be used to allow the agent to perform tasks, like
   moving in an environment while avoiding obstacles or enemies. a very
   popular machine learning technique used in these cases is
   [21]id23, where the agent learns to perform a task by
   learning from the reinforcement of the environment (the reinforcement
   is negative if it hits an obstacle or positive if it gets to the goal).

alright, i got the value of machine learning, but how does it work?

   one of the first books i read about machine learning about ten years
   ago was [22]machine learning by tom mitchell. this book was written in
   1997, but the general concepts remain valid today.

   from that book, i like the following formal definition about machine
   learning:

   a computer program is said to learn to perform a task t from experience
   e, if its performance at task t, as measured by a performance metric p,
   improves with experience e over time.

   for example, an artificial game player that has to play chess (task t),
   could learn by looking at previous chess matches or playing against a
   tutor (experience e). it   s performance p can be measured by counting
   the percentage of games won against a human.

   let   s picture that in a couple of more examples:
     * example 1: a system that given an image, it has to say if barack
       obama   s face appears in that image (the generalization would be
       like facebook   s auto tagging).
     * example 2: a system that given a tweet, tells if it talks with a
       positive or negative mood.
     * example 3: a system that given some person   s profile, assigns a
       score representing the id203 of that person paying a credit
       loan.

   in example 1, the task is to detect when barack obama   s face appears in
   an image. the experience could be a set of images where barack obama   s
   face appears and others where it doesn   t appear. the performance could
   be measured as the percentage of new images that our system correctly
   tags.

   in example 2, the task is to assign the sentiment of a tweet. the
   experience could be a set of tweets and their corresponding sentiment.
   the performance could be measured as the percentage of new tweets that
   our system correctly classifies.

   in example 3, the task is to assign a credit score. the experience
   could be a set of user profiles with their corresponding credit scores.
   the performance could be measured as the squared error (the difference
   between the predicted and expected score).

   in order to allow the algorithm to learn to transform the input to the
   desired output, you have to provide what is called training instances
   or training examples, which in mitchell   s definition are defined as
   experience e. a training set is a set of instances that will work as
   examples from which the machine learning algorithm will learn to
   perform the desired task. pretty intuitive, isn   t it? it   s like when
   you show a little baby how to throw a ball, you throw the ball a couple
   of times to show him how to do it, and by looking at those examples, he
   starts to learn to do it himself.

   every training instance usually is represented as a fixed set of
   attributes or features. the features are the way to characterize each
   instance. for instance, in example 1, an image could be characterized
   by the gray level of each of its pixels. in example 2, a tweet could be
   characterized by the words that appear in the tweet. in example 3, a
   credit record could be represented by the age of the person, the
   salary, the profession, etc.

   calculating and selecting the proper features to represent an instance
   is one of the most important tasks when working with machine learning,
   we   ll take a look at this point later in this post.

categories of machine learning algorithms

   at this point we have to talk about two general categories of machine
   learning algorithms: supervised learning or unsupervised learning
   algorithms. the main difference between both approaches resides in the
   way we feed training examples to our algorithm, how the algorithm uses
   them and the type of problems they solve.

supervised learning

   in the case of [23]supervised learning, the machine learning algorithm
   can be seen as a process that has to transform a particular input to a
   desired output.

   the machine learning process then has to learn how to transform every
   possible input to the correct/desired output, so each training example
   has the particular input and the desired output.

   in the example about the artificial chess player, our input would be a
   particular chess board state, and the output would be the best possible
   movement in that situation.

   depending on the type of output, we have two subtypes of supervised
   learning:

classification

   when the output value belongs to a discrete and finite set, we   re
   talking about a [24]classification. example 2 can be solved as a
   classification problem, the output is a finite set of options:
   positive, negative or neutral. in this case, our training examples will
   look like:

   [25]table1

regression

   when the output value is a continuous number, for example, a
   id203, then we   re talking about a [26]regression problem. example
   3 is a regression as the result is a number between 0 and 1 that
   represents the id203 that a person will pay his debts. in this
   case, our training examples will look like:

   [27]table2

   supervised learning is the most popular category of machine learning
   algorithms. the disadvantage of using this approach is that for every
   training example, we have to provide the correct output, and in many
   cases, this is quite expensive. for example, in the case of sentiment
   analysis, if we need 10,000 training examples (tweets), we would have
   to tag each tweet with the correct sentiment (positive, negative or
   neutral). that would require a group of humans to read and tag each
   tweet (quite a time consuming and boring task). this is usually a very
   common bottleneck for machine learning algorithms: gather quality
   tagged training data.

unsupervised learning

   there   s a second category of machine learning algorithms called
   [28]unsupervised learning. in this case, the training examples only
   need to be the input to the algorithm, but not the desired output. the
   typical use case is to discover the hidden structure and relations
   between the training examples. a typical example are [29]id91
   algorithms, where we learn to find similar instances or groups of
   instances (clusters). e.g.: we have a news article and we want to get
   similar ones to recommend. some id91 algorithms like [30]id116
      learn    to do that by only looking at the input.

machine learning algorithms

   ok, here   s when the math and logic comes to action. in order to
   transform an input to a desired output we can use different models.
   machine learning is not a unique type of algorithm, perhaps you heard
   about support vector machines, naive bayes, id90 or deep
   learning. those are different machine learning algorithms that try to
   solve the same problem: learn to transform every input to the correct
   output.

   those different machine learning algorithms use different paradigms or
   techniques to do the learning process and represent the knowledge of
   what they have learned.

   but before we go ahead and talk about each algorithm, a common
   principle is that, machine learning algorithms try to make
   generalizations. that is, they try to explain something with the
   simplest theory, a principle known as the [31]occam   s razor. every
   machine learning algorithm, regardless of the paradigm it uses, will
   try to create the simplest hypothesis (the one that makes fewest
   assumptions) that explains most of the training examples.

   there are lot of machine learning algorithms, but let   s briefly mention
   three of the most popular ones:
     * support vector machines: the model tries to build a set of
       hyperplanes in a high dimensional space that tries to separate
       instances of different classes by getting the largest separation
       between the nearest instances from different classes. the concept
       intuitively is simple, but the model can be very complex and
       powerful. in fact, for some domains it is one of the best machine
       learning algorithms you can use nowadays.
     * probabilistic models: these models usually try to predict the
       correct response by modeling the problem with a id203
       distribution. perhaps the most popular algorithms in this category
       are [32]naive bayes classifiers, that use the id47
       alongside with strong independence assumptions between the
       features. one of their advantages besides being a simple yet
       powerful model, is that they return not only the prediction but
       also the degree of certainty, which can be very useful.
     * deep learning: is a new trend in machine learning based on the very
       known [33]id158 models. neural networks have a
       connectionist approach, they try to emulate (in a very simplified
       way) the way the brain works. basically they consist of a huge set
       of interconnected neurons (the basic unit of processing), organized
       in various layers. deep learning has, in a few words, developed new
       structures with deeper layers and improved the learning algorithms
       to not only try to learn but also to build structures to represent
       the most important features automatically with higher levels of
       abstraction.

important aspects when dealing with machine learning

   again, machine learning sounds like a beautiful concept, and it is, but
   there are some processes involved that are not so automatic. in fact,
   many times manual steps are required when designing the solution.
   nevertheless, they are of huge importance in order to obtain decent
   results. some of those aspects are:

which type of machine learning algorithm should i use?

   supervised or unsupervised?

   do you have tagged data? that is, the input with its corresponding
   output? in that case you can apply supervised learning algorithms. if
   not, perhaps unsupervised algorithms can solve the problem.

   classification, regression or id91?

   that mainly depends on what you   re trying to solve. if you want to tag
   data (assign a tag within a discrete set of options), classification
   may be the right option. if on the other hand, you need to assign a
   number, for example a score, regression may be the best option for you.
   perhaps what you need is to recommend similar products to users
   depending on what they are currently looking at in an e-commerce site,
   in that case id91 could be the best option for you.

   deep learning, id166, naive bayes, id90    which one is the best?

   the answer for me is: none of them. obviously deep learning and support
   vector machines have demonstrated they are the most powerful and
   versatile in different applications. but take into account that
   depending on the particular application, some machine learning
   algorithms may be a better choice than others. just see which are their
   individual strengths and try them!

feature engineering

   feature engineering is the process by which we extract and select the
   most important features to be used to represent our training examples
   and instances to be processed by our machine learning algorithm. this
   process is one of the most important aspects of machine learning (and
   sometimes not given enough credit and importance).

   pay attention to that: if you don   t provide quality features to your
   algorithm, the results will be bad, no matter if you use the best
   machine learning algorithm out there. it   s like trying to learn to read
   with your eyes in complete darkness, you won   t be able to do that, no
   matter how intelligent you are.

feature extraction

   in order to feed the machine learning algorithm with data, you usually
   have to transform the raw data into something that the algorithm can
      understand   . that process is known as feature extraction. usually
   we   re talking about transforming the raw data into a vector of
   features.

   in example 1, how do we feed the machine learning algorithm with an
   image?

   well, a straightforward approach would be to transform the image into a
   vector where each component is the gray value of each pixel in the
   image. so, each component or feature, would be a number between say 0
   and 255, 0 being black, 255 white and the range between 1 to 254 the
   possible shades of gray.

   this approach may work, but perhaps it would work better if we provide
   higher level features:
     * does the image contain the face of a person?
     * what   s the skin color?
     * what   s the eye color?
     * does the face have hair?
     *    

   those are higher level features, that feed the algorithm with more
   knowledge than just the gray level of each pixel (and their calculation
   may be done by other machine learning algorithms!). by providing higher
   level features we   re    helping    the machine learning algorithm with
   better information to learn to decide if my or someone else   s face
   appears in an image.

   if we provide better feature extraction:
     * we   ll have more chances that our algorithm will learn to perform
       the desired task.
     * we may need less training examples to learn.
     * as a result, we may reduce dramatically the time needed to train
       our model.

feature selection

   sometimes (not to say mostly), the features that we selected to feed
   our algorithm may be useless. for example, when trying to tag the
   sentiment of a tweet, we could add the length of the tweet as a
   feature, the time of the day the tweet was written, etc. those features
   may be useful or not, and there are automatic methods to figure out
   which of them are the most useful. intuitively, feature selection
   algorithms use techniques to score each feature and return only the
   most valuable ones according to that score.

   another important thing to keep in mind is: avoid using huge feature
   sets. one may be tempted to add all the possible features to the model
   and let the algorithm just learn. but that   s not a good idea, as we add
   more features to represent our instances, the dimension of the space
   increases, making it more sparse. intuitively, as we get more features,
   we have to get many many instances to represent a decent amount of the
   combinations. this is a very common problem known as the [34]curse of
   dimensionality, as the complexity of the model grows, the number of
   training examples needed grows exponentially, and believe me, that   s a
   problem.

training examples

   so, you have to feed the machine learning algorithm with training
   examples. depending on the problem you want to solve, we may be talking
   in the order of hundreds, thousands, millions or billions of training
   examples. besides, it   s very important to keep the quality of the
   examples, if you feed the algorithm with wrong examples, the chances to
   obtain good results are low.

   collecting quality data in huge volumes to train machine learning
   algorithms is usually an expensive thing to do. unless you already have
   tagged data, you may have to manually tag the data yourself or pay
   others to do that. some tools to try to solve that are id104
   platforms where you can find labor to do the job. also id64 is
   a way to try to make tagging more efficient by using your own machine
   learning model to help you.

   the general rule regarding training examples is: the more quality
   training data you can gather, the better results you may get.

testing examples and performance metrics

   after we train a machine learning algorithm, we have to test how well
   it performs. this is super important, otherwise you won   t know if your
   model actually learned anything!

   the concept is simple, we use a testing set, a set of instances not
   contained in the training set. basically we   ll input every testing
   example to our model and see if it performs as expected. in the case of
   supervised learning classification, we just input each testing instance
   and check if the outputs are what we expected. if our model returns the
   correct output on 95% of the testing examples, we say that our model
   has an accuracy of 95%.

   it   s important to remember that the training and testing sets of
   instances must be disjoint, this is the only way to test the
   generalization and prediction power of your model. you may have very
   good results by measuring the accuracy in your training data, but get
   poor results when measuring in a separate testing set. that problem is
   known as [35]overfitting, that is, the algorithm overfits the training
   examples and has a poor predictive power. usually the way to avoid that
   is to try to use a simpler model with less features, simplify the model
   and use a bigger and more representative training set.

   accuracy is the most basic metric, you should also look at other
   metrics like [36]precision and recall which will tell you how well the
   algorithm performs on each class (when working with supervised learning
   classification). [37]confusion matrices are a great tool to see where
   our classification algorithm is    confusing    predictions.

   for regression and id91 problems you have other sets of metrics
   that will allow to see if your algorithm is performing well.

performance

   in real world applications, if you have to deploy a solution in
   production, you will have to build a robust and performant solution. in
   the case of machine learning applications, this can be a complex task.
   first, you have to select the machine learning framework, which is not
   easy as not all programming languages have strong tools on that. python
   and [38]scikit-learn are good examples of a programming language where
   a strong machine learning framework was built.

   having chosen your framework, performance issues may arise. depending
   on the amount of data, complexity and algorithm designed, it may take
   large amounts of computing power and memory to run the training
   process. you   ll probably have to run multiple trainings until you get
   decent results. besides, usually you may be retraining your model to
   cover new instances and keep improving its accuracy.

   in order to train huge models and get fast results when using it, we   re
   usually talking of various gbs of ram and multi-core machines to
   parallelize the processing.

   these are mostly practical issues, but definitively important ones if
   you want to deploy a real machine learning solution in production.

final words

   that   s it, a brief overview of what machine learning is about. there
   are plenty of other real world applications not covered here, plenty of
   other machine learning algorithms and concepts to talk about, but we
   leave the reader to do his/her own research on that.

   machine learning is powerful but hard, the difficulties and aspects to
   take into account described in this post are just the tip of the
   iceberg.

   usually a certain background in computer science and in particular,
   machine learning is required to obtain decent results. one can end very
   disappointed by the many difficulties to solve before getting on track.

   this is why we created [39]monkeylearn, to democratize the access to
   machine learning technologies applied to text analysis. to avoid
   reinventing the wheel and allow every software developer or
   entrepreneur to quickly get practical results. these are our main
   challenges, to abstract the end user of all of these problems, ranging
   from machine learning complexities to practical scalability issues to
   make just plug and play machine learning.

   hope you enjoyed this post! just drop me a line if you have any
   questions or comments!

   ____________________

   subscribe
   leave this field empty if you're human: ____________________
   [40]machine learning
   ra  l garreta

ra  l garreta

   monkeylearn co-founder & ceo. machine learning and natural language
   processing expert. author of "learning scikit-learn: machine learning
   in python".
   [41]notification

posts you might like   

   [42]machine learning

[43]getting started in natural language processing (nlp)

   let   s say you heard about natural language processing (nlp), some sort
   of technology that can   
   javier couto
   [44]javier couto    [45]june 7, 2018    8 min read

have something to say?

   [yh5baeaaaaalaaaaaabaaeaaaibraa7]

text analysis with machine learning

   turn tweets, emails, documents, webpages and more into actionable data.
   automate
   business processes and save hours of manual data processing.
   [46]try monkeylearn
   [yh5baeaaaaalaaaaaabaaeaaaibraa7]
   [yh5baeaaaaalaaaaaabaaeaaaibraa7]
   [yh5baeaaaaalaaaaaabaaeaaaibraa7]
   [yh5baeaaaaalaaaaaabaaeaaaibraa7]

   [47][yh5baeaaaaalaaaaaabaaeaaaibraa7]
     * [48]analyze text at scale with machine learning
     * [49]try monkeylearn

   ____________________ (button)

get awesome content in your inbox every week

   stay up to date with our content and receive tutorials, guides and cool
   posts about machine learning!

   ____________________

   subscribe
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://monkeylearn.com/blog/feed/
   2. https://monkeylearn.com/blog/comments/feed/
   3. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/feed/
   4. https://monkeylearn.com/blog/wp-json/oembed/1.0/embed?url=https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
   5. https://monkeylearn.com/blog/wp-json/oembed/1.0/embed?url=https://monkeylearn.com/blog/gentle-guide-to-machine-learning/&format=xml
   6. https://monkeylearn.com/blog/
   7. https://monkeylearn.com/blog/
   8. https://monkeylearn.com/blog/
   9. https://monkeylearn.com/blog/
  10. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  11. https://monkeylearn.com/blog/category/use-cases/
  12. https://monkeylearn.com/blog/category/machine-learning/
  13. https://monkeylearn.com/blog/category/news/
  14. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  15. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  16. https://monkeylearn.com/
  17. https://monkeylearn.com/blog/category/machine-learning/
  18. https://monkeylearn.com/blog/author/raul/
  19. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  20. https://monkeylearn.com/sentiment-analysis/
  21. https://en.wikipedia.org/wiki/reinforcement_learning
  22. http://www.amazon.com/machine-learning-tom-m-mitchell/dp/0070428077/ref=sr_1_10?ie=utf8&qid=1440450490&sr=8-10&keywords=machine+learning
  23. https://en.wikipedia.org/wiki/supervised_learning
  24. https://en.wikipedia.org/wiki/statistical_classification
  25. https://blog.monkeylearn.com/wp-content/uploads/2015/08/table1.png
  26. https://en.wikipedia.org/wiki/regression_analysis
  27. https://blog.monkeylearn.com/wp-content/uploads/2015/08/table2.png
  28. https://en.wikipedia.org/wiki/unsupervised_learning
  29. https://en.wikipedia.org/wiki/cluster_analysis
  30. https://en.wikipedia.org/wiki/id116_id91
  31. https://en.wikipedia.org/wiki/occam's_razor
  32. https://en.wikipedia.org/wiki/naive_bayes_classifier
  33. https://en.wikipedia.org/wiki/artificial_neural_network
  34. https://en.wikipedia.org/wiki/curse_of_dimensionality
  35. https://en.wikipedia.org/wiki/overfitting
  36. https://en.wikipedia.org/wiki/precision_and_recall
  37. https://en.wikipedia.org/wiki/confusion_matrix
  38. http://scikit-learn.org/
  39. http://www.monkeylearn.com/
  40. https://monkeylearn.com/blog/category/machine-learning/
  41. javascript:;
  42. https://monkeylearn.com/blog/category/machine-learning/
  43. https://monkeylearn.com/blog/getting-started-in-natural-language-processing-nlp/
  44. https://monkeylearn.com/blog/author/javier-couto/
  45. https://monkeylearn.com/blog/getting-started-in-natural-language-processing-nlp/
  46. https://app.monkeylearn.com/accounts/register/
  47. https://monkeylearn.com/blog
  48. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  49. https://app.monkeylearn.com/accounts/register/

   hidden links:
  51. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  52. https://www.facebook.com/sharer/sharer.php?u=https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  53. http://twitter.com/share?text=a+gentle+guide+to+machine+learning&url=https%3a%2f%2fmonkeylearn.com%2fblog%2fgentle-guide-to-machine-learning%2f
  54. https://www.linkedin.com/sharearticle?mini=true&url=https://monkeylearn.com/blog/gentle-guide-to-machine-learning&titlea%20gentle%20guide%20to%20machine%20learning&summary=&source=
  55. https://www.facebook.com/sharer/sharer.php?u=https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  56. http://twitter.com/share?text=a+gentle+guide+to+machine+learning&url=https%3a%2f%2fmonkeylearn.com%2fblog%2fgentle-guide-to-machine-learning%2f
  57. https://www.linkedin.com/sharearticle?mini=true&url=https%3a%2f%2fmonkeylearn.com%2fblog%2fgentle-guide-to-machine-learning%2f&titlea+gentle+guide+to+machine+learning&summary=&source=
  58. https://monkeylearn.com/blog/getting-started-in-natural-language-processing-nlp/
  59. https://monkeylearn.com/blog/gentle-guide-to-machine-learning/
  60. http://twitter.com/share?text=getting+started+in+natural+language+processing+%28nlp%29&url=https%3a%2f%2fmonkeylearn.com%2fblog%2fgetting-started-in-natural-language-processing-nlp%2f
  61. https://www.facebook.com/sharer/sharer.php?u=https://monkeylearn.com/blog/getting-started-in-natural-language-processing-nlp/
  62. https://plus.google.com/share?url=https://monkeylearn.com/blog/getting-started-in-natural-language-processing-nlp/
