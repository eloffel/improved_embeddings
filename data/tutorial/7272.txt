convolutional neural 
network

                 | jahan@nvidia.com

                 | hryu@nvidia.com /                  | hanbyuly@nvidia.com

1

background

convolution layer & id119

agenda

pooling layer

id172

id98 models

2

what is a convolution?

a refresher of 2d convolutions

i1

i7

i13

i19

i25

i31

f1

f4

f7

image

filter

i2

i8

i14

i20

i26

i32

i3

i9

i15

i21

i27

i33

i4

i10

i16

i22

i28

i34

i5

i11

i17

i23

i29

i35

i6

i12

i18

i24

i30

i36

f2

f5

f8

f3

f6

f9

o1

= f1*i1 + f2*i2 + f3*i3 + f4*i7 + f5*i8 + 

f6*i9 + f7*i13 + f8*i14 + f9*i15

3

what is a convolution?

a refresher of 2d convolutions

o1

o2

i1

i7

i13

i19

i25

i31

f1

f4

f7

image

filter

i2

i8

i14

i20

i26

i32

i3

i9

i15

i21

i27

i33

i4

i10

i16

i22

i28

i34

i5

i11

i17

i23

i29

i35

i6

i12

i18

i24

i30

i36

f2

f5

f8

f3

f6

f9

4

what is a convolution?

a refresher of 2d convolutions

i1

i7

i13

i19

i25

i31

f1

f4

f7

image

filter

i2

i8

i14

i20

i26

i32

i3

i9

i15

i21

i27

i33

i4

i10

i16

i22

i28

i34

i5

i11

i17

i23

i29

i35

i6

i12

i18

i24

i30

i36

f2

f5

f8

f3

f6

f9

o1

o2

o3

5

what is a convolution?

a refresher of 2d convolutions

i1

i7

i13

i19

i25

i31

f1

f4

f7

image

filter

i2

i8

i14

i20

i26

i32

i3

i9

i15

i21

i27

i33

i4

i10

i16

i22

i28

i34

i5

i11

i17

i23

i29

i35

i6

i12

i18

i24

i30

i36

f2

f5

f8

f3

f6

f9

o1

o2

o3

    and so on until you   ve covered the 

entire image

6

hierarchical representations

how id98s work

slide credit: 
yann lecun

7

some modern id98s

y. lecun et al. 1989-1998 : handwritten digit reading

a. krizhevsky, g. hinton et al.  2012 : id163 classification winner

8

convolutional neural network

what is it?

    a neural network where the linear operator is a convolution
    convolutions are nice because they   re invariant to translation 

   

filter doesn   t care where in the image the object of interest is located

    force weight sharing across input pixels

image

filter

9

the basic id98 layer

three components

input

convolution

pooling (eg. max 

pooling)

activation (eg. 
point-wise relu)

output

translation-invariant 
linear transformation

downsampling

non-linearity

together, they comprise a non-linear 2-d filter that   s at the heart of the id98

10

what does our data look like?

image and filter

    

   

    

    

    

filter

   . a set of     

    

image

   . a batch of size     

11

what does our data look like?

image and filter

    

   

    

    

    

filter

   . a set of     

attribute

symbol

batch size

input channels 
(same for image and filter)

image height x image width

output channels 
(equal to number of filters)

    

    

             

    

filter height x filter width

              

12

    

image

   . a batch of size     

convolution layer

32x32x3 image

32

height

width

32

3

depth

stanfords cs231n

13

convolution layer

32x32x3 image

5x5x3 filter

32

32

3

14

convolution layer

32x32x3 image

32

1 number

32

3

15

convolution layer

32x32x3 image

activation map

32

1 filter output

28

32

3

28

1

16

convolution layer

32x32x3 image

activation maps

32

convolution layer

28

28

we stack these up to get a    new image    of size 
28x28x6!

6

17

32

3

convolution layer

32

28

24

conv,
relu
e.g. 6
5x5x3
filters

28

6

conv,
relu
e.g. 10
5x5x6 
filters

24

10

32

3

   .

conv,
relu

18

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter

7

19

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter

7

20

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter

7

21

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter

7

22

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter

    5x5 output

7

23

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter 
applied with stride 2

7

24

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter 
applied with stride 2

7

25

a closer look at spatial dimension

7

7x7 input (spatially)
assume 3x3 filter 
applied with stride 2
    3x3 output

7

26

zero padding

to avoid spatial shrinking by convolution

7

0

0

0

0

0

0

0

0

0

7

                                          =

                                      + 2                                                                               

                                         

+ 1

32

28

24

conv,
relu
e.g. 6
5x5x3
filters

conv,
relu
e.g. 6
5x5x3
filters

32

32

32

3

3

28

32

6

6

   .

conv,
relu

conv,
relu
e.g. 10
5x5x6 
filters

24

10

32

32

conv,
relu
e.g. 10
5x5x6 
filters

   .

conv,
relu

32

10

27

convolution layer as a neuron

32

32

3

5

28

28

28

another example

this time, a tabular representation

overfeat, 2014

29

another example

this time, a tabular representation

overfeat, 2014

convolutional layers (feature extractor)

30

another example

this time, a tabular representation

overfeat, 2014

convolutional layers (feature extractor)

fully connected layers

(classifier)

31

convolution operation

32

convolution operation

input image

input filter

33

convolution operation

pointwise multiply and sum, scalar 

output

            [    ,     ] =  

                                  +     ,                          +      .                 [    ,     ]

    ,                                

input image

input filter

intermediate output

34

convolution operation

pointwise multiply and sum, scalar 

output

            [    ,     ] =  

                                  +     ,                          +      .                 [    ,     ]

    ,                                

input image

input filter

intermediate output

35

convolution operation

pointwise multiply and sum, scalar 

output

            [    ,     ] =  

                                  +     ,                          +      .                 [    ,     ]

    ,                                

input image

input filter

intermediate output

36

convolution operation

pointwise multiply and sum, scalar 

output

            [    ,     ] =  

                                  +     ,                          +      .                 [    ,     ]

    ,                                

input image

input filter

intermediate output

37

convolution operation

pointwise multiply and sum, scalar 

output

            [    ,     ] =  

                                  +     ,                          +      .                 [    ,     ]

    ,                                

input image

input filter

intermediate output

38

convolution operation

            [    ,     ] =  
            [    ,     ,     ] =  

                                  +     ,                          +      .                 [    ,     ]
        [    ]                          +     ,                          +      .                 [    ][    ,     ]

    ,                                

    ,                                

input image

input filter

intermediate output

39

convolution operation

            [    ,     ] =  
            [    ,     ,     ] =  

                                  +     ,                          +      .                 [    ,     ]
        [    ]                          +     ,                          +      .                 [    ][    ,     ]

    ,                                

    ,                                

input image

input filter

intermediate output

40

convolution operation

            [    ,     ] =  
            [    ,     ,     ] =  

                                  +     ,                          +      .                 [    ,     ]
        [    ]                          +     ,                          +      .                 [    ][    ,     ]

    ,                                

    ,                                

                             ,      =  
    

            [    ,     ,     ]

input image

input filter

intermediate output

final output

41

convolution operation

            [    ,     ] =  
            [    ,     ,     ] =  

                                  +     ,                          +      .                 [    ,     ]
        [    ]                          +     ,                          +      .                 [    ][    ,     ]

    ,                                

    ,                                

                             ,      =  
    

            [    ,     ,     ]

input image

input filter

intermediate output

final output

42

convolution operation

            [    ,     ] =  
            [    ,     ,     ] =  

                                  +     ,                          +      .                 [    ,     ]
        [    ]                          +     ,                          +      .                 [    ][    ,     ]

    ,                                

    ,                                

                             ,      =  
    

            [    ,     ,     ]

input image

input filter

intermediate output

final output

43

convolution operation

            [    ,     ] =  
            [    ,     ,     ] =  

                                  +     ,                          +      .                 [    ,     ]
        [    ]                          +     ,                          +      .                 [    ][    ,     ]

    ,                                

    ,                                

                             ,      =  
    

            [    ,     ,     ]

input image

input filter

intermediate output

final output

why do it once if you can do it n times ? batch the whole thing.

44

pooling

downsampling

224

224

45

pooling

max or average of pixels in the window

224

224

downsampling

46

pooling

max or average of pixels in the window

224

224

downsampling

47

pooling

max or average of pixels in the window

224

224

downsampling

48

pooling

downsampling

224

224

49

pooling

downsampling

224

224

pooling accomplishes 2 things:
1. acts as a smoother, reducing the number of small, high-frequency variations
2. increases effective receptive field by down sampling the image at each step
-

may be counterproductive when pixel accurate locations are  required

50

examples of pooling 

for single depth slice:

max pooling

mean pooling

stochastic

pooling

1

5

3

1

1

5

3

1

1

5

3

1

1

6

2

2

1

6

2

2

1

6

2

2

2

7

1

3

2

7

1

3

2

7

1

3

4

8

0

4

4

8

0

4

4

8

0

4

pool with 

2x2 filters and stride 2

6

3

3

2

5

2

8

4

5

2

4

0

common filter size:

2x2/3x3

common stride size:

2

51

optional layers

local response id172

input

conv + max pool 

+ activation

id172

output

52

local response id172

alexnet 2012

         =         /  (        )2

is the channel index of the input image
                 is some hard-coded subset of channels to normalize over
,      and      are also predetermined parameters

= 2,                      = 5,      = 10   4 and      = 0.75

   
   
   

53

local response id172

alexnet 2012

        

(    ,    ) =         

    ,     /(     +       
         

                    

        

    ,    

2

)    

         =         /  (        )2

    57.0         =              10     4 4 10     4     0 10     4 1         = , 5                                         = , 2     is the 

channel index of the input image
                     is some hard-coded subset of channels to normalize over

   
        ,      and      are also predetermined parameters
    motivation is to tone down the effect of    rogue    extreme hot-spots

54

other id172 routines
less frequent, but have been used effectively

local contrast id172 :

    operates within a feature map

look at a neighborhood of pixels centered at point-of-interest in (x,y) space 

   
    compute gaussian-weighted mean, and variance of these pixels
    normalize at point-of-interest                      = (                     )/    

batch id172: 

show remarkable improvement in convergence

   
    normalize across whole batch of images, rather than on a per-image basis

55

batch id172

motivation

    from the perspective of a layer     , the distribution of inputs in each iteration of 

the training process vary wildly

    think of a histogram of raw pixel values present in each batch of inputs to the layer

    this is because, at each iteration, the layers before it are being modified, 

possibly significantly

   

even with the simplifying assumption that the inputs to the network as a whole 
exhibit a somewhat constant distribution across all minibatches

    b.n. tries to normalize the distribution of inputs to a layer, to make the training 

process easier

56

id98 parameters you have to choose

id172

    id172 kernel     typical: gaussian with mean=0, 

std=1, over 7x7 pixels

    number of kernels to normalize over     typical: 5

pooling

    pooling ratio     typical value: (2,2)
    pooling function     max, sum, avg     max is most 

common

filtering+activation

    number of filters     typical values: 32, 64, 128
    filter size     typical values: 3x3, 4x4, 5x5 pixels
    step size
    activation function     use relu at the moment

57

id168s
quantify    wrongness   

    measures model quality : lower the loss, higher the accuracy 
    the term    id168    comes from the field of optimization

    conventional problem statement :    minimize loss subject to constraints   

    corrections in model during training originate with this value
    a conscious design choice, have significant impact on the learned model

    euclidean loss is a familiar option :          ,       =

1
    

 (                      )2

    more exotic variants exist, and are the subject of another session

58

choosing an architecture

aka black magic

    start with one of the    standard    architectures with similar input 

data properties

    modify the fully-connected layers according to output objective

    modify layer sizes until you overfit     then control overfitting (more 

later)

59

describing the network

caffe protobuf files

60

id98 architectures: googlenet

introduced multi-scale convolutional layers called    inception    layers

   going deeper with convolutions   , 
szegedy et al, google

61

practice

image classification for cifar-10

62

63

