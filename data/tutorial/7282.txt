defense against the dark arts: 
machine learning security and 

privacy

ian goodfellow, sta    research scientist, google brain 

baylearn 2017

an overview of a    eld

    this presentation summarizes the work of many 

people, not just my own / my collaborators 

    please check out the slides and view this link of  

extensive references 

    the presentation focuses on the concepts, not the 

history or the inventors

(goodfellow 2017)

machine learning pipeline

training data

learned parameters

learning algorithm

x    
x

  y

test output

test input

(goodfellow 2017)

privacy of training data

x       x

(goodfellow 2017)

de   ning (  ,   )-di   erential privacy 

(abadi 2017)

(goodfellow 2017)

private aggregation of teacher ensembles

(papernot et al 2016)

(goodfellow 2017)

training set poisoning

x       y

x

(goodfellow 2017)

id163 poisoning

(koh and liang 2017)

(goodfellow 2017)

adversarial examples
x    

  y

x

(goodfellow 2017)

model theft

x    
x

  y

     

(goodfellow 2017)

model theft++

x    
x

  y

  x
x

(goodfellow 2017)

     

advanced models can infer 

private information

(youyou et al 2014)

(goodfellow 2017)

automated crowdtur   ng

temperature

0.1

0.5

0.7

1.0

generated review text

i love this place! i have been here a few times and have never been disappointed. the service
is always great and the food is always great. the sta    is always friendly and the food is always
great. i will de   nitely be back and try some of their other food and service.
i love this place. i have been going here for years and it is a great place to hang out with friends
and family. i love the food and service. i have never had a bad experience when i am there.
my family and i are huge fans of this place. the sta    is super nice and the food is great. the
chicken is very good and the garlic sauce is perfect. ice cream topped with fruit is delicious
too. highly recommended!
i had the grilled veggie burger with fries!!!! ohhhh and taste. omgggg! very    avorful! it was
so delicious that i didn   t spell it!!

table 2: example of the generated    ve-star fake reviews targeting at a bu   et restaurant in nyc. more examples of generated
reviews are included in the appendix b.

(yao et al 2017)

 1

 0.8

 0.6

 0.4

precision
recall

 0.5

 0.4

 0.3

 0.2

machine-generated review
real review

(goodfellow 2017)

 

e
r
o
c
s
m
s
i
r
a
g

i

e
c
n
a
m
r
o
f
r
e
p
n
o

 

i

fake news

www.futureo   akenews.com

(goodfellow 2017)

machine learning for password 

guessing

(melicher et al 2016)

(goodfellow 2017)

ai for geopolitics?

(goodfellow 2017)

deep dive on adversarial 

examples

(goodfellow 2017)

since 2013, deep neural networks have 
matched human performance at...

...recognizing objects 
and faces   .

(szegedy et al, 2014)

(taigmen et al, 2013)

...solving captchas and 
reading addresses...

(goodfellow et al, 2013)

(goodfellow et al, 2013)

and other tasks...

(goodfellow 2017)

adversarial examples

timeline: 
   adversarial classi   cation    dalvi et al 2004: fool spam    lter 
   evasion attacks against machine learning at test time    
biggio 2013: fool neural nets 
szegedy et al 2013: fool id163 classi   ers imperceptibly 
goodfellow et al 2014: cheap, closed form attack

(goodfellow 2017)

turning objects into    airplanes   

(goodfellow 2017)

attacking a linear model

(goodfellow 2017)

adversarial examples from over   tting

o

x

x

x

x

o

o

o

(goodfellow 2017)

adversarial examples from 

excessive linearity

o

o

x

o

x

x

x

o

o

(goodfellow 2017)

modern deep nets are very 
modern deep nets are very (piecewise) linear

piecewise linear

rectified linear unit 
rectified linear unit

maxout 
maxout

carefully tuned sigmoid
carefully tuned sigmoid

lstm
lstm

google proprietary

(goodfellow 2017)

nearly linear responses in practice

x
a
m

t
f
o
s
 
o
t
 
t
n
e
m
u
g
r
a

(goodfellow 2017)

small inter-class distances

clean 
example

perturbation corrupted 

example

perturbation changes the true 
class

random perturbation does not 
change the class

perturbation changes the input 
to    rubbish class   

all three perturbations have l2 norm 3.96
this is actually small. we typically use 7!

(goodfellow 2017)

the fast gradient sign method

(goodfellow 2017)

maps of adversarial and random 

cross-sections

(collaboration with david warde-farley and nicolas papernot)

(goodfellow 2017)

estimating the subspace 

dimensionality

(tram  r et al, 2017)

(goodfellow 2017)

wrong almost everywhere

(goodfellow 2017)

adversarial examples for rl

(huang et al., 2017)

(goodfellow 2017)

rbfs behave more intuitively

(goodfellow 2017)

cross-model, cross-dataset 

generalization

(goodfellow 2017)

cross-technique transferability

(papernot 2016)

(goodfellow 2017)

transferability attack

target model with 
unknown weights, 
machine learning 
algorithm, training 
set; maybe non-
di   erentiable
deploy adversarial 
examples against the 
target; transferability 
property results in them 

succeeding

train your 
own model

substitute model 
mimicking target 
model with known, 
di   erentiable function

adversarial crafting 
against substitute

adversarial 
examples

(goodfellow 2017)

enhancing transfer with 

ensembles

(liu et al, 2016)

(goodfellow 2017)

adversarial examples in the 

human brain

these are 
concentric 
circles, 

not 

intertwined 

spirals. 

(pinna and gregory, 2002)

(goodfellow 2017)

adversarial examples in the 

physical world

(kurakin et al, 2016)

(goodfellow 2017)

training on adversarial examples

(goodfellow 2017)

success on mnist?

    open challenge to break model trained on adversarial 

perturbations initialized with noise 

    even strong, iterative white-box attacks can   t get more 

than 12% error so far 

    larger datasets remain challenging

(madry et al 2017)

(goodfellow 2017)

veri   cation

    given a seemingly robust model, can we prove that 

no adversarial examples exist near a given point? 

    yes, but hard to scale to large models (huang et al 

2016, katz et al 2017) 

    what about adversarial near test points that we 

don   t know to examine ahead of time?

(goodfellow 2017)

competition

best defense so far on id163: 
ensemble adversarial training, 

tram  r et al 2017. 

used as at least part of all top 10 entries in dev round 3

(goodfellow 2017)

clever hans

(   clever hans, 

clever 

algorithms,    
bob sturm)

(goodfellow 2017)

get involved!

https://github.com/tensor   ow/cleverhans

check out justin gilmer   s 

baylearn poster on adversarial 

sphere

(goodfellow 2017)

