introduction to 
machine learning

                 | jahan@nvidia.com
                 | hryu@nvidia.com /                  | hanbyuly@nvidia.com

agenda

introduction to deep learning

types of machine learning

example of machine learning

feature of machine learning

data features

2

deep learning     from research to technology

image classification, id164, localization, 

action recognition, scene understanding

id103, speech translation, 

natural language processing

pedestrian detection, traffic sign recognition

breast cancer cell mitosis detection, 
volumetric brain image segmentation

3

deep learning success
object classification and localization in images

image recognition challenge

1.2m training images     1000 object categories

hosted by

person
car
helmet
motorcycle

person
dog
chair

bird
frog

person
hammer
flower pot
power drill

120
100
80
60
40
20
0

gpu entries

110

60

2010

2011

4

2012

2013

2014

4

deep learning success
scene segmentation and classification

farabet, pami 2013

http://places.csail.mit.edu/ b. zhou et al. nips 14

5

deep learning success
artistic style recognition and imitation

http://demo.vislab.berkeleyvision.org/

6

deep learning success
activity recognition in video

https://www.youtube.com/watch?v=qrzq_ab1dzk

google/stanford

7

deep learning success
automotive and embedded systems

https://www.youtube.com/watch?v=fmvwlr0x1sk&feature=youtu.be

8

deep learning success
image noise reduction and upscaling

eigen , iccv 2010

dong et al, eccv 2014

9

deep learning success
end-to-end id103

baidu system is significantly simpler than traditional id103 
systems, which rely on laboriously engineered processing pipelines. 
deep speech does not need hand-designed components to model background 
noise, speaker variation etc, but instead directly learns them

10

deep learning success
style based music recommendation

http://benanne.github.io/2014/08/05/spotify-id98s.html

audio spectrogram 

input 

latent factors, 

i.e    tags    

output

11

deep learning success
language understanding

stanford nlp group

12

deep learning success
playing games

google deepmind

[cookie run]
https://www.youtube.com/watch?v=exxd6wjlj6s

13

machine learning fundamentals

14

machine learning

    machine learning is the ability to teach a computer without explicitly 

programming it

    examples are used to train computers to perform tasks that would be difficult to 

program

15

types of machine learning

   

supervised learning

    training data is labeled
    goal is correctly label new data

    id23

    training data is unlabeled
   
    goal is to perform better actions

system receives feedback for its actions

    unsupervised learning

    training data is unlabeled
    goal is to categorize the observations

16

machine learning

unsupervised 

learning

supervised 
learning

supervised     labelled data
convolutional nn (lecun)
recurrent nn (schmidhuber)

unsupervised     no labels

deep belief nets/stacked rbms
(hinton)
autoencoders (bengio, lecun, ng)

17

capability of machine to imitate intelligent 
behavior

18

learning from data
and some buzz words

artifical
intelligence
knowledge & reason
learning
planning
communicating
perceiving

machine
learning
learning from data

id109

handcrafted 
features

deep
learning
learning from data

neural networks

computer learned 
features

19

applications of machine learning

    handwriting recognition

convert written letters into digital letters

    language translation

   

translate spoken and or written languages (e.g. google translate)

id103

   

convert voice snippets to text (e.g. siri, cortana, and alexa)

image classification

   

   

label images with appropriate categories (e.g. google photos)

   

   

    autonomous driving

   

enable cars to drive

20

input-output examples

jeff dean, google, gtc 2015

21

features in machine learning

    features are the observations that are used to form predictions

   
   
   

for image classification, the pixels are the features
for voice recognition, the pitch and volume of the sound samples are the features
for id101, data from the cameras, range sensors, and gps are features

    extracting relevant features is important for building a model

    time of day is an irrelevant feature when classifying images
    time of day is relevant when classifying emails because spam often occurs at night

    common types of features in robotics

pixels (rgb data)

   
    depth data (sonar, laser rangefinders)
    movement (encoder values)
    orientation or acceleration (gyroscope, accelerometer, compass)

22

measuring success for classification

true positive
    correctly identified as relevant

true negative
    correctly identified as not relevant

classification

false positive
    incorrectly labeled as relevant

false negative
    incorrectly labeled as not relevant

23

example: identify cats

prediction:

image:

true
positive

images from the stl-10 dataset

true

negativ

e

false
negativ

e

false
positive

24

precision, recall, and accuracy

    precision

   
   

percentage of positive labels that are correct
precision = (# true positives) / (# true positives + # false positives)

    recall

percentage of positive examples that are correctly labeled

   
    recall = (# true positives) / (# true positives + # false negatives)

    accuracy

percentage of correct labels

   
    accuracy = (# true positives + # true negatives) / (# of samples)

25

supervised learning setup

inputs (aka features) - real-valued vectors of data

e.g. image pixels, audio spectrograms, character sequences

outputs (aka labels)     real-valued or categorical    truth    vectors
e.g. class labels for images, audio transcription, sentiment

training data  - many samples of input-output pairs

26

basic machine learning workflow

dataset

feed in raw 
data sample

model

feed in ground 

truth

predict 
something

scoring 
function

repeat until model 

is    good   

27

update model in 

response to 

prediction error

supervised learning objectives

    regression     outputs are continuous/real-valued scalar or vectors

   

example:

    classification     outputs are categorical

   

example: 

28

supervised vs unsupervised

29

score function (aka model)

a function that predicts the output given an input
example: id75

data

yi = mxi + c

slope

intercept

predicted output)

together, m and c are called the model parameters

y

c

  y
  x    =        /        

x

30

id168 (aka objective)

measures how good a particular choice of model parameters are
this is an application dependent choice that must be made
example: mean squared error

true output)

predicted output)

li = (   yi   yi)2
n xi

l =

li

1

y

c

total loss

sum over all input-output pairs

    =        /        

x

31

bias and variance

    bias: expected difference between model   s prediction and truth

    variance: how much the model differs among training sets

    model scenarios

    high bias: model makes inaccurate predictions on training data
    high variance: model does not generalize to new datasets
   
   

low bias: model makes accurate predictions on training data
low variance: model generalizes to new datasets

32

supervised learning

in simple examples like before we can often solve for the parameters analytically
as the function that maps inputs to outputs becomes more complex we lose this 
ability and must learn the parameters

training: the process of learning the model parameters that are optimal as judged 
by the id168
example: learn m and c so that the mean-squared error is minimized

33

supervised learning
how do we do this?

repeatedly feed training data into a learning algorithm
iteratively modify the model parameters to optimize (e.g. minimize) the loss 
function
repeat until the model is    good enough   

parameter adjustments:

{x1:n, y1:n}

score 
function
f (xi,    )

    

loss 

function

l

s
s
o
l

iterations

34

id119

finding the optimal parameters for our hypothesis

35

id119 - computation

partial 

parameter 

derivatives

update 
algorithm

parameter 

update 
algorithm

36

id119     learning rate
id119 hyperparameter

37

supervised learning
why do we do this?

given the model  we can take previously unseen inputs and predict the 
corresponding output.  we call this testing or deployment.

training data

{x1:n, y1:n}

model parameters

learning 
algorithm

   

testing data
xn+1,    

prediction 
algorithm

prediction
  yn+1

38

example: id163
image recognition challenge

1.2m training images     1000 object categories

hosted by

person 
car 
helmet 
motorcycle 

person 
dog 
chair 

bird 
frog 

person 
hammer 
flower pot 
power drill 

inputs: rgb images

outputs:

object labels

locations of objects

39

example: id163

training:

dog

id168 output

model

cat

testing:

honey badger

classifier

classifier

dog
cat

raccoon

parameters:

   

model

(same structure)

classifier

dog

40

example: id163

the model: convolutional neural network converting pixels to low-dimensional 
feature vector

score function: maps model output to vector of confidences that each object class 
is in the image

id168: difference between object class confidence vector and vector of true 
object classes in image

41

training problems

two major problems

underfitting: model is bad at it   s objective for all data
overfitting: model is really good at the objective for the training data but 

bad on the testing data

first line of defense:

break off a validation dataset from the training data, e.g. 25%
use it during training to check model performance on unseen data

42

training problems
underfit / overfit

low loss value may not the best

more validation is needed

43

training with validation

parameter adjustments:     

training data

{x1:n m, y1:n m}

validation data

{xn m+1:n, yn m+1:n}

score 
function
f (xi,    )

score 
function
f (xi,    )

loss 

function

l

loss 

function

l

training 

loss

validation 

loss

original training data

underfit

stop training here!

training

val

s
s
o
l

overfit

iterations

44

training with validation
validation dataset / cross-validation

45

training problems
some approaches to mitigating overfitting

add id173
add (naturally sensible) noise to training data

46

training problems
some approaches to mitigating underfitting

   if you're not overfitting, your network isn't big enough.        geoffrey hinton

get more training data
balance training data classes
increase model complexity
reduce id173 (constraints on parameter values)

47

live demo (20 mins)
image classification in digits

creation of training, validation and testing datasets
definition of score and id168
monitoring model training

48

bias and variance

    bias: expected difference between model   s prediction and truth

    variance: how much the model differs among training sets

    model scenarios

    high bias: model makes inaccurate predictions on training data
    high variance: model does not generalize to new datasets
   
   

low bias: model makes accurate predictions on training data
low variance: model generalizes to new datasets

50

