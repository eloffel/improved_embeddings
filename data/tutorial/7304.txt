1
neural 
networks
source: andrej karpathy & fei-fei li
2
source: andrej karpathy & fei-fei li
3
source: andrej karpathy & fei-fei li
4
source: andrej karpathy & fei-fei li
5
sigmoid activation function
source: andrej karpathy & fei-fei li
6
a single neuron can be used as a binary linear classifier
source: andrej karpathy & fei-fei li
7
be very careful with your brain analogies:


biological neurons:
many different types
dendrites can perform complex non-linear computations
synapses are not a single weight but a complex non-linear dynamical system
rate code may not be adequate
[dendritic computation. london and hausser]
source: andrej karpathy & fei-fei li
8
id180
source: andrej karpathy & fei-fei li
9
id180
sigmoid
squashes numbers to range [0,1]
historically popular since they have nice interpretation as a saturating    firing rate    of a neuron

a problem: saturated neurons    kill    the gradients
source: andrej karpathy & fei-fei li
10
id180
relu
computes f(x) = max(0,x)

does not saturate
very computationally efficient
converges much faster than sigmoid in practice! (e.g. 6x)

just one annoying problem   

hint: what is the gradient when x < 0?
source: andrej karpathy & fei-fei li
data cloud
11
active relu
dead relu
will never activate 
=> never update
source: andrej karpathy & fei-fei li
12
tldr: in practice:

use relu. be careful with your learning rates
never use sigmoid
source: andrej karpathy & fei-fei li
13
neural 
networks
source: andrej karpathy & fei-fei li
14
neural networks: architectures
   fully-connected    layers
   2-layer neural net   , or
   1-hidden-layer neural net   
   3-layer neural net   , or
   2-hidden-layer neural net   
source: andrej karpathy & fei-fei li
15
neural networks: architectures
number of neurons: ?
number of weights: ?
number of parameters: ?

source: andrej karpathy & fei-fei li
16
neural networks: architectures
number of neurons: 4+2 = 6
number of weights: [4x3 + 2x4] = 20
number of parameters: 20 + 6 = 26 (biases!)

number of neurons: ?
number of weights: ?
number of parameters: ?
source: andrej karpathy & fei-fei li
17
neural networks: architectures
number of neurons: 4+2 = 6
number of weights: [4x3 + 2x4] = 20
number of parameters: 20 + 6 = 26 (biases!)

number of neurons: 4 + 4 + 1 = 9
number of weights: [4x3+4x4+1x4]=32
number of parameters: 32+9 = 41
source: andrej karpathy & fei-fei li
18
neural networks: architectures
modern id98s: ~10 million neurons
human visual cortex: ~5 billion neurons

source: andrej karpathy & fei-fei li
19
what kinds of functions can a neural network represent?
[http://neuralnetworksanddeeplearning.com/chap4.html]
source: andrej karpathy & fei-fei li
20
what kinds of functions 
can a neural network 
represent?
[http://neuralnetworksanddeeplearning.com/chap4.html]

source: andrej karpathy & fei-fei li
21
setting the number of layers and their sizes
more neurons = more capacity
source: andrej karpathy & fei-fei li
22
(you can play with this demo over at convnetjs: http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html)
do not use size of neural network as a regularizer. use stronger id173 instead:
source: andrej karpathy & fei-fei li
23

training neural networks

24
mini-batch id119
loop:
sample a batch of data
backprop to calculate the analytic gradient  
perform a parameter update

source: andrej karpathy & fei-fei li
25
choose the architecture:
say we start with one hidden layer of 50 neurons:












input layer
hidden layer
output layer
cifar-10 images, 3072 numbers
10 output neurons, one per class
50 hidden neurons
source: andrej karpathy & fei-fei li
use cross-validation to choose hyper-parameters: 
e.g. learning rate, initialization, strength of id173,    
source: andrej karpathy & fei-fei li
27
learning rates and updates:
sgd + momentum > sgd
momentum 0.9 usually works well
decrease the learning rate over time
    (people use 1/t, exp(-t), or steps)
    simplest: learning_rate *= 0.97 every epoch (or so)
source: andrej karpathy & fei-fei li
28
monitor and visualize the loss curve
if this looks too linear: learning rate is low.
if it doesn   t decrease much: learning rate might be too high
the    width    of the curve is related 
to the batch size. this one looks too wide (noisy)
=> might want to increase batch size
source: andrej karpathy & fei-fei li
29
monitor and visualize the accuracy:
big gap = overfitting
=> increase id173 strength


no gap
=> increase model capacity
source: andrej karpathy & fei-fei li
30
track the ratio of weight updates / weight magnitudes:
ratio between the values and updates: ~ 0.0002 / 0.02 = 0.01 (about okay)
want this to be somewhere around 0.01 - 0.001 or so
max
min
mean
source: andrej karpathy & fei-fei li
31
visualizing first-layer weights:
noisy weights => id173 maybe not strong enough
source: andrej karpathy & fei-fei li
32
convolutional neural networks

[lenet-5, lecun 1980]
source: andrej karpathy & fei-fei li
33
convnets are everywhere
[krizhevsky 2012]
[goodfellow 2014]
classification
retrieval
source: andrej karpathy & fei-fei li
34
convnets are everywhere
[taigman et al. 2014]
[simonyan et al. 2014]
source: andrej karpathy & fei-fei li
35
convnets are everywhere
[ciresan et al. 2013]
[sermanet et al. 2011]
[ciresan et al.]
source: andrej karpathy & fei-fei li
36
source: andrej karpathy & fei-fei li
37
before:
now:















input layer
hidden layer
output layer
source: andrej karpathy & fei-fei li
38

depth
width
height
for example, a cifar-10 image is a 32x32x3 volume
32 width, 32 height, 3 depth (rgb channels)
all neural net activations 
arranged in 3 dimensions:
source: andrej karpathy & fei-fei li
39
convolutional neural networks
are just neural networks but:
local connectivity
nothing changes

image: 32x32x3 volume
before: full connectivity: 32x32x3 weights

now: one neuron will connect to, e.g. 5x5x3 chunk and only have 5x5x3 weights.

note that connectivity is:
local in space (5x5 inside 32x32)
but full in depth (all 3 depth channels)

a hidden neuron in next layer
32
32
3


source: andrej karpathy & fei-fei li
40
convolutional neural networks
are just neural networks but:
local connectivity
nothing changes

32
32
3




multiple neurons all looking at the same region of the input volume, stacked along depth.
before:    hidden layer of 200 neurons   
now:    output volume of depth 200   



depth dimension
source: andrej karpathy & fei-fei li


41
convolutional neural networks
are just neural networks but:
local connectivity
nothing changes


32
32
3




these form a single [1 x 1 x depth] 
   depth column    in the output volume

source: andrej karpathy & fei-fei li
42
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
source: andrej karpathy & fei-fei li
43
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
source: andrej karpathy & fei-fei li
44
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
source: andrej karpathy & fei-fei li
45
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
source: andrej karpathy & fei-fei li
46
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
source: andrej karpathy & fei-fei li
47
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
=> 5x5 output

source: andrej karpathy & fei-fei li
48
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
=> 5x5 output

what about stride 2?

source: andrej karpathy & fei-fei li
49
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
=> 5x5 output

what about stride 2?

source: andrej karpathy & fei-fei li
50
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
=> 5x5 output

what about stride 2?

source: andrej karpathy & fei-fei li
51
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
=> 5x5 output

what about stride 2?
=> 3x3 output
source: andrej karpathy & fei-fei li
52
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
=> 5x5 output

what about stride 2?
=> 3x3 output

what about stride 3?

source: andrej karpathy & fei-fei li
53
replicate this column of hidden neurons across space, with some stride.
7x7 input
assume 3x3 connectivity, stride 1
=> 5x5 output

what about stride 2?
=> 3x3 output

what about stride 3? cannot.


source: andrej karpathy & fei-fei li
54
n

n

f

f

output size:
(n - f) / stride + 1

e.g. n = 7, f = 3:
stride 1 => (7 - 3)/1 + 1 = 5
stride 2 => (7 - 3)/2 + 1 = 3
stride 3 => (7 - 3)/3 + 1 =     :\
source: andrej karpathy & fei-fei li

55
examples time:
input volume: 32x32x3
receptive fields: 5x5, stride 1
number of neurons: 5

output volume: ?








source: andrej karpathy & fei-fei li

56
examples time:
input volume: 32x32x3
receptive fields: 5x5, stride 1
number of neurons: 5

output volume: (32 - 5) / 1 + 1 = 28, so: 28x28x5
how many weights for each of the 28x28x5 neurons? 5x5x3 = 75









source: andrej karpathy & fei-fei li

57
examples time:
input volume: 32x32x3
receptive fields: 5x5, stride 3
number of neurons: 5

output volume: ?








source: andrej karpathy & fei-fei li

58
examples time:
input volume: 32x32x3
receptive fields: 5x5, stride 3
number of neurons: 5

output volume: (32 - 5) / 3 + 1 = 10, so: 10x10x5
how many weights for each of the 10x10x5 neurons?









source: andrej karpathy & fei-fei li

59
examples time:
input volume: 32x32x3
receptive fields: 5x5, stride 3
number of neurons: 5

output volume: (32 - 5) / 3 + 1 = 10, so: 10x10x5
how many weights for each of the 10x10x5 neurons? 5x5x3 = 75 (unchanged)









source: andrej karpathy & fei-fei li
60
in practice: common to zero pad the border
e.g. input 7x7
neuron with receptive field 3x3, stride 1 
pad with 1 pixel border => what is the output?


(in each channel)
source: andrej karpathy & fei-fei li
61
in practice: common to zero pad the border
e.g. input 7x7
neuron with receptive field 3x3, stride 1 
pad with 1 pixel border => what is the output?


7x7 => preserved size!

in general, common to see stride 1, size f, and zero-padding with (f-1)/2. 
(will preserve input size spatially)
(in each channel)
source: andrej karpathy & fei-fei li
62
input [9x9]

3x3 neurons, stride 1, pad 0 =>
[7x7]
3x3 neurons, stride 1, pad 0 =>
[5x5]

headaches with sizing the full architecture
works worse! border information will    wash away   , since those values are only used once in the forward function
input [9x9]

3x3 neurons, stride 1, pad 1 =>
[9x9]
3x3 neurons, stride 1, pad 1 =>
[9x9]

no headaches when sizing architectures
works well
   same convolution    (preserves size)
   valid convolution    (shrinks size)
source: andrej karpathy & fei-fei li
63
summary:
input volume of size [w1 x h1 x d1]
using k neurons with receptive fields f x f and applying them at strides of s gives
output volume: [w2, h2, d2]

w2 = (w1-f)/s+1 h2 = (h1-f)/s+1 d2 = k




source: andrej karpathy & fei-fei li
64









example trained weights
idea: lets not learn the same thing across all spatial locations
there   s one more problem    
assume input [32 x 32 x3]
30 neurons with receptive fields 5x5, applied at stride 1/pad1:
=> output volume: [32 x 32 x 30]    (32*32*30 =  30720 neurons)
each neuron has 5*5*3 (=75) weights
=> number of weights in such layer: 30720 * 75 ~= 3 million :\
source: andrej karpathy & fei-fei li
65
our first convnet layer had size [32 x 32 x3]
if we had 30 neurons with receptive fields 5x5, stride 1, pad 1
output volume: [32 x 32 x 30]    (32*32*30 =  30720 neurons)
each neuron has 5*5*3 (=75) weights

before:
#weights in such layer: (32*32*30) * 75 = 3 million :\

now: (paramater sharing)
#weights in the layer: 30 * 75 = 2250.
source: andrej karpathy & fei-fei li
66
note: sometimes it   s not a good idea to share the parameters
we   d like to be able to learn different things at different spatial positions
source: andrej karpathy & fei-fei li
67
these layers are called convolutional layers
connect neurons only to local receptive fields
use the same neuron weight parameters for neurons in each    depth slice    (i.e. across spatial positions)




one activation map (a depth slice), 
computed with one set of weights
source: andrej karpathy & fei-fei li
68


5x5 filters


can call the neurons    filters   
we call the layer convolutional because it is related to convolution of two signals (kind of):
elementwise multiplication and sum of a filter and the signal (image)
one filter = one depth slice (or activation map)
source: andrej karpathy & fei-fei li
69
fast-forward to today
[from recent yann lecun slides]
source: andrej karpathy & fei-fei li
70
conv
relu
conv
relu
source: andrej karpathy & fei-fei li
71
in convnet architectures, conv layers are often followed by pool layers

convenience layer: makes the representations smaller and more manageable without losing too much information. computes max operation (most common)

downsampling
32
32
16
16
source: andrej karpathy & fei-fei li
72
single depth slice
x
y
max pool with 2x2 filters and stride 2
max pooling

source: andrej karpathy & fei-fei li
73
in convnet architectures, conv layers are often followed by pool layers

convenience layer: makes the representations smaller and more manageable without losing too much information. computes max operation (most common)

input volume of size [w1 x h1 x d1]
pooling unit receptive fields f x f and applying them at strides of s gives
output volume: [w2, h2, d1]
w2 = (w1-f)/s+1, h2 = (h1-f)/s+1

note: pooling happens independently across each slice, preserving number of slices
e.g. a pooling    neuron    of size 2x2 will perform max operation over 4 numbers.
source: andrej karpathy & fei-fei li
74
conv
relu
conv
relu
pool
conv
relu
conv
relu
pool
conv
relu
conv
relu
pool
fc
(fully-connected)
source: andrej karpathy & fei-fei li
75
example:

input: [32x32x3]
conv with 10 3x3 filters, stride 1, pad 1:
gives: [32x32x10]
new parameters: (3*3*3)*10 + 10 = 280
relu
conv with 10 3x3 filters, stride 1, pad 1:
gives: [32x32x10]
new parameters: (3*3*10)*10 + 10 = 910
relu
pool with 2x2 filters, stride 2:
gives: [16x16x10]
parameters: 0




conv with 10 3x3 filters, stride 1:
gives: [16x16x10]
new parameters: (3*3*10)*10 + 10 = 910
relu
conv with 10 3x3 filters, stride 1:
gives: [16x16x10]
new parameters: (3*3*10)*10 + 10 = 910
relu
pool with 2x2 filters, stride 2:
gives: [8x8x10]
parameters: 0


(but in practice likely want to 
increase depth in larger layers)
source: andrej karpathy & fei-fei li
76
example:

input: [32x32x3]
->

eventually we have after the last pool:
[4x4x10]

fully-connected fc layer to 10 neurons
(which are our class scores)
number of parameters: 
10 * 4 * 4 * 10 + 10 = 1600

done!


source: andrej karpathy & fei-fei li
77
summary:

convnets are biologically-inspired architectures made up of neural net stuff
two key differences to vanilla neural nets: neurons arranged in 3d volumes have local connectivity, share parameters.
typical convnets look like: [conv-relu-pool]xn,[fc-relu]xm,softmax or
	[conv-relu-conv-relu-pool]xn,[fc-relu]xm,softmax
	(last fc layer should not have relu - these are the class scores)

source: andrej karpathy & fei-fei li
