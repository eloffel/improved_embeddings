noname manuscript no.
(will be inserted by the editor)

id183 techniques for information retrieval: a survey

hiteshwar kumar azad    akshay deepak

7
1
0
2

 

g
u
a
1

 

 
 
]

r

i
.
s
c
[
 
 

1
v
7
4
2
0
0

.

8
0
7
1
:
v
i
x
r
a

received: date / accepted: date

abstract with the ever increasing size of web, relevant information extraction on the internet
with a query formed by a few keywords has become a big challenge. to overcome this, query
expansion (qe) plays a crucial role in improving the internet searches, where the user   s initial
query is reformulated to a new query by adding new meaningful terms with similar signi   cance.
qe     as part of information retrieval (ir)     has long attracted researchers    attention. it has
also become very in   uential in the    eld of personalized social document, id53 over
linked data (qald), and, text retrieval conference (trec) and real sets. this paper surveys
qe techniques in ir from 1960 to 2017 with respect to core techniques, data sources used, weighting
and ranking methodologies, user participation and applications (of qe techniques)     bringing out
similarities and di   erences.
keywords id183    query reformulation    information retrieval    internet search

1 introduction

there is huge amount of data available on internet and it is growing exponentially. this uncon-
strained information-growth has not been accompanied by an analogous expansion of approaches
for extracting relevant information [185]. often, a web-search does not yield relevant results. there
are multiple reasons for this. first, the keywords submitted by the user can be related to multiple
topics; the search results are not focused on the topic of interest. second, the query can be too
short to express appropriately what the user is looking for. this can happen simply as a matter
of habit (average size of a web search is 2.4 words1 [249]). third, the user is often not sure about
what he is looking for until he sees the results. fourth, even if the user knows what he is searching
for, he does not know how to formulate the appropriate query (navigational queries are exception
to this [49]). qe plays an important part in fetching relevant results in the above cases.

most web queries fall under the three fundamental categories [49,137] :

    informational queries. queries that cover a broad topic (e.g., india or journals) for which there

may be thousands of relevant results.

    navigational queries. queries that looking for speci   c website or url (e.g., isro).
    transactional queries. queries that demonstrate the user intent to execute a speci   c activity

(e.g., downloading papers or buying books).

hiteshwar kumar azad
national institute of technology patna
tel.: +91-9852118731
e-mail: hiteshwar.cse15@nitp.ac.in

akshay deepak
national institute of technology patna
e-mail: akshayd@nitp.ac.in

1 https://www.statista.com/statistics/269740/number-of-search-terms-in-internet-research-in-the-us/

2

hiteshwar kumar azad, akshay deepak

currently, user queries are mostly processed using indexes and ontologies, which work on exact
matches and are hidden from the users. this leads to the problem of term mismatch: user and
search index don   t use the same terms. also known as the vocabulary problem [97]; it results from
the combination of synonymy and polysemy. synonymy refers to multiple words with common
meaning, e.g., such as    buy    and    purchase   . polysemy refers to words with multiple meanings,
e.g.,    mouse    (a computer device or an animal). synonymous and polysemous words are hindrance
in retrieving relevant information; they reduce recall and precision rates.

various techniques have been proposed to address vocabulary problem, including relevance
feedback, interactive query    ltration, corpus depended knowledge models, corpus independent
knowledge models, search result id91, and id51. almost all popular
techniques expand the initial query by adding new related terms. this can also involve selective re-
tention of terms from the original query. the expanded/reformulated query is then used to retrieve
more relevant results. the whole process is called id183 (qe).

id183 has a long history in literature. it was    rst implied in 1960 by moron et al.
[179] as a technique for literature indexing and searching in a mechanized library system. rocchio
[229] brought qe to spotlight; the author used    relevance feedback    and characterized it in vector
space model. the idea behind relevance feedback is to incorporate user   s feedback in the retrieval
process so as to improve the    nal result. in particular, the user gives feedback on the retrieved
documents in response to the initial query by indicating relevance of the results. rocchio   s work
was further extended and applied in techniques such as collection-based term co-occurrence [131,
219], cluster-based information retrieval [127, 188], comparative analysis of term distribution [212,
283,259] and automatic text processing [234,232,233].

this above was before the search engine era, when search-retrieval was done on a small amount
of data with short queries and satisfactory result were obtained. search engines were introduced in
1990s and a vast amount of data was suddenly published on the web, which has continued to grow
at an exponential rate since then. users continued to    re short queries for web searches. while the
recall rate suddenly increased, there was a loss in precision [235,109]. this called for modernization
of qe techniques to deal with internet-data.

as per a recent report 2 3, the most frequent queries consist of one, two or three words only
(see fig. 1)     the same as seventeen year ago as reported in reference [154]. while the number of
query terms have remained few, the number of web pages have increased exponentially. this has
increased the ambiguity     caused due to multiple meanings/senses of query term(s) or vocabulary
mismatch problem     in    nding relevant pages. hence, the importance of id183 (qe)
techniques has also increased in resolving the vocabulary mismatch problem.

recently, qe has come to spotlight because a lot of researchers are using the qe technique for
working on personalized social bookmarking services [102,36,47], id53 over linked
data (qald)4 [257] and in text retrieval conference (trec)5. they are also used heavily in
web, desktop and email searches [204]. many platforms provide qe facility to end users, which can
be turned on or o   , e.g., id1386, conceptnet7, lucene8, google enterprise 9 and mysql.

however, there are also drawbacks of qe techniques, e.g., there is a computational cost associ-
ated with the application of qe techniques. in case of internet searches, where quick response time
is a must, the computational cost associated with application of qe techniques prohibits their use
[123] in part of entirety. another drawback is that sometimes it can fail to establish relationship
between a word in the corpus with those which are used in di   erent communities, e.g.,    senior citi-
zen    and    elderly    [101]. another issue is that id183 may hurt the retrieval e   ectiveness
for some queries [66,174].

few surveys have been done in past on qe techniques. in 2007, bhogal et al. [34] reviewed
the id183 using an ontology, which are domain speci   c. such techniques have also been
described in book [177]. carpineto et al. [58] (published in year 2012) reviewed the major qe

2 https://www.statista.com/statistics/269740/number-of-search-terms-in-internet-research-in-the-us/
3 http://www.keyworddiscovery.com/keyword-stats.html
4 http://qald.sebastianwalter.org/
5 http://trec.nist.gov/
6 https://id138.princeton.edu/
7 http://conceptnet5.media.mit.edu/
8 http://lucene.apache.org/
9 https://enterprise.google.com/search/

id183 techniques for information retrieval: a survey

3

fig. 1: query size searched by di   erent countries

techniques, data sources and features in an information retrieval system. after this, we could not
   nd any major review covering recent progress in qe techniques. however, reference [58] covers
only automatic id183 techniques and does not include recent research on personalized
social documents, term weighting and ranking methods and categorization of several data sources.
in contrast, this survey     in addition to covering recent research in qe techniques     also covers
research on automatic, manual and interactive qe techniques. this paper discusses qe techniques
from four key aspects: (i) data sources, (ii) applications, (iii) working methodology and (iv) core
approaches (see fig. 2).

the rest of the article is organized as follows. section 2 de   nes qe and discuss the importance
and application of qe. it also brie   y discusses several applications of qe including recent liter-
atures. section 3 describes the working methodology of id183 and outlines the main
steps. section 4 classi   es the existing approaches on the basis of data sources. finally, section 5
discuss recent trend in literature and concludes our work.

2 id183

id183 reformulates user   s original query to enhance the information retrieval e   ective-
ness. let a user query consist of n terms, q = {t1, t2, ..., ti, ti+1, ..., tn}. the reformulated query
m} from the data source(s) d
can have two components: addition of new terms t (cid:48)={t(cid:48)
and removal of stop words t (cid:48)(cid:48)= {ti+1, ti+2, ..., tn }. the reformulated query can be represented
as:

2, ..., t(cid:48)

1, t(cid:48)

qexp = (q     t (cid:48)(cid:48))     t (cid:48)
= {t1, t2, ..., ti, t(cid:48)

1, t(cid:48)

2, ..., t(cid:48)

m}

(1)

in the above de   nition, the key aspect of qe is set t (cid:48): set of new meaningful terms added to
user   s original query to retrieve more relevant documents and reduce ambiguity. karovetz et al.
[146] reported that this set t (cid:48) computed on basis of term similarity, and without changing the
concept, increases recall rate in query results. hence, computation of set t (cid:48) and choice of data
sources d is the key aspect of research.

in regard to automation and end user involvement [88], qe techniques can be classi   ed as

follows:

37.6292.0466.9647.2745.8973.5875.8566.9663.4671.8462.9689.3360.1223.343.7617.4727.3621.7416.7111.7121.2532.6913.5930.37829.5517.562.438.6515.4616.815.578.058.752.889.713.71.336.280%10%20%30%40%50%60%70%80%90%100%usukaucadeesfrnlnoseplptitshare of keyword searchcountry codesone wordstwo wordsthree wordsfour wordsfive wordssix wordsseven wordseight wordsnine wordsten or more words4

hiteshwar kumar azad, akshay deepak

fig. 2: survey overview

    manual id183. here, user manually reformulates query.
    automatic id183. here, system automatically reformulates query     without any user
intervention. both the technique to compute set t (cid:48) and choice of data sources d is incorporated
into system   s intelligence.

    interactive id183. here, query reformulation happens as a result of joint cooperation
between the system and user. it is a human-in-the-loop approach, where the system returns
search results on an automatically reformulated query and the users choses meaningful results
among them. based on user   s preference, the system further reformulates query and retrieves
results. the process continues till the user is satis   ed with the search results.

2.1 importance of id183

one of the major importance of the qe is that it enhances the chance to retrieve the relevant
information on the internet, which is not retrieved otherwise using the original query. while this
improves the recall ratio, attempt to retrieve a lot of relevant documents adversely a   ects precision.
many times user   s original query is not su   cient to retrieve the information user intends or is look-
ing for. in this situation, qe plays a crucial role in improving the internet searches. for example,
if the user   s original query is novel, it is not understandable what the user wants: the user may be
searching for    ctitious narrative book or the user may be interested in something new or unusual.
so qe expands the original query    novel    to    novel book       book       new       novel approach   . this
new query retrieves the documents which have both types of meaning. this technique has been
used hugely for search operations in various commercial domains (such as education, hospitality in
medical science, economics, experimental research [58]) where the primary intension is to retrieve
entire relevant documents related to a particular concern. it has been experimentally observed that
during id183, attempt to increase recall rate adversely a   ects precision ratio and vice
versa [110,112,202]. the main reason behind the loss in precision is that the relevant documents
retrieved in response to the user   s initial query may rank lower in ranking after id183.
for improvement of retrieval precision, expanded query can also use boolean operators (and,or)
or paragraph operator [189] to transform expanded query to boolean query [207,141], which

key questionswhy isqe so influential in improving the internet searches?what are the appearance and participation of the user in qe?what are the applications of qe and how is it working? what are the data sources used for qe?what are the approaches of qe and how they correlate?applicationsworking methodologydata sourcescore approachesid53cross-languageirpersonalized social documentsinformation filteringmultimedia irotherslinguisticpseudo-relevance feedbackrelevance feedbackweb-basedsearch log-basedcorpus-basedid174terms weights & rankingquery reformulationterm selectionexternal text collections and resourceshand-built knowledge resourcesdocuments used in retrieval processid183 techniques for information retrieval: a survey

5

1 or t(cid:48)

1, t(cid:48)
1 and t(cid:48)

2,...,t(cid:48)
2 and...and t(cid:48)

m}, or, bquery= {t1 or t2 or...or ti or t(cid:48)

is eventually submitted for retrieval. for example, let the expanded query (from eq 1) be texp=
{t1,t2, . . .,ti, t(cid:48)
m}. the expanded boolean query can be bquery= {t1 and t2 and...and
ti and t(cid:48)
2 or...or
m}, or, a combination of or and and operators. a common issue with and operator is that
t(cid:48)
it improves precision but reduces recall rate, whereas, or operator reduce precision but improve
recall rate (e.g., [256]). reference [141] proposes a novel boolean query suggestion technique, where
boolean queries are produced by exploiting id90 learned from pseudo-labeled documents
and ranks produced queries using query quality predictors. the authors compared this technique
to the recent id183 techniques and experimentally demonstrated its superiority. xml
queries can also used for improving the precision in ir system for enhancing the internet searches
(e.g., [136,63,135]). improving precision in ir system through id183 using web pages
has been proposed in references [74,75,293]. here, id183 happens based on collection of
important words in related web pages. another set techniques for the same task expanded queries
using query concept [214,93,115,77]. here, expansion happens based on similar meaning of query
terms.

however, for considering the joint evaluation of precision and recall rate in id183,
several experimental study agree that retrieval quality of query results is enhanced by ten percent-
age or more with expansion of the user query (e.g., [236,278,59,157,89,221,69,53]). such reports
support the e   ectiveness of id183 techniques in information retrieval system. some re-
cent studies have shown that id183 can also improve the precision by disambiguating
the user query (e.g., [251,22,291,281]). table 1 show the e   orts of several researcher for improving
the precision & recall rate.

table 1: summary of techniques used for improving precision & recall rate

expansion techniques

publications

boolean query

xml queries

pane and myers 2000 [207], moldovan and mihalcea

2000 [189], kim et al. 2011 [141]

kamps et al. 2006 [136], chu-carroll et al. 2006 [63],

junedi et al. 2012 [135]

collection of the top terms within the

cui et al. 2002 [74], cui et al. 2003 [75], zhou et al.

web pages

query concepts

query disambiguation

2012 [293]

qiu and frei 1993 [214], fonseca et al. 2005 [93], hsu

et al. 2008 [115], bouchoucha et al. 2013 [48]

stokoe et al. 2003 [251], bai et al. 2005 [22], zhong

and ng 2012 [291], yao et al. 2015 [281]

2.2 application of id183

beyond the key area of information retrieval, there are other recent applications where qe tech-
nique has proved bene   cial. we discuss some of such applications next.

2.2.1 personalized social documents

in recent years social tagging systems have achieved popularity by being used in sharing, tagging,
commenting, rating, etc., of multi-media contents. every user wants to    nd relevant information
according to their interests and commitments. this has generated need of a id183
framework that is based on social bookmarking and tagging systems, which enhance document
representation.

reference [29] discusses exploiting the social relations for id183 using users, tags
and documents. reference [37] uses the social tagging and bookmarking in the id183
for personalized web searches. the experimental results show e   ective matching of user   s interests
and search results. reference [46] uses the combination of social proximity and semantic similarity
for personalized social id183, which is based on similar terms that are mostly used by
a given user and their social relatives. reference [293] proposed a id183 technique that
is based on distinctive user pro   les in which terms are extracted from both the annotations and

6

hiteshwar kumar azad, akshay deepak

resources the user has created and opted (also used in [44]). many other works (e.g., [45,107,
193]) discuss the id183 and social personalized ranking in the context of personalized
social documents. recently an article [47] proposed a technique persador (personalized social
id194), where for indexing and modeling user   s activities in a social tagging
system is used, and, for id183 social annotations are used. a more recent work in
personalized ir [12] uses id27 for id183, where experimental evaluation was
done on the collection of clef social book search 201610.the main motive of this paper is to
address the following questions: (1)    how to use the id27 for qe in the context of social
collection?   , and, (2)    how to use the id27 to personalize id183?    reference
[295] personalizes id183 using enriched user pro   les on the web; the user pro   les have
were created using external corpus (folksonomy data). they also proposed a model to enhance
the user pro   le. this model integrates the id27s with topic models in two groups of
pseudo-relevant documents such as user annotations and documents from the external corpus.

2.2.2 id53

id53 (qa) has become a very in   uential research area in the    eld of information
retrieval system. the main objective of qa is to grant a quick answer in response to a user   s query.
here the focus is to keep the answer concise rather than retrieving all relevant documents. the
system accepts as input natural language questions, such as    who is the    rst nation in the world
to enter mars orbit in    rst attempt?   , instead of a set of terms. recently search engines have also
started using the qa system to provide answer to such types of questions. however, for ranking
answers of such questions, the main challenges in qe is mismatch problem, which arises due to
mismatch between the expression in question and answer texts [164].

to overcome the mismatch problem and improving the document retrieval in qa system, many
articles have been published. in 2004, reference [4] presented a common approach for query ex-
pansion using faq data; the same approach was also followed in reference [248]. reference [218]
presents a technique to expand the user   s original query in qa system using statistical machine
translation (smt), which linked the verbal gap between user   s questions and system   s answers.
reference [35] ranked the retrieved documents in qa using social media search and web search.
other works [208,167,60,190] use social network for improving the retrieval performance in qa.
reference [271] expands short queries by mining the user intent from three di   erent sources includ-
ing community id53 (cqa) archive, query logs and web search results. currently
id183 on id53 over linked open data (qald) has gain much attention in
the area of natural language processing. an article [239] has proposed an approach for expansion
of the original query on linked data using linguistic and semantic features, where linguistic features
are extracted from id138 and semantic features are extracted from linked open data (lod)11
cloud. the evaluation was carried out on a training dataset extracted from the qald question
answering benchmark. /the experimental results show a considerable improvement in precision and
recall values over baseline approaches.

2.2.3 cross-language information retrieval (clir)

it is the part of ir which retrieves the information present in languages di   erent from the user   s
query language. for example a user   s query is in hindi but his retrieved relevant information can
be in english. over the past few years clir is achieving more attention due to the popularity of
clef12 and trec which are held annually for promoting the research in the area of ir.

traditionally there are three main approaches to clir : query translation with machine trans-
lation techniques [215], parallel or comparable corpora-based techniques [240] and machine read-
able bilingual dictionaries [23]. the main issue with the traditional clir is untranslatable query
terms, phrase translation, in   ected term, and uncertainty in language translation between source
and target languages [210]. to overcome this translation error, a popular approach is to use query

10 http://social-book-search.humanities.uva.nl
11 http://lod-cloud.net/
12 http://www.clef-initiative.eu/

id183 techniques for information retrieval: a survey

7

expansion [24,198]. it gives better output even in case of no translation error due to the use of sta-
tistical semantic similarity among the terms [2,143]. to counter the errors in automated machine
translation in case of cross-language queries, reference [98] uses the linguistic resources for query
expansion. id183 can be applied at various points in the translation process: before or
after translation or both. it has been shown that application at prior translation gives better result
in comparison to application at post translation, however, the application at both steps has given
best results [25,26,181,160]. for improving the id183 in clir reference [54] combines
the dictionary translation and the co-occurrence term relations into markov chain (mc) models    
de   ned as a directed graph where query translation is formulated as a random walk in mc mod-
els. recent work [292,294] used id183 techniques for personalize clir based on user   s
historical usage information. experimental results show that personalized approaches work better
than non-personalized approaches in clir. reference [33] presents a technique to translate the
query from hindi to english clir using id27.

2.2.4 information filtering

information    ltering (if) is a method to eliminate inessential information from the entire dataset
and deliver the relevant results to the end user. information    ltering is widely used in various
domains such as searching internet, e-mail, e-commerce, multimedia distributed system, blogs (for
survey see [108]). there are two basic approaches for if: content-based    ltering and collaborative
   ltering. reference [28] discusses the relationship between ir and if and establishes that if is a
special kind of ir, and has the same research challenges/outcomes. they have a common goal to
provide the relevant information to the user but from di   erent aspects. reference [108] gives a brief
overview of if and discuss the di   erence between ir and if with respect to research issues. for
improving the relevancy of results obtained after if, several qe approaches have been published.
relevance feedback techniques expanded query can re   ect the user   s interest and need well [8].
reference [91] combines user   s query with system   s master query [91] for improving results. other
techniques include using user   s pro   le [284], using geographical query footprint [96], using correlated
keywords [296], using the links and anchor text in wikipedia [14], using text classi   cation in twitter
messages [250] and using the patterns of online users behavior [287] [100]. a more recent work
[273] reformulated the query using user-item co-id91 method for improving the collaborative
filtering. another reference [285] reorganizes query using dbpedia13 corpus and clueweb0914
corpus for e   cient boolean if.

2.2.5 multimedia information retrieval

multimedia information retrieval (mir) deals with searching and extracting the semantic infor-
mation from multimedia documents (such as audio, video and image) (see [161] for review). most
of the mir systems typically rely on text-based search on multimedia documents such as title,
captions, anchor text, annotations and surrounding html or xml depiction. this approach can fail
when metadata is absent or when the metadata cannot exactly describe the actual multimedia
content. hence, id183 plays a crucial role in extracting the most relevant multimedia
data.

audio retrieval deals with searching audio    les in large collections of audio    les. the retrieved
   les should be similar to the audio query, which is natural language. the search analyzes the ac-
tual contents of the audio rather than the metadata such as keywords, tags, and/or descriptions
associated with the audio. for searching spoken audio, a common approach is to do text search on
transcription of the audio    le. however, transcription is obtained automatically by speech trans-
lation software and, hence, contain errors. in such a case, expanding the transcription by adding
related words greatly improves retrieval e   ectiveness [244]. however, for text document retrieval,
bene   ts of such document expansion are limited [265]. a study [134] shows that id183
can improve the average precision by 17 percent in audio retrieval. reference [27] follows qe tech-
nique based on semantic similarity in audio ir. reference [253] compares the language dependent
and language independent query through examples and concludes that language dependent setup

13 http://wiki.dbpedia.org/
14 http://lemurproject.org/clueweb09/

8

hiteshwar kumar azad, akshay deepak

provides better results in spoken term detection. recently, reference [140] presented a query expan-
sion method for social audio contents, where id183 approach uses three speech segments:
semantic, window and discourse-based segments.

in video retrieval, queries and documents have both visual as well as textual aspect. the ex-
panded text queries are matched with manually established text descriptions of the visual concepts.
reference [194] expands text query using lexical, statistical and content-based approaches for visual
id183. reference [254] expanded the query using the corpus of natural language descrip-
tion based on exact evaluation of system performance. a more recent work [255] uses the meta
synopsis for video indexing; the meta synopsis contains vital information for retrieving relevant
videos.

in id162, a common approach to retrieve relevant images is querying using textures,
shapes, color and visual aspect that match with image descriptions in the database (e.g., for
review on id162 [162] [81]). reference [148] presents two id183 approaches:
intra expansion (expanded query is obtained from existing query features) and inter expansion
(expanded query is obtained from search results). reference [117] uses the query logs data for
generic web image searches. reference [43] uses multitag for id162, whereas [166] retrieves
images using query adaptive hashing method. reference [275] presents a contextual id183
technique to overcome (a) the semantic gap of visual vocabulary quantization, and, (b) performance
and storage loss due to id183 in id162 .

2.2.6 other applications

some other recent applications of id183 are plagiarism detection [197], event search [87,
15,41], text classi   cation [262], patent retrieval [175,176, 261], in dynamic process in iot [120,121],
classi   cation of e-commerce [126], biomedical ir [1], enterprise search [170], code search [199] and
twitter search [147,297].

table 2 summarizes some of the prominent and recent applications of qe in literature based

on above discussion.

3 id183 working methodology

the process of generating id183 consists of mainly four steps: preprocessing of data
sources, term weights and ranking, term selection and query reformulation (see fig. 3). each step
has been discussed in the following sections.

fig. 3: id183 working model

3.1 preprocessing of data sources

preprocessing of a data source is depends upon the data sources and approaches used for query
expansion, instead of user   s query. the primary goal of this step (preprocessing of data source)
is to extract a set of terms form data sources that meaningfully augment user   s original query. it
consists of the following four sub-steps:

id174term weights and rankingterm selectionquery reformulationquerydata sourcesintermediate termsranked termsexpansion termsreformulatedqueryqueryexpansionid183 techniques for information retrieval: a survey

9

table 2: summary of research in applications of id183

research area

data sources

applications

publications

personalized

social annotations, user

logs, social tag and
bookmarking, social

social document

proximity and semantic

similarity, word

embedding, social context

enhance document   s

representation and grant

a personalized

representation of

documents to the user

question
answering

faqs, qa pairs, social
network, id138, lod

cloud, community
id53

(cqa) archive, query
logs and web search

responsind to user   s

query with quick concise

answers rather than
retunring all relevant

documents

cross-language

embeddings, dictionary

user logs, word

information

retrieval

translations and

co-occurrence terms,
linguistic resources

information

filtering

user pro   le, user log,

anchor text, wikipedia,
dbpedia corpus, twitter

messages

retrieving information
written in a language
di   erent from user   s

query language

searching results on

internet, e-mail,
e-commerce and

multimedia distributed

system

multimedia
information

retrieval

title, captions, anchor
text, annotations, meta

synopsis, query logs,
multitag, corpus of

natural language and

surrounding html or xml

depiction

searching and extracting

semantic information

from multimedia

documents (audio, video
and image) such as audio
retrieval, video retrieval

and id162

others

id27s,

text classi   cation, patent

clef- ip patent data,

top documents,

wikipedia, dbpedia,

trec collection,

retrieval, plagiarism
detection, dynamic

process in iot, twitter
search, biomedical ir,

zhou et al. 2017 [295],
bouadjenek et al. 2016

[47], amer et al. 2016 [12],
mulhem et al. 2016 [193],

hahm et al. 2014 [107],
bouadjenek et al. 2013
[44], zhou et al. 2012

[293], bouadjenek et al.

2011 [46], biancalana and

micarelli 2009 [37]

molino et al. 2016 [190],
cavalin et al. 2016 [60],

liu et al. 2015 [167],
shekarpour et al. 2013

[239], panovich et al. 2012
[208],bian et al. 2008 [35],

riezler et al. 2007 [218]
zhou et al. 2016 [294],

bhattacharya et al. 2016

[33], zhou et al. 2015

[292], gaillard et al. 2010
[98],cao et al. 2007 [54],
kraaij et al. 2003 [143]

zervakis et al. 2016 [285],
wu et al. 2016 [273], gao
et al. 2015 [100], zhang

and zeng 2012 [287],

arguello et al. 2008 [14],
fu et al. 2005 [96], yu et

al. 2004 [284]

khwileh and jones 2016
[140], thomas et al. 2016
[255], li et al. 2016 [162],
xie et al. 2014 [275], liu
et al. 2013 [166], tejedor
et al. 2012 [253], tellex et
al. 2010 [254], kuo et al.
2009 [148], wei and croft

2007 [265]

wang et al. 2016 [262],

wang and lin 2016 [261],
nawab et al. 2016 [197],
huber et al. 2016 [120],
zingla et al. 2016 [297],
abdulla et al. 2016 [1],

genomic data sets, top

code search, event search,

nie et al. 2016 [199],

tweets, etc.

enterprise search

atefeh et al. 2015 [15], liu

et al. 2014 [170]

1. text extraction from data sources (extraction of the whole texts from the speci   c data source

used for id183)

2. id121 (process of splitting the stream of texts into words)
3. stop word removal (removal of frequently used words e.g., articles, adjective, prepositions, etc.)
4. word id30 (process for reduction of derived or in   ected words to their base word)

a lot of data sources have been used for qe in literature. all such sources can be classi   ed into
three classes: (i) documents used in retrieval process, (ii) hand-built knowledge resources, and (iii)
external text collections and resources.

3.1.1 documents used in retrieval process

in the beginning of seventies, addition of clustered term into the initial query started playing a
crucial role in id183 (e.g.,[127, 188, 268]). researchers assume that the set of similar
words that appear frequently in documents belongs to the same subject and similar documents

10

hiteshwar kumar azad, akshay deepak

form a cluster [209]. two types of id91 have been discussed in documents retrieval system:
id91 of terms and id91 of documents [268]. reference [214] is a well known corpus-
based expansion technique [214] that uses similarity thesaurus for expanding the original query.
a similarity thesaurus is a collection of documents based on speci   c domain knowledge, where
each term is expressed as a weighted document vector. some other works use collection-based
data sources for id183 (e.g., [131,16,73, 277,101,57,22]). recently, article [290] used
four corpora as data sources (including one industry and three academic corpus) and presented
a two-stage feature selection framework (tfs) for id183 known as supervised query
expansion (sqe). the    rst stage is adaptive expansion decision (aed), which predicts whether
a query is suitable for sqe or not. for unsuitable queries, sqe is skipped with no term features
being extracted at all, so that computation time is reduced. for suitable queries, the second stage
conducts cost constrained feature selection (ccfs), which chooses a subset of e   ective yet
inexpensive features for supervised learning. a drawback of corpus speci   c id183 is that
they fail to establish relationship between a word in the corpus and those which are used in di   erent
communities, e.g.,    senior citizen    and    elderly    [101].

while researchers agree that the addition of selective terms improve the retrieval e   ectiveness,
there are di   ering point of views on the number of selective terms to be added; ranging form one
third of the terms [222],    ve to ten terms [11, 61], 20-30 terms [109,290], 30-40 terms [201], few
hundreds terms [31,269] to 350-530 terms for each query [52]. the source of these terms came can
be the top retrieved documents or well known relevant documents. further, it improves retrieval
e   ectiveness by 7% to 25% [52].

3.1.2 hand-built knowledge resources

the main goal of the hand-built knowledge resources is to extract knowledge from textual hand-
built data sources such as dictionaries, thesaurus, ontologies and lod cloud. thesaurus-based
id183 can be either automatic or hand-built. one of the famous hand-built thesaurus is
id138 [186]. reference [260] utilized the id138 to expand the original query with semantically
similar terms called synsets. it was observed that retrieval e   ectiveness was improved signi   cantly
for unstructured query, while only marginal improvement was observed for structured queries. some
other articles also use the id138 to expanded the original query (e.g., [245] uses synonyms of
the initial query and assigns half weight,[169] uses word sense, [103] uses semantic similarity, [288]
uses concepts and [206] uses semantic relations form id138). reference [206] proposes a new and
e   ective way of using id138 for id183, where candidate expansion terms (cet) are
selected from a set of pseudo-relevant documents and the usefulness of these terms determined by
considering multiple sources of information. the semantic relation between expanded terms and the
query terms is determined using id138. reference [159] presents an automatic id183
(aqe) approach that uses word relations to increase the chances of    nding relevant code. for
data source, it uses a thesaurus containing only software-related word relations and id138 for
expanding the user   s query. similarly, reference [114] uses conceptnet [168] (have higher concept
diversity) and id138 (have higher discrimination ability) as the data sources for expanding user
query. conceptnet is a relational semantic network that helps to understand the common sense
knowledge of text written by users. recently a number of researchers used conceptnet as the
data source for id183 (e.g., [115,142, 48, 13]). reference [48] uses conceptnet for query
expansion and proposes a qe technique known as maximal marginal relevance-based expansion
(mmre). this technique selects expansion terms that are closely related to the initial query, but
di   erent from the previously selected expansion terms. then, the top n expansion terms having
the highest mmre scores are selected. reference [17] uses lod cloud for keyword mapping and
exploits the graph structure within linked data to determine relations between resources that are
useful to discover, or directly express semantic similarity. utilization of data sources as knowledge
bases in information retrieval is still an open problem because most of the prior research focuses on
the construction of knowledge bases rather than their utilization techniques. presently, knowledge
bases (describes entities, their attributes, and their relationships to other entities) is an in   uential
data sources for id183. recent reference [276] uses the knowledge bases such as freebase
(large public knowledge base that contains semi-structured information about real world entities
and their facts) for improving the id183. for selection of the expansion term, reference
[276] developed two methods: (1) utilization of tf.idf based pseudo relevance feedback (prf) on

id183 techniques for information retrieval: a survey

11

linked objects    descriptions, and, (2) utilization of freebase   s entity categories which grants an
ontology tree that illustrate entities at several levels of abstraction.

however, reference [113] used thesaurus relationship for id183 in the umls metathe-
saurus and reported that nearly all types of id183 reduce the recall and precision based
on retrieval e   ectiveness. not surprisingly, in their result, only 38.6% of the queries with syn-
onym expansion and up to 29.7% of the queries with hierarchical expansion showed signi   cant
improvement in retrieval performance. primarily, there are three limitations in hand-built knowl-
edge resources: they are commonly domain speci   c, usually do not contain proper noun and they
have to be kept up to date. experiments with id183 using hand-built knowledge re-
sources did not show consistent improvements in retrieval e   ectiveness. it does not improve well
formulated user queries, but signi   cantly improve the retrieval e   ectiveness of badly constructed
queries.

3.1.3 external text collections and resources

text collection used in retrieval process (such as the www, wikipedia) is the most common and
e   ective data sources for id183. in such cases, id183 approaches shows overall
better performance in comparison to all three data sources. some data sources under this category
need preprocessing procedures for text collection. for example, reference [144,79] uses the anchor
texts as the data sources; it parses hyperlinks to extract data from anchor tags. further, additional
steps need to be carried out such as stop word removal and word id30. their experimental
results also suggests that anchor texts can also be used to improve the traditional qe based on
query logs. query logs is another data source for id183, where user   s queries are expanded
using correlation between query terms and document terms determined using user logs (e.g., [266,
75]). some researchers refer to query logs as user logs since it is derived from historical records
of user queries registered in the query logs of search engine (e.g., [74,38,18,282]). reference [282]
expresses the search engine query log as a bipartite graph, where query nodes are connected to the
url nodes by click edges; it reported improvement of retrieval e   ectiveness by more than 10%.
reference [264] uses web corpus and training data as data sources, and then, extracts query using
search logs. most of the search engines and surveyed papers using qe are based on the query logs.
however, customized search systems in the internet search, enterprise search, personalized search
(such as desktop or email search) or for infrequent queries, query logs are either not available
or the past user   s queries are not su   cient to describe the information needed. to overcome this
limitation reference [32] proposed a probabilistic model that provides the expansion terms from
the corpus without using query logs.

a good number of published works have used hybrid data sources (combining two or more
data sources) for id183. for example, reference [67] uses id138 as data source, an
external corpus, krovetz stemmer and top retrieve documents. recently, reference [205] used data
source based on term distributions (based on id181 (kld) and bose-einstein
statistics (bo1)) and term association (local context analysis (lca) and relevance-based lan-
guage model (rm3)) methods for id183. the experimental result demonstrated that
the combined method gives better result in comparison to the each individual method. other re-
search works based on hybrid resources are [111,157,271,77]. recently, wikipedia and dbpedia
are using widely as data sources for id183 (e.g., [163,14,279,3,9,13,106]). reference
[163] performed an investigation using wikipedia and retrieved all articles corresponding to the
original query as a source of the expansion terms for pseudo relevance feedback (prf). it ob-
served that for a particular query where the usual pseudo relevance feedback fails to improve the
query, wikipedia-based pseudo relevance feedback improves it signi   cantly. reference [279] uti-
lized wikipedia to categorize the original query into three types: (1) ambiguous queries (queries
with terms having more than one potential meaning) (2) entity queries (queries having a speci   c
meaning and cover a narrow topic) and, (3) broader queries (queries having neither ambiguous
nor speci   c entity). they consolidate the expansion terms into the original query and evaluate
these techniques using id38 information retrieval. reference [9] uses wikipedia for
semantic enrichment of short queries based on in-link and out-link articles. reference [77] propose
entity query feature expansion (eqfe) technique. it uses data sources such as wikipedia and
freebase to expand the initial query with features from entities and their links to knowledge bases
(wikipedia and freebase), including structured attributes and text. the main motive for linking

12

hiteshwar kumar azad, akshay deepak

entities to knowledge bases is to improve the understanding and representation of text documents
and queries. in reference [13], document collection and external resources (encyclopedias such as
dbpedia and knowledge bases such as conceptnet) are the data sources for id183.
for selecting the expansion terms, term graphs have been constructed using information theoretic
measures based on co-occurrence between each pair of terms in the vocabulary of the document
collection. today, id27 techniques are widely used for id183. recently, ref-
erence [230] proposed id27 framework (based on distributed neural language model
id97). based on the framework it extracted similar terms to a query using k-nearest neighbor
approach. the experimental study was done on standard trec ad-hoc data; it showed consid-
erable improvement over the classic term overlapping-based retrieval approach. it should also be
noticed that id97 based id183 methods perform more or less the same with and
without any feedback information. some other articles using id27 techniques are [84,
149]. reference [84] presented a qe technique based on locally-trained id27 (such as
id97 and glove) for ad hoc information retrieval. it also used local embeddings that capture
the nuances of topic-speci   c language and are better than global embeddings. it also suggested that
embeddings be learned on topically-constrained corpora, instead of large topically-unconstrained
corpora. in a query-speci   c manner, their experimental results suggested towards adopting the
local embeddings instead of global embedding for formers potentially superior representation. sim-
ilarly reference [149] proposed a qe technique based on id27s that uses id97s
continuous bag-of-words (cbow) approach [184]; cbow represents terms in a vector space
based on their co-occurrence in text windows. it also presents a technique for integrating the terms
selected using id27s with an e   ective pseudo relevance feedback method.

recently, fuzzy logic based expansion techniques have also become popular. references [243,
242] used a fuzzy logic-based id183 technique, and, top-retrieved documents (using
pseudo-relevance feedback) as data sources. here, each expansion term (obtained from top retrieved
documents) is given a relevance score using fuzzy rules. the relevance scores of the expanded terms
are summed up to infer the high fuzzy weights for selecting expansion terms.

table 3 summarizes the classi   cation of data sources used in qe in literature based on above

discussion.

3.2 weighting and ranking of id183 terms

in this step of qe, weights and ranks have been assigned to id183 terms [see fig. 3].
the input of this step is the user   s query as well as the texts extracted from the data sources in
the    rst step. assigned weights denote relevancy of terms in the expanded query and are further
used in ranking retrieved documents based on relevancy. there are many techniques for weighting
and ranking of id183 terms. reference [58] classi   es the techniques into four categories
on the basis of relationship between the query terms and the expansion features:

    one-to-one association. such as id138 to    nd synonyms and similar terms for the query

terms.

    one-to-many association. correlates one query term to many expanded query terms.
    feature distribution of top ranked documents. deals with the top retrieved documents from

the initial query and considers the top weighted terms from these documents.

    query id38. constructs a statistical model for the query and choses the expansion

terms having highest id203.

the    rst two approaches can also be considered as local techniques. these are based on association
hypothesis projected by reference [220]:    if an index term is good at discriminating relevant from
non-relevant documents, then any closely associated index term is also likely to be good at this.   
this hypothesis was mainly motivated by reference [178]. reference [220] outlines this concept
as    to enlarge the initial request by using additional index terms which have a similar or related
meaning to those of the given request.    the above approaches have been discussed next.

id183 techniques for information retrieval: a survey

13

table 3: summary of research in classi   cation of data sources used in id183

type of data

sources

data sources

term extraction

methodology

publications

documents used

in retrieval

process

clustered terms

id91 of terms and
documents from sets of

jardine and rijsbergen 1971
[127], minker et al. 1972 [188],

similar objects

willett 1988 [268]

jones 1971 [131], attar and
fraenkel 1977 [16], peat and

corpus or

terms collection from

willett 1991 [209], crouch and

collection based

data sources

speci   c domain

knowledge

hand built
knowledge
resources

id138 &
thesaurus

word sense and synset

conceptnet &

common sense

knowledge bases

knowledge and freebase

anchor texts

text or text extraction

adjacent terms in anchor

query logs or

user logs

external text
collections and

resources

from anchor tags

historical records of user
queries registered in the

query logs of search

engine

wikipedia or

articles, titles & hyper

dbpedia

links

external corpus

nearby terms in word
embedding framework

top-ranked
documents &
hybrid sources

all terms in top

retrieved documents

yang 1992 [73], qiu and frei 1993

[214], xu and croft 1996[277],

gauch et al. 1999 [101], carpineto
et al. 2001 [57], bai et al. 2005 [22]
miller et al. 1990 [186], voorhees
1994 [260], smeaton et al. 1995
[245], liu et al. 2004 [169], gong
et al. 2006 [103], zhang et al. 2009

[288], pal et al. 2014 [206]

liu and singh 2004 [168], hsu et

al. 2006 [114], hsu et al. 2008

[115], kotov and zhai 2012 [142],

bouadjenek et al. 2013 [45],
anand and kotov 2015 [13]

kraft and zien 2004 [144], dang

and croft 2010 [79]

wen et al. 2002 [266], cui et al.
2003 [75], billerbeck et al. 2003
[38], baeza-yates et al. 2004 [18],
yin et al. 2009 [282], hua et al.

2013 [117]

li et al. 2007 [163], arguello et al.

2008 [14], xu et al. 2009 [279],

aggarwal and buitelaar 2012 [3],
almasri et al. 2013 [9], al-shboul
and myaeng 2014 [7], anand and
kotov 2015 [13], guisado-gamez

et al. 2016 [106]

roy et al. 2016 [230], diaz et al.
2016 [84], kuzi et al. 2016 [149]
collins-thompson and callan
2005 [67], he and ounis 2007

[111], lee et al. 2008 [157], pal et
al. 2013[205], wu et al. 2014 [271],
dalton et al. 2014 [77], singh and

sharan 2016 [243]

3.2.1 one-to-one association

this is the basic approach for weighting and ranking the expansion terms based on one-to-one
association between the query terms and expansion terms. here, each expansion term is connected
to a individual query term and weights are assign for each query terms using several techniques.

one of the most in   uential approaches to establish one-to-one association is to use linguistic
associations namely id30 algorithm to minimize the in   ected word (plural forms, tenses of
verbs or derived forms ) from its word stem. for example, based on porter   s id30 algorithm
[211], the words    stems   ,    stemmed   ,    id30    and    stemmer    would be reduced to the root
word    stem.    another typical linguistic approach is the use of thesaurus. one of the most famous
thesaurus is id138 [260]; each query term is mapped to its synonyms and similar set of words
    obtained from id138     in the expanded query. for example, if we consider word    java    as
noun in id138, there are three synsets each having a speci   c sense: for location (as an island),
food (as co   ee), and computer science (as a programming language). the same approach has
been done using conceptnet [114] to    nd related concepts of user   s queries for id183.
for example, word       le    having related concept as    folder of document   ,    record   ,    computer   ,
   drawer   ,    smooth rough edge   ,    hand tool   , etc. then, each expanded term is assigned a similarity

14

hiteshwar kumar azad, akshay deepak

score based on their similarity with the query term. only terms with high scores are retained in
expanded query. the natural concept regarding term similarity is that two terms are semantically
similar, if both terms are in the same document. similarly two documents are similar if both are
having the same terms. there are several approaches to determine term similarity.

path length-based measure determines the term similarity between the synsets(sense)     ob-
tained from id138     based on path length of linked synsets. generally path length-based mea-
sures included two similarity measurement techniques: shortest path similarity (derived from [216])
and wu & palmer [274]. let the given terms be s1 and s2, and let lens denote the length of the
shortest path between s1 and s2 in id138. the shortest path similarity score is de   ne as:

simp ath(s1, s2) =

1

lens

(2)

path length between members of the same synset is considered to be 1, hence, the maximum
similarity score will be 1.

the wu & palmer (wp) similarity score is de   ned as

simw p (s1, s2) =

2 . d(lcs)

d(s1) + d(s2)

(3)

where, d(lcs) is the depth of least common sub-sumer(lcs)(the closest common ancestor node
of two synsets) and d(s1) & d(s2) are the depth of senses s1 and s2 from the root node r in
id138 (see figure 4). similarity score of wp varies from 0 to 1 (0 < simw p     1).

fig. 4: example of taxonomy hierarchy in id138

other approaches like jaccard coe   cient and dice coe   cient are also used widely for similarity

measurement. the jaccard coe   cient [124] is described as:

simjaccard(s1, s2) =

dfs1   s2
dfs1   s2

(4)

where, dfs1   s2 denotes the frequency of documents containing both s1 and s2, and dfs1   s2 denotes
the frequency of documents containing at least s1 or s2.

the dice coe   cient [85] is described as

simdice(s1, s2) =

2 . dfs1   s2
dfs1 + df s2

(5)

where dfs1 and df s2 denote the frequency of documents containing s1 and s2 respectively.

d(s1)d(s2)d(lcs)s1s2sr(cid:88)

dj

(cid:114)(cid:80)

dj

cs1,s2

w2

s1,s1

.(cid:80)

dj

id183 techniques for information retrieval: a survey

15

a more generic approach term-document matrix m is a two dimensional matrix, whose rows
represent the terms and columns represent the documents. cell mt,d contains value wt,d, where
wt,d denotes weight of term t in document d. correlation matrix c = m m t , where each cell cs1,s2
denotes correlation (similarity) score between terms s1 and s2 is described as

cs1,s2 =

ws1,j . ws2,j

(6)

the cosine similarity measure, simcosine is de   ned as id172 of the above correlation factors:

simcosine =

w2

s2,s2

(7)

id172 is done to account for relative frequency of terms.

as we see, using equation (6), we can create a set of conceptually di   erent term-to-term corre-
lation method by varying how to select the set of documents and the weighting function. although,
calculating co-occurrence of all terms present in the document is easy, it does not consider relative
position of terms in a document. for example, two terms that co-occur in the same sentence are
more correlated than when they occur in distant parts of the document.

a more exhaustive measurement technique for term co-occurrence that includes term depen-

dency is mutual information [64]:

is1,s2 = log2

(cid:20) p (s1, s2)

p (s1) . p (s2)

(cid:21)

+ 1

(8)

where p (s1, s2) is the combine id203 that s1 and s2 co-occur within a particular circumference,
and, p (s1) and p (s2) are the respective id203 of occurrence of terms s1 and s2. such a
measurement techniques account for relative positions of terms in a document. further, in the
sense of word order (such as    program executing    or    executing program   ), asymmetric order
is preferable, where p (s1, s2) refers to the id203 that s2 exactly follow the s2. the mutual
information will be: zero if there is no co-occurrence, equal to one if terms s1 and s2 are distinct,
and, equal to log2

if s2 is absolutely correlated to s2.

(cid:16) 1

(cid:17)

p (s1) + 1

the drawback of the above formulation is that it can favor infrequent co-occurring terms as

compared to frequent distant-occurring terms.

as another option, we can adopt the general description of id155 for calculat-

ing the stability of association between terms s1 to s2:

p (s1|s2) =

p (s1, s2)

p (s2)

(9)

this well known approach [22] is identical to the association rule used in data mining problem [6,
258]. association rules have been used widely for identifying the expansion feature correlation with
the user query terms [246,152].

another corpus-based term similarity measure based on information content-based measure-
ment is resnik similarity [216]. resnik measures the frequent information as information content
(ic) of the least common sub-sumer (lcs) (the closest common ancestor node of two synsets).
the value of resnik similarity would be greater than and equal to zero. the resnik similarity can
be formulated as

simresnik(s1, s2) =    log p(lcs(s1, s2))

the -ve sign makes the similarity score +ve because probabilities are always between [0,1].

recently, wikipedia has become popular for short id183. it is feasible in wikipedia
to have distinct articles with a common title. every article describes the individual sense of the
term, corresponding to the polysemous occurrences of the term in natural language. for example,
term    apple    has two articles in wikipedia, one indicating it as as a fruit and the other as the
company. reference [9] uses the wikipedia for semantic enhancement of short query and measures
the semantic similarity between two articles s1 and s2 as

sims1,s2 =

|i(s1)     i(s2)| + |o(s1)     o(s2)|
|i(s1)     i(s1)| + |o(s2)     o(s2)|

(10)

(11)

16

hiteshwar kumar azad, akshay deepak

where i(s1) & i(s2) is the set of articles that point to s1 & s2 respectively (as in-link) and o(s1)
& o(s2) is the set of articles that s1 & s2 point to (as out-link).

table 4 summarizes the mathematical form of term similarity score in one-to-one association

based on above discussion.

table 4: summery of one-to-one association for term ranking based on the term similarity score

reference
jaccard 1912

[124]

approaches

jaccard coe   cient

dice 1945 [85]

dice coe   cient

attar and

fraenkel 1977

[16]

church and

hanks 1990 [64]
wu and palmer

1994 [274]
resnik 1995

[216]

almasri et al.

2013 [9]

cosine similarity

mutual information

wu & palmer

similarity

resnik similarity

semantic similarity

mathematical form

dfs1   s2
dfs1   s2
2 . dfs1   s2
dfs1 + df s2
dj
w2

(cid:80)
(cid:115)(cid:80)
. (cid:80)
(cid:104) p (s1,s2)

s1,s1

dj

dj

ws1,j . ws2,j

w2

s2,s2

log2

p (s1) . p (s2) + 1
2 . d(lcs)

(cid:105)

d(s1) + d(s2)

   log p(lcs(s1, s2))

|i(s1)     i(s2)| + |o(s1)     o(s2)|
|i(s1)     i(s1)| + |o(s2)     o(s2)|

3.2.2 one-to-many associations

in one-to-one association, each query term is expanded into correlated terms independently, whereas,
in one-to-many association, multiple query terms can be expanded together     as a unit     into cor-
related terms. for example, consider queries    engineering technology    and    music technology   .
now, word    technology    is frequently associated with word    information   . hence, an automatic
expansion of    technology    in query    data technology    to    information technology    may work well
because    information    is strongly correlated to the overall meaning of query    data technology   .
however,    information    does not relate to the overall meaning of    music technology   . the main
issue with one-to-one association is that it may not properly demonstrate the connectivity between
the expansion term to the query as a whole. this issue has been discussed in reference [21], which
deals with query-speci   c contexts instead of user-centric ones along with the context around and
within the query. for resolving such language ambiguity problem, one-to-many association plays a
crucial role.

references [114,115] use one-to-many association. here, it is compulsory to correlate a new
term extracted form the combination of conceptnet and id138 to a minimum of two original
query terms before including the new term into expanded query. let q be the original query and let
s2 be an expansion term. in one-to-many association, we may calculate the correlation coe   cient
of s2 with q as:

(cid:88)
(cid:88)

s1   q

cs1,s2

(cid:88)

s1   q

dj

cq,s2 =

=

1
|q|
1
|q|

ws1,j . ws2,j

(12)

other works based on one-to-many association are [214,277,75,22,252,217,32,99,149]. as a
special mention, references [214,277] have gained large acceptance in literature because of their
one-to-many association expansion feature and weighting scheme as described in eq. 12.

reference [214] uses eq. 12 for    nding pairwise correlations between terms in the entire collec-
tion of documents. weight of a term s in document dj, denoted ws,j (as in eq. 12), is computed as
the multiplication of term frequency (tf) of term s in document dj and the inverse term frequency
(itf) of the document dj. the itf of document dj is de   ned as itf (dj) = log( t|dj| ), where |dj| is

id183 techniques for information retrieval: a survey

17

the number of distinct terms in document dj and t indicates the number of terms in the entire
collection. this approach is similar to the inverse document frequency (idf) used for document
ranking.

reference [277], uses concepts (group of contiguous nouns) instead of individual terms while
expanding query. concepts are chosen based on term co-occurrence with query terms. concepts
are picked from top retrieved documents, but they are determined on the basis of top passage
(   xed size text window) rather than the whole document. here, equation eq. 12 is used for    nding
the term-concept correlations (instead of term-term correlations), where ws1,j is the number of
co-occurrence of query term s1 in jth passage and ws2,j is the frequency of concept s2 in jth
passage. inverse term frequency of passages and the concepts contained in the passages     across
the entire corpus     have been considered for calculating the perfect term-concept correlation score.
a concept has a correlation factor with every query term. to obtain the correlation factor of the
entire query, correlation factors of individual query terms are multiplied. this approach is known
as local context analysis [277].

one-to-one association technique tends to be e   ective only for selecting expansion terms that
are loosely correlated to any of the query terms. however, if correlation with the entire query or
with multiple query words need to be considered, one-to-many association should be used. for
example, consider the strong correlation of    information    with    technology   . here,    information   
may be an expansion term for query    food technology    or       nancial technology   . this is not a
desired expansion because    information technology    and    food technology    are unrelated. one
way to overcome this problems is by adding context words to validate term-term associations.
for example, in case of adding    information    as an expansion term for query    food technology   ,
association of    food    and    information    should be considered strong only if these terms co-occur
together su   ciently high number of times. here,    food    is a context word added to evaluate term-
term association of    information    and    technology    in the context of query    food technology   .
such context words can be extracted from a corpus using term co-occurrence [20,21,264,130] or
derived from logical signi   cance of knowledge base [153, 77, 158,42].

reference [260]     using id138 data source for id183     found that expansion using
term co-occurrence techniques are commonly not e   cient because it doesn   t assure a reliable word
sense disambiguation. although, this issue can be resolved by evaluating the correlation between
id138 senses associated with a query term and the senses associated with its neighboring query
term. for example, consider query phrase    incandescent light   . in id138, the de   nition of synset
of incandescent contains word light. thus, instead of the phrase    incandescent light   , we can con-
sider the synset of incandescent. reference [169] uses this approach for id51
(wsd).
consider example query    tropical storm.    in id138, the sense of the word    storm    de-
termined through hyponym of the synset {violent stome, storm, tempest} is    hurricane   , whose
description having the word    tropical   . as a result, the sense of storm is determined correctly.
reference [169] determines the correlation value of the terms in a phrase using:

p (phrase)     (cid:81)

(cid:81)

si   phrase
p (si)

cs1,s2,...,sn =

p (si)

(13)

taining the phrase, p(si) is the id203 of the individual term si in the phrase and (cid:81)

where s1, s2, ..., sn are the terms in a phrase, p(phrase) indicates the id203 of documents con-
p (si)

si   phrase

si   phrase

indicates the id203 of document having all terms in a phrase.

another approach for determining one-to-many association is based on the combination of var-
ious relationships between term pairs through a markov chain framework [67]. here, words having
the highest id203 of relevance in the stationary distribution of the term network are selected
for id183. for every individual query term, a term network is built that consists of a
pair of correlated terms corresponding to di   erent types of relations (namely synonym, hyponym,
co-occurrence). reference [172] proposed a positional language model (plm) that incorporates
term proximity evidence in a model-based approach. term proximity was computed directly based
on proximity-based term propagation functions. reference [247] proposed proximity probabilistic
model (ppm) that uses a position-dependent term count to compute the number of term oc-
currences and term counts propagated from neighboring terms. recently, article [130] considered

18

hiteshwar kumar azad, akshay deepak

term-based information and semantic information as two features of query terms and presented an
e   cient ad-hoc ir system using id96. here,    rst topic model is used for extracting the
latent semantic information of the query term and then, term-based information is used as in a
typical ir system. this approach is sturdier in relation to data paucity and it does well on large
complicated (belonging to multiple topics) .

to overcome the limitations of considering term-to-term relationships     whether one-to-one or
one-to-many     one can break the original query as one or more phrases, and then seek for phrases
that are similar to it. phrases usually o   er richer context and have less ambiguity in comparison
to their individual constituent words. at times, id183 even at phrase level may not o   er
desired clarity, because the phrase may be compositional or non-compositional. with compositional
phrases each and every term associated with the phrase can be expanded using similar alternative
terms; the    nal expanded phrase keeps its signi   cance. reference [75] analyzes the phrases using
id165s from user   s query logs. they    lter the phrases that are not present in the documents being
searched. reference [171] selects most appropriate phrases for id183 based on conceptual
distance between two phrases (obtained using id138). first, phrases similar to the query phrase
are selected as candidate phrases. then, candidate phrases having low conceptual distance with
respect to query phrase are considered in the set of most appropriate phrases. recently reference
[7] presented a query phrase expansion approach using semantic annotations in wikipedia pages.
it tries to enrich the user query with the phrases that disambiguate the original query word.
however, generally it has been shown that short phrases have a more authentic representation of the
information needed, e.g.,    arti   cial intelligence   . further, phrases have a greater inverse document
frequency in document collections in the corpus because when compared to individual query terms.
this is because individual query terms occur more frequently in the document collection than the
phrase as a whole. reference [90] acknowledges that retrieval results are improved when pseudo
relevance feedback is also included in id183 based on phrases.

dealing with idiomatic phrases can be troublesome. they are non-compositional in nature and
replacing a word with a similar meaning word     as often done during id183     can
completely change the meaning of the phrase. for example,    break a leg    is a theatrical slang
meaning    good luck!   . when we replace    leg    with synonym    foot   , phrase    break a foot    gives
an entirely di   erent meaning from the original phrase.

table 5 summarizes the mathematical form of term-term correlation value in one-to-many

association based on the above discussion.

table 5: summary of one-to-many association for term ranking based on the term-term correlation
values

publications

approaches

mathematical form

qiu and frei 1993 [214], xu and

croft 1996 [277], cui et al. 2003 [75],
bai et al. 2005 [22], sun et al. 2006

[252], riezler et al. 2008 [217], bhatia
et al. 2011 [32], gan and hong 2015

[99], kuzi et al. 2016 [149]

correlation coe   cient

cq,s2 = 1|q|
= 1|q|

ws1,j . ws2,j

(cid:80)
(cid:80)

(cid:80)
s1   q cs1,s2
s1   q
(cid:81)

dj

(cid:81)

si   phrase
p (si)

si   phrase

p (phrase)   

p (si)

liu et al. 2004 [169]

correlation value

3.2.3 feature distribution of top ranked documents

approaches discussed in this section are entirely distinct from the approaches described in earlier
sections, because the id183 techniques used in this section are not directly associated
with the terms (individual or multiple) in the original query. this section uses the top relevant
documents for id183 in response to the initial query. the idea for using the top retrieved
documents as a source of potential relevant documents for a user   s motive comes from reference
[16]. the top documents are retrieved in response to the initial query and have more detailed
information about the initial query. this detailed information can be used for extracting the most
relevant terms for expanding the initial query. such id183 approaches demonstrate

id183 techniques for information retrieval: a survey

19

collectively better result in comparison to the above approaches. they can be subdivided into two
categories:

    id183 through relevance feedback. id183 terms are extracted from the
retrieved documents in response to the initial query and the user decides the relevance of the
results.

    id183 through pseudo-relevance feedback. id183 terms are extracted from

the top ranked documents in response to the initial query.

relevance feedback (rf) is the most e   ective id183 technique for modi   cation of
initial query using terms extracted from the documents in response to the initial query. the user
is asked to assess the relevance of documents retrieved in response to the initial query. retrieved
documents are mostly shown to the user in some surrogate form, such as title, abstract, keywords,
key-phrases or summaries. the user may also have a choice to see the entire documents before
making their relevant judgment and selecting the relevant documents. after the user indicates
relevant documents, these relevant documents are considered for extracting the terms for the initial
id183. the top weighted terms are either added to the initial query automatically or
based on manual selection by the user.

quite a few term selection techniques have been proposed for id183, which are based
on relevance feedback. the common thought behind the all similar techniques is to select terms that
will describe the full meaning of the initial query. one of the    rst approaches, who investigated the
relevance feedback is known as rocchio   s method [229]. this method used an information retrieval
system based on the vector space model. the main idea behind this approach is to update the
user   s initial query vector based on the user   s feedback. this method modi   es the initial query
vector as

      
q(cid:48) =   .      q +   .

1
|rd|

      
di       .

1
|id|

(cid:88)

      
di   rd

(cid:88)

      
dj   id

      
dj

(14)

      
where:
q(cid:48) is the modi   ed query vector,
      q is initial query vector,

      
dj is relevant and irrelevant document vector respectively.

  ,   ,    manage the comparative importance associated with documents as initial query weight,
      
relevant documents (rd) weight and irrelevant documents (id) weight respectively, and
di ,
in the above paper (i.e., [229]) only the positive feedback documents and their terms were used to
modify and expand the initial queries. hence, the weights are typically set as    = 1,    = 0.75,    =
0.15 and, any negative term weights are neglected and set to 0.

reference [132] presents a probabilistic model for calculating document matching score and
comes up with superior results on trec programme collections. here,    rst it retrieves the relevant
documents in response to the user   s initial query. then, the documents matching score (ms) is
computed as:

   wi

(15)

(cid:88)

ti   q

m s =

tfi    (k1 + 1)
tfi + n f    k1

where:
ti is an individual term in the user   s initial query q,
k1 is the term frequency id172 factor,
tfi is the term frequency of an individual term ti in the document,
nf is document length id172 factor calculated as n f = (1    c) + c   dl
constant, dl is the document length, and av dl is average document length)
wi is the collection frequency weight of term ti calculated as wi = log dn
(dn is the total number
ni
of documents in the whole collection and ni is the number of documents containing the term ti).

av dl (c is a tuning

some of other works based on probabilistic reweighting formulation are [225,227].
after the user selects relevant documents in response to the initial query, the system extracts

all terms of these documents and ranks them according to o   er weight (ow) computed as:

ow = r    rw

(16)

20

hiteshwar kumar azad, akshay deepak

where r is the number of relevant documents holding the id183 terms and rw is the
relevance weight.

rw is calculated as:

rw = log

(r + 0.5)(dn     n     dr + r + 0.5)

(dr     r + 0.5)(n     r + 0.5)

(17)

where:
dn is the total number of documents in the collection,
dr is number of documents selected as relevant by the user, and
n is the number of documents containing the term.

after this, either the system asks the user to select relevant terms, or adds a    xed number of

terms to the user   s initial query (automatic id183).

an approach similar to relevance feedback approach is pseudo-relevance feedback (or blind
feedback, or retrieval feedback). this directly uses the top retrieved documents in response to user   s
initial query for composing id183 terms. the user is not involved here in selection of
relevant documents. rocchio   s method [229] can also be applied in the context of pseudo-relevance
feedback, where every individual term extracted from the top retrieved documents is assigned
a score by employing a weighting function to the entire collection. the score gathered by every
individual term is estimated and the top terms are selected on the basis of resulting score. the
reccho   s weights can be computed as

scorerocchio(t) =

w(t, d)

(18)

(cid:88)

d   r

where w(t, d) indicate the weight of term t in pseudo-relevance document d and r is the set of
pseudo-relevance documents.

however, a disadvantage of the above approach is that it considers the score of each term in
document collection, in the process, showing more importance of the whole collection instead of
the importance of the user   s query. this problem can be resolved by analyzing the term distribu-
tion di   erence between the pseudo-relevant documents and the entire document collection. it is
expected that terms having less information content will have nearly the same distribution in any
documents in the whole collection. terms that are closely related to the user   s query will have a
more id203 of occurrence in the retrieve relevant documents.

various term ranking functions have been proposed on the basis of term distribution in pseudo-
relevant documents. these functions assign a high score to the terms that di   erentiate the relevant
documents from the irrelevant ones. some of the important term ranking functions have been
described below.

reference [225] proposes a weighting function known as binary independence model (bim)

that assigns a score to the query terms for term ranking as follows:
p(t|dr)[1     p(t|dc)]
p(t|dc)[1     p(t|dr)]

scorebim (t) = log

(19)

where p(t|dc) and p(t|dr) signify the id203 of occurrence of the term t in the document
collection dc and a set of pseudo-relevant documents dr respectively.

on the same lines, reference [86] uses a weighting function known as chi-square (  2) for scoring

the query terms. it is formulated as:

score  2(t) = log

[p(t|dr)     p(t|dc)]2

p(t|dc)

(20)

reference [224] presents a term selection method based on term weight known as robertson selec-
tion value (rsv). it assigns a weight to a term on the basis of deviation in term distribution in
the top retrieved documents. the term scoring method is formulated as:
w(t, d). [p(t|dr)     p(t|dc)]

scorersv (t) =

(cid:88)

(21)

d   r

where symbols have their meaning as given in equations 18 and 19.

id183 techniques for information retrieval: a survey

21

on the same lines, reference [57] uses the id181 (kld) for measuring
the term distribution di   erence between pseudo-relevant documents and the entire documents
collection. then, the terms having higher scores are added to the query along with kld score as
score of the term. the score of a term using kld is computed as:

scorekld(t) =

p(t|dr). log

p(t|dr)
p(t|dc)

(22)

(cid:88)

t   v

where symbols have their meaning as given in equation 19.

using the above term scoring approaches in id183, experimental studies [57,269,183]

showed very good results.

in 2012, reference [95] presented a novel collaborative semantic proximity measurement tech-
nique known as pming distance (further updated in [94]). it is based on the indexing information
returned by search engines. it uses the number of occurrences of a term or a set of terms and
counts the number of retrieved results returned by search engines.

the pming distance is de   ned as the weighted combination of pointwise mutual informa-
tion (pmi) and normalized google distance (ngd). whereas pmi o   ers excellent performance
in id91, ngd gives better results in human perception and contexts. overall, ngd and pmi
exhibit good performance in capturing the semantic information for id91, ranking and ex-
tracting meaningful relations among concepts. in order to understanding the pming distance, we
introduce some other concept similarity measurement technique such as pmi and ngd.

pointwise mutual information (pmi) [64] is a point-to-point measure of association used in
id205 and statistics. actually, mutual information (mi) (eq. 8) is a superset of pmi;
pmi refers to individual event, while mi refers to the average of all possible events. hence, pmi is
de   ned as same as mi:

p m is1,s2 = log2

(23)

(cid:20) p (s1, s2)

(cid:21)

p (s1) . p (s2)

normalized google distance (ngd) [65] measures the semantic relation between similar con-
cepts that occur together in a number of documents retrieved by a query on google or any other
search engine. originally, ngd was developed for google, but it can be applied for any other
search engine. ngd between the two terms s1 and s2 is de   ned as

n gds1,s2 =

max{log f (s1), log f (s2)}     log f (s1, s2)

log n     min{log f (s1), log f (s2)}

(24)

where:
f (s1), f (s2), and f (s1, s2) denotes the number of results returned by search engine for query sets
{s1}, {s2} and {s1, s2} respectively, and,
n is the total number of documents indexed by the search engine
signi   cantly greater than max{f (s1), f (s2)}.

n is usually unknown and varies very frequently. hence, it can be approximated by a value

though, in human perception ngd may stand good as a proximity measurement technique, in
strict sense it cannot be considered as a metric because it does not satisfy the property of triangular
inequality.

pming distance [95,94] includes the combination of two semantic similarity measurement
techniques: pmi and ngd. in pming distance pmi & ngd are locally normalized and pming
distance is de   ned as a convex linear combination of the two locally normalized distances. while
combining these two normalized distances, their relatives weights are chosen based on the context of
evaluation using, e.g., vector space model (vsm). for two terms s1 and s2 such that f (s1)     f (s2),
pming distance between s1 and s2 in context w is given as a function p m in g : w   w     (cid:100)0, 1(cid:101)
and de   ned as:

(cid:19) 1

(cid:21)

  1

(cid:20) log f (s1)     log f (s1, s2)

(log n     log f (s2))  2

(cid:21)

(25)

p m in gs1,s2 =   

1    

log

f (s1, s2)n
f (s1)f (s2)

+ (1       )

(cid:20)

(cid:18)

where:
   is a parameter to balance the weight of components such that 0            1,
n is the total number (if known) or estimated number (if not known) of documents indexed by

22

hiteshwar kumar azad, akshay deepak

the search engine,
  1 and   2 are constants; their value depends on the context of evaluation w and is de   ned as:

  1 = max
s1,s2   w

p m is1,s2

  1 = max
s1,s2   w

n gds1,s2

pming o   ers the advantages of both pmi and ngd: it outperforms the state-of-the-art prox-
imity measures in modeling human perception, modeling contexts and id91 of semantic asso-
ciations     regardless of the search engine/repository.

recently, article [201] presented a scoring function that uses two key properties of a query term:
the number of feedback documents having the query term, and, the rarity of the query term in the
whole document collection. the scoring function de   ned as:

score(t, f q) = log2(df (t, f q))    idf (t, c)

(26)

where:
f q is the set of feedback document for the query q,
df (t, f q) indicates the number of documents in f q having the term t
idf stand for inverse document frequency de   ned as idf (t, c) = log n
df (t,c) (n is the number of
documents in the whole collection and df (t, c) indicates the document frequency of the term t in
the collection c).

every term ranking method has its own justi   cation and the outcomes o   ered by their uti-
lization are also distinct. in case of speci   c queries, it has been observed that organized sets of
expansion terms recommended for each query are mostly unrelated to the original query [59].
however, various experimental analysis (such as [109, 236, 57,183]) observe that the selection of the
ranking approach commonly does not have a huge signi   cance on the system e   ciency; it is just
an approach to determine the set of terms for id183.

3.2.4 query id38

in this approach for id183, a statistical language model is constructed that assigns a
id203 distribution over term-collections. terms with maximum id203 are chosen for
id183. this approach is also known as model-based approach. the two popular founda-
tion language models are relevance model (based on probabilities of terms in relevant documents)
[156,70] and mixture model [286]; both utilize top retrieved documents for id183.

in relevance-based language model, reference [156] has caught the attention of researchers with
its strong probabilistic approach. it assumes that the query qi, and the top relevant documents
set d are sampled randomly (identically and independently) from an unknown relevance model
mrel. it determines the id203 of a term in relevant documents collection on the basis of its
co-occurrence with the query terms. for approximating this relevance model, the id203 of
term t is computed using id155 of the initial query term qi (i     1, ..., n). the
id203 of term t in the relevant documents is computed as:

p(t|mrel) =

p(  d) p(t|  d)

p(qi|  d)

(27)

(cid:88)

  d   r

n(cid:89)

i=1

in this equation, it has to be assumed that the term t and the query qi are mutually independent
once they elect a unigram distribution   d. recently this relevance model has been used widely
in id183. this model does not depend upon the distribution di   erence analysis, hence,
it can be said that conceptually this model is very much like rocchio method [229]. the main
di   erence of this model from the rocchio is that the top retrieved documents are assigned a weight
such that the lower ranked documents have insigni   cant impact on term id203 [155]. in the
research area of relevance model, several studies have been published [173,30,183]. reference [172]
performed a correlative analysis on several states of pseudo relevance feedback and concluded
that relevance model is the most e   cient method for selection of expansion terms. reference [30]
uses external resources for generating features for weighing di   erent types of query concepts and

id183 techniques for information retrieval: a survey

23

considers the latent concepts for expanding the initial query. reference [183] proposed a proximity-
based feedback model that is based on the traditional rocchio   s model, known as proc. it focus
on the proximity of terms rather than the positional information (unlike position relevance model
(prm)). it calculates the weights of candidate expansion terms by taking their distance from
query terms into account. reference [182] considers term dependencies during id183
and the expansion technique is based on markov random    elds model. this model provides a
powerful framework that includes both term occurrence and proximity-based features. an example
of markov random    eld is how many times the query terms occur within a window of    xed size in
an organized or unorganized way. reference [173] presents a technique for extracting the expansion
terms from the feedback documents known as positional relevance model. here, the focus is on query
topics based on the positions of query terms in feedback documents. another step in improving the
research on relevance model [76] presents a neighborhood relevance model that uses the relevance
feedback approaches for recognizing the specialty of entity linking across the document and query
collections. actually the main objective of entity linking is to map a string in a document to its
entity in knowledge base and recognize the disambiguating context inside the knowledge base.
recently article [78] proposed a context dependent relevance model that provides an approach to
incorporate the feedback through improvement of the document language models. for evaluating
document language models, it uses the context information on the relevant or irrelevant document
to obtain weight count (using bm25 weights [226, 223]) of the individual query terms.

discussing mixture model method, reference [286] considers the top ranked documents extracted
from the document collection that have both relevant and irrelevant information. the proposed
method is a mixture productive model that integrates the query topic model p(t|  q) to the col-
lection language model p(t|c). the collection language model is a suitable model for irrelevant
information (content) in top-ranked documents. following this mixture model, the log-likelihood
for top-ranked documents is de   ned as

log p(tr|  q) =

c(t, d) log(   p(t|c) + (1       ) p(t,   q))

(28)

(cid:88)

(cid:88)

d   tr

t

where:
tr is the set of top-ranked documents,
  q is the estimated query model,
c(t, d) is the number of occurrences of term t in document d, and
   is a weighting parameter with a value between 0 and 1.

after the evaluation of log-likelihood, em algorithm [82] is used to estimate the query topic
model so that the likelihood of the top-ranked documents is maximized. however, estimating the
query topic model is perhaps more di   cult than estimating the document model because queries
are generally short resulting in inadequacy of retrieved documents. comparatively, this mixture
model has a stronger theoretical justi   cation, estimating the value of weighting parameter    can
be a di   cult task.

table 6 summarizes some important term similarity score in mathematical form for term ranking

based on above discussion.

3.3 selection of id183 terms

in the previous section 3.2, weighting and ranking of expansion terms have been done. after this
step, the top-ranked terms are selected for id183. the term selection is done on individual
basis; mutually dependence of terms is not considered. this may be debatable, however, some
experimental studies (e.g, [165]) suggest that the independence assumption may be empirically
equitable.

it may happen that chosen id183 technique produces a large number of expansion
terms, but it might not be realistic to use all of these expansion terms. normally, only a limited
number of expansion terms are selected for id183. this is because the information
retrieval e   ectiveness of a query with a small set of expansion terms is usually better than the
query having a large set of expansion terms [236]; this happens due to noise reduction.

some experimental studies suggested the addition of optimum number of expansion terms
in the initial query [109,222,52,11,61,31,269, 201,290](described brie   y in section 3.1.1 and in

24

hiteshwar kumar azad, akshay deepak

table 6: summery of approaches for term ranking based on the term similarity score

reference

rocchio 1971 [229]

robertson and jones

1976 [225]

approaches

recchio   s weights

dice coe   cient

doszkocs 1978 [86]

chi-square (  2)

robertson 1990 [224]

carpineto et al. 2001

[57]

zhai and la   erty 2001

[286]

cilibrasi and vitanyi

2007 [65]

franzoni and milani
2012 [95], franzoni

2017 [94]

robertson selection

value (rsv)

kullback-leibler
divergence (kld)

log-likelihood

normalized google

distance (ngd)

pming distance

paik et al. 2014 [201]

scoring function

(cid:80)

mathematical form

d   r w(t, d)

log p(t|dr)[1   p(t|dc )]
p(t|dc )[1   p(t|dr)]
log [p(t|dr)   p(t|dc )]2

p(t|dc )

(cid:80)
d   r w(t, d). [p(t|dr)     p(t|dc )]
(cid:80)

p(t|dr). log p(t|dr)
p(t|dc )
log p(tr|  q) =

(cid:80)
t c(t, d) log(   p(t|c) + (1       ) p(t,   q))
d   tr
(cid:105)
n gds1,s2 = max{log f (s1),log f (s2)}   log f (s1,s2)
p m in gs1,s2 =   

(cid:104)
1    (cid:16)
(cid:104) log f (s1)   log f (s1,s2)

log n   min{log f (s1),log f (s2)}

log f (s1,s2)n
f (s1)f (s2)

(cid:17) 1

(cid:105)

  1

+

score(t, f q) = log2(df (t, f q))    idf (t, c)

(log n   log f (s2))  2

(1       )

table 7). however, this suggested optimum can vary from a few terms to a few hundred terms.
the expansion terms of the relevant or top-ranked documents improve the e   ectiveness of query
expansion by 7% to 25% [52]. on the contrary, some studies shows that the number of terms used
for id183 is less important than the terms selected on the basis of types and quality
[241]. it has been commonly shown that the e   ectiveness of the id183 decreases minutely
with the non-optimum number of expansion terms [57]. most of the experimental studies observed
that the number of expansion terms is of low relevance and it varies from query to query[39]. it
has been observed that the e   ectiveness of id183 (measured as mean average precision)
decreases when we consider less than 20 expansion terms [201,290]. usually 20-40 terms is the best
choice for id183. reference [286] assigns a id203 score to each expansion term and
selects those with score greater than a    xed threshold value p=0.001.

table 7: summery of terms selection suggested by several researchers

number of terms

one third of the terms

5 to 10 terms
20 to 30 terms
30 to 40 terms

few hundreds terms

350 to 530 terms

reference

robertson and willett 1993 [222]

amati et al. 2003 [11], chang et al. 2006 [61]
harman 1992 [109], zhang et al. 2016 [290]

paik et al. 2014 [201]

bernardini and carpineto 2008 [31], wong et al. 2008 [269]

buckley et al. 1995 [52]

however, instead of considering an optimum number of expansion terms, it may be better
to adopt more aware selection techniques. several experimental results notice that the optimum
number of expansion terms vary from query to query [50,38,55]. focus on selection of most relevant
terms for id183 instead of optimum number of terms yields better results [59,55].

for the selection of the expansion terms on the basis of ranks assigned to the individual term,
various approaches have been proposed that exploit additional information. reference [59] proposed
a technique that uses multiple term ranking functions and selects the most common terms for each
query. a similar approach is utilized in [68], however, multiple feedback models are constructed
from the same term ranking function. this is done by reconsidering documents from the corpus and
by creating alternatives of the initial query. the paper also claims that the proposed technique
is e   ective for eliminating the noise from expansion terms. it aims to expand the query terms
that are related to the various query features. another approach for selecting expansion terms
that depends upon the query ambiguity has been proposed in reference [62]. here, the number
of expansion terms depend on the ambiguity of the initial query in the web or the user log; the
ambiguity is determined by the clarity score [72]. reference [55] uses a classi   er to recognize the
relevant or irrelevant expansion terms. whether the classi   er parameter works well or not for
labeling the individual expansion terms, depends on the e   ectiveness of retrieval performance and

id183 techniques for information retrieval: a survey

25

co-occurrence of query terms. their study shows that top retrieved documents contain as many as
65% harmful terms. for selecting the best expansion terms reference [66] optimized the retrieved
data with respect to uncertainty sets resulting in an optimization problem.

however, it has been shown that majority of existing works on qe [155,270] only focused
on indexing and document optimization for selection of expansion terms and neglects the re-
ranking score. however, recently a number of articles [83, 290] supported the re-ranking with valid
proof and obtained good retrieval e   ectiveness. reference [270] proposed impact-sorted indexing
technique that utilizes a special index data structure; the technique improves the scoring methods
in information retrieval. reference [155] uses the pre-calculated pairwise document similarities to
reduce the searching time for expanded queries. however, supporting re-ranking, reference [83]
points out that re-ranking can provide nearly identical performance as the results returned from
the second retrieval done on expanded query. this works speci   cally for precision-oriented metrics.
this has also veri   ed in experimental result of reference [290], which utilizes re-ranking as the
default approach for information retrieval.

3.4 query reformulation

this is the last step of id183, where the expanded query is reformulated to achieve
better results when used for retrieving relevant documents. the reformulation is done based on
weights assigned to the individual terms of the expanded query     known as query reweighting.

a famous query reweighting method was proposed in reference [235], which is in   uence by roc-
chio   s method [229] for relevance feedback and its consequential developments. it can be formulated
as:

w(cid:48)

t,qe

= (1       ) . wt,q +    . wt

(29)

t,qe

is the reweighting of term t of the expanded query qe,

where w(cid:48)
wt is a weight assigned to the expansion term t, and,
   is weighting parameter, which weight the comparative contribution of the original query (q)
terms and the expansion terms.

when rocchio   s weights (see equation 18) are used for calculating the weights of the query
expansion terms, that are extracted from the pseudo-relevant documents, it can be observed that
the expanded query vector measured by equation 29 is relevant to the pseudo relevant documents.
this reduces the term distribution di   erence between pseudo relevance documents and documents
having expansion terms when terms are reweighed by rochhio   s weighing scheme. the intention
is to assign low weight to a top ranked term (in an expanded query) if its relevance score with
respect to the whole collection of documents is low. a number of experimental results support
this observation for various languages [290,201, 269,57], hindi [33,201], asian [237] and european
languages [80,151,11]. it has been observed that the reweighting system based on inverse term
ranks also provides a favorable outcome [116,59]. another observation is that the document-based
weights used for the original unexpanded query and the term distribution di   erence-based scores
used for expansion terms have di   erent units of measurement. hence, before using them in equation
29 their values must be normalized. a number of id172 approaches have been discussed in
survey [269] and it was observed that the discussed approaches commonly provide similar outcomes.
however, reference [191] observes the need for a better approach that not only normalizes data but
also increases equality among normalized terms, which can be more expressive.

in addition to the above discussion, the value of weighting parameter (  ) in equation 29 should
be adjusted appropriately for improving retrieval e   ectiveness. a common choice is to grant more
signi   cance     double     to the user   s initial query terms in comparison to the expanded query
terms. another way is to use the query reweighting formula without weighting parameter (  )
as suggested in reference [11]. another e   ective approach is to query-wise compute weight to
be assigned to the expansion terms. for example, references [172,173], use relevance feedback in
combination with a learning approach to forecast the values of weighting parameter (  ) for each
query and every collection of feedback documents. they also discuss various techniques     based
on e.g., length, clarity and id178     to measure the correlation of query terms with the entire
collection of documents as well as with only feedback documents. however, equation 29 can also
be used for extracting expansion terms from hand-built knowledge resources (such as thesaurus,

26

hiteshwar kumar azad, akshay deepak

id138 and conceptnet). the weighting score may be assigned on the basis of attributes such
as path length, number of co-occurrences, number of connections and relationship types [133]. for
example, reference [260], uses expanded query vector with eleven concept types sub vectors. each
concept type sub vector that comes inside the noun part of id138 is assigned individual weights.
examples of used concept type sub vectors are    original query terms    and    synonyms   . similarly,
reference [115] uses activation score for weighting of expansion terms.

when document ranking is based on id38 approach (see the section 3.2.4 ),
the query reweighting step usually favorably expands the original query. in id38
platform, most relevant documents are the ones that decrease id181 (kld)
between document language model and the query language model. it is formulated as:

simkld(q, d)    (cid:88)

p(t|  q). log

p(t|  q)
p(t|  d)

t   v

(30)

where:
  q is the query model (usually calculated using the original query terms), and,
  d is the document model.

document model   d is calculated based on unknown terms via id203 smoothing tech-

niques, such as jelinek-mercer interpolation[128,129]:

p(t|  (cid:48)

d) = (1       ) . p(t|  d) +    . p(t|  c)

(31)

where:
p(t|  (cid:48)
  c is the collection model.

d) is the id203 of term t in   (cid:48)

d (documents retrieved using expanded query), and

equation 30 raises the following question: is it possible to build a better query model by
obtaining similar terms with their concern probabilities? further, will it smooth the original query
model using the equivalent expanded query model (eqm) just as collection model   c smooths
the document model based on eq. 31 . to answer this, several approaches have been proposed
to build an expanded query model that not only consider feedback documents [286,156], but also
term relations [22,54,99], domain hierarchies [21] and can be heuristic [238]. hence, reference
[58] suggested that instead of considering a particular method, one can come up with a superior
expanded query model (calculated using jelinek-mercer interpolation [129]) given as:

p(t|  (cid:48)
q: p(t|  (cid:48)

q) = (1       ) . p(t|  q) +    . p(t|  eqm )
q) is the id203 of term t in expanded query   (cid:48)
q,

where, for each term t       (cid:48)
p(t|  q) is the id203 of term t in original query q,
p(t|  eqm ) is the id203 of term t in expanded query model   eqm , and,
   is the interpolation coe   cient.

(32)

this equation is the probabilistic representation of eq. 29 and many articles [279,142,58,99,

149,290] have used it for probabilistic query reweighting.

though the query reweighting approach is generally used in id183 techniques, it is
not mandatory. for example, one can increase the number of similar terms that characterize the
original query without using the query reweighting techniques [58]. another way can be to    rst
increase the number of similar query terms and then apply a customized weighting function for
ranking the expanded query terms, in stead of using the fundamental weighting function used for
reweighting the expanded query. this technique was used in reference [227] to enhance the okapi
bm25 ranking function [228]. some other approaches for query reformulation are utilization of
structured query [67,213,139,125], boolean query [207, 169, 105,141], xml query [136,63,135] and
phrase matching [14].

4 classi   cation of id183 approaches

on the basis of data sources used in id183, several approaches have been proposed. all
these approaches can be classi   ed into two main groups: (1) global analysis and (2) local analysis.
global and local analysis can be further split into four and three subclasses respectively as shown
in fig. 5. this section discusses properties of various data sources used in id183 as shown
in fig. 5; the id183 approaches have been categorized based on these properties.

id183 techniques for information retrieval: a survey

27

id30 analysis

linguistic
approaches

semantic analysis

query

expansion
approaches

global analysis

local analysis

corpus-based

approaches

search logbased

approaches

web-based
approaches

relevance feedback

pseudo-relevance

feedback

syntatic analysis

term id91

concept-
based term

user query log

query documents

relationships

anchor texts

wikipedia

faq

explicit feedback

implicit feedback

top documents

document
summaries

fig. 5: classi   cation of id183 approaches based on data sources.

4.1 global analysis

in global analysis, id183 techniques implicitly select expansion terms from hand-built
knowledge resources or from large corpora for expanding/reformulating the initial query. only
individual query terms are considered for expanding the initial query and expansion terms are
semantically similar to the original terms. each term is assigned a weight and expansion terms can
be assigned less weight in comparison to the original query terms. global analysis can be classi   ed
into four categories on the basis of query terms and data sources: linguistic-based, corpus-based,
search log-based and web-based. each approach has been discussed brie   y in the following sections.

4.1.1 linguistic-based approaches

the approaches in this category analyze the expansion features such as lexical, morphological,
semantic and syntactic term relationships to reformulate or expand the initial query terms. they
use thesaurus, dictionaries, ontologies, linked open data(lod) cloud or other similar knowledge
resources such as id138 or conceptnet.

28

hiteshwar kumar azad, akshay deepak

word id30 is one of the    rst and among the most in   uential id183 approaches
in linguistic association to reduce the in   ected word from its root word. the id30 algorithm
(e.g., [211]) can be utilized either at retrieval time or at indexing time. when used during retrieval,
terms from initially retrieved document are picked, and then, these terms are harmonized to the
morphological types of query terms (e.g., [145, 200]). when used during indexing time, document
word stems are picked, and then, these words are harmonized to the query root word stems (e.g.,
[122]). morphological approach is an ordered way of studying internal structure of the word. it
has been shown to give better result than the id30 approach [40,192], however, it requires
querying to be done in a structured way.

use of semantic and contextual analysis are other popular id183 approaches in
linguistic association. it includes knowledge sources such as ontologies, lod cloud, dictionaries
and thesaurus. in the context of ontological based id183, reference [34] uses domain-
speci   c and domain-independent ontologies. reference [272] utilizes the rich semantics of domain
ontology and evaluates the trade o    between the improvement in retrieval e   ectiveness and the
computation cost. several research works have been done on id183 using a thesaurus.
id138 is a well known thesaurus for expanding the initial query using the word synsets. as
discussed earlier, many of the research works use id138 for expanding the initial query. for
example, reference [260] uses id138 to    nd the synonyms. reference [245] uses id138 and
pos tagger for expanding the initial query. however, this approach has some practical problems,
such as no accurate matching between query and senses, absence of proper nouns, and, one query
term mapping to many noun synsets and collections. generally, utilization of id138 for query
expansion is bene   cial only if the query words are unambiguous in nature [104,260]; word sense
disambiguation (wsd) is not an easy problem [195,203]. several research works have attempted
to address the wsd problem. for example, reference [196] suggests that instead of considering the
replacement of the initial query term with its synonyms, hyponyms, and hyperonyms, it is better
to extract the similar concept from the same domain of the given query from id138 (such as the
common nodes and glossy terms). reference [103] uses the semantically similar information from
id138 in di   erent group; this may be combined to expand the initial query. references [288,246,
169] combine id138 concepts     that are extracted by consecutive application of heuristic rules
to match the similar query terms     with other term extraction techniques. reference [239] uses
linguistic and semantic features of the initial query over linked data for qe as discuss in earlier
section 2.2.2. recently, reference [5] introduced a wsd algorithm based on id93 over
large lexical knowledge bases (lkb). the experiments give better results than other graph-based
approaches when executed on a graph built from id138 and extended id138. nowadays,
id27s techniques are being used widely for id183, e.g., as in references
[230,84,149] discussed earlier.

another important approach that improves the linguistic information of the initial query is
syntactic analysis [289]. syntactic based id183 uses the enhanced relational features of
the query terms for expanding the initial query. it expands the query mostly through statistical
approaches [272]. it recognizes the term dependence statistically [218] by employing techniques
such as term co-occurrence. reference [252] uses this approach for extracting contextual terms
and relations from external corpus. here, it uses two dependency relation based id183
techniques for passage retrieval: density based system (dbs) and relation based system (rbs).
dbs makes use of relation analysis to extract high quality contextual terms. rbs extracts relation
paths for id183 in a density and relation based passage retrieval framework. syntactic
analysis approach may be bene   cial for natural language queries in search tasks where linguistic
analysis can break the task into a sequence of decisions [289] or integrate the taxonomic information
e   ectively [171].

4.1.2 corpus-based approaches

corpus-based approaches examine the contents of the whole text corpus to recognize the expansion
features utilized for id183. they are one of the earliest statistical approaches for query
expansion. they create co-relations between terms based on co-occurrence statistics in the corpus
to form sentences, paragraphs or neighboring words, which are used in expanded query. corpus-
based approaches have two admissible strategies: (1) term id91 [131,188,73], which groups
document terms into clusters based on their co-occurrences, and, (2) concept based terms [214,

id183 techniques for information retrieval: a survey

29

93,194], where expansion terms are based on the concept of query rather than the original query
terms. recently reference [149] selected the expansion terms after the analysis of the corpus using
id27, where each term in the corpus is characterized with a vector embedded in a
vector space.[290] uses four corpora as data sources (including one industry and three academic
corpus) and present a two-stage feature selection framework (tfs) for id183 known as
supervised id183 (sqe), discuss in earlier section 3.1.1 . some of the other approaches
established an association thesaurus based on the whole corpus; e.g., reference [101] uses context
vectors, reference [57] uses the term co-occurrence, reference [116] uses the mutual information and
reference [187] uses the interlinked wikipedia articles.

4.1.3 search log-based approaches

these approaches are based on the analysis of search logs. user feedback, which is an important
source for suggesting a set of similar terms based on the user   s initial query, is generally explored
based on the analysis of search logs. with the fast growing size of the web and increasing use of web
search engines, the abundance of search logs and their ease of use have made them an important
source for id183. it usually contains user queries corresponding to the urls of web
pages. reference [74] uses the query logs to extract probabilistic correlations between query terms
and document terms. these correlations are further used for expanding the user   s initial query.
similarly, reference [75] uses search logs for id183; their experiments give better results
when compared with id183 based on pseudo relevance feedback (prf). one of the
advantages of using search logs is that it implicitly incorporates relevance feedback. on the other
hand, it has been shown in reference [267] that implicit measurements are relatively good, but,
their performance may not be the same for all types of users and search task.

there are commonly two types of id183 approaches used on the basis of web search
logs. the    rst approach considers queries as documents and extracts features of these queries that
are related to the user   s initial query [118]. among the techniques based on    rst approach, some use
their combined retrieval results [119], while some do not (e.g., [118,282]). in the second approach,
the features are extracted on relational behavior of queries. for example, reference [19] represents
queries in a graph based vector space model (query-click bipartite graph) and analyzes the graph
constructed by query logs. references [75,218,56] extract the expansion terms directly from clicked
results. references [92,263] use the top results from past query terms entered by users. under the
second approach queries are also extracted from related documents [38,264], or through user clicks
[280,282,117]. the second is more popular and has been shown to give better results.

4.1.4 web-based approaches

these approaches include anchor texts and wikipedia for expanding the user   s original query, and
have become popular in recent times. anchor text was    rst used in reference [180] for associating
hyper-links with linked pages, as well as with the pages in which anchor texts are found. in the
context of a web-page, anchor text can play a role similar to the title since the anchor text pointing
to a page can serve as a concise summary of its contents. it has been shown that user search queries
and anchor texts are very similar because an anchor text is a brief characterization of its target page.
article [144] used anchor texts for qe; their experimental results suggest that anchor texts can
used to improve the traditional qe based on query logs. on similar lines, reference [79] suggested
that anchor text can be an e   ective substitute for query logs. it demonstrated e   ectiveness of query
expansion techniques using log-based id30 through experiments on standard trec collection
dataset.

another popular approach is use of wikipedia articles, titles and hyper-links (in-link and out-
link) [14, 9]. as we know, wikipedia is the largest encyclopedia freely available on the web; articles
are regularly updated and new ones are added every day. these features make it an ideal knowledge
source for id183. recently, quite a few research works have used it for id183
(e.g., [163,14,279,3,9]). article [7] attempts to enrich initial queries using semantic annotations
in wikipedia articles combined with phrases disambiguation. experimental results show better
results in comparison to the relevance based language model.

30

hiteshwar kumar azad, akshay deepak

faqs are another important web-based source of information for improving the qe. recently
published article [138] uses domain speci   c faqs data for manual id183. some other
works using faqs are [4,248,218].

4.2 local analysis

local analysis includes id183 techniques that select expansion terms from documents
collection retrieved in response to the user   s initial (unmodi   ed) query. the working belief is that
document retrieved in response to the user   s initial query are relevant, hence, terms present in
these documents should also be relevant to the initial query. using local analysis, there are two
ways to expand user   s original query: (1) relevance feedback and (2) pseudo-relevance feedback.
these two ways are discussed next.

4.2.1 relevance feedback (rf)

in this approach, user   s feedback about documents retrieved in response the initial query is col-
lected; the feedback is about whether or not retrieved documents are relevant to the user   s query.
the query is reformulated based on documents found relevant as per user   s feedback. rocchio   s
method [229] was amongst the    rst to use relevance feedback. relevance feedback can further be
categorized into two types: explicit feedback and implicit feedback. in explicit feedback, user ex-
plicitly evaluates the relevance of retrieved documents (as done in [235,109]), whereas in implicit
feedback, user   s activity on the set of documents retrieved in response to initial query is used to
indirectly infer user preferences (e.g. as done in [62,293,100]). relevance feedback su   ers from lack
of semantics in the corpus [272]. this restrains its applications in several occasions, for example,
when the query concept is as general as a disjunction of more speci   c concepts (see chap. 9 in
[177]). some of the research works based on relevance feedback are [51,236,231,177]; these have
been discussed earlier in sec. 3.2.3.

4.2.2 pseudo-relevance feedback (prf)

here, neither explicit nor implicit feedback of user is collected. instead, the feedback collection
process is automated by directly using the top ranked documents (or their snippets), retrieved
in response to the initial query, for id183. pseudo-relevance feedback is also known
as blind feedback, or, retrieval feedback. it has been discussed brie   y earlier in sec. 3.2.3. this
technique was    rst proposed in reference [71], which employs this technique in a probabilistic model.
reference [278] proposed    local context analysis    technique to extract the id183 terms
from the top documents retrieved in response to the initial query. each of the candidate expansion
term is assigned a score on the basis of co-occurrence of query terms. the candidate terms with
highest score are selected for query reformulation. a recent work [243] uses fuzzy logic-based query
expansion techniques and selects top-retrieved documents based on pseudo-relevance feedback.
here, each expansion term is assigned a distinct relevance score using fuzzy rules. terms having
highest scores are selected for id183. the experimental results demonstrate that the
proposed approach achieves signi   cant improvement over individual expansion, expansion on the
basis of entire query and other related advanced methods. reference [10] proposed deep learning
based qe technique and compared it with prf and other expansion models; the results show a
notable improvement over other techniques using various language models for evaluation.

however, considering top retrieved may not always be the best strategy. for example, for a
particular query, if the top retrieved documents have very similar contents, the expanded terms
    selected from the top retrieved documents     will be also very similar. hence, the expanded will
not be useful for e   ective id183. apart from using the top-ranked documents or their
snippets, several other approaches have been proposed. for example, techniques based on passage
extraction [277], text summarization [150], and document summaries [61]. some of the other articles
using prf are [55,279,173]; these have been discussed in earlier sections.

table 8 summarizes in   uential id183 approaches in chronological order on the basis of
   ve prominent features: data sources, term extraction methodology, term representation, term
selection methodology, and weighting schema.

id183 techniques for information retrieval: a survey

31

a
m
e
h
c
s

g
n

i
t
h
g
i
e

w

n
o
i
t
c
n
u
f

h
c
t
a
m

d
e
s
a
b

n
o
i
t
a
l
e
r
r
o
c

s
t
h
g
i
e
w

n
o
i
t
a
c
i
l

p
i
t
l
u
m

s
r
o
t
c
e
v

s
t
p
e
c
n
o
c

d
n
a

y
r
e
u
q

f
o

n
o
i
s
n
a
p
x
e
y
r
e
u
q

f
o

a
e
r
a

e
h
t

n

i

h
c
r
a
e
s
e
r

f
o

y
r
a
m
m
u
s

:
8

e
l
b
a
t

n
o
i
t
c
e
l
e
s
m
r
e
t

y
g
o
l
o
d
o
h
t
e

m

l
e
d
o
m

s
t
e
w
s

t
p
e
c
n
o
c
m
r
e
t

-

y
t
i
r
a
l
i

m

i
s

m
r
e
t

n
o
i
t
a
t
n
e
s
e
r
p
e
r

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

n
o
i
t
c
a
r
t
x
e
m
r
e
t

y
g
o
l
o
d
o
h
t
e

m

s
u
p
r
o
c

n

i

s

m
r
e
t

l
l

a

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
u
p
r
o
c

n

i

s

m
r
e
t

l
l

a

h
t
g
n
e
l

n
i
a
h
c
m
y
n
o
p
y
h

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

f
o

s

m
y
n
o
p
y
h
&
s
t
e
s
n
y
s

y
r
e
u
q

e
h
t

s
e
c
r
u
o
s

a
t
a
d

e
c
n
e
r
e
f
e
r

s
u
p
r
o
c

s
u
p
r
o
c

]
4
2
2
[

0
9
9
1

n
o
s
t
r
e
b
o
r

3
9
9
1

i
e
r
f

d
n
a

i

u
q

]
4
1
2
[

t
e
n
d
r
o

w

]
0
6
2
[

4
9
9
1

s
e
e
h
r
o
o
v

s
t
h
g
i
e
w
d
e
s
a
b
-
d
e
k
n
a
r

e
c
n
e
r
r
u
c
c
o
-
o
c
m
r
e
t

s
e
s
a
r
h
p

c
i
t
s
i
l
i

b
a
b
o
r
p

g
n
i
t
h
g
i
e
w
e
r

s
e
r
o
c
s
d
l
k
&
o
i
h
c
c
o
r

n
o
i
t
c
e
l
e
s

n
o
s
t
r
e
b
o
r

)
v
s
r
(

e
u
l
a
v

r
e
l
b
i
e
l
-
k
c
a
b

l
l

u
k

)
d
l
k
(

e
c
n
e
g
r
e
v
i
d

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

l
e
d
o
m
e
r
u
t
x
i
m

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

l
e
d
o
m
e
c
n
a
v
e
l
e
r

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

p
o
t

n

i

s
n
u
o
n

s
u
o
u
g
i
t
n
o
c

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

6
9
9
1

t
f
o
r
c
d
n
a

u
x

s
e
g
a
s
s
a
p

d
e
v
e
i
r
t
e
r

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

s
t
n
e
m
u
c
o
d

s
t
n
e
m
u
c
o
d

]
7
7
2
[

s
t
n
e
m
u
c
o
d

d
e
k
n
a
r
-
p
o
t

9
9
9
1

.
l
a

t
e

n
o
s
t
r
e
b
o
r

]
8
2
2
[

s
t
n
e
m
u
c
o
d

s
t
n
e
m
u
c
o
d

]
7
5
[

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

1
0
0
2

.
l
a

t
e

i

o
t
e
n
p
r
a
c

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

1
0
0
2

y
t
r
e
   
a
l

d
n
a

i
a
h
z

s
t
n
e
m
u
c
o
d

s
t
n
e
m
u
c
o
d

]
6
8
2
[

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

t
f
o
r
c
d
n
a

o
k
n
e
r
v
a
l

s
t
n
e
m
u
c
o
d

s
t
n
e
m
u
c
o
d
-
y
r
e
u
q

n
o
i
t
a
l
e
r
r
o
c

s
t
n
e
m
u
c
o
d

]
6
5
1
[

1
0
0
2

s
u
p
r
o
c
&
s
g
o
l

r
e
s
u

]
5
7
[

3
0
0
2

.
l
a

t
e

i

u
c

y
r
e
u
q

d
e
r
u
t
c
u
r
t
s

n
i
a
h
c

v
o
k
r
a
m

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
t
h
g
i
e
w
n
o
i
s
e
h
o
c

c
i
t
s
i
l
i

b
a
b
o
r
p

g
n
i
t
h
g
i
e
w
e
r

s

m
r
e
t

d
e
t
h
g
i
e
w
n
u

y
r
e
u
q

n
a
e
l
o
o
b

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

d
e
s
a
b
-
n
o
i
t
a
l
e
r
r
o
c

s
t
h
g
i
e
w

d
e
s
a
b
-
n
o
i
t
a
l
e
r
r
o
c

s
t
h
g
i
e
w

s
b
r
&
s
b
d

s
e
s
a
r
h
p

n
o
i
t
a
n
m

i

i
r
c
s
i
d

g
n
i
s
u

t
p
e
c
n
o
c
&
y
t
i
l
i

b
a

y
t
i
s
r
e
v
i
d

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

e
m
a
s

e
h
t

g
n
i
v
a
h

s

m
r
e
t

t
p
e
c
n
o
c

&

t
e
n
t
p
e
c
n
o
c

t
e
n
d
r
o

w

c
i
t
s
i
l
i

b
a
b
o
r
p

n
o
i
t
a
i
c
o
s
s
a
m
r
e
t
-

m
r
e
t

n
o
i
t
c
e
l
e
s

n
o
s
t
r
e
b
o
r

)
v
s
r
(

e
u
l
a
v

k
n
a
r

n
a
i
d
e
m

n
o
i
t
a
g
e
r
g
g
a

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

&
e
c
n
e
r
r
u
c
c
o
-
o
c
m
r
e
t

)
f
i
(
w
o
l
f

n
o
i
t
a
m
r
o
f
n
i

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

d
s
w

s
e
s
a
r
h
p

&
e
c
n
e
r
r
u
c
c
o
-
o
c
m
r
e
t

&
s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

&
n
o
i
t
a
c
   
i
s
s
a
l
c

e
s
a
r
h
p

d
e
k
n
a
r
-
p
o
t

,
s
u
p
r
o
c

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

n
o
i
t
a
i
c
o
s
s
a

y
r
e
u
q

s
g
o
l

y
r
e
u
q

s
e
s
a
r
h
p

n

i

s

m
r
e
t

t
n
e
c
a
j
d
a

t
x
e
t

r
o
h
c
n
a

s
t
x
e
t

r
o
h
c
n
a

3
0
0
2

.
l
a

t
e

k
c
e
b
r
e
l
l
i

b

]
8
3
[

4
0
0
2

n
e
i
z

d
n
a

t
f
a
r
k

]
4
4
1
[

]
9
6
1
[

4
0
0
2

.
l
a

t
e

i

u
l

s
t
p
e
c
n
o
c

t
e
n
d
r
o

w

n

i

s

m
r
e
t

t
n
e
c
a
j
d
a

s
t
n
e
m
u
c
o
d

d
e
k
n
a
r
-
p
o
t

m
r
e
t

c
i
t
s
i
l
i

b
a
b
o
r
p

k
r
o
w
t
e
n

n
o
i
t
a
i
c
o
s
s
a

l
a
u
t
x
e
t
n
o
c

t
n
a
v
e
l
e
r

s

m
r
e
t

t
e
n
d
r
o

w
&
s
t
n
e
m
u
c
o
d

s
t
n
e
m
u
c
o
d

d
e
k
n
a
r
-
p
o
t

]
2
2
[

5
0
0
2

.
l
a

t
e

i
a
b

,
s
u
p
r
o
c

,
t
e
n
d
r
o

w

d
n
a

r
e
m
m
e
t
s

s
t
n
e
m
u
c
o
d

d
e
k
n
a
r
-
p
o
t

n
o
s
p
m
o
h
t
-
s
n

i
l
l
o
c

]
7
6
[

5
0
0
2

n
a

l
l
a
c
d
n
a

s
u
p
r
o
c

]
2
5
2
[

6
0
0
2

.
l
a

t
e

n
u
s

s

m
r
e
t

d
e
t
h
g
i
e
w
n
u

s
e
u
q
i
n
h
c
e
t
t
m
s

s
e
s
a
r
h
p

s
r
e
w
s
n
a
q
a
f

n

i

s
e
s
a
r
h
p

a
t
a
d
q
a
f

h
p
a
r
g

y
r
e
u
q

d
e
d
n
a
p
x
e

d
o
o
h

i
l
e
k
i
l

m
u
m
i
x
a
m

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
d
l
e
   
m
o
d
n
a
r

v
o
k
r
a
m

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

t
f
o
r
c
d
n
a

r
e
l
z
t
e

m

l
e
d
o
m

s
t
n
e
m
u
c
o
d

]
2
8
1
[

7
0
0
2

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

&
n
o
i
t
a
c
   
i
s
s
a
l
c

y
r
e
u
q

n
o
i
t
a
m
r
o
f
n

i

l
a
u
t
u
m

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s

m
r
e
t

y
b
r
a
e
n
&
s

m
r
e
t

s
n
i
a
m
o
d

r
e
s
u

,
s
u
p
r
o
c

d
e
k
n
a
r
-
p
o
t

&

s
t
n
e
m
u
c
o
d

]
1
2
[

7
0
0
2

.
l
a

t
e

i
a
b

]
4
1
1
[

6
0
0
2

.
l
a

t
e

u
s
h

7
0
0
2

.
l
a

t
e

r
e
l
z
e
i
r

]
8
1
2
[

32

)
8

e
l

b
a
t
m
o
r
f

.
t
n
o
c
(

n
o
i
s
n
a
p
x
e
y
r
e
u
q

f
o

a
e
r
a

e
h
t

n

i

h
c
r
a
e
s
e
r

f
o

y
r
a
m
m
u
s

:
9

e
l
b
a
t

a
m
e
h
c
s

g
n

i
t
h
g
i
e

w

n
o
i
t
c
e
l
e
s
m
r
e
t

y
g
o
l
o
d
o
h
t
e

m

m
r
e
t

n
o
i
t
a
t
n
e
s
e
r
p
e
r

n
o
i
t
c
a
r
t
x
e
m
r
e
t

y
g
o
l
o
d
o
h
t
e

m

s
e
c
r
u
o
s

a
t
a
d

e
c
n
e
r
e
f
e
r

hiteshwar kumar azad, akshay deepak

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

l
e
d
o
m
e
c
n
a
v
e
l
e
r

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

n
o
i
t
a
c
   
i
s
s
a
l
c
m
r
e
t

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

y
r
t
n
e

f
o
m
u
s

s
d
o
o
h

i
l
e
k
i
l

k
n

i
l

&
k
n
a
r

t
n
e
m
u
c
o
d

y
c
n
e
u
q
e
r
f

s
e
s
a
r
h
p

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

l
e
d
o
m
e
c
n
a
v
e
l
e
r

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

d
e
k
n
a
r
-
p
o
t

f
o

g
n
i
r
e
t
s
u
c

l

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

s
t
n
e
m
u
c
o
d

s
t
n
e
m
u
c
o
d

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

s
t
n
e
m
u
c
o
d

a
i
d
e
p
i
k
i
w

]
7
5
1
[

8
0
0
2

.
l
a

t
e

e
e
l

]
5
5
[

8
0
0
2

.
l
a

t
e

o
a
c

8
0
0
2

.
l
a

t
e

o
l
l
e
u
g
r
a

]
4
1
[

a
i
d
e
p
i
k
i
w

]
9
7
2
[

9
0
0
2

.
l
a

t
e

u
x

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

n
o
i
t
u
t
i
t
s
b
u
s

y
t
i
l
i

b
a
b
o
r
p

c
i
t
s
i
l
i

b
a
b
o
r
p

g
n
i
t
h
g
i
e
w
e
r

&

l
e
d
o
m
e
c
n
a
v
e
l
e
r

l
e
d
o
m
e
r
u
t
x
i
m

r
e
l
b
i
e
l
-
k
c
a
b

l
l

u
k

)
d
l
k
(

e
c
n
e
g
r
e
v
i
d

e
c
n
a
v
e
l
e
r

l
a
n
o
i
t
i
s
o
p

)

m
r
p
(

l
e
d
o
m

&
s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

e
s
a
r
h
p

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

h
p
a
r
g

l
r
u
-
y
r
e
u
q

n
o

n

i

s

m
r
e
t

t
n
e
c
a
j
d
a

t
x
e
t

r
o
h
c
n
a

s
t
x
e
t

r
o
h
c
n
a

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

d
e
k
n
a
r
-
p
o
t

&
s
u
p
r
o
c

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

k
l
a
w
m
o
d
n
a
r
&
s
t
e
p
p
n
s

i

i

s
t
e
p
p
n
s
&
s
g
o
l

y
r
e
u
q

]
2
8
2
[

9
0
0
2

.
l
a

t
e

i

n
y

y
r
e
u
q

n
a
e
l
o
o
b

d
e
s
a
b
-
e
e
r
t

n
o
i
s
i
c
e
d

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

d
e
s
a
b

n
o
i
t
a
l
e
r
r
o
c

c
i
r
t
n
e
c
-
t
n
e
m
u
c
o
d

&
s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
t
h
g
i
e
w

s
e
r
o
c
s
d
l
k

d
e
s
a
b

n
o
i
t
a
l
e
r
r
o
c

s
t
h
g
i
e
w

h
c
a
o
r
p
p
a

d
e
s
a
b
-
y
t
i

m
i
x
o
r
p

l
e
d
o
m
k
c
a
b
d
e
e
f

)
c
o
r
p
(

d
n
a

s
n
o
i
t
a
t
o
n
n
a

s
e
s
a
r
h
p

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

d
e
k
r
a
m
k
o
o
b

s
a
h

r
e
s
u

e
h
t

s
e
c
r
u
o
s
e
r

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

f
d
i
-
f
t

c
i
t
n
a
m
e
s

t
i
c
i
l

p
x
e

e
r
o
c
s

)
a
s
e
(

s
i
s
y
l
a
n
a

&
s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
e
s
a
r
h
p

y
t
i
r
a
l
i

m

i
s

c
i
t
n
a
m
e
s

e
r
o
c
s

e
r
o
c
s
d
l
k

e
r
o
c
s
e
r
m
m

&
n
o
i
t
a
i
c
o
s
s
a

d
e
s
a
b

n
o
i
t
u
b
i
r
t
s
i
d

n
o
i
t
c
e
l
e
s

m
r
e
t

l
a
m
i
x
a
m

(
e
r
m
m

e
c
n
a
v
e
l
e
r

l
a
n
i
g
r
a
m

)
n
o
i
s
n
a
p
x
e
d
e
s
a
b
-

f
d
i
-
f
t

s
d
r
o
w
y
e
k
g
n
p
p
a
m

i

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
e
l
c
i
t
r
a

y
t
i
r
a
l
i

m

i
s

c
i
t
n
a
m
e
s

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

e
v
e
i
r
t
e
r

p
o
t

n

i

s
e
l
c
i
t
r
a

a
i
d
e
p
i
k
i
w

]
9
[

3
1
0
2

.
l
a

t
e

i
r
s
a
m
l
a

s
e
t
a
d
d
n
a
c

i

t
p
e
c
n
o
c

k
n

i
l
-
t
u
o
&
k
n

i
l
-
n
i

s
a

s
e
l
c
i
t
r
a

d
e
t
c
e
l
e
s

t
s
e
b

.
a
i
d
e
p
b
d
&
a
i
d
e
p
i
k
i
w

d
n
a

l
a
w
r
a
g
g
a

]
3
[

2
1
0
2

r
a
a
l
e
t
i
u
b

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

s
t
n
e
m
u
c
o
d

s
u
p
r
o
c

]
5
0
2
[

3
1
0
2

.
l
a

t
e

l
a
p

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s

m
r
e
t

n
o
i
s
n
a
p
x
e

e
s
r
e
v
i
d

s
t
n
e
m
u
c
o
d

e
v
e
i
r
t
e
r

m
o
r
f

e
l
o
h
w
n

i

m
r
e
t

s
r
o
b
h
g
i
e
n

d
o
l

f
o

h
p
a
r
g

t
e
n
t
p
e
c
n
o
c

d
u
o
l
c
d
o
l

.
l
a

t
e

a
h
c
u
o
h
c
u
o
b

]
8
4
[

3
1
0
2

3
1
0
2

.
l
a

t
e

n
i
e
t
s
n
e
g
u
a

]
7
1
[

s
t
n
e
m
u
c
o
d

s
u
p
r
o
c

s
u
p
r
o
c

0
1
0
2

t
f
o
r
c
d
n
a

g
n
a
d

]
9
7
[

]
3
7
1
[

0
1
0
2

i
a
h
z

d
n
a

v
l

]
1
4
1
[

1
1
0
2

.
l
a

t
e
m
k

i

]
2
3
[

1
1
0
2

.
l
a

t
e

a
i
t
a
h
b

s
u
p
r
o
c

]
3
8
1
[

2
1
0
2

.
l
a

t
e

o
a
i
m

s
g
o
l

r
e
s
u

]
3
9
2
[

2
1
0
2

.
l
a

t
e

u
o
h
z

s
t
n
e
m
u
c
o
d

p
o
t

n

i

s
t
x
e
t

r
o
h
c
n
a

a
i
d
e
p
i
k
i
w

e
v
e
i
r
t
e
r

s
t
n
e
m
u
c
o
d

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

s
e
l
c
i
t
r
a

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

s
t
n
e
m
u
c
o
d

k
c
a
b
d
e
e
f

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

s
t
n
e
m
u
c
o
d

s
u
p
r
o
c

e
h
t

n

i

s

m
r
e
t

l
l

a

d
e
s
a
b
-
y
t
i

m
i
x
o
r
p

l
l

a

s
u
p
r
o
c

e
h
t

n

i

s

m
r
e
t

s

m
r
e
t

d
e
t
a
i
c
o
s
s
a

p
o
t

m
o
r
f

d
e
t
c
a
r
t
x
e

s
t
n
e
m
u
c
o
d

d
e
k
n
a
r

m
o
r
f

s
e
l
c
i
t
r
a

d
e
k
n
a
r

p
o
t

id183 techniques for information retrieval: a survey

33

)
9

e
l

b
a
t
m
o
r
f

.
t
n
o
c
(

n
o
i
s
n
a
p
x
e
y
r
e
u
q

f
o

a
e
r
a

e
h
t

n

i

h
c
r
a
e
s
e
r

f
o

y
r
a
m
m
u
s

:
0
1

e
l
b
a
t

a
m
e
h
c
s

g
n

i
t
h
g
i
e

w

s
t
h
g
i
e
w
d
e
z
i
l
a
m
r
o
n

n
o
i
t
c
n
u
f

g
n
i
r
o
c
s

d
o
o
h

i
l
e
k
i
l

e
s
a
r
h
p

l
e
d
o
m

n
o
i
t
c
e
l
e
s
m
r
e
t

y
g
o
l
o
d
o
h
t
e

m

t
n
a
v
e
l
e
r

o
d
u
e
s
p

s
t
n
e
m
u
c
o
d

d
n

i
l

b

l
a
t
n
e
m
e
r
c
n
i

)
f
b
i
(

k
c
a
b
d
e
e
f

e
g
a
p

a
i
d
e
p
i
k
i
w

s
e
t
a
g
o
r
r
u
s

m
r
e
t

n
o
i
t
a
t
n
e
s
e
r
p
e
r

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
e
s
a
r
h
p

l
a
v
e
i
r
t
e
r

t
n
e
m
u
c
o
d

y
t
i
l
i

b
a
b
o
r
p

e
r
u
t
a
e
f

y
r
e
u
q

y
t
i
t
n
e

)
e
f
q
e
(

n
o
i
s
n
a
p
x
e

&
s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s
e
s
a
r
h
p

e
r
o
c
s
d
l
k

&

f
d

i
.
f
t

n
o
n
n
a
h
s
-
n
e
s
n
e
j

e
r
o
c
s

e
c
n
e
g
r
e
v
i
d

y
r
e
u
q

c
i
t
s
i
l
i

b
a
b
o
r
p

g
n
i
t
h
g
i
e
w
e
r

c
i
t
e
r
o
e
h
t

n
o
i
t
a
m
r
o
f
n
i

n
o

d
e
s
a
b

s
e
r
u
s
a
e
m

&
e
c
n
e
r
r
u
c
c
o
-
o
c

l
e
d
o
m
e
r
u
t
x
i
m

&
f
r
p
d
e
s
a
b

f
d

i
.
f
t

y
t
i
t
n
e

s
   
e
s
a
b
e
e
r
f

s
e
i
r
o
g
e
t
a
c

l
e
d
o
m
k
r
o
w
t
e
n

v
o
k
r
a
m

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

l
e
d
o
m
e
g
a
u
g
n
a
l

y
r
e
u
q

r
o
b
h
g
i
e
n

t
s
e
r
a
e
n
-
k

)
n
n
k
(

h
c
a
o
r
p
p
a

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

e
g
a
u
g
n
a
l

y
r
e
u
q

e
r
o
c
s
d
l
k
&
s
l
e
d
o
m

i

g
n
d
d
e
b
m
e

l
a
c
o
l

h
c
a
o
r
p
p
a

,
e
r
o
c
s

i

h
c

,
e
r
o
c
s

e
c
n
e
r
r
u
c
c
o
-
o
c

v
s
r
&
e
r
o
c
s
d
l
k

e
r
o
c
s

d
e
s
a
b
-
c
i
g
o
l
-
y
z
z
u
f

h
c
a
o
r
p
p
a

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

y
r
e
u
q

c
i
t
s
i
l
i

b
a
b
o
r
p

g
n
i
t
h
g
i
e
w
e
r

e
r
u
t
a
e
f

e
g
a
t
s
-
o
w
t

)
s
f
t
(

n
o
i
t
c
e
l
e
s

g
n
i
t
h
g
i
e
w

l
a
c
i
p
o
t

i

&
s
g
n
d
d
e
b
m
e

d
r
o

w

e
m
e
h
c
s

s
l
e
d
o
m
c
i
p
o
t

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

&
s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

f
o

s
k
n

i
l

t
u
o
/
n

i

&
s
e
l
t
i
t

k
c
a
b
d
e
e
f

n

i

s

m
r
e
t

l
l

a

f
o

t
e
s

d
e
v
e
i
r
t
e
r

p
o
t

n
o
i
t
c
a
r
t
x
e
m
r
e
t

y
g
o
l
o
d
o
h
t
e

m

&
s

m
y
n
o
l
o
h

,
s

m
y
n
o
n
y
s

y
r
e
u
q

e
h
t

f
o

s

m
y
n
o
r
e
m

s

m
r
e
t

s
e
c
r
u
o
s

a
t
a
d

e
c
n
e
r
e
f
e
r

t
e
n
d
r
o

w

]
6
0
2
[

4
1
0
2

.
l
a

t
e

l
a
p

s
t
n
e
m
u
c
o
d

s
e
g
a
p

a
i
d
e
p
i
k
i
w

d
e
k
n
a
r

p
o
t

n

i

s

m
r
e
t

l
l

a

o
t

s
k
n

i
l

s
e
l
c
i
t
r
a

s
e
s
a
b

e
g
d
e
l
w
o
n
k

e
s
a
b
e
e
r
f
&
a
i
d
e
p
i
k
i
w

]
7
7
[

4
1
0
2

.
l
a

t
e

n
o
t
l
a
d

s
t
n
e
m
u
c
o
d

a
i
d
e
p
i
k
i
w

]
1
0
2
[

4
1
0
2

.
l
a

t
e

k
i
a
p

g
n
e
a
y
m
d
n
a

l

u
o
b
h
s
-
l

a

]
7
[

4
1
0
2

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

m
r
e
t

n

i

s

m
r
e
t

k
-
p
o
t

s
h
p
a
r
g

n
o
i
t
a
i
c
o
s
s
a

&
a
i
d
e
p
b
d

t
e
n
t
p
e
c
n
o
c

v
o
t
o
k
d
n
a

d
n
a
n
a

]
3
1
[

5
1
0
2

s

m
r
e
t

l
a
u
d
i
v
i
d
n
i

d
r
o
w
d
e
n
i
a
r
t
-
y
l
l
a
c
o
l

s
u
p
r
o
c

]
4
8
[

6
1
0
2

.
l
a

t
e

z
a
i
d

e
v
e
i
r
t
e
r

p
o
t

n

i

s

m
r
e
t

l
l

a

s
t
n
e
m
u
c
o
d

s

m
r
e
t

d
e
t
a
l
e
r
r
o
c

k
-
p
o
t

s
u
p
r
o
c

e
h
t

n

i

t
a

s

m
r
e
t

y
b
r
a
e
n

l
l

a

i

g
n
d
d
e
b
m
e

d
r
o
w

k
r
o
w
e
m
a
r
f

n

i

s

m
r
e
t

l
l

a

s
u
p
r
o
c
&
a
i
d
e
p
i
k
i
w

]
9
9
[

5
1
0
2

n
o
h
d
n
a

n
a
g

e
s
a
b
e
e
r
f

5
1
0
2

n
a
l
l
a
c
d
n
a

g
n
o
i
x

]
6
7
2
[

s
u
p
r
o
c

]
0
3
2
[

6
1
0
2

.
l
a

t
e

y
o
r

i

s
g
n
d
d
e
b
m
e

f
o

s

m
r
e
t

e
u
q
i
n
u

e
h
t

l
l

a

d
e
v
e
i
r
t
e
r
n
p
o
t

s
t
n
e
m
u
c
o
d

l
a
v
e
i
r
t
e
r

n

i

s

m
r
e
t

k
-
p
o
t

s
t
n
e
m
u
c
o
d

r
a
l
i

m

i
s

c
i
t
n
a
m
e
s

l
l

a

e
h
t

e
d
i
s
n

i

s

m
r
e
t

s
e
l
   
o
r
p

r
e
s
u

d
e
h
c
i
r
n
e

s
t
n
e
m
u
c
o
d

d
e
k
n
a
r
-
p
o
t

n
a
r
a
h
s

d
n
a

h
g
n
s

i

]
3
4
2
[

6
1
0
2

&
s
e
l
   
o
r
p

r
e
s
u

a
t
a
d

y
m
o
n
o
s
k
l
o
f

]
5
9
2
[

7
1
0
2

.
l
a

t
e

u
o
h
z

a
r
o
p
r
o
c

]
0
9
2
[

6
1
0
2

.
l
a

t
e

g
n
a
h
z

34

hiteshwar kumar azad, akshay deepak

5 discussion and conclusions

this article has presented a comprehensive survey highlighting current progress, emerging research
directions, potential new research areas, working methodology, and detail classi   cation techniques
used for id183. although there is no perfect solution for the vocabulary mismatch prob-
lem in information retrieval system, id183 has the capability to overcome the primary
limitations. that is, provide the supporting explanation of the information needed for e   cient
information retrieval, which could not be provided earlier due to the unwillingness or inability of
the user. as we see in the present scenario of the search systems, most frequent queries are still
one, two or three words; the same as in the past few decades.

the lack of query terms increases the ambiguity in choosing among the many possible synony-
mous meanings of the query terms. this heightens the problem of vocabulary mismatch. this, in
turn, has motivated the necessity and opportunity to provide intelligent solutions to vocabulary
mismatch problem. over the past few decades, a lots of research have been done in the area of query
expansion based on data sources used, applications and expansion techniques. this article classi   es
the various data sources into three categories: documents used in the retrieval process, hand-built
knowledge resources and external text collections and resources. recently, it has been shown that
data sources of type external text collections and resources are used widely for id183,
specially, web data. in research involving web data, wikipedia is an popular data source because it
is the freely available largest encyclopedia on the web, where articles are regularly updated/added.
expansion approaches can be manual, automatic or interactive, (such as linguistic, corpus-
based, web-based, search log-based, rf and prf); they expand the user   s original query on the
basis of query features and available data sources. query characteristic depends upon query size,
lengths of terms, wordiness, ambiguity, di   culty and objective; addressing each of these features
requires speci   c approaches. several experimental studies have also reported remarkable improve-
ment in retrieval e   ectiveness: both with respect to precision and recall. these results are a proof
of advancement of research of id183 techniques. based on recent trend in literature,
hybrid techniques (combination of two or more techniques) give best results and seem to be more
e   ective with respect to diversity of users, queries and document corpus.

with the ever growing wealth of information available on internet, web searching has become an
integral part of our lives. every web user wants personalized information, and hence, information
retrieval systems need to personalize search results based on the query and the user. we believe
personalization of web search results will play an important in qe research in future.

references

1. abdulla, a.a.a., lin, h., xu, b., banbhrani, s.k.: improving biomedical information retrieval by linear

combinations of di   erent id183 techniques. bmc bioinformatics 17(7), 238 (2016)

2. adriani, m., van rijsbergen, c.: term similarity-based id183 for cross-language information re-
trieval. in: international conference on theory and practice of digital libraries, pp. 311   322. springer (1999)
in: clef (online working

3. aggarwal, n., buitelaar, p.: id183 using wikipedia and dbpedia.

notes/labs/workshop) (2012)

4. agichtein, e., lawrence, s., gravano, l.: learning to    nd answers to questions on the web. acm transactions

on internet technology (toit) 4(2), 129   162 (2004)

5. agirre, e., de lacalle, o.l., soroa, a.: id93 for knowledge-based id51. com-

putational linguistics 40(1), 57   84 (2014)

6. agrawal, r., imieli  nski, t., swami, a.: mining association rules between sets of items in large databases. in:

acm sigmod record, vol. 22, pp. 207   216. acm (1993)

7. al-shboul, b., myaeng, s.h.: wikipedia-based query phrase expansion in patent class search.

information

retrieval 17(5-6), 430   451 (2014)

8. allan, j.: incremental relevance feedback for information    ltering. in: proceedings of the 19th annual inter-
national acm sigir conference on research and development in information retrieval, pp. 270   278. acm
(1996)

9. almasri, m., berrut, c., chevallet, j.p.: wikipedia-based semantic query enrichment. in: proceedings of the
sixth international workshop on exploiting semantic annotations in information retrieval, pp. 5   8. acm (2013)
10. almasri, m., berrut, c., chevallet, j.p.: a comparison of deep learning based id183 with pseudo-
relevance feedback and mutual information. in: european conference on information retrieval, pp. 709   715.
springer (2016)

11. amati, g., joost, c., rijsbergen, v.: probabilistic models for information retrieval based on divergence from

randomness (2003)

12. amer, n.o., mulhem, p., g  ery, m.: toward id27 for personalized information retrieval. in: neu-ir:

the sigir 2016 workshop on neural information retrieval (2016)

id183 techniques for information retrieval: a survey

35

13. anand, r., kotov, a.: an empirical comparison of statistical term association graphs with dbpedia and con-
ceptnet for id183. in: proceedings of the 7th forum for information retrieval evaluation, pp. 27   30.
acm (2015)

14. arguello, j., elsas, j.l., callan, j., carbonell, j.g.: id194 and id183 models for

blog recommendation. icwsm 2008(0), 1 (2008)

15. atefeh, f., khreich, w.: a survey of techniques for id37 in twitter. computational intelligence

31(1), 132   164 (2015)

16. attar, r., fraenkel, a.s.: local feedback in full-text retrieval systems. journal of the acm (jacm) 24(3),

397   417 (1977)

17. augenstein, i., gentile, a.l., norton, b., zhang, z., ciravegna, f.: mapping keywords to linked data resources

for automatic id183. in: extended semantic web conference, pp. 101   112. springer (2013)

18. baeza-yates, r., hurtado, c., mendoza, m.: query recommendation using query logs in search engines. in:

international conference on extending database technology, pp. 588   596. springer (2004)

19. baeza-yates, r., tiberi, a.: extracting semantic relations from query logs. in: proceedings of the 13th acm

sigkdd international conference on knowledge discovery and data mining, pp. 76   85. acm (2007)

20. bai, j., nie, j.y., cao, g.: context-dependent term relations for information retrieval.

in: proceedings of
the 2006 conference on empirical methods in natural language processing, pp. 551   559. association for
computational linguistics (2006)

21. bai, j., nie, j.y., cao, g., bouchard, h.: using query contexts in information retrieval. in: proceedings of the
30th annual international acm sigir conference on research and development in information retrieval, pp.
15   22. acm (2007)

22. bai, j., song, d., bruza, p., nie, j.y., cao, g.: id183 using term relationships in language models for
information retrieval. in: proceedings of the 14th acm international conference on information and knowledge
management, pp. 688   695. acm (2005)

23. ballesteros, l., croft, b.: dictionary methods for cross-lingual information retrieval. in: international confer-

ence on database and id109 applications, pp. 791   801. springer (1996)

24. ballesteros, l., croft, w.b.: phrasal translation and id183 techniques for cross-language information

retrieval. in: acm sigir forum, vol. 31, pp. 84   91. acm (1997)

25. ballesteros, l., croft, w.b.: resolving ambiguity for cross-language retrieval.

in: proceedings of the 21st
annual international acm sigir conference on research and development in information retrieval, pp. 64   71.
acm (1998)

26. ballesteros, l.a.: cross-language retrieval via transitive translation. in: advances in information retrieval, pp.

203   234. springer (2002)

27. barrington, l., chan, a., turnbull, d., lanckriet, g.: audio information retrieval using semantic similarity.
in: 2007 ieee international conference on acoustics, speech and signal processing-icassp   07, vol. 2, pp.
ii   725. ieee (2007)

28. belkin, n.j., croft, w.b.: information    ltering and information retrieval: two sides of the same coin? com-

munications of the acm 35(12), 29   38 (1992)

29. bender, m., crecelius, t., kacimi, m., michel, s., neumann, t., parreira, j.x., schenkel, r., weikum, g.:
in: data engineering workshop, 2008.

exploiting social relations for id183 and result ranking.
icdew 2008. ieee 24th international conference on, pp. 501   506. ieee (2008)

30. bendersky, m., metzler, d., croft, w.b.: parameterized concept weighting in verbose queries. in: proceedings
of the 34th international acm sigir conference on research and development in information retrieval, pp.
605   614. acm (2011)

31. bernardini, a., carpineto, c.: fub at trec 2008 relevance feedback track: extending rocchio with distributional

term analysis. tech. rep., dtic document (2008)

32. bhatia, s., majumdar, d., mitra, p.: query suggestions in the absence of query logs. in: proceedings of the
34th international acm sigir conference on research and development in information retrieval, pp. 795   804.
acm (2011)

33. bhattacharya, p., goyal, p., sarkar, s.: usingid27s for query translation for hindi to english cross

language information retrieval. arxiv preprint arxiv:1608.01561 (2016)

34. bhogal, j., macfarlane, a., smith, p.: a review of ontology based id183. information processing &

management 43(4), 866   886 (2007)

35. bian, j., liu, y., agichtein, e., zha, h.: finding the right facts in the crowd: factoid id53 over
social media. in: proceedings of the 17th international conference on world wide web, pp. 467   476. acm
(2008)

36. biancalana, c., gasparetti, f., micarelli, a., sansonetti, g.: social semantic id183. acm transac-

tions on intelligent systems and technology (tist) 4(4), 60 (2013)

37. biancalana, c., micarelli, a.: social tagging in id183: a new way for personalized web search. in:
computational science and engineering, 2009. cse   09. international conference on, vol. 4, pp. 1060   1065.
ieee (2009)

38. billerbeck, b., scholer, f., williams, h.e., zobel, j.: id183 using associated queries. in: proceedings

of the twelfth international conference on information and knowledge management, pp. 2   9. acm (2003)
39. billerbeck, b., zobel, j.: questioning id183: an examination of behaviour and parameters.

in:
proceedings of the 15th australasian database conference-volume 27, pp. 69   76. australian computer society,
inc. (2004)

40. bilotti, m.w., katz, b., lin, j.: what works better for id53: id30 or morphological query
expansion. in: proceedings of the information retrieval for id53 (ir4qa) workshop at sigir,
vol. 2004, pp. 1   3 (2004)

41. boer, m., schutte, k., kraaij, w.: knowledge based id183 in complex multimedia id37.

multimedia tools and applications pp. 1   19 (2015)

36

hiteshwar kumar azad, akshay deepak

42. de boer, m., schutte, k., kraaij, w.: knowledge based id183 in complex multimedia id37.

multimedia tools and applications 75(15), 9025   9043 (2016)

43. borth, d., ji, r., chen, t., breuel, t., chang, s.f.: large-scale visual sentiment ontology and detectors using
adjective noun pairs. in: proceedings of the 21st acm international conference on multimedia, pp. 223   232.
acm (2013)

44. bouadjenek, m.r., hacid, h., bouzeghoub, m.: laicos: an open source platform for personalized social web
search. in: proceedings of the 19th acm sigkdd international conference on knowledge discovery and data
mining, pp. 1446   1449. acm (2013)

45. bouadjenek, m.r., hacid, h., bouzeghoub, m.: sopra: a new social personalized ranking function for improving
web search. in: proceedings of the 36th international acm sigir conference on research and development
in information retrieval, pp. 861   864. acm (2013)

46. bouadjenek, m.r., hacid, h., bouzeghoub, m., daigremont, j.: personalized social id183 using
social bookmarking systems. in: proceedings of the 34th international acm sigir conference on research
and development in information retrieval, pp. 1113   1114. acm (2011)

47. bouadjenek, m.r., hacid, h., bouzeghoub, m., vakali, a.: persador: personalized social document represen-

tation for improving web search. information sciences 369, 614   633 (2016)

48. bouchoucha, a., he, j., nie, j.y.: diversi   ed id183 using conceptnet. in: proceedings of the 22nd
acm international conference on conference on information & knowledge management, pp. 1861   1864. acm
(2013)

49. broder, a.: a taxonomy of web search. in: acm sigir forum, vol. 36, pp. 3   10. acm (2002)
50. buckley, c., harman, d.: reliable information access    nal workshop report. arda northeast regional re-

search center technical report 3 (2004)

51. buckley, c., salton, g., allan, j.: the e   ect of adding relevance information in a relevance feedback environ-
ment. in: proceedings of the 17th annual international acm sigir conference on research and development
in information retrieval, pp. 292   300. springer-verlag new york, inc. (1994)

52. buckley, c., salton, g., allan, j., singhal, a.: automatic id183 using smart: trec 3. nist special

publication sp pp. 69   69 (1995)

53. b  uttcher, s., clarke, c.l., cormack, g.v.: information retrieval: implementing and evaluating search engines.

mit press (2016)

54. cao, g., gao, j., nie, j.y., bai, j.: extending query translation to cross-language id183 with markov
chain models. in: proceedings of the sixteenth acm conference on conference on information and knowledge
management, pp. 351   360. acm (2007)

55. cao, g., nie, j.y., gao, j., robertson, s.: selecting good expansion terms for pseudo-relevance feedback.
in: proceedings of the 31st annual international acm sigir conference on research and development in
information retrieval, pp. 243   250. acm (2008)

56. cao, h., jiang, d., pei, j., he, q., liao, z., chen, e., li, h.: context-aware query suggestion by mining click-
through and session data. in: proceedings of the 14th acm sigkdd international conference on knowledge
discovery and data mining, pp. 875   883. acm (2008)

57. carpineto, c., de mori, r., romano, g., bigi, b.: an information-theoretic approach to automatic query

expansion. acm transactions on information systems (tois) 19(1), 1   27 (2001)

58. carpineto, c., romano, g.: a survey of automatic id183 in information retrieval. acm computing

surveys (csur) 44(1), 1 (2012)

59. carpineto, c., romano, g., giannini, v.: improving retrieval feedback with multiple term-ranking function

combination. acm transactions on information systems (tois) 20(3), 259   290 (2002)

60. cavalin, p., figueiredo, f., de bayser, m., moyano, l., candello, h., appel, a., souza, r.: building a question-
answering corpus using social media and news articles. in: international conference on computational pro-
cessing of the portuguese language, pp. 353   358. springer (2016)

61. chang, y., ounis, i., kim, m.: query reformulation using automatically generated query concepts from a

document space. information processing & management 42(2), 453   468 (2006)

62. chirita, p.a., firan, c.s., nejdl, w.: personalized id183 for the web. in: proceedings of the 30th
annual international acm sigir conference on research and development in information retrieval, pp. 7   14.
acm (2007)

63. chu-carroll, j., prager, j., czuba, k., ferrucci, d., duboue, p.: semantic search via xml fragments: a high-
precision approach to ir. in: proceedings of the 29th annual international acm sigir conference on research
and development in information retrieval, pp. 445   452. acm (2006)

64. church, k.w., hanks, p.: word association norms, mutual information, and id69. computational

linguistics 16(1), 22   29 (1990)

65. cilibrasi, r.l., vitanyi, p.m.: the google similarity distance.

ieee transactions on knowledge and data

engineering 19(3) (2007)

66. collins-thompson, k.: reducing the risk of id183 via robust constrained optimization. in: proceed-

ings of the 18th acm conference on information and knowledge management, pp. 837   846. acm (2009)

67. collins-thompson, k., callan, j.: id183 using random walk models. in: proceedings of the 14th

acm international conference on information and knowledge management, pp. 704   711. acm (2005)

68. collins-thompson, k., callan, j.: estimation and use of uncertainty in pseudo-relevance feedback. in: pro-
ceedings of the 30th annual international acm sigir conference on research and development in information
retrieval, pp. 303   310. acm (2007)

69. collins-thompson, k., macdonald, c., bennett, p., diaz, f., voorhees, e.m.: trec 2014 web track overview.

tech. rep., dtic document (2015)

70. croft, b., la   erty, j.: id38 for information retrieval, vol. 13. springer science & business media

(2013)

71. croft, w.b., harper, d.j.: using probabilistic models of document retrieval without relevance information.

journal of documentation 35(4), 285   295 (1979)

id183 techniques for information retrieval: a survey

37

72. cronen-townsend, s., zhou, y., croft, w.b.: predicting query performance. in: proceedings of the 25th annual
international acm sigir conference on research and development in information retrieval, pp. 299   306. acm
(2002)

73. crouch, c.j., yang, b.: experiments in automatic statistical thesaurus construction. in: proceedings of the
15th annual international acm sigir conference on research and development in information retrieval, pp.
77   88. acm (1992)

74. cui, h., wen, j.r., nie, j.y., ma, w.y.: probabilistic id183 using query logs. in: proceedings of

the 11th international conference on world wide web, pp. 325   332. acm (2002)

75. cui, h., wen, j.r., nie, j.y., ma, w.y.: id183 by mining user logs. ieee transactions on knowledge

and data engineering 15(4), 829   839 (2003)

76. dalton, j., dietz, l.: a neighborhood relevance model for entity linking. in: proceedings of the 10th confer-
ence on open research areas in information retrieval, pp. 149   156. le centre de hautes etudes
internationales d   informatique documentaire (2013)

77. dalton, j., dietz, l., allan, j.: entity query feature expansion using knowledge base links. in: proceedings
of the 37th international acm sigir conference on research & development in information retrieval, pp.
365   374. acm (2014)

78. dang, e.k.f., luk, r.w., allan, j.: a context-dependent relevance model. journal of the association for

information science and technology 67(3), 582   593 (2016)

79. dang, v., croft, b.w.: query reformulation using anchor text. in: proceedings of the third acm international
80. darwish, k., magdy, w., et al.: arabic information retrieval. foundations and trends r(cid:13) in information

conference on web search and data mining, pp. 41   50. acm (2010)

retrieval 7(4), 239   342 (2014)

81. datta, r., joshi, d., li, j., wang, j.z.: id162: ideas, in   uences, and trends of the new age. acm

computing surveys (csur) 40(2), 5 (2008)

82. dempster, a.p., laird, n.m., rubin, d.b.: maximum likelihood from incomplete data via the em algorithm.

journal of the royal statistical society. series b (methodological) pp. 1   38 (1977)

83. diaz, f.: condensed list relevance models. in: proceedings of the 2015 international conference on the theory

of information retrieval, pp. 313   316. acm (2015)

84. diaz, f., mitra, b., craswell, n.: id183 with locally-trained id27s. arxiv preprint

arxiv:1605.07891 (2016)

85. dice, l.r.: measures of the amount of ecologic association between species. ecology 26(3), 297   302 (1945)
86. doszkocs, t.e.: aid, an associative interactive dictionary for online searching. online review 2(2), 163   173

(1978)

87. douze, m., revaud, j., schmid, c., j  egou, h.: stable hyper-pooling and id183 for id37.

in: proceedings of the ieee international conference on id161, pp. 1825   1832 (2013)

88. efthimiadis, e.n.: id183. annual review of information science and technology 31, 121   187 (1996)
89. egozi, o., markovitch, s., gabrilovich, e.: concept-based information retrieval using explicit semantic analysis.

acm transactions on information systems (tois) 29(2), 8 (2011)

90. eguchi, k.: ntcir-5 id183 experiments using term dependence models. in: ntcir (2005)
91. eichstaedt, m., patel, a.p., lu, q., manber, u., rudkin, k.: system and method for personalized information

   ltering and alert generation (2002). us patent 6,381,594

92. fitzpatrick, l., dent, m.: automatic feedback using past queries: social searching? in: acm sigir forum,

vol. 31, pp. 306   313. acm (1997)

93. fonseca, b.m., golgher, p., p  ossas, b., ribeiro-neto, b., ziviani, n.: concept-based interactive query expan-
sion. in: proceedings of the 14th acm international conference on information and knowledge management,
pp. 696   703. acm (2005)

94. franzoni, v.: just an update on pming distance for web-based semantic similarity in arti   cial intelligence and

data mining. arxiv preprint arxiv:1701.02163 (2017)

95. franzoni, v., milani, a.: pming distance: a collaborative semantic proximity measure.

in: proceedings of
the the 2012 ieee/wic/acm international joint conferences on web intelligence and intelligent agent
technology-volume 02, pp. 442   449. ieee computer society (2012)

96. fu, g., jones, c.b., abdelmoty, a.i.: ontology-based spatial id183 in information retrieval. in:
otm confederated international conferences    on the move to meaningful internet systems   , pp. 1466   1482.
springer (2005)

97. furnas, g.w., landauer, t.k., gomez, l.m., dumais, s.t.: the vocabulary problem in human-system com-

munication. communications of the acm 30(11), 964   971 (1987)

98. gaillard, b., bouraoui, j.l., de neef, e.g., boualem, m.: id183 for cross language information

retrieval improvement. in: rcis, pp. 337   342 (2010)

99. gan, l., hong, h.: improving id183 for information retrieval using wikipedia. international journal

of database theory and application 8(3), 27   40 (2015)

100. gao, y., xu, y., li, y.: pattern-based topics for document modelling in information    ltering. ieee transac-

tions on knowledge and data engineering 27(6), 1629   1642 (2015)

101. gauch, s., wang, j., rachakonda, s.m.: a corpus analysis approach for automatic id183 and its

extension to multiple databases. acm transactions on information systems (tois) 17(3), 250   269 (1999)

102. ghorab, m.r., zhou, d., oconnor, a., wade, v.: personalised information retrieval: survey and classi   cation.

user modeling and user-adapted interaction 23(4), 381   443 (2013)

103. gong, z., cheang, c.w., et al.: multi-term web id183 using id138. in: international conference

on database and id109 applications, pp. 379   388. springer (2006)

104. gonzalo, j., verdejo, f., chugur, i., cigarran, j.: indexing with id138 synsets can improve text retrieval.

arxiv preprint cmp-lg/9808002 (1998)

105. graupmann, j., cai, j., schenkel, r.: automatic query re   nement using mined semantic relations. in: web
information retrieval and integration, 2005. wiri   05. proceedings. international workshop on challenges in,
pp. 205   213. ieee (2005)

38

hiteshwar kumar azad, akshay deepak

106. guisado-g  amez, j., prat-p  erez, a., larriba-pey, j.l.: id183 via structural motifs in wikipedia

graph. arxiv preprint arxiv:1602.07217 (2016)

107. hahm, g.j., yi, m.y., lee, j.h., suh, h.w.: a personalized id183 approach for engineering docu-

ment retrieval. advanced engineering informatics 28(4), 344   359 (2014)

108. hanani, u., shapira, b., shoval, p.: information    ltering: overview of issues, research and systems. user

modeling and user-adapted interaction 11(3), 203   259 (2001)

109. harman, d.: relevance feedback and other query modi   cation techniques. (1992)
110. harman, d., voorhees, e.: overview of the seventh text retrieval conference (trec-7). in: proceedings of the

seventh text retrieval conference (trec-7), nist special publication, pp. 500   242 (1996)

111. he, b., ounis, i.: combining    elds for id183 and adaptive id183. information processing

& management 43(5), 1294   1307 (2007)

112. he, b., ounis, i.: studying id183 e   ectiveness. in: ecir, vol. 9, pp. 611   619. springer (2009)
113. hersh, w., price, s., donohoe, l.: assessing thesaurus-based id183 using the umls metathesaurus.

in: proceedings of the amia symposium, p. 344. american medical informatics association (2000)

114. hsu, m.h., tsai, m.f., chen, h.h.: id183 with conceptnet and id138: an intrinsic comparison.

in: asia information retrieval symposium, pp. 1   13. springer (2006)

115. hsu, m.h., tsai, m.f., chen, h.h.: combining id138 and conceptnet for automatic id183: a

learning approach. in: asia information retrieval symposium, pp. 213   224. springer (2008)

116. hu, j., deng, w., guo, j.: improving retrieval performance by global analysis. in: pattern recognition, 2006.

icpr 2006. 18th international conference on, vol. 2, pp. 703   706. ieee (2006)

117. hua, x.s., yang, l., wang, j., wang, j., ye, m., wang, k., rui, y., li, j.: clickage: towards bridging semantic
and intent gaps via mining click logs of search engines. in: proceedings of the 21st acm international conference
on multimedia, pp. 243   252. acm (2013)

118. huang, c.k., chien, l.f., oyang, y.j.: relevant term suggestion in interactive web search based on contextual
information in query session logs. journal of the association for information science and technology 54(7),
638   649 (2003)

119. huang, j., efthimiadis, e.n.: analyzing and evaluating query reformulation strategies in web search logs. in:
proceedings of the 18th acm conference on information and knowledge management, pp. 77   86. acm (2009)
120. huber, s., seiger, r., k  uhnert, a., theodorou, v., schlegel, t.: goal-based semantic queries for dynamic

processes in the internet of things. international journal of semantic computing 10(02), 269   293 (2016)

121. huber, s., seiger, r., schlegel, t., et al.: using semantic queries to enable dynamic service invocation for
processes in the internet of things. in: 2016 ieee tenth international conference on semantic computing
(icsc), pp. 214   221. ieee (2016)

122. hull, d.a., et al.: id30 algorithms: a case study for detailed evaluation. jasis 47(1), 70   84 (1996)
123. imran, h., sharan, a.: selecting e   ective expansion terms for better information retrieval (2010)
124. jaccard, p.: the distribution of the    ora in the alpine zone. new phytologist 11(2), 37   50 (1912)
125. jamil, h.m., jagadish, h.v.: a structured query model for the deep relational web. in: proceedings of the 24th
acm international on conference on information and knowledge management, pp. 1679   1682. acm (2015)
126. jammalamadaka, r.c., salaka, v.k., johnson, b.s., king, t.h.: id183 classi   er for e-commerce

(2015). us patent 9,135,330

127. jardine, n., van rijsbergen, c.j.: the use of hierarchic id91 in information retrieval. information storage

and retrieval 7(5), 217   240 (1971)

128. jelinek, f.: interpolated estimation of markov source parameters from sparse data. in: proc. workshop on

pattern recognition in practice, 1980 (1980)

129. jelinek, f., mercer, r.l.: interpolated estimation of markov source parameters from sparse data. in: proceed-

ings of the workshop on pattern recognition in practice (1980)

130. jian, f., huang, j.x., zhao, j., he, t., hu, p.: a simple enhancement for ad-hoc information retrieval via topic
modelling. in: proceedings of the 39th international acm sigir conference on research and development in
information retrieval, pp. 733   736. acm (2016)

131. jones, k.s.: automatic keyword classi   cation for information retrieval (1971)
132. jones, k.s., walker, s., robertson, s.e.: a probabilistic model of information retrieval: development and

comparative experiments: part 2. information processing & management 36(6), 809   840 (2000)

133. jones, s., gatford, m., robertson, s., hancock-beaulieu, m., secker, j., walker, s.: interactive thesaurus

navigation: intelligence rules ok? journal of the american society for information science 46(1), 52 (1995)

134. jourlin, p., johnson, s.e., jones, k.s., woodland, p.c.: general id183 techniques for spoken doc-
ument retrieval. in: esca tutorial and research workshop (etrw) on accessing information in spoken
audio (1999)

135. junedi, m., genev`es, p., laya    da, n.: xml query-update independence analysis revisited. in: proceedings of

the 2012 acm symposium on document engineering, pp. 95   98. acm (2012)

136. kamps, j., marx, m., rijke, m.d., sigurbj  ornsson, b.: articulating information needs in xml query languages.

acm transactions on information systems (tois) 24(4), 407   436 (2006)

137. kang, i.h., kim, g.: query type classi   cation for web document retrieval. in: proceedings of the 26th annual
international acm sigir conference on research and development in informaion retrieval, pp. 64   71. acm
(2003)

138. karan, m.,   snajder, j.: evaluation of manual id183 rules on a domain speci   c faq collection. in:
international conference of the cross-language evaluation forum for european languages, pp. 248   253.
springer (2015)

139. kato, m.p., sakai, t., tanaka, k.: structured query suggestion for specialization and parallel movement: e   ect
on search behaviors. in: proceedings of the 21st international conference on world wide web, pp. 389   398.
acm (2012)

140. khwileh, a., jones, g.j.: investigating segment-based id183 for user-generated spoken content
retrieval. in: content-based multimedia indexing (cbmi), 2016 14th international workshop on, pp. 1   6.
ieee (2016)

id183 techniques for information retrieval: a survey

39

141. kim, y., seo, j., croft, w.b.: automatic boolean query suggestion for professional search. in: proceedings
of the 34th international acm sigir conference on research and development in information retrieval, pp.
825   834. acm (2011)

142. kotov, a., zhai, c.: tapping into knowledge base for concept feedback: leveraging conceptnet to improve
search results for di   cult queries. in: proceedings of the    fth acm international conference on web search
and data mining, pp. 403   412. acm (2012)

143. kraaij, w., nie, j.y., simard, m.: embedding web-based statistical translation models in cross-language

information retrieval. computational linguistics 29(3), 381   419 (2003)

144. kraft, r., zien, j.: mining anchor text for query re   nement. in: proceedings of the 13th international conference

on world wide web, pp. 666   674. acm (2004)

145. krovetz, r.: viewing morphology as an id136 process. in: proceedings of the 16th annual international

acm sigir conference on research and development in information retrieval, pp. 191   202. acm (1993)

146. krovetz, r., croft, w.b.: lexical ambiguity and information retrieval. acm transactions on information

systems (tois) 10(2), 115   141 (1992)

147. kumar, n., carterette, b.: time based feedback and id183 for twitter search. in: european con-

ference on information retrieval, pp. 734   737. springer (2013)

148. kuo, y.h., chen, k.t., chiang, c.h., hsu, w.h.: id183 for hash-based image object retrieval. in:

proceedings of the 17th acm international conference on multimedia, pp. 65   74. acm (2009)

149. kuzi, s., shtok, a., kurland, o.: id183 using id27s. in: proceedings of the 25th acm

international on conference on information and knowledge management, pp. 1929   1932. acm (2016)

150. lam-adesina, a.m., jones, g.j.: applying summarization techniques for term selection in relevance feedback.
in: proceedings of the 24th annual international acm sigir conference on research and development in
information retrieval, pp. 1   9. acm (2001)

151. larkey, l.s., ballesteros, l., connell, m.e.: light id30 for arabic information retrieval. in: arabic com-

putational morphology, pp. 221   243. springer (2007)

152. latiri, c., haddad, h., hamrouni, t.: towards an e   ective automatic id183 process using an asso-

ciation rule mining approach. journal of intelligent information systems 39(1), 209   247 (2012)

153. lau, r.y., bruza, p.d., song, d.: belief revision for adaptive information retrieval. in: proceedings of the
27th annual international acm sigir conference on research and development in information retrieval, pp.
130   137. acm (2004)

154. lau, t., horvitz, e.: patterns of search: analyzing and modeling web query re   nement.

in: um99 user

modeling, pp. 119   128. springer (1999)

155. lavrenko, v., allan, j.: real-time id183 in relevance models. internal report no 473, center for

intelligent information retrieval-ciir, university of massachusetts (2006)

156. lavrenko, v., croft, w.b.: relevance based language models. in: proceedings of the 24th annual international

acm sigir conference on research and development in information retrieval, pp. 120   127. acm (2001)

157. lee, k.s., croft, w.b., allan, j.: a cluster-based resampling method for pseudo-relevance feedback. in: pro-
ceedings of the 31st annual international acm sigir conference on research and development in information
retrieval, pp. 235   242. acm (2008)

158. lehmann, j., isele, r., jakob, m., jentzsch, a., kontokostas, d., mendes, p.n., hellmann, s., morsey, m.,
van kleef, p., auer, s., et al.: dbpedia   a large-scale, multilingual knowledge base extracted from wikipedia.
semantic web 6(2), 167   195 (2015)

159. lemos, o.a., de paula, a.c., zanichelli, f.c., lopes, c.v.: thesaurus-based automatic id183 for
interface-driven code search. in: proceedings of the 11th working conference on mining software repositories,
pp. 212   221. acm (2014)

160. levow, g.a., oard, d.w., resnik, p.: dictionary-based techniques for cross-language information retrieval.

information processing & management 41(3), 523   547 (2005)

161. lew, m.s., sebe, n., djeraba, c., jain, r.: content-based multimedia information retrieval: state of the art
and challenges. acm transactions on multimedia computing, communications, and applications (tomm)
2(1), 1   19 (2006)

162. li, x., uricchio, t., ballan, l., bertini, m., snoek, c.g., bimbo, a.d.: socializing the semantic gap: a
comparative survey on image tag assignment, re   nement, and retrieval. acm computing surveys (csur)
49(1), 14 (2016)

163. li, y., luk, w.p.r., ho, k.s.e., chung, f.l.k.: improving weak ad-hoc queries using wikipedia asexternal
corpus. in: proceedings of the 30th annual international acm sigir conference on research and development
in information retrieval, pp. 797   798. acm (2007)

164. lin, d., pantel, p.: discovery of id136 rules for question-answering. natural language engineering 7(04),

343   360 (2001)

165. lin, j., murray, g.c.: assessing the term independence assumption in blind relevance feedback. in: proceedings
of the 28th annual international acm sigir conference on research and development in information retrieval,
pp. 635   636. acm (2005)

166. liu, d., yan, s., ji, r.r., hua, x.s., zhang, h.j.: id162 with query-adaptive hashing. acm trans-

actions on multimedia computing, communications, and applications (tomm) 9(1), 2 (2013)

167. liu, d.r., chen, y.h., shen, m., lu, p.j.: complementary qa network analysis for qa retrieval in social
question-answering websites. journal of the association for information science and technology 66(1), 99   116
(2015)

168. liu, h., singh, p.: conceptneta practical commonsense reasoning tool-kit. bt technology journal 22(4),

211   226 (2004)

169. liu, s., liu, f., yu, c., meng, w.: an e   ective approach to document retrieval via utilizing id138 and
recognizing phrases. in: proceedings of the 27th annual international acm sigir conference on research and
development in information retrieval, pp. 266   272. acm (2004)

40

hiteshwar kumar azad, akshay deepak

170. liu, x., chen, f., fang, h., wang, m.: exploiting entity relationship for id183 in enterprise search.

information retrieval 17(3), 265   294 (2014)

171. liu, y., li, c., zhang, p., xiong, z.: a id183 algorithm based on phrases semantic similarity. in:

information processing (isip), 2008 international symposiums on, pp. 31   35. ieee (2008)

172. lv, y., zhai, c.: positional language models for information retrieval. in: proceedings of the 32nd international

acm sigir conference on research and development in information retrieval, pp. 299   306. acm (2009)

173. lv, y., zhai, c.: positional relevance model for pseudo-relevance feedback. in: proceedings of the 33rd inter-
national acm sigir conference on research and development in information retrieval, pp. 579   586. acm
(2010)

174. lv, y., zhai, c., chen, w.: a boosting approach to improving pseudo-relevance feedback. in: proceedings
of the 34th international acm sigir conference on research and development in information retrieval, pp.
165   174. acm (2011)

175. magdy, w., jones, g.j.: a study on id183 methods for patent retrieval. in: proceedings of the 4th

workshop on patent information retrieval, pp. 19   24. acm (2011)

176. mahdabi, p., crestani, f.: the e   ect of citation analysis on id183 for patent retrieval. information

retrieval 17(5-6), 412   429 (2014)

177. manning, c.d., raghavan, p., sch  utze, h.: introduction to information retrieval. cambridge university press,

new york, ny, usa (2008)

178. maron, m.: mechanized documentation: the logic behind a probabilistic. in: statistical association methods
for mechanized documentation: symposium proceedings, vol. 269, p. 9. us government printing o   ce (1965)
179. maron, m.e., kuhns, j.l.: on relevance, probabilistic indexing and information retrieval. journal of the acm

(jacm) 7(3), 216   244 (1960)

180. mcbryan, o.a.: genvl and wwww: tools for taming the web. in: proceedings of the    rst international world

wide web conference, vol. 341. geneva (1994)

181. mcnamee, p., may   eld, j.: comparing cross-language id183 techniques by degrading translation re-
sources. in: proceedings of the 25th annual international acm sigir conference on research and development
in information retrieval, pp. 159   166. acm (2002)

182. metzler, d., croft, w.b.: latent concept expansion using markov random    elds. in: proceedings of the 30th
annual international acm sigir conference on research and development in information retrieval, pp. 311   
318. acm (2007)

183. miao, j., huang, j.x., ye, z.: proximity-based rocchio   s model for pseudo relevance. in: proceedings of the
35th international acm sigir conference on research and development in information retrieval, pp. 535   544.
acm (2012)

184. mikolov, t., chen, k., corrado, g., dean, j.: e   cient estimation of word representations in vector space.

arxiv preprint arxiv:1301.3781 (2013)

185. mikroyannidis, a.: toward a social semantic web. computer 40(11), 113   115 (2007)
186. miller, g.a., beckwith, r., fellbaum, c., gross, d., miller, k.j.: introduction to id138: an on-line lexical

database. international journal of id69 3(4), 235   244 (1990)

187. milne, d., witten, i.h.: learning to link with wikipedia.

in: proceedings of the 17th acm conference on

information and knowledge management, pp. 509   518. acm (2008)

188. minker, j., wilson, g.a., zimmerman, b.h.: an evaluation of id183 by the addition of clustered

terms for a document retrieval system. information storage and retrieval 8(6), 329   348 (1972)

189. moldovan, d.i., mihalcea, r.: using id138 and lexical operators to improve internet searches. ieee internet

computing 4(1), 34 (2000)

190. molino, p., aiello, l.m., lops, p.: social id53: textual, user, and network features for best

answer prediction. acm transactions on information systems (tois) 35(1), 4 (2016)

191. montague, m., aslam, j.a.: relevance score id172 for metasearch.

in: proceedings of the tenth

international conference on information and knowledge management, pp. 427   433. acm (2001)

192. moreau, f., claveau, v., s  ebillot, p.: automatic morphological id183 using analogy-based machine

learning. in: european conference on information retrieval, pp. 222   233. springer (2007)

193. mulhem, p., amer, n.o., g  ery, m.: axiomatic term-based personalized id183 using bookmarking

system, pp. 235   243. springer international publishing, cham (2016)

194. natsev, a.p., haubold, a., te  si  c, j., xie, l., yan, r.: semantic concept-based id183 and re-ranking
for multimedia retrieval. in: proceedings of the 15th acm international conference on multimedia, pp. 991   
1000. acm (2007)

195. navigli, r.: id51: a survey. acm computing surveys (csur) 41(2), 10 (2009)
196. navigli, r., velardi, p.: structural semantic interconnections: a knowledge-based approach to word sense dis-

ambiguation. ieee transactions on pattern analysis and machine intelligence 27(7), 1075   1086 (2005)

197. nawab, r.m.a., stevenson, m., clough, p.: an ir-based approach utilising id183 for plagiarism

detection in medline (2016)

198. nie, j.y., simard, m., isabelle, p., durand, r.: cross-language information retrieval based on parallel texts
and automatic mining of parallel texts from the web. in: proceedings of the 22nd annual international acm
sigir conference on research and development in information retrieval, pp. 74   81. acm (1999)

199. nie, l., jiang, h., ren, z., sun, z., li, x.: id183 based on crowd knowledge for code search. ieee

transactions on services computing 9(5), 771   783 (2016)

200. paice, c.d.: an evaluation method for id30 algorithms. in: proceedings of the 17th annual international
acm sigir conference on research and development in information retrieval, pp. 42   50. springer-verlag new
york, inc. (1994)

201. paik, j.h., pal, d., parui, s.k.: incremental blind feedback: an e   ective approach to automatic query expan-

sion. acm transactions on asian language information processing (talip) 13(3), 13 (2014)

202. pakhomov, s.v., finley, g., mcewan, r., wang, y., melton, g.b.: corpus domain e   ects on distributional

semantic modeling of medical terms. bioinformatics 32(23), 3635   3644 (2016)

id183 techniques for information retrieval: a survey

41

203. pal, a.r., saha, d.: id51: a survey. arxiv preprint arxiv:1508.01346 (2015)
204. pal, d., mitra, m., bhattacharya, s.: exploring query categorisation for id183: a study. arxiv

preprint arxiv:1509.05567 (2015)

205. pal, d., mitra, m., datta, k.: id183 using term distribution and term association. arxiv preprint

arxiv:1303.0667 (2013)

206. pal, d., mitra, m., datta, k.: improving id183 using id138. journal of the association for

information science and technology 65(12), 2469   2478 (2014)

207. pane, j.f., myers, b.a.: improving user performance on boolean queries. in: chi   00 extended abstracts on

human factors in computing systems, pp. 269   270. acm (2000)

208. panovich, k., miller, r., karger, d.: tie strength in question & answer on social network sites. in: proceedings

of the acm 2012 conference on computer supported cooperative work, pp. 1057   1066. acm (2012)

209. peat, h.j., willett, p.: the limitations of term co-occurrence data for id183 in document retrieval

systems. journal of the american society for information science 42(5), 378 (1991)

210. pirkola, a., hedlund, t., keskustalo, h., j  arvelin, k.: dictionary-based cross-language information retrieval:

problems, methods, and research    ndings. information retrieval 4(3-4), 209   230 (2001)

211. porter, m.f.: an algorithm for su   x stripping. program 14(3), 130   137 (1980)
212. porter, m.f.: implementing a probabilistic information retrieval system. information technology: research

and development 1(2), 131   156 (1982)

213. pound, j., ilyas, i.f., weddell, g.: expressive and    exible access to web-extracted data: a keyword-based struc-
tured query language. in: proceedings of the 2010 acm sigmod international conference on management
of data, pp. 423   434. acm (2010)

214. qiu, y., frei, h.p.: concept based id183. in: proceedings of the 16th annual international acm

sigir conference on research and development in information retrieval, pp. 160   169. acm (1993)

215. radwan, k.: vers l   acces multilingue en langage naturel aux bases de donnees textuelles. ph.d. thesis (1994)
216. resnik, p.: using information content to evaluate semantic similarity in a taxonomy. arxiv preprint cmp-

lg/9511007 (1995)

217. riezler, s., liu, y., vasserman, a.: translating queries into snippets for improved id183. in: proceed-
ings of the 22nd international conference on computational linguistics-volume 1, pp. 737   744. association
for computational linguistics (2008)

218. riezler, s., vasserman, a., tsochantaridis, i., mittal, v., liu, y.: id151 for query
expansion in answer retrieval. in: annual meeting-association for computational linguistics, vol. 45, p. 464
(2007)

219. van rijsbergen, c.j.: a theoretical basis for the use of co-occurrence data in information retrieval. journal of

documentation 33(2), 106   119 (1977)

220. rijsbergen, c.j.v.: information retrieval, 2nd edn. butterworth-heinemann, newton, ma, usa (1979)
221. rivas, a.r., iglesias, e.l., borrajo, l.: study of id183 techniques and their application in the

biomedical information retrieval. the scienti   c world journal 2014 (2014)

222. robertson, a.m., willett, p.: a comparison of spelling-correction methods for the identi   cation of word forms

in historical text databases. literary and linguistic computing 8(3), 143   152 (1993)

223. robertson, s.: understanding inverse document frequency: on theoretical arguments for idf. journal of docu-

mentation 60(5), 503   520 (2004)

224. robertson, s.e.: on term selection for id183. journal of documentation 46(4), 359   364 (1990)
225. robertson, s.e., jones, k.s.: relevance weighting of search terms. journal of the american society for

information science 27(3), 129   146 (1976)

226. robertson, s.e., walker, s.: some simple e   ective approximations to the 2-poisson model for probabilistic
weighted retrieval. in: proceedings of the 17th annual international acm sigir conference on research and
development in information retrieval, pp. 232   241. springer-verlag new york, inc. (1994)

227. robertson, s.e., walker, s.: microsoft cambridge at trec-9: filtering track. in: trec (2000)
228. robertson, s.e., walker, s., beaulieu, m., willett, p.: okapi at trec-7: automatic ad hoc,    ltering, vlc and

interactive track. nist special publication sp (500), 253   264 (1999)

229. rocchio, j.j.: relevance feedback in information retrieval (1971)
230. roy, d., paul, d., mitra, m., garain, u.: using id27s for automatic id183. arxiv

preprint arxiv:1606.07608 (2016)

231. ruthven, i., lalmas, m.: a survey on the use of relevance feedback for information access systems. the

knowledge engineering review 18(2), 95   145 (2003)

232. salton, g.: automatic text processing: the transformation, analysis, and retrieval of. reading: addison-wesley

(1989)

233. salton, g.: developments in automatic text retrieval. science 253(5023), 974   980 (1991)
234. salton, g., buckley, c.: term-weighting approaches in automatic text retrieval.

information processing &

management 24(5), 513   523 (1988)

235. salton, g., buckley, c.: improving retrieval performance by relevance feedback. journal of the american

society for information science 41, 288   297 (1990)

236. salton, g., buckley, c.: improving retrieval performance by relevance feedback. readings in information

retrieval 24(5), 355   363 (1997)

237. savoy, j.: comparative study of monolingual and multilingual search models for use with asian languages.

acm transactions on asian language information processing (talip) 4(2), 163   189 (2005)

238. shah, c., croft, w.b.: evaluating high accuracy retrieval techniques.

in: proceedings of the 27th annual
international acm sigir conference on research and development in information retrieval, pp. 2   9. acm
(2004)

239. shekarpour, s., h  o   ner, k., lehmann, j., auer, s.: keyword id183 on linked data using linguistic
and semantic features. in: semantic computing (icsc), 2013 ieee seventh international conference on, pp.
191   197. ieee (2013)

42

hiteshwar kumar azad, akshay deepak

240. sheridan, p., ballerini, j.p.: experiments in multilingual information retrieval using the spider system. in: pro-
ceedings of the 19th annual international acm sigir conference on research and development in information
retrieval, pp. 58   65. acm (1996)

241. sihvonen, a., vakkari, p.: subject knowledge improves interactive id183 assisted by a thesaurus.

journal of documentation 60(6), 673   690 (2004)

242. singh, j., prasad, m., prasad, o.k., joo, e.m., saxena, a.k., lin, c.t.: a novel fuzzy logic model for pseudo-

relevance feedback-based id183. international journal of fuzzy systems 18(6), 980   989 (2016)

243. singh, j., sharan, a.: a new fuzzy logic-based id183 model for e   cient information retrieval using

relevance feedback approach. neural computing and applications pp. 1   24 (2016)

244. singhal, a., pereira, f.: document expansion for speech retrieval.

in: proceedings of the 22nd annual in-
ternational acm sigir conference on research and development in information retrieval, pp. 34   41. acm
(1999)

245. smeaton, a.f., kelledy, f., o   donnell, r.: trec-4 experiments at dublin city university: thresholding posting

lists, id183 with id138 and id52 of spanish. harman [6] pp. 373   389 (1995)

246. song, m., song, i.y., hu, x., allen, r.b.: integration of association rules and ontologies for semantic query

expansion. data & knowledge engineering 63(1), 63   75 (2007)

247. song, r., yu, l., wen, j.r., hon, h.w.: a proximity probabilistic model for information retrieval. tech. rep.,

tech. rep., microsoft research (2011)

248. soricut, r., brill, e.: automatic id53 using the web: beyond the factoid. information retrieval

9(2), 191   206 (2006)

249. spink, a., wolfram, d., jansen, m.b., saracevic, t.: searching the web: the public and their queries. journal

of the american society for information science and technology 52(3), 226   234 (2001)

250. sriram, b., fuhry, d., demir, e., ferhatosmanoglu, h., demirbas, m.: short text classi   cation in twitter to
improve information    ltering. in: proceedings of the 33rd international acm sigir conference on research
and development in information retrieval, pp. 841   842. acm (2010)

251. stokoe, c., oakes, m.p., tait, j.: id51 in information retrieval revisited. in: proceedings
of the 26th annual international acm sigir conference on research and development in informaion retrieval,
pp. 159   166. acm (2003)

252. sun, r., ong, c.h., chua, t.s.: mining dependency relations for id183 in passage retrieval. in: pro-
ceedings of the 29th annual international acm sigir conference on research and development in information
retrieval, pp. 382   389. acm (2006)

253. tejedor, j., fap  so, m., sz  oke, i.,   cernock`y, j., gr  ezl, f., et al.: comparison of methods for language-dependent
and language-independent query-by-example spoken term detection. acm transactions on information sys-
tems (tois) 30(3), 18 (2012)

254. tellex, s., kollar, t., shaw, g., roy, n., roy, d.: grounding spatial language for video search. in: international
conference on multimodal interfaces and the workshop on machine learning for multimodal interaction, p. 31.
acm (2010)

255. thomas, s.s., gupta, s., venkatesh, k.: perceptual synoptic view-based video retrieval using metadata. signal,

image and video processing pp. 1   7 (2016)

256. turtle, h.: natural language vs. boolean query evaluation: a comparison of retrieval performance. in: pro-
ceedings of the 17th annual international acm sigir conference on research and development in information
retrieval, pp. 212   220. springer-verlag new york, inc. (1994)

257. unger, c., ngomo, a.c.n., cabrio, e.: 6th open challenge on id53 over linked data (qald-6).

in: semantic web evaluation challenge, pp. 171   177. springer (2016)

258. vaidya, j., clifton, c.: privacy preserving association rule mining in vertically partitioned data. in: proceedings
of the eighth acm sigkdd international conference on knowledge discovery and data mining, pp. 639   644.
acm (2002)

259. van rijsbergen, c.j.: a non-classical logic for information retrieval. the computer journal 29(6), 481   485

(1986)

260. voorhees, e.m.: id183 using lexical-semantic relations. in: sigir94, pp. 61   69. springer (1994)
261. wang, f., lin, l.: domain lexicon-based id183 for patent retrieval. in: natural computation, fuzzy
systems and knowledge discovery (icnc-fskd), 2016 12th international conference on, pp. 1543   1547. ieee
(2016)

262. wang, p., xu, b., xu, j., tian, g., liu, c.l., hao, h.: semantic expansion using id27 id91
and convolutional neural network for improving short text classi   cation. neurocomputing 174, 806   814 (2016)
263. wang, x., zhai, c.: learn from web search logs to organize search results. in: proceedings of the 30th annual
international acm sigir conference on research and development in information retrieval, pp. 87   94. acm
(2007)

264. wang, x., zhai, c.: mining term association patterns from search logs for e   ective query reformulation. in:
proceedings of the 17th acm conference on information and knowledge management, pp. 479   488. acm
(2008)

265. wei, x., croft, w.b.: modeling term associations for ad-hoc retrieval performance within id38

framework. in: european conference on information retrieval, pp. 52   63. springer (2007)

266. wen, j.r., nie, j.y., zhang, h.j.: query id91 using user logs. acm transactions on information systems

20(1), 59   81 (2002)

267. white, r.w., ruthven, i., jose, j.m.: a study of factors a   ecting the utility of implicit relevance feedback.
in: proceedings of the 28th annual international acm sigir conference on research and development in
information retrieval, pp. 35   42. acm (2005)

268. willett, p.: recent trends in hierarchic document id91: a critical review.

information processing &

management 24(5), 577   597 (1988)

269. wong, w., luk, r.w.p., leong, h.v., ho, k., lee, d.l.: re-examining the e   ects of adding relevance infor-
mation in a relevance feedback environment. information processing & management 44(3), 1086   1116 (2008)

id183 techniques for information retrieval: a survey

43

270. wu, h., fang, h.: an incremental approach to e   cient pseudo-relevance feedback.

in: proceedings of the
36th international acm sigir conference on research and development in information retrieval, pp. 553   562.
acm (2013)

271. wu, h., wu, w., zhou, m., chen, e., duan, l., shum, h.y.: improving search relevance for short queries in
community id53. in: proceedings of the 7th acm international conference on web search and
data mining, wsdm    14, pp. 43   52. acm, new york, ny, usa (2014)

272. wu, j., ilyas, i., weddell, g.: a study of ontology-based id183. technical report cs-2011   04 (2011)
273. wu, y., liu, x., xie, m., ester, m., yang, q.: cccf: improving collaborative    ltering via scalable user-item
co-id91. in: proceedings of the ninth acm international conference on web search and data mining,
pp. 73   82. acm (2016)

274. wu, z., palmer, m.: verbs semantics and lexical selection. in: proceedings of the 32nd annual meeting on

association for computational linguistics, pp. 133   138. association for computational linguistics (1994)

275. xie, h., zhang, y., tan, j., guo, l., li, j.: contextual id183 for id162. ieee transactions

on multimedia 16(4), 1104   1114 (2014)

276. xiong, c., callan, j.: id183 with freebase. in: proceedings of the 2015 international conference on

the theory of information retrieval, pp. 111   120. acm (2015)

277. xu, j., croft, w.b.: id183 using local and global document analysis. in: proceedings of the 19th
annual international acm sigir conference on research and development in information retrieval, pp. 4   11.
acm (1996)

278. xu, j., croft, w.b.: improving the e   ectiveness of information retrieval with local context analysis. acm

transactions on information systems (tois) 18(1), 79   112 (2000)

279. xu, y., jones, g.j., wang, b.: query dependent pseudo-relevance feedback based on wikipedia. in: proceedings
of the 32nd international acm sigir conference on research and development in information retrieval, pp.
59   66. acm (2009)

280. xue, g.r., zeng, h.j., chen, z., yu, y., ma, w.y., xi, w., fan, w.: optimizing web search using web click-
through data. in: proceedings of the thirteenth acm international conference on information and knowledge
management, pp. 118   126. acm (2004)

281. yao, y., yi, j., liu, y., zhao, x., sun, c.: query processing based on associated semantic context id136. in:
information science and control engineering (icisce), 2015 2nd international conference on, pp. 395   399.
ieee (2015)

282. yin, z., shokouhi, m., craswell, n.: id183 using external evidence. in: european conference on

information retrieval, pp. 362   374. springer (2009)

283. yu, c.t., buckley, c., lam, k., salton, g.: a generalized term dependence model in information retrieval.

tech. rep., cornell university (1983)

284. yu, k., tresp, v., yu, s.: a nonparametric hierarchical bayesian framework for information    ltering. in: pro-
ceedings of the 27th annual international acm sigir conference on research and development in information
retrieval, pp. 353   360. acm (2004)

285. zervakis, l., tryfonopoulos, c., skiadopoulos, s., koubarakis, m.: query reorganisation algorithms for e   cient

boolean information    ltering. ieee transactions on knowledge and data engineering (2016)

286. zhai, c., la   erty, j.: model-based feedback in the id38 approach to information retrieval. in:
proceedings of the tenth international conference on information and knowledge management, pp. 403   410.
acm (2001)

287. zhang, c.j., zeng, a.: behavior patterns of online users and the e   ect on information    ltering. physica a:

statistical mechanics and its applications 391(4), 1822   1830 (2012)

288. zhang, j., deng, b., li, x.: concept based id183 using id138.

in: proceedings of the 2009

international e-conference on advanced science and technology, pp. 52   55. ieee computer society (2009)

289. zhang, y., clark, s.: syntactic processing using the generalized id88 and id125. computational

linguistics 37(1), 105   151 (2011)

290. zhang, z., wang, q., si, l., gao, j.: learning for e   cient supervised id183 via two-stage feature
selection. in: proceedings of the 39th international acm sigir conference on research and development in
information retrieval, pp. 265   274. acm (2016)

291. zhong, z., ng, h.t.: id51 improves information retrieval. in: proceedings of the 50th
annual meeting of the association for computational linguistics: long papers-volume 1, pp. 273   282. asso-
ciation for computational linguistics (2012)

292. zhou, d., lawless, s., liu, j., zhang, s., xu, y.: id183 for personalized cross-language information
retrieval. in: semantic and social media adaptation and personalization (smap), 2015 10th international
workshop on, pp. 1   5. ieee (2015)

293. zhou, d., lawless, s., wade, v.: improving search via personalized id183 using social media. infor-

mation retrieval 15(3-4), 218   242 (2012)

294. zhou, d., lawless, s., wu, x., zhao, w., liu, j., lewandowski, d.: a study of user pro   le representation for

personalized cross-language information retrieval. aslib journal of information management 68(4) (2016)

295. zhou, d., wu, x., zhao, w., lawless, s., liu, j.: id183 with enriched user pro   les for personalized

search utilizing folksonomy data. ieee transactions on knowledge and data engineering (2017)

296. zimmer, c., tryfonopoulos, c., weikum, g.: exploiting correlated keywords to improve approximate infor-
mation    ltering. in: proceedings of the 31st annual international acm sigir conference on research and
development in information retrieval, pp. 323   330. acm (2008)

297. zingla, m.a., chiraz, l., slimani, y.: short id183 for microblog retrieval. procedia computer

science 96, 225   234 (2016)

