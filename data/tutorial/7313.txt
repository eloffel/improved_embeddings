a survey of automatic id183 in information retrieval

claudio carpineto and giovanni romano, fondazione ugo bordoni

1

the relative ineffectiveness of information retrieval systems is largely caused by the inaccuracy with which
a query formed by a few keywords models the actual user information need. one well known method to over-
come this limitation is automatic id183 (aqe), whereby the user   s original query is augmented by
new features with a similar meaning. aqe has a long history in the information retrieval community but it
is only in the last years that it has reached a level of scienti   c and experimental maturity, especially in labo-
ratory settings such as trec. this survey presents a uni   ed view of a large number of recent approaches to
aqe that leverage various data sources and employ very different principles and techniques. the following
questions are addressed. why is id183 so important to improve search effectiveness? what are
the main steps involved in the design and implementation of an aqe component? what approaches to aqe
are available and how do they compare? which issues must still be resolved before aqe becomes a standard
component of large operational information retrieval systems (e.g., search engines)?
categories and subject descriptors: h.3.3 [information storage and retrieval]: information search
and retrieval   query formulation; h.3.1 [information storage and retrieval]: content analysis and
indexing
general terms: algorithms, experimentation, measurement, performance

additional key words and phrases: id183, query re   nement, search, word associations,
pseudo-relevance feedback, document ranking
acm reference format:
carpineto, c. and romano, g. 2012. a survey of automatic id183 in information retrieval. acm
comput. surv. 44, 1, article 1 (january 2012), 50 pages.
doi = 10.1145/2071389.2071390 http://doi.acm.org/10.1145/2071389.2071390

1. introduction
current information retrieval systems, including web search engines, have a stan-
dard interface consisting of a single input box that accepts keywords. the keywords
submitted by the user are matched against the collection index to    nd the documents
that contain those keywords, which are then sorted by various methods. when a user
query contains multiple topic-speci   c keywords that accurately describe his informa-
tion need, the system is likely to return good matches; however, given that user queries
are usually short and that the natural language is inherently ambiguous, this simple
retrieval model is in general prone to errors and omissions.

the most critical language issue for retrieval effectiveness is the term mismatch
problem: the indexers and the users do often not use the same words. this is known
as the vocabulary problem furnas et al. [1987], compounded by synonymy (same word
with different meanings, such as    java   ) and polysemy (different words with the same

authors    address: c. carpineto and g. romano, fondazione ugo bordoni, via baldassarre castiglione 59,
00142, rome, italy; email: carpinet@fub.it.
permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for pro   t or commercial advantage and that
copies show this notice on the    rst page or initial screen of a display along with the full citation. copyrights
for components of this work owned by others than acm must be honored. abstracting with credit is permit-
ted. to copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of
this work in other works requires prior speci   c permission and/or a fee. permissions may be requested from
the publications dept., acm, inc., 2 penn plaza, suite 701, new york, ny 10121-0701, usa, fax +1 (212)
869-0481, or permissions@acm.org.
c(cid:2) 2012 acm 0360-0300/2012/01-art1 $10.00
doi 10.1145/2071389.2071390 http://doi.acm.org/10.1145/2071389.2071390

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:2

c. carpineto and g. romano

or similar meanings, such as    tv    and    television   ). synonymy, together with word in-
   ections (such as with plural forms,    television    versus    televisions   ), may result in a
failure to retrieve relevant documents, with a decrease in recall (the ability of the sys-
tem to retrieve all relevant documents). polysemy may cause retrieval of erroneous or
irrelevant documents, thus implying a decrease in precision (the ability of the system
to retrieve only relevant documents).

to deal with the vocabulary problem, several approaches have been proposed in-
cluding interactive query re   nement, relevance feedback, id51,
and search results id91. one of the most natural and successful techniques
is to expand the original query with other words that best capture the actual user
intent, or that simply produce a more useful query   a query that is more likely to
retrieve relevant documents. automatic id183 (aqe) has a long history in
information retrieval (ir), as it has been suggested as early as 1960 by maron and
kuhns [1960]. early work investigated a range of seminal techniques that have been
subsequently improved and extended in various ways, for example, vector feedback
[ide 1971; rocchio 1971], term-term id91 [harper and van rijsbergen 1978; lesk
1969; minker et al. 1972], and comparative analysis of term distributions [doszkocs
1978; porter 1982]. on the other hand, in a number of early experiments performed on
small scale collections inconclusive results were achieved about the retrieval effective-
ness of such techniques, with gain in recall often compensated by the corresponding
loss in precision (see salton and buckley [1990] and harman [1992] for a review).

as the volume of data has dramatically increased while the number of searcher-
supplied query terms has remained very low, research on aqe has been revamped.
web search is the best case in point. according to hitwise1, in 2009 the average query
length was 2.30 words, the same as that reported ten years before in lau and horvitz
[1999]. while there has been a slight increase in the number of long queries (of    ve or
more words), the most prevalent queries are still those of one, two, and three words.
in this situation, the vocabulary problem has become even more serious because the
paucity of query terms reduces the possibility of handling synonymy while the hetero-
geneity and size of data make the effects of polysemy more severe. the need for and
the scope of aqe have thus increased.

in the last years, a huge number of aqe techniques have been presented using a
variety of approaches that leverage on several data sources and employ sophisticated
methods for    nding new features correlated with the query terms. today, there are
   rmer theoretical foundations and a better understanding of the utility and limitations
of aqe; e.g., which are the critical parameters affecting the method performance, what
type of queries is aqe useful for, and so on. at the same time, the basic techniques
are being increasingly used in conjunction with other mechanisms to increase their
effectiveness, including method combination, more active selection of information
sources, and discriminative policies of method application. these scienti   c advances
have been corroborated by very positive experimental    ndings obtained in laboratory
settings. in fact, aqe has regained much popularity thanks to the evaluation results
obtained at the text retrieval conference series (trec)2, where most participants
have made use of this technique, reporting noticeable improvements in retrieval
performance.

aqe is currently considered an extremely promising technique to improve the re-
trieval effectiveness of document ranking and there are signs that it is being adopted

1http://www.hitwise.com/us/press-center/press-releases/2009/google-searches-oct-09/
2http://trec.nist.gov/

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:3

in commercial applications, especially for desktop and intranet searches. for instance,
google enterprise, mysql, and lucene provide the user with an aqe facility that can
be turned on or off. in contrast, it has not yet been regularly employed in the major
operational web ir systems such as search engines.

there are several explanations for the limited uptake of aqe in web search. first,
the fast response times required by web search applications may prevent the use of
some computationally expensive aqe techniques. second, current aqe techniques
are optimized to perform well on average, but are unstable and may cause degrada-
tion of search service for some queries. also, the emphasis of aqe on improving recall
(as opposed to guaranteeing high precision) is less important, given that there is usu-
ally an abundance of relevant documents and that many users look only at the    rst
page of results. third, there is probably an issue with the acceptance of aqe, due to
the limited usability and transparency of an ir system implementing aqe: the user
may get confused if the system retrieves documents that do not contain the original
query terms. on the other hand, these features are less important in many other ir
applications (e.g., search by experts in specialized domains), where a straightforward
application of aqe may have no major contraindications. one of the objectives of this
survey is to critically assess the performance limitations of this technique and discuss
what we need to push it forward.

although aqe has received a great deal of attention in the recent literature on ir
and search, very little work has been done to review such studies. one notable excep-
tion is bhogal et al. [2007], which however reviews a speci   c approach to aqe: using
ontologies. aqe has also been covered in the books baeza-yates and ribeiro-neto
[1999] and manning et al. [2008], with a focus on early techniques for    nding term
correlations, and has a dedicated entry in the encyclopedia of database systems vech-
tomova [2009]. this article is the    rst comprehensive study of aqe that deals with
all processing steps, reviews the major techniques including the recent ones, discusses
their retrieval performance, identi   es open issues, and suggests research directions.

after discussing how aqe can improve not only recall but also precision, we de-
scribe the main computational steps involved, from data acquisition and preprocess-
ing, to candidate feature generation and ranking, to feature selection, and    nally to
query reformulation. this modelization accounts for a large number of proposed ap-
proaches, with each approach usually    tting in one or more sections of the full process-
ing pipeline. besides summarizing current practice, it can be used as a blueprint for
designing and implementing an aqe component for a ranking system. we also provide
a classi   cation of existing techniques that is more oriented towards methodological as-
pects; e.g., the source of data, the feature extraction method, and the representation of
the expanded query. the latter characterization is more useful for system comparison.
the remainder of the article has the following organization. we    rst provide a prag-
matic de   nition of aqe (section 2), discuss why and under which assumptions it pro-
duces more accurate results than using unexpanded queries (section 3), and brie   y re-
view other applications of aqe in addition to document ranking (section 4) and differ-
ent approaches to the vocabulary problem (section 5). then, in section 6, we describe
how aqe works, identifying the main computational steps in which the whole process
can be broken down. section 7 is devoted to a classi   cation of existing approaches: we
provide a broad taxonomy by data source and by expansion feature-   nding method as
well as a detailed features chart using a set of more speci   c criteria. we next address
the performance issue. section 8 deals with the retrieval effectiveness of expanded
queries and section 9 discusses the computational ef   ciency of performing aqe. in
section 10 we discuss a few critical issues that must still be solved for moving aqe be-
yond its experimental status. section 11 reviews some research directions, and    nally,
section 12 offers some conclusions.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:4

c. carpineto and g. romano

2. document ranking with aqe
most ir systems including search engines rely, totally or in part, on computing the
importance of terms that occur in the query and in the documents to determine their
answers. the similarity sim(q, d) between query q and document d can be usually
expressed as

sim(q, d) =

wt,q    wt,d,

(1)

(cid:2)
t   q   d

where wt,q and wt,d are the weights of term t in query q and document d, respectively,
according to the system   s weighting function. the weight of a term is typically propor-
tional to the term frequency and inversely proportional to the frequency and length
of the documents containing the term. this broad formulation accounts for several
widely used ranking models that which can be directly or indirectly traced back to it,
including vector space model [salton and mcgill 1983], probabilistic relevance model
[robertson et al. 1998], statistical id38 [zhai and lafferty 2001b], and
deviation from randomness [amati et al. 2001].

the ranking scheme of formula 1 can be easily modi   ed to accommodate query ex-
pansion, abstracting away from the speci   c underlying weighting model. the basic
input to aqe consists of the original query q and a source of data from which to com-
pute and weight the expansion terms. the output of aqe is a query q(cid:4) formed by an
expanded set of terms with their associated weights w(cid:4). the new weighted query terms
are used to compute the similarity between query q(cid:4) and document d

(cid:4)
sim(q

, d) =

w

(cid:4)
(cid:4)
t,q

   wt,d.

(2)

(cid:2)
(cid:4)   d
t   q

the most typical data source for generating new terms is the collection itself being
searched and the simplest way of weighting the id183 terms is to use just
the weighting function used by the ranking system. if more complex features than sin-
gle terms are used for id183 (e.g., phrases), the underlying ranking system
must be able to handle such features.

3. why and when aqe works
in most document ranking systems the query terms are connected by an implicit or.
under this assumption, one advantage of id183 is that there is more chance
for a relevant document that does not contain the original query terms to be retrieved,
with an obvious increase in recall. for instance, if the query al-qaeda is expanded
to al-qaeda al-qaida al-qa   ida    osama bin laden       terrorist sunni organization   
   september 11 2001,    this new query does not only retrieve the documents that con-
tain the original term (al-qaeda) but also the documents that use different spellings
or don   t directly name it. this observation has originated most early research in aqe,
and such a capacity is still very important for search applications in professional do-
mains (e.g., legal,    nancial, medical, scienti   c) where the main goal is to retrieve all
documents that are relevant to an issue. notice that a strict recall improvement can be
achieved even when the query terms are strictly anded together by default, as with
some web search engines, provided that the expanded query can be submitted to the
system by using boolean operators (e.g., and of ors).

the additional terms, however, may cause query drift   the alteration of the focus
of a search topic caused by improper expansion mitra et al. [1998]   thus hurting
precision. there may be several reasons for this. when an expansion term is

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:5

correlated with a single term of the original query rather than with the entire query
it may easily match unrelated concepts. this phenomenon may be more serious if the
additional term is a proper noun, as pointed out in vechtomova and karamuftuoglu
[2004]. it is also possible that the set of candidate expansion terms as a whole is not
relevant to the original query. this may happen, for instance, when aqe is based on
the top documents retrieved in response to the original query and such documents are
mostly not relevant. a further reason for a decrease in precision is that the relevant
documents that match just the original query terms may move lower down in the
ranking after id183, even if the additional terms are relevant to the query
concept. for example, if the query    jennifer aniston    is expanded with    actress,   
   movie,    and    player,    a document about a different actress in which such additional
terms are well represented may be assigned a higher score than a document about
jennifer aniston that does not contain the additional terms [carmel et al. 2002]. that
id183 may result in a loss of precision has been con   rmed in some earlier
experimental studies (e.g., voorhees and harman [1998]).

on the other hand, the effectiveness of ir systems is usually evaluated taking into
account both recall and precision. using a combined recall/precision measure, the
overwhelming majority of recent experimental studies agree that aqe results in better
retrieval effectiveness, with improvements of the order of 10% and larger (e.g., mitra
et al. [1998], carpineto et al. [2002], liu et al. [2004], lee et al. [2008]). such    ndings
are important to support the claim that aqe is an effective technique, but this may be
not suf   cient for the cases when we are primarily interested in precision. however, as
explained in the following, several recent studies have pointed out that aqe does not
necessarily hurt precision.

one common problem affecting the precision of document ranking is that retrieved
documents can often match a query term out of context with its relationships to the
other terms. there may be several types of out-of-context matches causing false drops.
in bodoff and kambil [1998], for instance,    ve types were identi   ed: polysemy, ordered
relationships among terms (e.g.,    wars due to crises    versus    crises due to wars   ), out
of phrase terms (when a query or document phrase is not treated as a single unit),
secondary topic keyword (e.g.,    siamese cats    versus    cats   ), and noncategorical terms
(e.g.,    tiger    is simultaneously an instance of    mammal    and of    operating system   ).

the problem of improper partial matching between query and document can be ame-
liorated by using aqe, to the extent that the additional terms favor a more univocal
interpretation of the original query. for example, if the query    tiger, operating system   
is expanded with    mac os x,    the score of the documents about the computer meaning
of    tiger    will increase while the score of the documents about different meanings of
   tiger    or different operating systems will decrease. this is an example of out-of-phrase
term-matching. a similar argument can be applied to the other types of out-of-context
matches. indeed, some recent studies have con   rmed that aqe may also improve pre-
cision by implicitly disambiguating query terms (e.g., bai et al. [2005], carmel et al.
[2002], navigli and velardi [2003]). in section 6.2.3 we give an example of this be-
havior in a situation of practical interest, while the use of id51
techniques in ir is discussed in section 5.3.

sometimes, aqe achieves better precision in the sense that it has the effect of mov-
ing the results toward the most popular or representative meaning of the query in the
collection at hand and away from other meanings; e.g., when the features used for aqe
are extracted from web pages [cui et al. 2003], or when the general concept terms in
a query are substituted by a set of speci   c concept terms present in the corpus that
co-occur with the query concept [chu et al. 2002]. aqe is also useful for improving
precision when it is required that several aspects (or dimensions) of a query must be
present at once in a relevant document. this is another facet of query disambiguation,

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:6

c. carpineto and g. romano

in which id183 can enhance those aspects that are underrepresented in the
original user query [arguello et al. 2008; crabtree et al. 2007].

we should emphasize that aqe may not be suitable for all user queries, especially
when searching the web. it has been observed broder [2002] that most web queries
fall into one of three basic categories: informational, navigational, or transactional.
the informational queries (in which the user has a particular information need to
satisfy) seem the most relevant to aqe because the user often does not know exactly
what he is looking for and and/or he is not able to clearly describe it in words. by
contrast, in navigational queries (where the user has a particular url to    nd) and
transactional queries (where the user is interested in some web-mediated activity),
usually the sought pages are characterized by very speci   c words that are known to
the user.

4. applications of aqe
although in this survey we mainly focus on the use of id183 for improving
document ranking, there are other retrieval tasks that may bene   t from this tech-
nique. we now brie   y discuss four areas in addition to document ranking, where the
use of aqe has been rather intensive, and then provide pointers to further, more re-
cent, applications.

4.1 id53
the goal of id53 (qa) is to provide concise responses (instead of full doc-
uments) to certain types of natural language questions such as    how many kings were
there in ancient rome?   . similar to document ranking, qa is faced by a fundamental
problem of mismatch between question and answer vocabularies.

to improve the early document retrieval stage of a qa system, one common strat-
egy is to expand the original question with terms that are expected to appear in docu-
ments containing answers to it, often extracted from faq data [agichtein et al. 2004;
harabagiu and lacatusu 2004]. a recent example in this research line is riezler et al.
[2007], in which the faq data are processed by id151 tech-
niques, as if questions and answers in the corpus were two distinct languages. in this
case, the goal of question-answer translation is to learn associations between question
words and synonymous answer words. different approaches to aqe for qa include
using lexical ontologies such as id138 [harabagiu et al. 2001], shared dependency
parse trees between the query and the candidate answers [sun et al. 2006], and se-
mantic parsing of questions based on roles [schlaefer et al. 2007], among others.

in the multilingual id53 track run at the cross language evalua-
tion forum (clef)3, 2009, three variants of the classical qa task were explored: geo-
graphical qa, qa in speech transcripts, and passage retrieval from legal texts. some
authors made use of aqe techniques based on lexical or geographical ontologies, with
good [agirre et al. 2009] or mixed [flemmings et al. 2009] results.

4.2 multimedia information retrieval
with the proliferation of digital media and libraries, search of multimedia documents
(e.g., speech, image, video) has become increasingly important. most multimedia ir
systems perform text-based search over media metadata such as annotations, cap-
tions, and surrounding html/xml descriptions. when the metadata is absent, ir relies
on some form of multimedia content analysis, often combined with aqe techniques.

3www.clefcampaign.org

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:7

for example, in spoken document retrieval, the transcription produced by an auto-
matic id103 system can be augmented with related terms prior to query
time [singhal and pereira 1999]. this form of document expansion is very useful for
spoken document retrieval since automatic speech transcriptions often contain mis-
takes, while for plain document retrieval its bene   ts are more limited [billerbeck and
zobel 2005; wei and croft 2007]. in id162, a typical approach consists of
using query examples with visual features such as colors, textures, and shapes, and
iteratively re   ning the visual query through relevance feedback kher    et al. [2004].
in video retrieval, both the documents and the queries are usually multimodal, in that
they have textual as well as visual aspects. an expanded text query is typically com-
pared against the textual description of the visual concepts and any matched concepts
are used for visual re   nement. also, aqe can be directly applied to visual examples
represented by low-level feature vectors using relevance or pseudo-relevance feedback
(assuming that the top retrieved images are relevant). a review of existing aqe ap-
proaches to video retrieval is given in natsev et al. [2007]. the authors also present
an interesting method based on identifying global correlations (not related to a spe-
ci   c query) between terms from the speech transcript and visual concepts; such visual
concepts are then used for id183.

4.3 information filtering
information    ltering (if) is the process of monitoring a stream of documents and se-
lecting those that are relevant to the user. the documents arrive continuously and
the user   s information needs evolve over time. some examples of    ltering application
domains are electronic news, blogs, e-commerce, and e-mail (see hanani et al. [2004]
for a review). there are two main approaches, collaborative if (based on the prefer-
ences of like-minded users) and content-based if. the latter technique bears a strong
conceptual similarity to ir because the user pro   le can be modeled as a query and the
data stream as a collection of documents [belkin and croft 1992].

better pro   les (queries) can be learned using relevance feedback techniques [allan
1996], or other forms of id183, such as based on similar users [palleti et al.
2007] or on links and anchor textin wikipedia [arguello et al. 2008]. in zimmer et al.
[2008], keyword correlation is used to improve the recall in approximate if   a scenario
in which the system is responsible for selecting the best information sources to which
a subscription (query) should be submitted.

4.4 cross-language information retrieval
cross-language information retrieval (clir) deals with retrieving documents written
in a language other than the language of the user   s query. there has been an increas-
ing interest in clir in the last years, thanks to the annual evaluation campaigns run
by clef and trec. the traditional approach to clir consists of query translation
followed by monolingual retrieval, where query translation is performed with machine
readable bilingual dictionaries, parallel corpora or machine translation [koehn 2010].
regardless of the type of translation resource used, there are usually limitations due
to insuf   cient coverage, untranslatable terms, and translation ambiguity between
the source and target languages [pirkola et al. 2001]. to combat the errors induced
by translation, one well known technique is to use id183 [ballesteros and
croft 1997]; even when the translation contains no error, the use of semantically
similar terms yields better results than those obtainable by literal translation terms
alone [kraaij et al. 2003]. id183 can be applied before or after translation,
or even at both times; pretranslation yields better results than posttranslation, with
a combination being the most effective [ballesteros and croft 1998; mcnamee and

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:8

c. carpineto and g. romano

may   eld 2002]. a more recent work [cao et al. 2007] integrates both translation
relations and monolingual relations such as term co-occurrence into a unique directed
graph in which query translation is performed as a random walk.

4.5 other applications of aqe
other recent applications of aqe include text categorization [zelikovitz and hirsh
2000; hidalgo et al. 2005], search of hidden web content that is not indexed by
standard search engines [graupmann et al. 2005], query completion on mobile de-
vices [kamvar and baluja 2007], training corpora acquisition [huang et al. 2005], e-
commerce [chen et al. 2004; perugini and ramakrishnan 2006], mobile search [church
and smyth 2007], expert    nding [macdonald and ounis 2007], slot-based document re-
trieval [suryanto et al. 2007], federated search [shokouhi et al. 2009], and paid search
advertising [broder et al. 2009; wang et al. 2009].

5. related techniques
the word mismatch between query and documents is a long-standing issue in the    eld
of ir. in this section, aqe is put in context with respect to alternative strategies to
the vocabulary problem.

5.1 interactive query re   nement
there is a vast related literature on interactive id183 (iqe) and re   nement
(e.g., efthimiadis [1996], baeza-yates and ribeiro-neto [1999]). its main difference
from automatic methods is that the system provides several suggestions for query
(re)formulation, but the decision is made by the user. from a computational point
of view, iqe and aqe share the    rst two computational steps, namely data acquisi-
tion and candidate feature generation, whereas iqe does not address the subsequent
problems of feature selection and query reformulation.

one of the best known systems of this kind is google suggest, which offers real-time
hints to complete a search query as the user types. iqe has the potential for producing
better results than aqe kanaan et al. [2008], but this generally requires expertise on
the part of the user ruthven [2003]. from a usability point of view, iqe gives the
user more control over the query processing, which is a aspect lacking in aqe (see
section 10.3). although in this article we focus on fully automatic methods for single-
query searches, we do include some innovative techniques mainly developed for term
suggestion, which are susceptible to also being used for aqe.

5.2 relevance feedback
relevance feedback takes the results that are initially returned from a given query and
uses information provided by the user about whether or not those results are relevant
to perform a new query. the content of the assessed documents is used to adjust the
weights of terms in the original query and/or to add words to the query. relevance
feedback is often implemented using variants of the rocchio algorithm [rocchio 1971],
discussed in the following, or the f4 probabilistic reweighting formulas [robertson and
sparck jones 1976; robertson 1986; robertson and walker 2000]. relevance feedback
is covered in several books (e.g., harman [1992], baeza-yates and ribeiro-neto [1999],
manning et al. [2008]) and surveys ruthven and lalmas [2003]. a dedicated track
(the relevance feedback track) was run at trec in 2008 and 2009.

relevance feedback essentially reinforces the system   s original decision, by making
the expanded query more similar to the retrieved relevant documents, whereas aqe
tries to form a better match with the user   s underlying intentions. the speci   c data
source from which the expansion features are generated using relevance feedback may

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:9

be more reliable than the sources generally used by aqe, but the user must assess
the relevance of the documents. on the other hand, relevance feedback has directly
inspired one of the most popular aqe techniques, namely pseudo-relevance feedback
(discussed in section 6.2.3), and it has also provided foundational work for modeling
query reformulation in a variety of aqe approaches (see section 6.4).

5.3 id51 in ir
id51 (wsd) is the ability to identify the meaning of words
in context in a computationalmanner [navigli 2009]. wsd is a natural and well
known approach to the vocabulary problem in ir [krovetz and croft 1992; lesk
1988; sanderson 2000]. early work focused on representing words by the text of
their dictionary de   nitions, or by their id138 synsets (discussed in section 6.2.1).4
however, several experiments suggested that a straightforward application of this
technique may not be effective for ir voorhees [1993], at least as long as the selection
of the correct sense de   nition (or synset) is    awed; e.g., if the precision is no greater
than 75%, according to sanderson [1994]. the work on using id138 for aqe has
continued using more sophisticated methods, described below in the paper.

rather than relying on short, prede   ned lists of senses, it may be more convenient
to use a corpus as evidence to perform word sense induction. in sch   utze and pedersen
[1995], the context of every occurrence of a word is found and similar contexts are
clustered to determine the word senses (or word uses). with a correct disambiguation
rate of 90%, this paper was the    rst to show that wsd can work successfully with an ir
system, reporting a 7 to 14% improvement in retrieval effectiveness. given its reliance
on corpus analysis, this approach is similar in spirit, to the global aqe techniques
discussed in section 7.2. another corpus-based wsd technique is described in v  eronis
[2004]. by applying the metaphor of small worlds to word co-occurrence graphs, this
technique is capable of discovering low-frequency senses (as low as 1%).

on the whole, however, the application of wsd to ir presents both computational
and effectiveness limitations. mixed evidence has also been reported in a recent series
of experiments performed at clef 2008 and clef 2009, in the robust   wsd task
[agirre et al. 2009]. furthermore, a typical query context, as in web searches, may be
too short for sense disambiguation.

5.4 search results id91
search results id91 (src) organizes search results by topic, thus allowing, in
principle, direct access to the documents pertaining to distinct aspects of the given
query. in contrast to conventional id91, src algorithms try to optimize not only
the id91 structure, but also the quality of cluster labels, because a cluster with
a poor description is very likely to be entirelyomitted by the user even if it points to
a group of strongly related and relevant documents. some examples of description-
centric src algorithms are clusty5, lingo [osi   nski and weiss 2005], and keysrc
[bernardini et al. 2009], all available for testing on the internet. a recent review of
this relatively large body of literature is given in carpineto et al. [2009].

the cluster labels produced by src algorithms can be naturally seen as re   nements
of the given query, although they have been typically employed for browsing through
the search results rather than for reformulating the query. an explicit link between

4term co-occurence representations are typically used in the computational linguistic community to express
the semantics of a term. a comparison with document occurrence representations, more common in ir, is
made in lavelli et al. [2004].
5http://clusty.com

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:10

c. carpineto and g. romano

fig. 1. main steps of automatic id183.

src and aqe is made in kurl and et al. [2005], where the clusters built from top
retrieved documents are used as pseudo-queries representing different facets of the
original query. this approach can be iterated, although caution must be taken (e.g., by
rescoring the documents retrieved at each round) to avoid query drift.

5.5 other related techniques
other techniques related to aqe include boolean term decomposition [wong et al.
1987], spreading activation networks [crestani 1997], concept lattice-based ir
[carpineto and romano 2004], random indexing [sahlgren 2005], and contextual doc-
ument ranking modeled as basis vectors [melucci 2008]. although these methods do
not strictly perform id183, they have the ability to retrieve documents that
do not contain the original query terms, based on particular content relationships
among all the terms contained in the collection. another relevant technique is la-
tent semantic indexing (lsi), which replaces the observed features of documents with
a new (smaller) set of uncorrelated features using the singular value decomposition of
the term-document matrix [deerwester et al. 1990]. the relationships between lsi
and rocchio relevance feedback have been theoretically investigated in efron [2008].
rocchio is optimal for discriminating between relevant and nonrelevant documents
(viewing ir as classi   cation), whereas lsi is optimal for estimating the degree of rel-
evance of a particular document (viewing ir as regression), because projection onto a
low-dimension space reduces model variance. features generated by lsi have been
directly used for aqe in park and ramamohanarao [2007].

6. how aqe works
aqe can be broken down into the four steps shown in figure 1: preprocessing of data
source, generation and ranking of candidate expansion features, selection of expan-
sion features, query reformulation. each step is discussed, in turn, in the following
sections.

6.1 preprocessing of data source
this step transforms the raw data source used for expanding the user query into a
format that will be more effectively processed by subsequent steps. it usually con-
sists of a phase of extraction of intermediate features, followed by the construction of
appropriate data structures for easy access to and manipulation of such features. pre-
processing of a data source is usually independent of the particular user query that
is to be expanded but it is speci   c to the type of data source and expansion method
being considered. the most common preprocessing procedures are discussed in the
following.

many id183 techniques are based on the information contained in the
top-ranked items retrieved in response to the original user query from a collection of

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:11

documents. in order to compute the initial retrieval run, it is necessary to index the
collection and run the query against the collection index. indexing usually comprises

(1) text extraction from documents like html, pdf, ms word, and so on (if the col-

lection is made of such documents);

(2) id121 (extraction of individual words, ignoring punctuation and case);
(3) stop word removal (removal of common words such as articles and prepositions);
(4) word id30 (reduction of in   ected or derivational words to their root form);
(5) word weighting (assignment of a score that re   ects the importance of the word,

usually in each document).

to illustrate, consider the following short html fragment.

   <b>automatic id183</b> expands queries automatically.   

the indexed representation, using porter   s stemmer [porter 1997], and assuming

that the weight of a word is simply given by its frequency in the text, is:

automat 0.33, queri 0.33, expan 0.16, expand 0.16.

as a result, each document is represented as a set of weighted terms, with a com-
plementary inverted index    le, which maps terms to documents at query time. the in-
dexing system may also store term positions, to provide proximity-based search. when
the collection used for id183 is the same as the one being searched (e.g.,
attar and fraenkel [1977], xu and croft [1996], robertson et al. [1998], carpineto
et al. [2001], bai et al. [2005]), the ranking system to which the expanded query will
be submitted is typically used to also perform a    rst-pass ranking. if an external
corpus is employed (e.g., web data for intranet searches, or personal desktop data
for web searches), as in xu and croft [2000], voorhees [2004], diaz and metzler
[2006], and chirita et al. [2007], a different ir system will, in general, be necessary;
several options are available, such as installing and running a desktop search engine
(commercial or freely available), using web retrieval apis, or even developing one   s
own system for document indexing and ranking.

other aqe techniques, based on corpus analysis, require the extraction of partic-
ular features from the collection at hand. these are usually different from those dis-
cussed in the preceding, which are employed for indexing purposes by a conventional
ir system. a well known approach is qiu and frei [1993], where each term is repre-
sented as a weighted document vector using nonstandard collection statistics. another
example is crouch and yang [1992], which builds a statistical thesaurus by    rst clus-
tering the whole document collection via the complete link id91 algorithm.

some id183 techniques require preprocessing procedures tailored to cer-
tain data sources. for example, if id183 makes use of anchor texts, one
needs to parse a hyperlinked collection to extract the text content of anchor tags, and
to further process such texts to normalize them and/or remove those that contain too
few or too many terms [kraft and zien 2004]. clickthrough records (query, url) ex-
tracted from search engine logs are another source of data for id183 (e.g.,
cui et al. [2003], billerbeck et al. [2003]). in this case, besides extracting from the
user logs, the sequence of characters comprising the query and the corresponding doc-
uments clicked on, it may be useful to remove objectionable content and also to perform
some form of query and url canonicalization to    nd semantically equivalent strings
[beeferman and berger 2000].

in the approaches discussed so far, preprocessing is applied to a given data source.
this is the predominant situation, but there are exceptions. the data source may be
selected from multiple choices, as in gauch et al. [1999] and he and ounis [2007], or

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:12

c. carpineto and g. romano

even built from scratch. two examples of the latter are riezler et al. [2007] and bai
et al. [2007]. in riezler et al. [2007], a collection of faqs is automatically built by
   rst using web queries such as    inurl:faq    and subsequently applying machine learn-
ing techniques to extract the actual faqs from the retrieved set of pages. in bai et al.
[2007], several strategies for constructing domain models (topic pro   les) to which the
queries will be assigned for expansion are tested. such strategies involve the uti-
lization of the documents contained in the open directory project6, or the top web
answers to user-de   ned topics. of   ine web-based construction of term vectors repre-
senting    xed topics is also performed in finkelstein et al. [2002]. in all these cases,
an earlier preprocessing procedure is necessary to acquire the source data in the    rst
place, prior to the strict id174 step dealt with in this section.

6.2 generation and ranking of candidate expansion features
in the second stage of aqe, the system generates and ranks the candidate expansion
features. the reason that feature ranking is important is that most id183
methods will only choose a small proportion of the candidate expansion features to add
to the query.

the input to this stage is the original query and the transformed data source; the
output is a set of expansion features, usually with associated scores. the original
query may be preprocessed to remove common words and/or extract important terms
to be expanded (the importance being approximated e.g., by their inverse document
frequency).

we classify the techniques used to execute candidate generation and ranking ac-
cording to the type of relationship between the expansion features generated and the
query terms (after query preprocessing, if any).

6.2.1 one-to-one associations. the simplest form of candidate generation and ranking
is based on one-to-one associations between expansion features and query terms, i.e.,
each expansion feature is related to a single query term. in practice, one or more
expansion features are generated and scored for each query term, using a variety of
techniques.

one of the most natural approaches is to rely on linguistic associations, such as
using a id30 algorithm to reduce different words to the same stem. a stemmer
may remove in   ected forms of a word that strictly follow the language syntax (e.g.,
singular/plural of nouns, tenses of verbs), or it may also remove derivational forms. in
the latter case, the stem will not, in general, coincide with the morphological root of the
word. for instance, using porter   s derivational id30 algorithm [porter 1997], the
words    generalizations,       generalization,       generalize,    and    general    would be reduced
to the same stem:    gener.    clearly, the latter approach is more powerful but it is prone
to errors due to overgeneralization.

another common linguistic technique is to    nd synonyms and related words of
a query word from a thesaurus, most usually from id138 (e.g., voorhees [1994],
mandala et al. [1998]). the id138 lexicon [miller et al. 1990], available online7,
groups english words into sets of synonyms called synsets and records various
lexical semantic relations between these synonym sets.
in particular, it includes
hypernym/hyponym relationships among noun synsets that can be interpreted as
generalization/specialization relations between the concepts corresponding to such

6http://dmoz.org
7http://id138.princeton.edu/

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:13

synsets. for instance, there are three synsets with the noun    spider    in id138, each
with a speci   c sense   for zoology, computer science, and cooking. the synset with the
computer science meaning is spider, wanderer, which is de   ned as    a computer pro-
gram that prowls the internet looking for...    and has one direct hypernym ({program,
programme, computer program, computer programme}) and no hyponyms.
expansion feature generation from id138 requires selecting one synset for a
given query term, thus solving the ambiguity problem, and then traversing the hier-
archy by following its typed links. in order to choose a synset with a similar meaning
to the query term, the adjacent query terms can be best matched with the concepts
present in each synset containing the query term. after selecting the most relevant
synset, one might consider for id183, all the synonyms of the query term in
the synset plus the concepts contained in any synset directly related to it, usually with
different weights (see section 6.4). using this approach on the query    spider program   
for instance, it would    rst select the id138 node with the computer meaning of spi-
der, and then the following candidate id183 features would be generated:
   wanderer,       programme,       computer program,       computer programme.   

a radical departure from the linguistic approach consists of generating associations
automatically by computing term-to-term similarities in a collection of documents. the
general idea is that two terms are semantically related if they appear in the same
documents, just as two documents are considered similar if they contain the same
terms. two simple measures of similarity are the dice coef   cient and the jaccard
index. given terms terms u and v, the dice coef   cient (d) is de   ned as

d =

,

(3)

2    dfu   v
dfu + dfv

where dfu   v is the number of documents that contain both u and v, and dfu, dfv are the
number of documents that contain u and v, respectively.

the jaccard index (j) is de   ned as

j =

dfu   v
dfu   v

,

(4)

where dfu   v is the number of documents that contain u or v.8

a more general approach is the following. consider a term-document matrix a,
where each cell at,d is a weight wt,d for term t and document d. if we calculate c =
a a t, then c is a term-term correlation matrix, where each element cu,v is a correlation
(similarity) score between terms u and v given by

cu,v =

wu, j    wv, j.

(5)

(cid:3)

dj

using this formula, we can compute the correlation between each term of the query
and each term in the document collection. to take into account the relative frequency
of terms, it is preferable to generate normalized correlation factors, e.g. by the cosine
similarity:

(cid:4)(cid:2)

.

cu,v

u,u    (cid:2)

w2

dj

w2

v,v

dj

depending on how the set of documents and the weighting function are chosen,
formula (5) can give rise to conceptually different term-to-term correlation methods.
one well known technique,    rst proposed in attar and fraenkel [1977], relies on the
set of documents returned in response to the original query and makes use of term

8the dice coef   cient and the jaccard index are related: d = 2j/(1 + j) and j = d/(2     d).

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:14

c. carpineto and g. romano

frequency to weight the terms. we will see more elaborated techniques that can be
traced back to formula (5) in section 6.2.2.

computing co-occurrence of terms in the whole document is simple but it has the
disadvantage that position is not taken into account, whereas two terms that co-occur
in the same sentence seem more correlated than two terms that occur distantly within
a document. this aspect is usually addressed by considering term proximity; using
only restricted textual contexts such as windows of    xed length for measuring co-
occurrence of terms. however, the simple co-occurrence, whether in a large or small
context, does not necessarily mean that the terms are correlated. for instance, the
word    verdi    is correlated with the word    giuseppe    in a music book, whereas the same
correlation will not hold for a telephone book, because in the latter case the surname
   verdi    cooccurs with many names other than    giuseppe.   

a more comprehensive measure for word association that incorporates term
dependency is mutual information [church and hanks 1990; van rijsbergen 1979],
de   ned as

(cid:5)

iu,v = log2

p(u, v)
p(u)    p(v)

,

(6)

(cid:6)
+ 1

where p(u, v) is the joint id203 that u and v co-occur within a certain context,
usually a window of interest, and p(u) and p(v) are the id203 of occurrence of
terms u and v, respectively. such probabilities can be estimated, for instance, by rela-
tive frequency counts.

notice that the mutual information is symmetric: i(u, v) = i(v, u). as word order
matters (e.g., compare    word processing    to    processing word   ), it is preferable to con-
sider an asymmetric version, in which p(u, v) is the id203 that v strictly follows
u. the mutual information is zero if there is a zero co-occurrence, equal to one if u and
v are independent, and equal to log2( 1
p(u) + 1) if v is perfectly associated with u. one
of its disadvantages is that it tends to favor rare terms over common terms, because
i(u, v) will increase if p(v|u) is    xed, but p(u) decreases. this problem may become
more acute for sparse data, which is most relevant to us.
alternatively, we could consider the classical de   nition of id155 to

measure the strength of the association of term v to term u

p(v|u) =

p(u, v)
p(u)

.

(7)

the id155 can be computed by dividing the number of contexts
(e.g., phrases) in which terms u and v co-occur by the number of contexts in which term
u occurs. this popular approach (e.g., sch   utze and pedersen [1997], bai et al. [2005])
is similar to the de   nition of con   dence of association rules in data mining problems
[agrawal et al. 1993]. in fact, association rules have been explicitly used for    nding
expansion features correlated with the query terms [latiri et al. 2004; song et al.
2007]. one disadvantage of this approach is that associations with high con   dence
may hold by chance (e.g., when the two terms are statistically independent).

expansion features can also be generated by mining user query logs, with the goal
of associating the terms of the original query with terms in past related queries. as the
texts extracted from such data (possibly after preprocessing   see section 6.1) are usu-
ally very short, the standard correlation techniques based on term frequency cannot
be applied. in fact, several additional contextual clues extracted from the query logs
have been used to help identify useful associations, such as considering queries that
occurred in the same session (e.g., successive queries issued by a single user [jones
et al. 2006]) or queries that yielded similar sets of presumably relevant documents
(e.g., by deploying the bipartite graph induced by queries and user clicks [beeferman

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:15

and berger 2000]). these latter types of evidence do not depend on the content of
queries and documents and are thus especially useful when content-based approaches
are not applicable. we will return to this in section 7.

6.2.2 one-to-many associations. one-to-one associations tend to add a term when it is
strongly related to one of the query terms. however, this may not accurately re   ect the
relationships of the expansion term to the query as a whole. this problem has been an-
alyzed in bai et al. [2007]. for example, while the word    program    may well be highly
associated with the word    computer,    an automatic expansion of all queries containing
   program    with    computer    might work well for some queries (e.g.,    java program,   
   application program   ), but not for others (e.g.,    tv program,       government program,   
   space program   ). here again we come across the issue of language ambiguity.

one simple approach to one-to-many associations is to extend the one-to-one associ-
ation techniques described in the previous section to the other terms in the query. the
idea is that if an expansion feature is correlated to several individual query terms,
then it is correlated to the query as a whole. in voorhees [1994], for instance, it is
required that a new term extracted from id138 be related to at least two original
query terms before it is included in the expanded query. if we use term-to-term corre-
lations, we might compute the correlation factors of a given candidate expansion term
v to every query term, and then combine the found scores to    nd the correlation to the
global query q, e.g. by

cq,v =

1
|q|

(cid:2)
u   q

cu,v .

(8)

a similar approach was suggested in qiu and frei [1993] and xu and croft [1996],
and followed in several other research works [bai et al. 2005; cui et al. 2003; hu et al.
2006; sun et al. 2006]. the two former papers are interesting not only because they
extend the one-to-one correlation paradigm to the whole query, but also because of
their particular weighting functions and expansion feature types.

in qiu and frei [1993], formula (5) is used to    nd term-term correlations in the
whole collection, seen as a concept-term space, where documents are used to index
terms. the weight of a term in a document is expressed as the product of the fre-
quency of the term in the document by the inverse term frequency associated with
that document. the inverse term frequency for document dj is given by log t
, where
dt j
t is the number of terms in the collection and dt j is the number of distinct terms in
the document dj. this concept is analogous to the inverse document frequency used
for document ranking.

in xu and croft [1996], concepts rather than single terms are generated as expan-
sion features. a concept is a group of adjacent nouns in the top retrieved documents;
candidate concepts are analyzed using passages (a text window of    xed size) instead of
full documents. formula (5) is applied to compute a term-concept correlation (rather
than a term-term correlation), where wu, j is the frequency of the query term u in the
j-th passage and wv, j is the frequency of the concept v in the j-th passage. the exact
term-concept correlation value is determined by taking into account the inverse fre-
quency of the term and the concept in the passages contained in the whole collection.
the correlation factors of each single query term to a given concept are then combined
through a function of their product. this method is called local context analysis.

the extended one-to-one associations approach can be useful to    lter out expansion
features that are weakly related to some query terms, but it does not guarantee that
an expansion feature that is strongly connected to only one term will be discarded. for

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:16

c. carpineto and g. romano

example, if the association of    computer    with    program    is strong enough,    computer   
may remain as an expansion term even for the queries    tv program    or    government
program.   

this problem can be alleviated by adding context words to a term-to-term associa-
tion that specify under which conditions the association is valid. such context words,
for instance, can be derived as logical consequences from a knowledge base [lau et al.
2004], or they can be extracted from a corpus using term co-occurrences [bai et al.
2006]. considering our example again, if we require that    program    appears with
   application    (or    java   ), then we limit the applicability of the association    program   -
   computer    to the appropriate contexts.

when id183 is based on id138, the need for relating the expansion fea-
tures to the entire query, and not to its terms considered in isolation, is even stronger.
voorhees [1994] showed that the latter techniques are usually not effective because
they do not guarantee a good id51. this problem, however, can
be addressed by analyzing the relationships between the id138 concepts associated
with one query word and the concepts associated with the other (contiguous) query
words. consider as an example the query    tropical storm.    the sense of    storm    can be
unequivocally determined by observing that a hyponym of the synset {storm, violent
storm} is    hurricane,    whose de   nition contains the word    tropical.    this and other
simple heuristic strategies have been used in liu et al. [2004]. we will discuss more
elaborated disambiguation methods based on id138 concepts in section 7.1.

another, perhaps more principled, approach to    nding one-to-many associations
is based on combining multiple relationships between term pairs through a markov
chain framework [collins-thompson and callan 2005]. for each query, a term net-
work is constructed that contains pairs of words linked by several types of relations,
such as synonyms, stems, co-occurrence, together with transition probabilities. such
relations can be generated from various sources; collins-thompson and callan [2005]
makes use of id138, krovetz stemmer, an external corpus and top retrieved doc-
uments. then the words with the highest id203 of relevance in the stationary
distribution of the term network are selected as expansion features, for they best re-
   ect the multiple aspects of the given query. this approach is more robust with respect
to data sparsity and it supports complex id136s involving chains of terms. a sim-
ilar association paradigm, using a spreading activation model [anderson 1983], has
been successfully applied to solve a language game in which the player has to    nd a
word semantically related to a set of given words [semeraro et al. 2009].

to overcome the limitations inherent in considering relationships between single
terms, one can see the query as a phrase and look for phrases that are related to it.
phrases typically provide a richer context and have a smaller degree of ambiguity than
their constituent words, although a similarity assessment at the phrase level may not
be straightforward. in riezler et al. [2007], for instance, the best translation phrases,
from which the expansion terms are extracted, are learned from training data; in liu
et al. [2008], the criterion for selecting the best phrases, which are directly used as
expansion features, is based on a conceptual distance, measured on id138, between
the query phrase and keyphrases of its search results.

6.2.3 analysis of feature distribution in top-ranked documents. the techniques described
in this section do not    t into either of the previous categories, because they do not
try to    nd features directly associated with the terms in the query, whether single or
multiple. the idea is to use the    rst documents retrieved in response to the origi-
nal query as a more detailed description of the underlying query topic, from which to
extract the most important terms to be used as expansion features. in a sense, the
expansion features are related to the full meaning of the query because the extracted

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:17

table i. main term-ranking functions based on analysis of term distribution in

pseudo-relevant documents

reference
[rocchio 1971]

function

rocchio   s weights

[robertson and sparck jones 1976]

binary independence model

[doszkocs 1978]

(bim)

chi-square

[robertson 1990]

robertson selection value

(rsv)

[carpineto et al. 2001]

kullback-leibler distance

(kld)

mathematical form

(cid:3)
d   r

w(t, d)

log

p(t|r) [1     p(t|c)]
p(t|c) [1     p(t|r)]
[p(t|r)     p(t|c)]2

p(t|c)

w(t, d) . [p(t|r)     p(t|c)]

p(t|r) . log

p(t|r)
p(t|c)

(cid:3)
d   r

terms are those that best characterize the pseudo-relevant documents as a whole, but
their association with the query terms is not analyzed explicitly.

a simple approach, inspired by rocchio   s method for relevance feedback [rocchio
1971], is to assign a score to each term in the top retrieved documents by a weighting
function applied to the whole collection. the weights collected by each term are then
summed up and the resulting score is used to sort the set of terms. this approach,
termed pseudo-relevance feedback (or retrieval feedback, or blind feedback), is simple
and computationally ef   cient, but it has the disadvantage that each term weight may
re   ect more the usefulness of that term with respect to the entire collection rather
than its importance with respect to the user query.

this issue can be addressed by studying the difference in term distribution between
the subsets of (pseudo-)relevant documents and the whole collection. it is expected
that terms with little informative content will have the same (random) distribution
in any subset of the collection, whereas the terms that are most closely related to
the query will have a comparatively higher id203 of occurrence in the relevant
documents. following this general paradigm, various functions have been proposed
that assign high scores to the terms that best discriminate relevant from nonrelevant
documents.

in table i we show some well known term-ranking functions, including rocchio   s
weights. the notation is the following: t indicates a term, w(t, d) is the weight of t in
pseudo-relevant document d, p(t|r) and p(t|c)indicate the id203 of occurrence of
t in the set of pseudo-relevantdocuments r and in the whole collection c, respectively.
the list in table i is not exhaustive. other term-scoring functions, including variants
of those reported in this article, are considered in efthimiadis [1993], carpineto et al.
[2001], and wong et al. [2008].

the estimation of probabilities in the expressions in table i is an important issue
because it might affect performance results. to compute the id203 of occurrence
of a term t in x (whether the set of pseudo-relevant documents r or the whole col-
lection c), the maximum likelihood criterion is often adopted   the ratio between the
number of occurrences of t in x , treated as a long sequence of terms, and the number
of terms in x . a different id203 estimate is to use the fraction of documents in
x that contain the term t. this latter criterion, generally used to compute the binary
independence model (bim) and robertson selection value (rsv) functions, has also
been applied to chi-square and kullback-leibler distance (kld) in a recent experi-
mental study [wong et al. 2008], with very good results.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:18

c. carpineto and g. romano

each term-ranking function has its ownrationale, and the results produced by their
application may be very different. in particular, it has been shown that the ordered
sets of expansion terms suggested for each query by the different functions are largely
uncorrelated [carpineto et al. 2002]. however, several experiments suggest that the
choice of the ranking function does not have a great impact on the overall system
performance as long as it is used just to determine a set of terms to be used in the
expanded query [salton and buckley 1990; harman 1992; carpineto et al. 2001]. by
contrast, we will see in section 6.4 that the scores produced by different functions
can make a big difference if they are used not only to select but also to reweight the
expansion terms.

6.2.4 query id38. another commonly-used approach to aqe is to build
a statistical language model for the query, specifying a id203 distribution over
terms. the best terms for id183 are those with the highest probabilities.
these techniques are usually referred to as model-based. the two main represen-
tatives are the mixture model [zhai and lafferty 2001a] and the relevance model
[lavrenko and croft 2001], both making use of the top retrieved documents. they
are described in the following.

in the former method, similarly to term-ranking functions based on distribution
difference analysis, one tries to build a query topic model from the top-ranked doc-
uments by extracting the part that is most distinct from the whole document collec-
tion. as top-ranked documents are likely to contain both relevant and background (or
even irrelevant) information, they can be represented by a mixture generative model
that combines the query topic model   t (to be estimated) and the collection language
model. the log-likelihood of top-ranked documents is as follows, where r is the top-
ranked document set, c(t, d) is the number of the occurrences of t in d, and    is the
interpolation weight.

log p(r|  t) =

c(t, d) log((1       ) p(t|  t) +    p(t|c)).

(9)

(cid:3)
d   r

(cid:3)

t

the id83 [dempster et al. 1977] is then used
to extract the topic model so as maximize the likelihood of the top-ranked documents
(assuming that    has a non-zero value). compared to the term-ranking functions illus-
trated in the preceding, the mixture model has a stronger theoretical basis but there
is one parameter (  ) that needs to be set and it may be more dif   cult to compute.

in the relevance model approach, it is assumed that both the query and the
top-ranked documents are samples from an unknown relevance model thetarel. to
approximate such a model, the id203 of term t is related to the conditional
id203 of observing that term given that we just observed the original query
terms. by assuming that the k query terms qi and the document terms are sampled
identically and independently, the following estimate can be derived [lavrenko and
croft 2001].

p(t|  rel) =

p(d) p(t|d)

p(qi|d).

(10)

(cid:3)
d   r

k(cid:7)

i=1

this model has been widely used recently. as it does not rely on distribution dif-
ference analysis, it is more similar in spirit to the rocchio method. operationally,
its main difference from rocchiois that top-ranked documents are weighted such that
documents further down the list have smaller and smaller in   uence on word probabil-
ities [lavrenko and allan 2006].

an interesting generalization of the relevance model that takes the term dependen-
cies into account is described in metzler and croft [2007]. by modeling the relevance

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:19

fig. 2. the    rst ten results returned by google in response to the query    foreign minorities germany    (as
of may 2009).

distribution with markov random    elds, a wider set of features is used, that includes
not only simple term occurrence statistics but also proximity-based features, such as
the number of times the query terms appear ordered or unordered within a window
of    xed size. the same method can also generate multi-term expansion concepts, al-
though such concepts were not found to be highly effective, probably due to the corre-
lation between their constituent single terms.

6.2.5 a web search example. to give an impression of the features generated by dif-
ferent expansion methods in a practical application, consider the following exam-
ple. suppose you are interested in retrieving web pages about foreign minorities in
germany. figure 2 shows the    rst results page returned by google in response to the
query    foreign minorities germany    (as of april 2009). notice that due to improper
matching with the query terms,    ve out of the    rst ten results are non-relevant to the
query (e.g., they are about german minorities living abroad).

to help focus the search, we performed automatic id183. using just the
   rst thirty results (title + snippet) returned by google as a data source, we applied
several expansion-feature generation methods illustrated in the preceding, recapitu-
lated in the    rst column of table ii. preprocessing was common to all methods and

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:20

c. carpineto and g. romano

table ii. expansion features (with associated scores) generated by several methods for the

query    foreign minorities germany    by analyzing the first thirty results returned by google on the

same query

method

expansion features

query-term correlation west (0.415), workers (0.391), policy (0.380), republic (0.326),
matrix
mutual information

housing (0.378), access (0.378), language (0.378), cultural (0.378)
integration (4.355), jstor (4.355), reports (4.355), description (4.241)
european (0.319), continental (0.319), cultural (0.319), language (0.319)
housing germany (26.422), access housing (20.644), minority experience
(18.446), foreign policy (16.759), books result (16.586), west germany
(15.749), minorities groups (12.718), joschka    scher (10.422)
joschka (1.121), poland (0.865), shareholders (0.726), romania (0.695)
danish (0.668),    scher (0.621), frisians (0.618), sorbs (0.580)
frisians (10.183), sorbs (9.036), joschka (8.878), hillard (6.669)
gaining (2.482), shareholders (1.848),    scher (1.304), continental (0.459)
frisians (4.176), sorbs (1.881), joschka (1.685), hillard (0.358)
google (0.061), number (0.046), history (0.041), books (0.036)
joschka (0.004), gaining (0.002), poland (0.002), frisians (0.002)
sorbs (0.002), shareholders (0.001), hillard (0.001),    scher (0.001)
frisians (0.036), sorbs (0.032), joschka (0.032), hillard (0.024),
gaining (0.017), poland (0.005),    scher (0.004), clark (0.002)
poland (0.0083449), language (0.0041835), description (0.0041832),
european (0.0041820), cultural (0.0041815), continental (0.0041814),
west (0.00418107), integration (0.0041806)

local context analysis

rocchio   s weights

binary independence
model
chi-square

robertson selection
value
kullback-leibler
distance

relevance model

consisted of html tag stripping, text id121, stop wording, and word id30.
the query-term correlation was found by computing the correlations with the single
query terms with formula (5) and then taking their arithmetic mean. a similar proce-
dure was used for the mutual information scores, where we used a window size equal
to three, to compute the term-term correlations. the lca method was approximated
considering the snippets as passages and estimating the frequency of the concepts in
the web collection with the frequency counts returned by google on the candidate con-
cepts (submitted in quotes). the weights in rocchio and rsv were computed using a
simple tf    idf function (proportional to the term frequency in the search result and in-
versely proportional to the frequency of the web documents containing the term). for
the other methods, we estimated the conditional probabilities p(t|d) as the frequency
of term t in document(s) d. for the relevance model, we also used laplace smoothing
to eliminate zeros, and a constant id203 value for pseudo-relevant documents.
the results produced by each method (expansion features + scores or probabilities) are
shown in table ii.

notice that    frisians    and    sorbs    (two minorities living in germany) were the
   rst suggestions by bim, chi-square, and kld, and they were also present in the
list of expansion terms produced by the other term distribution-based methods. in
figure 3 we see the google results when the original query was expanded with
   frisians    and    sorbs.    the difference from the unexpanded case is striking; all the    rst
ten results appear to be relevant to the query, while the overall number of retrieved
results reduced from 4,100,000 to 1,610. judging from figure 3, the new results cover
not only frisians and sorbs but also the other minorities. this example shows that it
was possible to generate in a very ef   cient manner, a set of expansion features that
produced a more accurate model of the query topic, thus    ltering out those pages that
spuriously matched the shorter description.

before concluding this section, we would like to note that the methods for generating
id183 features can themselves take advantage of an earlier id183

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:21

fig. 3. the    rst ten results returned by google in response to the expanded query    foreign minorities
germany sorbs frisians    (as of may 2009).

step. the idea is to use the query augmented with some context as an input, instead
of the mere user query. in finkelstein et al. [2002], for instance, the authors use the
text surrounding the marked query, assuming that search is initiated from a document
the user views. this amounts to performing a double id183, in which the
   rst expansion is used to reduce query ambiguity and increase the accuracy of the
procedure that generates the actual expansion features from the augmented query
and the data source. an early stage of id183 with a similar goal is also
used in jones [1993], to    nd the id138 nodes that best match the query terms; such
nodes are the starting points to generate the expansion features.

6.3 selection of expansion features
after ranking the candidate features, the top elements are selected for query expan-
sion. the selection is made on an individual basis, without considering the mutual
dependencies between the expansion features. this is of course a simplifying assump-
tion, although there are some experimental results that seem to suggest that the in-
dependence assumption may be justi   ed [lin and murray 2005].

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:22

c. carpineto and g. romano

usually only a limited number of features is selected for expansion, partly because
the resulting query can be processed more rapidly, partly because the retrieval effec-
tiveness of a small set of good terms is not necessarily less successful than adding all
candidate expansion terms, due to noise reduction (e.g., salton and buckley [1990],
harman [1992]).

some research has been carried out on the optimum number of features to include
and thereare differing suggestions ranging from    ve   ten features [amati 2003; chang
et al. 2006] to a few hundred [bernardini and carpineto 2008; buckley et al. 1995;
wong et al. 2008]. on the other hand, the performance decrease associated with non-
optimal values is usually modest carpineto et al. [2001], and most experimental stud-
ies agree that the number of expansion features is of low relevance. the typical choice
is to use 10   30 features. when the feature scores can be interpreted as probabilities,
one can select only the terms having a id203 greater than a certain threshold;
e.g., p = 0.001, as in zhai and lafferty [2001a].

rather than concentrating on    nding an optimal number of expansion terms, it may
be more convenient to adopt more informed selection policies. it has been shown that
different queries have a varying optimal number of expansion features [billerbeck and
zobel 2004a; buckley and harman 2003; cao et al. 2008], and that many expansion
terms   about one third in cao et al. [2008]   are harmful to retrieval performance. in
fact, if one were able to select exactly the best features for each query, the performance
improvement would be much higher than usually achieved [carpineto et al. 2002; cao
et al. 2008].

to go beyond a straightforward selection based on the ranks assigned to candidate
features, several methods that employ additional information have been proposed.
one technique [carpineto et al. 2002] consists of using multiple term-ranking func-
tions and selecting for each query the most common terms (e.g., based on majority
vote). a similar idea is exploited in collins-thompson and callan [2007], with the dif-
ference that multiple feedback models are created from the same term-ranking func-
tion by resampling documents and by generating variants of the original query. the
authors argue that in this way it is possible to remove noise expansion terms as well
as focus on expansion terms related to multiple query aspects. another strategy con-
sists of choosing a variable amount of expansion depending on the query dif   culty. in
chirita et al. [2007], the number of expansion terms is a function of the ambiguity of
the original query in the web (or in the personal information repository of the user),
as measured by the clarity score [cronen-townsend and croft 2002].

in cao et al. [2008], the authors use a classi   er to discriminate between relevant
and irrelevant ranked expansion terms. to learn the support vector machine clas-
si   er parameters, a training set is created in which single terms are labeled as good
or bad depending on whether they improve or hurt retrieval performance and each
term is described by a set of features such as co-occurrence and proximity with query
terms. the selection of the best expansion terms for a given query (including zero
terms) is explicitly cast as an optimization problem in collins-thompson [2009]. by
optimizing with respect touncertainty sets de   ned around the observed data (e.g., us-
ing query perturbations and topic-speci   c constraints such as aspect balance, aspect
coverage and support of the query), the system mitigates the risk-reward tradeoff
of expansion.

6.4 query reformulation
the last step of aqe is query reformulation, namely how to describe the ex-
panded query that will be submitted to the ir system. this usually amounts to
assigning a weight to each feature describing the expanded query   termed query

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:23

reweighting   but there are other approaches that will be discussed at the end of this
section.

the most popular query reweighting technique is modeled after rocchio   s formula
for relevance feedback [rocchio 1971] and its subsequent improvements [salton and
buckley 1990], adapted to the aqe setting. a general formulation is the following,
where q(cid:4) is the expanded query, q is the original query,    is a parameter to weight
the relative contribution of query terms and expansion terms, and scoret is a weight
assigned to expansion term t.
t,q(cid:4) = (1       )    wt,q +       scoret
w(cid:4)

(11)
when the expansion terms are extracted from pseudo-relevant documents and their
score is computed using the documents, or rocchio   s, weights (see the    rst function in
table i), it is easy to show that the expanded query vector computed by expression (11)
moves towards the centroid of pseudo-relevant documents (according to the document
weights). however, the bene   ts of taking into account the term distribution differ-
ence between the pseudo-relevant documents and the whole collection to select the
expansion terms may be reduced if we reweight such terms by rocchio   s weights. the
rationale is that terms that were correctly ranked higher (because more relevant to the
speci   c query at hand) will be downweighted if their relevance value with respect to
the entire collection being searched is low. this observation has been con   rmed in sev-
eral experiments where the use of a distribution difference-based scoring function for
both id183 and reweighting achieved the best retrieval effectiveness, not
only for english (e.g., carpineto et al. [2001], wong et al. [2008]) but also for other
european [amati et al. 2003] and asian languages [savoy 2005]. even a simple
reweighting scheme based on an inverse function of term ranks may produce good
results (e.g., carpineto et al. [2002], hu et al. [2006]).

notice that as the document-based weights used for the unexpanded query and
thedistribution difference-based scores used for the expansion terms have different
scales, their values must be normalized before summing them in expression (11). sev-
eral simple id172 schemes, discussed in wong et al. [2008], have been pro-
posed; usually they produce comparable results, although more powerful methods that
not onlyscale data into the same range but also increase its uniformity could be more
effective [montague and aslam 2001].

the value of    in expression (11) can be adjusted so as to optimize performance, if
training data are available. a typical default choice is to give more importance to the
original query terms; e.g, twice as much as the expansion terms. another possibility is
to use a parameter-free query reweighting formula such as proposed in amati [2003].
a more powerful approach is to adaptively determine how much weight one should put
on expansion information. in lv and zhai [2009], considering a relevance feedback
setting, the authors use a learning approach to predict the optimal value of    for each
query and each set of feedback documents, exploring a number of features related to
the discrimination of query and documents (such as length, id178, and clarity) and
to the divergence between query and feedback documents.

formula (11) can also be used when the expansion features have been extracted
from a thesaurus or id138. the weightings may be based on criteria such as number
of connections, number of co-occurrences, path length, and type of relationship [jones
1995]. in voorhees [1994], for instance, the expanded query vector is comprised of
subvectors of eleven different concept types with an associated importance weight:
one for original query terms, one for synonyms, and one each for the other relation
types contained within the noun portion of id138.

if document ranking is performed through a id38 approach, the
query reweighting step of aqe is naturally supported. in the basic id38

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:24

c. carpineto and g. romano

framework, the most relevant documents are those that minimize the kullback-
leibler divergence between the query language model and the document language
model:

sim(q, d)    

p(t|  q)log

p(t|  q)
p(t|  d)

(cid:3)
t   v

.

(12)

in formula (12), the query model is usually estimated considering only the original
query words, while the document model is estimated also taking into account unseen
words through id203 smoothing, for example, by the jelinek-mercer interpolation
jelinek and mercer [1980]: p(t|  (cid:4)
d) = (1      )   p(t|  d) +      p(t|  c). thus, the question arises
as to whether it is possible to create a better query model by    nding related words
with their associated probabilities and then using the corresponding id183
model (qem) to smooth the original query model, in the same way as the document
model is smoothed with the collection model. various methods for creating a query
expansion model have been explored, based not only on feedback documents [lavrenko
and croft 2001; zhai and lafferty 2001a], but also on term relations [bai et al. 2005],
and domain hierarchies [bai et al. 2007]. regardless of the speci   c generation method,
the    nal expanded query model (computed with the jelinek-mercer interpolation) is
given by

p(t|  (cid:4)

q) = (1       )    p(t|  q) +       p(t|  qem),

(13)

which can be seen as a generalization of expression (11).

query reweighting is common in aqe but it is not always performed. one sim-
ple alternative approach is to increase the number of features describing the query
without performing query reweighting at all, as in our example in figure 3. another
approach consists of increasing the number of query features and then applying a
modi   ed version of the weighting function used by the ranking system to explicitly
deal with the expansion features, in contrast to ranking the documents using the sys-
tem   s basic weighting function in conjunction with a reweighted expanded query. a
well known example is robertson and walker [2000], used to extend the okapi bm25
ranking function [robertson et al. 1998].

in other cases, it is produced by a boolean query [graupmann et al. 2005; liu et al.
2004], or more generally, a structured query [collins-thompson and callan 2005]. in
kek  al  ainen and j  arvelin [1998], it was shown that the probabilistic and operator,
incombination with maximally expanded query aspects, was very effective for query
expansion. nowadays, there are several search query languages that allow speci-
   cation of general concepts including boolean    ltering, phrase matching, and term
proximity, among others. for instance arguello et al. [2008], using indri9, the query
   dslr camera review    can be expressed as:

#weight (

0.8
0.1

#combine ( dslr camera review )
#combine (

0.1

#combine (

#1 ( dslr camera )
#1 ( camera review )
#1 ( dslr camera review ) )
#uw8 ( dslr camera )
#uw8 ( camera review )
#uw8 ( dslr review )
#uw12 ( dslr camera review ) ) ),

9http://www.lemurproject.org/indri/

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:25

fig. 4. a taxonomy of approaches to aqe.

where the    rst line is a unigram query, the second group is a query of exact phrases,
and the third group is a query of unordered windows (uw) with a speci   ed size.

7. a classification of approaches
aqe techniques can be classi   ed into    ve main groups according to the conceptual
paradigm used for    nding the expansion features: linguistic methods, corpus-speci   c
statistical approaches, query-speci   c statistical approaches, search log analysis, and
web data. each group can then be further split into a few subclasses, thus yielding the
general taxonomy shown in figure 4. in this section we discuss the main character-
istics of the groups in the taxonomy. then we provide a detailed feature chart, where
single aqe techniques can be analyzed and compared to one another along a number
of speci   c dimensions.

7.1 linguistic analysis
these techniques leverage global language properties such as morphological, lexical,
syntactic and semantic word relationships to expand or reformulate query terms. they
are typically based on dictionaries, thesauri, or other similar knowledge representa-
tionsources such as id138. as the expansion features are usually generated inde-
pendently of the full query and of the content of the database being searched, they are
usually more sensitive to word sense ambiguity.

using word stems is one of the simplest and earliest language-speci   c aqe tech-
nique. the id30 algorithm can be applied either at indexing time (only the docu-
ment word stems are stored and then they are matched to the query word stems), as
in most systems (e.g., krovetz [1993], hull [1996]), or at retrieval time (the original
document words are stored and then they are matched to the morphological variants
of query terms). the latter strategy may be more effective [bilotti et al. 2004], but
it requires structured querying   an ability that may not be present in alldocument
retrieval systems.

ontology browsing is another well known language-speci   c aqe technique [navigli
and velardi 2003]. knowledge models such as ontologies and thesauri (the distinc-
tion between the two is blurred) provide a means for id141 the user   s query
in context. both domain-speci   c and domain-independent ontologies have been used
(see bhogal et al. [2007] for a review of case studies), including the combination of
multiple thesauri [mandala et al. 1999]. most of the recent work has focused on the
use of id138. as already remarked, id138 is very appealing for supporting aqe,
but its application may raise several practical issues; e.g., lack of proper nouns and
collocations, no exact match between query and concepts, one query term mapping to

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:26

c. carpineto and g. romano

several noun synsets. furthermore, the use of id138 suffers from the disambigua-
tion problems discussed in section 5.3. in particular, its use for id183 is
advantageous only if the query words are disambiguated almost exactly ([voorhees
1994]; gonzalo et al. [1998]), while id51 remains a hard prob-
lem [navigli 2009].

there are several ways to circumvent these dif   culties. to increase the coverage
of single and multiword concepts, id138 has been enriched with an automatical-
lyconstructed thesaurus [mandala et al. 1998]. the disambiguation issue has been
addressed in a more effective manner in some recent papers. in navigli and velardi
[2005], the authors argue that instead of replacing a given query word with its syn-
onyms, hyperonyms, and hyponyms, it might be better to extract the concepts that
pertain to the same semantic domain of query, through other types of de   nitional in-
formation derivable from id138, such as gloss words and common nodes. the dif-
ferent types of information present in id138 can also be combined, e.g., to assign
terms in the same query into semantically similar groups, followed by conventional
expansion of each group [gong et al. 2006]. in liu et al. [2004] and song et al. [2007],
classical id138 concepts, extracted by a sequential application of heuristic rules to
pairs of query terms, are then integrated with other feature extraction methods.

the third main approach for providing additional linguistic information to the orig-
inal query is syntactic analysis. the objective is to extract relations between the query
terms, which can then be used to identify expansion features that appear in related re-
lations. for example, it is possible to index the user query and the top-ranked snippets
by relation paths induced from parse trees, and then learn the most relevant paths to
the query [sun et al. 2006]. the syntactic approach may be most useful for natural
language queries; to solve more general search tasks, the linguistic analysis can be
more effectively integrated with statistical [song et al. 2006] or taxonomic information
[liu et al. 2008].

7.2 corpus-speci   c global techniques
the techniques in this category analyze the contents of a full database to identify
features used in similar ways. most early statistical approaches to aqe were
corpus-speci   c and generated correlations between pairs of terms by exploiting term
co-occurrence, either at the document level, or to better handle topic drift, in more
restricted contexts such as paragraphs, sentences, or small neighborhoods. concept
terms [qiu and frei 1993] and term id91 [bast et al. 2007; crouch and yang
1992; sch   utze and pedersen 1997] are two classical strategies, already reviewed in
the preceding sections. other approaches to building an association thesaurus are de-
scribed in gauch et al. [1999], hu et al. [2006], park and ramamohanarao [2007], and
milne et al. [2007], making use of context vectors, mutual information, latent seman-
tic indexing, and interlinked wikipedia articles, respectively. this aqe paradigm has
also been recently extended with good results to multimedia documents [natsev et al.
2007]. note that since global techniques are data-driven, they may not always have a
simple linguistic interpretation.

7.3 query-speci   c local techniques
query-speci   c techniques take advantage of the local context provided by the query.
they can be more effective than corpus-speci   c techniques because the latter might
bebased on features that are frequent in the collection but irrelevant for the query
athand.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:27

query-speci   c techniques typically make use of top-ranked documents. the most
commonly used methods are analysis of feature distribution difference and model-
based aqe. both were discussed in depth in the preceding sections.

a different vein of research on query speci   c-techniques is based on preprocessing
top retrieved documents for    ltering out irrelevant features prior to the utilization of
a term-ranking function. besides using just web snippets, several methods for    nding
more compact and informative id194s have been proposed, such
as passage extraction [xu and croft 1996] and text summarization [lam-adesina and
jones 2001]. in chang et al. [2006], the document summaries go through a further
process of id91 and classi   cation with the aim of    nding an even more reduced
set of orthogonal features describing each document (termed query concepts). in this
case, id91 is used to extract intradocument rather than cross-document contex-
tual information, in contrast with the approaches described in section 5.4.

7.4 search log analysis
the fourth main aqe paradigm is based on analysis of search logs. the idea is to mine
query associations that have been implicitly suggested by web users, thus bypassing
the need to generate such associations in the    rst place by content analysis.

search logs typically contain user queries, followed by the urls of web pages that
are clicked by the user in thecorresponding search results page. one advantage of
using search logs is that they may encode implicit relevance feedback, as opposed to
strict retrieval feedback.

on the other hand, implicit measures are generally thought to be only relatively
accurate (see joachims et al. [2007] for an assessment of the reliability of this as-
sumption) and their effectiveness may not be equally good for all types of users and
search tasks [white et al. 2005]. other problems with their use for aqe are caused
by noise, incompleteness, sparseness, and the volatility of web pages and query [xue
et al. 2004]. also, the availability of large-scale search logs is an issue.

there are two main aqe techniques based on search logs. the    rst is to treat
the individual queries as documents and extract features from those related to the
original user query, with or without making use of their associated retrieval results
(e.g., huang et al. [2003], jones et al. [2006], yin et al. [2009]). the second technique,
more widely used, consists of exploiting the relation of queries and retrieval results
to provide additional or greater context in    nding expansion features. examples of
the latter approach include using top results from past queries [fitzpatrick and dent
1997],    nding queries associated with the same documents [billerbeck et al. 2003] or
user clicks [beeferman and berger 2000]), and extracting terms directly from clicked
results [cui et al. 2003; riezler et al. 2007].

7.5 web data
a common web data source for aqe is represented by anchor texts. anchor texts
and real user search queries are very similar because most anchor textsare succinct
descriptions of the destination page. however, in the absence of any implicit user
feedback, it is dif   cult to    nd the anchor texts that are similar to the query because
classical ranking techniques such as equation (1) do not work well on very short
texts. in kraft and zien [2004], anchor texts are ranked using several criteria that
best relate to the speci   c nature of the data, such as the number of occurrences of an
anchor text (taking into account whether it points to a different site or to the same
site) and the number of terms and characters in it. each anchor text is then assigned
a combined rank based on a median aggregation of its individual ranks. at query

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:28

c. carpineto and g. romano

time, the highest-ranked anchor texts that have a non-empty intersection with the
query are selected as re   nement features.

another interesting method, based on wikipedia documents and hyperlinks, is pro-
posed in arguello et al. [2008]. the initial set of candidates associated with a query
is restricted by considering only those anchor texts that point to a short set of top-
ranked documents from a larger set of top-ranked documents, followed by scoring each
candidate proportional to its frequency and inversely proportional to the rank of the
documents it links to. speci   c categories of wikipedia articles are used in xu et al.
[2009].

other types of web data that can be employed for aqe include faqs [riezler et al.

2007] and the open directory project web pages [bai et al. 2007].

7.6 a feature chart
in tables iii and iv we consider some of the most in   uential or innovative aqe meth-
ods, regardless of their broad conceptual paradigms, and provide a detailed classi   ca-
tion along    ve speci   c problem dimensions. the methods are ordered chronologically.

8. retrieval effectiveness
the retrieval effectiveness of aqe systems is typically evaluated by executing each
querytwice, with and without id183, and then comparingthe two lists of
retrieved documents. in this section, after a brief illustration of the experimental
setting, we report and analyze the results published in the literature. we next discuss
alternative evaluation methods.

8.1 experimental setting
most researchers have used, in their experiments, the test collections developed at
trec over the last years. the trec workshop series is organized in a number of
tracks, the ones most relevant to aqe being those that involve searching a static set
of documents using new queries (called topics); i.e., ad hoc, web, robust, and terabyte
track. the search tasks evaluated in such tracks mainly differ in the type and size
of the collection being searched; the robust track, in addition, explicitly focuses on
dif   cult topics: topics where unexpanded queries achieve poor results. each collec-
tion typically consists of a very large set of documents (drawn from sources such as
newswires and the web), a set of test topics, and manual (human) relevance assess-
ments stating which documents are relevant to which topic. in table v we report the
main document collection statistics.10

the most common measure used to evaluate the retrieval effectiveness of the list of
documents retrieved in response to a topic is average precision. it is de   ned as the sum
of the precision at each relevant document in the list divided by the total number of
relevant documents. this measure is computed for each topic and then it is averaged
over the set of topics.

8.2 published results of aqe approaches
the data sets summarized in table v have become a standard benchmark for mea-
suring the retrieval performance of aqe. however, even when referring to the same
speci   c trec test collection, the published    gures are not always directly comparable

10other classical test collections, based on the trec model, are those provided by clef. however, although
there are also monolingual search tasks, the emphasis of clef is on cross-lingual information retrieval (see
section 4.4).

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:29

)

v

i

l

e
b
a
t
n

i

s
e
u
n

i
t

n
o
c

(

t

s
d
o
h
e
m
e
q
a

l

a
r
e
v
e
s

f

o
n
o

i
t

i

l

a
c
   
s
s
a
c
e
n
f
a

i

.
i
i
i

l

e
b
a
t

y
r
e
u
q
d
e
d
n
a
p
x
e

n
o
i
t
a
t
n
e
s
e
r
p
e
r

n
o
i
t
c
e
l
e
s

e
r
u
t
a
e
f

e
r
u
t
a
e
f

e
t
a
d
i
d
n
a
c

d
o
h
t
e
m

n
o
i
t
a
t
n
e
s
e
r
p
e
r

e
r
u
t
a
e
f

e
t
a
d
i
d
n
a
c

d
o
h
t
e
m
n
o
i
t
c
a
r
t
x
e

-
n
o
i
t
a
l
e
r
r
o
c

s
t
h
g
i
e
w
d
e
s
a
b

t
p
e
c
n
o
c
-

m

e
c
a
p
s

r
e
t

s
d
r
o
w
e
l
g
n
i
s

f
o

s
r
o
t
c
e
v

s
e
p
y
t

t
p
e
c
n
o
c

d
e
s
a
b
-
k
n
a
r

s
t
h
g
i
e
w

o
i
h
c
c
o
r

c
i
t
s
i
l
i
b
a
b
o
r
p

g
n
i
t
h
g
i
e
w
e
r

d
e
t
a
l
o
p
r
e
t
n
i

l
e
d
o
m
y
r
e
u
q

d
e
t
a
l
o
p
r
e
t
n
i

l
e
d
o
m
y
r
e
u
q

+
o
i
h
c
c
o
r

s
e
r
o
c
s
d
l
k

d
e
t
h
g
i
e
w
n
u

s
m

r
e
t

o
i
h
c
c
o
r

c
i
t
s
i
l
i
b
a
b
o
r
p

g
n
i
t
h
g
i
e
w
e
r

d
e
t
h
g
i
e
w
n
u

s
m

r
e
t

d
e
t
h
g
i
e
w
n
u

s
m

r
e
t

y
r
e
u
q
n
a
e
l
o
o
b

d
e
t
a
l
o
p
r
e
t
n
i

l
e
d
o
m
y
r
e
u
q

m
y
n
o
p
y
h

h
t
g
n
e
l
n
i
a
h
c

e
c
n
e
r
r
u
c
c
o
o
c

x
i
r
t
a
m

o
i
h
c
c
o
r

s
t
h
g
i
e
w

v
s
r

s
d
r
o
w
e
l
g
n
i
s

s
e
s
a
r
h
p

s
d
r
o
w
e
l
g
n
i
s

s
d
r
o
w
e
l
g
n
i
s

l
e
d
o
m
e
c
n
e
v
e
l
e
r

s
d
r
o
w
e
l
g
n
i
s

l
e
d
o
m
e
r
u
t
x
i
m

s
d
r
o
w
e
l
g
n
i
s

d
l
k

v
s
r

g
n
i
t
t
i
l
p
s

s
l
e
r
n
o
n
/
s
l
e
r

v
s
r

c
i
t
s
i
l
i
b
a
b
o
r
p

m

r
e
t
-
o
t
-

m

r
e
t

n
o
i
t
a
i
c
o
s
s
a

k
n
a
r
n
a
i
d
e
m

n
o
i
t
a
g
e
r
g
g
a

x
i
r
t
a
m

r
u
c
c
o
o
c

n
o
i
t
a
u
g
i
b
m
a
s
i
d
+

x
i
r
t
a
m

r
u
c
c
o
o
c

w
o
   
n
o
i
t
a
m
r
o
f
n
i
+

s
d
r
o
w
e
l
g
n
i
s

s
e
s
a
r
h
p

s
d
r
o
w
e
l
g
n
i
s

s
d
r
o
w
e
l
g
n
i
s

s
d
r
o
w
e
l
g
n
i
s

s
e
s
a
r
h
p

+
s
e
s
a
r
h
p

s
d
r
o
w
e
l
g
n
i
s

s
d
r
o
w
e
l
g
n
i
s

s
m

r
e
t

l
l

a

s
u
p
r
o
c
n
i

s
t
e
s
n
y
s

y
r
e
u
q

s
m
y
n
o
p
y
h
+

s
n
u
o
n
t
n
e
c
a
j
d
a

s
e
g
a
s
s
a
p
d
e
k
n
a
r
-
p
o
t
n
i

y
r
e
u
q
t
n
e
d
n
e
p
e
d
n
i

k
b
d
f

c
o
h
d
a
+
s
m

r
e
t

n
i

s
m

r
e
t

l
l

a

s
c
o
d
d
e
k
n
a
r
-
p
o
t

n
i

s
m

r
e
t

l
l

a

s
c
o
d
d
e
k
n
a
r
-
p
o
t

n
i

s
m

r
e
t

l
l

a

s
c
o
d
d
e
k
n
a
r
-
p
o
t

n
i

s
m

r
e
t

l
l

a

s
c
o
d
d
e
k
n
a
r
-
p
o
t

t
n
e
m
u
c
o
d

n
o
i
t
a
z
i
r
a
m
m
u
s

l
a
c
i
x
e
l

s
e
i
t
i
n
   
f
a

y
r
e
u
q

n
o
i
t
a
i
c
o
s
s
a

d
e
s
a
b
-
n
o
i
s
s
e
s

c
o
d
-
y
r
e
u
q

n
o
i
t
a
l
e
r
r
o
c

s
m

r
e
t

t
n
e
c
a
j
d
a

t
x
e
t

r
o
h
c
n
a
n
i

+
n
o
i
t
a
c
   
i
s
s
a
l
c

e
s
a
r
h
p

s
t
p
e
c
n
o
c

t
e
n
d
r
o
w

s
m

r
e
t

y
b
r
a
e
n

s
c
o
d
d
e
k
n
a
r
-
p
o
t
n
i

a
t
a
d

e
c
r
u
o
s

s
u
p
r
o
c

t
e
n
d
r
o
w

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
c
o
d
d
e
k
n
a
r
-
p
o
t

e
c
n
e
r
e
f
e
r
d
o
h
t
e
m

]
3
9
9
1
i
e
r
f
d
n
a
u
i
q

[

]
4
9
9
1
s
e
e
h
r
o
o
v

[

]
6
9
9
1

t
f
o
r
c
d
n
a
u
x

[

]
8
9
9
1

.
l
a

t
e
a
r
t
i

m

[

s
c
o
d
d
e
k
n
a
r
-
p
o
t

]
8
9
9
1

.
l
a

t
e
n
o
s
t
r
e
b
o
r

[

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

g
o
l

y
r
e
u
q

g
o
l

y
r
e
u
q

s
u
p
r
o
c
+

r
o
h
c
n
a

s
t
x
e
t

+
s
c
o
d
d
e
k
n
a
r
-
p
o
t

t
e
n
d
r
o
w
+
s
u
p
r
o
c

s
c
o
d
d
e
k
n
a
r
-
p
o
t

]
1
0
0
2

t
f
o
r
c
d
n
a

o
k
n
e
r
v
a
l

[

]
a
1
0
0
2

y
t
r
e
f
f
a
l
d
n
a
i
a
h
z
[

]
1
0
0
2

.
l
a

t
e

o
t
e
n
i
p
r
a
c

[

]
1
0
0
2
s
e
n
o
j
d
n
a

a
n
i
s
e
d
a
m
a
l

-

[

]
3
0
0
2

.
l
a

t
e
k
c
e
b
r
e
l
l
i

b

[

]
2
0
0
2

.
l
a

t
e

l
e
m
r
a
c

[

]
4
0
0
2
n
e
i
z
d
n
a

t
f
a
r
k

[

]
3
0
0
2

.
l
a

t
e

i
u
c

[

]
4
0
0
2

.
l
a

t
e
u
i
l

[

]
5
0
0
2

.
l
a

t
e

i
a
b

[

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:30

c. carpineto and g. romano

d
e
d
n
a
p
x
e

h
p
a
r
g

y
r
e
u
q

d
e
t
a
l
o
p
r
e
t
n
i

l
e
d
o
m
y
r
e
u
q

y
r
e
u
q
d
e
r
u
t
c
u
r
t
s

d
e
t
a
l
o
p
r
e
t
n
i

l
e
d
o
m
y
r
e
u
q

d
e
t
a
l
o
p
r
e
t
n
i

l
e
d
o
m
y
r
e
u
q

)
i
i
i

l

e
b
a
t
m
o
r
f

d
e
u
n

i
t

n
o
c

(

t

s
d
o
h
e
m
e
q
a

l

a
r
e
v
e
s

f

o

n
o

i
t

i

l

a
c
   
s
s
a
c
e
n
f
a

i

.

v

i

l

e
b
a
t

y
r
e
u
q
d
e
d
n
a
p
x
e

n
o
i
t
a
t
n
e
s
e
r
p
e
r

y
r
e
u
q
n
a
e
l
o
o
b

n
o
i
t
c
e
l
e
s

e
r
u
t
a
e
f

d
o
h
t
e
m

e
r
u
t
a
e
f

e
t
a
d
i
d
n
a
c

n
o
i
t
a
t
n
e
s
e
r
p
e
r

e
r
u
t
a
e
f

e
t
a
d
i
d
n
a
c

d
o
h
t
e
m
n
o
i
t
c
a
r
t
x
e

n
o
i
t
a
i
c
o
s
s
a

s
e
l
u
r

e
u
l
a
v
-
e
t
u
b
i
r
t
t
a

s
r
i
a
p

d
n
a

e
l
b
a
t
b
e
w

g
n
i
n
i
m
m

r
o
f

a
t
a
d

e
c
r
u
o
s

s
u
p
r
o
c

e
c
n
e
r
e
f
e
r
d
o
h
t
e
m

]
5
0
0
2

.
l
a

t
e
n
n
a
m
p
u
a
r
g

[

f
o
f
n
d

s
e
s
a
r
h
p
d
e
z
i
r
o
g
e
t
a
c

n
i
a
g
n
o
i
t
a
m
r
o
f
n
i

g
n
i
t
h
g
i
e
w
m
r
e
t
+

n
o
i
t
a
l
e
r
r
o
c

s
t
h
g
i
e
w
d
e
s
a
b
-

l
a
u
t
u
m

n
o
i
t
a
m
r
o
f
n
i

s
e
s
a
r
h
p

e
s
a
r
h
p
y
e
k

n
o
i
t
c
a
r
t
x
e

s
d
r
o
w
e
l
g
n
i
s

n
i

s
m

r
e
t

s
u
p
r
o
c

l
l

a

y
r
e
u
q
d
e
r
u
t
c
u
r
t
s

n
i
a
h
c

v
o
k
r
a
m

s
d
r
o
w
e
l
g
n
i
s

c
i
t
s
i
l
i
b
a
b
o
r
p

n
o
i
t
a
i
c
o
s
s
a
m

r
e
t

k
r
o
w

t
e
n

e
g
a
u
g
n
a
l

y
r
e
u
q

n
o
i
t
a
n
i
b
m
o
c

l
e
d
o
m

+
m
e

+
n
o
i
t
a
c
   
i
s
s
a
l
c

y
r
e
u
q

n
o
i
t
a
m
r
o
f
n
i

l
a
u
t
u
m

d
e
t
h
g
i
e
w
n
u

s
m

r
e
t

l
a
c
i
t
s
i
t
a
t
s

n
o
i
t
a
l
s
n
a
r
t

e
n
i
h
c
a
m

s
n
o
i
t
s
e
u
q
f
o

s
e
s
a
r
h
p

s
d
r
o
w
e
l
g
n
i
s

n
i

s
e
s
a
r
h
p

s
r
e
w
s
n
a
q
a
f

+
s
m

r
e
t

s
m

r
e
t

y
b
r
a
e
n

+
r
e
m
m
e
t
s

s
u
p
r
o
c
+
t
e
n
d
r
o
w

s
c
o
d
d
e
k
n
a
r
-
p
o
t
+

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
u
p
r
o
c

q
a
f

a
t
a
d
g
n
i
n
i
a
r
t

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
n
i
a
m
o
d
r
e
s
u
+

+
o
i
h
c
c
o
r

d
e
n
i
b
m
o
c

s
e
r
o
c
s
r
f
d

s
d
l
e
   
n
o
r
f
d

s
d
r
o
w
e
l
g
n
i
s

n
i

s
m

r
e
t

l
l

a

d
n
a
s
t
x
e
t

r
o
h
c
n
a

s
c
o
d
d
e
k
n
a
r
-
p
o
t

+
s
t
x
e
t

r
o
h
c
n
a

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

l
e
d
o
m
e
c
n
a
v
e
l
e
r

s
d
r
o
w
e
l
g
n
i
s

m
u
m
i
x
a
m

d
o
o
h
i
l
e
k
i
l

+
s
d
r
o
w
e
l
g
n
i
s

s
t
p
e
c
n
o
c
d
r
o
w

i
t
l
u
m

v
o
k
r
a
m

s
d
l
e
   
m
o
d
n
a
r

f
o
g
n
i
r
e
t
s
u
l
c

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

]
5
0
0
2
n
a
l
l
a
c
d
n
a
n
o
s
p
m
o
h
t
-
s
n
i
l
l
o
c

[

]
6
0
0
2

.
l
a

t
e

g
n
o
s
[

]
6
0
0
2

.
l
a
t
e
u
h

[

]
7
0
0
2

.
l
a

t
e

r
e
l
z
e
i
r

[

]
7
0
0
2

.
l
a

t
e

i
a
b

[

]
7
0
0
2
t
f
o
r
c
d
n
a

r
e
l
z
t
e
m

[

]
7
0
0
2
s
i
n
u
o
d
n
a

e
h

[

]
8
0
0
2

.
l
a

t
e

e
e
l

[

+
k
n
a
r

c
o
d

y
c
n
e
u
q
e
r
f
k
n
i
l

s
e
s
a
r
h
p

s
t
x
e
t

r
o
h
c
n
a

d
e
k
n
a
r
-
p
o
t
n
i

s
c
o
d

a
i
d
e
p
i
k
i
w

n
o
i
t
a
c
   
i
s
s
a
l
c

m

r
e
t

s
d
r
o
w
e
l
g
n
i
s

l
e
d
o
m
e
c
n
a
v
e
l
e
r

s
d
r
o
w
e
l
g
n
i
s

n
i

s
m

r
e
t

l
l

a

s
c
o
d
d
e
k
n
a
r
-
p
o
t

n
i

s
m

r
e
t

l
l

a

s
e
l
c
i
t
r
a
d
e
k
n
a
r
-
p
o
t

s
c
o
d
d
e
k
n
a
r
-
p
o
t

s
u
p
r
o
c
+

a
i
d
e
p
i
k
i
w

]
8
0
0
2

.
l
a

t
e

o
a
c

[

]
9
0
0
2

.
l
a

t
e
u
x

[

a
i
d
e
p
i
k
i
w

]
8
0
0
2

.
l
a

t
e

o
l
l
e
u
g
r
a

[

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:31

table v. overview of trec collections. the meanings of the acronyms are the following:

wsj = wall street journal, ap = associated press newswire, ziff = computer select articles
(ziff-davis), fr = federal register, doe = abstracts of u.s. department of energy publications,

sjmn = san jose mercury news, pat = u.s. patents, ft = financial times,
cr = congressional record, fbis = foreign broadcast information service

description

size

(gigabytes)

number of mean number of

terms per doc

trec

collection

disk 1

disk 2

disk 3

disk 4

disk 5
wt10g

gov2

wsj (1986-1989), ap (1989)

fr (1989), ziff, doe

wsj (1990-1992), ap (1988)

fr (1989), ziff

sjmn (1991), ap (1990)

ziff, pat (1993)

ft (1991-1994), fr (1994)

cr (1993)

fbis, the la times

1997 crawl of the
internet archive

2004 crawl of
.gov domain

docs
510,637

231,219

336,310

293,710

262,367
1,692,096

1.2

0.8

1.1

1.1

0.9
10

446

25,205,179

348

555

481

547

535
412

691

because the experiments have sometimes been carried out in subtly different condi-
tions. to enable cross-comparison, we considered only the experiments performed

(a) on the full set of documents;
(b) on the full set of topics;
(c) using the title-only description of the topics;
(d) using the mean average precision as evaluation measure.

the results published in the literature have been summarized in table vi. in ad-
dition to the average precision of the single aqe methods, for each test collection we
listed the best baseline (a run of the ranking system without aqe) and true rele-
vance feedback when available. in particular, the penultimate row contains the best
performance of unexpanded queries (of those reported in the papers associated with
the corresponding column), while the last row shows the true relevance feedback per-
formance, taken from wong et al. [2008] for the trec6-7-8 collections (making use
of rocchio + chi-square scores) and from lee et al. [2008] for the other collections
(making use of cluster-based resampling). these latter    gures provide upper-bound
performance oneach collection (at least for aqe methods based on top retrieved doc-
uments), when we are able to choose better pseudo-relevant documents, approaching
true relevant documents.

first of all it should be noted that the best absolute results (displayed in bold) varied
widely across the various test collections. this phenomenon is evident looking at the
results achieved by the same aqe method for the different collections on which it
was tested. for instance, the performance of    information    ow    ranged from 0.266 (on
trec-1) to 0.394 (on trec-3). the variability of results can be explained considering
that the test collections have very different characteristics; e.g., in terms of size, noise,
heterogeneity of contents, dif   culty of topics, and so on.

the aqe methods in table vi belong to several categories described in the
preceding. the best results were achieved by four methods, namely    information
   ow    [bai et al. 2005] on trec1-2-3,    query contexts    on trec7-8 [bai et al. 2007],
   phrases + id138    [liu et al. 2004] on trec9-10-12, and    markov random    elds   
[metzler and croft 2007] on trec13 (robust track)-14. interestingly, each was

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:32

c. carpineto and g. romano

5
1
c
e
r
t

6
0
0
2

4
1
c
e
r
t

5
0
0
2

3
1
c
e
r
t

4
0
0
2

]

8
0
0
2

.
l

a

t

e
g
n
o
w

[

a
r
e
t

e
t
y
b

-
1
0
8

0
5
8

a
r
e
t

e
t
y
b

-
1
5
7

0
0
8

2
v
o
g

a
r
e
t

e
t
y
b

-
1
0
7

0
5
7

3
1
c
e
r
t

4
0
0
2

t
s
u
b
o
r

2
1
c
e
r
t

3
0
0
2

t
s
u
b
o
r

0
1
c
e
r
t

1
0
0
2

b
e
w

0
5
4
-
1
0
3

0
0
7
-
1
0
6

0
5
4
-
1
0
3

0
5
6
-
1
0
6

-
1
0
5

0
5
5

9
c
e
r
t

0
0
0
2

b
e
w

-
1
5
4

0
0
5

s
k
s
i
d

5

.
.
.

1

s
k
s
i
d

5

.
.
.

1

g
0
1
t
w

)

v
o
g

(

0
5
2

.

)
8
2
2
.
(

8
6
2

.

)
9
8
1
.
(

2
2
2

.

)
8
7
1
.
(

*
9
8
1

.

)
8
4
1
.
(

5
7
2

.

)
3
8
1
.
(

7
2
2

.

)
9
0
2
.
(

*
7
8
1

.

)
3
6
1
.
(

*
3
2
2

.

)
9
8
1
.
(

1
6
2

.

)
7
8
1
.
(

8
c
e
r
t

9
9
9
1

7
c
e
r
t

8
9
9
1

6
c
e
r
t

7
9
9
1

5
c
e
r
t

6
9
9
1

3
c
e
r
t

4
9
9
1

2
c
e
r
t

3
9
9
1

1
c
e
r
t

2
9
9
1

c
o
h
d
a

c
o
h
d
a

c
o
h
d
a

c
o
h
d
a

c
o
h
d
a

c
o
h
d
a

c
o
h
d
a

-
1
0
4

0
5
4

s
k
s
i
d

5

.
.
.

1

2
8
2

.

)
6
5
2
.
(

*
8
8
2

.

)
4
2
2
.
(

4
9
2

.

)
0
8
2
.
(

-
1
5
3

0
0
4

s
k
s
i
d

5

.
.
.

1

-
1
0
3

0
5
3

s
k
s
i
d

5

.
.
.

1

-
1
5
2

0
0
3

s
k
s
i
d

4

.
.
.

1

5
1
2

.

)
0
1
2
.
(

-
1
5
1

0
0
2

s
k
s
i
d

3

.
.
.

1

-
1
0
1

0
5
1

s
k
s
i
d

3
.
.
.
1

6
9
2
.

)
0
1
2
.
(

-
1
5

0
0
1

s
k
s
i
d

2
,
1

8
2
2
.

)
4
1
2
.
(

e
n

i
l

e
s
a
b
e
h

t

m
o
r
f

t

n
e
r
e

f
f
i

d
y
l
t

i

n
a
c
   
n
g
s
e
r
e
w

i

t

a
h

t

s
t
l

u
s
e
r
s
k
r
a
m

*

n
a

.
s
n
o

i
t
c
e

l
l

o
c

l

t
s
e
t
e
b
a
r
a
p
m
o
c
n
o

t

s
d
o
h
e
m
e
q
a

l

a
r
e
v
e
s

i

i

f
o
n
o
s
c
e
r
p
e
g
a
r
e
v
a
n
a
e
m

.
i

l

v
e
b
a
t

e
r
a
n
o

i
t
c
e

l
l

o
c
h
c
a
e

r
o

f

s
t
l

u
s
e
r
e
q
a

t
s
e
b
e
h
t

.
t
s
e
t
k
n
a
r
d
e
n
g
s
n
o
x
o
c
w
e
h

l
i

i

t

o

t

i

g
n
d
r
o
c
c
a
y

l
l

a
u
s
u

,
l

e
v
e
l
5
0
0

.

e
h

t

t

a

i

)
s
s
e
h
t
n
e
r
a
p
n

i

n
w
o
h
s

(

i

n
o
s
n
a
p
x
e
o
n

f

o

.
l

a

t

e

u
l

i

[

)
5
(

;
]

3
0
0
2

.
l

a

t

e
k
c
e
b
r
e

l
l
i

b

[

)
4
(

;
]

7
0
0
2
n
a

l
l

a
c
d
n
a
n
o
s
p
m
o
h
t
-
s
n

i
l
l

o
c

[

)
6
1
(

;
]

9
0
0
2

.
l

a

t

e

u
x

[

)
5
1
(

;
]

8
0
0
2

.
l

a

t

e
e
e
l

[

)
4
1
(

;
]

i

7
0
0
2
s
n
u
o
d
n
a

e
h

[

)
2
1
(

;
]

7
0
0
2

.
l

a

t

e

i

a
b

[

;
]
7
0
0
2

t
f
o
r
c
d
n
a

l

r
e
z
t
e
m

[

)
0
1
(

;
]

7
0
0
2

.
l

a

t

e
r
e
v
a
n
w

i

[

;
]

6
0
0
2

.
l

a

t

e

g
n
o
s

[

)
9
(

)
8
(

;
]

5
0
0
2

t

e

i

a
b

[

)
7
(

;
]

5
0
0
2
n
a

l
l

a
c
d
n
a
n
o
s
p
m
o
h
t
-
s
n

i
l
l

o
c

[

.
l

a

)
3
1
(

)
1
1
(

)
6
(

;
]

4
0
0
2

.
l

a

t

e

i
t

a
m
a

[

,
]

2
0
0
2

.
l

a

t

t

e
o
e
n
p
r
a
c

i

[

,
]

1
0
0
2

.
l

a

t

e

i
t

a
m
a

[

;
]

a
1
0
0
2

y
t
r
e

f
f

a
l
d
n
a

i

a
h
z

[

)
3
(

)
2
(

;
]
0
0
0
2

t
f
o
r
c
d
n
a

u
x

[

)
1
(

.

i

g
n
w
o

l
l

o
f
e
h

t

e
r
a

s
e
c
n
e
r
e
e
r
e
h
t

f

.

l

d
o
b
n

i

d
e
y
a
p
s
d

i

l

;
]
4
0
0
2

k
c
a
r
t

s
c
i
p
o
t

n
o
i
t
c
e
l
l
o
c

e
r
u
t
x
i
m

)
2
(
l
e
d
o
m

)
1
(
a
c
l

n
o
i
t
a
i
c
o
s
s
a

)
4
(
s
e
i
r
e
u
q

)
5
(
t
e
n
d
r
o
w

+
s
e
s
a
r
h
p

)
3
(
d
l
k

v
o
k
r
a
m

)
6
(
n
i
a
h
c

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:33

*
2
9
3

.

)
3
2
3
.
(

*
0
6
3

.

)
2
9
2
.
(

4
9
1

.

)
4
7
1
.
(

*
6
2
2

.

)
6
8
1
.
(

8
4
3

.

3
6
2

.

2
4
2

.

9
9
1

.

0
7
2

.

6
2
2

.

)
3
0
2
.
(

6
1
2

.

)
9
8
1
.
(

*
2
0
3

.

)
8
3
2
.
(

*
6
4
2

.

)
5
6
1
.
(

5
4
2

.

)
2
2
2
.
(

1
1
2

.

)
9
7
1
.
(

8
9
1

.

)
2
6
1
.
(

*
0
8
3

.

)
5
2
3
.
(

*
9
3
3

.

6
9
2

.

5
2
3

.

1
3
4

.

*
1
5
3

.

)
2
9
2
.
(

*
0
9
2

.

)
3
5
2
.
(

2
9
2

.

5
3
5

.

*
5
3
2

.

)
6
8
1
.
(

*
9
0
2

.

)
3
8
1
.
(

3
0
4

.

8
8
4

.

4
3
5

.

5
5
5

.

5
2
4

.

2
3
2

.

9
0
2

.

9
8
1

.

0
8
2

.

2
2
2

.

9
7
1

.

0
1
2

.

0
1
3

.

4
3
2
.

4
1
2
.

*
9
6
2

.

)
7
0
2
.
(

*
8
4
2

.

)
7
5
1
.
(

*
0
9
2

)
7
0
2
.
(

0
4
2
.

)
1
8
1
.
(

2
6
1
.

)
2
4
1
.
(

3
0
3

.

8
3
2
.

)
8
(
s
e
s
a
r
h
p
y
e
k

)
9
(
n
o
i
t
c
e
l
e
s

l
e
d
o
m

l
e
d
o
m

)
1
1
(
s
d
l
e
   
m
o
d
n
a
r

v
o
k
r
a
m

)
0
1
(
n
o
i
t
a
n
i
b
m
o
c

)
3
1
(
n
o
i
t
a
n
i
b
m
o
c

d
e
s
a
b
-
r
e
t
s
u
l
c

)
4
1
(
g
n
i
l
p
m
a
s
e
r

)
2
1
(
s
t
x
e
t
n
o
c

y
r
e
u
q

d
l
e
   

)
5
1
(

a
i
d
e
p
i
k
i
w

e
c
n
a
v
e
l
e
r

e
u
r
t

)
6
1
(
,
)
4
1
(
k
c
a
b
d
e
e
f

e
n
i
l
e
s
a
b
t
s
e
b

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

.
t

n
o
c

.
i

l

v
e
b
a
t

4
9
3

.

)
0
1
3
.
(

8
1
3

.

)
4
3
2
.
(

6
6
2

.

)
1
0
2
.
(

n
o
i
t
a
m
r
o
f
n
i

)
7
(
w
o
   

1:34

c. carpineto and g. romano

consistently better than other methods across all or most tested collections on which
it was tested. one thing common to these four methods is that they explicitly took
into account term-dependency, although using different techniques; in addition, they
primarily made use of top retrieved documents, possibly combined with other sources
of evidence, and were built on top of very effective baseline ranking systems.

it is important to note that such    ndings need to be taken with caution because
in table vi, we listed the absolute overall performance of the system, including, but
not limited to, the aqe component. an effective aqe method will clearly yield poor
results when combined with an ineffective basic ir system, and vice versa. in fact,
the underlying ranking methods employed in the experiments were usually very dif-
ferent and never exactly the same. the baseline performance    gures, when reported
in the papers, presented considerable variations. the    nal results achieved in [bai
et al. 2005], for instance, greatly bene   tted from a very high baseline performance
(e.g., 3107 on trec-3), even superior to that of the other methods with aqe. we
should also consider that even when performing strict single-word indexing and using
the same weighting function for document-ranking, there are a number of system-
speci   c factors that can signi   cantly alter the    nal retrieval performance, including
document parsing, stop wording, and id30. for instance, the removal of spuri-
ous, low-frequency words at indexing time from the trec-9 and trec-10 collections
was observed to be highly bene   cial because it reduced the number of typographical
errors in documents, which is one of the causes of poor id183 in noisy col-
lections. there is another issue that can complicate interpretation of results, namely,
that the parameters involved in each aqe method might have been optimized using
training data or other types of data not always readily or widely available.

8.3 other evaluation methods
to address the shortcomings of the classical aqe evaluation method based on overall
change in performance, a few new approaches have recently been proposed. in custis
and al-kofahi [2007], the idea is to measure the speci   c capability of the aqe com-
ponent in overcoming query-document term mismatch by purposefully degrading the
quality of the queries with respect to their relevant documents. in practice, query
terms are removed from relevant documents one by one in order of importance (e.g.,
from highest-to-lowest inverse document frequency) and the performance of the ir sys-
tems being evaluated (with or without id183) is measured in the standard
manner on the altered collections. this approach can be very useful when the use of
technical synonyms is the main issue for unsatisfactory information retrieval, as with
some domain-speci   c test collections. another alternative evaluation strategy, based
on the quality of query re   nement terms, consists of measuring the degree to which
such terms, when used as queries, are capable of retrieving different query aspects or
subtopics [nallapati and shah 2006]. this latter approach requires labeled documents
for the subtopics underlying the query   s topic.

besides evaluating the average retrieval performance, it is also important to con-
sider the robustness of the system. it is well known that the performance of aqe
presents a marked variability across queries.
in particular, while the majority of
queries are improved, some are hurt. evaluation of robustness has thus become com-
mon practice. the standard measure is the robustness index (ri), de   ned as the ratio
of the difference between the number of queries helped and of those hurt by aqe, to
the total number of queries. on trec data, the fraction of negatively affected queries
is of the order of 25% (ri = 0.5), if we use the same aqe method across several collec-
tions (e.g., metzler and croft [2007], collins-thompson [2009]).

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:35

9. computational efficiency
the total time necessary per performing aqe is the sum of two factors, namely the cost
of generating expansion features and the increased cost of evaluating the expanded
query against the collection, due to its larger size.

in practice, the latter factor is the most critical one. consider that most ranking
systems have a common architecture based on inverted lists, one for each each term
in the collection, where each inverted list speci   es which documents that particular
term occurs in, usually with a precomputed per-term score. at query time, the system
retrieves the inverted list of each query term and updates the score accumulators of
the documents present in each list. as query terms are processed one at a time, the
execution time of a ranked query is almost linearly dependent on the number of its
terms, as also con   rmed by experimental observations. for instance, in billerbeck
[2005] and lavrenko and allan [2006], aqe runs with sizes of practical interest
(ten   twenty words) were found to be much slower than those with original queries,
approximately by a factor of ten, yielding    nal response times on the order of hundreds
of milliseconds.

the techniques that have been developed for increasing the ef   ciency of evaluating
ranked queries are based on reducing the number and portion of inverted lists that
need to be processed in order to service a query; see e.g. witten et al. [1999] and
billerbeck [2005]. documents that are likely to score high are considered with higher
priority, and the processing is halted before the whole update has taken place; e.g., as
soon as a certain percentage of documents have been given entries in the accumulator
table for the current query. the two main strategies for implementing this priority
ranking are, (1) evaluating query terms in order of their importance (e.g., by their
inverse document frequency), and (2) sorting the documents in the inverted list of a
particular term by their relevance to the term (e.g, by their within-document term
frequency), followed by parallel execution of ordered inverted lists.

an interesting re   nement of such techniques is top-k query processing [theobald
et al. 2004, 2005]. the algorithm operates on the same score-sorted index as the previ-
ous, but in addition, it makes use of score-distribution statistics to estimate aggregated
scores of candidates and to perform early candidate pruning (when the id203
of being in the top-k results drops belowan acceptable error threshold). theoretical
and experimental evidence suggests that the use of these approximated faster ranking
techniques results in very limited, or even no, degradation of retrieval effectiveness
over unapproximated ranking.

rather than relying on pruning mechanisms, one can try to optimize the full execu-
tion of aqe. a recent method [bast and weber 2006] suggests precomputing a block-
based index, where a block is the union of the inverted lists associated with words that
are lexically close, and then adding this information as arti   cial words to the index
for direct use at query time. this index structure explicitly stores expanded inverted
lists; it allows faster query processing due to a reduction of random accesses to atomic
inverted lists. a similar technique has been applied to advertisement search, treating
bid phrases as keyword queries and ads as documents, and placing together in a same
block bid, phrases that shared a common pre   x [wang et al. 2009].

another method for improving the ef   ciency of unapproximated aqe, although
restricted to the id38 framework, is described in lavrenko and allan
[2006]; the problem of giant queries is improved by moving some of the computational
effort to indexing time via computation of a particular document similarity matrix.
overall, the utilization of the techniques illustrated in this section considerably in-
creased the ef   ciency of query evaluation, with gains of up to a factor of ten over the
traditional inverted index.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:36

c. carpineto and g. romano

turning to the cost of generating expansion features, it may have a very limited
impact on the    nal response time of the system for several aqe techniques such as
extraction of expansion features from query logs and anchor texts, construction of sim-
ilarity thesauri, and word id30. the reason is that all possible expansion features
are usually generated in advance (e.g., at indexing time, or of   ine with respect to the
underlying ranking system) and the computation left at query time is reduced to se-
lecting those that are appropriate to the current query. the main ef   ciency concern
for such techniques is rather that they may not scale well to large volumes of data due
to their inherent complexity (e.g., id91-based methods grow quadratically with
the collection size); this aspect is dif   cult to evaluate, given the lack of experimen-
tal analyses and because the relevant literature is somewhat elusive about the whole
ef   ciency issue.

of the aqe techniques summarized in the taxonomy in figure 4, only the query-
speci   c ones raise speci   c ef   ciency issues at query time, mainly due to their reliance
on a    rst-pass retrieval. the major bottleneck is fetching the full-text top documents
after they have been ranked according to the original query, because these documents
are usually stored on disk and disk access times are much slower than memory access
times. a more ef   cient approach is proposed in billerbeck and zobel [2004b], mak-
ing use of short document summaries to be kept in main memory in the form of a set
of terms with the highest tf-idf values. during querying, all terms in thesummaries
that have been ranked against the original query are then used forsourcing expansion
terms, thus bypassing disk access altogether and also avoiding the need of parsing the
raw documents. another possibility is to use an external source such as a web search
engine. downloading the full documents from the web would clearly be impractical,
but using the search result pages is an appealing alternative [kwok et al. 2004; yin
et al. 2009]. expansion based on snippetstakes advantage of the engine   s large-scale
query processing and results-cachinginfrastructure, but it may be subjected to techni-
cal limitations (e.g., maximum number of fetched results per query, maximum number
of queries per day).

9.1 which aqe method is best?
in general, linguistic techniques are considered less effective than those based on sta-
tistical analysis, whether global or local, because they require almost exact word sense
disambiguation, but statistical analysis may not always be applied (e.g., when good-
expansion terms do not frequently co-occur with the query terms). of the statistical
techniques, local analysis seems to perform better than corpus analysis because the
extracted features are query speci   c, while methods based on web data (query logs or
anchor texts) have not yet been systematically evaluated or compared with the others
on standard test collection. the results shown in table vi con   rm this perspective,
although they suggest that the single aqe paradigms have a high degree of comple-
mentarity that should be exploited to maximize retrieval performance.

from the point of view of computational ef   ciency, query-speci   c techniques need
a double run at query time while other forms of aqe are mostly performed in an
of   ine stage, but the inherent complexity of the latter techniques may prevent their
application in high dimensionality domains. besides effectiveness and ef   ciency, there
are other points that should be considered. query-speci   c techniques are dependent
on the quality of the    rst-pass retrieval, corpus-speci   c techniques are not suitable for
dynamic document collections, linguistic techniques and methods based on analysis of
query logs or hyperlinks make use of data that are not always available or suitable for
the ir task at hand. finally, some aqe techniques require the capability of evaluating
structured expanded queries.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:37

to summarize, there is a wide range of aqe techniques that present different fea-
tures and are mostly useful or applicable in certain situations. the best choice depends
on the evaluation of a number of factors, including type of collection being searched,
availability and characteristics of external data, facilities offered by the underlying
ranking system, type of queries, and ef   ciency requirements.

10. critical issues
in this section we discuss three key issues that pose obstacles for a widespread adop-
tion of aqe in a wider range of operational search systems: parameter setting, ef   -
ciency, and usability.

10.1 parameter setting
all aqe techniques rely on several parameters. for instance, for a typical pseudo-
relevance feedback method it is necessary to choose the number of pseudo-relevant
documents, the number of expansion terms, and the    balance coef   cient for query
reformulation. the retrieval performance of the overall method is usually markedly
dependent on the parameter setting.

the standard approach is to use    xed values for key parameters, determinedby    ne
tuning on test collections. but there are two main drawbacks. the    rst is that a    xed
value for all queries is probably not the best choice. queries have different charac-
teristics in terms of length, dif   culty, verbosity, ambiguity, and goal, and they should
receive an individual treatment. several experiments (e.g., carpineto et al. [2002],
billerbeck [2005]) showed that the use of    xed parameter values results in a heavy
penalization of average retrieval performance, compared to that theoretically obtain-
able with optimal query-based aqe, and it is probably one of the main reasons for the
unsatisfactory robustness of aqe. the second problem is that while such a tuning is
standard in benchmarkslike trec, it becomes very dif   cult for real search applica-
tions with highly dynamic corpora, unpredictable queries,and continuously evolving
search tasks (e.g., web ir, intranets,digital libraries, web communities, etc.)

this calls for automatic and self-adaptive query-based parameter setting. we will
see in the next section that this issue has started to be investigated but there are still
many challenges.

10.2 ef   ciency
the ef   cient evaluation of queries is essential for ir systems such as web search en-
ginesthat need to deliver real-time results to a very large numbers of users. while
the expansion feature generation stage can be carried out ef   ciently, the successive
execution of the expanded query may become too slow, as discussed in section 9. this
slowdown may prevent theadoption of aqe for real retrieval systems. it is also harm-
ful to research because far fewer runs    t into a particular window of time [lavrenko
and allan 2006]. faster aqe techniques would allow researchers to carry outmore
experiments and interactive studies to better understand the applicability and limita-
tions of this methodology.

there are three possible ways to address this issue:

    limit expansion features to a few important items and then rank the expanded query

in a standard way,

    allow for a possibly large number of expansion features, but prune features and doc-
uments that are unlikely to lead to an improved result when ranking the expanded
query,

    use ef   cient index structure (for applications when it is possible) that support nearly

full document ranking against nearly full expanded queries.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:38

c. carpineto and g. romano

the adoption of such approximated techniques usually involves a moderate trade-off
between speed and retrieval performance, although their overall adequacy ultimately
depends on the requirements posed by the search application.

10.3 usability
usability is probably another critical issue, although it has not received much atten-
tion so far. aqe acts like a black box employing hidden features that may considerably
complicate the interpretation of the logic used by the system to deliver results. for in-
stance, some web users may be unsatis   ed    nding documents (even relevant ones)
that do not contain the terms in their query. this happens sometimes, using aqe. for
example, a document may be returned because the anchor texts pointing to it contain
the query terms, or because a query term is subsumed by a more general term in the
document, according to a given ontology. when users obtain a result set that they
   nd inadequate, they have no explanation for why certain results not containing the
original query terms were ranked high so they have no easy way to improve the query.
a simple method to reduce the lack of transparency and increase user control over
the relationships between query and results is to display the list of expansion features
used by the system for ranking the documents. a more comprehensive approach would
be not only to show why certain search results have been obtained, but also to allow
some form of manipulation of query and results on the part of the user; e.g., revising
the expanded query, zooming in on results that are related to some expansion features,
and so on.

it is known [ruthven 2003] that expert users are capable of taking full advantage of
a query re   nement feature, whereas pure aqe is better for non-expert users. hybrid
strategies that integrate aqe and interactive search facilities might be more effective
for all types of users, but they have not been much investigated so far. a notable ex-
ception is bast et al. [2007], where the individual expansion terms and the number
of their associated hits are displayed automatically after each keystroke in the search
box, together with the best hits. a similar search paradigm has recently been fol-
lowed for improving content-based visual retrieval, using pairs formed by a re   nement
keyword and its associated representative images as single expansion features [zha
et al. 2009]. overall, the usability issue in aqe needs more research.

11. research directions
most current research effort aims at improving the retrieval effectiveness and robust-
ness of aqe. in this section we focus on three relatively well-established topics: selec-
tive aqe, evidence combination, and active feedback. other directions that are being
investigated are attempts to integrate personal [chirita et al. 2007] and negative rele-
vance feedback [bernardini and carpineto 2008; wang et al. 2008] information in the
aqe framework, as well as more sophisticated forms of implicit user feedback such as
eye tracking [buscher et al. 2008].

11.1 selective aqe
selective aqe aims to improve id183 with decision mechanisms based on
the characteristics of queries. based on the observation that some queries are hurt
by expansion, one simple strategy is to disable aqe if the query can be predicted
to perform poorly. however, it is not obvious which properties make a query suit-
able/unsuitable for aqe. for instance, easy (dif   cult) queries do not necessarily pro-
duce better (worse) performance, as there is no clear correlation between the average
precision that the original query achieves and by how much aqe improves average
precision [billerbeck and zobel 2003; carpineto et al. 2001; he and ounis 2009b].

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:39

the best known predictive function, termed clarity score [cronen-townsend and
croft 2002], is the id181 between the query model, estimated
from the top-ranked documents, and the collection model. in principle, the higher
the divergence, the better the retrieval performance that aqe can provide. experi-
mentally, however, a straightforward use of the clarity score is not always bene   cial.
perhaps, a more effective strategy is to use the difference between the clarity score
of theinitial query and that of the expanded query, yielding performance results com-
parable to ranking without aqe on the worst queries (those hurt by expansion) and
better than conventional aqe on the whole set of queries [amati et al. 2004].

rather than just disabling aqe when its application is deemed harmful, it may be
more convenient to apply different expansion strategies according to the type of query.
an interesting form of query-dependent aqe is presented in xu et al. [2009] using
wikipedia pages. queries are classi   ed in three types: (1) entity queries, if they match
the title of an entity or redirect page, (2) ambiguous queries, if they match the title
of a disambiguation page, and (3) broader queries in all other cases. for each type of
query, a different method of aqe is then carried out. another approach that exploits
a similar idea is described in fujii [2008]. queries are classi   ed as either navigational
or informational, making use of anchor-link distribution. navigational queries are
then handled by a particular anchor-based retrieval model that expands anchor terms
with their synonyms. focused expansions have also been applied in a federated search
setting, producing speci   c queries for each source [shokouhi et al. 2009].

11.2 evidence combination
distinct aqe methods usually produce different re   nements, with low to moderate
overlap [kraft and zien 2004]. even when the overlap is large, the ordered sets of
expansion features may be largely uncorrelated [carpineto et al. 2002]. if the re-
   nements suggested by the single methods are, on the whole, equally useful (e.g.,
they result in comparable average performance over a set of queries), one can try to
combine the most effective re   nements at the individual query level. this strategy
often works fairly well, with the combined method improving over all single
methods.

several combination methods have been proposed. two approaches, already men-
tioned, consist of selecting the most common terms of those produced by multiple term-
ranking functions [carpineto et al. 2002], or classifying as relevant or non-relevant the
terms produced by the same term-ranking function with different document samples
[collins-thompson and callan 2007]. in he and ounis [2007], the focus is on improv-
ing the quality of query term reweighting, rather than choosing the best terms, by
taking a linear combination of the term frequencies in three document    elds (title, an-
chor texts, body). all these combination methods were applied as an improvement of
pseudo-relevance feedback.

linguistically-oriented aqe techniques can also greatly bene   t from a combined
approach due to data sparsity: general-purpose resources are limited in coverage and
depth, but they can complement co-occurrence relations when the latter evidence is not
available or reliable. in liu et al. [2004], id138 concepts (synonyms and hyponyms)
are combined by heuristic rules with other expansion features extracted using global
and local statistical methods. in bai et al. [2007], multiple id183 models
are employed (using an external ontology, the whole collection, and the top retrieved
documents) and then they are combined by interpolation to yield the    nal expanded
query model

(cid:3)

p(t|  q) =

  i p(t|   i
q),

i

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

(14)

1:40

(cid:2)

c. carpineto and g. romano

i

with
  i = 1. the best settings of such mixture weights con   rmed that all models
affected the    nal performance, but the pseudo-relevance feedback model was largely
the most effective one. another two approaches that combine complex linguistic and
statistical features are discussed in collins-thompson and callan [2005] and metzler
and croft [2007]; both were reviewed in the preceding sections.

11.3 active feedback
in query-speci   c aqe techniques, treating the top documents as relevant is often not
the best strategy. for example, if the top documents have very similar contents, their
cumulative bene   t will not be very different from that attainable from any one of them.
the main approach for choosing more informative feedback documents is to empha-
size their diversity. several techniques have been proposed, such as reranking docu-
ments based on independent query concepts [mitra et al. 1998], using cluster centroids
or ranking gaps [shen and zhai 2005], skipping redundant documents [sakai et al.
2005], estimating uncertainty associated with a feedback model [collins-thompson
and callan 2007], and choosing documents that appear in multiple overlapping clus-
ters [lee et al. 2008]. diversity is always combined, explicitly or implicitly, with rele-
vance. in xu and akella [2007], a more comprehensive framework is presented, which
integrates relevance, diversity, and density, where density is measured as the average
distance of a document from all other documents.

in he and ounis [2009a], the authors present a machine learning approach to active
feedback, analogous to that used in cao et al. [2008] to select relevant expansion terms.
they classify the top-retrieved documents as good or bad, using various features such
as the distribution of query terms in the document and the proximity between the
expansion terms and the original query terms in the document. to train the classi   er,
they use top-retrieved documents labeled as good or bad depending on whether they
improve or hurt retrieval performance when used as feedback documents.

usually, it is assumed that the collection from which to extract the documents for
aqe is    xed. selection from a multidatabase corpus is an interesting larger-scale form
of document selection. it turns out that analyzing the databases separately can be
better than treating the corpus as one large database, with substantial improvements
if the best database is chosen [gauch et al. 1999]. the most appropriate database can
be chosen by running the query against the individual databases and analyzing the
search results [gauch et al. 1999] or by more ef   cient, preretrieval query performance
predictors [hauff et al. 2008; he and ounis 2007]. besides optimizing the choice of
the best feedback documents, one can also focus on their best parts. an earlier textual
form of this approach is passage selection [xu and croft 1996]; other aqe methods
suitable for web pages involve more sophisticated features such as visual clues [yu
et al. 2003] or tables and forms [graupmann et al. 2005].

12. conclusions
although there is no silver bullet for the vocabulary problem in ir, aqe has the po-
tential to overcome one of the main limitations of current search systems usage: the
reluctance and the dif   culty of users in providing a more precise description of their in-
formation needs. in the last ten years, aqe has made a big leap forward, by leveraging
diverse data sources and inventing more principled and effective methods. nowadays
a spectrum of techniques is available (e.g., linguistic, corpus-speci   c, query-speci   c,
based on search logs, and on web data) that cater to different requirements in terms of
query type, computational ef   ciency, availability of external data, and characteristics
of the underlying ranking system.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:41

the advance of aqe techniques has been con   rmed by a number of experimental
tests on classical benchmarks. remarkable improvements in average retrieval effec-
tiveness have been reported in most evaluation studies, with gains not only in recall
but also in precision, at least for some types of queries.

in spite of such good results, aqe still suffers from drawbacks that have limited its
deployment as a standard component in search systems. the key aspects that need
to be improved are the robustness of retrieval performance, the automatic setting of
parameters, the computational ef   ciency of executing larger queries, and the usability
of an ir system implementing aqe. these limitations have started to be addressed in
recent research, together with the exploration of new directions.

among the most promising trends are the development of aqe methods that ex-
plicitly take into account term dependency (e.g., through a combination of statistical
and linguistic techniques), the utilization of search query languages that allow for
structured expanded queries, and the injection of interactive facilities into the ba-
sic aqe framework. hybrid methods achieved the best results on the experimental
benchmarks and seem, in principle, more robust with respect to variation of queries,
document collections, and users. equally important are the exploration and learning
of adaptive techniques. query-dependent criteria can be used to optimize the amount
of expansion, the type of reformulation, the setting of parameters, and the selective
application of aqe.

in summary, aqe may be at a turning point after about forty years of research. it
has reached a level of scienti   c maturity and there are signs that it is moving beyond
its experimental status and being adopted in operating systems. this article will hope-
fully help to make aqe better known and more widely accepted and used in the search
market.

acknowledgments

we are very grateful to three anonymous reviewers for their excellent comments and suggestions.

references
agichtein, e., lawrence, s., and gravano, l. 2004. learning to    nd answers to questions on the web.

acm trans. on internet technol. 4, 2, 1299   162.

agirre, e., ansa, o., arregi, x., de lacalle, m. l., otegi, a., saralegi, x., and saragoza, h.
2009. elhuyar-ixa: semantic relatedness and cross-lingual passage retrieval. in proceedings of clef.
springer.

agirre, e., di nunzio, g. m., mandl, t., and otegi, a. 2009. clef 2009 ad hoc track overview: robust   

wsd task. in proceedings of clef. springer.

agrawal, r., imielinski, t., and swami, a. 1993. mining association rules between sets of items in large
databases. in proceedings of the acm sigmod international conference on management of data. acm
press, 207   216.

allan, j. 1996. incremental relevance feedback for information    ltering. in proceedings of the 19th annual
international acm sigir conference on research and development in information retrieval. acm
press, 270   278.

amati, g. 2003. probabilistic models for information retrieval based on divergence from randomness. ph.d.

thesis, department of computing science, university of glasgow, uk.

amati, g., carpineto, c., and romano, g. 2001. fub at trec-10 web track: a probabilistic
framework for topic relevance term weighting. in proceedings of the 10th text retrieval conference
(trec   10). nist special publication 500   250. national institute of standards and technology (nist),
gaithersburg, md, 182   191.

amati, g., carpineto, c., and romano, g. 2003. comparing weighting models for monolingual informa-
tion retrieval. in proceedings of the 4th workshop of the cross-language evaluation forum (clef   03).
springer, 310   318.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:42

c. carpineto and g. romano

amati, g., carpineto, c., and romano, g. 2004. query dif   culty, robustness, and selective application
of id183. in proceedings of the 26th european conference on information retrieval (ecir   04).
springer, 127   137.

anderson, j. r. 1983. a spreading activation theory of memory. j. verbal learn. verbal behav. 22,

261   295.

arguello, j., elsas, j. l., callan, j., and carbonell, j. g. 2008. id194 and
id183 models for blog recommendation. in proceedings of the 2nd international conference
on weblogs and social media. aaai press, 10   18.

attar, r. and fraenkel, a. s. 1977. local feedback in full-text retrieval systems. j. acm 24, 3, 397   417.
baeza-yates, r. and ribeiro-neto, b. 1999. modern information retrieval. addison wesley.
bai, j., nie, j.-y., and cao, g. 2006. context-dependent term relations for information retrieval. in
proceedings of the conference on empirical methods in natural language processing. association for
computational linguistics, 551   559.

bai, j., song, d., bruza, p., nie, j.-y., and cao, g. 2005. id183 using term relationships in
language models for information retrieval. in proceedings of the 14th acm international conference on
information and knowledge management. acm press, 688   695.

bai, j., nie, j.-y., cao, g., and bouchard, h. 2007. using query contexts in information retrieval. in
proceedings of the 30th annual international acm sigir conference on research and development in
information retrieval. acm press, 15   22.

ballesteros, l. and croft, w. b. 1997. phrasal translation and id183 techniques for cross-
language information retrieval. in proceedings of the 20th annual international acm sigir conference
on research and development in information retrieval. acm press, 84   91.

ballesteros, l. and croft, w. b. 1998. resolving ambiguity for cross-language retrieval. in proceedings
of the 21st annual international acm sigir conference on research and development in information
retrieval. acm press, 64   71.

bast, h. and weber, i. 2006. type less,    nd more: fast autocompletion search with a succinct index. in
proceedings of the 29th annual international acm sigir conference on research and development in
information retrieval. acm press, 364   371.

bast, h., majumdar, d., and weber, i. 2007. ef   cient interactive id183 with complete search.
in proceedings of the 30th annual international acm sigir conference on research and development
in information retrieval. acm press, 857   860.

beeferman, d. and berger, a. 2000. agglomerative id91 of a search engine query log. in proceed-
ings of the 6th acm sigkdd international conference on knowledge discovery and data mining. acm
press, 407   416.

belkin, n. j. and croft, w. b. 1992. information    ltering and information retrieval: two sides of the

same coin? comm. acm 35, 12, 29   38.

bernardini, a. and carpineto, c. 2008. fub at trec 2008 relevance feedback track: extending rocchio
with distributional term analysis. in proceedings of trec-2008. national institute of standards and
technology, gaithersburg, md, usa.

bernardini, a., carpineto, c., and d   amico, m. 2009. full-subtopic retrieval with keyphrase-based
search results id91. in proceedings of the ieee/wic/acm international conference on web
intelligence. ieee computer society, 206   213.

bhogal, j., macfarlane, a., and smith, p. 2007. a review of ontology based id183. info.

process. manage. 43, 4, 866   886.

billerbeck, b. 2005. ef   cient id183. ph.d. thesis, rmit university, melbourne, australia.
billerbeck, b. and zobel, j. 2003. when id183 fails. in proceedings of the 26th annual in-
ternational acm sigir conference on research and development in informaion retrieval. acm press,
387   388.

billerbeck, b. and zobel, j. 2004a. questioning id183: an examination of behaviour and
parameters. in proceedings of the 15th australasian database conference. vol. 27, australian computer
society, 69   76.

billerbeck, b. and zobel, j. 2004b. techniques for ef   cient id183. in proceedings of the

string processing and information retrieval symposium. springer, 30   42.

billerbeck, b. and zobel, j. 2005. document expansion versus id183 for ad-hoc retrieval. in
proceedings of the 10th australasian document computing symposium. australian computer society,
sydney, australia, 34   41.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:43

billerbeck, b., scholer, f., williams, h. e., and zobel, j. 2003. id183 using associ-
ated queries. in proceedings of the 12th acm international conference on information and knowledge
management. acm press, 2   9.

bilotti, m., katz, b., and lin, j. 2004. what works better for id53: id30 or morpho-
logical id183? in proceedings of the information retrieval for id53 (ir4qa)
workshop at sigir   04.

bodoff, d. and kambil, a. 1998. partial coordination. i. the best of pre-coordination and post-

coordination. j. amer. soc. info. sciences 49, 14, 1254   1269.

broder, a. 2002. a taxonomy of web search. acm sigir forum 36, 2, 3   10.
broder, a., ciccolo, p., e.gabrilovich, josifovski, v., metzler, d., riedel, l., and yuan, j.
2009. online expansion of rare queries for sponsored search. in proceedings of the 18th international
conference on world wide web. acm, 511   520.

buckley, c. and harman, d. k. 2003. reliable information access    nal workshop report. in proceedings

of the reliable information access workshop (ria). nrrc, 1   30.

buckley, c., salton, g., allan, g., and singhal, a. 1995. automatic id183 using smart:
trec3. in proceedings of the 3rd text retrieval conference (trec-3). nist special publication
500   226. national institute of standards and technology (nist), gaithersburg, md, 69   80.

buscher, g., dengel, a., and van elst, l. 2008. id183 using gaze-based feedback on the
subdocument level. in proceedings of the 31th annual international acm sigir conference on research
and development in information retrieval. acm press, 387   394.

cao, g., gao, j., nie, j.-y., and bai, j. 2007. extending query translation to cross-language query expan-
sion with markov chain models. in proceedings of the 16th conference on information and knowledge
management (cikm   07). acm press.

cao, g., gao, j., nie, j.-y., and robertson, s. 2008. selecting good expansion terms for pseudo-
relevance feedback. in proceedings of the 31st annual international acm sigir conference on research
and development in information retrieval. acm press, 243   250.

carmel, d., farchi, e., petruschka, y., and soffer, a. 2002. automatic query re   nement using
lexical af   nities with maximal information gain. in proceedings of the 25th annual international acm
sigir conference on research and development in information retrieval. acm press, 283   290.

carpineto, c. and romano, g. 2004. concept data analysis: theory and applications. john wiley &

sons.

carpineto, c., de mori, r., romano, g., and bigi, b. 2001. an information theoretic approach to

automatic id183. acm trans. info. syst. 19, 1, 1   27.

carpineto, c., romano, g., and giannini, v. 2002. improving retrieval feedback with multiple

term-ranking function combination. acm trans. info. syst. 20, 3, 259   290.

carpineto, c., osi   nski, s., romano, g., and weiss, d. 2009. a survey of web id91 engines. acm

comput. surv. 41, 3.

chang, y., ounis, i., and kim, m. 2006. query reformulation using automatically generated query

concepts from a document space. info. process. manage. 42, 2, 453   468.

chen, l., l   abbate, m., thiel, u., and neuhold, e. j. 2004. increasing the customers choice: query
expansion based on the layer-seeds method and its application in e-commerce. in proceedings of the
ieee international conference on e-technology, e-commerce and e-service (eee   04). ieee computer
society, 317   324.

chirita, p.-a., firan, c. s., and nejdl, w. 2007. personalized id183 for the web. in
proceedings of the 30th annual international acm sigir conference on research and development
in information retrieval. acm press, 7   14.

chu, w. w., liu, z., and mao, w. 2002. textual document indexing and retrieval via knowledge sources

and data mining. comm. institute of info. comput. machinery 5, 2.

church, k. and hanks, p. 1990. word association norms, mutual information and id69. compu-

tat. linguist. 16, 1, 22   29.

church, k. and smyth, b. 2007. mobile content enrichment. in proceedings of the 12th international

conference on intelligent user interfaces. acm press, 112   121.

collins-thompson, k. 2009. reducing the risk of id183 via robust constrained optimization.
in proceedings of the 18th conference on information and knowledge management (cikm   09). acm
press, 837   846.

collins-thompson, k. and callan, j. 2005. id183 using random walk models. in pro-
ceedings of the 14th conference on information and knowledge management (cikm   05). acm press,
704   711.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:44

c. carpineto and g. romano

collins-thompson, k. and callan, j. 2007. estimation and use of uncertainty in pseudo-relevance
feedback. in proceedings of the 30th annual international acm sigir conference on research and
development in information retrieval. acm press, 303   310.

crabtree, d., andreae, p., and gao, x. 2007. exploiting underrepresented query aspects for automatic
id183. in proceedings of the 13th acm sigkdd international conference on knowledge dis-
covery and data mining. acm press, 191   200.

crestani, f. 1997. application of spreading activation techniques in information retrieval. artif. intell.

11, 6, 453   482.

cronen-townsend, s. and croft, w. b. 2002. quantifying query ambiguity. in proceedings of the 2nd

international conference on human language technology research. acm press, 104   109.

crouch, c. and yang, b. 1992. experiments in automatic statistical thesaurus construction. in pro-
ceedings of the 15th annual international acm sigir conference on research and development in
information retrieval. acm press, 77   88.

cui, h., wen, j.-r., nie, j.-y., and ma, w.-y. 2003. id183 by mining user logs. ieee trans.

knowl. data engin. 15, 4, 829   839.

custis, t. and al-kofahi, k. 2007. a new approach for evaluating id183: query-document
term mismatch. in proceedings of the 30th annual international acm sigir conference on research
and development in information retrieval. acm press, 575   582.

deerwester, s., dumais, s. t., furnas, w., landauer, t. k., and harshman, r. 1990. indexing by

latent semantic analysis. j. amer. soc. info. science 41, 6, 391   407.

dempster, a., laird, n., and rubin, d. 1977. maximum likelihood from incomplete data via the em

algorithm. j. royal statist. soc. series b (methodological) 39, 1, 1   38.

diaz, f. and metzler, d. 2006. improving the estimation of relevance models using large external cor-
pora. in proceedings of the 29th annual international acm sigir conference on research and devel-
opment in information retrieval. acm press, 154   161.

doszkocs, t. e. 1978. aid, an associative interactive dictionary for online searching. online rev. 2, 2,

163   174.

efron, m. 2008. id183 and id84: notions of optimality in rocchio

relevance feedback and id45. info. process. manage. 44, 1, 163   180.

efthimiadis, e. n. 1993. a user-centred evaluation of ranking algorithms for interactive id183.
in proceedings of the 16th annual international acm sigir conference on research and development
in information retrieval. acm press, 146   159.

efthimiadis, e. n. 1996. id183. in annual review of information systems and technology,

m. e. williams ed., asis&t, 121   187.

finkelstein, l., gabrilovich, e., matias, y., rivlin, e., solan, z., wolfman, g., and ruppin, e.

2002. placing search in context: the concept revisited. acm trans. info. syst. 20, 1, 116   131.

fitzpatrick, l. and dent, m. 1997. automatic feedback using past queries: social searching? in
proceedings of the 20th annual international acm sigir conference on research and development
in information retrieval. acm press, 306   313.

flemmings, r., barros, j., geraldo, a. p., and moreira, v. p. 2009. bbk-ufrgs@clef2009: query

expansion of geographic place names. in proceedings of clef.

fujii, a. 2008. modeling anchor text and classifying queries to enhance web document retrieval. in

proceeding of the 17th international conference on world wide web. acm press, 337   346.

furnas, g. w., landauer, t. k., gomez, l. m., and dumais, s. t. 1987. the vocabulary problem in

human-system communication. comm. acm 30, 11, 964   971.

gauch, s., wang, j., and rachakonda, s. m. 1999. a corpus analysis approach for automatic query

expansion and its extension to multiple databases. acm trans. info. syst. 17, 3, 250   269.

gong, z., cheang, c.-w., and u, l. 2006. multi-term web id183 using id138. in proceedings
of the 17th international conference on database and id109 applications (dexa   06). springer,
379   388.

gonzalo, j., verdejo, f., chugur, i., and cigarr   an, j. m. 1998. indexing with id138 synsets can
improve text retrieval. in proceedings of the coling/acl workshop on usage of id138 in natural
language processing systems. association for computational linguistics, 647   678.

graupmann, j., cai, j., and schenkel, r. 2005. automatic query re   nement using mined semantic
relations. in proceedings of the international workshop on challenges in web information retrieval and
integration (wiri). ieee computer society, 205   213.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:45

hanani, u., shapira, b., and shoval, p. 2004. information    ltering: overview of issues, research and

systems. user model. user-adapt. interact. 11, 3, 203   259.

harabagiu, s. and lacatusu, f. 2004. strategies for advanced id53. in proceedings of the

hlt- naacl   04 workshop on pragmatics of id53. 1   9.

harabagiu, s., moldovan, d., pasca, m., mihalcea, r., surdeanu, m., bunescu, r., grju, r.,
rus, v., and morarescu, p. 2001. the role of lexico-semantic feedback in open-domain textual
question-answering. in proceedings of the 39th annual meeting of the association for computational
linguistics (acl-01). association for computational linguistics, 282   289.

harman, d. k. 1992. relevance feedback and other query modi   cation techniques. in information
retrieval     id206, w. b. frakes and r. baeza-yates eds., prentice hall,
englewood cliffs, n. j., 241   263.

harper, g. w. and van rijsbergen, c. j. 1978. an evaluation of feedback in document retrieval using

co-occurrence data. j. documentation 34, 3, 189   216.

hauff, c., hiemstra, d., and de jong, f. 2008. a survey of pre-retrieval query performance predictors.
in proceedings of the 17th conference on information and knowledge management (cikm   08). acm
press, 1419   1420.

he, b. and ounis, i. 2007. combining    elds for id183 and adaptive id183. info.

process. manage. 43, 1294   1307.

he, b. and ounis, i. 2009a. finding good feedback documents. in proceedings of the 18th conference on

information and knowledge management (cikm   09). acm press, 2011   2014.

he, b. and ounis, i. 2009b. studying id183 effectiveness. in proceedings of the 31th european

conference on information retrieval (ecir   09). springer, 611   619.

hidalgo, j. m. g., de buenaga rodr  iguez, m., and p   erez, j. c. c. 2005. the role of word sense
disambiguation in automated text categorization. in proceedings of the 10th international conference
on applications of natural language to information systems. springer, 298   309.

hu, j., deng, w., and guo, j. 2006. improving retrieval performance by global analysis. in proceedings of

the 18th international conference on pattern recognition. ieee computer society, 703   706.

huang, c.-c., chien, l.-f., and oyang, y.-j. 2003. relevant term suggestion in interactive web search
based on contextual information in query session logs. j. amer. soc. info. science technol. 54, 7, 638   649.
huang, c.-c., lin, k.-m., and chien, l.-f. 2005. automatic training corpora acquisition through web
mining. in proceedings of the ieee/wic/acm international conference on web intelligence. ieee com-
puter society, 193   199.

hull, d. a. 1996. id30 algorithms: a case study for detailed evaluation. j. amer. soc. info.

science 47, 1, 70   84.

ide, e. 1971. new experiments in relevance feedback. in the smart retrieval system, g. salton ed.,

prentice hall, englewood cliffs, n. j., 337   354.

jelinek, f. and mercer, r. l. 1980. interpolated estimation of markov source parameters from sparse
data. in proceedings of the workshop on pattern recognition in practice. north-holland, amsterdam,
the netherlands, 381   397.

joachims, t., granka, l., pan, b., hembrooke, h., radlinski, f., and gay, g. 2007. evaluating the
accuracy of implicit feedback from clicks and query reformulations in web search. acm trans. info.
syst. 25, 2, 7.

jones, r., rey, b., madani, o., and greiner, w. 2006. generating query substitutions. in proceedings

of the 15th international conference on world wide web. acm press, 387   396.

jones, s. 1993. a thesaurus data model for an intelligent retrieval system. j. info. science 19, 3, 167   178.
jones, s. 1995. interactive thesaurus navigation: intelligence rules ok? j. amer. soc. for info. science 46, 1,

52   59.

kamvar, m. and baluja, s. 2007. the role of context in query input: using contextual signals to complete
queries on mobile devices. in proceedings of the 9th international conference on human computer
interaction with mobile devices and services. acm press, 405   412.

kanaan, g., al-shalabi, r., ghwanmeh, s., and bani-ismail, b. 2008. interactive and automatic
id183: a comparative study with an application on arabic. amer. j. appl. sciences 5, 11,
1433   1436.

kek   al   ainen, j. and j   arvelin, k. 1998. the impact of query structure and id183 on retrieval
performance. in proceedings of the 21st annual international acm sigir conference on research and
development in information retrieval. acm press, 130   137.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:46

c. carpineto and g. romano

kherfi, m. l., ziou, d., and bernardi., a. 2004. id162 from the world wide web: issues,

techniques, and systems. acm comput. surv. 36, 1, 35   67.

koehn, p. 2010. id151. cambridge university press.
kraaij, w., nie, j., and simard, m. 2003. embedding web-based statistical translation models in cross-

language information retrieval. computat. linguist. 29, 3, 381   420.

kraft, r. and zien, j. 2004. mining anchor text for query re   nement. in proceedings of the 13th interna-

tional conference on world wide web. acm press, 666   674.

krovetz, r. 1993. viewing morphology as an id136 process. in proceedings of the 16th annual inter-
national acm sigir conference on research and development in information retrieval. acm press,
191   202.

krovetz, r. and croft, w. b. 1992. lexical ambiguity and information retrieval. acm trans. info. syst.

10, 2, 115   141.

kurland, o., lee, l., and domshlak, c. 2005. better than the real thing?: iterative pseudo-query pro-
cessing using cluster-based language models. in proceedings of the 28th annual international acm
sigir conference on research and development in information retrieval. acm press, 19   26.

kwok, k. l., grunfeld, l., sun, k. l., and deng, p. 2004. trec2004 robust track experiments using
pircs. in proceedings of the 13th text retrieval conference (trec-8). national institute of standards
and technology, gaithersburg, md.

lam-adesina, a. m. and jones, g. j. f. 2001. applying summarization techniques for term selection in
relevance feedback. in proceedings of the 24th annual international acm sigir conference on research
and development in information retrieval. 1   9.

latiri, c. c., yahia, s. b., chevallet, j. p., and jaoua, a. 2004. id183 using fuzzy associa-
tion rules between terms. in proceedings of the 4th international conference journ  ees de l   informatique
messine (jim   03).

lau, r. y. k., bruza, p. d., and song, d. 2004. belief revision for adaptive information retrieval. in
proceedings of the 27th annual international acm sigir conference on research and development in
information retrieval. acm press, 130   137.

lau, t. and horvitz, e. 1999. patterns of search: analyzing and modeling web query re   nement. in

proceedings of the 7th international conference on user modeling. springer, 119   128.

lavelli, a., sebastiani, f., and zanoli, r. 2004. distributional term representations: an experimen-
tal comparison. in proceedings of the 16th conference on information and knowledge management
(cikm   04). acm press, 615   624.

lavrenko, v. and allan, j. 2006. realtime id183 in relevance models. ir 473, university of

massachusetts.

lavrenko, v. and croft, w. b. 2001. relevance based language models. in proceedings of the 24th annual
international acm sigir conference on research and development in information retrieval. acm
press, 120   127.

lee, k. s., croft, w. b., and allan, j. 2008. a cluster-based resampling method for pseudo-relevance
feedback. in proceedings of the 31th annual international acm sigir conference on research and
development in information retrieval. acm press, 235   242.

lesk, m. e. 1969. word-word associations in document retrieval systems. amer. documentation 20, 1,

8   36.

lesk, m. e. 1988. they said true things, but called them by wrong names     vocabulary problems over time

in retrieval. in proceedings of the waterloo oed conference. acm press, 1   10.

lin, j. and murray, g. c. 2005. assessing the term independence assumption in blind relevance feedback.
in proceedings of the 28th annual international acm sigir conference on research and development
in information retrieval. acm press, 635   636.

liu, s., liu, f., yu, c., and meng, w. 2004. an effective approach to document retrieval via utilizing word-
net and recognizing phrases. in proceedings of the 27th annual international acm sigir conference
on research and development in information retrieval. acm press, 266   272.

liu, y., li, c., zhang, p., and xiong, z. 2008. a id183 algorithm based on phrases semantic
similarity. in proceedings of the international symposiums on information processing. ieee computer
society, 31   35.

lv, y. and zhai, c. 2009. adaptive relevance feedback in information retrieval. in proceedings of the 18th

conference on information and knowledge management (cikm   09). acm press, 255   264.

macdonald, c. and ounis, i. 2007. expertise drift and id183 in expert search. in proceedings

of the 16th conference on information and knowledge management (cikm   07). acm press.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:47

mandala, r., takenobu, t., and hozumi, t. 1998. the use of id138 in information retrieval. in
proceedings of the acl workshop on the usage of id138 in information retrieval. association for
computational linguistics, 31   37.

mandala, r., tokunaga, t., and tanaka, h. 1999. combining multiple evidence from different types of
thesaurus for id183. in proceedings of the 22nd annual international acm sigir conference
on research and development in information retrieval. acm press, 191   197.

manning, c. d., raghavan, p., and sch     utze, h. 2008. introduction to information retrieval.

cambridge university press.

maron, m. e. and kuhns, j. l. 1960. on relevance, probabilistic indexing and information retrieval. j.

acm 7, 3, 216   244.

mcnamee, p. and mayfield, j. 2002. comparing cross-language id183 techniques by degrad-
ing translation resources. in proceedings of the 25th annual international acm sigir conference on
research and development in information retrieval. acm press, 159   166.

melucci, m. 2008. a basis for information retrieval

article no 14.

in context. acm trans. info. syst. 26, 3,

metzler, d. and croft, w. b. 2007. latent concept expansion using markov random    elds. in pro-
ceedings of the 30th annual international acm sigir conference on research and development in
information retrieval. acm press, 311   318.

miller, g. a., beckwith, r. t., fellbaum, c. d., gross, d., and miller, k. 1990. id138: an

online lexical database. int. j. id69 3, 4, 235   244.

milne, d. n., witten, i. h., and nichols, d. m. 2007. a knowledge-based search engine powered by
wikipedia. in proceedings of the 16th acm conference on information and knowledge management.
acm press, 445   454.

minker, j., wilson, g. a., and zimmerman, b. h. 1972. an evaluation of id183 by the addi-

tion of clustered terms for a document retrieval system. info. stor. retrieval 8, 6, 329   348.

mitra, m., singhal, a., and buckley, c. 1998. improving automatic id183. in proceedings
of the 21st annual international acm sigir conference on research and development in information
retrieval. acm press, 206   214.

montague, m. and aslam, j. 2001. relevance score id172 for metasearch. in proceedings of the

10th international conference on information and knowledge management. acm press, 427   433.

nallapati, r. and shah, c. 2006. evaluating the quality of query re   nement suggestions in information

retrieval. ir 521, university of massachusetts.

natsev, a., haubold, a., te   si   c, j., xie, l., and yan, r. 2007. semantic concept-based query expan-
sion and re-ranking for multimedia retrieval. in proceedings of the 15th international conference on
multimedia. acm press, 991   1000.

navigli, r. 2009. id51: a survey. acm comput. surv. 41, 2, 1   69.
navigli, r. and velardi, p. 2003. an analysis of ontology-based id183 strategies. in proceed-

ings of the ecml/pkdd-2003 workshop on adaptive text extraction and mining.

navigli, r. and velardi, p. 2005. structural semantic interconnections: a knowledge-based approach to

id51. ieee trans. pattern anal. mach. intell. 27, 7, 1075   1086.

osi   nski, s. and weiss, d. 2005. a concept-driven algorithm for id91 search results. ieee intell.

syst. 20, 3, 48   54.

palleti, p., karnick, h., and mitra, p. 2007. personalizedweb search using probabilistic query expan-
sion. in proceedings of the ieee/wic/acm international conference on web intelligence. ieee com-
puter society, 83   86.

park, l. a. f. and ramamohanarao, k. 2007. id183 using a collection dependent probabilistic
latent semantic thesaurus. in proceedings of the 11th paci   c-asia conference on knowledge discovery
and data mining (pakdd   07). springer, 224   235.

perugini, s. and ramakrishnan, n. 2006. interacting with web hierarchies. it professional 8, 4, 19   28.
pirkola, a., hedlund, t., keskusalo, h., and j   arvelin, k. 2001. dictionary-based cross-language

information retrieval: problems, methods, and research    ndings. info. retrieval 4, 209   230.

porter, m. f. 1982. implementing a probabilistic information retrieval system. info. technol.: resear. de-

velop. 1, 2, 131   156.

porter, m. f. 1997. an algorithm for suf   x stripping. in readings in information retrieval, k. s. jones

and p. willett eds., morgan kaufmann, 313   316.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:48

c. carpineto and g. romano

qiu, y. and frei, h.-p. 1993. concept-based id183. in proceedings of the 16th annual inter-
national acm sigir conference on research and development in information retrieval. acm press,
160   169.

riezler, s., vasserman, a., tsochantaridis, i., mittal, v., and liu, y. 2007. statistical machine
translation for id183 in answer retrieval. in proceedings of the 45th annual meeting of
the association for computational linguistics (acl-07). association for computational linguistics,
464   471.

robertson, s. e. 1986. on relevance weight estimation and id183. j. documentation 42, 3,

182   188.

robertson, s. e. 1990. on term selection for id183. j. documentation 46, 4, 359   364.
robertson, s. e. and sparck jones, k. 1976. relevance weighting of search terms. j. amer. soc. info.

science 27, 129   146.

robertson, s. e. and walker, s. 2000. microsoft cambridge at trec-9: filtering track. in proceedings
of the 9th text retrieval conference (trec-9). nist special publication 500-249. national institute of
standards and technology (nist), gaithersburg, md, 361   368.

robertson, s. e., walker, s., and beaulieu, m. m. 1998. okapi at trec-7: automatic ad hoc,    ltering,
vlc, and interactive track. in proceedings of the 7th text retrieval conference (trec-7), nist spe-
cial publication 500-242. national institute of standards and technology (nist), gaithersburg, md,
253   264.

rocchio, j. j. 1971. relevance feedback in information retrieval. in the smart retrieval system,

g. salton ed., prentice-hall, englewood cliffs, nj, 313   323.

ruthven, i. 2003. re-examining the potential effectiveness of interactive id183. in proceedings
of the 26th annual international acm sigir conference on research and development in information
retrieval. acm press, 213   220.

ruthven, i. and lalmas, m. 2003. a survey on the use of relevance feedback for information access

systems. knowl. engin. rev. 18, 2, 95   145.

sahlgren, m. 2005. an introduction to random indexing. in proceedings of the methods and applications
of semantic indexing workshop at the 7th international conference on terminology and knowledge
engineering.

sakai, t., manabe, m., and koyama, m. 2005. flexible pseudo-relevance feedback via selective sampling.

acm trans. info. syst. 4, 2, 111   35.

salton, g. and buckley, c. 1990. improving retrieval performance by relevance feedback. j. amer. soc.

info. science 41, 4, 288   297.

salton, g. and mcgill, m. 1983. introduction to modern information retrieval. mcgraw hill,

new york, ny.

sanderson, m. 1994. id51 and information retrieval. in proceedings of the 17th
annual international acm sigir conference on research and development in information retrieval.
acm press, 142   151.

sanderson, m. 2000. retrieving with good sense. info. retrieval 2, 1, 49   69.
savoy, j. 2005. comparative study of monolingual and multilingual search models for use with asian lan-

guages. acm trans. asian lang. info. process. 4, 2, 163   189.

schlaefer, n., ko, j., betteridge, j., sautter, g., and amd e. nyberg, m. p. 2007. semantic ex-
tensions of the ephyra qa system for trec 2007. in proceedings of the 16th text retrieval conference
(trec   07). nist special publication 500-274. national institute of standards and technology (nist),
gaithersburg, md, 332   341.

sch   utze, h. and pedersen, j. o. 1995. information retrieval based on word senses. in proceedings of the

4th annual symposium on document analysis and information retrieval. 161   175.

sch   utze, h. and pedersen, o. 1997. a co-occurrence based thesaurus and two applications to informa-

tion retrieval. info. process. manage. 33, 3, 307   318.

semeraro, g., lops, p., basile, p., and de gemmis, m. 2009. on the tip of my thought: playing the
guillotine game. in proceedings of the 21st international joint conference on arti   cial intelligence. aaai
press, 1543   1548.

shen, x. and zhai, c. 2005. active feedback in ad hoc information retrieval. in proceedings of the 28th
annual international acm sigir conference on research and development in information retrieval.
acm press, 59   66.

shokouhi, m., azzopardi, l., and thomas, p. 2009. effective id183 for federated search. in
proceedings of the 32nd annual international acm sigir conference on research and development in
information retrieval. acm press, 427   434.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

automatic id183 in information retrieval

1:49

singhal, a. and pereira, f. 1999. document expansion for speech retrieval. in proceedings of the 22nd
annual international acm sigir conference on research and development in information retrieval.
acm press, 34   41.

song, m., song, i.-y., allen, r. b., and obradovic, z. 2006. keyphrase extraction-based query ex-
pansion in digital libraries. in proceedings of the 6th acm/ieee-cs joint international conference on
digital libraries (jcdl   06). acm press, 202   209.

song, m., song, i.-y., hu, x., and allen, r. b. 2007. integration of association rules and ontologies for

semantic id183. data knowl. engin. 63, 1, 63   75.

sun, r., ong, c.-h., and chua, t.-s. 2006. mining dependency relations for id183 in passage
retrieval. in proceedings of the 29th annual international acm sigir conference on research and
development in information retrieval. acm press, 382   389.

suryanto, m. a., lim, e.-p., sun, a., and chiang, r. h. 2007. document expansion versus query expan-
sion for ad-hoc retrieval. in proceedings of the acm 1st workshop on cyberinfrastructure: information
management in escience. acm press, 47   54.

theobald, m., shenkel, r., and weikum, g. 2004. top-k query evaluation with probabilistic guar-
antees. in proceedings of the 13th international conference on very large data bases. acm press,
648   659.

theobald, m., shenkel, r., and weikum, g. 2005. ef   cient and selftuning incremental query expan-
sion for top-k query processing. in proceedings of the 28th annual international acm sigir conference
on research and development in information retrieval. acm press, 242   249.

van rijsbergen, c. j. 1979. information retrieval. butterworths.
vechtomova, o. 2009. id183 for information retrieval. in encyclopedia of database systems,

l. liu and m. t.   ozsu eds., springer, 2254   2257.

vechtomova, o. and karamuftuoglu, m. 2004. elicitation and use of relevance feedback information.

info. process. manage. 42, 1, 191   206.

v   eronis, j. 2004. hyperlex: lexical cartography for information retrieval. computer speech lang. 18, 3,

223   252.

voorhees, e. 1993. using id138 to disambiguate word senses for text retrieval. in proceedings of
the 16th annual international acm sigir conference on research and development in information
retrieval. acm press, 171   180.

voorhees, e. 1994. id183 using lexical-semantic relations. in proceedings of the 17th annual
international acm sigir conference on research and development in information retrieval. acm
press, 61   69.

voorhees, e. 2004. overview of the trec 2004 robust track. in proceedings of the 13th text retrieval con-
ference (trec-7). nist special publication 500-261. national institute of standards and technology
(nist), gaithersburg, md.

voorhees, e. and harman, d. 1998. overview of the seventh text retrieval conference (trec-7). in
proceedings of the 7th text retrieval conference (trec-7). nist special publication 500-242. national
institute of standards and technology (nist), gaithersburg, md, 1   24.

wang, h., liang, y., fu, l., xue, g.-r., and yu, y. 2009. ef   cient id183 for advertise-
ment search. in proceedings of the 32nd annual international acm sigir conference on research and
development in information retrieval. acm press, 51   58.

wang, x., fang, h., and zhai, c. 2008. a study of methods for negative relevance feedback. in proceedings
of the 31th annual international acm sigir conference on research and development in information
retrieval. acm press, 219   226.

wei, x. and croft, w. b. 2007. modeling term associations for ad-hoc retrieval performance within lan-
guage modeling framework. in proceedings of the 29th european conference on ir research (ecir   07).
springer, 52   63.

white, r. w., ruthven, i., and jose, j. m. 2005. a study of factors affecting the utility of implicit
relevance feedback. in proceedings of the 28th annual international acm sigir conference on research
and development in information retrieval. acm press, 35   42.

winaver, m., kurland, o., and domshlak, c. 2007. towards robust id183: model selection
in the id38 framework. in proceedings of the 30th annual international acm sigir
conference on research and development in information retrieval. acm press, 729   730.

witten, i. h., moffat, a., and bell, t. c. 1999. managing gigabytes: compressing and indexing docu-

ments and images 2nd ed. morgan kaufman.

wong, s. k. m., ziarko, w., raghavan, v. v., and wong, p. c. n. 1987. on modeling of information

retrieval concepts in vector spaces. acm trans. datab. syst. 12, 2, 299   321.

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

1:50

c. carpineto and g. romano

wong, w. s., luk, r. w. p., leong, h. v., ho, k. s., and lee, d. l. 2008. re-examining the effects
of adding relevance information in a relevance feedback environment. info. process. manage. 44, 3,
1086   1116.

xu, j. and croft, w. b. 1996. id183 using local and global document analysis. in proceedings
of the 19th annual international acm sigir conference on research and development in information
retrieval. acm press, 4   11.

xu, j. and croft, w. b. 2000. improving the effectiveness of information retrieval with local context

analysis. acm trans. info. syst. 18, 1, 79   112.

xu, y., jones, g. j. f., and wang, b. 2009. query dependent pseudo-relevance feedback based on
wikipedia. in proceedings of the 32nd annual international acm sigir conference on research and
development in information retrieval. acm press, 59   66.

xu, z. and akella, r. 2007. incorporating diversity and density in active learning for relevance feedback.

in proceedings of the 29th european conference on ir research (ecir   07). springer, 246   257.

xue, g.-r., zeng, h.-j., chen, z., yu, y., ma, w.-y., xi, w., and fan, w. 2004. optimizing web search
using web click-through data. in proceedings of the 13th acm international conference on information
and knowledge management. acm press, 118   126.

yin, z., shokouhi, m., and craswell, n. 2009. id183 using external evidence. in proceedings

of the 31th european conference on information retrieval (ecir   09). springer, 362   374.

yu, s., cai, d., wen, j. r., and ma, w. y. 2003. improving pseudo-relevance feedback in web information
retrieval using web page segmentation. in proceedings of the 12th international conference on world
wide web. acm, 11   18.

zelikovitz, s. and hirsh, h. 2000. improving short-text classi   cation using unlabeled background
knowledge to assess document similarity. in proceedings of the 17th international conference on
machine learning (icml   00). national institute of standards and technology (nist), 1183   1190.

zha, z.-j., yang, l., mei, t., wang, m., and wang, z. 2009. visual query suggestion. in proceedings of

the 17th acm international conference on multimedia. acm press, 15   24.

zhai, c. and lafferty, j. 2001a. model-based feedback in the id38 approach to information
retrieval. in proceedings of the 10th international conference on information and knowledge manage-
ment. acm press, 403   410.

zhai, c. and lafferty, j. 2001b. a study of smoothing methods for language models applied to ad
hoc information retrieval. in proceedings of the 24th annual international acm sigir conference on
research and development in information retrieval. acm press, 334   342.

zimmer, c., tryfonopoulos, c., and weikum, g. 2008. exploiting correlated keywords to improve ap-
proximate information    ltering. in proceedings of the 31th annual international acm sigir conference
on research and development in information retrieval. acm press, 323   330.

received november 2009; revised february 2010; accepted march 2010

acm computing surveys, vol. 44, no. 1, article 1, publication date: january 2012.

