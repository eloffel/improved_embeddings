contents

1 high-dimensional space

2
4
1.1 properties of high-dimensional space . . . . . . . . . . . . . . . . . . . . .
5
1.2 the high-dimensional sphere . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2.1 the sphere and the cube in higher dimensions . . . . . . . . . . .
6
1.2.2 volume and surface area of the unit sphere . . . . . . . . . . . . .
1.2.3 the volume is near the equator
9
. . . . . . . . . . . . . . . . . . .
1.2.4 the volume is in a narrow annulus . . . . . . . . . . . . . . . . . . 11
. . . . . . . . . . . . . . . . 11
1.2.5 the surface area is near the equator
1.3 the high-dimensional cube and cherno    bounds . . . . . . . . . . . . . . 13
1.4 volumes of other solids
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
1.5 generating points uniformly at random on the surface of a sphere . . . . 19
1.6 gaussians in high dimension . . . . . . . . . . . . . . . . . . . . . . . . . 20
1.7 random projection and the johnson-lindenstrauss theorem . . . . . . . . 26
1.8 bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.9 exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

1

1 high-dimensional space

consider representing a document by a vector each component of which corresponds to
the number of occurrences of a particular word in the document. the english language
has on the order of 25,000 words. thus, such a document is represented by a 25,000-
dimensional vector. the representation of a document is called the word vector model [?].
a collection of n documents may be represented by a collection of 25,000-dimensional vec-
tors, one vector per document. the vectors may be arranged as columns of a 25, 000    n
matrix.

another example of high-dimensional data arises in customer-product data. if there
are 1,000 products for sale and a large number of customers, recording the number of
times each customer buys each product results in a collection of 1,000-dimensional vec-
tors.

there are many other examples where each record of a data set is represented by a
high-dimensional vector. consider a collection of n web pages that are linked. a link
is a pointer from one web page to another. each web page can be represented by a 0-
1 vector with n components where the jth component of the vector representing the ith
web page has value 1, if and only if there is a link from the ith web page to the jth web page.

in the vector space representation of data, properties of vectors such as dot products,
distance between vectors, and orthogonality often have natural interpretations. for ex-
ample, the squared distance between two 0-1 vectors representing links on web pages is
the number of web pages to which only one of them is linked. in figure 1.2, pages 4 and
5 both have links to pages 1, 3, and 6 but only page 5 has a link to page 2. thus, the
squared distance between the two vectors is one.

when a new web page is created a natural question is which are the closest pages
to it, that is the pages that contain a similar set of links. this question translates to
the geometric question of    nding nearest neighbors. the nearest neighbor query needs
to be answered quickly. later in this chapter we will see a geometric theorem, called the
random projection theorem, that helps with this. if each web page is a d-dimensional
vector, then instead of spending time d to read the vector in its entirety, once the random
projection to a k-dimensional space is done, one needs only read k entries per vector.

dot products also play a useful role. in our    rst example, two documents containing
many of the same words are considered similar. one way to measure co-occurrence of
words in two documents is to take the dot product of the vectors representing the two
documents. if the most frequent words in the two documents co-occur with similar fre-
quencies, the dot product of the vectors will be close to the maximum, namely the product
of the lengths of the vectors. if there is no co-occurrence, then the dot product will be
close to zero. here the objective of the vector representation is information retrieval.

2

figure 1.1: a document and its term-document vector along with a collection of docu-
ments represented by their term-document vectors.

after preprocessing the document vectors, we are presented with queries and we want to
   nd for each query the most relevant documents. a query is also represented by a vector
which has one component per word; the component measures how important the word is
to the query. as a simple example, to    nd documents about cars that are not race cars, a
query vector will have a large positive component for the word car and also for the words
engine and perhaps door and a negative component for the words race, betting, etc. here
dot products represent relevance.

an important task for search algorithms is to rank a collection of web pages in order
of relevance to the collection. an intrinsic notion of relevance is that a document in a
collection is relevant if it is similar to the other documents in the collection. to formalize
this, one can de   ne an ideal direction for a collection of vectors as the line of best-   t,
or the line of least-squares    t, i.e., the line for which the sum of squared perpendicular
distances of the vectors to it is minimized. then, one can rank the vectors according to
their dot product similarity with this unit vector. we will see in chapter ?? that this
is a well-studied notion in id202 and that there are e   cient algorithms to    nd
the line of best    t. thus, this ranking can be e   ciently done. while the de   nition of
rank seems ad-hoc, it yields excellent results in practice and has become a workhorse for
modern search, information retrieval, and other applications.

notice that in these examples, there was no intrinsic geometry or vectors, just a
collection of documents, web pages or customers. geometry was added and is extremely
useful. our aim in this book is to present the reader with the mathematical foundations
to deal with high-dimensional data. there are two important parts of this foundation.
the    rst is high-dimensional geometry along with vectors, matrices, and id202.
the second more modern aspect is the combination with id203. when there is a
stochastic model of the high-dimensional data, we turn to the study of random points.
again, there are domain-speci   c detailed stochastic models, but keeping with our objective
of introducing the foundations, the book presents the reader with the mathematical results
needed to tackle the simplest stochastic models, often assuming independence and uniform
or gaussian distributions.

3

(1,0,1,0,0,1)

(1,1,1,0,0,1)

web page 4

web page 5

figure 1.2: two web pages as vectors. the squared distance between the two vectors is
the number of web pages linked to by just one of the two web pages.

1.1 properties of high-dimensional space

our intuition about space was formed in two and three dimensions and is often mis-
leading in high dimensions. consider placing 100 points uniformly at random in a unit
square. each coordinate is generated independently and uniformly at random from the
interval [0, 1]. select a point and measure the distance to all other points and observe
the distribution of distances. then increase the dimension and generate the points uni-
formly at random in a 100-dimensional unit cube. the distribution of distances becomes
concentrated about an average distance. the reason is easy to see. let x and y be two
such points in d-dimensions. the distance between x and y is

(cid:118)(cid:117)(cid:117)(cid:116) d(cid:88)

i=1

|x     y| =

(xi     yi)2.

since(cid:80)d

i=1 (xi     yi)2 is the summation of a number of independent random variables of
bounded variance, by the law of large numbers the distribution of |x    y|2 is concentrated
about its expected value. contrast this with the situation where the dimension is two or
three and the distribution of distances is spread out.

for another example, consider the di   erence between picking a point uniformly at
random from the unit-radius circle and from a unit radius sphere in d-dimensions.
in
d-dimensions the distance from the point to the center of the sphere is very likely to be
between 1     c
d and 1, where c is a constant independent of d. furthermore, the    rst
coordinate, x1, of such a point is likely to be between     c   
and + c   
, which we express
by saying that most of the mass is near the equator. the equator perpendicular to the
x1 axis is the set {x|x1 = 0}. we will prove these facts in this chapter.

d

d

4

best    t line

figure 1.3: the best    t line is that line that minimizes the sum of perpendicular distances
squared.

1.2 the high-dimensional sphere

one of the interesting facts about a unit-radius sphere in high dimensions is that
as the dimension increases, the volume of the sphere goes to zero. this has important
implications. also, the volume of a high-dimensional sphere is essentially all contained
in a thin slice at the equator and is simultaneously contained in a narrow annulus at the
surface. there is essentially no interior volume. similarly, the surface area is essentially
all at the equator. these facts are contrary to our two or three-dimensional intuition;
they will be proved by integration.

1.2.1 the sphere and the cube in higher dimensions

consider the di   erence between the volume of a cube with unit-length sides and the
volume of a unit-radius sphere as the dimension d of the space increases. as the dimen-
   
sion of the cube increases, its volume is always one and the maximum possible distance
d. in contrast, as the dimension of a unit-radius sphere
between two points grows as
increases, its volume goes to zero and the maximum possible distance between two points
stays at two.

note that for d=2, the unit square centered at the origin lies completely inside the

unit-radius circle. the distance from the origin to a vertex of the square is

(cid:113)

(cid:113)

2)2
( 1

+( 1

2)2

=

   

2

2

   = 0.707

2)2
( 1

+( 1

2)2

+( 1

2)2

+( 1

2)2 = 1

and thus the square lies inside the circle. at d=4, the distance from the origin to a vertex
of a unit cube centered at the origin is

and thus the vertex lies on the surface of the unit 4-sphere centered at the origin. as the
dimension d increases, the distance from the origin to a vertex of the cube increases as
   
d
2 , and for large d, the vertices of the cube lie far outside the unit sphere. figure 1.5
   
d
illustrates conceptually a cube and a sphere. the vertices of the cube are at distance
2

5

(cid:113) d

2

1

   

2

1

1

1
2

1
2

1

1
2

figure 1.4: illustration of the relationship between the sphere and the cube in 2, 4, and
d-dimensions.

(cid:113) d

nearly all of the volume

2

1

1
2

unit sphere

vertex of hypercube

figure 1.5: conceptual drawing of a sphere and a cube.

from the origin and for large d lie outside the unit sphere. on the other hand, the mid
point of each face of the cube is only distance 1/2 from the origin and thus is inside the
sphere. for large d, almost all the volume of the cube is located outside the sphere.

1.2.2 volume and surface area of the unit sphere

for    xed dimension d, the volume of a sphere is a function of its radius and grows as
rd. for    xed radius, the volume of a sphere is a function of the dimension of the space.
what is interesting is that the volume of a unit sphere goes to zero as the dimension of
the sphere increases.

to calculate the volume of a sphere, one can integrate in either cartesian or polar

6

d   

dr

r

rd   1d   

dr

figure 1.6: in   nitesimal volume in d-dimensional sphere of unit radius.

coordinates. in cartesian coordinates the volume of a unit sphere is given by

x1=1(cid:90)

   
1   x2

1

(cid:90)

x2=

x1=   1

x2=   

   
1   x2

1

   

(cid:90)

xd=

1   x2

1            x2

d   1

1   x2

1            x2

d   1

v (d) =

dxd        dx2dx1.

since the limits of the integrals are complex, it is easier to integrate using polar coordi-
nates. in polar coordinates, v (d) is given by

      
xd=      
(cid:90)
1(cid:90)

v (d) =

rd   1d   dr.

sd

r=0

here, d    is the surface area of the in   nitesimal piece of the solid angle sd of the unit
sphere. see figure 1.6. the convex hull of the d    piece and the origin form a cone. at
radius r, the surface area of the top of the cone is rd   1d    since the surface area is d     1
dimensional and each dimension scales by r. the volume of the in   nitesimal piece is base
times height, and since the surface of the sphere is perpendicular to the radial direction
at each point, the height is dr giving the above integral.

since the variables     and r do not interact,

(cid:90)

1(cid:90)

(cid:90)

v (d) =

d   

the question remains, how to determine the surface area a (d) =(cid:82)

r=0

sd

sd

d

d    =

.

d   ?

rd   1dr =

1
d

a(d)

consider a di   erent integral

   (cid:90)

   (cid:90)

   (cid:90)

e

      

sd

   (x2

1+x2

2+      x2

d)dxd        dx2dx1.

i (d) =

      

      

      

7

          (cid:90)

      

      d

   (cid:90)

(cid:90)

sd

0

   (cid:90)

1
2

   (cid:82)

0

including the exponential allows one to integrate to in   nity rather than stopping at the
surface of the sphere. thus, i(d) can be computed by integrating in cartesian coordi-
nates. integrating in polar coordinates relates i(d) to the surface area a(d). equating
the two results for i(d) gives a(d).

first, calculate i(d) by integration in cartesian coordinates.

i (d) =

e   x2dx

=(cid:0)   

  (cid:1)d =   

d
2

next, calculate i(d) by integrating in polar coordinates. the volume of the di   erential
element is rd   1d   dr. thus

i (d) =

d   

e   r2rd   1dr.

the integral (cid:82)

sd

integral gives

d    is the integral over the entire solid angle and gives the surface area,

a(d), of a unit sphere. thus, i (d) = a (d)

e   r2rd   1dr. evaluating the remaining

e   r2rd   1dr =

0
and hence, i(d) = a(d) 1
factorial function for noninteger values of x.    (x) = (x     1)    (x     1),    (1) =    (2) = 1,

(cid:1) where the gamma function    (x) is a generalization of the

  

2

0

   
  . for integer x,    (x) = (x     1)!.

and   (cid:0) 1

(cid:1) =

2

e   tt

d

2     1dt =

1
2

   (cid:90)
2  (cid:0) d

2

(cid:18) d

(cid:19)

combining i (d) =   

d
2 with i (d) = a (d) 1

a (d) =

this establishes the following lemma.

2  (cid:0) d
(cid:1) yields
(cid:1) .
2  (cid:0) d

  

d
2

2

1

2

lemma 1.1 the surface area a(d) and the volume v (d) of a unit-radius sphere in d-
dimensions are given by

  (cid:0) d

2   d

2

(cid:1)

2

a (d) =

2   (cid:0) d

   d

2

d

2

(cid:1) .

and

v (d) =

8

3
2

= 4

  
2)
  ( 3

v (3) = 2
3

to check the formula for the volume of a unit sphere, note that v (2) =    and
3  , which are the correct volumes for the unit spheres in two and
three dimensions. to check the formula for the surface area of a unit sphere, note that
   
a(2) = 2   and a(3) = 2  
= 4  , which are the correct surface areas for the unit sphere
in two and three dimensions. note that    d
factorial of d

(cid:1) grows as the

2 and   (cid:0) d

2 is an exponential in d

2 . this implies that lim

d       v (d) = 0, as claimed.

3
2
  

1
2

2

1.2.3 the volume is near the equator

consider a high-dimensional unit sphere and    x the north pole on the x1 axis at
x1 = 1. divide the sphere in half by intersecting it with the plane x1 = 0. the in-
tersection of the plane with the sphere forms a region of one lower dimension, namely
{x||x|     1, x1 = 0} which we call the equator. the intersection is a sphere of dimension
d-1 and has volume v (d     1). in three dimensions this region is a circle, in four dimen-
sions the region is a three-dimensional sphere, etc. in general, the intersection is a sphere
of dimension d     1.

it turns out that essentially all of the mass of the upper hemisphere lies between the
plane x1 = 0 and a parallel plane, x1 =   , that is slightly higher. for what value of   
does essentially all the mass lie between x1 = 0 and x1 =   ? the answer depends on the
). to see this, calculate the volume of the portion
dimension. for dimension d it is o(
of the sphere above the slice lying between x1 = 0 and x1 =   . let t = {x||x|     1, x1       }
be the portion of the sphere above the slice. to calculate the volume of t , integrate over
x1 from    to 1. the incremental volume is a disk of width dx1 whose face is a sphere of
1 (see figure 1.7) and, therefore, the surface area of the

dimension d-1 of radius(cid:112)1     x2

d   1

1   

disk is

thus,

(cid:0)1     x2

1

1(cid:90)

  

volume (t ) =

2 v (d     1) .

(cid:1) d   1

(cid:0)1     x2
(cid:1) d   1

1

2 v (d     1) dx1 = v (d     1)

(cid:0)1     x2

1

(cid:1) d   1

2 dx1.

1(cid:90)

  

note that v (d) denotes the volume of the d-dimensional unit sphere. for the volume
of other sets such as the set t , we use the notation volume(t ) for the volume. the
above integral is di   cult to evaluate so we use some approximations. first, we use the
inequality 1 + x     ex for all real x and change the upper bound on the integral to be
in   nity. since x1 is always greater than    over the region of integration, we can insert
x1/   in the integral. this gives

volume (t )     v (d     1)

    d   1
e

2 x2

1dx1     v (d     1)

    d   1
e

2 x2

1dx1.

x1
  

   (cid:90)

   (cid:90)

  

  

9

dx1

x1

1

(cid:112)1     x2

1 radius

(d     1)-dimensional sphere

figure 1.7: the volume of a cross-sectional slab of a d-dimensional sphere.

now,(cid:82) x1e    d   1

2 x2

1 dx1 =     1

1 and, hence,

d   1e    d   1
2 x2
volume (t )     1

    d   1

2   2

  (d   1)e

v (d     1) .

(1.1)

next, we lower bound the volume of the entire upper hemisphere. clearly the volume of
the upper hemisphere is at least the volume between the slabs x1 = 0 and x1 = 1   
,
d   1
. the
which is at least the volume of the cylinder of radius
d     1 times the d     1-dimensional volume of the disk r =
d   1 and so

}. now r is a d     1-dimensional sphere of radius

   
volume of the cylinder is 1/
{x| |x|     1; x1 = 1   
d   1
its volume is

d   1 and height

1     1

1     1

(cid:113)

d   1

1   

(cid:113)

(cid:18)

volume(r) = v (d     1)

1     1
d     1

using (1     x)a     1     ax

volume(r)     v (d     1)

(cid:18)

1     1
d     1

d     1
2

v (d     1).

.

(cid:19)(d   1)/2
(cid:19)

=

1
2

thus, the volume of the upper hemisphere is at least

v (d     1). the fraction of
the volume above the plane x1 =    is upper bounded by the ratio of the upper bound on
the volume of the hemisphere above the plane x1 =    to the lower bound on the total
volume. this ratio is

2   2 which leads to the following lemma.

   
1
d   1
2

e    d   1

   
2
(d   1)

  

lemma 1.2 for any c > 0, the fraction of the volume of the hemisphere above the plane
x1 = c   

is less than 2

c e   c2/2.

d   1

proof: substitute

c   

d   1

for    in the above.

for a large constant c, 2

of the volume of the d-dimensional sphere of radius r lies within distance o(r/

c e   c2/2 is small. the important item to remember is that most
d) of the

   

10

r

0( r   

d

)

figure 1.8: most of the volume of the d-dimensional sphere of radius r is within distance
o( r   

) of the equator.

d

equator as shown in figure 1.8.

for c     2, the fraction of the volume of the hemisphere above x1 = c   
d   1

2e   8     3    10   4. essentially all

than e   2     0.14 and for c     4 the fraction is less than 1
the mass of the sphere lies in a narrow slice at the equator. note that we selected a unit
vector in the x1 direction and de   ned the equator to be the intersection of the sphere with
a (d     1)-dimensional plane perpendicular to the unit vector. however, we could have
selected an arbitrary point on the surface of the sphere and considered the vector from
the center of the sphere to that point and de   ned the equator using the plane through
the center perpendicular to this arbitrary vector. essentially all the mass of the sphere
lies in a narrow slice about this equator also.

is less

1.2.4 the volume is in a narrow annulus

the ratio of the volume of a sphere of radius 1        to the volume of a unit sphere in

d-dimensions is

(1     )dv (d)

v (d) = (1       )d

and thus goes to zero as d goes to in   nity, when    is a    xed constant. in high dimensions,
all of the volume of the sphere is concentrated in a narrow annulus at the surface.

indeed, (1      )d     e     d, so if    = c

d, for a large constant c, all but e   c of the volume of
the sphere is contained in a thin annulus of width c/d. the important item to remember
is that most of the volume of the d-dimensional sphere of radius r < 1 is contained in an
annulus of width o(1     r/d) near the boundary.

1.2.5 the surface area is near the equator

just as a 2-dimensional circle has an area and a circumference and a 3-dimensional
sphere has a volume and a surface area, a d-dimensional sphere has a volume and a surface
area. the surface of the sphere is the set {x||x| = 1}. the surface of the equator is the

11

annulus of
width 1
d

1

figure 1.9: most of the volume of the d-dimensional sphere of radius r is contained in an
annulus of width o(r/d) near the boundary.

set s = {x||x| = 1, x1 = 0} and it is the surface of a sphere of one lower dimension, i.e.,
for a 3-dimensional sphere, the circumference of a circle. just as with volume, essentially
all the surface area of a high-dimensional sphere is near the equator. to see this, calculate
the surface area of the slice of the sphere between x1 = 0 and x1 =   .

let s = {x||x| = 1, x1       }. to calculate the surface area of s, integrate over x1 from
   to 1. the incremental surface unit will be a band of width dx1 whose edge is the surface
area of a d     1-dimensional sphere of radius depending on x1. the radius of the band is

1 and therefore the surface area of the (d     1)-dimensional sphere is

(cid:112)1     x2

where a(d     1) is the surface area of a unit sphere of dimension d     1. thus,

2

a (d     1)(cid:0)1     x2
1(cid:90)

(cid:1) d   2
(cid:0)1     x2

1

1

(cid:1) d   2

2 dx1.

area (s) = a (d     1)

again the above integral is di   cult to integrate and the same approximations as in the
earlier section on volume leads to the bound

  

area (s)     1

  (d   2)e

    d   2

2   2

a (d     1) .

(1.2)

(cid:113)

next we lower bound the surface area of the entire upper hemisphere. clearly the surface
area of the upper hemisphere is greater than the surface area of the side of a d-dimensional
cylinder of height

times the circumference area of the d-dimensional cylinder of radius
a(d     1)(1     1

d   2
d   2 which is
2 . using (1     x)a     1     ax, the surface area of the hemisphere is at

d   2. the surface area of the cylinder is

and radius

1     1

1     1

(cid:113)

d   2

1   

1   

d   2) d   2

12

most

1   
d     2

(1     1
d     2

)

d   2

2 a(d     1)    
   

(1     d     2
2
a(d     1)

1   
d     2
   
1
d     2
2

1
d     2

)a(d     1)

(1.3)

comparing the upper bound on the surface area of s, in (1.2), with the lower bound on
the surface area of the hemisphere in (1.3), we see that the surface area above the band
{x||x| = 1, 0     x1       } is less than
lemma 1.3 for any c > 0, the fraction of the surface area above the plane x1 = c   

of the total surface area.

   
2
d   2
  

    d   2

2   2

is

e

d   2

less than or equal to 2
c e

    c2
2 .

proof: substitute

c   

d   2

for    in the above.

so far we have considered unit-radius spheres of dimension d. now    x the dimension
d and vary the radius r. let v (d, r) denote the volume and let a(d, r) denote the surface
area of a d-dimensional sphere. then,

(cid:90) r

v (d, r) =

a(d, x)dx.

thus, it follows that the surface area is the derivative of the volume with respect to the
radius. in two dimensions the volume of a circle is   r2 and the circumference is 2  r. in
three dimensions the volume of a sphere is 4

3  r3 and the surface area is 4  r2.

x=0

1.3 the high-dimensional cube and cherno    bounds

we can ask the same questions about the d-dimensional unit cube c = {x|0     xi    
1, i = 1, 2, . . . , d} as we did for spheres. first, is the volume concentrated in an annulus?
the answer to this question is simple. if we shrink the cube from its center ( 1
2) by
a factor of 1    (c/d) for some constant c, the volume clearly shrinks by (1    (c/d))d     e   c,
so much of the volume of the cube is contained in an annulus of width o(1/d). see figure
1.10. we can also ask if the volume is concentrated about the equator as in the sphere.
a natural de   nition of the equator is the set

2, . . . , 1

2, 1

(cid:40)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) d(cid:88)

i=1

h =

x

(cid:41)

.

xi =

d
2

we will show that most of the volume of c is within distance o(1) of h. see figure
1.11. the cube does not have the symmetries of the sphere, so the proof is di   erent.
the starting point is the observation that picking a point uniformly at random from c is

13

(1, 1, . . . , 1)

annulus of width o(1/d)

(0, 0, . . . , 0)

figure 1.10: most of the volume of the cube is in an o(1/d) annulus.

(1, 1, . . . , 1)

o(1)

(0, 0, . . . , 0)

figure 1.11: most of the volume of the cube is within o(1) of equator.

equivalent to independently picking x1, x2, . . . , xd, each uniformly at random from [0, 1].
the perpendicular distance of a point x = (x1, x2, . . . , xd) to h is

i=1 xi = c de   nes the set of points on a hyperplane parallel to h. the

i=1 xi = c to h is 1   

d

(cid:0)c     d

(cid:1) or

2

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:33)

1   
d

(cid:32) d(cid:88)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) .
note that (cid:80)d
perpendicular distance of a point x on the hyperplane(cid:80)d
(cid:12)(cid:12)(cid:12)(cid:16)(cid:80)d
(cid:17)     d
(cid:32) d(cid:88)

(cid:12)(cid:12)(cid:12). the expected squared distance of a point from h is

    d
2

(cid:33)

xi

i=1

1   
d

i=1 xi

      (cid:32)(cid:32) d(cid:88)
(cid:33)
by independence, the variance of (cid:80)d
var((cid:80)d

i=1 xi) = (cid:80)d

1
d

xi

i=1

e

(cid:33)2       =

    d
2

xi

.

var

1
d

i=1

2

is the sum of the variances of the xi, so
i=1 var(xi) = d/4. thus, the expected squared distance of a point

i=1 xi

14

(cid:18) distance squared from h is

greater than or equal to t2

(cid:19)

    1
4t2 .

prob

from h is 1/4. by markov   s inequality

(cid:19)

(cid:18) distance from h is greater
(cid:12)(cid:12)(cid:12)(cid:80)d

than or equal to t

(cid:110)

= prob

(cid:111)

lemma 1.4 a point picked at random in a unit cube will be within distance t of the
equator de   ned by h =

with id203 at least 1     1
4t2 .

i=1 xi = d

x

2

the proof of lemma 1.4 basically relied on the fact that the sum of the coordinates
of a random point in the unit cube will, with high id203, be close to its expected
value. we will frequently see such phenomena and the fact that the sum of a large num-
ber of independent random variables will be close to its expected value is called the law
of large numbers and depends only on the fact that the random numbers have a    nite
variance. how close is given by a cherno    bound and depends on the actual id203
distributions involved.

the proof of lemma 1.4 also covers the case when the xi are bernoulli random variables
with id203 1/2 of being 0 or 1 since in this case var(xi) also equals 1/4. in this
case, the argument claims that at most a 1/(4t2) fraction of the corners of the cube are
at distance more than t away from h. thus, the id203 that a randomly chosen
corner is at a distance t from h goes to zero as t increases, but not nearly as fast as the
exponential drop for the sphere. we will prove that the expectation of the rth power of
the distance to h is at most some value a. this implies that the id203 that the
distance is greater than t is at most a/tr, ensuring a faster drop than 1/t2. we will prove
this for a more general case than that of uniform density for each xi. the more general
case includes independent identically distributed bernoulli random variables.

we begin by considering the sum of d random variables, x1, x2, . . . , xd, and bounding
the expected value of the rth power of the sum of the xi. each variable xi is bounded by
0     xi     1 with an expected value pi. to simplify the argument, we create a new set of
variables, yi = xi     pi, that have zero mean. bounding the rth power of the sum of the yi
is equivalent to bounding the rth power of the sum of the xi     pi. the reader my wonder
i=1 pi appears in the statement of lemma 1.5 since the yi have zero mean.
the answer is because the yi are not bounded by the range [0, 1], but rather each yi is
bounded by the range [   pi, 1     pi].
lemma 1.5 let x1, x2, . . . , xd be independent random variables with 0     xi     1 and

why the    =(cid:80)d
e(xi) = pi. let yi = xi     pi and    =(cid:80)d
(cid:33)r(cid:35)

i=1 pi. for any positive integer r,

    max(cid:2)(2r  )r/2 , rr(cid:3) .

(cid:34)(cid:32) d(cid:88)

e

yi

(1.4)

proof: there are dr terms in the multinomial expansion of e ((y1 + y2 +        yd)r); each
term a product of r not necessarily distinct yi. focus on one term. let ri be the number

i=1

15

of times yi occurs in that term and let i be the set of i for which ri is nonzero. the ri
associated with the term sum to r. by independence

(cid:33)

(cid:32)(cid:89)

i   i

(cid:89)

i   i

e

yri
i

=

e(yri

i ).

if any of the ri equals one, then the term is zero since e(yi) = 0. thus, assume each ri
is at least two implying that |i| is at most r/2. now,

thus, (cid:81)

i   i

e(|yri

i )    (cid:81)

i   i

e(yri

i )     e(xi) = pi.

pi. so,

i |)     e(y2
e(|yri

i ) = e(x2

i     e(x2

i |)    (cid:81)
pi. let p(i) denote (cid:81)
i )     p2
(cid:33)r(cid:35)
(cid:34)(cid:32) d(cid:88)

    (cid:88)

i   i

i   i

e

yi

i=1

with i as the set of i with
where n(i) is number of terms in the expansion of
nonzero ri. each term corresponds to selecting one of the variables among yi, i     i from
each of the r brackets in the expansion of (y1 + y2 +        + yd)r. thus n(i)     |i|r. also,

i=1 yi

(cid:81)
. for each iwith|i| = t, we get
i   i pi exactly t! times. we also get other terms with repeated pi, hence the inequality.
thus, using the stirling approximation t!    =

to see this, do the multinomial expansion of
   

(cid:1)t,

i=1 pi

(cid:34)(cid:32) d(cid:88)

(cid:33)r(cid:35)

e

yi

    r/2(cid:88)

i=1

t=1

    r/2(cid:88)

t=1

  ttr
t!

  t   
2  tte   t

tr     1   
2  

maxr/2

t=1f (t)

tr,

(cid:17) r/2(cid:88)

t=1

where f (t) = (e  )t
tt

. taking logarithms and di   erentiating, we get

ln f (t) = t ln(e  )     t ln t
ln f (t) = ln(e  )     1 + ln t

= ln(  )     ln(t)

d
dt

setting ln(  )     ln(t) to zero, we see that the maximum of f (t) is attained at t =   . if
t=1f (t)     e       er/2. if
   < r/2, then the maximum of f (t) occurs for t = u and maxr/2

16

(cid:88)

p(i)    

(cid:32) d(cid:88)

i|i|=t

i=1

p(i)n(i),

i

|i|   r/2

(cid:16)(cid:80)d

(cid:17)r

pi

(cid:33)t
(cid:16)(cid:80)d
2  t(cid:0) t

e

1
t!

=

  t
t!

.

(cid:17)t

(cid:16)

       r/2, then maxr/2
last term or 2(r/2)r. thus,

rr/2

t=1f (t)     (2e  )r/2
(cid:33)r(cid:35)

(cid:34)(cid:32) d(cid:88)

yi

i=1

e

proving the lemma.

t=1 tr is bounded by twice its

. the geometric sum(cid:80)r/2
(cid:35)(cid:16) r
(cid:34)(cid:18)2e  
(cid:19) r
(cid:21)
(cid:20)(cid:16)er  
r2(cid:17) r
(cid:16) e
(cid:17) r
    max(cid:2)(2r  )r/2 , rr(cid:3)

    2   
2  
    max

max

2 ,

, e

2

4

r

r
2

2

2

2

(cid:17)r

theorem 1.6 (cherno    bounds): suppose xi, yi, and    are as in the lemma 1.5.
then

(cid:32)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) d(cid:88)
(cid:32)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) d(cid:88)

i=1

i=1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)     t
(cid:33)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)     t
(cid:33)

yi

yi

prob

prob

    3e   t2/12  ,

    4    2   t/3,

0 < t     3  

for

for

t > 3  .

yi. since r is even, yr is nonnegative.

d(cid:80)

i=1

proof: let r be a positive even integer. let y =

by markov inequality

prob (|y|     t) = prob (yr     tr)     e(yr)

.

applying lemma 1.5,

prob (|y|     t)     max

(cid:20)(2r  )r/2

tr

,

rr
tr

tr

(cid:21)

.

(1.5)

since this holds for every even positive integer r, choose r to minimize the right hand
side. by calculus, the r that minimizes (2r  )r/2
is r = t2/(2e  ). this is seen by taking
logarithms and di   erentiating with respect to r. since the r that minimizes the quantity
may not be an even integer, choose r to be the largest even integer that is at most t2/(2e  ).
then,

tr

for all t. when t     3  , since r was choosen such that r     t2
2eu,

(cid:19)r/2     e   r/2     e1   (t2/4e  )     3e   t2/12  
(cid:18)2r  
(cid:18) 3  
(cid:19)r    
(cid:18) t

(cid:19)   r    (cid:0)   

(cid:19)r    

(cid:18)2e

t2

2e  

2e  

3

e(cid:1)   r     e   r/2,

rr

tr    

17

which completes the proof of the    rst inequality.

for the second inequality, choose r to be the largest even integer less than or equal to

(cid:104) (2r  )r/2

, rr
tr

tr

(cid:105)     2   r/2 and the proof is completed similar to the    rst case.

2t/3. then, max

concentration for heavier-tailed distributions

the only place 0     xi     1 is used in the proof of (1.4) is in asserting that e|yk

i |     pi
for all k = 2, 3, . . . , r. imitating the proof above, one can prove stronger theorems that
only assume bounds on moments up to the rth moment and so include cases when xi may
be unbounded as in the poisson or exponential density on the real line as well as power
law distributions for which only moments up to some rth moment are bounded. we state
one such theorem. the proof is left to the reader.

(cid:80)d
i=1 pi =    and e|(xi     pi)k|     pi for k = 2, 3, . . . ,(cid:98)t2/6  (cid:99). then,

theorem 1.7 suppose x1, x2, . . . , xd are independent random variables with e(xi) = pi,

(cid:32)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) d(cid:88)

i=1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)     t
(cid:33)

prob

xi       

    max

(cid:16)
3e   t2/12  , 4    2   t/e(cid:17)

.

1.4 volumes of other solids

there are very few high-dimensional solids for which there are closed-form formulae

for the volume. the volume of the rectangular solid

r = {x|l1     x1     u1, l2     x2     u2, . . . , ld     xd     ud},

is the product of the lengths of its sides. namely, it is

a parallelepiped is a solid described by

i=1

p = {x| l     ax     u},

where a is an invertible d    d matrix, and l and u are lower and upper bound vectors,
respectively. the statements l     ax and ax     u are to be interpreted row by row
asserting 2d inequalities. a parallelepiped is a generalization of a parallelogram. it is
easy to see that p is the image under an invertible linear transformation of a rectangular
solid. indeed, let

r = {y | l     y     u}.

then the map x = a   1y maps r to p . this implies that

volume(p ) = |det(a   1)| volume(r).

18

d(cid:81)

(ui     li).

simplices, which are generalizations of triangles, are another class of solids for which
volumes can be easily calculated. consider the triangle in the plane with vertices
{(0, 0), (1, 0), (1, 1)} which can be described as {(x, y)| 0     y     x     1}.
its area is
1/2 because two such right triangles can be combined to form the unit square. the
generalization is the simplex in d-space with d + 1 vertices,

{(0, 0, . . . , 0), (1, 0, 0, . . . , 0), (1, 1, 0, 0, . . . 0), . . . , (1, 1, . . . , 1)},

which is the set

s = {x| 1     x1     x2                xd     0}.

how many copies of this simplex exactly    t into the unit square, {x| 0     xi     1}?
every point in the square has some ordering of its coordinates and since there are d!
orderings, exactly d! simplices    t into the unit square. thus, the volume of each sim-
plex is 1/d!. now consider the right angle simplex r whose vertices are the d unit
vectors (1, 0, 0, . . . , 0), (0, 1, 0, . . . , 0), . . . , (0, 0, 0, . . . , 0, 1) and the origin. a vector y in
r is mapped to an x in s by the mapping: xd = yd; xd   1 = yd + yd   1;
; x1 =
y1 + y2 +        + yd. this is an invertible transformation with determinant one, so the
volume of r is also 1/d!.

. . .

a general simplex is obtained by a translation (adding the same vector to every point)
followed by an invertible linear transformation on the right simplex. convince yourself
that in the plane every triangle is the image under a translation plus an invertible linear
transformation of the right triangle. as in the case of parallelepipeds, applying a linear
transformation a multiplies the volume by the determinant of a. translation does not
change the volume. thus, if the vertices of a simplex t are v1, v2, . . . , vd+1, then trans-
lating the simplex by    vd+1 results in vertices v1     vd+1, v2     vd+1, . . . , vd     vd+1, 0. let
a be the d   d matrix with columns v1     vd+1, v2     vd+1, . . . , vd     vd+1. then, a   1t = r
and ar = t . thus, the volume of t is 1

d!|det(a)|.

1.5 generating points uniformly at random on the surface of

a sphere

consider generating points uniformly at random on the surface of a unit-radius sphere.
first, consider the 2-dimensional version of generating points on the circumference of a
unit-radius circle by the following method. independently generate each coordinate uni-
formly at random from the interval [   1, 1]. this produces points distributed over a square
that is large enough to completely contain the unit circle. project each point onto the
unit circle. the distribution is not uniform since more points fall on a line from the origin
to a vertex of the square, than fall on a line from the origin to the midpoint of an edge
of the square due to the di   erence in length. to solve this problem, discard all points
outside the unit circle and project the remaining points onto the circle.

one might generalize this technique in the obvious way to higher dimensions. however,
the ratio of the volume of a d-dimensional unit sphere to the volume of a d-dimensional

19

unit cube decreases rapidly making the process impractical for high dimensions since
almost no points will lie inside the sphere. the solution is to generate a point each
of whose coordinates is a gaussian variable. the id203 distribution for a point
(x1, x2, . . . , xd) is given by

p (x1, x2, . . . , xd) =

1

d
2

(2  )

e

1+x2

    x2

2+      +x2
2

d

and is spherically symmetric. normalizing the vector x = (x1, x2, . . . , xd) to a unit vec-
tor gives a distribution that is uniform over the sphere. note that once the vector is
normalized, its coordinates are no longer statistically independent.

1.6 gaussians in high dimension

a 1-dimensional gaussian has its mass close to the origin. however, as the dimension
is increased something di   erent happens. the d-dimensional spherical gaussian with zero
mean and variance    has density function

(cid:17)

(cid:16)   |x|2

2  2

.

p(x) =

1

(2  )d/2   d

exp

the value of the gaussian is maximum at the origin, but there is very little volume
there. when    = 1, integrating the id203 density over a unit sphere centered at
   
the origin yields nearly zero mass since the volume of such a sphere is negligible. in fact,
one needs to increase the radius of the sphere to
d before there is a signi   cant nonzero
d, the
volume and hence a nonzero id203 mass. if one increases the radius beyond
integral ceases to increase even though the volume increases since the id203 density
   
is dropping o    at a much higher rate. the natural scale for the gaussian is in units of
  

   

d.

expected squared distance of a point from the center of a gaussian

consider a d-dimensional gaussian centered at the origin with variance   2. for a point
x = (x1, x2, . . . , xd) chosen at random from the gaussian, the expected squared length of
x is

e(cid:0)x2

1 + x2

2 +        + x2

d

(cid:1) = d e(cid:0)x2

(cid:1) = d  2.

1

   
for large d, the value of the squared length of x is tightly concentrated about its mean.
we call the square root of the expected squared distance (namely   
d) the radius of
the gaussian. in the rest of this section we consider spherical gaussians with    = 1; all
results can be scaled up by   .

the id203 mass of a unit variance gaussian as a function of the distance from
its center is given by rd   1e   r2/2 times some constant id172 factor where r is the

20

distance from the center and d is the dimension of the space. the id203 mass
function has its maximum at

   

d     1

r =

which can be seen from setting the derivative equal to zero

   
   r e
which implies r2 = d     1.

2 rd   1 = (d     1)e
    r2

2 rd   2     rde
    r2

    r2

2 = 0

calculation of width of the annulus

   
we now show that most of the mass of the gaussian is within an annulus of constant
d     1. the id203 mass of the gaussian as a function of r is
width and radius
g(r) = rd   1e   r2/2. to determine the width of the annulus in which g(r) is nonnegligible,
consider the logarithm of g(r)

f (r) = ln g(r) = (d     1) ln r     r2
2

.

di   erentiating f (r),

f(cid:48)(r) =

note that f(cid:48)(r) = 0 at r =
   
d     1, is
for f (r) about
   
   
d     1) + f(cid:48)(

f (r) = f (

and

    r

r2     1        1.

f(cid:48)(cid:48)(r) =    d     1

d     1
r
   
d     1 and f(cid:48)(cid:48)(r) < 0 for all r. the taylor series expansion
d     1)(r        

d     1)(r        

d     1)2 +        .

d     1) +

   
f(cid:48)(cid:48)(

1
2

thus,

   
f (r) = f (

for some point    between
and

   
d     1) + f(cid:48)(

d     1)(r        
d     1) +
   
d     1 and r.1 since f(cid:48)(

   

1
2

   
f (r) = f (

d     1) +

f(cid:48)(cid:48)(  )(r        

d     1)2.

1
2

since the second derivative is always less than    1,

f(cid:48)(cid:48)(  )(r        

d     1)2

d     1) = 0, the second term vanishes

   
f (r)     f (

d     1)     1
2

(r        

d     1)2.

recall that g(r) = ef (r). thus
   
g(r)     ef (

d   1)    1

2 (r      

   
d   1)2 = g(

d     1)e    1

2 (r      

d   1)2.

1see whittaker and watson 1990, pp. 95-96

21

d     1 + c]. we calculate the
let c be a positive real and let i be the interval [
ratio of an upper bound on the id203 mass outside the interval to a lower bound on
the total id203 mass. the id203 mass outside the interval i is upper bounded
by

d     1    c,

   

   

(cid:90)    

   
g(
   
d   1+c

r=

d     1)e   (r      

d   1)2/2 dr

(cid:90)

g(r) dr    
r /   i

(cid:90)    

d   1)2/2 dr +

d   1)2/2 dr

r=0

d     1)

   
d   1   c
g(
   
    2g(
   
= 2g(

d     1)
   
    2g(

d     1)e   (r      
(cid:90)    
(cid:90)    
(cid:90)    

e   (r      
   
d   1+c
e   y2/2 dy

y=c

r=

d     1)
   
g(

y
c
d     1)e   c2/2.

y=c

e   y2/2 dy

=

2
c

to get a lower bound on the id203 mass in the interval [
consider the subinterval [
f(cid:48)(cid:48)(r)        2 and

2]. for r in the subinterval [

d     1+ c

   
d     1,

   

   

   
d     1 + c],
d     1     c,
   
d     1,
d     1+ c
2],

   

   
f (r)     f (

d     1)     (r        

   
d     1 )2     f (

d     1)     c2
4

.

g(r) = ef (r)     ef

   

d   1e    c2

4 = g(

   
d     1)e c2
4 .

g(r) dr     c

d     1)e   c2/4 and the fraction of the mass outside the

   
2g(

thus

hence, (cid:82)    

   
interval is

d   1+ c
d   1

2

   
2
c g(

   
c
2g(

d     1)e   c2/4 + 2

d     1)e   c2/2
   
d     1)e   c2/2

c g(

=

4

2

c2 e    c2
c2 e    c2
2 + 2

c

4

=

4

e    c2
4 + e    c2

4

c2

    4
c2 e    c2

4 .

this establishes the following lemma.

lemma 1.8 for a d-dimensional spherical gaussian of variance 1, all but 4
tion of its mass is within the annulus

d     1     c     r        

d     1 + c for any c > 0.

   

c2 e   c2/4 frac-

separating gaussians

gaussians are often used to model data. a common stochastic model is the mixture
model where one hypothesizes that the data is generated from a convex combination of
simple id203 densities. an example is two gaussian densities f1(x) and f2(x) where
data is drawn from the mixture f (x) = w1f1(x) + w2f2(x) with positive weights w1 and
w2 summing to one. assume that f1 and f2 are spherical with unit variance. if their

22

   
d

   
2d

   

d

figure 1.12: two randomly chosen points in high dimension are almost surely nearly
orthogonal.

means are very close, then given data from the mixture, one cannot tell for each data
point whether it came from f1 or f2. the question arises as to how much separation is
needed between the means to tell which gaussian generated which data point. we will
see that a separation of    (d1/4) su   ces. later, we will see that with more sophisticated
algorithms, even a separation of    (1) su   ces.

   

i e   x2

e   |x|2/2 factors into(cid:81)

consider two spherical unit variance gaussians. from lemma 1.8, most of the prob-
d     1. also
ability mass of each gaussian lies on an annulus of width o(1) at radius
i /2 and almost all of the mass is within the slab {x|   c     x1     c},
for c     o(1). pick a point x from the    rst gaussian. after picking x, rotate the coordi-
nate system to make the    rst axis point towards x. then, independently pick a second
point y also from the    rst gaussian. the fact that almost all of the mass of the gaussian
is within the slab {x|     c     x1     c, c     o(1)} at the equator says that y   s component
along x   s direction is o(1) with high id203. thus, y is nearly perpendicular to x.

so, |x     y|    (cid:112)|x|2 + |y|2. see figure 1.12. more precisely, since the coordinate system
has been rotated so that x is at the north pole, x = ((cid:112)(d)    o(1), 0, . . . ). since y is
y = (o(1),(cid:112)(d)    o(1), . . . ). thus,
and |x     y| =(cid:112)(2d)    o(1).

almost on the equator, further rotate the coordinate system so that the component of
y that is perpendicular to the axis of the north pole is in the second coordinate. then

   
(x     y)2 = d    o(

   
   
d) = 2d    o(

d) + d    o(

d)

given two spherical unit variance gaussians with centers p and q separated by a
distance   , the distance between a randomly chosen point x from the    rst gaussian and a
  2 + 2d, since x   p, p   q, and q   y
randomly chosen point y from the second is close to

   

23

   

d

x

p

  

   

  2 + 2d

  

   

2d

y

z

q

figure 1.13: distance between a pair of random points from two di   erent unit spheres
approximating the annuli of two gaussians.

are nearly mutually perpendicular. to see this, pick x and rotate the coordinate system
so that x is at the north pole. let z be the north pole of the sphere approximating the
second gaussian. now pick y. most of the mass of the second gaussian is within o(1)
of the equator perpendicular to q     z. also, most of the mass of each gaussian is within
distance o(1) of the respective equators perpendicular to the line q     p. thus,

|x     y|2       2 + |z     q|2 + |q     y|2

=   2 + 2d    o(

   
d)).

to ensure that the distance between two points picked from the same gaussian are
closer to each other than two points picked from di   erent gaussians requires that the
upper limit of the distance between a pair of points from the same gaussian is at most
   
2d + o(1)        
the lower limit of distance between points from di   erent gaussians. this requires that
d)     2d +   2, which holds when           (d1/4).
thus, mixtures of spherical gaussians can be separated provided their centers are sepa-
rated by more than d 1
4 . one can actually separate gaussians where the centers are much
closer. in chapter 4, we will see an algorithm that separates a mixture of k spherical
gaussians whose centers are much closer.

   
2d +   2     o(1) or 2d + o(

algorithm for separating points from two gaussians

calculate all pairwise distances between points. the cluster of smallest
pairwise distances must come from a single gaussian. remove these
points and repeat the process.

fitting a single spherical gaussian to data

24

(cid:32)

c exp

given a set of sample points, x1, x2, . . . , xn, in a d-dimensional space, we wish to    nd
the spherical gaussian that best    ts the points. let f be the unknown gaussian with
mean    and variance   2 in every direction. the id203 of picking these very points
when sampling according to f is given by

2  2

    (x1       )2 + (x2       )2 +        + (xn       )2
(cid:21)n
(cid:21)   n

   |x     |2

2  2 dx

(cid:20)(cid:82) e
(cid:20)(cid:82) e

2  2 dx

    |x|2

where the normalizing constant c is the reciprocal of

. in integrating from

       to    , one could shift the origin to    and thus c is
of   .

and is independent

(cid:33)

the maximum likelihood estimator (id113) of f, given the samples x1, x2, . . . , xn, is

the f that maximizes the above id203.
lemma 1.9 let {x1, x2, . . . , xn} be a set of n points in d-space. then (x1       )2 +
(x2       )2+      +(xn       )2 is minimized when    is the centroid of the points x1, x2, . . . , xn,
namely    = 1
proof: setting the derivative of (x1       )2 + (x2       )2 +        + (xn       )2 to zero yields

n(x1 + x2 +        + xn).

   2 (x1       )     2 (x2       )                2 (xd       ) = 0.

solving for    gives    = 1

n(x1 + x2 +        + xn).

in the maximum likelihood estimate for f ,    is set to the centroid. next we show
that    is set to the standard deviation of the sample. substitute    = 1
2  2 and a =
(x1       )2 + (x2       )2 +       + (xn       )2 into the formula for the id203 of picking the
points x1, x2, . . . , xn. this gives

now, a is    xed and    is to be determined. taking logs, the expression to maximize is

to    nd the maximum, di   erentiate with respect to   , set the derivative to zero, and solve
for   . the derivative is

(cid:21)n .

e   a  
e   |x|2  dx

(cid:20)(cid:82)

x

   a       n ln

e     |x|2dx

       .

   a + n

x

(cid:82)

|x|2e     |x|2
e     |x|2dx

dx

.

      (cid:90)

x

(cid:82)

x

25

   

setting y =

  x in the derivative, yields

   a +

n
  

(cid:82)

y

(cid:82)

y2e   y2dy
e   y2dy

.

y

since the ratio of the two integrals is the expected distance squared of a d-dimensional
spherical gaussian of standard deviation 1   
2 , we
2   gives    a + nd  2. setting    a + nd  2 = 0 shows that
get    a + nd
2   . substituting   2 for 1
   
a   
the maximum occurs when    =
. note that this quantity is the square root of the
nd
average coordinate distance squared of the samples to their mean, which is the standard
deviation of the sample. thus, we get the following lemma.

to its center, and this is known to be d

2

lemma 1.10 the maximum likelihood spherical gaussian for a set of samples is the
one with center equal to the sample mean and standard deviation equal to the standard
deviation of the sample.

let x1, x2, . . . , xn be a sample of points generated by a gaussian id203 distri-
n(x1 + x2 +        + xn) is an unbiased estimator of the expected value of

bution.    = 1
the distribution. however, if in estimating the variance from the sample set, we use the
estimate of the expected value rather than the true expected value, we will not get an
unbiased estimate of the variance since the sample mean is not independent of the sam-
ple set. one should use    = 1
appendix.

n   1(x1 + x2 +        + xn) when estimating the variance. see

1.7 random projection and the johnson-lindenstrauss theo-

rem

many high-dimensional problems such as the nearest neighbor problem can be sped up
by projecting the data to a random lower-dimensional subspace and solving the problem
there. this technique requires that the projected distances have the same ordering as the
original distances. if one chooses a random k-dimensional subspace, then indeed all the
projected distances in the k-dimensional space are approximately within a known scale
factor of the distances in the d-dimensional space. we    rst show that for one distance
pair, the id203 of its projection being badly represented is exponentially small in k.
then we use the union bound to argue that failure does not happen for any pair.

project a    xed (not random) unit length vector v in d-dimensional space onto a
random k-dimensional space. by the pythagoras theorem, the length squared of a vector
is the sum of the squares of its components. thus, we would expect the squared length
of the projection to be k
d . the following theorem asserts that the squared length of the
projection is very close to this quantity.

26

theorem 1.11 (the random projection theorem): let v be a    xed unit length
vector in a d-dimensional space and let w be a random k-dimensional subspace. let w

be the projection of v onto w . for any 0            1, prob(cid:0)(cid:12)(cid:12)|w|2     k

(cid:1)     4e     k  2

(cid:12)(cid:12)        k

64 .

d

d

proof: a random subspace is generated by selecting a set of basis vectors. working with
such a set of dependent vectors is di   cult. however, projecting a    xed vector onto a
random subspace is the same as projecting a random vector onto a    xed subspace. that
is, the id203 distribution of w in the theorem is the same as the id203 dis-
tribution of the vector obtained by taking a random unit length vector z and projecting
it onto the    xed subspace u spanned by its    rst k coordinate vectors. this is because
one can rotate the coordinate system so that a set of basis vectors for w are the    rst k
coordinate axes.

let   z be the projection of z onto u . we will prove that |  z|2     k
d or |  z|2     (1       ) k

d if either |  z|2     (1       ) k

greater than or equal to    k

we will prove that prob(cid:0)|  z|2 <    k
(cid:1)     2e
(cid:12)(cid:12)        k
together they imply prob(cid:0)(cid:12)(cid:12)|w|2     k

(cid:1)     4e     k  2

    k  2

64 .

d

d

d

4 . the other case is similar and is omitted.

d . now(cid:12)(cid:12)|  z|2     k

(cid:12)(cid:12) is

d . let    = 1       .

d

pick a random vector z of length one by picking independent gaussian random vari-
ables x1, x2, . . . , xd, each with mean zero and variance one. let x = (x1, x2, . . . , xd) and
take z = x/|x|. this yields a random vector z of length one.

(cid:20)

(cid:21)

prob

|  z|2 <   

k
d

(cid:20)
(cid:20)

(cid:21)

= p rob

|  z|2       

= prob

= prob(cid:2)  k(cid:0)x2

x2
1 + x2

|z|2

k
d
2 +        + x2
1 + x2

k <   
2 +        + x2

d

(cid:0)x2
(cid:1)     d(cid:0)x2

k
d

1 + x2

2 +        + x2

d

1 + x2

2 +        + x2

k

(cid:1) > 0(cid:3) .

(cid:1)(cid:21)

k

. de   ne c =   

if k  2 < 64, then 4e    k  2
64 > 1, so the id203 upper bound asserted in the theorem is
greater than one and there is nothing to prove. so assume that k  2     64 which implies
   
       8   
k/4 and since        8   
d)     d (x2
2 +        + x2
   
k/4:
inequalities must hold with c =   
2 +        + x2
2 +        + x2

, it follows that c     2.
2 +        + x2

   
d) >   k(
   
k) <   k(

k) > 0, then one of the following

d     1 + c)2
d     1 + c)2.

1 + x2
1 + x2

  k(x2
d(x2

now if   k (x2

1 + x2

1 + x2

(1.6)

(1.7)

k

using lemma 1.8 we will prove that the id203 of each of (1.6) and (1.7) is at most
64     e   k  2/64 so that the id203 of at least one of (1.6) or (1.7) is less
c2 e    c2
4
than or equal to 2e    k  2

64 which proves the theorem. lemma 1.8 implies

k  2 e    k  2

4 = 64

(x2

1 + x2

2 +        x2

   
d)2     (

d     1 + c)2

27

with id203 less than or equal to 4
(1.7), from lemma 1.8,

c2 e   c2/4     e   k  2/64 from which (1.6) follows. for

prob(d(x2

1 + x2

2 +        + x2

   
k) < d(

k     1     c)2)

   
with id203 less than or equal to 4
  k(

   
k     1     c)2 and thus

d     1     c)2     d(

(cid:16)

prob

d(x2

1 + x2

c2 e   c2/4     e   k  2/64. since   k < d,

d     1     c)2(cid:17)

   
k) <   k(

1 + x2

2 +        + x2

   
k) < d(

k     1     c)2(cid:17)

(cid:16)
2 +        + x2
    prob
d(x2
    e   k  2/64

completing the proof of theorem 1.11.

the random projection theorem enables us to argue, using the union bound, that
the projection to order log n dimensions preserves all relative pairwise distances between
a set of n points. this is the content of the johnson-lindenstrauss lemma.

theorem 1.12 (johnson-lindenstrauss lemma): for any 0 <    < 1 and any inte-
ger n, let k be an integer such that

k     64 ln n

  2

.

for any set p of n points in rd, a random projection f mapping f : rd     rk has the
property that for all u and v in p ,

(1       )

k
d

|u     v|2     |f (u)     f (v)|2     (1 +   )

|u     v|2

k
d

with id203 at least 9/10.

proof: let s be a random k-dimensional subspace and let f (u) be the projection of u
k . applying the random projection theorem 1.11, for

onto s multiplied by the scalar
any    xed u and v, the id203 that (cid:107)f (u)     f (v)(cid:107)2 is outside the range

(1       ) k

  |u     v|2, (1 +   ) k

  |u     v|2(cid:105)

(cid:113) d

(cid:104)

by the union bound the id203 that any pair has a large distortion is less than

is at most

(cid:0)n
(cid:1)    1

2

n4     1
n.

    k  2
e

16 = e   4 ln n =

1
n4 .

28

remark: it is important to note that the conclusion of theorem 1.12 is asserted for all
u and v in p , not just for most u and v. the weaker assertion for most u and v is not
that useful, since we do not know which v would end up being the closest point to u and
an assertion for most may not cover the particular v. a remarkable aspect of the theorem
is that the number of dimensions in the projection is only dependent logarithmically on
n. since k is often much less than d, this is called a dimension reduction technique.

for the nearest neighbor problem, if the database has n1 points and n2 queries are
expected during the lifetime, then take n = n1 + n2 and project the database to a random
k-dimensional space, where k     64 ln n
. on receiving a query, project the query to the
same subspace and compute nearby database points. the theorem says that this will yield
the right answer whatever the query with high id203. note that the exponentially
small in k id203 in theorem 1.11 was useful here in making k only dependent on
log n, rather than n.

  2

1.8 bibliographic notes

the word vector model was introduced by salton [?]. taylor series remainder mate-
rial can be found in whittaker and watson 1990, pp. 95-96. there is vast literature on
gaussian distribution, its properties, drawing samples according to it, etc. the reader
can choose the level and depth according to his/her background. for cherno    bounds
and their applications, see [?] or [?]. the proof here and the application to heavy-tailed
distributions is simpli   ed from [?]. the original proof of the random projection theo-
rem by johnson and lindenstrauss was complicated. several authors used gaussians to
simplify the proof, see [?] for details and applications of the theorem. the proof here is
due to das gupta and gupta [?].

the svd based algorithm for identifying the space spanned by centers of spherical gaus-
sians is from vempala and wang [?]. the paper handles more complex densities besides
spherical gaussians, but the restricted case of spherical gaussians contains the key ideas.

29

1.9 exercises

exercise 1.1 assume you have 100 million documents each represented by a vector in
the word vector model. how would you represent the documents so that given a query
with a small number of words you could e   ciently    nd the documents with the highest dot
product with the query vector? given the number of documents you do not have time to
look at every document.

exercise 1.2 let x and y be independent random variables with uniform distribution in
[0, 1]. what is the expected value e(x)? e(x2)? e(x     y)? e(xy)? and e((x     y)2)?

exercise 1.3 what is the distribution of the distance between two points chosen uni-
formly at random in the interval [0, 1]? in the unit square? in the unit cube in 100
dimensions? give a qualitative answer.

exercise 1.4 what is the expected distance between two points selected at random inside
a d-dimensional unit cube? for two points selected at random inside a d-dimensional unit
sphere? what is the cosine of the angle between them?

exercise 1.5 consider two random 0-1 vectors in high dimension. what is the angle
between them? what is the id203 that the angle is less than 45?

exercise 1.6 place two unit-radius spheres in d-dimensions, one at (-2,0,0,. . . ,0 ) and
the other at (2,0,0,. . . ,0). give an upper bound on the id203 that a random line
through the origin will intersect the spheres.

exercise 1.7 generate a 1,000 points at vertices of a 1,000-dimensional cube. select two
points i and j at random and    nd a path from i to j by the following algorithm. start at i
and go to a point k di   ering from i in only one coordinate so that dist (i, k) and dist (j, k)
are both less than dist (i, j). then continue the path by the same algorithm from k to j.
what is the expected length of the path?

exercise 1.8 (overlap of spheres) let x be a random sample from the unit sphere in
d-dimensions with the origin as center.

1. what is the mean of the random variable x? the mean, denoted e(x), is the vector,

whose ith component is e(xi).

2. what is the component-wise variance of x?

3. show that for any unit length vector u, the variance of the real-valued random vari-

u2
i e(x2

i ). using this, compute the variance and standard deviation

30

d(cid:80)

i=1

able ut    x is
of ut x.

4. given two spheres in d-space, both of radius one whose centers are distance a apart,

show that the volume of their intersection is at most

4e    a2(d   1)
   
d     1
a

8

times the volume of each sphere.
hint: relate the volume of the intersection to the volume of a cap, then, use lemma
1.2.

   
5. from (4), conclude that if the inter-center separation of the two spheres of radius
r is    (r/
d), then they share very small mass. theoretically, at this separation,
given randomly generated points from the two distributions, one inside each sphere,
it is possible to tell which sphere contains which point, i.e., classify them into two
clusters so that each cluster is exactly the set of points generated from one sphere.
the actual classi   cation requires an e   cient algorithm to achive this. note that
the inter-center separation required here goes to zero as d gets larger, provided the
radius of the spheres remains the same. so, it is easier to tell apart spheres (of the
same radii) in higher dimensions.

x=   e   x2 dx where    is a positive real. discuss

exercise 1.9 derive an upper bound on(cid:82)    

for what values of    this is a good bound.
hint: use e   x2     x

   e   x2 for x       .

exercise 1.10 what is the formula for the incremental unit of area in using polar coor-
dinates to integrate the area of a circle that lies in a 2-dimensional cone whose vertex is
at the center of the circle? what is the formula for the integral? what is the value of the
integral if the cone is 36   ?

exercise 1.11 for what value of d is the volume, v (d), of a d-dimensional unit sphere
maximum?
hint: consider the ratio v (d)

v (d   1) for odd and even values of d.

exercise 1.12 how does the volume of a sphere of radius two behave as the dimension
of the space increases? what if the radius was larger than two but a constant independent
of d? what function of d would the radius need to be for a sphere of radius r to have
approximately constant volume as the dimension increases?

exercise 1.13

1. what is the volume of a sphere of radius r in d-dimensions?

2. what is the surface area of a sphere of radius r in d-dimensions?

3. what is the relationship between the volume and the surface area of a sphere of

radius r in d-dimensions?

31

4. why does the relationship determined in (3) hold?

exercise 1.14 consider vertices of a d-dimensional cube of width two centered at the
origin. vertices are the points (  1,  1, . . . ,  1). place a unit-radius sphere at each vertex.
each sphere    ts in a cube of width two and, thus, no two spheres intersect. show that the
id203 that a point of the cube picked at random will fall into one of the 2d unit-radius
spheres, centered at the vertices of the cube, goes to 0 as d tends to in   nity.

exercise 1.15 consider the power law id203 density

p(x) =

c

max(1, x2)

over the nonnegative real line.

1. determine the constant c.

2. for a nonnegative random variable x with this density, does e(x) exist? how about

e(x2)?

exercise 1.16 consider d-space and the following density over the positive orthant:

p(x) =

c

max(1,|x|  )

.

show that    > d is necessary for this to be a proper density function. show that    > d + 1
is a necessary condition for a (vector-valued) random variable x with this density to have
an expected value e(|x|). what condition do you need if we want e(|x|2) to exist?

exercise 1.17 consider the upper hemisphere of a unit-radius sphere in d-dimensions.
what is the height of the maximum volume cylinder that can be placed entirely inside the
hemisphere? as you increase the height of the cylinder, you need to reduce the cylinder   s
radius so that it will lie entirely within the hemisphere.

exercise 1.18 what is the volume of a radius r cylinder of height h in d-dimensions?

exercise 1.19 for a 1,000-dimensional unit-radius sphere centered at the origin, what
fraction of the volume of the upper hemisphere is above the plane x1 = 0.1? above the
plane x1 = 0.01?

exercise 1.20 almost all of the volume of a sphere in high dimensions lies in a narrow
slice of the sphere at the equator. however, the narrow slice is determined by the point on
the surface of the sphere that is designated the north pole. explain how this can be true
if several di   erent locations are selected for the north pole.

exercise 1.21 explain how the volume of a sphere in high dimensions can simultaneously
be in a narrow slice at the equator and also be concentrated in a narrow annulus at the
surface of the sphere.

32

exercise 1.22 how large must    be for 99% of the volume of a d-dimensional unit-radius
sphere to lie in the shell of   -thickness at the surface of the sphere?

exercise 1.23

1. write a computer program that generates n points uniformly distributed over the

surface of a unit-radius d-dimensional sphere.

2. generate 200 points on the surface of a sphere in 50 dimensions.

3. create several random lines through the origin and project the points onto each line.

plot the distribution of points on each line.

4. what does your result from (3) say about the surface area of the sphere in relation

to the lines, i.e., where is the surface area concentrated relative to each line?

   
exercise 1.24 if one generates points in d-dimensions with each coordinate a unit vari-
d.
ance gaussian, the points will approximately lie on the surface of a sphere of radius
what is the distribution when the points are projected onto a random line through the
origin?

   
d in d-dimensions onto
exercise 1.25 project the surface area of a sphere of radius
a line through the center. for d equal 2 and 3, derive an explicit formula for how the
projected surface area changes as we move along the line. for large d, argue (intuitively)
that the projected surface area should behave like a gaussian.

exercise 1.26 generate 500 points uniformly at random on the surface of a unit-radius
sphere in 50 dimensions. then randomly generate    ve additional points. for each of
the    ve new points calculate a narrow band at the equator assuming the point was the
north pole. how many of the 500 points are in each band corresponding to one of the    ve
equators? how many of the points are in all    ve bands?

exercise 1.27 we have claimed that a randomly generated point on a sphere lies near
the equator of the sphere independent of the point selected for the north pole.
is the
same claim true for a randomly generated point on a cube? to test this claim, randomly
generate ten   1 valued vectors in 128 dimensions. think of these ten vectors as ten
choices for the north pole. then generate some additional   1 valued vectors. to how
many of the original vectors is each of the new vectors close to being perpendicular, that
is how many of the equators is each new vectors close to.

exercise 1.28 consider a slice of a 100-dimensional sphere that lies between two parallel
planes each equidistant from the equator and perpendicular to the line from the north to
south pole. what percentage of the distance from the center of the sphere to the poles
must the planes be to contain 95% of the surface area?

33

exercise 1.29 place n points at random on a d-dimensional unit radius sphere. assume
d is large. pick a random vector and let it de   ne two parallel hyperplanes on opposite sides
of the origin that are equal distance from the origin. how far apart can the hyperplanes
be moved and still have no points between them?

exercise 1.30 consider two random vectors in a high-dimensional space. assume the
vectors have been normalized so that their lengths are one and thus the points lie on a
unit sphere. assume one of the vectors is the north pole. prove that the ratio of the area
of a cone, with axis at the north pole of    xed angle say 45    to the area of a hemisphere,
goes to zero as the dimension increases. thus, the id203 that the angle between two
random vectors is at most 45    goes to zero. how does this relate to the result that most
of the volume is near the equator?

exercise 1.31 project the vertices of a high-dimensional cube onto a line from (0, 0, . . . , 0)
to (1, 1, . . . , 1). argue that the    density    of the number of projected points (per unit dis-
tance) varies roughly as a gaussian with variance o(1) with the mid-point of the line as
center.

exercise 1.32 draw a 3-dimensional cube and illustrate the equator as de   ned in section
1.3.

exercise 1.33

1. what is the surface area of a unit cube in d-dimensions?

2. is the surface area of a unit cube concentrated close to the equator as is the case

with the sphere?

exercise 1.34 consider the simplex

s = {x| xi     0, 1     i     d;

d(cid:88)

i=1

xi     1}.

for a random point x picked with uniform density from s,    nd e(x1 + x2 +        + xd).
find the centroid of s.

exercise 1.35 how would you sample uniformly at random from the parallelepiped

p = {x| 0     ax     1},

where a is a given nonsingular matrix? how about from the simplex

{x| 0     (ax)1     (ax)2            (ax)d     1}?

your algorithms must run in polynomial time.

34

exercise 1.36 randomly generate a 100 points on the surface of a sphere in 3-dimensions
and in 100-dimensions. create a histogram of all distances between the pairs of points in
both cases.

exercise 1.37 we have claimed that in high dimensions a unit variance gaussian cen-
tered at the origin has essentially zero id203 mass in a unit-radius sphere centered at
the origin since the unit-radius sphere has no volume. explain what happens if the gaus-
sian has an extremely small variance and has no id203 mass outside the unit-radius
sphere? how small must the variance be in terms of d for this to happen?

exercise 1.38 consider two unit-radius spheres in d-dimensions whose centers are dis-
tance    apart where    is a constant independent of d. let x be a random point on the
surface of the    rst sphere and y a random point on the surface of the second sphere. prove
that the id203 that |x     y|2 is more than 2 +   2 + a falls o    exponentially with a.

exercise 1.39 the cauchy distribution in one dimension is prob(x) = 1
c+x2 . what
would happen if one tried to extend the distribution to higher dimensions by the formula
prob(r) = 1
1+r2 where r is the distance from the origin? what happens when you try to
determine a id172 constant c?

exercise 1.40 where do points generated by a heavy tailed, high-dimensional distribu-
tion lie? for the gaussian distribution, points lie in an annulus because the id203
distribution falls o    quickly as the volume increases.

exercise 1.41 pick a point x uniformly at random from the following set in d-space:

1 + x4

k = {x|x4

1. show that the id203 that x4

d     1}.
2 +        + x4
d     1
2 +        + x4
2 is
2 +        + x4
d     1     o(1/d).
2. show that with high id203, x4
3. show that with high id203, |x1|     o(1/d1/4).

1 + x4

1 + x4

1
2d/4 .

exercise 1.42 suppose there is an object moving at constant velocity along a straight
line. you receive the gps coordinates corrupted by gaussian noise every minute. how do
you estimate the current position?

exercise 1.43 generate ten values by a gaussian id203 distribution with zero mean
and variance one. what is the center determined by averaging the points? what is the
variance? in estimating the variance use both the real center and the estimated center.
when using the estimated center to estimate the variance, use both n = 10 and n = 9.
how do the three estimates compare?

35

exercise 1.44 suppose you want to estimate the (unknown) center of a gaussian in d-
space which has variance one in each direction. show that o(log d/  2) random samples
from the gaussian are su   cient to get an estimate      of the true center    so that with
id203 at least 99/100, we have

|           |          .

how many samples are su   cient to ensure that

|           |       ?

exercise 1.45 let g be a d-dimensional spherical gaussian with variance 1
the origin. derive the expected squared distance to the origin.

exercise 1.46 show that the maximum of f (t) =(cid:0)   

1     2t  k(cid:1)(d   k)(cid:16)(cid:112)1     2t (  k     d)
(cid:17)k

2 centered at

is attained at t = 1     
hint: maximize the logarithm of f (t) by di   erentiating.

2  (d   k  ).

exercise 1.47 generate 20 points uniformly at random on a 1000-dimensional sphere
of radius 100. calculate the distance between each pair of points. then project the data
onto subspaces of dimension k=100, 50, 10, 5, 4, 3, 2, 1 and calculate the sum of squared
error between k
d times the original distances and the new pair wise distances for each of
the above values of k.

exercise 1.48 you are given two sets, p and q, of n points each in n-dimensional space.
your task is to    nd the closest pair of points, one each from p and q, i.e.,    nd x in p
and y in q such that |x     y| is minimum.

1. show that this can be done in time o(n3).

2. show how to do this with relative error 0.1% in time o(n2 ln n), i.e., you must    nd
a pair x     p, y     q so that the distance between them is, at most, 1.001 times the
minimum possible distance. if the minimum distance is 0, you must    nd x = y.

exercise 1.49 given n data points in d-space,    nd a subset of k data points whose vector

sum has the smallest length. you can try all(cid:0)n
o(kd) for a total time of o(cid:0)(cid:0)n

(cid:1) subsets, compute each vector sum in time
(cid:1)kd(cid:1). show that we can replace d in the expression above

k

k

by o(k ln n), if we settle for an answer with relative error .02%.

exercise 1.50 create a list of the    ve most important things that you learned about high
dimensions.

exercise 1.51 write a short essay whose purpose is to excite a college freshman to learn
about high dimensions.

36

