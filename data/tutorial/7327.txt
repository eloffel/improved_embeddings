large scale distributed systems for 

training neural networks

jeff dean & oriol vinyals

google

google brain team in collaboration with many other teams 

background

google brain project started in 2011, with a focus on 
pushing state-of-the-art in neural networks.  initial 
emphasis:

    use large datasets, and 
    large amounts of computation

to push boundaries of what is possible in perception and 
language understanding

overview

    cover our experience from past ~5 years

    research: speech, images, video, robotics, language understanding, 

nlp, translation, optimization algorithms, unsupervised learning,    

    production: deployed systems for advertising, search, gmail, photos, 
maps, youtube, id103, image analysis, user prediction,    

    focus on neural nets, but many techniques more 

broadly applicable

overview

    demonstrate tensorflow, an open source machine 

learning system
    our primary research and production system
    show real examples
    explain what   s happening underneath the covers

outline

    introduction to deep learning
    tensorflow basics

    demo
    implementation overview

    scaling up

    model parallelism
    data parallelism
    expressing these in tensorflow

    more complex examples

    id98s / deep lstms

growing use of deep learning at google
# of directories containing model description files

s
e
i
r
o
t
c
e
r
i

d

 
t
c
e
o
r

j

 

p
e
u
q
n
u

i

time

across many 
products/areas:

android
apps
drug discovery
gmail
image understanding
maps
natural language 
understanding
photos
robotics research
speech
translation
youtube
    many others ...

deep learning

universal machine learning

speech
text
search 
queries
images
videos
labels
entities
words
audio
features

speech
text
search 
queries
images
videos
labels
entities
words
audio
features

deep learning

universal machine learning

...that works better than the alternatives!

current state-of-the-art in:

id103
image recognition
machine translation

molecular activity prediction

road hazard detection

id42

...

convnets

some more benefits

deals very naturally w/sequence data (text, speech, video...)

very effective at id21 across tasks

very easy to get started with a commodity gpu

a common    language    across great many fields of research

two generations of distributed ml systems

1st generation - distbelief (dean et al., nips 2012)

    scalable, good for production, but not very flexible for research

2nd generation - tensorflow (see tenorflow.org and 
whitepaper 2015, tensorflow.org/whitepaper2015.pdf)

    scalable, good for production, but also flexible for variety of research uses
    portable across range of platforms
    open source w/ apache 2.0 license

need both large datasets & large, powerful models
   scaling recurrent neural network language models   , williams et al. 2015
arxiv.org/pdf/1502.00512v1.pdf

large datasets + powerful models

    combination works incredibly well
    poses interesting systems problems, though:

    need lots of computation
    want to train and do experiments quickly
    large-scale parallelism using distributed systems 

really only way to do this at very large scale

    also want to easily express machine learning ideas

basics of deep learning

    unsupervised cat
    speech
    vision
    general trend is towards more complex models:

    embeddings of various kinds
    generative models
    layered lstms
    attention

learning from unlabeled images

    train on 10 million images (youtube)
    1000 machines (16,000 cores) for 1 week.
    1.15 billion parameters

learning from unlabeled images

top 48 stimuli from the test set

optimal stimulus 

by numerical optimization

learning from unlabeled images

top 48 stimuli from the test set

optimal stimulus 

by numerical optimization

adding supervision

top stimuli for selected neurons. 

speech: feedforward acoustic models

model speech frame-by-frame, 
independently

simple fully-connected networks

deep neural networks for 
acoustic modeling in speech 
recognition
hinton et al. ieee signal 
processing magazine, 2012

cldnns

model frequency invariance using 1d convolutions

model time dynamics using an lstm

use fully connected layers on top to add depth

convolutional, long short-term memory,
fully connected deep neural networks

sainath et al. icassp   15

trend: lstms end-to-end!

speech

acoustics

id102

language

text

train recurrent models that also incorporate lexical and id38:

fast and accurate recurrent neural network

acoustic models for id103, h. sak et al. 2015

deep speech: scaling up end-to-end id103, a. hannun et al. 2014

listen, attend and spell, w. chan et al. 2015

id98s for vision: alexnet

id163 classification with deep convolutional neural networks
krizhevsky, sutskever and hinton, nips 2012

the inception architecture (googlenet, 2015)

basic module, which is then 
replicated many times

the inception architecture (googlenet, 2015)

going deeper with convolutions

christian szegedy, wei liu, yangqing jia, pierre sermanet, scott reed, dragomir anguelov, 

dumitru erhan, vincent vanhoucke, andrew rabinovich

arxiv 2014, cvpr 2015

inception-v3 (december 2015)

http://arxiv.org/abs/1512.00567

rapid progress in image recognition

team

year

place

error (top-5)

params

xrce (pre-neural-net explosion)

supervision (alexnet)

clarifai

msra

vgg

googlenet (inception)

andrej karpathy (human)

bn-inception (arxiv)

inception-v3 (arxiv)

2011

2012

2013

2014

2014

2014

2014

2015

2015

1st

1st

1st

3rd

2nd

1st

n/a

n/a

n/a

25.8%

16.4%

11.7%

7.35%

7.32%

6.66%

5.1%

4.9%

3.46%

60m

65m

180m

5m

100 trillion?

13m

25m

id163 
challenge 
classification 
task

models with small number of parameters fit easily in a mobile app (8-bit fixed point)

today   s news: pre-trained inception-v3 model released

http://googleresearch.blogspot.com/2015/12/how-to-classify-images-with-tensorflow.html

dear tensorflow community,

today we are releasing our best image classifier trained on id163 data. as described in our 
recent arxiv preprint at http://arxiv.org/abs/1512.00567, an ensemble of four of these models 
achieves 3.5% top-5 error on the validation set of the id163 whole image ilsvrc2012 
classification task (compared with our ensemble from last year that won the 2014 id163 
classification challenge with a 6.66% top-5 error rate).

in this release, we are supplying code and data files containing the trained model parameters for 
running the image classifier on:

    both desktop and mobile environments
    employing either a c++ or python api.

in addition, we are providing a tutorial that describes how to use the image recognition system for a 
variety of use-cases.
    http://www.tensorflow.org/tutorials/image_recognition/index.html

what do you want in a research system?

    ease of expression: for lots of crazy ml ideas/algorithms
    scalability: can run experiments quickly
    portability: can run on wide variety of platforms
    reproducibility: easy to share and reproduce research
    production readiness: go from research to real products

tensorflow:

second generation deep learning system

if we like it, wouldn   t the rest of the world like it, too?

open sourced single-machine tensorflow on monday, nov. 9th
    flexible apache 2.0 open source licensing
    updates for distributed implementation coming soon

http://tensorflow.org/

motivations

distbelief (1st system):

    great for scalability, and production training of basic kinds of models
    not as flexible as we wanted for research purposes

better understanding of problem space allowed us to 
make some dramatic simplifications

tensorflow: expressing high-level ml computations

    core in c++

core tensorflow execution system

cpu

gpu

android

ios

...

tensorflow: expressing high-level ml computations

    core in c++
    different front ends for specifying/driving the computation

    python and c++ today, easy to add more

core tensorflow execution system

cpu

gpu

android

ios

...

tensorflow: expressing high-level ml computations

    core in c++
    different front ends for specifying/driving the computation

    python and c++ today, easy to add more

c++ front end

python front end

...

core tensorflow execution system

cpu

gpu

android

ios

...

portable
automatically runs models on range of platforms:

from phones ...

to single machines (cpu and/or gpus)    

to distributed systems of many 100s of gpu cards

computation is a dataflow graph

graph of nodes, also called operations or ops.

add

relu

matmul

xent

biases

weights

examples

labels

computation is a dataflow graph

t e n s o r

s

t h  

w i

edges are n-dimensional arrays: tensors

add

relu

matmul

xent

biases

weights

examples

labels

computation is a dataflow graph

t h   s t a t e

w i

'biases' is a variable

some ops compute gradients

   = updates biases

biases

...

add

...

mul

   =

learning rate

computation is a dataflow graph

i b u t e d

d i s t

r

device a

device b

add

...

mul

   =

biases

...

learning rate

devices: processes, machines, gpus, etc

send and receive nodes

i b u t e d

d i s t

r

device a

device b

add

...

mul

   =

biases

...

learning rate

devices: processes, machines, gpus, etc

send and receive nodes

i b u t e d

d i s t

r

send

recv

add
add

...

mul

   =

device a

device b

biases

...

learning rate

devices: processes, machines, gpus, etc

send and receive nodes

i b u t e d

d i s t

r

biases

...

send

send

recv

recv

device a

device b

add

...

mul

send

recv

   =

recv

learning rate

send

devices: processes, machines, gpus, etc

send and receive implementations

    different implementations depending on source/dest devices
    e.g. gpus on same machine: local gpu     gpu copy
    e.g. cpus on different machines: cross-machine rpc
    e.g. gpus on different machines: rdma

extensible
    core system defines a number of standard operations 

and kernels (device-specific implementations of 
operations)

    easy to define new operators and/or kernels

session interface

    extend: add nodes to computation graph
    run: execute an arbitrary subgraph

    optionally feeding in tensor inputs and retrieving tensor output

typically, setup a graph with one or a few extend calls and 
then run it thousands or millions or times

single process configuration

distributed configuration

rpc

rpc

rpc

rpc

feeding and fetching

run(input={   b   : ...}, outputs={   f:0   })

feeding and fetching

run(input={   b   : ...}, outputs={   f:0   })

example: power method for eigenvectors
    simple 5x5 matrix, compute result, iterated k times
    tensorboard graph visualization

under the hood: power method

    operators
    kernel implementations for different devices
    run call
    tensor memory management

example: symbolic differentiation

    f(x) = xt * w * x ; now minimize
    show df/dx = 2*wx in graph

tensorflow single device performance

initial measurements done by soumith chintala

benchmark

alexnet - cudnnv3 on torch (soumith)

alexnet - neon (soumith)

alexnet - cudnnv2 on torch (soumith)

alexnet - cudnnv2 on tensorflow 0.5 (soumith)

forward

forward+backward

32 ms

32 ms

70 ms

96 ms

96 ms

101 ms

231 ms

326 ms

see https://github.com/soumith/convnet-benchmarks/issues/66
two main factors:
(1) various overheads (nvcc doesn   t like 64-bit tensor indices, etc.)
(2) versions of convolutional libraries being used (cudnnv2 vs. v3, etc.)

tensorflow single device performance

prong 1: tackling sources of overhead

benchmark

alexnet - cudnnv3 on torch (soumith)

alexnet - neon (soumith)

alexnet - cudnnv2 on torch (soumith)

alexnet - cudnnv2 on tensorflow 0.5 (soumith)

alexnet - cudnnv2 on tensorflow 0.5 (our machine)

forward

forward+backward

32 ms

32 ms

70 ms

96 ms

97 ms

96 ms

101 ms

231 ms

326 ms

336 ms

tensorflow single device performance

prong 1: tackling sources of overhead

benchmark

alexnet - cudnnv3 on torch (soumith)

alexnet - neon (soumith)

alexnet - cudnnv2 on torch (soumith)

alexnet - cudnnv2 on tensorflow 0.5 (soumith)

alexnet - cudnnv2 on tensorflow 0.5 (our machine)

forward

forward+backward

32 ms

32 ms

70 ms

96 ms

97 ms

96 ms

101 ms

231 ms

326 ms

336 ms

alexnet - cudnnv2 on tensorflow 0.6 (our machine: soon)

70 ms (+39%)

230 ms (+31%)

tensorflow single device performance

prong 1: tackling sources of overhead

benchmark

alexnet - cudnnv3 on torch (soumith)

alexnet - neon (soumith)

alexnet - cudnnv2 on torch (soumith)

alexnet - cudnnv2 on tensorflow 0.5 (soumith)

alexnet - cudnnv2 on tensorflow 0.5 (our machine)

forward

forward+backward

32 ms

32 ms

70 ms

96 ms

97 ms

96 ms

101 ms

231 ms

326 ms

336 ms

alexnet - cudnnv2 on tensorflow 0.6 (our machine: soon)

70 ms (+39%)

230 ms (+31%)

tensorflow single device performance

tf 0.5 vs. 0.6 release candidate measurements (on our machine w/ titan-x)

benchmark

alexnet - cudnnv2 on tensorflow 0.5

forward

forward+backward

97 ms

336 ms

alexnet - cudnnv2 on tensorflow 0.6 (soon)

70 ms (+27%)

230 ms (+31%)

oxfordnet - cudnnv2 on tensorflow 0.5

573 ms

1923 ms

oxfordnet - cudnnv2 on tensorflow 0.6 (soon)

338 ms (+41%)

1240 ms (+36%)

overfeat - cudnnv2 on tensorflow 0.5

322 ms

1179 ms

overfeat - cudnnv2 on tensorflow 0.6 (soon)

198 ms (+39%)

832 ms (+29%)

tensorflow single device performance

prong 2: upgrade to faster core libraries like cudnn v3 
(and/or the upcoming v4)

won   t make it into 0.6 release later this week, but likely in 
next release

single device performance important, but

   .

 biggest performance improvements come 
from large-scale distributed systems with 

model and data parallelism

experiment turnaround time and research productivity
    minutes, hours:

    interactive research!  instant gratification!

    1-4 days

    tolerable
    interactivity replaced by running many experiments in parallel

    1-4 weeks

    high value experiments only
    progress stalls

    >1 month

    don   t even try

transition

    how do you do this at scale?
    how does tensorflow make distributed training easy?

model parallelism

    best way to decrease training time: decrease the step 

time

    many models have lots of inherent parallelism
    problem is distributing work so communication doesn   t 

kill you
    local connectivity (as found in id98s)
    towers with little or no connectivity between towers (e.g. alexnet)
    specialized parts of model active only for some examples

exploiting model parallelism

on a single core: instruction parallelism (simd). pretty much 
free.

across cores: thread parallelism. almost free, unless across 
sockets, in which case inter-socket bandwidth matters (qpi on 
intel).

across devices: for gpus, often limited by pcie bandwidth.

across machines: limited by network bandwidth / latency

model parallelism

model parallelism

model parallelism

data parallelism

    use multiple model replicas to process different 

examples at the same time
    all collaborate to update model state (parameters) in shared 

parameter server(s)

    speedups depend highly on kind of model

    dense models: 10-40x speedup from 50 replicas
    sparse models:

    support many more replicas
    often can use as many as 1000 replicas

data parallelism

parameter servers

 

model
replicas

data

...
...

data parallelism

parameter servers

 

p

model
replicas

data

...
...

data parallelism

parameter servers

 

   p

p

model
replicas

data

...
...

data parallelism

parameter servers

p    = p +    p

 

   p

p

model
replicas

data

...
...

data parallelism

parameter servers

p    = p +    p

 

p   

...
...

model
replicas

data

data parallelism

parameter servers

 

   p   

p   

model
replicas

data

...
...

data parallelism

parameter servers

p       = p    +    p

 

   p   

p   

model
replicas

data

...
...

data parallelism

parameter servers

p       = p    +    p

 

   p   

p   

model
replicas

data

...
...

data parallelism choices

can do this synchronously:

    n replicas equivalent to an n times larger batch size
    pro: no gradient staleness
    con: less fault tolerant (requires some recovery if any single machine fails)

can do this asynchronously:

    pro: relatively fault tolerant (failure in model replica doesn   t block other 

replicas)

    con: gradient staleness means each gradient less effective

(or hybrid: m asynchronous groups of n synchronous replicas)

data parallelism considerations

want model computation time to be large relative to time to 
send/receive parameters over network

models with fewer parameters, that reuse each parameter multiple times in the 
computation

    mini-batches of size b reuse parameters b times

certain model structures reuse each parameter many times within each example:

    convolutional models tend to reuse hundreds or thousands of times per 

example (for different spatial positions)

    recurrent models (lstms, id56s) tend to reuse tens to hundreds of times 

(for unrolling through t time steps during training)

success of data parallelism

    data parallelism is really important for many of google   s 

problems (very large datasets, large models):
    rankbrain uses 500 replicas
    id163 inception training uses 50 gpus, ~40x 

speedup

    smartreply uses 16 replicas, each with multiple gpus
    state-of-the-art on lm    one billion word    benchmark 

model uses both data and model parallelism on 32 
gpus

10 vs 50 replica inception synchronous training

50 replicas
10 replicas

hours

10 vs 50 replica inception synchronous training

19.6 vs. 80.3 (4.1x)

5.6 vs. 21.8 (3.9x)

50 replicas
10 replicas

hours

using tensorflow for parallelism

trivial to express both model parallelism as well as data 
parallelism

    very minimal changes to single device model code

devices and graph placement
    given a graph and set of devices, tensorflow 

implementation must decide which device executes 
each node

full and partial device constraints (hints)

devices are named hierarchically:

/job:localhost/device:cpu:0
/job:worker/task:17/device:gpu:3
/job:parameters/task:4/device:cpu:0

client can specify full or partial constraints for nodes in 
graph:

   place this node on /job:localhost/device:gpu:2   

   place this node on /device:gpu:*   

placement algorithm

given hints, plus a cost model (node execution time 
estimates and tensor size estimates), make placement 
decisions

    current relatively simple greedy algorithm
    active area of work

show cifar10 placement tensorboard.

example: lstm [hochreiter et al, 1997]

    from research paper to code

sequence-to-sequence model

[sutskever & vinyals & le nips 2014]

target sequence

 x

 y

 z

 q

v

 a

 b

 c

 d

__

 x

 y

 z

input sequence

sequence-to-sequence

    active area of research
    many groups actively pursuing id56/lstm

    montreal
    stanford
    u of toronto
    berkeley
    google
    ...

    further improvements

    attention
    ntm / memory nets
    ...

sequence-to-sequence

    translation: [kalchbrenner et al., emnlp 2013][cho et al., emlp 2014][sutskever & vinyals & le, nips 

2014][luong et al., acl 2015][bahdanau et al., iclr 2015]

    image captions: [mao et al., iclr 2015][vinyals et al., cvpr 2015][donahue et al., cvpr 2015][xu et al., 

icml 2015]

    speech: [chorowsky et al., nips dl 2014][chan et al., arxiv 2015]
    language understanding: [vinyals & kaiser et al., nips 2015][kiros et al., nips 2015]
    dialogue: [shang et al., acl 2015][sordoni et al., naacl 2015][vinyals & le, icml dl 2015]
    video generation: [srivastava et al., icml 2015] 
    algorithms: [zaremba & sutskever, arxiv 2014][vinyals & fortunato & jaitly, nips 2015][kaiser & 

sutskever, arxiv 2015][zaremba et al., arxiv 2015]

how to do image captions?

p(english | french)
p(english | image )

how?

[vinyals et al., cvpr 2015]

 a

young

 girl

 asleep

w

__

 a

young

 girl

human: a young girl asleep on 
the sofa cuddling a stuffed 
bear.

nic: a close up of a child 
holding a stuffed animal.

nic: a baby is asleep next to a 
teddy bear.

(recent) captioning results

source: http://mscoco.org/dataset/#leaderboard-cap

method

google nic
msr capt

ucla/baidu v2

msr

msr nearest

human

ucla/baidu v1
lrcn berkeley
uofm/toronto

meteor
0.346 (1)
0.339 (2)
0.325 (5)
0.331 (4)
0.318 (10)
0.335 (3)
0.320 (8)
0.322 (7)
0.323 (6)

cider
0.946 (1)
0.937 (2)
0.935 (3)
0.925 (4)
0.916 (5)
0.910 (6)
0.896 (7)
0.891 (8)
0.878 (9)

lsun
0.273 (2)
0.250 (3)
0.223 (5)
0.268 (2)
0.216 (6)
0.638 (1)
0.190 (9)
0.246 (4)
0.262 (3)

lsun (2)
0.317 (2)
0.301 (3)
0.252 (7)
0.322 (2)
0.255 (6)
0.675 (1)
0.241 (8)
0.268 (5)
0.272 (4)

human: a close up of two 
bananas with bottles in the 
background.

bestmodel: a bunch of bananas 
and a bottle of wine.

initialmodel: a close up of a 
plate of food on a table.

human: a view of inside of a car 
where a cat is laying down.

bestmodel: a cat sitting on top 
of a black car.

initialmodel: a dog sitting in 
the passenger seat of a car.

human: a brown dog laying in a 
red wicker bed.

bestmodel: a small dog is 
sitting on a chair.

initialmodel: a large brown dog 
laying on top of a couch. 

human: a man outside cooking 
with a sub in his hand.

bestmodel: a man is holding a 
sandwich in his hand.

initialmodel: a man cutting a 
cake with a knife.

human: someone is using a 
small grill to melt his sandwich.

bestmodel: a person is cooking 
some food on a grill. 

initialmodel: a pizza sitting on 
top of a white plate.

human: a woman holding up a 
yellow banana to her face.

bestmodel: a woman holding a 
banana up to her face.

initialmodel: a close up of a 
person eating a hot dog. 

human: a blue , yellow and red 
train travels across the tracks 
near a depot.

bestmodel: a blue and yellow 
train traveling down train 
tracks. 

initialmodel: a train that is 
sitting on the tracks.

id193 teaser
    goal: mappings where outputs are (sub)sets of inputs
    travelling salesman problem

    convex hulls

id193

   

   

2

1

1

5

6

x1y1

 

x2y2

 

x3y3

 

x4y4

x5y5

 

x6y6

 

      

x1y1

x6y6

 

x5y5

x2y2

 

x1y1

 

poster => wed. 210c #22

neural conversational models

    take movie subtitles (~900m words) or it helpdesk chats
    predict the next dialog from history
i got to go .
no .
i get too emotional when i drink .
have another beer . i 've got to get up early .
no , you don 't . sit down .
i get too emotional when i drink .
will you have another beer ?
i 've got to go !
why ?
i got to get up early in the morning .
you 're drunk .
and emotional !
you got to go .

[vinyals & le icml dl workshop 2015]

smart reply

incoming email

small feed-

forward

neural network

deep recurrent
neural network

google research blog
- nov 2015

activate

smart reply?
yes/no

generated replies

example: lstm

for i in range(20):
      m, c = lstmcell(x[i], mprev, cprev)
      mprev = m
      cprev = c

example: deep lstm

for i in range(20):
  for d in range(4): # d is depth
      input = x[i] if d is 0 else m[d-1]
      m[d], c[d] = lstmcell(input, mprev[d], cprev[d])
      mprev[d] = m[d]
      cprev[d] = c[d]

example: deep lstm

for i in range(20):
  for d in range(4): # d is depth
      input = x[i] if d is 0 else m[d-1]
      m[d], c[d] = lstmcell(input, mprev[d], cprev[d])
      mprev[d] = m[d]
      cprev[d] = c[d]

example: deep lstm

for i in range(20):
  for d in range(4): # d is depth
    with tf.device("/gpu:%d" % d):
      input = x[i] if d is 0 else m[d-1]
      m[d], c[d] = lstmcell(input, mprev[d], cprev[d])
      mprev[d] = m[d]
      cprev[d] = c[d]

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

gpu6

gpu5

a

a

b

b

c

c

d

d

gpu4

gpu3

gpu2

gpu1

a

b

c 

d

_
_

a

b

c

80k softmax by
1000 dims
this is very big!

split softmax into
4 gpus

1000 lstm cells
2000 dims per
timestep

2000 x 4 = 
8k dims per
sentence

tensorflow queues

input prefetching

grouping similar examples

randomization/shuffling

...

dequeue

enqueue

queue

...

example: deep lstms

    wrinkles

    bucket sentences by length using a queue per length
    dequeue when a full batch of same length has 

accumulated

    n different graphs for different lengths
    alternative: while loop

expressing data parallelism

# we use the replicadevicesetter() device function to automatically
# assign variables to the 'ps' jobs.   
with tf.device(   /cpu:0   ):
      # create the mnist model.
      model = mnistmodel(batch_size=16, hidden_units=200)

      # get an initialized, and possibly recovered session.  
      sess = tf.session()

      # train the model.
      for local_step in xrange(flags.max_steps):
        _, loss, step = sess.run([model.train_op, model.loss, model.global_step])
        if local_step % 1000 == 0:
          print "step %d: %g" % (step, loss)

expressing data parallelism

# we use the replicadevicesetter() device function to automatically
# assign variables to the 'ps' jobs.   
with tf.device(tf.replicadevicesetter(parameter_devices=10)):
      # create the mnist model.
      model = mnistmodel(batch_size=16, hidden_units=200)

      # create a supervisor.  it will take care of initialization, summaries,
      # checkpoints, and recovery. when multiple replicas of this program are running,
      # the first one, identified by --task=0 is the 'chief' supervisor (e.g., initialization, saving) 
      supervisor = tf.supervisor(is_chief=(flags.task == 0), saver=model.saver)

      # get an initialized, and possibly recovered session.  
      sess = supervisor.preparesession(flags.master_job)

      # train the model.
      for local_step in xrange(int32_max):
        _, loss, step = sess.run([model.train_op, model.loss, model.global_step])
        if step >= flags.max_steps:
          break
        if local_step % 1000 == 0:
          print "step %d: %g" % (step, loss)

asynchronous training
    unlike distbelief, no separate parameter server system:
    parameters are now just stateful nodes in the graph

synchronous variant

network optimizations

    neural net training very tolerant of reduced precision
    e.g. drop precision to 16 bits across network

device a

device b

params

send

recv

input

mat
mul

...

network optimizations

    neural net training very tolerant of reduced precision
    e.g. drop precision to 16 bits across network

device a

device b

params

tofp16

send

tofp32

recv

input

mat
mul

...

quantization for id136

    need even less precision for id136
    8-bit fixed point works well, but many ways of 

quantizing

    critical for things like mobile devices

    w/quantization, high-end smart phone can run 
inception model at >6 frames per second (fps)

open source status for distributed tensorflow
multi gpu in single machine already in open source release

    see 4-gpu cifar10 training example in repository

distributed implementation coming soon:

    github tracking issue: github.

com/tensorflow/tensorflow/issues/23

concluding remarks

    model and data parallelism enable great ml work:

    id4: ~6x speedup on 8 gpus
    inception / id163: ~40x speedup on 50 gpus
    rankbrain: ~300x speedup on 500 machines

    a variety of different parallelization schemes are easy to 

express in tensorflow

concluding remarks

    open sourcing of tensorflow

    rapid exchange of research ideas (we hope!)
    easy deployment of ml systems into products
    tensorflow community doing interesting things!

a few tensorflow community examples

    id25: github.com/nivwusquorum/tensorflow-deepq
    neuralart: github.com/woodrush/neural-art-tf
    char id56: github.com/sherjilozair/char-id56-tensorflow
    keras ported to tensorflow: github.com/fchollet/keras
    show and tell: github.com/jazzsaxmafia/show_and_tell.tensorflow
    mandarin translation: github.com/jikexueyuanwiki/tensorflow-zh

...

 github.com/nivwusquorum/tensorflow-deepq

github.com/woodrush/neural-art-tf

github.com/sherjilozair/char-id56-tensorflow

github.com/fchollet/keras

github.com/jazzsaxmafia/show_and_tell.tensorflow

github.com/jikexueyuanwiki/tensorflow-zh

google brain residency program

new one year immersion program in deep learning research

learn to conduct deep learning research w/experts in our team
    fixed one-year employment with salary, benefits, ...
    goal after one year is to have conducted several research projects
    interesting problems, tensorflow, and access to computational resources

google brain residency program

who should apply? 
    people with bsc, msc or phd, ideally in cs, mathematics or statistics
    completed coursework in calculus, id202, and id203, or equiv.
    programming experience
    motivated, hard working, and have a strong interest in deep learning

google brain residency program

 program application & timeline
deadline: january 15, 2016

google brain residency program

for more information:

g.co/brainresidency

contact us:

brain-residency@google.com

