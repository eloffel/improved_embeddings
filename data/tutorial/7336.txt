mining	
knowledge	
graphs	from	text

wsdm	2018
jay pujara,	sameer singh

tutorial	overview
https://kgtutorial.github.io

part	1:	knowledge	graphs

part	2:	
knowledge	
extraction

part	3:
graph	
construction

part	4:	critical	analysis

2

tutorial	outline
1. knowledge	graph	primer	
2.	 knowledge	extraction	primer
3. knowledge	graph	construction

a.

probabilistic	models	

[jay]
[jay]

[jay]

coffee	break

b.

embedding	techniques	

[sameer]
4. critical	overview	and	conclusion	 [sameer]

3

knowledge	graph	

construction

topics:
problem setting
probabilistic models
embedding techniques

4

knowledge	graph	

construction

topics:
problem setting
probabilistic models
embedding techniques

5

reminder:	basic	problems

    who	are	the	entities	
(nodes)	in	the	graph?

    what are	their	attributes	
and	types	(labels)?

    how	are	they	related	
(edges)?

e1

a1
a2

e3

a1
a2

e2

a1
a2

6

graph	construction	issues

extracted	knowledge	is:
    ambiguous:

    ex:	beetles,	beetles,	beatles
    ex:	citizenof,	livedin,	bornin

7

graph	construction	issues

extracted	knowledge	is:
    ambiguous

    incomplete

    ex:	missing	relationships
    ex:	missing	labels
    ex:	missing	entities

8

graph	construction	issues

extracted	knowledge	is:
    ambiguous

    incomplete

    inconsistent

    ex:	cynthia	lennon,	yoko	ono
    ex:	exclusive	labels	(alive,	dead)
    ex:	domain-range	constraints

e
s
u
o
p
s

spouse

9

graph	construction	issues

extracted	knowledge	is:
    ambiguous

    incomplete

    inconsistent

10

graph	construction	approach
   graph	construction	cleans	and	completes	extraction	graph

   incorporate	ontological	constraints	and	relational	patterns

   discover	statistical	relationships	within	knowledge	graph

11

knowledge	graph	

construction

topics:
problem setting
probabilistic models
embedding techniques

12

graph	construction

probabilistic	models

topics:
overview
id114
random walk methods

13

graph	construction

probabilistic	models

topics:
overview
id114
random walk methods

14

beyond	pure	reasoning

   classical	ai	approach	to	knowledge:	reasoning
lbl(socrates,	man)	&	sub(man,	mortal)	->	lbl(socrates,	mortal)

15

beyond	pure	reasoning

   classical	ai	approach	to	knowledge:	reasoning
lbl(socrates,	man)	&	sub(man,	mortal)	->	lbl(socrates,	mortal)
   reasoning	difficult	when	extracted	knowledge	has	errors

16

beyond	pure	reasoning

   classical	ai	approach	to	knowledge:	reasoning
lbl(socrates,	man)	&	sub(man,	mortal)	->	lbl(socrates,	mortal)
   reasoning	difficult	when	extracted	knowledge	has	errors
   solution:	probabilistic	models	
p(lbl(socrates,	mortal)|lbl(socrates,man)=0.9)

17

graph	construction

probabilistic	models

topics:
overview
id114
random walk methods

18

graphical	models:	overview
   define	joint	id203	distribution on	knowledge	graphs

   each	candidate	fact	in	the	knowledge	graph	is	a	variable

   statistical	signals,	ontological	knowledge	and	rules	
parameterize	the	dependencies	between	variables

   find	most	likely	knowledge	graph	by	optimization/sampling

19

knowledge	graph	identification
define	a	graphical	model	to	
perform	all	three	of	these	
tasks	simultaneously!

e1

a1
a2

    who	are	the	entities	
(nodes)	in	the	graph?

    what are	their	attributes	
and	types	(labels)?

    how	are	they	related	
(edges)?

e2

a1
a2

e3

a1
a2

pujara+iswc13

20

knowledge	graph	identification

p(who,	what,	how|extractions)

e1

a1
a2

e3

a1
a2

e2

a1
a2

pujara+iswc13

21

probabilistic	models
   use	dependencies	between	facts	in	kg	

   id203	defined	jointly over	facts

p=0

p=0.25

p=0.75

22

what	determines	id203?
   statistical	signals	from	text	extractors	and	classifiers

23

what	determines	id203?
   statistical	signals	from	text	extractors	and	classifiers
    p(r(john,spouse,yoko))=0.75;	p(r(john,spouse,cynthia))=0.25
    levenshteinsimilarity(beatles,	beetles)	=	0.9

24

what	determines	id203?
   statistical	signals	from	text	extractors	and	classifiers

   ontological	knowledge	about	domain

25

what	determines	id203?
   statistical	signals	from	text	extractors	and	classifiers

   ontological	knowledge	about	domain
    functional(spouse)	&	r(a,spouse,b)	->	!r(a,spouse,c)
    range(spouse,	person)	&	r(a,spouse,b)	->	type(b,	person)

26

what	determines	id203?
   statistical	signals	from	text	extractors	and	classifiers

   ontological	knowledge	about	domain

   rules	and	patterns	mined	from	data

27

what	determines	id203?
   statistical	signals	from	text	extractors	and	classifiers

   ontological	knowledge	about	domain

   rules	and	patterns	mined	from	data
    r(a,	spouse,	b)	&	r(a,	lives,	l)	->	r(b,	lives,	l)
    r(a,	spouse,	b)	&	r(a,	child,	c)	->	r(b,	child,	c)

28

what	determines	id203?
   statistical	signals	from	text	extractors	and	classifiers
    p(r(john,spouse,yoko))=0.75;	p(r(john,spouse,cynthia))=0.25
    levenshteinsimilarity(beatles,	beetles)	=	0.9

   ontological	knowledge	about	domain
    functional(spouse)	&	r(a,spouse,b)	->	!r(a,spouse,c)
    range(spouse,	person)	&	r(a,spouse,b)	->	type(b,	person)

   rules	and	patterns	mined	from	data
    r(a,	spouse,	b)	&	r(a,	lives,	l)	->	r(b,	lives,	l)
    r(a,	spouse,	b)	&	r(a,	child,	c)	->	r(b,	child,	c)

29

example:	the	fab	four

30

illustration	of	kg	identification

uncertain extractions:
.5: lbl(fab four, novel)
.7: lbl(fab four, musician)
.9: lbl(beatles, musician)
.8: rel(beatles,albumartist, 

abbey road)

pujara+iswc13;	pujara+aimag15

illustration	of	kg	identification

(annotated)	extraction	graph

uncertain extractions:
.5: lbl(fab four, novel)
.7: lbl(fab four, musician)
.9: lbl(beatles, musician)
.8: rel(beatles,albumartist, 

abbey road)

fab	four

beatles

musician

novel

abbey	road

pujara+iswc13;	pujara+aimag15

illustration	of	kg	identification

extraction	graph

uncertain extractions:
.5: lbl(fab four, novel)
.7: lbl(fab four, musician)
.9: lbl(beatles, musician)
.8: rel(beatles,albumartist, 

abbey road)

ontology:
dom(albumartist, musician)
mut(novel, musician)

fab	four

beatles

musician

novel

abbey	road

pujara+iswc13;	pujara+aimag15

illustration	of	kg	identification

(annotated)	extraction	graph

uncertain extractions:
.5: lbl(fab four, novel)
.7: lbl(fab four, musician)
.9: lbl(beatles, musician)
.8: rel(beatles,albumartist, 

abbey road)

ontology:
dom(albumartist, musician)
mut(novel, musician)
entity resolution:
sameent(fab four,  beatles)

fab	four

sameent

beatles

musician

novel

abbey	road

pujara+iswc13;	pujara+aimag15

illustration	of	kg	identification

(annotated)	extraction	graph

uncertain extractions:
.5: lbl(fab four, novel)
.7: lbl(fab four, musician)
.9: lbl(beatles, musician)
.8: rel(beatles,albumartist, 

abbey road)

ontology:
dom(albumartist, musician)
mut(novel, musician)
entity resolution:
sameent(fab four,  beatles)

fab	four

sameent

beatles

musician

novel

abbey	road

after	knowledge	graph	identification

musician

lbl

beatles

fab	four

rel(albumartist)

abbey	road

pujara+iswc13;	pujara+aimag15

probabilistic	graphical	model	for	kg

lbl(beatles,	novel)

lbl(fab	four,	novel)

lbl(beatles,	
musician)

lbl(fab	four,	
musician)

rel(beatles,	
albumartist,	
abbey	road)

rel(fab	four,	
albumartist,	
abbey	road)

defining	graphical	models
   many	options	for	defining	a	graphical	model

   we	focus	on	two	approaches,	mlns	and	psl,	that	use	rules

   mlns	treat	facts	as	boolean,	use	sampling	for	satisfaction

   psl	infers	a	   truth	value   	for	each	fact	via	optimization

37

rules	for	kg	model

100: 
100:

subsumes(l1,l2)
exclusive(l1,l2)

& label(e,l1)
& label(e,l1)

label(e,l2)
->
-> !label(e,l2)

100:
100:
100:

100:
100:

10:
10:

1:
1:
1:
1:
1:

inverse(r1,r2)
subsumes(r1,r2)
exclusive(r1,r2)

relation(r2,o,e)
& relation(r1,e,o) ->
& relation(r1,e,o) ->
relation(r2,e,o)
& relation(r1,e,o) -> !relation(r2,e,o)

domain(r,l)
range(r,l)

& relation(r,e,o)
& relation(r,e,o)

->  label(e,l)
label(o,l)
->

sameentity(e1,e2) & label(e1,l)
->
sameentity(e1,e2) & relation(r,e1,o) ->

label(e2,l)
relation(r,e2,o)

label_obie(e,l)
label_openie(e,l)
relation_pattern(r,e,o)

->
->
->

label(e,l)
label(e,l)
relation(r,e,o)
!relation(r,e,o)
!label(e,l)

jiang+icdm12;	pujara+iswc13,	pujara+aimag15

38

rules	to	distributions

   rules	are	grounded by	substituting	literals	into	formulas
wr : sameent(fab four, beatles) ^
   each	ground	rule	has	a	weighted	satisfaction	derived	
from	the	formula   s	truth	value

lbl(beatles, musician) ) lbl(fab four, musician)

p (g|e) =

1
z

exp"xr2r

wr r(g, e)#

   together,	the	ground	rules	provide	a	joint	id203	
distribution	over	knowledge	graph	facts,	conditioned	on	
the	extractions

jiang+icdm12;	pujara+iswc13

id203	distribution	over	kgs

p(g | e) =

1
z exp    

$
%

r   r   

wr

  r(g)
&
'

candlblt (fabfour, novel)

) lbl(fabfour, novel)

mut(novel, musician)

sameent(beatles, fabfour)

^ lbl(beatles, novel)
)   lbl(beatles, musician)

^ lbl(beatles, musician)
) lbl(fabfour, musician)

[ 1] candlblstruct(fabfour, novel)

) lbl(fabfour, novel)

[ 2] candrelpat(beatles, albumartist, abbeyroad)

) rel(beatles, albumartist, abbeyroad)

[ 3] sameent(beatles, fabfour)

^ lbl(beatles, musician)
) lbl(fabfour, musician)

[ 4] dom(albumartist, musician)

^ rel(beatles, albumartist, abbeyroad)
) lbl(beatles, musician)

[ 5] mut(musician, novel)

^ lbl(fabfour, musican)
)   lbl(fabfour, novel)

  1

  

  

  

lbl(fab	four,
novel)

lbl(beatles,
novel)

  5

  

lbl(fab	four,
musician)

lbl(beatles,
musician)

  3

  4

  

  2

rel(beatles,	
albumartist,	
abbey	road)

pujara+iswc13;	pujara+aimag15

how	do	we	get	a	knowledge	graph?
have:	p(kg)	forall kgs

need:	best	kg

e1p(

e3

a1
a2

a1
a2

)

e2

a1
a2

a1
a2

e1

e3

a1
a2

e2

a1
a2

map	id136:	optimizing	over	distribution	to	
find	the	best	knowledge	graph	

42

id136	and	kg	optimization
   finding	the	best	kg	satisfying	weighed	rules:	np	hard

   mlns	[discrete]:	monte	carlo	sampling	methods
   solution	quality	dependent	on	burn-in	time,	iterations,	etc.

   psl	[continuous]:	optimize	convex	linear	surrogate
   fast	optimization,	  -optimal	max	sat	lower	bound	

43

graphical	models	experiments

data:	~1.5m	extractions,	~70k	ontological	relations,	~500	relation/label	types
task:	collectively	construct	a	kg	and	evaluate	on	25k	target	facts

comparisons:
extract
rules
mln
psl

average	confidences	of	extractors	for	each	fact	in	the	nell	candidates
default,	rule-based	heuristic	strategy	used	by	the	nell	project
jiang+,	icdm12	    estimates	marginal	probabilities	with	mc-sat
pujara+,	iswc13	    convex	optimization	of	continuous	truth	values	with	admm

running	time:	id136	completes	in	10	seconds,	values	for	25k	facts

extract

rules

mln	(jiang, 12)

psl	(pujara,	13)

auc

.873

.765

.899

.904

f1

.828

.673

.836

.853

jiang+icdm12;	pujara+iswc13

graphical	models:	pros/cons
benefits
    define	id203	
distribution	over	kgs

drawbacks
    requires	optimization	over	
all	kg	facts	- overkill

    easily	specified	via	rules

    dependent	on	rules	from	
ontology/expert

    fuse	knowledge	from	many	
different	sources

    require	probabilistic	
semantics	- unavailable

45

graph	construction

probabilistic	models

topics:
overview
id114
random walk methods

46

random	walk	overview
   given:	a	query	of	an	entity	and relation

   starting	at	the	entity,	randomly	walk	the	kg

   random	walk	ends	when	reaching	an	appropriate	goal

   learned	parameters	bias	choices	in	the	random	walk

   output	relative	probabilities	of	goal	states

random	walk	illustration

query:	r(lennon,	playsinstrument,	?)

48

random	walk	illustration

query:	r(lennon,	playsinstrument,	?)

albumartist

playsinstrument

h
a
s
i
n
s
t
r
u
m
e
n
t

49

random	walk	illustration

query:	r(lennon,	playsinstrument,	?)

50

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

51

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

52

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

53

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

p(q|    =<coworker,playsinstrument>)	w    

path

weight	of	path

54

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

p(q|    =<coworker,playsinstrument>)	w    

55

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

p(q|    =<coworker,playsinstrument>)	w    

56

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

57

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

p(q|    =<albumartist,hasinstrument>)	w    

58

random	walk	illustration
query	q:	r(lennon,	playsinstrument,	?)

p(q|    =<albumartist,hasinstrument>)	w    

59

random	walk	illustration

query:	r(lennon,	playsinstrument,	?)

60

recent	random	walk	methods
pra:	path	ranking	algorithm
    performs	random	walk	of	imperfect	knowledge	graph
    estimates	transition	probabilities	using	kg
    for	each	relation,	learns	parameters	for	paths	through	the	kg

proppr:	programming	with	personalized	id95
    constructs	proof	graph

    nodes	are	partially-ground	clauses	with	one	or	more	facts
    edges	are	proof-transformations

    parameters are	learned	for	each	ground	entity	and	rule

61

recent	random	walk	methods
pra:	path	ranking	algorithm
    performs	random	walk	of	imperfect	knowledge	graph
    estimates	transition	probabilities	using	kg
    for	each	relation,	learns	parameters	for	paths	through	the	kg

proppr:	programming	with	personalized	id95
    constructs	proof	graph

    nodes	are	partially-ground	clauses	with	one	or	more	facts
    edges	are	proof-transformations

    parameters are	learned	for	each	ground	entity	and	rule

62

pra	in	a	nutshell

score(q.s ! e; q) = x   i2   b

p (q.s ! e;    i)w   i

lao+emnlp11

63

pra	in	a	nutshell

score(q.s ! e; q) = x   i2   b

p (q.s ! e;    i)w   i

filter	paths	based	on	hits	and	accuracy

lao+emnlp11

64

pra	in	a	nutshell

score(q.s ! e; q) = x   i2   b

p (q.s ! e;    i)w   i

filter	paths	based	on	hits	and	accuracy

estimate	probabilities	efficiently	with	dynamic	programming

lao+emnlp11

65

pra	in	a	nutshell

score(q.s ! e; q) = x   i2   b

p (q.s ! e;    i)w   i

filter	paths	based	on	hits	and	accuracy

estimate	probabilities	efficiently	with	dynamic	programming

path	weights	are	learned	with	logistic	regression

lao+emnlp11

66

recent	random	walk	methods
pra:	path	ranking	algorithm
    performs	random	walk	of	imperfect	knowledge	graph
    estimates	transition	probabilities	using	kg
    for	each	relation,	learns	parameters	for	paths	through	the	kg

proppr:	problog +	personalized	id95
    constructs	proof	graph

    nodes	are	partially-ground	clauses	with	one	or	more	facts
    edges	are	proof-transformations

    parameters are	learned	for	each	ground	entity	and	rule

67

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

unbound	variables	in	proof	tree!

68

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,y)

69

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,y)

70

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,y)

71

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,y)

r(									,coworker,								)
r(					,playsinstrument,					)

72

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,y)

r(									,albumartist,							)
r(							,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,					)

73

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,y)

r(									,albumartist,							)
r(							,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,					)

r(									,albumartist,							)
r(							,hasinstrument,					)

74

proppr-ized pra	example
query	q:	r(lennon,	playsinstrument,	?)

r(									,coworker,x)
r(x,playsinstrument,y)

r(									,albumartist,j)
r(j,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,y)

r(									,albumartist,							)
r(							,hasinstrument,k)

r(									,coworker,								)
r(					,playsinstrument,					)

r(									,albumartist,							)
r(							,hasinstrument,					)

75

proppr in	a	nutshell
w   xk2+

+] +xk2 

log p   0[uk

min

log(1   p   0[uk

 ]! +   ||w||2

2

   

input:	queries,	positive	answers,	negative	answers

    goal:

p   0[uk

+]   p   0[uk
 ]
learn:	random	walk	weights

   

(page	rank	from	rw)

    train	via	stochastic	gradient	descent

wang+mlj15

76

results	from	pra	and	proppr

    task:	

    1m	extractions	for	3	domains;
    ~100s	of	training	queries
    ~1000s	of	test	queries
    auc	of	extractions	alone	is	0.7

0.96

0.95

0.94

0.93

0.92

relation	prediction	auc

pra	(1m) 
proppr	(1m)

google

beatles

baseball

wang+mlj15

77

random	walks:	pros/cons
drawbacks
benefits
    full	kg	completion	task	
    kg	query	estimation	
inefficient
independent	of	kg	size

    model	training	produces	
interpretable,	logical	rules

    training	data	difficult	to	
obtain	at	scale

    robust	to	noisy	extractions	
through	probabilistic	form

    input	must	follow	
probabilistic	semantics

78

two	classes	of	probabilistic	models

graphical	models
    possible	facts	in	kg	are	
variables

random	walk	methods
    possible	facts	posed	as	
queries

    logical	rules	relate	facts

    random	walks	of	the	kg	
constitute	   proofs   

    id203							satisfied	
rules

    id203							path	
lengths/transitions

    universally-quantified

    locally	grounded

79

