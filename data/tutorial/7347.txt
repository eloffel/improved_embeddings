probabilistic programming

frank wood 

fwood@robots.ox.ac.uk 

nips tutorial 2015

my objectives

get you to 

    know what probabilistic program is and how it   s different 

to a normal program. 

    roughly understand how to write a probabilistic program 

and have the resources to get started if you want to. 

    understand the literature at a very high level. 

    know one way to roll your own state-of-the-art universal 

probabilistic programming system.

what is probabilistic 

programming?

the field

ml: 

algorithms &
applications

stats: 
id136 &

theory

probabilistic
programming

pl: 

compilers,
semantics,

transformations

intuition

id136

parameters

parameters

program

program

output

observations

cs

probabilistic programming

statistics

yp(y|x)p(x)p(x|p(x|y)a probabilistic program
   probabilistic programs are usual functional or 
imperative programs with two added constructs:  

(1) the ability to draw values at random from 
distributions, and  

(2) the ability to condition values of variables in a 
program via observations.     

   probabilistic programming.    in proceedings of on the future of software engineering (2014).

gordon, henzinger, nori, and rajamani  

goals of the field

increase programmer productivity

object tracking, [neiswanger et al 2014]

e
d
o
c
n
a
c

 

i
l

g
n
a

 
f

o
 
s
e
n
l

i

automata induction [pfau et al 2010]

collapsed lda

dp conjugate mixture

hpyp, [teh 2006]

lines of matlab/java code

caron et al.

commodify id136

this lack of consistency is shared by other models based on the p  olya urn construction (zhu
et al., 2005; ahmed and xing, 2008; blei and frazier, 2011). blei and frazier (2011) provide a
detailed discussion on this issue and describe cases where one should or should not bother about it.
it is possible to de   ne a slightly modi   ed version of our model that is consistent under marginal-

isation, at the expense of an additional set of latent variables. this is described in appendix c.

3.2 stationary models for cluster locations
to ensure we obtain a    rst-order stationary pitman-yor process mixture model, we also need to
satisfy (b). this can be easily achieved if for k 2 i(mt
t)
uk,t        p (  |uk,t 1)
if k 2 i(mt
otherwise

models / simulators 

in the time series
where h is the invariant distribution of the markov transition kernel p (  |  ).
literature, many approaches are available to build such transition kernels based on copulas (joe,
1997) or id150 techniques (pitt and walker, 2005).

t 1)

h

gaussian mixture model

combining the stationary pitman-yor and cluster locations models, we can summarize the full
model by the following id110 in figure 1. it can also be summarized using a chinese
restaurant metaphor (see figure 2).

id44

   

   d

zd
i

wd
i

 k

 

i = 1 . . . n d
.

d = 1...d

k = 1 . . . k

figure 1. graphical model for lda model

lecture lda

   d     dirk (   ~1)
 k     dirm( ~1)
z d
i     discrete(   d )
w d
i     discrete( z d

lda is a hierarchical model used to model text documents. each document is modeled as
a mixture of topics. each topic is de   ned as a distribution over the words in the vocabulary.
here, we will denote by k the number of topics in the model. we use d to indicate the
number of documents, m to denote the number of words in the vocabulary, and n d
. to
denote the number of words in document d. we will assume that the words have been
translated to the set of integers {1, . . . , m} through the use of a static dictionary. this is
for convenience only and the integer mapping will contain no semantic information. the
generative model for the d documents can be thought of as sequentially drawing a topic
mixture    d for each document independently from a dirk (   ~1) distribution, where dirk (~ )
is a dirichlet distribution over the k-dimensional simplex with parameters [ 1,  2, . . . ,  k ].
k=1 are drawn independently from dirm ( ~1). then, for each of the
each of k topics { k}k
is drawn from mult(   d).
i = 1 . . . n d. words in document d, an assignment variable zd
i
conditional on the assignment variable zd
i , is drawn
january, 2014
). the graphical model for the process can be seen in figure 1.
independently from mult( zd
k=1, the
, and the scalar positive parameters     and  . the model

the model is parameterized by the vector valued parameters {   d}d

i , word i in document d, denoted as wd

unsupervised machine learning

d=1, and { k}k

)

i

i

parameters {z d
is formally written as:

i }d=1,...,d,i=1,...,n d

.

wood (university of oxford)

   d     dirk (   ~1)
 k     dirm ( ~1)
zd
i     mult(   d)
wd
i     mult( zd

i

)

1

   c0

   

   c1

hy

hr

 m

   m  

   m
1

  r0

  s0

  r1

  s1

  y1

 r2
  

k

 r3

k

n

  s2
c

i

  y2
y

i

  s3

  

k

  y3

k

  

k

rt
  
k

 st
c

i

 yt
y

i

n

g

o

  

k

k

  

  

k

c

i

y

i

1

n

g

o

  

k

1

figure 1: a representation of the time-varying pitman-yor process mixture as a directed graphi-
cal model, representing conditional independencies between variables. all assignment
variables and observations at time t are denoted ct and zt, respectively.

3.3 properties of the models

15 / 19

under the uniform deletion model, the number at =pi mt

language representation / abstraction layer

i,t 1 of alive allocation variables at time

t can be written as

at =

xj,k

t 1xj=1

nxk=1

8

figure : from left to right: id114 for a    nite gaussian mixture model
(gmm), a bayesian gmm, and an in   nite gmm

ci|~        discrete(~   )
~yi|ci = k;         gaussian(  |   k).
   
k

~   |        dirichlet(  |
        g0

, . . . ,

   
k

)

wood (university of oxford)

unsupervised machine learning

january, 2014

id136 engines

new kinds of models

figure 1: graphical model for gaussian unknown mean model

y2

y1

p(x|y) =

p(y|x)p(x)

p(y)

x

y

x

figure 2: general graphical model

y

program source code

scene description
policy and world
cognitive process

simulation

program output

error if you attempt to de   ne a model with cycles) then you can compute the markov
blanket for each node and attempt to pattern match it to an    ef   cient    gibbs operator
for such a node. in this case we might identify the markov blanket of x as being all the
variables in the model and then, given the type of the variable (available, syntactically,
from the name of the of the random procedure, here dnorm).
if each random proce-
dure includes type information in the form of its domain, a function that evaluates the
density or distribution of it   s output given its arguments, and, perhaps, whether or not
it can form a conjugate relationship with any other distributions, then, pattern matching
on the graph can be used to select amongst a bank of univariate (or, rather, single
random variable     which might not be univariate) samplers that apply to that particular
pattern, and, in the case of gibbs kernels that require evaluating the id203 of the
variable at the node (like, for instance, an enumerative local kernel for a discrete node),
compute the id203 of a new value for the random variable at that node.

image
rewards
behavior
constraint

in this case p(x; a, b) is univariate normal so we know that x 2 r and, additionally,
if a and b are    xed and y1 and y2 are either normally distributed with mean x (as they
are in this example) or normally distributed with means given by af   ne functions of x
(which can be detected by a pattern like y[i] ~ dnorm(d*x+e,c) which again isn   t

11

history

long

pl

ai

ml

stats

2010

figaro
hansai

2000

ibal

1990

probabilistic-ml,haskell,scheme,   

probabilistic-c

webppl
venture anglican
church
factorie

infer.net

libbi

stan

jags

problog

blog

prism

kmp

winbugs

bugs

simula

prolog

   osuccess stories

id114

factor graphs

bugs

stan

factorie infer.net

have any deterministic variables, but, even in the general setting, these don   t cause trouble
in    guring out a way to interpret the program, just, potentially, how well the conditional
distribution denoted by the program can be characterized.

wood group

bugs 

algorithm 1 gaussian unknown mean model in bugs
model {

a b

x ~ dnorm(a, 1/b)
for (i in 1:n) {

y[i] ~ dnorm(x, 1/c)

}

}

c

x

y2

y1

    language restrictions 

algorithm 2 gaussian unknown mean query in anglican (eqv. to bugs model in alg. 1)
(defquery unknown-mean

figure 1: graphical model for gaussian unknown mean model

    bounded loops 
    no branching  
[ys a b c]
(let [x (sample (normal a (sqrt b)))

    model class 

    id136 - sampling 

now, given such a graphical structure, one can examine it and pattern match to, for
instance, per-vertex gibbs operators for use in a global id150 algorithm. as
likelihood (normal x (sqrt c))]
    finite id114 
this and programs allowed by the bugs modeling language, describe directed graphical
(map (fn [y] (observe likelihood y)) ys)
models (and, in the case of many bugs/jags packages will cause a compilation error
(predict :x x)))
if you attempt to de   ne a model with cycles) then you can compute the markov blanket
for each node and attempt to pattern match it to an    e cient    gibbs operator for such
a node. in this case we might identify the markov blanket of x as being all the variables
in the model and then, given the type of the variable (available, syntactically, from the

looks a lot like some kind of weird program. in fact, it is, particularly if you think about it

spiegelhalter et al. "bugs: bayesian id136 using id150, version 0.50." cambridge 1995.

    gibbs

15

stan : finite dimensional differentiable distributions 

real ys[t];
real a;
real q;

}
parameters {

real xs[t];

}
model {

xs[1] ~ normal(0.0, 1.0);
for (t in 2:t)

xs[t] ~ normal(a * xs[t - 1], q);

for (t in 1:t)

ys[t] ~ normal(xs[t], 1.0);

}

rx log p(x, y)

(hmc) is one such approach.
tent random variables x in the target density as a real-valued potential energy function
u(x), with

    language restrictions 

    bounded loops 
    no discrete random variables* 

in stan models are speci   ed using an imperative syntax that minimally contains
three required blocks: data, parameters, and model. figure 12 show these three
blocks for the 1-dimensional lds. the data block de   nes the type signature of all
known variables and constants, whose values must be supplied to the back end prior
to id136. the parameters block de   nes type signatures for all unknown variables,

    model class 

   0(x, p) =

hamiltonian monte carlo introduces auxiliary    momentum    variables p, with k(p) rep-
resenting the kinetic energy of the system. the momentum variables are typically
de   ned as from a zero-mean gaussian with covariance m, noting that the dimension
of p is the same as the dimension of x (i.e., if x 2 rd, then also p 2 rd). this yields
a joint target distribution    0(x, p) given by

   

    finite dimensional differentiable distributions 
id136 - sampling 
    hamiltonian monte carlo  

90

    reverse-mode automatic differentiation 

    black box variational id136, etc.

stan development team "stan: a c++ library for id203 and sampling." 2014.

the total energy of the system is de   ned by a function known as the hamiltonian,

by way of physical analogy, we can consider the energy    landscape    de   ned by u(x)
(with lower-energy states having higher id203), with the kinetic energy pushing our
sampler along this surface. if we consider this    movement    of the sampler over some
time    , the time evolution of the system is given by the differential equations

16

(observe (dirac (> (sample (normal alice-skill perf-noise))
(sample (normal bob-skill perf-noise))))

factorie and infer.net 

; rejection criterion: bob wins from cyd
(observe (dirac (> (sample (normal bob-skill perf-noise))

true)

(sample (normal cyd-skill perf-noise))))

    language restrictions 

true)

     finite compositions of factors 

; predict: does cyd beat alice?
(predict :cyd-wins

    model class 

    finite factor graphs  

    id136 - message passing, etc.

(> (sample (normal cyd-skill perf-noise))

(sample (normal alice-skill perf-noise))))

figure 5: anglican program for the trueskill example.

wood group

s)
n (sa;   s,  2

s)
n (sb;   s,  2

s)
n (sc;   s,  2

sa

sb

sc

p)
n (pa1;   p,  2
p)
n (pa3;   p,  2

pa1

p)
n (pb1;   p,  2
p)
n (pb2;   p,  2

pb1

p)
n (pc2;   p,  2
p)
n (pc3;   p,  2

pb2

pc2

pa3

i(w1 = pa1 > pb1))

w1

i(w2 = pb2 > pc2))

pc3

w2

i(w3 = pc3 > pa3))

w3

trueskill

figure 5: factor graph for the trueskill example.

x1

fx1,y1

fx1,x2

x2

fx2,y2

fx2,x3

x3

fx3,y3

y1

y2

y3

figure 6: factor graph for crf.

crf

each approximating factor   fm is chosen to be an exponential family distribution of the
form

 

. 

minka, winn, guiver, and knowles "infer .net 2.4, microsoft research cambridge." 2010. 

17
mccallum, schultz, and singh.    factorie probabilistic programming via imperatively de   ned factor graphs.    nips 2009    

hm(xm) exp(   m    um(x)),

  fm(x) =

zm(   m)

47

(55)

1

where    m is the vector of natural parameters, which will be learned, and u(x) is the
vector of suf   cient statistics. one of the properties of exponential family distributions is

modeling language desiderata

    unrestricted 

       open-universe    / in   nite dim. parameter spaces 

    mixed variable types 

    unfettered access to existing libraries 

    easily extensible 

    will come at a cost 

    id136 is going to be harder 
    more ways to shoot yourself in the foot

languages and systems

pl

ai

ml

stats

probabilistic-ml,haskell,scheme,   

probabilistic-c

webppl
venture anglican
church
factorie

infer.net

libbi

stan

problog

blog

2010

figaro
hansai

2000

ibal

1990

kmp

prism

discrete rv   s  

only

simula

prolog

jags

winbugs
bounded 
recursion

bugs

   owhat people are doing with these languages

x

y

program source code

program output

scene description
policy and world
cognitive process

simulation

image
rewards
behavior
constraint

perception / inverse graphics

captcha solving

x

y

y

observed

image

x

scene description

inferred

(reconstruction)

inferred model 
re-rendered with 
novel poses

inferred model 
re-rendered with 
novel lighting

figure 2: four input images from our captcha corpus, along with the    nal results and conver-
gence trajectory of typical id136 runs. the    rst row is a highly cluttered synthetic captcha
exhibiting extreme letter overlap. the second row is a captcha from turbotax, the third row
is a captcha from aol, and the fourth row shows an example where our system makes errors
on some runs. our probabilistic graphics program did not originally support rotation, which was
needed for the aol captchas; adding it required only 1 additional line of probabilistic code. see
the main text for quantitative details, and supplemental material for the full corpus.

x

scene description

3 generative probabilistic graphics in 2d for reading degraded text.
we developed a probabilistic graphics program for reading short snippets of degraded text consisting
of arbitrary digits and letters. see figure 2 for representative inputs and outputs. in this program,
the latent scene s = {si} contains a bank of variables for each glyph, including whether a potential
letter is present or absent from the scene, what its spatial coordinates and size are, what its identity
is, and how it is rotated:
i = y) =   1/h 0     x     h

generative probabilistic graphics programs." nips (2013).
i = 1) = 0.5 p (sx

mansinghka,, kulkarni, perov, and tenenbaum.  
"approximate bayesian image interpretation using 

i = x) =   1/w 0     x     w

otherwise

otherwise

p (spres

p (sy

0

0

figure 3: id136 on representative faces using picture: we
tested our approach on a held-out dataset of 2d image projections
of laser-scanned faces from [36]. our short probabilistic program
is applicable to non-frontal faces and provides reasonable parses as
illustrated above using only general-purpose id136 machinery.
for quantitative metrics, refer to section 4.1.

y

image

kulkarni, kohli, tenenbaum, mansinghka  

and informed samplers [19]. gpgp aimed to address the
main challenges of generative vision by representing visual
scenes as short probabilistic programs with random vari-
"picture: a probabilistic programming language for 
ables, and using a generic mcmc (single-site metropolis-
21
hastings) method for id136. however, due to modeling
limitations of earlier probabilistic programming languages,
and the inef   ciency of the metropolis-hastings sampler,

scene perception." cvpr (2015).

effects can be combined much more richly than is typical for
random variables in traditional statistical models.

consider running the program in figure 2 unconditionally
(without observed data): as different    i   s are encountered
(for e.g. coeff ), random values are sampled w.r.t their under-
lying id203 distribution and cached in the current state
of the id136 engine. program execution outputs an image
of a face with random shape, texture, camera and lighting
parameters. given image data id, id136 in picture pro-
grams amounts to iteratively sampling or evolving program
trace     to a high id203 state while respecting constraints
imposed by the data (figure 3). this constrained simulation
can be achieved by using the observe language construct
(see code in figure 2),    rst proposed in venture [32] and
also used in [35, 47].

2.1. architecture

in this section, we will explain the essential architectural
components highlighted in figure 1 (see figure 4 for a sum-
mary of notation used).
scene language: the scene language is used to describe
2d/3d visual scenes as probabilistic code. visual scenes
can be built out of several graphics primitives such as: de-
scription of 3d objects in the scene (e.g. mesh, z-map,
volumetric), one or more lights, textures, and the camera
information. it is important to note that scenes expressed

id23

 

50

100

policies evaluated x 50

figure 3: the snake robot (left), a learned policy for wiggling
forward (middle), and the maze (right).

options

figure 2: results on the memory maze. top left: with a shap-
ing reward throughout the entire maze, using options slightly
degrades performance. top right: when the shaping reward is
turned off halfway through the maze, using options improves
performance. the explanation is shown on the bottom row.
bottom left: path learned without using options (starting in
the lower-right corner; the goal is in the upper-left corner). it
consistently stops at the edge of the shaping reward without
   nding the goal. bottom-right: options learned in the    rst
half of the maze enable the agent to reliably    nd the goal.

in this domain, the agent has external, physical actions
(denoted by ae     ae) which move north, south, east and
west (here    ae    denotes    external action.   ). observations
are severely aliased, re   ecting only the presence or absence of
walls in the four cardinal directions (resulting in 16 possible
observations, denoted oe     oe, for    external observation   ).
to simultaneously capture state and a policy, we use a    nite
state controller (fsc). to allow for a potentially unbounded

x

lect an action ae(si, oe). we take this opportunity to encode
more prior knowledge into our policy search. because the
maze is largely open, it is likely that there are repeated se-
quences of external actions which could be useful   go north
four steps and west two steps, for example. we term these
motor primitives, which are a simpli   ed version of options
[precup et al., 1998]. however, we do not know how long the
motor primitives should be, or how many there are, or which
sequence of actions each should be composed of.
our distribution over motor primitives is given by the fol-
lowing generative process: to sample a motor primitive k, we
sample its length nk     poisson(  ), then sample nk external
actions from a compound dirichlet-multinomial.
given the size of the search space, for our    rst experiment,
we add a shaping reward which guides the algorithm from
lower-right to upper-left. figure 2 (upper left) compares the
results of using motor primitives vs. not using motor primi-
tives. the version with primitives does slightly worse.
"bayesian policy search with policy priors."  
the story changes signi   cantly if we turn off the shaping
reward halfway through the maze. the results are shown in
the upper-right pane, where the option-based policy reliably
achieves a higher return. the explanation is shown in the

policy and world

(ijcai), 2011.

wingate, goodman, roy, kaelbling, and tenenbaum.  

y

reward

van de meent, tolpin, paige, and wood.  

"black-box policy search with probabilistic programs."  
22

arxiv:1507.04635 (2015).

reasoning about reasoning

want to meet up but phones are dead   

i prefer the pub. 

where will noah go? 

simulate noah: 
noah prefers pub 

but will go wherever andreas is 

simulate noah simulating andreas: 

    

-> both go to pub 

x

cognitive process

y

behavior

"reasoning about reasoning by nested conditioning: modeling theory of mind with probabilistic programs."  
23

cognitive systems research 28 (2014): 80-99.

stuhlm  ller, and goodman.  

(declare noah andreas)

(with-primitive-procedures [pub-or-starbucks?]

(defm noah [depth]

(defm andreas [depth]

9. simulation based modeling

an alternative characterization of a probabilistic program can be considered, which focuses
purely on the generative simulation process. a deterministic (or    traditional   ) program
performs some computation and then returns an output. a probabilistic programming
language augments the deterministic programming language with two constructs:

    sampling a random value according to some distribution; and
    conditioning on the value of an observed random variable.

the probabilistic program then de   nes a distribution over outputs, and returns some rep-
resentation of this distribution.

informally, one can imagine    running    a probabilistic program as an operation similar
to running a deterministic program. suppose we have some set of random primitives    
distributions such as the gaussian, uniform, binomial, etc.     from which we can sample
new random values, or condition on observed values. in anglican, we could draw a value

program induction

  y     p(  |x)

  y     p(  |x)

y

x     p(x|y)

y

x     p(x)

x

program source code

program output

perov and wood.  

"learning probabilistic programs."  

arxiv:1407.2646 (2014).

24

eurographics 2015 / o. sorkine-hornung and m. wimmer
(guest editors)

constrained stochastic simulation

gradient-based probabilistic programming

generating design suggestions under tight constraints with

volume 34 (2015), number 2

daniel ritchie sharon lin noah d. goodman pat hanrahan

stable static structures

stanford university

figure 1: physical realizations of stable structures generated by our system. to create these structures, we write programs that
generate random structures (e.g. a random tower or a randomly-perturbed arch), constrain the output of the program to be near
static equilibrium, and then sample from the constrained output space using hamiltonian monte carlo.

abstract

we present a system for generating suggestions from highly-constrained, continuous design spaces. we formulate
suggestion as sampling from a id203 distribution; constraints are represented as factors that concentrate
id203 mass around sub-manifolds of the design space. these sampling problems are intractable using typical
random walk mcmc techniques, so we adopt hamiltonian monte carlo (hmc), a gradient-based mcmc method.
we implement hmc in a high-performance probabilistic programming language, and we evaluate its ability to
ef   ciently generate suggestions for two different, highly-constrained example applications: vector art coloring
and designing stable stacking structures.

1. introduction

considering multiple possibilities is critical in design. ex-
posure to different examples facilitates creativity   for in-
stance, prototyping multiple alternatives can lead to better-
quality    nal designs [kdk14, dgk   10]. exploring the
whole space of creative options seems to help people avoid
   xation and overcome their unconscious biases [js91].
computation can assist with this exploration by generating

   2015 the author(s)
computer graphics forum    2015 the eurographics association and john
wiley & sons ltd. published by john wiley & sons ltd.

suggestions: given a model of the design space, computers
can synthesize examples that their users might never have
thought of independently.

x

in computer graphics, probabilistic id136 has become
popular for computer-aided suggestion in domains as diverse
as color selection and furniture layout [lrfh13,yyw   12].
in this framework, the user provides a model of the de-
sign space by expressing her preferences as soft constraints,

simulation

ritchie, lin, goodman, & hanrahan. 

generating design suggestions under tight constraints 

with gradient   based probabilistic programming.  

in computer graphics forum, (2015)

forward sampling

procedural graphics

figure 3: sosmc sampling from a random building complex
model with volume matching applied.

sosmc-controlled sampling

figure 4: using the object avoidance scoring function to make
gnarly trees grow around obstacles.

figure 1 shows some examples of spaceships and trees sampled
according to this score function using sosmc. figure 3 applies
the same score function to encourage a building complex to take on
a crescent-like shape.

6.2 object avoidance

y

volume matching allows an artist to specify what regions of space
a model should occupy; it can also be valuable to specify the space
a model should not occupy. for this control, the user provides a set
of objects with which the model should avoid contact. we rasterize
these objects onto a binary voxel grid vavoid. the object avoidance
score function savoid is then
ritchie, mildenhall, goodman, & hanrahan.   
   controlling procedural modeling programs with 
stochastically-ordered sequential monte carlo.    
where " is logical nand. this function imposes a hard constraint:
25
it returns 0 if vr and vavoid have any mutually    lled cells and 1
otherwise.
figure 4 shows two examples of using object avoidance to generate

constraint
savoid(r) = yx2d
 siggraph (2015) 

1{vr(x) " vavoid(x)}

front view

figure 5: the image matching scoring function is used to control
the appearance of a building complex from a particular viewpoint.
(left): the model as viewed from the target viewpoint. (right): the
model viewed from above.

target

front view

top view

figure 6: using image matching to control the appearance of
a spaceship   s front pro   le. the sosmc-sampled results closely
match the target when viewed head on but exhibit a variety of struc-
tures when viewed from other angles.

lar angle. we implement this type of control through image-based
comparisons. if itarget is a target binary image de   ned over domain
d, and ir is a rendering of the model described by trace r onto d,
then the image matching score function simatch is
simatch(r) = n (sim(ir, itarget), 1,  )
sim(i1, i2) = px2d

where w is a    weight image    de   ned over d. the weight image
allows users to draw strokes over parts of the image domain where
strict matching is more or less important. for the results shown in
this paper, w is uniform unless explicitly shown. as with volume
matching,   is 0.02 unless otherwise speci   ed.
figure 5 shows a use of the image matching scoring function to en-
force a target silhouette for a building complex when viewed from

universal  

probabilistic programming  

modeling language 

introduction to  

anglican/church/venture/webppl    

interpreted

a language family tree

church

webchurch (bher)

interpreted anglican

venturescript

probabilistic-c

webppl

anglican

lisp javascript

clojure

c

compiled

inspiration
modeling language

28

syntax : anglican     clojure     church     lisp
   notation : prefix vs. infix 

clojure is a kind of like lisp. this means that parenthesis are used for function application:
the    rst element in a parenthesized sequence is a function, and the following elements are
its arguments.
it can take a few minutes to become accustomed to this sort of pre   x
notation. the following code demonstrates a series of standard arithmetic and mathematical
expressions.

;; add two numbers
(+ 1 1)

a tutorial on probabilistic programming

;; subtract: "10 - 3"
(- 10 3)
;; complex arithmetic expressions are built up like so:
;; (10 * (2.1 + 4.3) / 2)
;; multiply, divide
(/ (* 10 (+ 2.1 4.3)) 2)
(* 2 5)
(/ 10.0 3.3)
;;
(exp -2)
(log (+ 1 1))
(sqrt 5)

8

functions like "log", "exp", and more exist as you would expect:

clojure is typed and performs type conversion behind the scenes, almost always nicely.
it has types for    oating-point numbers, integers, fractions, and booleans. clojure also has
matrix types, but we don   t show them here, though anglican supports them.

29

comparison operators <, >, =, <=, >= behave as one would expect, and can be used

   notation : prefix vs. infix 

   branching 

a tutorial on probabilistic programming

syntax 

within an if statement. the if statement takes the form
clojure is a kind of like lisp. this means that parenthesis are used for function application:
the    rst element in a parenthesized sequence is a function, and the following elements are
(if bool? expr-if-true expr-if-false)
its arguments.
it can take a few minutes to become accustomed to this sort of pre   x
notation. the following code demonstrates a series of standard arithmetic and mathematical
that is, an if expression will itself be a list with four elements: the    rst is if, the
expressions.
second evaluates to a boolean, and the last two are any arbitrary expressions. here are a
few examples.
;; add two numbers
(+ 1 1)
;; outputs true
(< 4 10)
;; subtract: "10 - 3"
(- 10 3)
;; outputs 1
;; complex arithmetic expressions are built up like so:
(if (> 3 2) 1 -1)
;; (10 * (2.1 + 4.3) / 2)
;; multiply, divide
(/ (* 10 (+ 2.1 4.3)) 2)
(* 2 5)
;; outputs 20
(/ 10.0 3.3)
(if (<= 3 3) (+ 10 10) 0)
;;
(exp -2)
;; outputs 4
(log (+ 1 1))
(+ (if (< 4 5) 1 2) 3)
(sqrt 5)

functions like "log", "exp", and more exist as you would expect:

8

a let block is a bit of clojure which can be used to de   ne variables within a local
clojure is typed and performs type conversion behind the scenes, almost always nicely.
scope. a let block takes an initial argument which de   nes a sequence of bindings, followed
it has types for    oating-point numbers, integers, fractions, and booleans. clojure also has
by a sequence of statements.
matrix types, but we don   t show them here, though anglican supports them.
the expr is evaluated with x set equal to 1, and y equal to 2.

bindings are a list in square-brackets [] of name-value pairs. in (let [x 1 y 2] expr),
comparison operators <, >, =, <=, >= behave as one would expect, and can be used

30

y 2]

functions

(* x 3)
(+ x y))

   functions are first class 

;; evaluates to 32
((fn [x y] (+ (* x 3) y))

10
2)

;; let is syntactic "sugar" for the same
(let [x 10
y 2]

(+ (* x 3) y))

;; ... and so does this
(let [x 10

y 2
x (* x 3)]

(+ x y))

;; this has a side-effect, printing to the console,
;; which is carried out within the let block
(let [x 10

31

functions

y 2]
;; also prints 12!
(* x 3)
(let [x 10
(+ x y))
y 2]
(* x 3)
(+ x y))

   functions are first class  

   local bindings 

;; evaluates to 32
((fn [x y] (+ (* x 3) y))
;; evaluates to 32
((fn [x y] (+ (* x 3) y))

10
2)
10
2)

;; let is syntactic "sugar" for the same
(let [x 10
y 2]
;; let is syntactic "sugar" for the same
(let [x 10
y 2]

(+ (* x 3) y))

(+ (* x 3) y))

;; ... and so does this
(let [x 10
y 2
;; ... and so does this
x (* x 3)]
(let [x 10
(+ x y))
y 2
x (* x 3)]

(+ x y))

;; this has a side-effect, printing to the console,
;; which is carried out within the let block
(let [x 10
;; this has a side-effect, printing to the console,

32

   map 

   reduce 

(map (fn [x] (* x x))

(list 1 2 3 4))

higher-order

;; here   s a different way of writing the above:
(map (fn [x] (pow x 2)) (range 1 5))

wood group

the    nal essential clojure construct we will want for the exercises is loop ... recur.

; these are values x1, x2, x3
[1 2 3]
[10 9 8]) ; these are values y1, y2, y3

;; apply the function f(x,y) = x + 2y to the
[10 9 8]) ; these are values y1, y2, y3
;; x values [1 2 3] and the y values [10 9 8]
;; produces [21 20 19]
;; reduce recursively applies function,
(map (fn [x y] (+ x (* 2 y)))
;; to current result and next list element, e.g.
(reduce + [1 2 3 4])
;; does (+ (+ (+ 0 1) 2) ...
;; and evaluates to 10
this allows us to easily write looping code.
;; reduce recursively applies function,
loop speci   es initial values for a set of names (similar to a let-block) and then recur
;; to result and next element, i.e.
passes new values in when running the next loop iteration. this is best demonstrated by
(reduce + 0 [1 2 3 4])
example.
;; does (+ (+ (+ 0 1) 2) ...
;; and evaluates to 10
;; loop from x=1 until x=10, printing each x
(loop [x 1]
this allows us to easily write looping code.

the    nal essential clojure construct we will want for the exercises is loop ... recur.
(if (<= x 10)
(let [next-x (+ x 1)]
loop speci   es initial values for a set of names (similar to a let-block) and then

33

anglican by example : graphical model

(defquery gaussian-model [data]
  (let [x (sample (normal 1 (sqrt 5)))
        sigma (sqrt 2)]
    (map (fn [y] (observe (normal x sigma) y)) data)
    (predict :x x)))

x     normal(1,p5)
yi|x     normal(x,p2)

(def dataset [9 8])
(def posterior 
  ((conditional gaussian-model 
                :pgibbs 
                :number-of-particles 1000) dataset))

y1 = 9, y2 = 8

x|y     normal(7.25, 0.91)

(def posterior-samples 
  (repeatedly 20000 #(sample posterior)))

34

https://www.java.com/graphical model

(defquery gaussian-model [data]
  (let [x (sample (normal 1 (sqrt 5)))
        sigma (sqrt 2)]
    (map (fn [y] (observe (normal x sigma) y)) data)
    (predict :x x)))

x     normal(1,p5)
yi|x     normal(x,p2)

(def dataset [9 8])
(def posterior 
  ((conditional gaussian-model 
                :pgibbs 
                :number-of-particles 1000) dataset))

y1 = 9, y2 = 8

x|y     normal(7.25, 0.91)

(def posterior-samples 
  (repeatedly 20000 #(sample posterior)))

35

https://www.java.com/graphical model

(defquery gaussian-model [data]
  (let [x (sample (normal 1 (sqrt 5)))
        sigma (sqrt 2)]
    (map (fn [y] (observe (normal x sigma) y)) data)
    (predict :x x)))

x     normal(1,p5)
yi|x     normal(x,p2)

(def dataset [9 8])
(def posterior 
  ((conditional gaussian-model 
                :pgibbs 
                :number-of-particles 1000) dataset))

y1 = 9, y2 = 8

x|y     normal(7.25, 0.91)

(def posterior-samples 
  (repeatedly 20000 #(sample posterior)))

36

https://www.java.com/graphical model

(defquery gaussian-model [data]
  (let [x (sample (normal 1 (sqrt 5)))
        sigma (sqrt 2)]
    (map (fn [y] (observe (normal x sigma) y)) data)
    (predict :x x)))

x     normal(1,p5)
yi|x     normal(x,p2)

(def dataset [9 8])
(def posterior 
  ((conditional gaussian-model 
                :pgibbs 
                :number-of-particles 1000) dataset))

y1 = 9, y2 = 8

x|y     normal(7.25, 0.91)

(def posterior-samples 
  (repeatedly 20000 #(sample posterior)))

37

anglican : syntax     clojure, semantics     clojure

(defquery gaussian-model [data]
  (let [x (sample (normal 1 (sqrt 5)))
        sigma (sqrt 2)]
    (map (fn [y] (observe (normal x sigma) y)) data)
    (predict :x x)))

x     normal(1,p5)
yi|x     normal(x,p2)

(def dataset [9 8])
(def posterior 
  ((conditional gaussian-model 
                :pgibbs 
                :number-of-particles 1000) dataset))

y1 = 9, y2 = 8

x|y     normal(7.25, 0.91)

(def posterior-samples 
  (repeatedly 20000 #(sample posterior)))

38

https://www.java.com/bayes net

(defquery sprinkler-bayes-net

(let [cloudy (sample (flip 0.5))

raining (sample (if cloudy

(flip 0.8)
(flip 0.2)))

sprinkler-dist (if cloudy

(flip 0.1)
(flip 0.5))

sprinkler true
_ (observe sprinkler-dist sprinkler)

wetgrass-dist

(cond (and (= sprinkler true)

(= raining

true))

(flip 0.99)
(and (= sprinkler false)

(= raining

false))

(flip 0.00)
(or (= sprinkler true)

(= raining

true))

(flip 0.90))

wetgrass true
_ (observe wetgrass-dist wetgrass)]

(predict :cloudy cloudy)
(predict :raining raining)
(predict :wetgrass wetgrass)))

39

(conj states state)))

[(sample init-dist)]
observations)))

one hidden markov model

[(sample init-dist)]
ys)))

(conj xs x)))

(defquery id48

(let [init-dist (discrete [1 1 1])

trans-dist (fn [s]
(cond

x0

x1

y1

x2

y2

x3

y3

      

figure 11: square lattice ising model

(= s 0) (discrete [0 1 1])
(= s 1) (discrete [0 0 1])
(= s 2) (dirac 2)))

(declare noah andreas)

obs-dist (fn [s] (normal s 1))
y-1 1
y-2 1
x-0 (sample init-dist)
x-1 (sample (trans-dist x-0))
x-2 (sample (trans-dist x-1))]

(with-primitive-procedures [pub-or-starbucks?]

(defm noah [depth]

(let [noah-location (pub-or-starbucks? 0.6)

andreas-location (andreas (dec depth))]

(observe noah-location andreas-location)
andreas-location))

(observe (obs-dist x-1) y-1)
(observe (obs-dist x-2) y-2)
(predict :x-0 x-0)
(predict :x-1 x-1)
(predict :x-2 x-2)))

57

(defquery id48

(conj states state)))

[(sample init-dist)]
observations)))

all id48

[(sample init-dist)]
observations)))

(defquery id48

[ys init-dist trans-dists obs-dists]
(predict

(defquery id48

[ys init-dist trans-dists obs-dists]
(predict

:x
(reduce

(fn [xs y]

:x
(reduce

(let [x (sample (get trans-dists

(fn [xs y]

(let [x (sample (get trans-dists (peek xs)))]

(peek xs)))]

(observe (get obs-dists state) y)
(conj xs x)))

(observe (get obs-dists x) y)
(conj xs x)))

[(sample init-dist)]
ys)))

[(sample init-dist)]
ys)))

x0

x1

x0

y1

x2

x1

y2

y1

x3

x2

      

x3

      

y3

y2

y3

an unbounded recursion

algorithm 8 anglican query that generates geometrically distributed random variables
(defquery geometric [p]

"geometric distribution"
(let [dist (flip p)

samp (loop [n 0]

(if (sample dist)

n
(recur (+ n 1))))]

(predict :x samp)))

p
0

1-p

1-p
ok, where have we arrived? if you have a language like bugs that restricts you
p
to    nite-id114 (technically part of the de   nition as far as i know ?) and the
1
language contains a mix of discrete and continuous variables then a probabilistic pro-
gramming execution strategy for such a program/model is    running    the program like
illustrated in fig. 6. the output of the program will then be a sample-based characteri-
zation of the conditional distribution of the latents given the observes and integrals can
be computed against these samples to answer questions.

p
2

1-p

deterministic simulation

(defquery arrange-bumpers []
    (let [bumper-positions []

          ;; code to simulate the world
          world (create-world bumper-positions)
          end-world (simulate-world world)
          balls (:balls end-world)

          ;; how many balls entered the box?
          num-balls-in-box (balls-in-box end-world)]

      (predict :balls balls)
      (predict :num-balls-in-box num-balls-in-box)
      (predict :bumper-positions bumper-positions)))

goal:    world    that puts ~20% of balls in box    

stochastic simulation

(defquery arrange-bumpers []
    (let [number-of-bumpers (sample (poisson 20))
          bumpydist (uniform-continuous 0 10)
          bumpxdist (uniform-continuous -5 14)
          bumper-positions (repeatedly
                            number-of-bumpers
                            #(vector (sample bumpxdist) 
                                     (sample bumpydist)))

          ;; code to simulate the world
          world (create-world bumper-positions)
          end-world (simulate-world world)
          balls (:balls end-world)

          ;; how many balls entered the box?
          num-balls-in-box (balls-in-box end-world)]

      (predict :balls balls)
      (predict :num-balls-in-box num-balls-in-box)
      (predict :bumper-positions bumper-positions)))

constrained stochastic simulation

(defquery arrange-bumpers []
    (let [number-of-bumpers (sample (poisson 20))
          bumpydist (uniform-continuous 0 10)
          bumpxdist (uniform-continuous -5 14)
          bumper-positions (repeatedly
                            number-of-bumpers
                            #(vector (sample bumpxdist) 
                                     (sample bumpydist)))

          ;; code to simulate the world
          world (create-world bumper-positions)
          end-world (simulate-world world)
          balls (:balls end-world)

          ;; how many balls entered the box?
          num-balls-in-box (balls-in-box end-world)
          
          obs-dist (normal 4 0.1)]

      (observe obs-dist num-balls-in-box)
      
      (predict :balls balls)
      (predict :num-balls-in-box num-balls-in-box)
      (predict :bumper-positions bumper-positions)))

a hard id136 problem

(defquery md5-inverse [l md5str] 
    "conditional distribution of strings
     that map to the same md5 hashed string"
    (let [mesg (sample (string-generative-model l))]
      (observe (dirac md5str) (md5 mesg))
      (predict :message mesg))))

an id136 framework 
for universal probabilistic 
programming languages

the gist

    explore as many    traces    as possible, intelligently 
    each trace contains all random choices made 

during the execution of a generative model 

    compute trace    goodness    (id203) as side-effect 
    combine weighted traces probabilistically coherently 
    report projection of posterior over traces 

    if it   s going to be    hard,    let   s at least make it fast 

    first generation - interpreted 
    second generation - compiled

48

traces

(poisson 7)

(poisson 9)

x2 = 0

x2 = 1

x2 = 2

...

x2 = 2

x2 = 1

x2 = 0

(discrete `(1 1 1))

x1 = 0

x1 = 1

x1 = 2

(let [t-1 3
      x-1 (sample (discrete (repeat t-1 1)))] 
  (if (not= x-1 1) 
    (let [t-2 (+ x-1 7)
          x-2 (sample (poisson t-2))])))

...

goodness of trace

 (normpdf 0 1 0.0001)

(poisson 7)

x2 = 0

 (normpdf 1 1 0.0001)

(discrete `(1 1 1))

x1 = 0

x1 = 1

x1 = 2

(poisson 9)

x2 = 1

x2 = 2

...

x2 = 2

x2 = 1

x2 = 0

 (normpdf 2 1 0.0001)

 (normpdf 2 1 0.0001)

 (normpdf 1 1 0.0001)

 (normpdf 0 1 0.0001)

(let [t-1 3
      x-1 (sample (discrete (repeat t-1 1)))] 
  (if (not= x-1 1) 
    (let [t-2 (+ x-1 7)
          x-2 (sample (poisson t-2))]
      (observe (gaussian x-2 0.0001) 1))))

...

vector  , and a observed value y. control is then returned to p, which continues
trace
    sample: p passes to b a tuple (f,    ) consisting of a distribution f and a parameter
    if p has terminated, it returns a value z, which can be any arbitrary (determin-
vector    . the backend samples a value x     f (  |   ); it then returns control to p
which continues execution, providing this value as the output of sample.

vector    . the backend samples a value x     f (  |   ); it then returns control to p
which continues execution, providing this value as the output of sample.

    observe: p passes to b a tuple (g,  , y) consisting of a distribution g, a parameter
vector  , and a observed value y. control is then returned to p, which continues
execution.

    sequence of n observe   s 

of the program, it yields control to the backend.

istic) function of the program trace.

istic) function of the program trace.

    sequence of m sample   s 

    if p has terminated, it returns a value z, which can be any arbitrary (determin-

    observe: p passes to b a tuple (g,  , y) consisting of a distribution g, a parameter
vector  , and a observed value y. control is then returned to p, which continues
execution.

suppose after a single execution of a probabilistic program in this manner, we encounter n
observe statements and m sample statements. this yields sequences of tuples {(gi,  i, yi)}n
corresponding to the observe statements, and {(fj,    j)}m
j=1 corresponding to the sample
statements, with the associated sequence of sampled values (i.e. the program execution
suppose after a single execution of a probabilistic program in this manner, we encounter n
j=1. the id203 of this program execution trace can be de   ned, up to an
observe statements and m sample statements. this yields sequences of tuples {(gi,  i, yi)}n
istic) function of the program trace.
unknown normalizing constant, as a product of all random choices x and all observed values
corresponding to the observe statements, and {(fj,    j)}m
j=1 corresponding to the sample
suppose after a single execution of a probabilistic program in this manner, we encounter n
statements, with the associated sequence of sampled values (i.e. the program execution
observe statements and m sample statements. this yields sequences of tuples {(gi,  i, yi)}n
    sequence of m sampled values 
trace) {xj}m
j=1. the id203 of this program execution trace can be de   ned, up to an
nyi=1
corresponding to the observe statements, and {(fj,    j)}m
unknown normalizing constant, as a product of all random choices x and all observed values
(72)
statements, with the associated sequence of sampled values (i.e. the program execution
trace) {xj}m
j=1. the id203 of this program execution trace can be de   ned, up to an
unknown normalizing constant, as a product of all random choices x and all observed values
note that this ordering, as well as the cardinalities m and n , are not necessarily identical
gi(yi| i)
y, with

    if p has terminated, it returns a value z, which can be any arbitrary (determin-

    conditioned on these sampled values the entire computation 
(72)

 (x) , p(x, y) =

fj(xj|   j).

fj(xj|   j).

gi(yi| i)

myj=1

i=1

i=1

is deterministic

nyi=1

myj=1

obscured by the notation above is the dependency structure induced by the probabilistic
program p. each parameter vector  i and    j are themselves deterministic functions of
(potentially) every previous random choice in the program. so too are gi and fj. let ni
denote the total number of random values sampled prior to the ith observe statement and

note that this ordering, as well as the cardinalities m and n , are not necessarily identical
across di   erent runs of the program.

 (x) , p(x, y) =

nyi=1

gi(yi| i)

corresponding to the observe statements, and {(fj,    j)}m
trace id203
statements, with the associated sequence of sampled values (i.e. the program execution
trace) {xj}m
j=1. the id203 of this program execution trace can be de   ned, up to an
unknown normalizing constant, as a product of all random choices x and all observed values
y, with

    de   ned as (up to a id172 constant) 

wood group

nyi=1

fj(xj|   j).

nyi=1
myj=1
  fj(xj 1)   xj    
  gi(xni)   yi    
   i(xni)    myj=1

x6

 (x) , p(x, y) =

gi(yi| i)
    hides true dependency structure

(72)
consisting of the    rst j sampled values (with x0     ;). we can then rewrite equation 72 in
a form which explicitly represents the dependency structure, as
note that this ordering, as well as the cardinalities m and n , are not necessarily identical
across di   erent runs of the program.

a tutorial on probabilistic programming

 (x) = p(x, y) =

{

obscured by the notation above is the dependency structure induced by the probabilistic
obscured by the notation above is the dependency structure induced by the prob-
program p. each parameter vector  i and    j are themselves deterministic functions of
abilistic program p. each parameter vector  i and    j are themselves deterministic
(potentially) every previous random choice in the program. so too are gi and fj. let ni
functions of (potentially) every previous random choice in the program. so too are
denote the total number of random values sampled prior to the ith observe statement and
gi and fj. let ni denote the total number of random values sampled prior to the ith
here, each    i and      j are deterministic procedures which take partial program traces xni, xj
observe statement and the bold, subscripted value xj = x1                xj denote a partial
the bold, subscripted value xj = x1                xj denote a partial program execution trace
and return parameter vectors  i and    j; similarly   gi and   fj are deterministic functions which
program execution trace consisting of the    rst j sampled values (with x0     ;). we
can then rewrite equation 105 in a form which explicitly represents the dependency
return density functions gi and fj. these procedures correspond exactly to the incremental
structure, as
executions of p above. note that the functional forms of the distributions gi and fj are all
those of random primitives, and so by construction we can sample from any fj(  |   j) and
evaluate any gi(yi| i)     once the parameters are known.
the normalized posterior id203 distribution over program traces can be de   ned as

here, each    i and      j are deterministic procedures which take partial program traces
xni, xj and return parameter vectors  i and    j; similarly   gi and   fj are deterministic
functions which return density functions gi and fj. these procedures correspond ex-

  gi(xni)   yi    

{

 (x) = p(x, y) =
y1

     j(xj 1)    .

nyi=1

x4
53

(106)

etc

x6

x1

x5

x4

x3

x2

y2

     j(xj 1)    .

   i(xni)    myj=1

  fj(xj 1)   xj    
z = p(y) =z  (x)dx

z = p(y) =z  (x)dx

   (x) , p(x|y) =

,

z

z

 (x)
,

id136 goal

the normalizing constant z is found by integrating over all possible program execution
traces.

functions which return density functions gi and fj. these procedures correspond ex-
functions which return density functions gi and fj. these procedures correspond ex-
actly to the incremental executions of p above. note that the functional forms of the
actly to the incremental executions of p above. note that the functional forms of the
the normalizing constant z is found by integrating over all possible program execution
distributions gi and fj are all those of random primitives, and so by construction we can
distributions gi and fj are all those of random primitives, and so by construction we can
traces.
sample from any fj(  |   j) and evaluate any gi(yi| i)     once the parameters are known.
sample from any fj(  |   j) and evaluate any gi(yi| i)     once the parameters are known.
    posterior over traces 
the program output z is de   ned as a deterministic function of the trace; that is,
the normalized posterior id203 distribution over program traces can be de   ned
the normalized posterior id203 distribution over program traces can be de   ned
given a program execution trace x, we de   ne z = q(x). this allows us, in theory, to
as
use the posterior distribution over traces    (x) to characterize the distribution over z
given the observations y; for example, the posterior mean can be found by
(107)

the normalizing constant z is found by integrating over all possible program execution
(108)
traces.
    output 
the program output z is de   ned as a deterministic function of the trace; that is,
the program output z is de   ned as a deterministic function of the trace; that is,
given a program execution trace x, we de   ne z = q(x). this allows us, in theory, to
given a program execution trace x, we de   ne z = q(x). this allows us, in theory, to
use the posterior distribution over traces    (x) to characterize the distribution over z
use the posterior distribution over traces    (x) to characterize the distribution over z
(109)
given the observations y; for example, the posterior mean can be found by
given the observations y; for example, the posterior mean can be found by

z = p(y) =z  (x)dx
z = p(y) =z  (x)dx
 (x)
   (x) , p(x|y) =
   (x) , p(x|y) =
z
e[z] = e[q(x)] =z q(x)p(x|y)dx =z q(x)   (x)dx.
e[z] = e[q(x)] =z q(x)   (x)dx =
e[z] = e[q(x)] =z q(x)p(x|y)dx =z q(x)   (x)dx.

it should be clear that this characterization of a probabilistic program allows us to
(108)
de   ne models literally as simulations, with the random elements controlled by sample
it should be clear that this characterization of a probabilistic program allows us to
and observe statements. the generative procedure uses sample to create random
it should be clear that this characterization of a probabilistic program allows us to
de   ne models literally as simulations, with the random elements controlled by sample
de   ne models literally as simulations, with the random elements controlled by sample
variables; synthetic data sets could be created simply by replacing any observe state-
and observe statements. the generative procedure uses sample to create random
and observe statements. the generative procedure uses sample to create random
ment with sample, without changing the unnormalized distribution p(x, y).
variables; synthetic data sets could be created simply by replacing any observe state-
variables; synthetic data sets could be created simply by replacing any observe state-

e[z] = e[q(x)] =z q(x)p(x|y)dx =z q(x)   (x)dx.

zz q(x)

 (x)
q(x)

q(x)dx

(108)

(107)

1

three base algorithms

    likelihood weighting 

    sequential monte carlo 

    metropolis hastings

kxk=1

likelihood weighting

a very simple way of generating trace samples xk is to run k independent copies of
the program p, yielding k traces, each sampled according to some sequence of m k
a very simple way of generating trace samples xk is to run k independent copies of
j}m k
different densities {f k
j=1. to be clear what this means is running each copy of
j ,    k
the program p, yielding k traces, each sampled according to some sequence of m k
the program entirely independently with the backend sampling proposing values of xk
    run k independent copies of program simulating from 
j}m k
j=1. to be clear what this means is running each copy of
different densities {f k
j ,    k
j
directly via the prior.
the program entirely independently with the backend sampling proposing values of xk
the prior 
j
directly via the prior.

q(xk) =

q(xk) =

wood group
fj(xk
j|   k
j )
j|   k
j )

fj(xk

m kyj=1
m kyj=1

. for each of these k traces xk, we can compute an associated unnormalized weight
    accumulate unnormalized weights (likelihoods) 
w(xk) as
. for each of these k traces xk, we can compute an associated unnormalized weight
w(xk) as

this estimator can be compactly represented using normalized weights,

=

w(xk) =

w(xk) =

 (xk)
q(xk)

wood group

 (xk)
q(xk)
=

w(xk)
w k =
`=1 w(x`)
i (yk
gk
i | k
i )
i | k
i (yk
gk
i )
this estimator can be compactly represented using normalized weights,

w kq(xk)
    use in approximate (monte carlo) integration
where n k denotes the number of observe statements yielding tuples {(gk
for each of the k traces. it follows that
where n k denotes the number of observe statements yielding tuples {(gk
i ,  k
w kq(xk)
for each of the k traces. it follows that
pk
w(xk)q(xk)# =
e" 1
kxk=1
w(xk)q(xk)# =
e" 1
kxk=1
kxk=1
bqk =

pk
n kyi=1
n kyi=1
kxk=1
bqk =
kxk=1
be   [q(x)] =
kxk=1z q(xk)24
n kyi=1
m kyj=1
kxk=1z q(xk)24
m kyj=1
n kyi=1
kxk=1z q(xk) (xk)dxk

w(xk)
`=1 w(x`)

w k =

(120)

1
k

k

k

(110)

(110)
i )}n k
i , yk
i )}n k

i=1

i=1

i ,  k
i , yk

j )35 dx1 . . . xm k
j )35 dx1 . . . xm k

(111)

gk
i (yk
i | k
i )
note that this estimator is biased for any    nite k, but the bias drops of as order o(1/k)
1
w kq(xk)
i | k
i (yk
gk
i )
?. also, since each xk is simulated independently, we have from the strong law of large
k
blog default id136 engine: 
numbers that ?
http://bayesianlogic.github.io/pages/users-manual.html

j|   k
f k
j (xk
(121)
j|   k
j (xk
f k

(111)

likelihood weighting schematic

...

z1, w1

z2, w2

...

zk, wk

between executions.

sequential monte carlo

particular re-execution of the program on the same dataset will have n observe state-
particular re-execution of the program on the same dataset will have n observe state-
ments; the number m of latent variables xj in each trace may still vary dramatically
ments; the number m of latent variables xj in each trace may still vary dramatically
between executions.
between executions.
    notation 

a sequential monte carlo algorithm for id136 in probabilistic programs is based
on the ability to decompose the full program trace x into a product over incremental
expansions of the program trace. we de   ne   xi as the subspace of x which is sampled
in between observe statements i   1 and i, that is, with   x1:n =   x1                  xn such that
  x1:n denotes the full program trace, and with each   xi disjoint. while there are always n
such   xi, each may be of varying dimensionality on each execution, and there may also
be some   xi = ; if no new randomness is sampled between two subsequent observe
statements. we can thus de   ne a sequence of incremental program execution traces

a sequential monte carlo algorithm for id136 in probabilistic programs is based
a sequential monte carlo algorithm for id136 in probabilistic programs is based
on the ability to decompose the full program trace x into a product over incremental
on the ability to decompose the full program trace x into a product over incremental
expansions of the program trace. we de   ne   xi as the subspace of x which is sampled
expansions of the program trace. we de   ne   xi as the subspace of x which is sampled
in between observe statements i   1 and i, that is, with x1:n =   x1                  xn such that
in between observe statements i   1 and i, that is, with x1:n =   x1                  xn such that
  x1:n denotes the full program trace, and with each   xi disjoint. while there are always n
  x1:n denotes the full program trace, and with each   xi disjoint. while there are always n
such   xi, each may be of varying dimensionality on each execution, and there may also
such   xi, each may be of varying dimensionality on each execution, and there may also
be some   xi = ; if no new randomness is sampled between two subsequent observe
be some   xi = ; if no new randomness is sampled between two subsequent observe
statements. we can thus de   ne a sequence of incremental program execution traces
statements. we can thus de   ne a sequence of incremental program execution traces
 1, . . . ,  n with
 1, . . . ,  n with

x3
g(yn|  x1:n)p(  xn|  x1:n 1),

with associated normalized incremental targets

{{etc

    incrementalized joint 

nyn=1

 n(  x1:n) =

(126)

x4

x5

x6

x1

  x1

  x2

x2

y2

y1

1
zn

   n(  x1:n) =

 n(  x1:n)
 n(  x1:n) =
 n(  x1:n) =
     incrementalized target

nyn=1
nyn=1

where each zn is an unknown constant. note that computing the density p(  xn|  x1:n 1)
may well be impossible in general, but we can still draw samples from it via forward
simulation of the program.

the sequential importance resampling algorithm initializes by executing k parallel
copies of the program p, and continuing execution until the    rst observe statement is
encountered. weights for each partial trace   xk
1, for k = 1, . . . , k, are then initialized to

with associated normalized incremental targets
with associated normalized incremental targets
1
1
zn
zn

   n(  x1:n) =
   n(  x1:n) =

 n(  x1:n)
 n(  x1:n)

g(yn|  x1:n)p(  xn|  x1:n 1),
g(yn|  x1:n)p(  xn|  x1:n 1),

(127)

(126)

(127)

where each zn is an unknown constant. note that computing the density p(  xn|  x1:n 1)
where each zn is an unknown constant. note that computing the density p(  xn|  x1:n 1)

kxk=1

1

2

1

.

1:n

n 1

n 1

n 1

n|  xak

1 ) 1(  xak

1:2) 2(  xak

recursion:

n ,
want samples from 

n|  xak
wood group

tion traces, and discards those which are already very unlikely, by sampling ancestor
1:2)p(  xk
indices ak
1:2)

kxk=1
kxk=1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
  zn , 1
     n(  x1:n) ,
w(  xk
w k
(  x1:n)
1:n)
n    xk
1:n 1) =yj
kxk=1
smc for probabilistic programming
q(  xn|  xak
1:n 1) = p(  xn|  xak
1
1:2) = p(y2|  xk
 2(  xk
k
f k
j (xk
j|   k
n 1
n 1
j )
1 from a discrete distribution on w k
1 , where
w(  xk
(  x1:n 1)
     n 1(  x1:n 1) :=
1:n 1)   xk
proposal (several options):
  zn 1
w(  xk
1:2) = p(y2|  xk
1:n 1
n , w(  xk
w(  xk
1:n)
1:n)
w(  xk
n|  xak
1:n 1     p(  xn|  xak
w k
w k
n)
pk
  xk
n 1
n 1
1:n 1)
(142)
w k
n =
pk
k   zn
k0=1 w(  xk0
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n)
`=1 w(  xk
n)
q(  xn|  xak
1:n 1) = p(  xn|  xak
 n(  xk
1:3)p(  xk
1:3) = p(y3|  xk
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
after resampling, all particles have equal weight. we then continue executing the pro-
1:n 1) =yj
n 1 = k0) = w k0
p(ak
w(  xk
1:3) = p(y3|  xk
1:3)
proposal (several options):
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
j (xk
f k
j|   k
n 1
j )
gram from the program traces {  xak
k=1, until the next observe statement. in general,
1 }k
proposal (several options):
have a sample-based approximation to 
  xak
n 1
1:n 1          n 1(  x1:n 1)
for n > 1, we then have
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
kxk=1
1:n 1     p(  xn|  xak
n|  xak
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
  xk
n 1
1:n 1)
     n 1(  x1:n 1) ,
weights:
w k
(  x1:n 1)
n 1   xk
n|  xak
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1       xk
w(  xk
n) = gk
n| k
n(yk
n)     p(yk
n 1
n);
1:n 1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1) =yj
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(x1:n) = p(yn|  x1:n)
j (xk
f k
1:n 1) =yj
n 1
n 1
sample from 
n|  xak
1:n 1) n 1(  xak
1:n)p(  xk
 n(  xk
1:n) = p(yn|  xk
n and new incremental partial trace   xk
n, are attained by continuing pro-
that is, each  k
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1 = k0) = w k0
f k
j|   k
j (xk
p(ak
n 1
n 1
j )
n 1
gram execution from the partial execution corresponding to the previous partial trace
w(x1:n) =
1:n) = p(yn|  xk
w(  xk
recursion:
1:n)
 n 1(  x1:n 1)q(  xn| . . . )
  xak
n|  xak
1:n 1     p(  xn|  xak
  xak
  xk
n 1
1:n 1          n 1(  x1:n 1)
n 1
n 1
1:n 1, de   ning
1:n 1)
n|  xak
1:n 1) n 1(  xak
1:n 1     p(  xn|  xak
n|  xak
1:n)p(  xk
p(yn|  xk
 n(  xk
n 1
de   nitions
1:n )
1:n)
  xk
n 1
n 1
1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(xk
=
1:n) =
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n =   xak
ak
ak
ak
ak
1:n 1    yj
(144)
  xk
1:n 1       xk
n 1
n.
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1)q(  xk
1:n 1)q(  xk
n 1
n 1
n 1
n 1
n|  x
n|  x
 n 1(  x
 n 1(  x
1:n 1)
1:n 1)
n|  xak
kxk=1
  xk
j|   k
f k
j (xk
n 1 = k0) = w k0
n 1
p(ak
j )
     n(  x1:n) ,
w k
importance weight by 
(  x1:n)
n|  xak
n    xk
n 1
   n+1(  x1:n+1) / p(yn+1|  x1:n+1)p(  xn+1|  x1:n)   n(  x1:n)
1:n)p(  xk
p(yn|  xk
after the    rst observation (and prior to resampling), as in the likelihood weighting
n 1
1:n 1)
= p(yn|  xk
  xak
1:n)
. . . =
n 1
1:n 1          n 1(  x1:n 1)
above, the weighted set of samples {  xk
k=1 provides an approximation to the    rst
1, w k
1 }k
ak
 n(  x1:n)
q(  xk
n 1
n|  x
1:n 1)
w(  xk
1:n)
n ,
 n 1(  x1:n 1)q(  xn| . . . )
75
pk
n(yn|  xk
1:n) = p(yn|  xk
1:n) = gk
1:n)
weights:
k0=1 w(  xk0
75
77
1:n 1) n 1(  xak
p(yn|  xk
1:n)p(  xk
 n(  xk
n 1
1:n )
1:n)
recursion:
w(x1:n) = p(yn|  x1:n)
ak
ak
ak
1:n 1)q(  xk
n 1
n 1
n 1
n|  x
 n 1(  x
1:n 1)
 n(  x1:n)
n|  xak
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
w(x1:n) =

wood, van de meent, and mansinghka    a new approach to probabilistic programming id136    aistats 2014
paige and wood    a compilation target for probabilistic programming languages    icml 2014

w(x1:n) = p(yn|  x1:n)
w(x1:n) =

n|  xak
1:n 1)q(  xk

ak
n 1
1:n 1)

 n 1(  x

weights:

 n(  x1:n)

1:n) =

(143)

w(xk

n|  x

w(  xk

w k

w k

1:n)

n 1

n 1

n 1

=

...

1:n

kxk=1

1

2

1

.

1:n

n 1

n 1

n 1

n|  xak

1 ) 1(  xak

1:2) 2(  xak

recursion:

n ,
want samples from 

n|  xak
wood group

tion traces, and discards those which are already very unlikely, by sampling ancestor
1:2)p(  xk
indices ak
1:2)

kxk=1
kxk=1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
  zn , 1
     n(  x1:n) ,
w(  xk
w k
(  x1:n)
1:n)
n    xk
1:n 1) =yj
kxk=1
smc for probabilistic programming
q(  xn|  xak
1:n 1) = p(  xn|  xak
1
1:2) = p(y2|  xk
 2(  xk
k
f k
j (xk
j|   k
n 1
n 1
j )
1 from a discrete distribution on w k
1 , where
w(  xk
(  x1:n 1)
     n 1(  x1:n 1) :=
1:n 1)   xk
proposal (several options):
  zn 1
w(  xk
1:2) = p(y2|  xk
1:n 1
n , w(  xk
w(  xk
1:n)
1:n)
w(  xk
n|  xak
1:n 1     p(  xn|  xak
w k
w k
n)
pk
  xk
n 1
n 1
1:n 1)
(142)
w k
n =
pk
k   zn
k0=1 w(  xk0
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n)
`=1 w(  xk
n)
q(  xn|  xak
1:n 1) = p(  xn|  xak
 n(  xk
1:3)p(  xk
1:3) = p(y3|  xk
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
after resampling, all particles have equal weight. we then continue executing the pro-
1:n 1) =yj
n 1 = k0) = w k0
p(ak
w(  xk
1:3) = p(y3|  xk
1:3)
proposal (several options):
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
j (xk
f k
j|   k
n 1
j )
gram from the program traces {  xak
k=1, until the next observe statement. in general,
1 }k
proposal (several options):
have a sample-based approximation to 
  xak
n 1
1:n 1          n 1(  x1:n 1)
for n > 1, we then have
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
kxk=1
1:n 1     p(  xn|  xak
n|  xak
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
  xk
n 1
1:n 1)
     n 1(  x1:n 1) ,
weights:
w k
(  x1:n 1)
n 1   xk
n|  xak
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1       xk
w(  xk
n) = gk
n| k
n(yk
n)     p(yk
n 1
n);
1:n 1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1) =yj
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(x1:n) = p(yn|  x1:n)
j (xk
f k
1:n 1) =yj
n 1
n 1
sample from 
n|  xak
1:n 1) n 1(  xak
1:n)p(  xk
 n(  xk
1:n) = p(yn|  xk
n and new incremental partial trace   xk
n, are attained by continuing pro-
that is, each  k
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1 = k0) = w k0
f k
j|   k
j (xk
p(ak
n 1
n 1
j )
n 1
gram execution from the partial execution corresponding to the previous partial trace
w(x1:n) =
1:n) = p(yn|  xk
w(  xk
recursion:
1:n)
 n 1(  x1:n 1)q(  xn| . . . )
  xak
n|  xak
1:n 1     p(  xn|  xak
  xak
  xk
n 1
1:n 1          n 1(  x1:n 1)
n 1
n 1
1:n 1, de   ning
1:n 1)
n|  xak
1:n 1) n 1(  xak
1:n 1     p(  xn|  xak
n|  xak
1:n)p(  xk
p(yn|  xk
 n(  xk
n 1
de   nitions
1:n )
1:n)
  xk
n 1
n 1
1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(xk
=
1:n) =
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n =   xak
ak
ak
ak
ak
1:n 1    yj
(144)
  xk
1:n 1       xk
n 1
n.
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1)q(  xk
1:n 1)q(  xk
n 1
n 1
n 1
n 1
n|  x
n|  x
 n 1(  x
 n 1(  x
1:n 1)
1:n 1)
n|  xak
kxk=1
  xk
j|   k
f k
j (xk
n 1 = k0) = w k0
n 1
p(ak
j )
     n(  x1:n) ,
w k
importance weight by 
(  x1:n)
n|  xak
n    xk
n 1
   n+1(  x1:n+1) / p(yn+1|  x1:n+1)p(  xn+1|  x1:n)   n(  x1:n)
1:n)p(  xk
p(yn|  xk
after the    rst observation (and prior to resampling), as in the likelihood weighting
n 1
1:n 1)
= p(yn|  xk
  xak
1:n)
. . . =
n 1
1:n 1          n 1(  x1:n 1)
above, the weighted set of samples {  xk
k=1 provides an approximation to the    rst
1, w k
1 }k
ak
 n(  x1:n)
q(  xk
n 1
n|  x
1:n 1)
w(  xk
1:n)
n ,
 n 1(  x1:n 1)q(  xn| . . . )
75
pk
n(yn|  xk
1:n) = p(yn|  xk
1:n) = gk
1:n)
weights:
k0=1 w(  xk0
75
77
1:n 1) n 1(  xak
p(yn|  xk
1:n)p(  xk
 n(  xk
n 1
1:n )
1:n)
recursion:
w(x1:n) = p(yn|  x1:n)
ak
ak
ak
1:n 1)q(  xk
n 1
n 1
n 1
n|  x
 n 1(  x
1:n 1)
 n(  x1:n)
n|  xak
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
w(x1:n) =

wood, van de meent, and mansinghka    a new approach to probabilistic programming id136    aistats 2014
paige and wood    a compilation target for probabilistic programming languages    icml 2014

w(x1:n) = p(yn|  x1:n)
w(x1:n) =

n|  xak
1:n 1)q(  xk

ak
n 1
1:n 1)

 n 1(  x

weights:

 n(  x1:n)

1:n) =

(143)

w(xk

n|  x

w(  xk

w k

w k

1:n)

n 1

n 1

n 1

=

...

1:n

kxk=1

1

2

1

.

1:n

n 1

n 1

n 1

n|  xak

1 ) 1(  xak

1:2) 2(  xak

recursion:

n ,
want samples from 

n|  xak
wood group

tion traces, and discards those which are already very unlikely, by sampling ancestor
1:2)p(  xk
indices ak
1:2)

kxk=1
kxk=1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
  zn , 1
     n(  x1:n) ,
w(  xk
w k
(  x1:n)
1:n)
n    xk
1:n 1) =yj
kxk=1
smc for probabilistic programming
q(  xn|  xak
1:n 1) = p(  xn|  xak
1
1:2) = p(y2|  xk
 2(  xk
k
f k
j (xk
j|   k
n 1
n 1
j )
1 from a discrete distribution on w k
1 , where
w(  xk
(  x1:n 1)
     n 1(  x1:n 1) :=
1:n 1)   xk
proposal (several options):
  zn 1
w(  xk
1:2) = p(y2|  xk
1:n 1
n , w(  xk
w(  xk
1:n)
1:n)
w(  xk
n|  xak
1:n 1     p(  xn|  xak
w k
w k
n)
pk
  xk
n 1
n 1
1:n 1)
(142)
w k
n =
pk
k   zn
k0=1 w(  xk0
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n)
`=1 w(  xk
n)
q(  xn|  xak
1:n 1) = p(  xn|  xak
 n(  xk
1:3)p(  xk
1:3) = p(y3|  xk
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
after resampling, all particles have equal weight. we then continue executing the pro-
1:n 1) =yj
n 1 = k0) = w k0
p(ak
w(  xk
1:3) = p(y3|  xk
1:3)
proposal (several options):
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
j (xk
f k
j|   k
n 1
j )
gram from the program traces {  xak
k=1, until the next observe statement. in general,
1 }k
proposal (several options):
have a sample-based approximation to 
  xak
n 1
1:n 1          n 1(  x1:n 1)
for n > 1, we then have
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
kxk=1
1:n 1     p(  xn|  xak
n|  xak
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
  xk
n 1
1:n 1)
     n 1(  x1:n 1) ,
weights:
w k
(  x1:n 1)
n 1   xk
n|  xak
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1       xk
w(  xk
n) = gk
n| k
n(yk
n)     p(yk
n 1
n);
1:n 1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1) =yj
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(x1:n) = p(yn|  x1:n)
j (xk
f k
1:n 1) =yj
n 1
n 1
sample from 
n|  xak
1:n 1) n 1(  xak
1:n)p(  xk
 n(  xk
1:n) = p(yn|  xk
n and new incremental partial trace   xk
n, are attained by continuing pro-
that is, each  k
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1 = k0) = w k0
f k
j|   k
j (xk
p(ak
n 1
n 1
j )
n 1
gram execution from the partial execution corresponding to the previous partial trace
w(x1:n) =
1:n) = p(yn|  xk
w(  xk
recursion:
1:n)
 n 1(  x1:n 1)q(  xn| . . . )
  xak
n|  xak
1:n 1     p(  xn|  xak
  xak
  xk
n 1
1:n 1          n 1(  x1:n 1)
n 1
n 1
1:n 1, de   ning
1:n 1)
n|  xak
1:n 1) n 1(  xak
1:n 1     p(  xn|  xak
n|  xak
1:n)p(  xk
p(yn|  xk
 n(  xk
n 1
de   nitions
1:n )
1:n)
  xk
n 1
n 1
1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(xk
=
1:n) =
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n =   xak
ak
ak
ak
ak
1:n 1    yj
(144)
  xk
1:n 1       xk
n 1
n.
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1)q(  xk
1:n 1)q(  xk
n 1
n 1
n 1
n 1
n|  x
n|  x
 n 1(  x
 n 1(  x
1:n 1)
1:n 1)
n|  xak
kxk=1
  xk
j|   k
f k
j (xk
n 1 = k0) = w k0
n 1
p(ak
j )
     n(  x1:n) ,
w k
importance weight by 
(  x1:n)
n|  xak
n    xk
n 1
   n+1(  x1:n+1) / p(yn+1|  x1:n+1)p(  xn+1|  x1:n)   n(  x1:n)
1:n)p(  xk
p(yn|  xk
after the    rst observation (and prior to resampling), as in the likelihood weighting
n 1
1:n 1)
= p(yn|  xk
  xak
1:n)
. . . =
n 1
1:n 1          n 1(  x1:n 1)
above, the weighted set of samples {  xk
k=1 provides an approximation to the    rst
1, w k
1 }k
ak
 n(  x1:n)
q(  xk
n 1
n|  x
1:n 1)
w(  xk
1:n)
n ,
 n 1(  x1:n 1)q(  xn| . . . )
75
pk
n(yn|  xk
1:n) = p(yn|  xk
1:n) = gk
1:n)
weights:
k0=1 w(  xk0
75
77
1:n 1) n 1(  xak
p(yn|  xk
1:n)p(  xk
 n(  xk
n 1
1:n )
1:n)
recursion:
w(x1:n) = p(yn|  x1:n)
ak
ak
ak
1:n 1)q(  xk
n 1
n 1
n 1
n|  x
 n 1(  x
1:n 1)
 n(  x1:n)
n|  xak
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
w(x1:n) =

wood, van de meent, and mansinghka    a new approach to probabilistic programming id136    aistats 2014
paige and wood    a compilation target for probabilistic programming languages    icml 2014

w(x1:n) = p(yn|  x1:n)
w(x1:n) =

n|  xak
1:n 1)q(  xk

ak
n 1
1:n 1)

 n 1(  x

weights:

 n(  x1:n)

1:n) =

(143)

w(xk

n|  x

w(  xk

w k

w k

1:n)

n 1

n 1

n 1

=

...

1:n

kxk=1

1

2

1

.

1:n

n 1

n 1

n 1

n|  xak

1 ) 1(  xak

1:2) 2(  xak

recursion:

n ,
want samples from 

n|  xak
wood group

tion traces, and discards those which are already very unlikely, by sampling ancestor
1:2)p(  xk
indices ak
1:2)

kxk=1
kxk=1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
  zn , 1
     n(  x1:n) ,
w(  xk
w k
(  x1:n)
1:n)
n    xk
1:n 1) =yj
kxk=1
smc for probabilistic programming
q(  xn|  xak
1:n 1) = p(  xn|  xak
1
1:2) = p(y2|  xk
 2(  xk
k
f k
j (xk
j|   k
n 1
n 1
j )
1 from a discrete distribution on w k
1 , where
w(  xk
(  x1:n 1)
     n 1(  x1:n 1) :=
1:n 1)   xk
proposal (several options):
  zn 1
w(  xk
1:2) = p(y2|  xk
1:n 1
n , w(  xk
w(  xk
1:n)
1:n)
w(  xk
n|  xak
1:n 1     p(  xn|  xak
w k
w k
n)
pk
  xk
n 1
n 1
1:n 1)
(142)
w k
n =
pk
k   zn
k0=1 w(  xk0
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n)
`=1 w(  xk
n)
q(  xn|  xak
1:n 1) = p(  xn|  xak
 n(  xk
1:3)p(  xk
1:3) = p(y3|  xk
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
after resampling, all particles have equal weight. we then continue executing the pro-
1:n 1) =yj
n 1 = k0) = w k0
p(ak
w(  xk
1:3) = p(y3|  xk
1:3)
proposal (several options):
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
j (xk
f k
j|   k
n 1
j )
gram from the program traces {  xak
k=1, until the next observe statement. in general,
1 }k
proposal (several options):
have a sample-based approximation to 
  xak
n 1
1:n 1          n 1(  x1:n 1)
for n > 1, we then have
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
kxk=1
1:n 1     p(  xn|  xak
n|  xak
q(  xn, . . . )     p(  xn|  x1:n 1)   n 1(  x1:n 1)
  xk
n 1
1:n 1)
     n 1(  x1:n 1) ,
weights:
w k
(  x1:n 1)
n 1   xk
n|  xak
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1       xk
w(  xk
n) = gk
n| k
n(yk
n)     p(yk
n 1
n);
1:n 1
q(  xn, . . . ) = p(  xn|  x1:n 1)     n 1(  x1:n 1)
1:n 1) =yj
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(x1:n) = p(yn|  x1:n)
j (xk
f k
1:n 1) =yj
n 1
n 1
sample from 
n|  xak
1:n 1) n 1(  xak
1:n)p(  xk
 n(  xk
1:n) = p(yn|  xk
n and new incremental partial trace   xk
n, are attained by continuing pro-
that is, each  k
1:n 1) = p(  xn|  xak
q(  xn|  xak
n 1
n 1 = k0) = w k0
f k
j|   k
j (xk
p(ak
n 1
n 1
j )
n 1
gram execution from the partial execution corresponding to the previous partial trace
w(x1:n) =
1:n) = p(yn|  xk
w(  xk
recursion:
1:n)
 n 1(  x1:n 1)q(  xn| . . . )
  xak
n|  xak
1:n 1     p(  xn|  xak
  xak
  xk
n 1
1:n 1          n 1(  x1:n 1)
n 1
n 1
1:n 1, de   ning
1:n 1)
n|  xak
1:n 1) n 1(  xak
1:n 1     p(  xn|  xak
n|  xak
1:n)p(  xk
p(yn|  xk
 n(  xk
n 1
de   nitions
1:n )
1:n)
  xk
n 1
n 1
1:n 1)
1:n 1) = p(  xn|  xak
q(  xn|  xak
w(xk
=
1:n) =
n 1
n 1
1:n 1)    / p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n =   xak
ak
ak
ak
ak
1:n 1    yj
(144)
  xk
1:n 1       xk
n 1
n.
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
1:n 1)q(  xk
1:n 1)q(  xk
n 1
n 1
n 1
n 1
n|  x
n|  x
 n 1(  x
 n 1(  x
1:n 1)
1:n 1)
n|  xak
kxk=1
  xk
j|   k
f k
j (xk
n 1 = k0) = w k0
n 1
p(ak
j )
     n(  x1:n) ,
w k
importance weight by 
(  x1:n)
n|  xak
n    xk
n 1
   n+1(  x1:n+1) / p(yn+1|  x1:n+1)p(  xn+1|  x1:n)   n(  x1:n)
1:n)p(  xk
p(yn|  xk
after the    rst observation (and prior to resampling), as in the likelihood weighting
n 1
1:n 1)
= p(yn|  xk
  xak
1:n)
. . . =
n 1
1:n 1          n 1(  x1:n 1)
above, the weighted set of samples {  xk
k=1 provides an approximation to the    rst
1, w k
1 }k
ak
 n(  x1:n)
q(  xk
n 1
n|  x
1:n 1)
w(  xk
1:n)
n ,
 n 1(  x1:n 1)q(  xn| . . . )
75
pk
n(yn|  xk
1:n) = p(yn|  xk
1:n) = gk
1:n)
weights:
k0=1 w(  xk0
75
77
1:n 1) n 1(  xak
p(yn|  xk
1:n)p(  xk
 n(  xk
n 1
1:n )
1:n)
recursion:
w(x1:n) = p(yn|  x1:n)
ak
ak
ak
1:n 1)q(  xk
n 1
n 1
n 1
n|  x
 n 1(  x
1:n 1)
 n(  x1:n)
n|  xak
   n(  x1:n) / p(yn|  x1:n)p(  xn|  x1:n 1)   n 1(  x1:n 1)
w(x1:n) =

wood, van de meent, and mansinghka    a new approach to probabilistic programming id136    aistats 2014
paige and wood    a compilation target for probabilistic programming languages    icml 2014

w(x1:n) = p(yn|  x1:n)
w(x1:n) =

n|  xak
1:n 1)q(  xk

ak
n 1
1:n 1)

 n 1(  x

weights:

 n(  x1:n)

1:n) =

(143)

w(xk

n|  x

w(  xk

w k

w k

1:n)

n 1

n 1

n 1

=

...

1:n

smc schematic

intuitively   
- run   
- wait/weight   
- continue 

s
d
a
e
r
h
t

continuations

observe

the normalized posterior id203 distribution over program traces can be de   ned

each observe.

wood group

j=1 cor-
tuples {(gi,  i, yi)}n
responding to the sample statements, with the associated sequence of sampled values
(i.e. the program execution trace) {xj}m
j=1. the id203 of this program execution
trace can be de   ned, up to an unknown normalizing constant, as a product of all ran-
dom choices x and all observed values y, with

i=1 corresponding to the observe statements, and {(fj,    j)}m
metropolis hastings =    single site    mcmc = lmh
posterior distribution of execution traces is proportional to trace score with 
observed values plugged in

10.2 a metropolis-hastings algorithm
if we are given a probabilistic model speci   ed only in terms of this simulation model, can
we de   ne a metropolis-hastings algorithm to sample from its posterior? the answer is
yes. recall that a mh algorithm draws a sequence of dependent samples according
to a target distribution    (x) by using a proposal kernel q(x0|x); given a current sam-
ple x, we propose a new candidate sample x0     q(  |x) and compute an acceptance
id203

 (x) , p(x, y) =
metropolis-hastings acceptance rule  

note that this ordering, as well as the cardinalities m and n, are not necessarily iden-
tical across different runs of the program.

   (x) , p(x|y) =

fj(xj|   j).

gi(yi| i)

nyi=1

(105)

 (x)

as

z

,

obscured by the notation above is the dependency structure induced by the prob-
abilistic program p. each parameter vector  i and    j are themselves deterministic
functions of (potentially) every previous random choice in the program. so too are
gi and fj. let ni denote the total number of random values sampled prior to the ith
observe statement and the bold, subscripted value xj = x1                xj denote a partial
program execution trace consisting of the    rst j sampled values (with x0     ;). we
can then rewrite equation 105 in a form which explicitly represents the dependency

with id203     we accept this proposal, and select x0 as the next sample; otherwise,
we select x, repeating it as the next sample. note that as the id172 constant
z for the density     is the same for both x and x0, we can replace     with   in this ac-
ceptance ratio. we can construct a sampler along these lines for sampling probabilistic
program traces.

    need proposal

myj=1
    = min   1,

 (x) = p(x, y) =

milch and russell    general-purpose mcmc id136 over relational structures.     uai 2006.
goodman, mansinghka, roy, bonawitz, and tenenbaum    church: a language for generative models.    uai 2008.
wingate, stuhlm  ller, goodman    lightweight implementations of probabilistic programming languages via transformational compilation    aistats 2011

the style of sampling algorithm we consider here is related to    single-site    mh al-
gorithms. we initialize the algorithm by running a single execution of the probabilistic
program, generating an initial trace x0, of length m 0. now, given a trace xs, we de   ne a

     j(xj 1)    .

   i(xni)    myj=1

nyi=1

(106)

  fj(xj 1)   xj    

  gi(xni)   yi    

e[z] = e[q(x)] =z q(x)p(x|y)dx =z q(x)   (x)dx.
e[z] = e[q(x)] =z q(x)   (x)dx =

63

the normalizing constant z is found by integrating over all possible program execution
traces.
   (x0)q(x|x0)
the program output z is de   ned as a deterministic function of the trace; that is,
given a program execution trace x, we de   ne z = q(x). this allows us, in theory, to
use the posterior distribution over traces    (x) to characterize the distribution over z
given the observations y; for example, the posterior mean can be found by

   (x)q(x0|x)    .

lmh proposal 

` by drawing ` uniformly from
xs has length m s, and we pick a single random choice xs
`) to
the set of integers 1, . . . , m s. then, we apply a reversible transition kernel    (x0`|xs
propose a new value at that speci   c random choice. we now re-run the remainder of
the program p, starting with the partial program execution trace x0` = xs
` 1     x0`, sim-
id203 of new part of 
ulating the rest of the program to generate a new proposal trace x0 of length m0. this
proposed execution trace
leads to an overall proposal density

which in turn leads to an acceptance id203

q(x0|xs) =

1
m s    (x0`|xs
`)

number of samples in  
original trace

    = min 1,

 (x0)m0   (xs
 (x)m s   (x0`|xs

f0j(x0j|   0j)

m0yj=`+1
j=`+1 f0j(x0j|   0j)!
`|x0`)qm s
`)qm0

j=`+1 f s

j|   s
j )

j (xs

which de   nes a basic mcmc sampler targeting the space of program execution traces.

10.2.1 a database of random choices
for high-dimensional problems, the basic metropolis-hasting algorithm that arises by
proposing according to equation 124 will still perform poorly, as after changing propos-
ing a single value x0` we re-run the rest of the program. this can be made more ef   cient
by re-using some of the sampled values in the remainder of the original trace xs.

(124)

(125)

    resume p by calling (k x0) if sample, observe, or predict reached do:
    sample: p passes us a continuation k0 and an object (f0,    0) consisting
of a distribution f0 with parameter    0. we sample a value x0     f0(  |   0),
store (x0,k0,f0,   0), then call (k0 x0).
    observe: p passes us a continuation k0, an object (g0,  0) consisting of
a distribution g0 with parameter  0, and a observed value y. we store
(y, k0,g0, 0), and call (k0).

lmh acceptance ratio

   single site update    = sample from the prior = run program forward

   (x0m|xm) = fm(x0m|   m),    m =    0m

mh acceptance ratio

    predict: p passes us a continuation k0, a label `0, and a value z0. we
id203 of original trace continuation  
restarting proposal trace at mth sample 

store (`0, z0) and call (k0).

number of sample statements 
in original trace

    when p terminates we compute
    = min 1,

 (x0)mqm
 (x)m0qm0

j=m fj(xj|   j)

j=m f0j(x0j|   0j)!

and accept proposed trace and and output (`0, z0) w.p.    , keep old trace and
number of sample statements 
id203 of proposal trace continuation  
output (`, z) otherwise.
in new trace
restarting original trace at mth sample 

65

lmh schematic

...

z1

z1

z3
...

zk

implementation strategy

    interpreted 

    interpreter tracks side effects and directs control    ow 

for id136 

    compiled  

    leverages existing compiler infrastructure 
    can only exert control over    ow from within function 

calls  

    e.g. sample, observe, predict

wingate, stuhlm  ller, goodman    lightweight implementations of probabilistic programming languages via transformational compilation    aistats 2011 
paige and wood    a compilation target for probabilistic programming languages    icml 2014 

probabilistic c

intuitively   
- run   
- wait/weight   
- fork 

s
e
s
s
e
c
o
r
p

new processes

observe

paige and wood    a compilation target for probabilistic programming languages    icml 2014 

compilation

    lw  

    sample: inject random values 

    lmh  

    catalog all random choices and compare traces by running 

new future 

    smc - run multiple independent futures without corrupting past 

    must have control over the    rest of the computation    

    no longer control execution, can only interrupt and exert control 

at key points 

    start, sample, observe, predict, terminate

continuations

    a continuation is a function that encapsulates the    rest of the 

computation    

    a continuation passing style (cps) transformation rewrites 

programs so  
    no function ever returns 

    every function takes an extra argument, a function called the  

continuation  

    standard programming language technique 

    no limitations

friedman and wand.    essentials of programming languages.    mit press, 2008. 
fischer, kiselyov, and shan    purely functional lazy non-deterministic programming    acm sigplan 2009 
goodman and stuhlm  ller http://dippl.org/ 2014 
tolpin https://bitbucket.org/probprog/anglican/ 2014 

the computation using cps-transformed functions makes clear the actual order of ex-
ecution, from    inside    to    outside   . suppose we try to compute a sum of a product and
another number, i.e. evaluate equations of the form ab + c.

example cps transformation

;; standard clojure:
(println (+ (* 2 3) 4))

a tutorial on probabilistic programming

;; cps transformed:
(*& 2 3 (fn [x] (+& x 4 println)))
10.5.1 examples of cps transformation
;; here   s probably the clearest way to write this:
here we demonstrate continuation passing style by example, showing a few simple clo-
(defn add-to-product&
jure functions as transformed into cps. we will denote cps-transformed functions by
ending their names with &; the last argument c will explicitly represent the continuation.

first continuation

second cont.

"compute a*b + c"
[a b c k]
(*& a b

;; cps-transformed "primitives"
(fn [tmp] (+& tmp c k))))
(defn +& [a b k] (k (+ a b)))
(defn *& [a b k] (k (* a b)))
(add-to-product& 2 3 4 println)
the add-to-product function    rst computes the product of a and b (the innermost
;; example:
computation), and then calls a continuation which adds c to the result, which then calls
(+& 2 4 println)
the outermost continuation. note that in this example we don   t necessarily have to nest
(*& 3 5 println)

(defn square& [a k] (*& a a k))

cps explicitly linearizes execution

;; for example:
(square& 5 println)
(sqrt& 9 println)

; 25
; 3

(defn pythag&

"compute sqrt(x^2 + y^2)"
[x y k]
(square& x

(fn [xx]

(square& y

xx = x2
yy = y2

xxyy = xx + yy

   = pxxyy

(fn [yy]

(+& xx yy

(fn [xxyy]

(sqrt& xxyy k))))))))

    compiling to a pure language with lexical scoping ensures 

;; test it:
a. variables needed in subsequent computation are bound in the environment  
(pythag& 3 4 println)
b. can   t be modi   ed by multiple calls to the continuation function
(pythag& 5 12 println)
note that the continuations we de   ne within the pythag& function have state, in their

; 5
; 13

can allows us to    get away with" calling these continuation functions repeatedly, anyway,
since no subsequent executions of the program will modify these variables.

anglican programs

(observe (flip p) outcome)
(predict :p p))

10.5.2 an example of a probabilistic model
(defquery flip-example [outcome]

(let [p (sample (uniform-continuous 0 1))]

(observe (flip p) outcome)
(predict :p p))

(flip-example true)

(flip-example true)

(let [u (uniform-continuous 0 1)

p (sample u)

dist (flip p)]

consider a very simple program which samples a id203 p uniformly on (0, 1)
and then observe true from a single bernoulli trial. this model, in traditional clo-
jure/anglican syntax, would look like

(predict :p p))

(observe dist outcome)

(defn flip-example [outcome]

(let [p (sample (uniform-continuous 0 1))]

(observe (flip p) outcome)
(predict :p p))

consider a very simple program which samples a id203 p uniformly on (0, 1)
and then observe true from a single bernoulli trial. this model, in traditional clo-
jure/anglican syntax, would look like

83

(flip-example true)

to give an idea of how this program might look once cps-transformed, we implement
a    dummy" id136 backend.

anglican

74

anglican    linearized   

are    compiled    to native cps-clojure

a tutorial on probabilistic programming

(observe (flip p) outcome)
(predict :p p))

wood group

(flip-example true)

(let [u (uniform-continuous 0 1)

p (sample u)

dist (flip p)]

(observe dist outcome)

(defn flip-query& [outcome k1]

(uniform-continuous& 0 1

(defn flip-example [outcome]

(fn [dist1]

(let [p (sample (uniform-continuous 0 1))]

(sample& dist1

(observe (flip p) outcome)
(predict :p p))

(fn [p] ((fn [p k2]
(flip& p

(flip-example true)

(observe& dist2 outcome

(fn [dist2]

(fn []

;; cps-ed distribution constructors
(flip-query& true terminate)
(defn uniform-continuous& [a b k]
(defn weighted-sample [query&]

(k (uniform-continuous a b)))
(init-backend!)
(defn flip& [p k]
(query& terminate)
(k (flip p)))
[(:predicts @backend) (:log-weight @backend)])

to give an idea of how this program might look once cps-transformed, we implement
a very simple likelihood weighting id136 backend.

(predict& :p p k2))))))

(predict :p p))

p k1))))))

consider a very simple program which samples a id203 p uniformly on (0, 1)
and then observe true from a single bernoulli trial. this model, in traditional clo-
jure/anglican syntax, would look like

83

;; implement a "backend"
(weighted-sample flip-query-true&)
(defn sample& [dist k]
10.6
;; [ algorithm-specific implementation here ]
clojure
;; pass the sampled value to the continuation
and then talk about implementation, from transformation compilation to prob.-c to an-
(k (sample dist)))
glican style with brooks    prob.-c and how to get "the same" via cps transformation
and compilation to a pure functional language     this works because of datastructures.
(defn observe& [dist value k]

anglican    linearized   

are    compiled    to native cps-clojure

a tutorial on probabilistic programming

(observe (flip p) outcome)
(predict :p p))

wood group

(flip-example true)

(let [u (uniform-continuous 0 1)

p (sample u)

dist (flip p)]

(observe dist outcome)

(defn flip-query& [outcome k1]

(uniform-continuous& 0 1

(defn flip-example [outcome]

(fn [dist1]

(let [p (sample (uniform-continuous 0 1))]

(sample& dist1

(observe (flip p) outcome)
(predict :p p))

(fn [p] ((fn [p k2]
(flip& p

(flip-example true)

(observe& dist2 outcome

(fn [dist2]

(fn []

;; cps-ed distribution constructors
(flip-query& true terminate)
(defn uniform-continuous& [a b k]
(defn weighted-sample [query&]

(k (uniform-continuous a b)))
(init-backend!)
(defn flip& [p k]
(query& terminate)
(k (flip p)))
[(:predicts @backend) (:log-weight @backend)])

to give an idea of how this program might look once cps-transformed, we implement
a very simple likelihood weighting id136 backend.

(predict& :p p k2))))))

(predict :p p))

p k1))))))

consider a very simple program which samples a id203 p uniformly on (0, 1)
and then observe true from a single bernoulli trial. this model, in traditional clo-
jure/anglican syntax, would look like

83

;; implement a "backend"
(weighted-sample flip-query-true&)
(defn sample& [dist k]
10.6
;; [ algorithm-specific implementation here ]
clojure
;; pass the sampled value to the continuation
and then talk about implementation, from transformation compilation to prob.-c to an-
(k (sample dist)))
glican style with brooks    prob.-c and how to get "the same" via cps transformation
and compilation to a pure functional language     this works because of datastructures.
(defn observe& [dist value k]

anglican    linearized   

explicit functional form for    rest of program   

wood group

s
n
o

i
t

c
n
u

f
 

n
o

i
t

a
u
n

i
t
n
o
c

(defn flip-query& [outcome k1]

(uniform-continuous& 0 1

(fn [dist1]

(sample& dist1

(fn [p] ((fn [p k2]
(flip& p

(fn [dist2]

(observe& dist2 outcome

(fn []

(predict& :p p k2))))))

p k1))))))

(flip-query& true terminate)

(defn weighted-sample [query&]

(init-backend!)
(query& terminate)

interruptiblewood group

s
n
o

i
t

c
n
u

f
 

n
o

i
t

a
u
n

i
t
n
o
c

(defn flip-query& [outcome k1]

(uniform-continuous& 0 1

(fn [dist1]

(sample& dist1

(fn [p] ((fn [p k2]
(flip& p

(fn [dist2]

(observe& dist2 outcome

(fn []

(predict& :p p k2))))))

p k1))))))

a
n
g

l
i

c
a
n
p
r
i

 

m

i
t
i
v
e
s

(flip-query& true terminate)

(defn weighted-sample [query&]

(init-backend!)
(query& terminate)

controllablewood group

wood group

s
n
o

i
t

c
n
u

f
 

n
o

i
t

a
u
n

i
t
n
o
c

(defn flip-query& [outcome k1]
(defn flip-query& [outcome k1]

(uniform-continuous& 0 1
(uniform-continuous& 0 1

(fn [dist1]
(fn [dist1]

(sample& dist1
(sample& dist1

(fn [p] ((fn [p k2]
(fn [p] ((fn [p k2]
(flip& p
(flip& p

(fn [dist2]
(fn [dist2]

(observe& dist2 outcome
(observe& dist2 outcome

(fn []
(fn []

(predict& :p p k2))))))
(predict& :p p k2))))))

p k1))))))
p k1))))))

a
n
g

l
i

c
a
n
p
r
i

 

m

i
t
i
v
e
s

(flip-query& true terminate)
(flip-query& true terminate)

id136    backend    interface

(defn weighted-sample [query&]
(defn weighted-sample [query&]

(init-backend!)
(init-backend!)
(query& terminate)
(query& terminate)

webppl cps compiles to pure functional javascript

(defn flip& [p k]

(k (flip p)))

id136    backend   

;; implement a "backend"
(defn sample& [dist k]

;; [ algorithm-specific implementation here ]
;; pass the sampled value to the continuation
(k (sample dist)))

(defn observe& [dist value k]

(println "log-weight =" (observe dist value))
;; [ algorithm-specific implementation here ]
;; call continuation with no arguments
(k))

(defn predict& [label value k]

;; [ algorithm-specific implementation here ]
(k label value))

to cps transform the program itself, we    rst perform a    desugaring    step, replacing the
let block with a function call.

;; before cps transformation, desugar by removing    let    block

importance sampling
    for k = 1 . . .1

    initialize w   1
    initialize w   1
common framework 
    execute program p.
    execute program p.
    while executing p if a sample, observe, or the end of the program is
    while executing p if a sample, observe, or the end of the program is
pure compiled deterministic computation 
    initialize w   1
reached do:
reached do:
    execute program p.
    sample: p passes to us a continuation k and a tuple (f,    ) consisting of
    sample: p passes to us a continuation k and a tuple (f,    ) consisting of
start
continue
p
p
a distribution f and a parameter vector    . we sample a value x     f (  |   )
a distribution f and a parameter vector    . we sample a value x     f (  |   )
    while executing p if a sample, observe, or the end of the program is
reached do:
then call (k x) which continues execution of p provided the value.
then call (k x) which continues execution of p provided the value.
    observe: p passes to us a continuation k and a tuple (g,  , y) consist-
    observe: p passes to us a continuation k and a tuple (g,  , y) consist-
    sample: p passes to us a continuation k and a tuple (f,    ) consisting of
ing of a distribution g, a parameter vector  , and a observed value y.
ing of a distribution g, a parameter vector  , and a observed value y.
a distribution f and a parameter vector    . we sample a value x     f (  |   )
we compute w   wg(y| ) and call (k).
we compute w   wg(y| ) and call (k).
then call (k x) which continues execution of p provided the value.
    observe: p passes to us a continuation k and a tuple (g,  , y) consist-
    if p terminates, it passes to us a value z. we    output    z, w.
ing of a distribution g, a parameter vector  , and a observed value y.
we compute w   wg(y| ) and call (k).
observe
terminate
(g,  , y, k)

    if p terminates, it passes to us a value z. we    output    z, w.

    if p terminates, it passes to us a value z. we    output    z, w.

sample
(f,    , k)

predict
(z, k)

   backend   

terminate

continue

p

p

(defn store! [label value]

likelihood weighting    backend   

(swap! backend #(assoc-in % [:predicts label] value)))

(init-backend!)

(defn sample& [dist k]

;; call the continuation with a sampled value
(k (sample dist)))

(defn observe& [dist value k]

;; compute and record the log weight
(add-log-weight! (observe dist value))
;; call the continuation with no arguments
(k))

(defn predict& [label value k]

;; store predict, and call continuation
(store! label value)
(k))

likelihood weighting example

(sqrt& xxyy k))))))))

(fn [xxyy]

compiled pure deterministic computation 

start

p

sample&

   backend   

p

p

continue

continue
; 5
; 13

terminate p

;; test it:
(pythag& 3 4 println)
(pythag& 5 12 println)
note that the continuations we de   ne within the pythag& function have state, in their
closure! we cannot write, for example, the function (fn [yy k] (+& xx yy k)) since
it requires a value xx, a variable which is available due to being in scope at the time the
function is called, rather than passed in as an argument. immutability in clojure/angli-
can allows us to    get away with" calling these continuation functions repeatedly, anyway,
p     u(0, 1) w   pi(outcome=true)(1   p)i(outcome=false)
since no subsequent executions of the program will modify these variables.
10.5.2 an example of a probabilistic model
(defquery flip-example [outcome]

terminate

predict&

observe&

(let [p (sample (uniform-continuous 0 1))]

(observe (flip p) outcome)
(predict :p p))

(flip-example true)

76

smc backend

wood group

(defn sample& [dist k]

;; call the continuation with a sampled value
(k (sample dist)))

(defn observe& [dist value k]

;; block and wait for k calls to reach observe&
;; compute weights
;; use weights to subselect continuations to call
;; call k sampled continuations (often multiple times)
)

(defn predict& [label value k]

;; store predict, and call continuation
(store! label value)
(k))

(defn flip-query& [outcome k1]

(uniform-continuous& 0 1

(fn [dist1]

particle id115

andrieu, doucet, holenstein    particle id115 methods.    jrssb 2010

    iterable smc 

- pimh :    particle 

independent metropolis-
hastings    

- pgibbs :    iterated 
conditional smc    
 pgas :    particle gibbs 
ancestral sampleing"

-

p
e
e
w
s

n 

n 

n 

   

n 

n 

n 

   

n 

n 

n 

   

wood, van de meent, mansinghka    a new approach to probabilistic programming id136    aistats 2014

pimh math

wood group

compute 
nyn=1

  z =

    each sweep of smc can 

n 
the approximation we can compute through the unnormalized weights at each resam-
pling point (i.e. at each observe) given by

wood group
wood group
  zn =

w(  xk

1:n)

1
k

nyn=1

kxk=1

(145)

is known to be unbiased (?).

    pimh is mh that accepts entire 

likelihood estimate   z ?. the new candidate set of particles is accepted according to a
likelihood estimate   z ?. the new candidate set of particles is accepted according to a
id203
id203

new particle sets w.p. 
  z s 1! .
  z s 1! .
  z ?
  z ?

10.4 particle mcmc algorithms
particle mcmc algorithms use sequential monte carlo as a proposal distribution within
an mcmc algorithm. the most basic application of particle mcmc to probabilistic pro-
grams is the particle independent metropolis-hastings algorithm. in this algorithm, we
initialize an mcmc sampler by running smc with k particles to create an initial set of
k weighted execution traces {x0,k, w 0,k}k
k=1 and compute its marginal likelihood esti-
mate   z 0 according to equation ?? then, for s = 1, 2, . . . , we run a new smc sampler
n 
k=1 with associated marginal
to propose a candidate set of execution traces {x?,k, w 0,k}k
likelihood estimate   z ?. the new candidate set of particles is accepted according to a
id203

if accepted, then the next particle set and next marginal likelihood estimate is set to the
if accepted, then the next particle set and next marginal likelihood estimate is set to the
    and all particles can be used
proposed values; otherwise, the values from the previous iteration s   1 are repeated.
proposed values; otherwise, the values from the previous iteration s   1 are repeated.
in estimating expectations, the full set of particles can be used, with
in estimating expectations, the full set of particles can be used, with

p imh = min 1,
p imh = min 1,

p
e
e
w
s

(136)

(136)

   s
   s

n 

1
1
  ep imh[q(x)] =
  ep imh[q(x)] =
s
s

kxk=1
sxs=1
kxk=1
sxs=1
p imh = min 1,
  z s 1! .

  z ?

   s

w s,kq(xs,k).
w s,kq(xs,k).

(137)

(137)

(146)

n 

n 

   

n 

n 

   

n 

n 

   

  z1

  z2

  z   

formal correctness of the pimh algorithm is shown by considering it as a standard
formal correctness of the pimh algorithm is shown by considering it as a standard
independent mh algorithm on an extended space of both the program traces, and the
independent mh algorithm on an extended space of both the program traces, and the
ancestor indices.

if accepted, then the next particle set and next marginal likelihood estimate is set to the
proposed values; otherwise, the values from the previous iteration s   1 are repeated.

paige and wood    a compilation target for probabilistic programming languages    icml 2014

wood, van de meent, mansinghka    a new approach to probabilistic programming id136    aistats 2014

particle cascade

n = 1

n = 2

asynchronously    
- simulate   
- weight   
- branch

paige, w., doucet, teh; nips 2014

lmh sketch

lmh backend

(defn sample& [a dist k]

(let [;; reuse previous value,
;; or sample from prior
x (or (get-cache a)

(sample dist))]

;; add to log-weight when reused
(when (get-cache a)

(add-log-weight! (observe dist x)))

;; store value and its log prob in trace
(store-in-trace! a x dist)
;; continue with value x
(k x)))

(defn observe& [dist value k]

;; compute and record the log weight
(add-log-weight! (observe dist value))
;; call the continuation with no arguments
(k))

(defn mh-transition [prog args state]

(let [trace (get-trace state)

lmh variants

"lightweight implementations of probabilistic programming languages via transformational compilation." aistats (2011).

d. wingate, a. stuhlmueller, and n. d. goodman.  

webppl 
anglican

 "c3: lightweight incrementalized mcmc for probabilistic programs using continuations and callsite caching."  

d. ritchie, a. stuhlmuller, and n. d. goodman. arxiv:1509.02151 (2015).

"venture: a higher-order probabilistic programming platform with programmable id136."  

v. mansinghka, d. selsam, and y. perov. arxiv:1404.0099 (2014).

id136 backends in anglican

    14+ algorithms 
    average 165 lines of code per! 
    can implement and use without touching core 

code base. 

algorithm type

lines of 
code

citation

description

smc

importance

pcascade

pgibbs

pimh

pgas

lmh

almh

rmh*

palmh

plmh

bamc

siman

is

is

is

pmcmc

pmcmc

pmcmc

mcmc

mcmc

mcmc

mcmc

mcmc

map

map

127 wood et al. aistats, 2014

sequential monte carlo

21

176 paige et al., nips, 2014

121 wood et al. aistats, 2014

68 wood et al. aistats, 2014
179 van de meent et al., aistats, 
177 wingate et al., aistats, 2011

2015

likelihood weighting
particle cascade: anytime asynchronous sequential monte 
carlo
particle gibbs (iterated conditional smc)

particle independent metropolis-hastings

particle gibbs with ancestor sampling

lightweight metropolis-hastings

320 tolpin et al., ecml pkdd, 2015 adaptive scheduling lightweight metropolis-hastings

319 -

66 -

62 -

random-walk metropolis-hastings
parallelised adaptive scheduling lightweight metropolis-
hastings
parallelised lightweight metropolis-hastings

318 tolpin et al., socs, 2015

bayesian ascent monte carlo

193 tolpin et al., socs, 2015

map estimation via simulated annealing

89

wrap up

where we stand

    probabilistic programming concept 

    long well established 

    tool maturity 
    homework 
    prototyping 
    research 
    advanced research 
    small real-world applications 

    put-offs 

    some highly optimized models that you know to scale 
well don   t necessarily scale well in current probabilistic 
programming systems.

91

opportunities

static ef   ciencies

why not a new page

(defquery beta-bernoulli [observation]

a tutorial on probabilistic programming

    automated program transformations that simplify or 
theta (sample dist)
eliminate id136 (moving observes up and out)
like (flip theta)]
(observe like observation)
why not a new page
(predict :theta theta)))

(let [dist (beta 1 1)

(defquery beta-bernoulli [observation]

(let [dist (beta 1 1)

theta (sample dist)
like (flip theta)]

(observe like observation)
(predict :theta theta)))

(defquery beta-bernoulli [observation]

(let [dist (beta

(if observation 2 1)
(if observation 1 2))

theta (sample dist)]
(predict :theta theta)))

(defquery beta-bernoulli [observation]

(let [dist (beta

(if observation 2 1)
(if observation 1 2))

theta (sample dist)]
(predict :theta theta)))

carette and shan.    simplifying probabilistic programs using computer algebra   .    t.r. 719, indiana university (2015) 

yang - keynote lecture, aplas (2015)

(let [u (uniform-continuous -1.0 1.0)]

likelihood (normal mu sigma)]
(predict :x

(reduce (fn [_ obs]

(observe likelihood obs))

id172

(loop [x (sample u)
y (sample u)]

nil
observations)

    program analyses that identify algebraic or algorithmic 

(let [s (+ (* x x) (* y y))]

(predict :mu mu)))

id172 opportunities

(if (< s 1.0)

(+ mu (* sigma

(defquery marsaglia [mu sigma]

(let [u (uniform-continuous -1.0 1.0)]

(predict :x

(loop [x (sample u)
y (sample u)]

p(x|  ,  ) =

1

 p2   

e  (x   )2

2 2

(* x (sqrt (* -2.0 (/ (log s) s))))))

(recur (sample u) (sample u))))))))

(let [s (+ (* x x) (* y y))]

(if (< s 1.0)

(+ mu (* sigma

(recur (sample u) (sample u))))))))

ok, where have we arrived? if you have a language like bugs that restricts you
to    nite-id114 (technically part of the de   nition as far as i know ?) and the
language contains a mix of discrete and continuous variables then a probabilistic pro-
(* x (sqrt (* -2.0 (/ (log s) s))))))
gramming execution strategy for such a program/model is    running    the program like
illustrated in fig. 6. the output of the program will then be a sample-based characteri-
zation of the conditional distribution of the latents given the observes and integrals can
p(x|  ,  ) =
be computed against these samples to answer questions.

e  (x   )2

 p2   

2 2

1

ok, where have we arrived? if you have a language like bugs that restricts you
to    nite-id114 (technically part of the de   nition as far as i know ?) and the
language contains a mix of discrete and continuous variables then a probabilistic pro-
gramming execution strategy for such a program/model is    running    the program like
illustrated in fig. 6. the output of the program will then be a sample-based characteri-

26

data driven proposals

observed

image

inferred

(reconstruction)

inferred model 
re-rendered with 
novel poses

inferred model 
re-rendered with 
novel lighting

kulkarni, kohli, tenenbaum, mansinghka "picture: a probabilistic programming language for scene perception." cvpr (2015). 

perov, le, wood    data-driven sequential monte carlo in probabilistic programming    nips bbli workshop (2015). 

paige, wood    id136 networks for id114    nips aabi workshop (2015).

wrap up

a gentle plea

    bayesians 

    stop writing assembly code! 

    join us 

    try writing models in our languages 
    contribute id136 algorithms 

    neural net people 

    help make id136 better  
    train your neural nets to do something 

interpretable

97

best way to ai
    neural nets end to end (deepmind) 
    generic probabilistic programs used to impose 

evolutionary regularity on that which is computed 
by deep networks.

98

bubble up

models

probabilistic programming language

probabilistic programming system

id136

bubble up

ai

models

probabilistic programming language

probabilistic programming system

id136

anglican resources

    general 

    http://www.robots.ox.ac.uk/~fwood/anglican/ 

    learning probabilistic programming and anglican 

    https://bitbucket.org/probprog/mlss2015 

    writing applications 

    https://bitbucket.org/probprog/anglican-user 

    the core / looking at id136 algorithms 

    https://bitbucket.org/probprog/anglican 

    trying it out (5 min. install) 

    https://bitbucket.org/probprog/anglican-examples

go-to resources

    writing your own probabilistic programming language 

    http://dippl.org 

    model example repository  

    http://forestdb.org/ 

    easiest places to start (browser-based) 

    http://webppl.org/ 

    https://probmods.org/ 

    place to    nd all the literature in one place 

    http://probabilistic-programming.org/wiki/home 

    place to go for the most advanced ideas in prob. prog. 

    http://probcomp.csail.mit.edu/venture/

some final thoughts

adopting the kinds of abstraction boundaries 

suggested by probabilistic programming practice will 

move the field of machine learning forward much 
faster make it easier for id136 and modeling 

experts to work together. 

probabilistic programming is not about making what 
you already do faster or somehow better but instead 

about making it possible to do things that would 

otherwise be nearly impossible to do.

103

thank you

faculty market

graduating

too late

van de meent

paige

tolpin 

perov

le

yang 

    funding : darpa

mansinghka!

tenenbaum 

mansinghka 

postdoc openings

    3 probabilistic programming postdoc openings 

    http://goo.gl/btocer 

next tutorial by

van de meent!

paige!

mansinghka!

pfeffer 

shan

perov!

wingate!

goodman!

ritchie 

gordon

stuhlm  ller!

roy!

russell!

scibior

