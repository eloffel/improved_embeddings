speech and language processing. daniel jurafsky & james h. martin.
rights reserved.

draft of september 23, 2018.

copyright c(cid:13) 2018.

all

chapter

14 the representation of sen-

tence meaning

ishmael: surely all this is not without meaning.
herman melville, moby dick

meaning
representations

meaning
representation
languages

the approach to semantics introduced here, and elaborated on in the next two chap-
ters, is based on the idea that the meaning of linguistic expressions can be cap-
tured in formal structures called meaning representations. correspondingly, the
frameworks that specify the syntax and semantics of these representations are called
meaning representation languages. these meaning representations play a role
analogous to that of the syntactic representations introduced in earlier chapters   
they abstract away from surface forms and facilitate downstream processing.

the need for meaning representations arises when neither the raw linguistic in-
puts nor any of the syntactic structures derivable from them facilitate the kind of se-
mantic processing that is required. we need representations that bridge the gap from
linguistic inputs to the knowledge of the world needed to perform tasks. consider
the following ordinary language tasks that require some form of semantic processing
of natural language:

    deciding what to order at a restaurant by reading a menu
    learning to use a new piece of software by reading the manual
    answering essay questions on an exam
    realizing that you   ve been insulted
    following recipes
grammatical representations aren   t suf   cient to accomplish these tasks. what
is required are representations that link the linguistic elements to the non-linguistic
knowledge of the world needed to successfully accomplish the tasks:

    reading a menu and deciding what to order, giving advice about where to go
to dinner, following a recipe, and generating new recipes all require knowl-
edge about food and its preparation, what people like to eat, and what restau-
rants are like.
    answering and grading essay questions requires background knowledge about
the topic of the question, the desired knowledge level of the students, and how
such questions are normally answered.
    learning to use a piece of software by reading a manual, or giving advice
about how to use the software, requires knowledge about current computers,
the speci   c software in question, similar software applications, and knowl-
edge about users in general.

in this chapter, we assume that linguistic expressions have meaning representa-
tions that are made up of the same kind of stuff that is used to represent this kind

2 chapter 14

    the representation of sentence meaning

   e,y having(e)    haver(e,speaker)    hadt hing(e,y)   car(y)

having:

haver:
hadthing:

speaker

car

computational
semantics

literal meaning

figure 14.1 a list of symbols, two directed graphs, and a record structure: a sampler of
meaning representations for i have a car.

of everyday common-sense knowledge of the world. the process whereby such
representations are created and assigned to linguistic inputs is called semantic anal-
ysis, and the entire enterprise of designing meaning representations and associated
semantic analyzers is referred to as computational semantics.

to make these notions a bit more concrete, consider fig. 14.1, which shows
example meaning representations for the sentence i have a car using four com-
monly used meaning representation languages. the top row illustrates a sentence
in id85, covered in detail in section 14.3; the directed graph and its
corresponding textual form is an example of an abstract meaning representa-
tion (amr) form, to be discussed in chapter 18, and    nally a frame-based or
slot-filler representation, discussed in section 14.5 and again in chapter 17.

while there are non-trivial differences among these approaches, they all share
the notion that a meaning representation consists of structures composed from a
set of symbols, or representational vocabulary. when appropriately arranged, these
symbol structures are taken to correspond to objects, properties of objects, and rela-
tions among objects in some state of affairs being represented or reasoned about. in
this case, all four representations make use of symbols corresponding to the speaker,
a car, and a relation denoting the possession of one by the other.

importantly, these representations can be viewed from at least two distinct per-
spectives in all of these approaches: as representations of the meaning of the par-
ticular linguistic input i have a car, and as representations of the state of affairs in
some world. it is this dual perspective that allows these representations to be used
to link linguistic inputs to the world and to our knowledge of it.

this chapter introduces the basics of what is needed in a meaning representa-
tion. a number of extremely important issues are therefore deferred to later chap-
ters. the focus of this chapter is on representing the literal meaning of individual
sentences. by this, we mean representations that are derived from the core conven-
tional meanings of words and that do not re   ect much of the context in which they
occur. chapter 15 and chapter 16 introduce techniques for generating these formal
meaning representations for linguistic inputs. chapter 17 focuses on the extraction
of entities, relations events and times, chapter 18 and chapter 19 on semantic struc-

h / have-01c / cari / i arg0arg1(h / have-01        arg0: (i / i)        arg1: (c / car))14.1

    computational desiderata for representations

3

ture of verbs and their arguments, while the task of producing representations for
larger stretches of discourse is deferred to chapter 20 and chapter 21.

there are four major parts to this chapter. section 14.1 explores some of the key
computational requirements for what we need in a meaning representation language.
section 14.2 discusses how we can provide some guarantees that these representa-
tions will actually do what we need them to do   provide a correspondence to the
state of affairs being represented. section 14.3 then introduces id85,
which has historically been the primary technique for investigating issues in natural
language semantics. section 14.4 then describes how fol can be used to capture the
semantics of events and states in english.

14.1 computational desiderata for representations

we begin by considering the issue of why meaning representations are needed and
what they should do for us. to focus this discussion, we use the task of giving advice
about restaurants to tourists. assume that we have a computer system that accepts
spoken language inputs from tourists and constructs appropriate responses using a
knowledge base of relevant domain knowledge. a series of examples will serve to
introduce some of the basic requirements that a meaning representation must ful   ll
and some of the complications that inevitably arise in the process of designing such
meaning representations.

14.1.1 veri   ability
consider the following simple question:
(14.1) does maharani serve vegetarian food?
this example illustrates the most basic requirement for a meaning representation:
it must be possible to use the representation to determine the relationship between
the meaning of a sentence and the state of the world as we know it. in other words,
we need to be able to determine the truth of our representations. section 14.2 ex-
plores the standard approach to this topic in some detail. for now, let   s assume that
computational semantic systems require the ability to compare, or match, meaning
representations associated with linguistic expressions with formal representations in
a knowledge base, its store of information about its world.

in this example, assume that the meaning of this question involves the proposi-
tion maharani serves vegetarian food. for now, we will simply gloss this represen-
tation as

serves(maharani,vegetarianfood)

(14.2)

this representation of the input can be matched against our knowledge base of facts
about a set of restaurants. if the system    nds a representation matching this propo-
sition in its knowledge base, it can return an af   rmative answer. otherwise, it must
either say no if its knowledge of local restaurants is complete, or say that it doesn   t
know if there is reason to believe that its knowledge is incomplete.

this notion, known as veri   ability, describes a system   s ability to compare the
state of affairs described by a representation to the state of affairs in some world as
modeled in a knowledge base.

knowledge base

veri   ability

4 chapter 14

    the representation of sentence meaning

vagueness

14.1.2 unambiguous representations
semantics, like all the other domains we have studied, is subject to ambiguity.
speci   cally, individual linguistic expressions can have different meaning represen-
tations assigned to them based on the circumstances in which they occur. consider
the following example from the berp corpus:
(14.3) i wanna eat someplace that   s close to icsi.
given the allowable argument structures for the verb eat, this sentence can either
mean that the speaker wants to eat at some nearby location, or under a godzilla-as-
speaker interpretation, the speaker may want to devour some nearby location. the
answer generated by the system for this request will depend on which interpretation
is chosen as the correct one.

since ambiguities such as this abound in all genres of all languages, some means
of determining that certain interpretations are preferable (or alternatively, not as
preferable) to others is needed. the various linguistic phenomena that give rise
to such ambiguities and the techniques that can be employed to deal with them are
discussed in detail in the next four chapters.

our concern in this chapter, however, is with the status of our meaning repre-
sentations with respect to ambiguity, and not with the means by which we might
arrive at correct interpretations. since we reason about, and act upon, the semantic
content of linguistic inputs, the    nal representation of an input   s meaning should be
free from any ambiguity.1

a concept closely related to ambiguity is vagueness. like ambiguity, vagueness
can make it dif   cult to determine what to do with a particular input on the basis
of its meaning representation. vagueness, however, does not give rise to multiple
representations. consider the following request as an example:
(14.4) i want to eat italian food.
while the use of the phrase italian food may provide enough information for a
restaurant advisor to provide reasonable recommendations, it is nevertheless quite
vague as to what the user really wants to eat. therefore, a vague representation
of the meaning of this phrase may be appropriate for some purposes, while a more
speci   c representation may be needed for other purposes. it will, therefore, be ad-
vantageous for a meaning representation language to support representations that
maintain a certain level of vagueness. note that it is not always easy to distinguish
ambiguity from vagueness. zwicky and sadock (1975) provide a useful set of tests
that can be used as diagnostics.

14.1.3 canonical form
the notion that single sentences can be assigned multiple meanings leads to the
related phenomenon of distinct inputs that should be assigned the same meaning
representation. consider the following alternative ways of expressing (14.1):
(14.5) does maharani have vegetarian dishes?
(14.6) do they have vegetarian food at maharani?
(14.7) are vegetarian dishes served at maharani?
(14.8) does maharani serve vegetarian fare?

1 this does not preclude the use of intermediate semantic representations that maintain some level of
ambiguity on the way to a single unambiguous form. examples of such representations are discussed in
chapter 15.

canonical form

14.1

    computational desiderata for representations

5

given that these alternatives use different words and have widely varying syn-
tactic analyses, it would not be unreasonable to expect them to have quite different
meaning representations. such a situation would, however, have undesirable con-
sequences for how we determine the truth of our representations. if the system   s
knowledge base contains only a single representation of the fact in question, then
the representations underlying all but one of our alternatives will fail to produce
a match. we could, of course, store all possible alternative representations of the
same fact in the knowledge base, but doing so would lead to an enormous number
of problems related to keeping such a knowledge base consistent.

the way out of this dilemma is motivated by the fact that since the answers given
for each of these alternatives should be the same in all situations, we might say that
they all mean the same thing, at least for the purposes of giving restaurant recom-
mendations. in other words, at least in this domain, we can legitimately consider
assigning the same meaning representation to the propositions underlying each of
these requests. taking such an approach would guarantee that our simple scheme
for answering yes-no questions will still work.

the notion that distinct inputs that mean the same thing should have the same
meaning representation is known as the doctrine of canonical form. this approach
greatly simpli   es various reasoning tasks since systems need only deal with a single
meaning representation for a potentially wide range of expressions.

canonical form does complicate the task of semantic analysis. to see this, note
that the alternatives given above use completely different words and syntax to refer
to vegetarian fare and to what restaurants do with it. to assign the same representa-
tion to all of these requests, our system would have to conclude that vegetarian fare,
vegetarian dishes, and vegetarian food refer to the same thing in this context, that
the use here of having and serving are similarly equivalent, and that the different
syntactic parses underlying these requests are all compatible with the same meaning
representation.

being able to assign the same representation to such diverse inputs is a tall or-
der. fortunately, systematic meaning relationships among word senses and among
grammatical constructions can be exploited to make this task tractable. consider the
issue of the meanings of the words food, dish, and fare in these examples. a little
introspection or a glance at a dictionary reveals that these words have a fair number
of distinct uses. however, it also reveals that at least one sense is shared among them
all. if a system has the ability to choose that shared sense, then an identical meaning
representation can be assigned to the phrases containing these words.

just as there are systematic relationships among the meanings of different words,
there are similar relationships related to the role that syntactic analyses play in as-
signing meanings to sentences. speci   cally, alternative syntactic analyses often have
meanings that are, if not identical, at least systematically related to one another.
consider the following pair of examples:
(14.9) maharani serves vegetarian dishes.
(14.10) vegetarian dishes are served by maharani.

despite the different placement of the arguments to serve in these examples, we
can still assign maharani and vegetarian dishes to the same roles in both of these
examples because of our knowledge of the relationship between active and passive
sentence constructions. in particular, we can use knowledge of where grammatical
subjects and direct objects appear in these constructions to assign maharani to the
role of the server, and vegetarian dishes to the role of thing being served in both
of these examples, despite the fact that they appear in different surface locations.

6 chapter 14

    the representation of sentence meaning

the precise role of the grammar in the construction of meaning representations is
covered in chapter 15.

id136

id136 and variables

14.1.4
continuing with the topic of the computational purposes that meaning representa-
tions should serve, we should consider more complex requests such as the following:
(14.11) can vegetarians eat at maharani?
here, it would be a mistake to invoke canonical form to force our system to as-
sign the same representation to this request as for the previous examples. that this
request results in the same answer as the others arises, not because they mean the
same thing, but because there is a common-sense connection between what vegetar-
ians eat and what vegetarian restaurants serve. this is a fact about the world and
not a fact about any particular kind of linguistic regularity. this implies that no
approach based on canonical form and simple matching will give us an appropriate
answer to this request. what is needed is a systematic way to connect the meaning
representation of this request with the facts about the world as they are represented
in a knowledge base.

we use the term id136 to refer generically to a system   s ability to draw valid
conclusions based on the meaning representation of inputs and its store of back-
ground knowledge. it must be possible for the system to draw conclusions about the
truth of propositions that are not explicitly represented in the knowledge base but
that are nevertheless logically derivable from the propositions that are present.

now consider the following somewhat more complex request:

(14.12) i   d like to    nd a restaurant where i can get vegetarian food.
unlike our previous examples, this request does not make reference to any particular
restaurant. the user is expressing a desire for information about an unknown and
unnamed entity that is a restaurant that serves vegetarian food. since this request
does not mention any particular restaurant, the kind of simple matching-based ap-
proach we have been advocating is not going to work. rather, answering this request
requires a more complex kind of matching that involves the use of variables. we can
gloss a representation containing such variables as follows:

serves(x,vegetarianfood)

(14.13)

matching such a proposition succeeds only if the variable x can be replaced by some
known object in the knowledge base in such a way that the entire proposition will
then match. the concept that is substituted for the variable can then be used to ful   ll
the user   s request. of course, this simple example only hints at the issues involved
in the use of such variables. suf   ce it to say that linguistic inputs contain many
instances of all kinds of inde   nite references, and it is, therefore, critical for any
meaning representation language to be able to handle this kind of expression.

14.1.5 expressiveness
finally, to be useful, a meaning representation scheme must be expressive enough
to handle a wide range of subject matter. the ideal situation would be to have a sin-
gle meaning representation language that could adequately represent the meaning
of any sensible natural language utterance. although this is probably too much to
expect from any single representational system, id85, as described in

14.2

    model-theoretic semantics

7

section 14.3, is expressive enough to handle quite a lot of what needs to be repre-
sented.

14.2 model-theoretic semantics

the last two sections focused on various desiderata for meaning representations and
on some of the ways in which natural languages convey meaning. we haven   t said
much formally about what it is about meaning representation languages that allows
them to do all the things we want them to.
in particular, we might like to have
some kind of guarantee that these representations can do the work that we require of
them: bridge the gap from merely formal representations to representations that tell
us something about some state of affairs in the world.

to see how we might provide such a guarantee, let   s start with the basic notions
shared by most meaning representation schemes. what they all have in common
is the ability to represent objects, properties of objects, and relations among ob-
jects. this ability can be formalized by the notion of a model. a model is a formal
construct that stands for the particular state of affairs in the world. expressions in
a meaning representation language can be mapped in a systematic way to the ele-
ments of the model. if the model accurately captures the facts we   re interested in
concerning some state of affairs, then a consistent mapping between the meaning
representation and the model provides the bridge between the meaning representa-
tion and world being considered. as we show, models provide a surprisingly simple
and powerful way to ground the expressions in meaning representation languages.

first, some terminology. the vocabulary of a meaning representation consists of
two parts: the non-logical vocabulary and the logical vocabulary. the non-logical
vocabulary consists of the open-ended set of names for the objects, properties, and
relations that make up the world we   re trying to represent. these appear in various
schemes as predicates, nodes, labels on links, or labels in slots in frames, the log-
ical vocabulary consists of the closed set of symbols, operators, quanti   ers, links,
etc., that provide the formal means for composing expressions in a given meaning
representation language.

we   ll start by requiring that each element of the non-logical vocabulary have a
denotation in the model. by denotation, we simply mean that every element of the
non-logical vocabulary corresponds to a    xed, well-de   ned part of the model. let   s
start with objects, the most basic notion in most representational schemes. the do-
main of a model is simply the set of objects that are part of the application, or state
of affairs, being represented. each distinct concept, category, or individual in an ap-
plication denotes a unique element in the domain. a domain is therefore formally a
set. note that it isn   t mandatory that every element of the domain have a correspond-
ing concept in our meaning representation; it   s perfectly acceptable to have domain
elements that aren   t mentioned or conceived of in the meaning representation. nor
do we require that elements of the domain have a single denoting concept in the
meaning representation; a given element in the domain might have several distinct
representations denoting it, such as mary, wifeof(abe), or motherof(robert).

we can capture properties of objects in a model by denoting those domain ele-
ments that have the property in question; that is, properties denote sets. similarly,
relations among objects denote sets of ordered lists, or tuples, of domain elements
that take part in the corresponding relations. this approach to properties and rela-
tions is thus an extensional one: the denotation of properties like red is the set of

model

non-logical
vocabulary

logical
vocabulary

denotation

domain

extensional

8 chapter 14

    the representation of sentence meaning

things we think are red, the denotation of a relation like married is simply set of
pairs of domain elements that are married. to summarize:

interpretation

    objects denote elements of the domain
    properties denote sets of elements of the domain
    relations denote sets of tuples of elements of the domain
there is one additional element that we need to make this scheme work. we
need a mapping that systematically gets us from our meaning representation to the
corresponding denotations. more formally, we need a function that maps from the
non-logical vocabulary of our meaning representation to the proper denotations in
the model. we   ll call such a mapping an interpretation.

to make these notions more concrete, let   s return to our restaurant advice appli-
cation. assume that our application domain consists of sets of restaurants, patrons,
and various facts about the likes and dislikes of the patrons, and facts about the
restaurants such as their cuisine, typical cost, and noise level.

to begin populating our domain, d, let   s assume that we   re dealing with four pa-
trons designated by the non-logical symbols matthew, franco, katie, and caroline.
these four symbols will denote four unique domain elements. we   ll use the con-
stants a,b,c and, d to stand for these domain elements. note that we   re deliberately
using meaningless, non-mnemonic names for our domain elements to emphasize the
fact that whatever it is that we know about these entities has to come from the formal
properties of the model and not from the names of the symbols. continuing, let   s
assume that our application includes three restaurants, designated as frasca, med,
and rio in our meaning representation, that denote the domain elements e, f , and g.
finally, let   s assume that we   re dealing with the three cuisines italian, mexican, and
eclectic, denoted by h,i, and j in our model.

having populated the domain, let   s move on to the properties and relations we
believe to be true in this particular state of affairs. for our application, we need to
represent various properties of restaurants such as the fact that some are noisy or
expensive. properties like noisy denote the subset of restaurants from our domain
that are known to be noisy. two-place relational notions, such as which restaurants
individual patrons like, denote ordered pairs, or tuples, of the objects from the do-
main. and, since we decided to represent cuisines as objects in our model, we can
capture which restaurants serve which cuisines as a set of tuples. one possible state
of affairs using this scheme is given in fig. 14.2.

given this simple scheme, we can ground our meaning representations by con-
sulting the appropriate denotations in the corresponding model. for example, we can
evaluate a representation claiming that matthew likes the rio, or that the med serves
italian by mapping the objects in the meaning representations to their corresponding
domain elements and mapping any links, predicates, or slots in the meaning repre-
sentation to the appropriate relations in the model. more concretely, we can verify
a representation asserting that matthew likes frasca by    rst using our interpretation
function to map the symbol matthew to its denotation a, frasca to e, and the likes
relation to the appropriate set of tuples. we then check that set of tuples for the
presence of the tuple (cid:104)a,e(cid:105). if, as it is in this case, the tuple is present in the model,
then we can conclude that matthew likes frasca is true; if it isn   t then we can   t.

this is all pretty straightforward   we   re using sets and operations on sets to
ground the expressions in our meaning representations. of course, the more inter-
esting part comes when we consider more complex examples such as the following:
(14.14) katie likes the rio and matthew likes the med.

14.2

    model-theoretic semantics

9

d = {a,b,c,d,e, f ,g,h,i, j}
a,b,c,d
e, f ,g
h,i, j

noisy = {e, f ,g}

likes = {(cid:104)a, f(cid:105),(cid:104)c, f(cid:105),(cid:104)c,g(cid:105),(cid:104)b,e(cid:105),(cid:104)d, f(cid:105),(cid:104)d,g(cid:105)}

serves = {(cid:104) f , j(cid:105),(cid:104)g,i(cid:105),(cid:104)e,h(cid:105)}

domain
matthew, franco, katie and caroline
frasca, med, rio
italian, mexican, eclectic
properties
noisy

frasca, med, and rio are noisy

relations
likes

matthew likes the med
katie likes the med and rio
franco likes frasca
caroline likes the med and rio

serves

med serves eclectic
rio serves mexican
frasca serves italian

figure 14.2 a model of the restaurant world.

(14.15) katie and caroline like the same restaurants.
(14.16) franco likes noisy, expensive restaurants.
(14.17) not everybody likes frasca.

our simple scheme for grounding the meaning of representations is not adequate
for examples such as these. plausible meaning representations for these examples
will not map directly to individual entities, properties, or relations. instead, they
involve complications such as conjunctions, equality, quanti   ed variables, and nega-
tions. to assess whether these statements are consistent with our model, we   ll have
to tear them apart, assess the parts, and then determine the meaning of the whole
from the meaning of the parts according to the details of how the whole is assem-
bled.

consider the    rst example given above. a meaning representation for an exam-
ple like this will include two distinct propositions expressing the individual patron   s
preferences, conjoined with some kind of implicit or explicit conjunction operator.
our model doesn   t have a relation that encodes pairwise preferences for all of the
patrons and restaurants in our model, nor does it need to. we know from our model
that matthew likes the med and separately that katie likes the rio (that is, the tuples
(cid:104)a, f(cid:105) and (cid:104)c,g(cid:105) are members of the set denoted by the likes relation). all we really
need to know is how to deal with the semantics of the conjunction operator. if we
assume the simplest possible semantics for the english word and, the whole state-
ment is true if it is the case that each of the components is true in our model. in this
case, both components are true since the appropriate tuples are present and therefore
the sentence as a whole is true.

what we   ve done with this example is provide a truth-conditional semantics
for the assumed conjunction operator in some meaning representation. that is,
we   ve provided a method for determining the truth of a complex expression from
the meanings of the parts (by consulting a model) and the meaning of an operator by
consulting a truth table. meaning representation languages are truth-conditional to
the extent that they give a formal speci   cation as to how we can determine the mean-

truth-
conditional
semantics

10 chapter 14

    the representation of sentence meaning

formula     atomicformula

| formula connective formula
| quanti   er variable, . . . formula
|    formula
|
(formula)

atomicformula     predicate(term, . . .)
term     function(term, . . .)

| constant
| variable

connective         |     | =   
quanti   er         |    
constant     a | vegetarianfood | maharani      
variable     x | y |       
predicate     serves | near |       
function     locationof | cuisineof |       

figure 14.3 a context-free grammar speci   cation of the syntax of id85 rep-
resentations. adapted from russell and norvig (2002)
.

ing of complex sentences from the meaning of their parts. in particular, we need to
know the semantics of the entire logical vocabulary of the meaning representation
scheme being used.

note that although the details of how this happens depends on details of the
particular meaning representation being used, it should be clear that assessing the
truth conditions of examples like these involves nothing beyond the simple set op-
erations we   ve been discussing. we return to these issues in the next section, where
we discuss them in the context of the semantics of id85.

14.3 id85

id85 (fol) is a    exible, well-understood, and computationally tractable
meaning representation language that satis   es many of the desiderata given in sec-
tion 14.1. it provides a sound computational basis for the veri   ability, id136,
and expressiveness requirements, as well as a sound model-theoretic semantics.

an additional attractive feature of fol is that it makes very few speci   c com-
mitments as to how things ought to be represented. and, the speci   c commitments
it does make are ones that are fairly easy to live with and that are shared by many of
the schemes mentioned earlier; the represented world consists of objects, properties
of objects, and relations among objects.

the remainder of this section introduces the basic syntax and semantics of fol

and then describes the application of fol to the representation of events.

14.3.1 basic elements of id85
let   s explore fol by    rst examining its various atomic elements and then showing
how they can be composed to create larger meaning representations. figure 14.3,
which provides a complete context-free grammar for the particular syntax of fol
that we will use, is our roadmap for this section.

let   s begin by examining the notion of a term, the fol device for representing

term

constants

functions

variable

14.3

    id85

11

objects. as can be seen from fig. 14.3, fol provides three ways to represent these
basic building blocks: constants, functions, and variables. each of these devices can
be thought of as designating an object in the world under consideration.

constants in fol refer to speci   c objects in the world being described. such
constants are conventionally depicted as either single capitalized letters such as a
and b or single capitalized words that are often reminiscent of proper nouns such as
maharani and harry. like programming language constants, fol constants refer
to exactly one object. objects can, however, have multiple constants that refer to
them.

functions in fol correspond to concepts that are often expressed in english as
genitives such as frasca   s location. a fol translation of such an expression might
look like the following.

locationof (frasca)

(14.18)

fol functions are syntactically the same as single argument predicates. it is im-
portant to remember, however, that while they have the appearance of predicates,
they are in fact terms in that they refer to unique objects. functions provide a con-
venient way to refer to speci   c objects without having to associate a named constant
with them. this is particularly convenient in cases in which many named objects,
like restaurants, have a unique concept such as a location associated with them.

variables are variable our    nal fol mechanism for referring to objects. vari-
ables, depicted as single lower-case letters, let us make assertions and draw infer-
ences about objects without having to make reference to any particular named ob-
ject. this ability to make statements about anonymous objects comes in two    avors:
making statements about a particular unknown object and making statements about
all the objects in some arbitrary world of objects. we return to the topic of variables
after we have presented quanti   ers, the elements of fol that make variables useful.
now that we have the means to refer to objects, we can move on to the fol
mechanisms that are used to state relations that hold among objects. predicates are
symbols that refer to, or name, the relations that hold among some    xed number
of objects in a given domain. returning to the example introduced informally in
section 14.1, a reasonable fol representation for maharani serves vegetarian food
might look like the following formula:

serves(maharani,vegetarianfood)

(14.19)

this fol sentence asserts that serves, a two-place predicate, holds between the
objects denoted by the constants maharani and vegetarianfood.

a somewhat different use of predicates is illustrated by the following fairly typ-

ical representation for a sentence like maharani is a restaurant:

restaurant(maharani)

(14.20)

this is an example of a one-place predicate that is used, not to relate multiple objects,
but rather to assert a property of a single object. in this case, it encodes the category
membership of maharani.

with the ability to refer to objects, to assert facts about objects, and to relate
objects to one another, we can create rudimentary composite representations. these
representations correspond to the atomic formula level in fig. 14.3. this ability
to compose complex representations is, however, not limited to the use of single
predicates. larger composite representations can also be put together through the
use of logical connectives. as can be seen from fig. 14.3, logical connectives let

logical
connectives

12 chapter 14

    the representation of sentence meaning

us create larger representations by conjoining logical formulas using one of three
operators. consider, for example, the following berp sentence and one possible
representation for it:
(14.21) i only have    ve dollars and i don   t have a lot of time.

have(speaker,fivedollars)     have(speaker,lotoftime)

(14.22)

quanti   ers

the semantic representation for this example is built up in a straightforward way
from semantics of the individual clauses through the use of the     and    operators.
note that the recursive nature of the grammar in fig. 14.3 allows an in   nite number
of logical formulas to be created through the use of these connectives. thus, as with
syntax, we can use a    nite device to create an in   nite number of representations.

14.3.2 variables and quanti   ers
we now have all the machinery necessary to return to our earlier discussion of vari-
ables. as noted above, variables are used in two ways in fol: to refer to particular
anonymous objects and to refer generically to all objects in a collection. these two
uses are made possible through the use of operators known as quanti   ers. the two
operators that are basic to fol are the existential quanti   er, which is denoted     and
is pronounced as    there exists   , and the universal quanti   er, which is denoted     and
is pronounced as    for all   .

the need for an existentially quanti   ed variable is often signaled by the presence

of an inde   nite noun phrase in english. consider the following example:
(14.23) a restaurant that serves mexican food near icsi.
here, reference is being made to an anonymous object of a speci   ed category with
particular properties. the following would be a reasonable representation of the
meaning of such a phrase:

   xrestaurant(x)     serves(x,mexicanfood)

    near((locationof (x),locationof (icsi))

(14.24)

the existential quanti   er at the head of this sentence instructs us on how to
interpret the variable x in the context of this sentence. informally, it says that for
this sentence to be true there must be at least one object such that if we were to
substitute it for the variable x, the resulting sentence would be true. for example,
if aycaramba is a mexican restaurant near icsi, then substituting aycaramba for x
results in the following logical formula:

restaurant(aycaramba)    serves(aycaramba,mexicanfood)
   near((locationof (aycaramba),locationof (icsi))

(14.25)

based on the semantics of the     operator, this sentence will be true if all of its
three component atomic formulas are true. these in turn will be true if they are
either present in the system   s knowledge base or can be inferred from other facts in
the knowledge base.

the use of the universal quanti   er also has an interpretation based on substi-
tution of known objects for variables. the substitution semantics for the universal
quanti   er takes the expression for all quite literally; the     operator states that for the
logical formula in question to be true, the substitution of any object in the knowledge
base for the universally quanti   ed variable should result in a true formula. this is in

14.3

    id85

13

marked contrast to the     operator, which only insists on a single valid substitution
for the sentence to be true.

consider the following example:

(14.26) all vegetarian restaurants serve vegetarian food.

a reasonable representation for this sentence would be something like the following:

   xvegetarianrestaurant(x) =    serves(x,vegetarianfood)

(14.27)

for this sentence to be true, it must be the case that every substitution of a known
object for x must result in a sentence that is true. we can divide the set of all possible
substitutions into the set of objects consisting of vegetarian restaurants and the set
consisting of everything else. let us    rst consider the case in which the substituted
object actually is a vegetarian restaurant; one such substitution would result in the
following sentence:

vegetarianrestaurant(maharani) =    serves(maharani,vegetarianfood)

if we assume that we know that the consequent clause

serves(maharani,vegetarianfood)

(14.28)

(14.29)

is true, then this sentence as a whole must be true. both the antecedent and the
consequent have the value true and, therefore, according to the    rst two rows of
fig. 14.4 on page 15 the sentence itself can have the value true. this result will be
the same for all possible substitutions of terms representing vegetarian restaurants
for x.

remember, however, that for this sentence to be true, it must be true for all
possible substitutions. what happens when we consider a substitution from the set
of objects that are not vegetarian restaurants? consider the substitution of a non-
vegetarian restaurant such as ay caramba   s for the variable x:
vegetarianrestaurant(aycaramba) =    serves(aycaramba,vegetarianfood)

since the antecedent of the implication is false, we can determine from fig. 14.4

that the sentence is always true, again satisfying the     constraint.

note that it may still be the case that ay caramba serves vegetarian food with-
out actually being a vegetarian restaurant. note also, that despite our choice of
examples, there are no implied categorical restrictions on the objects that can be
substituted for x by this kind of reasoning. in other words, there is no restriction of
x to restaurants or concepts related to them. consider the following substitution:
vegetarianrestaurant(carburetor) =    serves(carburetor,vegetarianfood)

here the antecedent is still false, and hence, the rule remains true under this kind of
irrelevant substitution.
to review, variables in logical formulas must be either existentially (   ) or uni-
versally (   ) quanti   ed. to satisfy an existentially quanti   ed variable, at least one
substitution must result in a true sentence. sentences with universally quanti   ed
variables must be true under all possible substitutions.

14 chapter 14

    the representation of sentence meaning

lambda
notation

   -reduction

14.3.3 lambda notation
the    nal element we need to complete our discussion of fol is called the lambda
notation (church, 1940). this notation provides a way to abstract from fully speci-
   ed fol formula in a way that will be particularly useful for semantic analysis. the
lambda notation extends the syntax of fol to include expressions of the following
form:

   x.p(x)

(14.30)

such expressions consist of the greek symbol    , followed by one or more variables,
followed by a fol formula that makes use of those variables.

the usefulness of these    -expressions is based on the ability to apply them to
logical terms to yield new fol expressions where the formal parameter variables are
bound to the speci   ed terms. this process is known as   -reduction and consists of
a simple textual replacement of the    variables with the speci   ed fol terms, accom-
panied by the subsequent removal of the    . the following expressions illustrate the
application of a    -expression to the constant a, followed by the result of performing
a    -reduction on this expression:

   x.p(x)(a)

p(a)

(14.31)

an important and useful variation of this technique is the use of one    -expression

as the body of another as in the following expression:

   x.   y.near(x,y)

(14.32)

this fairly abstract expression can be glossed as the state of something being
near something else. the following expressions illustrate a single    -application and
subsequent reduction with this kind of embedded    -expression:

   x.   y.near(x,y)(bacaro)

   y.near(bacaro,y)

(14.33)

the important point here is that the resulting expression is still a    -expression;
the    rst reduction bound the variable x and removed the outer    , thus revealing the
inner expression. as might be expected, this resulting    -expression can, in turn,
be applied to another term to arrive at a fully speci   ed logical formula, as in the
following:

   y.near(bacaro,y)(centro)

near(bacaro,centro)

(14.34)

currying

this general technique, called currying2 (sch  onk   nkel, 1924) is a way of con-
verting a predicate with multiple arguments into a sequence of single-argument pred-
icates.

as we show in chapter 15, the    -notation provides a way to incrementally gather
arguments to a predicate when they do not all appear together as daughters of the
predicate in a parse tree.

2 currying is the standard term, although heim and kratzer (1998) present an interesting argument for
the term sch  onk   nkelization over currying, since curry later built on sch  on   nkel   s work.

14.3

    id85

15

14.3.4 the semantics of id85
the various objects, properties, and relations represented in a fol knowledge base
acquire their meanings by virtue of their correspondence to objects, properties, and
relations out in the external world being modeled. we can accomplish this by em-
ploying the model-theoretic approach introduced in section 14.2. recall that this
approach employs simple set-theoretic notions to provide a truth-conditional map-
ping from the expressions in a meaning representation to the state of affairs being
modeled. we can apply this approach to fol by going through all the elements in
fig. 14.3 on page 10 and specifying how each should be accounted for.

we can start by asserting that the objects in our world, fol terms, denote ele-
ments in a domain, and asserting that atomic formulas are captured either as sets of
domain elements for properties, or as sets of tuples of elements for relations. as an
example, consider the following:
(14.35) centro is near bacaro.

capturing the meaning of this example in fol involves identifying the terms
and predicates that correspond to the various grammatical elements in the sentence
and creating logical formulas that capture the relations implied by the words and
syntax of the sentence. for this example, such an effort might yield something like
the following:

near(centro,bacaro)

(14.36)
the meaning of this logical formula is based on whether the domain elements de-
noted by the terms centro and bacaro are contained among the tuples denoted by
the relation denoted by the predicate near in the current model.

the interpretations of formulas involving logical connectives is based on the
meaning of the components in the formulas combined with the meanings of the
connectives they contain. figure 14.4 gives interpretations for each of the logical
operators shown in fig. 14.3.

p

q

false
false
true
true

false
true
false
true

   p

true
true
false
false

p     q

p     q

false
false
false
true

false
true
true
true

p =   
q
true
true
false
true

figure 14.4 truth table giving the semantics of the various logical connectives.

the semantics of the     (and) and    (not) operators are fairly straightforward,
and are correlated with at least some of the senses of the corresponding english
terms. however, it is worth pointing out that the     (or) operator is not disjunctive
in the same way that the corresponding english word is, and that the =    (im-
plies) operator is only loosely based on any common-sense notions of implication
or causation.

the    nal bit we need to address involves variables and quanti   ers. recall that
there are no variables in our set-based models, only elements of the domain and
relations that hold among them. we can provide a model-based account for formulas
with variables by employing the notion of a substitution introduced earlier on page
12. formulas involving     are true if a substitution of terms for variables results in
a formula that is true in the model. formulas involving     must be true under all
possible substitutions.

16 chapter 14

    the representation of sentence meaning

id136

14.3.5
one of the most important desiderata given in section 14.1 for a meaning rep-
resentation language is that it should support id136, or deduction. that is, the
ability to add valid new propositions to a knowledge base or to determine the truth of
propositions not explicitly contained within a knowledge base. this section brie   y
discusses modus ponens, the most widely implemented id136 method provided
by fol. applications of modus ponens to id136 in discourse is discussed in
chapter 21.

modus ponens is a familiar form of id136 that corresponds to what is in-
formally known as if-then reasoning. we can abstractly de   ne modus ponens as
follows, where    and    should be taken as fol formulas:

modus ponens

  
   =      

  

(14.37)

a schema like this indicates that the formula below the line can be inferred from
the formulas above the line by some form of id136. modus ponens simply states
that if the left-hand side of an implication rule is true, then the right-hand side of the
rule can be inferred. in the following discussions, we will refer to the left-hand side
of an implication as the antecedent and the right-hand side as the consequent.

for a typical use of modus ponens, consider the following example, which uses

a rule from the last section:

forward
chaining

backward
chaining

vegetarianrestaurant(leaf )
   xvegetarianrestaurant(x) =    serves(x,vegetarianfood)

serves(leaf ,vegetarianfood)

(14.38)

here, the formula vegetarianrestaurant(leaf ) matches the antecedent of the rule,
thus allowing us to use modus ponens to conclude serves(leaf ,vegetarianfood).
modus ponens can be put to practical use in one of two ways: forward chaining
and backward chaining. in forward chaining systems, modus ponens is used in
precisely the manner just described. as individual facts are added to the knowledge
base, modus ponens is used to    re all applicable implication rules. in this kind of
arrangement, as soon as a new fact is added to the knowledge base, all applicable
implication rules are found and applied, each resulting in the addition of new facts to
the knowledge base. these new propositions in turn can be used to    re implication
rules applicable to them. the process continues until no further facts can be deduced.
the forward chaining approach has the advantage that facts will be present in
the knowledge base when needed, because, in a sense all id136 is performed in
advance. this can substantially reduce the time needed to answer subsequent queries
since they should all amount to simple lookups. the disadvantage of this approach
is that facts that will never be needed may be inferred and stored.

in backward chaining, modus ponens is run in reverse to prove speci   c propo-
sitions called queries. the    rst step is to see if the query formula is true by determin-
ing if it is present in the knowledge base. if it is not, then the next step is to search
for applicable implication rules present in the knowledge base. an applicable rule is
one whereby the consequent of the rule matches the query formula. if there are any
such rules, then the query can be proved if the antecedent of any one them can be
shown to be true. not surprisingly, this can be performed recursively by backward

14.4

    event and state representations

17

chaining on the antecedent as a new query. the prolog programming language is a
backward chaining system that implements this strategy.

to see how this works, let   s assume that we have been asked to verify the truth of
the proposition serves(leaf ,vegetarianfood), assuming the facts given above the
line in (14.38). since this proposition is not present in the knowledge base, a search
for an applicable rule is initiated resulting in the rule given above. after substituting
the constant leaf for the variable x, our next task is to prove the antecedent of the
rule, vegetarianrestaurant(leaf ), which, of course, is one of the facts we are given.
note that it is critical to distinguish between reasoning by backward chaining
from queries to known facts and reasoning backwards from known consequents to
unknown antecedents. to be speci   c, by reasoning backwards we mean that if the
consequent of a rule is known to be true, we assume that the antecedent will be as
well. for example, let   s assume that we know that serves(leaf ,vegetarianfood) is
true. since this fact matches the consequent of our rule, we might reason backwards
to the conclusion that vegetarianrestaurant(leaf ).

while backward chaining is a sound method of reasoning, reasoning backwards
is an invalid, though frequently useful, form of plausible reasoning. plausible rea-
soning from consequents to antecedents is known as abduction, and as we show in
chapter 21, is often useful in accounting for many of the id136s people make
while analyzing extended discourses.

while forward and backward reasoning are sound, neither is complete. this
means that there are valid id136s that cannot be found by systems using these
methods alone. fortunately, there is an alternative id136 technique called reso-
lution that is sound and complete. unfortunately, id136 systems based on res-
olution are far more computationally expensive than forward or backward chaining
systems. in practice, therefore, most systems use some form of chaining and place
a burden on knowledge-base developers to encode the knowledge in a fashion that
permits the necessary id136s to be drawn.

abduction

complete

resolution

14.4 event and state representations

much of the semantics that we wish to capture consists of representations of states
and events. states are conditions, or properties, that remain unchanged over an
extended period of time, and events denote changes in some state of affairs. the
representation of both states and events may involve a host of participants, props,
times and locations.

the representations for events and states that we have used thus far have con-
sisted of single predicates with as many arguments as are needed to incorporate all
the roles associated with a given example. for example, the representation for leaf
serves vegetarian fare consists of a single predicate with arguments for the entity
doing the serving and the thing served.

serves(leaf ,vegetarianfare)

(14.39)

this approach assumes that the predicate used to represent an event verb has the
same number of arguments as are present in the verb   s syntactic subcategorization
frame. unfortunately, this is clearly not always the case. consider the following
examples of the verb eat:
(14.40) i ate.

18 chapter 14

    the representation of sentence meaning

arity

event variable

neo-
davidsonian

(14.41) i ate a turkey sandwich.
(14.42) i ate a turkey sandwich at my desk.
(14.43) i ate at my desk.
(14.44) i ate lunch.
(14.45) i ate a turkey sandwich for lunch.
(14.46) i ate a turkey sandwich for lunch at my desk.

clearly, choosing the correct number of arguments for the predicate represent-
ing the meaning of eat is a tricky problem. these examples introduce    ve distinct
arguments, or roles, in an array of different syntactic forms, locations, and combina-
tions. unfortunately, predicates in fol have    xed arity     they take a    xed number
of arguments.

to address this problem, we introduce the notion of an event variable to allow
us to make assertions about particular events. to do this, we can refactor our event
predicates to have an existentially quanti   ed variable as their    rst, and only, argu-
ment. using this event variable, we can introduce additional predicates to represent
the other information we have about the event. these predicates take an event vari-
able as their    rst argument and related fol terms as their second argument. the
following formula illustrates this scheme with the meaning representation of 14.41
from our earlier discussion.

   e eating(e)     eater(e,speaker)    eaten(e,turkeysandwich)

here, the quanti   ed variable e stands for the eating event and is used to bind the
event predicate with the core information provided via the named roles eater and
eaten. to handle the more complex examples, we simply add additional relations
to capture the provided information, as in the following for 14.46.

   e eating(e)     eater(e,speaker)    eaten(e,turkeysandwich)

    meal(e,lunch)    location(e,desk)

(14.47)

event representations of this sort are referred to as neo-davidsonian event repre-
sentations (davidson, 1967; parsons, 1990) after the philosopher donald davidson
who introduced the notion of an event variable (davidson, 1967). to summarize, in
the neo-davidsonian approach to event representations:

argument.

    events are captured with predicates that take a single event variable as an
    there is no need to specify a    xed number of arguments for a given fol
predicate; rather, as many roles and    llers can be glued on as are provided in
the input.

    no more roles are postulated than are mentioned in the input.
    the logical connections among closely related inputs that share the same pred-

icate are satis   ed without the need for additional id136.

this approach still leaves us with the problem of determining the set of predi-
cates needed to represent roles associated with speci   c events like eater and eaten,
as well as more general concepts like location and time. we   ll return to this prob-
lem in more detail in chapter 18.

14.4.1 representing time
in our discussion of events, we did not seriously address the issue of capturing the
time when the represented events are supposed to have occurred. the representation

temporal logic

tense logic

14.4

    event and state representations

19

of such information in a useful form is the domain of temporal logic. this dis-
cussion introduces the most basic concerns of temporal logic and brie   y discusses
the means by which human languages convey temporal information, which, among
other things, includes tense logic, the ways that verb tenses convey temporal infor-
mation. a more detailed discussion of robust approaches to the representation and
analysis of temporal expressions is presented in chapter 17.

the most straightforward theory of time holds that it    ows inexorably forward
and that events are associated with either points or intervals in time, as on a timeline.
given these notions, we can order distinct events by situating them on the timeline.
more speci   cally, we can say that one event precedes another if the    ow of time
leads from the    rst event to the second. accompanying these notions in most theo-
ries is the idea of the current moment in time. combining this notion with the idea
of a temporal ordering relationship yields the familiar notions of past, present, and
future.

not surprisingly, a large number of schemes can represent this kind of temporal
information. the one presented here is a fairly simple one that stays within the fol
framework of rei   ed events that we have been pursuing. consider the following
examples:
(14.48) i arrived in new york.
(14.49) i am arriving in new york.
(14.50) i will arrive in new york.
these sentences all refer to the same kind of event and differ solely in the tense of
the verb. in our current scheme for representing events, all three would share the
following kind of representation, which lacks any temporal information:
   earriving(e)    arriver(e,speaker)    destination(e,newyork)

(14.51)

the temporal information provided by the tense of the verbs can be exploited
by predicating additional information about the event variable e. speci   cally, we
can add temporal variables representing the interval corresponding to the event, the
end point of the event, and temporal predicates relating this end point to the current
time as indicated by the tense of the verb. such an approach yields the following
representations for our arriving examples:

   e,i,n arriving(e)     arriver(e,speaker)    destination(e,newyork)

    intervalof (e,i)    endpoint(i,n)    precedes(n,now)

   e,i,n arriving(e)     arriver(e,speaker)    destination(e,newyork)

    intervalof (e,i)    memberof (i,now)

   e,i,n arriving(e)     arriver(e,speaker)    destination(e,newyork)

    intervalof (e,i)    endpoint(i,n)    precedes(now,n)

this representation introduces a variable to stand for the interval of time as-
sociated with the event and a variable that stands for the end of that interval. the
two-place predicate precedes represents the notion that the    rst time-point argument
precedes the second in time; the constant now refers to the current time. for past
events, the end point of the interval must precede the current time. similarly, for fu-
ture events the current time must precede the end of the event. for events happening
in the present, the current time is contained within the event interval.

unfortunately, the relation between simple verb tenses and points in time is by

no means straightforward. consider the following examples:

20 chapter 14

    the representation of sentence meaning

reference point

(14.52) ok, we    y from san francisco to boston at 10.
(14.53) flight 1390 will be at the gate an hour now.
in the    rst example, the present tense of the verb    y is used to refer to a future event,
while in the second the future tense is used to refer to a past event.

more complications occur when we consider some of the other verb tenses. con-

sider the following examples:
(14.54) flight 1902 arrived late.
(14.55) flight 1902 had arrived late.
although both refer to events in the past, representing them in the same way seems
wrong. the second example seems to have another unnamed event lurking in the
background (e.g., flight 1902 had already arrived late when something else hap-
pened). to account for this phenomena, reichenbach (1947) introduced the notion
of a reference point. in our simple temporal scheme, the current moment in time
is equated with the time of the utterance and is used as a reference point for when
the event occurred (before, at, or after). in reichenbach   s approach, the notion of
the reference point is separated from the utterance time and the event time. the
following examples illustrate the basics of this approach:
(14.56) when mary   s    ight departed, i ate lunch.
(14.57) when mary   s    ight departed, i had eaten lunch.

in both of these examples, the eating event has happened in the past, that is, prior
to the utterance. however, the verb tense in the    rst example indicates that the eating
event began when the    ight departed, while the second example indicates that the
eating was accomplished prior to the    ight   s departure. therefore, in reichenbach   s
terms the departure event speci   es the reference point. these facts can be accom-
modated by additional constraints relating the eating and departure events. in the
   rst example, the reference point precedes the eating event, and in the second exam-
ple, the eating precedes the reference point. figure 14.5 illustrates reichenbach   s
approach with the primary english tenses. exercise 14.6 asks you to represent these
examples in fol.

figure 14.5 reichenbach   s approach applied to various english tenses. in these diagrams,
time    ows from left to right, an e denotes the time of the event, an r denotes the reference
time, and an u denotes the time of the utterance.

past perfectsimple pastpresent perfectsimple futurefuture perfectpresenteeeerrur,eur,uu,r,eu,ru14.4

    event and state representations

21

this discussion has focused narrowly on the broad notions of past, present, and
future and how they are signaled by various english verb tenses. of course, lan-
guages also have many other more direct and more speci   c ways to convey temporal
information, including the use of a wide variety of temporal expressions, as in the
following atis examples:
(14.58) i   d like to go at 6:45, in the morning.
(14.59) somewhere around noon, please.
as we show in chapter 17, grammars for such temporal expressions are of consid-
erable practical importance to information extraction and question-answering appli-
cations.

finally, we should note that a systematic conceptual organization is re   ected in
examples like these. in particular, temporal expressions in english are frequently ex-
pressed in spatial terms, as is illustrated by the various uses of at, in, somewhere, and
near in these examples (lakoff and johnson, 1980; jackendoff, 1983). metaphori-
cal organizations such as these, in which one domain is systematically expressed in
terms of another, are very common in languages of the world.

14.4.2 aspect
in the last section, we discussed ways to represent the time of an event with respect
to the time of an utterance describing it. in this section, we address the notion of
aspect, which concerns a cluster of related topics, including whether an event has
ended or is ongoing, whether it is conceptualized as happening at a point in time or
over some interval, and whether any particular state in the world comes about be-
cause of it. based on these and related notions, event expressions have traditionally
been divided into four general classes illustrated in the following examples:
stative: i know my departure gate.
activity: john is    ying.
accomplishment: sally booked her    ight.
achievement: she found her gate.

although the earliest versions of this classi   cation were discussed by aristotle,

the one presented here is due to vendler (1967).

stative expressions represent the notion of an event participant having a partic-
ular property, or being in a state, at a given point in time. as such, these expressions
can be thought of as capturing an aspect of a world at a single point in time. consider
the following atis examples.
(14.60) i like flight 840 arriving at 10:06.
(14.61) i need the cheapest fare.
(14.62) i want to go    rst class.
in examples like these, the event participant denoted by the subject can be seen as
experiencing something at a speci   c point in time. whether or not the experiencer
was in the same state earlier or will be in the future is left unspeci   ed.

activity expressions describe events undertaken by a participant and have no
particular end point. unlike statives, activities are seen as occurring over some span
of time and are therefore not associated with single points in time. consider the
following examples:
(14.63) she drove a mazda.

aspect

stative
expressions

activity
expressions

22 chapter 14

    the representation of sentence meaning

(14.64) i live in brooklyn.
these examples both specify that the subject is engaged in, or has engaged in, the
activity speci   ed by the verb for some period of time.

the    nal aspectual class, achievement expressions, is similar to accomplish-

ments in that these expressions result in a state. consider the following:
(14.65) she found her gate.
(14.66) i reached new york.
unlike accomplishments, achievement events are thought of as happening in an in-
stant and are not equated with any particular activity leading up to the state. to be
more speci   c, the events in these examples may have been preceded by extended
searching or traveling events, but the events corresponding directly to found and
reach are conceived of as points, not intervals.

note that since both accomplishments and achievements are events that result
in a state, they are sometimes characterized as subtypes of a single aspectual class.
members of this combined class are known as telic eventualities.

achievement
expressions

telic
eventualities

14.5 description logics

as noted at the beginning of this chapter, a fair number of representational schemes
have been invented to capture the meaning of linguistic utterances. it is now widely
accepted that meanings represented in these various approaches can, in principle, be
translated into equivalent statements in fol with relative ease. the dif   culty is that
in many of these approaches the semantics of a statement are de   ned procedurally.
that is, the meaning arises from whatever the system that interprets it does with it.
description logics are an effort to better specify the semantics of these earlier
structured network representations and to provide a conceptual framework that is
especially well suited to certain kinds of domain modeling. formally, the term de-
scription logics refers to a family of logical approaches that correspond to varying
subsets of fol. the restrictions placed on the expressiveness of description logics
serve to guarantee the tractability of various critical kinds of id136. our focus
here, however, will be on the modeling aspects of dls rather than on computational
complexity issues.

when using description logics to model an application domain, the emphasis
is on the representation of knowledge about categories, individuals that belong to
those categories, and the relationships that can hold among these individuals. the
set of categories, or concepts, that make up a particular application domain is called
its terminology. the portion of a knowledge base that contains the terminology is
traditionally called the tbox; this is in contrast to the abox that contains facts about
individuals. the terminology is typically arranged into a hierarchical organization
called an ontology that captures the subset/superset relations among the categories.
returning to our earlier culinary domain, we represented domain concepts like
using unary predicates such as restaurant(x); the dl equivalent simply omits the
variable, so the restaurant category is simply written as restaurant.3 to capture
the fact that a particular domain element, such as frasca, is a restaurant, we assert
restaurant(frasca) in much the same way we would in fol. the semantics of

3 dl statements are conventionally typeset with a sans serif font. we   ll follow that convention here,
reverting to our standard mathematical notation when giving fol equivalents of dl statements.

terminology
tbox
abox
ontology

subsumption

14.5

    description logics

23

these categories are speci   ed in precisely the same way that was introduced earlier in
section 14.2: a category like restaurant simply denotes the set of domain elements
that are restaurants.

once we   ve speci   ed the categories of interest in a particular domain, the next
step is to arrange them into a hierarchical structure. there are two ways to cap-
ture the hierarchical relationships present in a terminology: we can directly assert
relations between categories that are related hierarchically, or we can provide com-
plete de   nitions for our concepts and then rely on id136 to provide hierarchical
relationships. the choice between these methods hinges on the use to which the re-
sulting categories will be put and the feasibility of formulating precise de   nitions for
many naturally occurring categories. we   ll discuss the    rst option here and return to
the notion of de   nitions later in this section.

to directly specify a hierarchical structure, we can assert subsumption relations
between the appropriate concepts in a terminology. the subsumption relation is
conventionally written as c (cid:118) d and is read as c is subsumed by d; that is, all
members of the category c are also members of the category d. not surprisingly, the
formal semantics of this relation are provided by a simple set relation; any domain
element that is in the set denoted by c is also in the set denoted by d.

adding the following statements to the tbox asserts that all restaurants are com-
mercial establishments and, moreover, that there are various subtypes of restaurants.

restaurant (cid:118) commercialestablishment

italianrestaurant (cid:118) restaurant
chineserestaurant (cid:118) restaurant
mexicanrestaurant (cid:118) restaurant

(14.67)
(14.68)
(14.69)
(14.70)

ontologies such as this are conventionally illustrated with diagrams such as the one
shown in fig. 14.6, where subsumption relations are denoted by links between the
nodes representing the categories.

figure 14.6 a graphical network representation of a set of subsumption relations in the
restaurant domain.

note, that it was precisely the vague nature of semantic network diagrams like
this that motivated the development of description logics. for example, from this

restaurantchineserestaurant mexicanrestaurantitalianrestaurantcommercialestablishment24 chapter 14

    the representation of sentence meaning

diagram we can   t tell whether the given set of categories is exhaustive or disjoint.
that is, we can   t tell if these are all the kinds of restaurants that we   ll be dealing with
in our domain or whether there might be others. we also can   t tell if an individual
restaurant must fall into only one of these categories, or if it is possible, for example,
for a restaurant to be both italian and chinese. the dl statements given above are
more transparent in their meaning; they simply assert a set of subsumption relations
between categories and make no claims about coverage or mutual exclusion.

if an application requires coverage and disjointness information, then such in-
formation must be made explicitly. the simplest ways to capture this kind of in-
formation is through the use of negation and disjunction operators. for example,
the following assertion would tell us that chinese restaurants can   t also be italian
restaurants.

chineserestaurant (cid:118) not italianrestaurant

(14.71)

specifying that a set of subconcepts covers a category can be achieved with disjunc-
tion, as in the following:
restaurant (cid:118)

(14.72)

(or italianrestaurant chineserestaurant mexicanrestaurant)

having a hierarchy such as the one given in fig. 14.6 tells us next to nothing
about the concepts in it. we certainly don   t know anything about what makes a
restaurant a restaurant, much less italian, chinese, or expensive. what is needed are
additional assertions about what it means to be a member of any of these categories.
in description logics such statements come in the form of relations between the
concepts being described and other concepts in the domain.
in keeping with its
origins in structured network representations, relations in description logics are
typically binary and are often referred to as roles, or role-relations.

to see how such relations work, let   s consider some of the facts about restaurants
discussed earlier in the chapter. we   ll use the hascuisine relation to capture infor-
mation as to what kinds of food restaurants serve and the haspricerange relation
to capture how pricey particular restaurants tend to be. we can use these relations
to say something more concrete about our various classes of restaurants. let   s start
with our italianrestaurant concept. as a    rst approximation, we might say some-
thing uncontroversial like italian restaurants serve italian cuisine. to capture these
notions, let   s    rst add some new concepts to our terminology to represent various
kinds of cuisine.

mexicancuisine (cid:118) cuisine
italiancuisine (cid:118) cuisine
chinesecuisine (cid:118) cuisine
vegetariancuisine (cid:118) cuisine

expensiverestaurant (cid:118) restaurant
moderaterestaurant (cid:118) restaurant
cheaprestaurant (cid:118) restaurant

next, let   s revise our earlier version of italianrestaurant to capture cuisine

information.

italianrestaurant (cid:118) restaurant(cid:117)   hascuisine.italiancuisine

(14.73)

the correct way to read this expression is that individuals in the category italian-
restaurant are subsumed both by the category restaurant and by an unnamed

14.5

    description logics

25

class de   ned by the existential clause   the set of entities that serve italian cuisine.
an equivalent statement in fol would be

   xitalianrestaurant(x)     restaurant(x)

   (   yserves(x,y)    italiancuisine(y))

(14.74)

this fol translation should make it clear what the dl assertions given above do
and do not entail. in particular, they don   t say that domain entities classi   ed as ital-
ian restaurants can   t engage in other relations like being expensive or even serving
chinese cuisine. and critically, they don   t say much about domain entities that we
know do serve italian cuisine. in fact, inspection of the fol translation makes it
clear that we cannot infer that any new entities belong to this category based on their
characteristics. the best we can do is infer new facts about restaurants that we   re
explicitly told are members of this category.

of course, inferring the category membership of individuals given certain char-
acteristics is a common and critical reasoning task that we need to support. this
brings us back to the alternative approach to creating hierarchical structures in a
terminology: actually providing a de   nition of the categories we   re creating in the
form of necessary and suf   cient conditions for category membership. in this case,
we might explicitly provide a de   nition for italianrestaurant as being those restau-
rants that serve italian cuisine, and moderaterestaurant as being those whose
price range is moderate.

italianrestaurant     restaurant(cid:117)   hascuisine.italiancuisine

(14.75)
moderaterestaurant     restaurant(cid:117) haspricerange.moderateprices (14.76)

while our earlier statements provided necessary conditions for membership in these
categories, these statements provide both necessary and suf   cient conditions.

finally, let   s now consider the super   cially similar case of vegetarian restaurants.
clearly, vegetarian restaurants are those that serve vegetarian cuisine. but they don   t
merely serve vegetarian fare, that   s all they serve. we can accommodate this kind of
constraint by adding an additional restriction in the form of a universal quanti   er to
our earlier description of vegetarianrestaurants, as follows:

vegetarianrestaurant     restaurant

(cid:117)   hascuisine.vegetariancuisine
(cid:117)   hascuisine.vegetariancuisine

(14.77)

id136
paralleling the focus of description logics on categories, relations, and individuals
is a processing focus on a restricted subset of logical id136. rather than employ-
ing the full range of reasoning permitted by fol, dl reasoning systems emphasize
the closely coupled problems of subsumption and instance checking.

subsumption, as a form of id136, is the task of determining, based on the
facts asserted in a terminology, whether a superset/subset relationship exists between
two concepts. correspondingly, instance checking asks if an individual can be a
member of a particular category given the facts we know about both the individual
and the terminology. the id136 mechanisms underlying subsumption and in-
stance checking go beyond simply checking for explicitly stated subsumption rela-
tions in a terminology. they must explicitly reason using the relational information

subsumption

instance
checking

26 chapter 14

    the representation of sentence meaning

figure 14.7 a graphical network representation of the complete set of subsumption rela-
tions in the restaurant domain given the current set of assertions in the tbox.

asserted about the terminology to infer appropriate subsumption and membership
relations.

returning to our restaurant domain, let   s add a new kind of restaurant using the

following statement:

ilfornaio (cid:118) moderaterestaurant(cid:117)   hascuisine.italiancuisine

(14.78)

given this assertion, we might ask whether the ilfornaio chain of restaurants might
be classi   ed as an italian restaurant or a vegetarian restaurant. more precisely, we
can pose the following questions to our reasoning system:

ilfornaio (cid:118) italianrestaurant
ilfornaio (cid:118) vegetarianrestaurant

(14.79)
(14.80)

the answer to the    rst question is positive since ilfornaio meets the criteria we
speci   ed for the category italianrestaurant: it   s a restaurant since we explicitly
classi   ed it as a moderaterestaurant, which is a subtype of restaurant, and it
meets the has.cuisine class restriction since we   ve asserted that directly.

the answer to the second question is negative. recall, that our criteria for veg-
etarian restaurants contains two requirements: it has to serve vegetarian fare, and
that   s all it can serve. our current de   nition for ilfornaio fails on both counts since
we have not asserted any relations that state that ilfornaio serves vegetarian fare,
and the relation we have asserted, hascuisine.italiancuisine, contradicts the sec-
ond criteria.

a related reasoning task, based on the basic subsumption id136, is to derive
the implied hierarchy for a terminology given facts about the categories in the ter-
minology. this task roughly corresponds to a repeated application of the subsump-
tion operator to pairs of concepts in the terminology. given our current collection of
statements, the expanded hierarchy shown in fig. 14.7 can be inferred. you should
convince yourself that this diagram contains all and only the subsumption links that
should be present given our current knowledge.

instance checking is the task of determining whether a particular individual can
be classi   ed as a member of a particular category. this process takes what is known

implied
hierarchy

restaurantchineserestaurant mexicanrestaurantitalianrestaurantexpensiverestaurantcheaprestaurantmoderaterestaurantilfornaiovegetarianrestaurant14.6

    summary

27

about a given individual, in the form of relations and explicit categorical statements,
and then compares that information with what is known about the current terminol-
ogy. it then returns a list of the most speci   c categories to which the individual can
belong.

as an example of a categorization problem, consider an establishment that we   re

told is a restaurant and serves italian cuisine.

restaurant(gondolier)
hascuisine(gondolier, italiancuisine)

here, we   re being told that the entity denoted by the term gondolier is a restau-
rant and serves italian food. given this new information and the contents of our
current tbox, we might reasonably like to ask if this is an italian restaurant, if it is
a vegetarian restaurant, or if it has moderate prices.

assuming the de   nitional statements given earlier, we can indeed categorize
the gondolier as an italian restaurant. that is, the information we   ve been given
about it meets the necessary and suf   cient conditions required for membership in
this category. and as with the ilfornaio category, this individual fails to match the
stated criteria for the vegetarianrestaurant. finally, the gondolier might also
turn out to be a moderately priced restaurant, but we can   t tell at this point since
we don   t know anything about its prices. what this means is that given our current
knowledge the answer to the query moderaterestaurant(gondolier) would be false
since it lacks the required haspricerange relation.

the implementation of subsumption, instance checking, as well as other kinds of
id136s needed for practical applications, varies according to the expressivity of
the description logic being used. however, for a description logic of even modest
power, the primary implementation techniques are based on satis   ability methods
that in turn rely on the underlying model-based semantics introduced earlier in this
chapter.

owl and the semantic web
the highest-pro   le role for description logics, to date, has been as a part of the
development of the semantic web. the semantic web is an ongoing effort to pro-
vide a way to formally specify the semantics of the contents of the web (fensel
et al., 2003). a key component of this effort involves the creation and deployment
of ontologies for various application areas of interest. the meaning representation
language used to represent this knowledge is the web ontology language (owl)
(mcguiness and van harmelen, 2004). owl embodies a description logic that
corresponds roughly to the one we   ve been describing here.

web ontology
language

14.6 summary

this chapter has introduced the representational approach to meaning. the follow-
ing are some of the highlights of this chapter:

    a major approach to meaning in computational linguistics involves the cre-
ation of formal meaning representations that capture the meaning-related
content of linguistic inputs. these representations are intended to bridge the
gap from language to common-sense knowledge of the world.

28 chapter 14

    the representation of sentence meaning

    the frameworks that specify the syntax and semantics of these representa-
tions are called meaning representation languages. a wide variety of such
languages are used in natural language processing and arti   cial intelligence.
    such representations need to be able to support the practical computational
requirements of semantic processing. among these are the need to determine
the truth of propositions, to support unambiguous representations, to rep-
resent variables, to support id136, and to be suf   ciently expressive.
    human languages have a wide variety of features that are used to convey

meaning. among the most important of these is the ability to convey a predicate-
argument structure.

can be captured in fol.

    id85 is a well-understood, computationally tractable meaning
representation language that offers much of what is needed in a meaning rep-
resentation language.
    important elements of semantic representation including states and events
    semantic networks and frames can be captured within the fol framework.
    modern description logics consist of useful and computationally tractable
subsets of full id85. the most prominent use of a description
logic is the web ontology language (owl), used in the speci   cation of the
semantic web.

bibliographical and historical notes

the earliest computational use of declarative meaning representations in natural lan-
guage processing was in the context of question-answering systems (green et al.,
1961; raphael, 1968; lindsey, 1963). these systems employed ad hoc representa-
tions for the facts needed to answer questions. questions were then translated into
a form that could be matched against facts in the knowledge base. simmons (1965)
provides an overview of these early efforts.

woods (1967) investigated the use of fol-like representations in question an-
swering as a replacement for the ad hoc representations in use at the time. woods
(1973) further developed and extended these ideas in the landmark lunar system.
interestingly, the representations used in lunar had both truth-conditional and pro-
cedural semantics. winograd (1972) employed a similar representation based on the
micro-planner language in his shrdlu system.

during this same period, researchers interested in the cognitive modeling of lan-
guage and memory had been working with various forms of associative network
representations. masterman (1957) was the    rst to make computational use of a
semantic network-like id99, although semantic networks are
generally credited to quillian (1968). a considerable amount of work in the se-
mantic network framework was carried out during this era (norman and rumelhart,
1975; schank, 1972; wilks, 1975b, 1975a; kintsch, 1974). it was during this pe-
riod that a number of researchers began to incorporate fillmore   s notion of case roles
(fillmore, 1968) into their representations. simmons (1973) was the earliest adopter
of case roles as part of representations for natural language processing.

detailed analyses by woods (1975) and brachman (1979) aimed at    guring out
what semantic networks actually mean led to the development of a number of more

exercises

29

sophisticated network-like languages including krl (bobrow and winograd, 1977)
and kl-one (brachman and schmolze, 1985). as these frameworks became more
sophisticated and well de   ned, it became clear that they were restricted variants of
fol coupled with specialized indexing id136 procedures. a useful collection of
papers covering much of this work can be found in brachman and levesque (1985).
russell and norvig (2002) describe a modern perspective on these representational
efforts.

linguistic efforts to assign semantic structures to natural language sentences in
the generative era began with the work of katz and fodor (1963). the limitations
of their simple feature-based representations and the natural    t of logic to many
of the linguistic problems of the day quickly led to the adoption of a variety of
predicate-argument structures as preferred semantic representations (lakoff, 1972;
mccawley, 1968). the subsequent introduction by montague (1973) of the truth-
conditional model-theoretic framework into linguistic theory led to a much tighter
integration between theories of formal syntax and a wide range of formal semantic
frameworks. good introductions to montague semantics and its role in linguistic
theory can be found in dowty et al. (1981) and partee (1976).

the representation of events as rei   ed objects is due to davidson (1967). the
approach presented here, which explicitly rei   es event participants, is due to parsons
(1990).

most current computational approaches to temporal reasoning are based on
allen   s notion of temporal intervals (allen, 1984); see chapter 17.
ter meulen
(1995) provides a modern treatment of tense and aspect. davis (1990) describes the
use of fol to represent knowledge across a wide range of common-sense domains
including quantities, space, time, and beliefs.

a recent comprehensive treatment of logic and language can be found in van
benthem and ter meulen (1997). a classic semantics text is lyons (1977). mccaw-
ley (1993) is an indispensable textbook covering a wide range of topics concerning
logic and language. chierchia and mcconnell-ginet (1991) also broadly covers
semantic issues from a linguistic perspective. heim and kratzer (1998) is a more
recent text written from the perspective of current generative theory.

exercises

14.1 peruse your daily newspaper for three examples of ambiguous sentences or

headlines. describe the various sources of the ambiguities.

14.2 consider a domain in which the word coffee can refer to the following con-
cepts in a knowledge-based system: a caffeinated or decaffeinated beverage,
ground coffee used to make either kind of beverage, and the beans themselves.
give arguments as to which of the following uses of coffee are ambiguous and
which are vague.

1. i   ve had my coffee for today.
2. buy some coffee on your way home.
3. please grind some more coffee.

14.3 the following rule, which we gave as a translation for example 14.26, is not

a reasonable de   nition of what it means to be a vegetarian restaurant.
   xvegetarianrestaurant(x) =    serves(x,vegetarianfood)

30 chapter 14

    the representation of sentence meaning

give a fol rule that better de   nes vegetarian restaurants in terms of what they
serve.

14.4 give fol translations for the following sentences:

1. vegetarians do not eat meat.
2. not all vegetarians eat eggs.

14.5 give a set of facts and id136s necessary to prove the following assertions:

1. mcdonald   s is not a vegetarian restaurant.
2. some vegetarians can eat at mcdonald   s.

don   t just place these facts in your knowledge base. show that they can be
inferred from some more general facts about vegetarians and mcdonald   s.

14.6 for the following sentences, give fol translations that capture the temporal

relationships between the events.

1. when mary   s    ight departed, i ate lunch.
2. when mary   s    ight departed, i had eaten lunch.

14.7 on page 15, we gave the representation near(centro,bacaro) as a transla-
tion for the sentence centro is near bacaro. in a truth-conditional semantics,
this formula is either true or false given some model. critique this truth-
conditional approach with respect to the meaning of words like near.

allen, j. (1984). towards a general theory of action and time.

arti   cial intelligence, 23(2), 123   154.

bobrow, d. g. and winograd, t. (1977). an overview of
krl, a id99 language. cognitive sci-
ence, 1(1), 3   46.

brachman, r. j. (1979). on the epistemogical status of se-
mantic networks. in findler, n. v. (ed.), associative net-
works: representation and use of knowledge by comput-
ers, pp. 3   50. academic press.

brachman, r. j. and levesque, h. j. (eds.). (1985). read-

ings in id99. morgan kaufmann.

brachman, r. j. and schmolze, j. g. (1985). an overview of
the kl-one id99 system. cognitive
science, 9(2), 171   216.

chierchia, g. and mcconnell-ginet, s. (1991). meaning and

grammar. mit press.

church, a. (1940). a formulation of a simple theory of

types. journal of symbolic logic, 5, 56   68.

davidson, d. (1967). the logical form of action sentences.
in rescher, n. (ed.), the logic of decision and action.
university of pittsburgh press.

davis, e. (1990). representations of commonsense knowl-

edge. morgan kaufmann.

dowty, d. r., wall, r. e., and peters, s. (1981). introduction

to montague semantics. d. reidel.

fensel, d., hendler, j. a., lieberman, h., and wahlster,
w. (eds.). (2003). spinning the semantic web: bring the
world wide web to its full potential. mit press, cam-
bridge, ma.

fillmore, c. j. (1968). the case for case. in bach, e. w. and
harms, r. t. (eds.), universals in linguistic theory, pp.
1   88. holt, rinehart & winston.

green, b. f., wolf, a. k., chomsky, c., and laughery, k.
(1961). baseball: an automatic question answerer. in pro-
ceedings of the western joint computer conference 19, pp.
219   224. reprinted in grosz et al. (1986).

heim, i. and kratzer, a. (1998). semantics in a generative

grammar. blackwell publishers, malden, ma.

jackendoff, r. (1983). semantics and cognition. mit press.
katz, j. j. and fodor, j. a. (1963). the structure of a seman-

tic theory. language, 39, 170   210.

kintsch, w. (1974). the representation of meaning in mem-

ory. wiley, new york.

lakoff, g. (1972). linguistics and natural logic. in david-
son, d. and harman, g. (eds.), semantics for natural lan-
guage, pp. 545   665. d. reidel.

lakoff, g. and johnson, m. (1980). metaphors we live by.

university of chicago press, chicago, il.

lindsey, r. (1963). inferential memory as the basis of ma-
chines which understand natural language. in feigenbaum,
e. and feldman, j. (eds.), computers and thought, pp.
217   233. mcgraw hill.

lyons, j. (1977). semantics. cambridge university press.
masterman, m. (1957). the thesaurus in syntax and seman-

tics. mechanical translation, 4(1), 1   2.

mccawley, j. d. (1968). the role of semantics in a gram-
mar. in bach, e. w. and harms, r. t. (eds.), universals in
linguistic theory, pp. 124   169. holt, rinehart & winston.

exercises

31

mccawley, j. d. (1993). everything that linguists have al-
ways wanted to know about logic (2nd ed.). university of
chicago press, chicago, il.

mcguiness, d. l. and van harmelen, f. (2004). owl web
ontology overview. tech. rep. 20040210, world wide web
consortium.

montague, r. (1973). the proper treatment of quanti   cation
in ordinary english. in thomason, r. (ed.), formal philos-
ophy: selected papers of richard montague, pp. 247   270.
yale university press, new haven, ct.

norman, d. a. and rumelhart, d. e. (1975). explorations

in cognition. freeman.

parsons, t. (1990). events in the semantics of english. mit

press.

partee, b. h. (ed.). (1976). montague grammar. academic

press.

quillian, m. r. (1968). semantic memory. in minsky, m.
(ed.), semantic information processing, pp. 227   270. mit
press.

raphael, b. (1968). sir: a computer program for seman-
in minsky, m. (ed.), semantic

tic information retrieval.
information processing, pp. 33   145. mit press.

reichenbach, h. (1947).

macmillan, new york.

elements of symbolic logic.

russell, s. and norvig, p. (2002). arti   cial intelligence: a

modern approach (2nd ed.). prentice hall.

schank, r. c. (1972). conceptual dependency: a theory
of natural language processing. cognitive psychology, 3,
552   631.

sch  onk   nkel, m. (1924).

  uber die bausteine der mathe-
matischen logik. mathematische annalen, 92, 305   316.
english translation appears in from frege to g  odel: a
source book in mathematical logic, harvard university
press, 1967.

simmons, r. f. (1965). answering english questions by
computer: a survey. communications of the acm, 8(1),
53   70.

simmons, r. f. (1973). semantic networks: their com-
putation and use for understanding english sentences. in
schank, r. c. and colby, k. m. (eds.), computer models
of thought and language, pp. 61   113. w.h. freeman and
co.

ter meulen, a. (1995). representing time in natural lan-

guage. mit press.

van benthem, j. and ter meulen, a. (eds.). (1997). hand-

book of logic and language. mit press.

vendler, z. (1967). linguistics in philosophy. cornell uni-

versity press, ithaca, ny.

wilks, y. (1975a). preference semantics. in keenan, e. l.
(ed.), the formal semantics of natural language, pp.
329   350. cambridge univ. press.

wilks, y. (1975b). a preferential, pattern-seeking, semantics
for natural language id136. arti   cial intelligence, 6(1),
53   74.

winograd, t. (1972). understanding natural language.

academic press.

woods, w. a. (1967). semantics for a question-answering

system. ph.d. thesis, harvard university.

32 chapter 14     the representation of sentence meaning

woods, w. a. (1973). progress in natural language under-
standing. in proceedings of afips national conference,
pp. 441   450.

woods, w. a. (1975). what   s in a link: foundations for
semantic networks. in bobrow, d. g. and collins, a. m.
(eds.), representation and understanding: studies in cog-
nitive science, pp. 35   82. academic press.

zwicky, a. and sadock, j. m. (1975). ambiguity tests and
how to fail them. in kimball, j. (ed.), syntax and seman-
tics 4, pp. 1   36. academic press.

