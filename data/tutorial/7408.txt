speech and language processing. daniel jurafsky & james h. martin.
rights reserved.

draft of september 23, 2018.

copyright c(cid:13) 2018.

all

chapter

17 information extraction

i am the very model of a modern major-general,
i   ve information vegetable, animal, and mineral,
i know the kings of england, and i quote the    ghts historical
from marathon to waterloo, in order categorical...
gilbert and sullivan, pirates of penzance

imagine that you are an analyst with an investment    rm that tracks airline stocks.
you   re given the task of determining the relationship (if any) between airline an-
nouncements of fare increases and the behavior of their stocks the next day. his-
torical data about stock prices is easy to come by, but what about the airline an-
nouncements? you will need to know at least the name of the airline, the nature of
the proposed fare hike, the dates of the announcement, and possibly the response of
other airlines. fortunately, these can be all found in news articles like this one:
citing high fuel prices, united airlines said friday it has increased fares
by $6 per round trip on    ights to some cities also served by lower-
cost carriers. american airlines, a unit of amr corp., immediately
matched the move, spokesman tim wagner said. united, a unit of ual
corp., said the increase took effect thursday and applies to most routes
where it competes against discount carriers, such as chicago to dallas
and denver to san francisco.

information
extraction

named entity
recognition

relation
extraction

event
extraction

this chapter presents techniques for extracting limited kinds of semantic con-
tent from text. this process of information extraction (ie), turns the unstructured
information embedded in texts into structured data, for example for populating a
relational database to enable further processing.

we begin with the    rst step in most ie tasks,    nding the proper names or named
entities in a text. the task of id39 (ner) is to    nd each
mention of a named entity in the text and label its type. what constitutes a named
entity type is task speci   c; people, places, and organizations are common, but gene
or protein names (cohen and demner-fushman, 2014) or    nancial asset classes
might be relevant for some tasks. once all the named entities in a text have been
extracted, they can be linked together in sets corresponding to real-world entities,
inferring, for example, that mentions of united airlines and united refer to the same
company. this is the joint task of coreference resolution and entity linking which
we defer til chapter 20.

next, we turn to the task of id36:    nding and classifying semantic
relations among the text entities. these are often binary relations like child-of, em-
ployment, part-whole, and geospatial relations. id36 has close links
to populating a relational database.

finally, we discuss three tasks related to events. event extraction is    nding
events in which these entities participate, like, in our sample text, the fare increases

2 chapter 17

   

information extraction

temporal
expression

temporal
id172

template    lling

by united and american and the reporting events said and cite. event coreference
(chapter 20) is needed to    gure out which event mentions in a text refer to the same
event; in our running example the two instances of increase and the phrase the move
all refer to the same event.

to    gure out when the events in a text happened we extract temporal expres-
sions like days of the week (friday and thursday), relative expressions like two
days from now or next year and times such as 3:30 p.m.. these expressions must be
normalized onto speci   c calendar dates or times of day to situate events in time. in
our sample task, this will allow us to link friday to the time of united   s announce-
ment, and thursday to the previous day   s fare increase, and produce a timeline in
which united   s announcement follows the fare increase and american   s announce-
ment follows both of those events.

finally, many texts describe recurring stereotypical events or situations. the task
of template    lling is to    nd such situations in documents and    ll in the template
slots. these slot-   llers may consist of text segments extracted directly from the text,
or concepts like times, amounts, or ontology entities that have been inferred from
text elements through additional processing.

our airline text is an example of this kind of stereotypical situation since airlines
often raise fares and then wait to see if competitors follow along.
in this situa-
tion, we can identify united as a lead airline that initially raised its fares, $6 as the
amount, thursday as the increase date, and american as an airline that followed
along, leading to a    lled template like the following.

fare-raise attempt:                

lead airline:
amount:
effective date:
follower:

united airlines
$6
2006-10-26
american airlines

               

17.1 id39

named entity

temporal
expressions

the    rst step in information extraction is to detect the entities in the text. a named
entity is, roughly speaking, anything that can be referred to with a proper name:
a person, a location, an organization. the term is commonly extended to include
things that aren   t entities per se, including dates, times, and other kinds of temporal
expressions, and even numerical expressions like prices. here   s the sample text
introduced earlier with the named entities marked:

citing high fuel prices, [org united airlines] said [time friday] it
has increased fares by [money $6] per round trip on    ights to some
cities also served by lower-cost carriers. [org american airlines], a
unit of [org amr corp.], immediately matched the move, spokesman
[per tim wagner] said. [org united], a unit of [org ual corp.],
said the increase took effect [time thursday] and applies to most
routes where it competes against discount carriers, such as [loc chicago]
to [loc dallas] and [loc denver] to [loc san francisco].

the text contains 13 mentions of named entities including 5 organizations, 4 loca-
tions, 2 times, 1 person, and 1 mention of money.

in addition to their use in extracting events and the relationship between par-
ticipants, named entities are useful for many other language processing tasks. in

17.1

    id39

3

id31 we might want to know a consumer   s sentiment toward a partic-
ular entity. entities are a useful    rst stage in id53, or for linking text
to information in structured knowledge sources like wikipedia.

figure 17.1 shows typical generic named entity types. many applications will
also need to use speci   c entity types like proteins, genes, commercial products, or
works of art.

tag sample categories
per people, characters

type
people
organization org companies, sports teams
location
loc regions, mountains, seas
gpe countries, states, provinces palo alto is raising the fees for parking.
geo-political
entity
facility
it was a classic ford falcon.
vehicles
figure 17.1 a list of generic named entity types with the kinds of entities they refer to.

fac bridges, buildings, airports consider the golden gate bridge.
veh planes, trains, automobiles

example sentences
turing is a giant of computer science.
the ipcc warned about the cyclone.
the mt. sanitas loop is in sunshine canyon.

id39 means    nding spans of text that constitute proper
names and then classifying the type of the entity. recognition is dif   cult partly be-
cause of the ambiguity of segmentation; we need to decide what   s an entity and what
isn   t, and where the boundaries are. another dif   culty is caused by type ambiguity.
the mention jfk can refer to a person, the airport in new york, or any number of
schools, bridges, and streets around the united states. some examples of this kind
of cross-type confusion are given in figures 17.2 and 17.3.

name
washington
downing st.
ira
louis vuitton

possible categories
person, location, political entity, organization, vehicle
location, organization
person, organization, monetary instrument
person, organization, commercial product

figure 17.2 common categorical ambiguities associated with various proper names.

[per washington] was born into slavery on the farm of james burroughs.
[org washington] went up 2 games to 1 in the four-game series.
blair arrived in [loc washington] for what may well be his last state visit.
in june, [gpe washington] passed a primary seatbelt law.
the [veh washington] had proved to be a leaky ship, every passage i made...

figure 17.3 examples of type ambiguities in the use of the name washington.

17.1.1 ner as sequence labeling
the standard algorithm for id39 is as a word-by-word sequence
labeling task, in which the assigned tags capture both the boundary and the type. a
sequence classi   er like an memm/crf or a bi-lstm is trained to label the tokens
in a text with tags that indicate the presence of particular kinds of named entities.
consider the following simpli   ed excerpt from our running example.

[org american airlines], a unit of [org amr corp.], immediately matched
the move, spokesman [per tim wagner] said.

4 chapter 17

   

information extraction

iob

figure 17.4 shows the same excerpt represented with iob tagging. in iob tag-
ging we introduce a tag for the beginning (b) and inside (i) of each entity type,
and one for tokens outside (o) any entity. the number of tags is thus 2n + 1 tags,
where n is the number of entity types. iob tagging can represent exactly the same
information as the bracketed notation.

words
american
airlines
,
a
unit
of
amr
corp.
,
immediately
matched
the
move
,
spokesman
tim
wagner
said
.

iob label
b-org
i-org
o
o
o
o
b-org
i-org
o
o
o
o
o
o
o
b-per
i-per
o
o

io label
i-org
i-org
o
o
o
o
i-org
i-org
o
o
o
o
o
o
o
i-per
i-per
o
o

figure 17.4 named entity tagging as a sequence model, showing iob and io encodings.

we   ve also shown io tagging, which loses some information by eliminating the
b tag. without the b tag io tagging is unable to distinguish between two entities of
the same type that are right next to each other. since this situation doesn   t arise very
often (usually there is at least some punctuation or other deliminator), io tagging
may be suf   cient, and has the advantage of using only n + 1 tags.

in the following three sections we introduce the three standard families of al-
gorithms for ner tagging: feature based (memm/crf), neural (bi-lstm), and
rule-based.

17.1.2 a feature-based algorithm for ner

identity of wi, identity of neighboring words
embeddings for wi, embeddings for neighboring words
part of speech of wi, part of speech of neighboring words
base-phrase syntactic chunk label of wi and neighboring words
presence of wi in a gazetteer
wi contains a particular pre   x (from all pre   xes of length     4)
wi contains a particular suf   x (from all suf   xes of length     4)
wi is all upper case
word shape of wi, word shape of neighboring words
short word shape of wi, short word shape of neighboring words
presence of hyphen
figure 17.5 typical features for a feature-based ner system.

word shape

gazetteer

17.1

    id39

5

the    rst approach is to extract features and train an memm or crf sequence
model of the type we saw for part-of-speech tagging in chapter 8. figure 17.5 lists
standard features used in such feature-based systems. we   ve seen many of these
features before in the context of part-of-speech tagging, particularly for tagging un-
known words. this is not surprising, as many unknown words are in fact named
entities. word shape features are thus particularly important in the context of ner.
recall that word shape features are used to represent the abstract letter pattern of
the word by mapping lower-case letters to    x   , upper-case to    x   , numbers to    d   , and
retaining punctuation. thus for example i.m.f would map to x.x.x. and dc10-30
would map to xxdd-dd. a second class of shorter word shape features is also used.
in these features consecutive character types are removed, so dc10-30 would be
mapped to xd-d but i.m.f would still map to x.x.x. this feature by itself accounts
for a considerable part of the success of feature-based ner systems for english
news text. shape features are also particularly important in recognizing names of
proteins and genes in biological texts.

for example the named entity token l   occitane would generate the following

non-zero valued feature values:

pre   x(wi) = l
pre   x(wi) = l   
pre   x(wi) = l   o
pre   x(wi) = l   oc
word-shape(wi) = x   xxxxxxxx

suf   x(wi) = tane
suf   x(wi) = ane
suf   x(wi) = ne
suf   x(wi) = e
short-word-shape(wi) = x   xx

a gazetteer is a list of place names, often providing millions of entries for lo-
cations with detailed geographical and political information.1 a related resource
is name-lists; the united states census bureau also provides extensive lists of    rst
names and surnames derived from its decadal census in the u.s.2 similar lists of cor-
porations, commercial products, and all manner of things biological and mineral are
also available from a variety of sources. gazetteer and name features are typically
implemented as a binary feature for each name list. unfortunately, such lists can
be dif   cult to create and maintain, and their usefulness varies considerably. while
gazetteers can be quite effective, lists of persons and organizations are not always
helpful (mikheev et al., 1999).

feature effectiveness depends on the application, genre, media, and language.
for example, shape features, critical for english newswire texts, are of little use
with automatic id103 transcripts, or other non-edited or informally-
edited sources, or for languages like chinese that don   t use orthographic case. the
features in fig. 17.5 should therefore be thought of as only a starting point.

figure 17.6 illustrates the result of adding part-of-speech tags, syntactic base-

phrase chunk tags, and some shape information to our earlier example.

given such a training set, a sequence classi   er like an memm can be trained to
label new sentences. figure 17.7 illustrates the operation of such a sequence labeler
at the point where the token corp. is next to be labeled. if we assume a context win-
dow that includes the two preceding and following words, then the features available
to the classi   er are those shown in the boxed area.

1 www.geonames.org
2 www.census.gov

6 chapter 17

   

information extraction

word
american
airlines
,
a
unit
of
amr
corp.
,
immediately rb
vbd b-vp
matched
b-np
dt
the
i-np
nn
move
o
,
,
b-np
spokesman nn
i-np
nnp
tim
nnp
wagner
i-np
vbd b-vp
said
.
,

short shape
pos chunk
xx
nnp b-np
xx
nnps i-np
,
,
o
x
dt
b-np
x
nn
i-np
x
in
b-pp
x
nnp b-np
xx.
i-np
nnp
o
,
,
b-advp x
x
x
x
,
x
xx
xx
x
.

o

label
b-org
i-org
o
o
o
o
b-org
i-org
o
o
o
o
o
o
o
b-per
i-per
o
o

figure 17.6 word-by-word feature encoding for ner.

figure 17.7 id39 as sequence labeling. the features available to the classi   er during
training and classi   cation are those in the boxed area.

17.1.3 a neural algorithm for ner

the standard neural algorithm for ner is based on the bi-lstm introduced in chap-
ter 9. recall that in that model, word and character embeddings are computed for
input word wi. these are passed through a left-to-right lstm and a right-to-left
lstm, whose outputs are concatenated (or otherwise combined) to produce a sin-
gle output layer at position i. in the simplest method, this layer can then be directly
passed onto a softmax that creates a id203 distribution over all ner tags, and
the most likely tag is chosen as ti.

for named entity tagging this greedy approach to decoding is insuf   cient, since
it doesn   t allow us to impose the strong constraints neighboring tokens have on each
other (e.g., the tag i-per must follow another i-per or b-per). instead a crf layer
is normally used on top of the bi-lstm output, and the viterbi decoding algorithm
is used to decode. fig. 17.8 shows a sketch of the algorithm

classifierinnnpnnprbunitofa...xb-pp...amrcorp.immediatelyb-npxi-npx.b-advpxob-org?......,,o,matched17.1

    id39

7

figure 17.8 putting it all together: character embeddings and words together a bi-lstm
sequence model. after (lample et al., 2016)

17.1.4 rule-based ner
while machine learned (neural or memm/crf) sequence models are the norm in
academic research, commercial approaches to ner are often based on pragmatic
combinations of lists and rules, with some smaller amount of supervised machine
learning (chiticariu et al., 2013). for example ibm system t is a text understand-
ing architecture in which a user speci   es complex declarative constraints for tagging
tasks in a formal query language that includes id157, dictionaries, se-
mantic constraints, nlp operators, and table structures, all of which the system
compiles into an ef   cient extractor (chiticariu et al., 2018)

one common approach is to make repeated rule-based passes over a text, allow-
ing the results of one pass to in   uence the next. the stages typically    rst involve
the use of rules that have extremely high precision but low recall. subsequent stages
employ more error-prone statistical methods that take the output of the    rst pass into
account.

1. first, use high-precision rules to tag unambiguous entity mentions.
2. then, search for substring matches of the previously detected names.
3. consult application-speci   c name lists to identify likely name entity mentions

from the given domain.

4. finally, apply probabilistic sequence labeling techniques that make use of the

tags from previous stages as additional features.

the intuition behind this staged approach is twofold. first, some of the entity
mentions in a text will be more clearly indicative of a given entity   s class than others.
second, once an unambiguous entity mention is introduced into a text, it is likely that
subsequent shortened versions will refer to the same entity (and thus the same type
of entity).

17.1.5 evaluation of id39
the familiar metrics of recall, precision, and f1 measure are used to evaluate ner
systems. remember that recall is the ratio of the number of correctly labeled re-
sponses to the total that should have been labeled; precision is the ratio of the num-

markwatneyvisitsmarslstm1lstm1lstm1lstm1lstm2lstm2lstm2lstm2concatenationright-to-left lstid113ft-to-right lstmb-peri-perob-loccrf layerchar lstmchar lstmchar lstmchar lstmgloveglovegloveglovechar+gloveembeddings8 chapter 17

   

information extraction

figure 17.9 the 17 relations used in the ace id36 task.

ber of correctly labeled responses to the total labeled; and f-measure is the harmonic
mean of the two. for named entities, the entity rather than the word is the unit of
response. thus in the example in fig. 17.6, the two entities tim wagner and amr
corp. and the non-entity said would each count as a single response.

the fact that named entity tagging has a segmentation component which is not
present in tasks like text categorization or part-of-speech tagging causes some prob-
lems with evaluation. for example, a system that labeled american but not american
airlines as an organization would cause two errors, a false positive for o and a false
negative for i-org. in addition, using entities as the unit of response but words as
the unit of training means that there is a mismatch between the training and test
conditions.

17.2 id36

next on our list of tasks is to discern the relationships that exist among the detected
entities. let   s return to our sample airline text:

citing high fuel prices, [org united airlines] said [time friday] it
has increased fares by [money $6] per round trip on    ights to some
cities also served by lower-cost carriers. [org american airlines], a
unit of [org amr corp.], immediately matched the move, spokesman
[per tim wagner] said. [org united], a unit of [org ual corp.],
said the increase took effect [time thursday] and applies to most
routes where it competes against discount carriers, such as [loc chicago]
to [loc dallas] and [loc denver] to [loc san francisco].

the text tells us, for example, that tim wagner is a spokesman for american
airlines, that united is a unit of ual corp., and that american is a unit of amr.
these binary relations are instances of more generic relations such as part-of or
employs that are fairly frequent in news-style texts. figure 17.9 lists the 17 relations
used in the ace id36 evaluations and fig. 17.10 shows some sample
relations. we might also extract more domain-speci   c relation such as the notion of
an airline route. for example from this text we can conclude that united has routes
to chicago, dallas, denver, and san francisco.

artifactgeneralaffiliationorgaffiliationpart-wholeperson-socialphysicallocatednearbusinessfamilylasting personalcitizen-resident-ethnicity-religionorg-location-originfounderemploymentmembershipownershipstudent-aluminvestoruser-owner-inventor-manufacturergeographicalsubsidiarysports-affiliation17.2

    id36

9

examples
relations
he was in tennessee
physical-located
xyz, the parent company of abc
part-whole-subsidiary
yoko   s husband john
person-social-family
steve jobs, co-founder of apple...
org-aff-founder
figure 17.10 semantic relations with examples and the named entity types they involve.

types
per-gpe
org-org
per-per
per-org

d = {a,b,c,d,e, f ,g,h,i}
a,b,c,d
e
f ,g,h,i

domain
united, ual, american airlines, amr
tim wagner
chicago, dallas, denver, and san francisco
classes
united, ual, american, and amr are organizations
tim wagner is a person
chicago, dallas, denver, and san francisco are places
relations
united is a unit of ual
american is a unit of amr
tim wagner works for american airlines
united serves chicago, dallas, denver, and san francisco
figure 17.11 a model-based view of the relations and entities in our sample text.

org = {a,b,c,d}
pers = {e}
loc = { f ,g,h,i}

partof = {(cid:104)a,b(cid:105),(cid:104)c,d(cid:105)}
orgaff = {(cid:104)c,e(cid:105)}
serves = {(cid:104)a, f(cid:105),(cid:104)a,g(cid:105),(cid:104)a,h(cid:105),(cid:104)a,i(cid:105)}

these relations correspond nicely to the model-theoretic notions we introduced
in chapter 14 to ground the meanings of the logical forms. that is, a relation consists
of a set of ordered tuples over elements of a domain. in most standard information-
extraction applications, the domain elements correspond to the named entities that
occur in the text, to the underlying entities that result from co-reference resolution, or
to entities selected from a domain ontology. figure 17.11 shows a model-based view
of the set of entities and relations that can be extracted from our running example.
notice how this model-theoretic view subsumes the ner task as well; named entity
recognition corresponds to the identi   cation of a class of unary relations.

sets of relations have been de   ned for many other domains as well. for example
umls, the uni   ed medical language system from the us national library of
medicine has a network that de   nes 134 broad subject categories, entity types, and
54 relations between the entities, such as the following:

entity
relation
injury
disrupts
bodily location
location-of biologic function
anatomical structure
part-of
pharmacologic substance causes
pharmacologic substance treats

organism
pathological function
pathologic function

entity
physiological function

given a medical sentence like this one:
(17.1) doppler echocardiography can be used to diagnose left anterior descending

artery stenosis in patients with type 2 diabetes

we could thus extract the umls relation:

echocardiography, doppler diagnoses acquired stenosis

infoboxes

wikipedia also offers a large supply of relations, drawn from infoboxes, struc-
tured tables associated with certain wikipedia articles. for example, the wikipedia

10 chapter 17

   

information extraction

rdf
rdf triple

infobox for stanford includes structured facts like state = "california" or
president = "mark tessier-lavigne". these facts can be turned into rela-
tions like president-of or located-in. or into relations in a metalanguage called rdf
(resource description framework). an rdf triple is a tuple of entity-relation-
entity, called a subject-predicate-object expression. here   s a sample rdf triple:

subject
golden gate park location

predicate object

san francisco

for example the crowdsourced dbpedia (bizer et al., 2009) is an ontology de-
rived from wikipedia containing over 2 billion rdf triples. another dataset from
wikipedia infoboxes, freebase (bollacker et al., 2008), has relations like

freebase

people/person/nationality
location/location/contains

is-a
hypernym

id138 or other ontologies offer useful ontological relations that express hier-
archical relations between words or concepts. for example id138 has the is-a or
hypernym relation between classes,

giraffe is-a ruminant is-a ungulate is-a mammal is-a vertebrate ...

id138 also has instance-of relation between individuals and classes, so that for
example san francisco is in the instance-of relation with city. extracting these
relations is an important step in extending or building ontologies.

there are    ve main classes of algorithms for id36: hand-written
patterns, supervised machine learning, semi-supervised (via id64 and
via distant supervision), and unsupervised. we   ll introduce each of these in the
next sections.

17.2.1 using patterns to extract relations
the earliest and still common algorithm for id36 is lexico-syntactic
patterns,    rst developed by hearst (1992a). consider the following sentence:
agar is a substance prepared from a mixture of red algae, such as ge-
lidium, for laboratory or industrial use.

hearst points out that most human readers will not know what gelidium is, but that
they can readily infer that it is a kind of (a hyponym of) red algae, whatever that is.
she suggests that the following lexico-syntactic pattern

np0 such as np1{,np2 . . . , (and|or)npi},i     1

implies the following semantics

allowing us to infer

   npi,i     1,hyponym(npi,np0)

hyponym(gelidium,red algae)

(17.2)

(17.3)

(17.4)

figure 17.12 shows    ve patterns hearst (1992a, 1998) suggested for inferring
the hyponym relation; we   ve shown nph as the parent/hyponym. modern versions
of the pattern-based approach extend it by adding named entity constraints. for
example if our goal is to answer questions about    who holds what of   ce in which
organization?   , we can use patterns like the following:

17.2

    id36

11

np {, np}* {,} (and|or) other nph
temples, treasuries, and other important civic buildings
nph such as {np,}* {(or|and)} np
red algae such as gelidium
such nph as {np,}* {(or|and)} np
such authors as herrick, goldsmith, and shakespeare
nph {,} including {np,}* {(or|and)} np
common-law countries, including canada and england
nph {,} especially {np}* {(or|and)} np
european countries, especially france, england, and spain
figure 17.12 hand-built lexico-syntactic patterns for    nding hypernyms, using {} to mark optionality
(hearst 1992a, hearst 1998).

per, position of org:
george marshall, secretary of state of the united states
per (named|appointed|chose|etc.) per prep? position
truman appointed marshall secretary of state
per [be]? (named|appointed|etc.) prep? org position
george marshall was named us secretary of state

hand-built patterns have the advantage of high-precision and they can be tailored
to speci   c domains. on the other hand, they are often low-recall, and it   s a lot of
work to create them for all possible patterns.

17.2.2 id36 via supervised learning
supervised machine learning approaches to id36 follow a scheme that
should be familiar by now. a    xed set of relations and entities is chosen, a training
corpus is hand-annotated with the relations and entities, and the annotated texts are
then used to train classi   ers to annotate an unseen test set.

the most straightforward approach has three steps, illustrated in fig. 17.13. step
one is to    nd pairs of named entities (usually in the same sentence). in step two, a
   ltering classi   er is trained to make a binary decision as to whether a given pair of
named entities are related (by any relation). positive examples are extracted directly
from all relations in the annotated corpus, and negative examples are generated from
within-sentence entity pairs that are not annotated with a relation. in step 3, a classi-
   er is trained to assign a label to the relations that were found by step 2. the use of
the    ltering classi   er can speed up the    nal classi   cation and also allows the use of
distinct feature-sets appropriate for each task. for each of the two classi   ers, we can
use any of the standard classi   cation techniques (id28, neural network,
id166, etc.)

function findrelations(words) returns relations

relations   nil
entities    findentities(words)
forall entity pairs (cid:104)e1, e2(cid:105) in entities do

if related?(e1, e2)

relations   relations+classifyrelation(e1, e2)

figure 17.13 finding and classifying the relations among entities in a text.

for the feature-based classi   ers like id28 or id79s the
most important step is to identify useful features. let   s consider features for clas-

12 chapter 17

   

information extraction

sifying the relationship between american airlines (mention 1, or m1) and tim
wagner (mention 2, m2) from this sentence:
(17.5) american airlines, a unit of amr, immediately matched the move,

spokesman tim wagner said

useful word features include

airlines wagner

    the headwords of m1 and m2 and their concatenation
airlines-wagner
    bag-of-words and bigrams in m1 and m2
    words or bigrams in particular positions

american, airlines, tim, wagner, american airlines, tim wagner

m2: -1 spokesman
m2: +1 said

    bag of words or bigrams between m1 and m2:
    stemmed versions of the same

a, amr, of, immediately, matched, move, spokesman, the, unit

embeddings can be used to represent words in any of these features. useful named
entity features include

    named-entity types and their concatenation
(m1: org, m2: per, m1m2: org-per)
    entity level of m1 and m2 (from the set name, nominal, pronoun)

m1: name [it or he would be pronoun]
m2: name [the company would be nominal]

    number of entities between the arguments (in this case 1, for amr)
the syntactic structure of a sentence can also signal relationships among its
entities. syntax is often featured by using strings representing syntactic paths: the
(dependency or constituency) path traversed through the tree in getting from one
entity to the other.

    base syntactic chunk sequence from m1 to m2
np np pp vp np np
    constituent paths between m1 and m2
np     np     s     s     np
    dependency-tree paths
airlines    sub j matched    comp said    sub j wagner

figure 17.14 summarizes many of the features we have discussed that could be
used for classifying the relationship between american airlines and tim wagner
from our example text.

neural models for id36 similarly treat the task as supervised clas-
si   cation. one option is to use a similar architecture as we saw for named entity
tagging: a bi-lstm model with id27s as inputs and a single softmax
classi   cation of the sentence output as a 1-of-n relation label. because relations
often hold between entities that are far part in a sentence (or across sentences), it
may be possible to get higher performance from algorithms like convolutional nets
(dos santos et al., 2015) or chain or tree lstms (miwa and bansal 2016, peng
et al. 2017).

in general, if the test set is similar enough to the training set, and if there is
enough hand-labeled data, supervised id36 systems can get high ac-
curacies. but labeling a large training set is extremely expensive and supervised

17.2

    id36

13

m1 headword
m2 headword
word(s) before m1
word(s) after m2
bag of words between
m1 type
m2 type
concatenated types
constituent path
base phrase path
typed-dependency path airlines    sub j matched    comp said    sub j wagner
figure 17.14 sample of features extracted during classi   cation of the <american airlines, tim wagner>
tuple; m1 is the    rst mention, m2 the second.

airlines (as a word token or an embedding)
wagner
none
said
{a, unit, of, amr, inc., immediately, matched, the, move, spokesman }
org
pers
org-pers
np     np     s     s     np
np     np     pp     np     v p     np     np

models are brittle: they don   t generalize well to different text genres. for this rea-
son, much research in id36 has focused on the semi-supervised and
unsupervised approaches we turn to next.

17.2.3 semisupervised id36 via id64
supervised machine learning assumes that we have lots of labeled data. unfortu-
nately, this is expensive. but suppose we just have a few high-precision seed pat-
terns, like those in section 17.2.1, or perhaps a few seed tuples. that   s enough
to bootstrap a classi   er! id64 proceeds by taking the entities in the seed
pair, and then    nding sentences (on the web, or whatever dataset we are using) that
contain both entities. from all such sentences, we extract and generalize the context
around the entities to learn new patterns. fig. 17.15 sketches a basic algorithm.

seed patterns
seed tuples
id64

function bootstrap(relation r) returns new relation tuples

tuples   gather a set of seed tuples that have relation r
iterate

sentences      nd sentences that contain entities in tuples
patterns   generalize the context between and around entities in sentences
newpairs   use patterns to grep for more tuples
newpairs   newpairs with high con   dence
tuples   tuples + newpairs

return tuples

figure 17.15 id64 from seed entity pairs to learn relations.

suppose, for example, that we need to create a list of airline/hub pairs, and we
know only that ryanair has a hub at charleroi. we can use this seed fact to discover
new patterns by    nding other mentions of this relation in our corpus. we search
for the terms ryanair, charleroi and hub in some proximity. perhaps we    nd the
following set of sentences:
(17.6) budget airline ryanair, which uses charleroi as a hub, scrapped all

weekend    ights out of the airport.

(17.7) all    ights in and out of ryanair   s belgian hub at charleroi airport were

grounded on friday...

14 chapter 17

   

information extraction

(17.8) a spokesman at charleroi, a main hub for ryanair, estimated that 8000

passengers had already been affected.

from these results, we can use the context of words between the entity mentions,
the words before mention one, the word after mention two, and the named entity
types of the two mentions, and perhaps other features, to extract general patterns
such as the following:

/ [org], which uses [loc] as a hub /
/ [org]   s hub at [loc] /
/ [loc] a main hub for [org] /

con   dence
values
semantic drift

noisy-or

these new patterns can then be used to search for additional tuples.

id64 systems also assign con   dence values to new tuples to avoid se-
mantic drift. in semantic drift, an erroneous pattern leads to the introduction of
erroneous tuples, which, in turn, lead to the creation of problematic patterns and the
meaning of the extracted relations    drifts   . consider the following example:
(17.9) sydney has a ferry hub at circular quay.
if accepted as a positive example, this expression could lead to the incorrect in-
troduction of the tuple (cid:104)sydney,circularquay(cid:105). patterns based on this tuple could
propagate further errors into the database.

con   dence values for patterns are based on balancing two factors: the pattern   s
performance with respect to the current set of tuples and the pattern   s productivity
in terms of the number of matches it produces in the document collection. more
formally, given a document collection d, a current set of tuples t , and a proposed
pattern p, we need to track two factors:

    hits: the set of tuples in t that p matches while looking in d
    f inds: the total set of tuples that p    nds in d
the following equation balances these considerations (riloff and jones, 1999).

conf rlogf (p) =

hitsp
   ndsp

   log(   ndsp)

(17.10)

this metric is generally normalized to produce a id203.
we can assess the con   dence in a proposed new tuple by combining the evidence
supporting it from all the patterns p(cid:48) that match that tuple in d (agichtein and
gravano, 2000). one way to combine such evidence is the noisy-or technique.
assume that a given tuple is supported by a subset of the patterns in p, each with
its own con   dence assessed as above. in the noisy-or model, we make two basic
assumptions. first, that for a proposed tuple to be false, all of its supporting patterns
must have been in error, and second, that the sources of their individual failures are
all independent. if we loosely treat our con   dence measures as probabilities, then
the id203 of any individual pattern p failing is 1    conf (p); the id203 of
all of the supporting patterns for a tuple being wrong is the product of their individual
failure probabilities, leaving us with the following equation for our con   dence in a
new tuple.

(1    conf (p))

(17.11)

conf (t) = 1   (cid:89)

p   p(cid:48)

setting conservative con   dence thresholds for the acceptance of new patterns
and tuples during the id64 process helps prevent the system from drifting
away from the targeted relation.

distant
supervision

17.2

    id36

15

17.2.4 distant supervision for id36
although text that has been hand-labeled with relation labels is extremely expensive
to produce, there are ways to    nd indirect sources of training data. the distant
supervision method of mintz et al. (2009) combines the advantages of id64
with supervised learning. instead of just a handful of seeds, distant supervision uses
a large database to acquire a huge number of seed examples, creates lots of noisy
pattern features from all these examples and then combines them in a supervised
classi   er.

for example suppose we are trying to learn the place-of-birth relationship be-
tween people and their birth cities. in the seed-based approach, we might have only
5 examples to start with. but wikipedia-based databases like dbpedia or freebase
have tens of thousands of examples of many relations; including over 100,000 ex-
amples of place-of-birth, (<edwin hubble, marshfield>, <albert einstein,
ulm>, etc.,). the next step is to run named entity taggers on large amounts of text   
mintz et al. (2009) used 800,000 articles from wikipedia   and extract all sentences
that have two named entities that match the tuple, like the following:

...hubble was born in marsh   eld...
...einstein, born (1879), ulm...
...hubble   s birthplace in marsh   eld...
training instances can now be extracted from this data, one training instance
for each identical tuple <relation, entity1, entity2>. thus there will be one
training instance for each of:

<born-in, edwin hubble, marshfield>
<born-in, albert einstein, ulm>
<born-year, albert einstein, 1879>
and so on.

we can then apply feature-based or neural classi   cation. for feature-based clas-
si   cation, standard supervised id36 features like the named entity la-
bels of the two mentions, the words and dependency paths in between the mentions,
and neighboring words. each tuple will have features collected from many training
instances; the feature vector for a single training instance like (<born-in,albert
einstein, ulm> will have lexical and syntactic features from many different sen-
tences that mention einstein and ulm.

because distant supervision has very large training sets, it is also able to use very
rich features that are conjunctions of these individual features. so we will extract
thousands of patterns that conjoin the entity types with the intervening words or
dependency paths like these:

per was born in loc
per, born (xxxx), loc
per   s birthplace in loc
to return to our running example, for this sentence:

(17.12) american airlines, a unit of amr, immediately matched the move,

spokesman tim wagner said

we would learn rich conjunction features like this one:

m1 = org & m2 = per & nextword=   said   & path= np     np     s     s     np
the result is a supervised classi   er that has a huge rich set of features to use
in detecting relations. since not every test sentence will have one of the training

16 chapter 17

   

information extraction

relations, the classi   er will also need to be able to label an example as no-relation.
this label is trained by randomly selecting entity pairs that do not appear in any
freebase relation, extracting features for them, and building a feature vector for
each such tuple. the    nal algorithm is sketched in fig. 17.16.

function distant supervision(database d, text t) returns relation classi   er c

foreach relation r

foreach tuple (e1,e2) of entities with relation r in d
sentences   sentences in t that contain e1 and e2
f   frequent features in sentences
observations   observations + new training tuple (e1, e2, f, r)

c   train supervised classi   er on observations
return c

figure 17.16 the distant supervision algorithm for id36. a neural classi   er
might not need to use the feature set f .

distant supervision shares advantages with each of the methods we   ve exam-
ined. like supervised classi   cation, distant supervision uses a classi   er with lots
of features, and supervised by detailed hand-created knowledge. like pattern-based
classi   ers, it can make use of high-precision evidence for the relation between en-
tities. indeed, distance supervision systems learn patterns just like the hand-built
patterns of early relation extractors. for example the is-a or hypernym extraction
system of snow et al. (2005) used hypernym/hyponym np pairs from id138 as
distant supervision, and then learned new patterns from large amounts of text. their
system induced exactly the original 5 template patterns of hearst (1992a), but also
70,000 additional patterns including these four:

nph like np many hormones like leptin...
nph called np ...using a markup language called xhtml
np is a nph
np, a nph

ruby is a programming language...
ibm, a company with a long...

this ability to use a large number of features simultaneously means that, un-
like the iterative expansion of patterns in seed-based systems, there   s no semantic
drift. like unsupervised classi   cation, it doesn   t use a labeled training corpus of
texts, so it isn   t sensitive to genre issues in the training corpus, and relies on very
large amounts of unlabeled data. distant supervision also has the advantage that it
can create training tuples to be used with neural classi   ers, where features are not
required.

but distant supervision can only help in extracting relations for which a large
enough database already exists. to extract new relations without datasets, or rela-
tions for new domains, purely unsupervised methods must be used.

17.2.5 unsupervised id36
the goal of unsupervised id36 is to extract relations from the web
when we have no labeled training data, and not even any list of relations. this task
is often called id10 or open ie. in open ie, the relations
are simply strings of words (usually beginning with a verb).

for example, the reverb system (fader et al., 2011) extracts a relation from a

sentence s in 4 steps:

open
information
extraction

17.2

    id36

17

1. run a part-of-speech tagger and entity chunker over s
2. for each verb in s,    nd the longest sequence of words w that start with a verb

and satisfy syntactic and lexical constraints, merging adjacent matches.

3. for each phrase w,    nd the nearest noun phrase x to the left which is not a
relative pronoun, wh-word or existential    there   . find the nearest noun phrase
y to the right.

4. assign con   dence c to the relation r = (x,w,y) using a con   dence classi   er

and return it.

a relation is only accepted if it meets syntactic and lexical constraints. the
syntactic constraints ensure that it is a verb-initial sequence that might also include
nouns (relations that begin with light verbs like make, have, or do often express the
core of the relation with a noun, like have a hub in):

v | vp | vw*p
v = verb particle? adv?
w = (noun | adj | adv | pron | det )
p = (prep | particle | inf. marker)

the lexical constraints are based on a dictionary d that is used to prune very rare,
long relation strings. the intuition is to eliminate candidate relations that don   t oc-
cur with suf   cient number of distinct argument types and so are likely to be bad
examples. the system    rst runs the above id36 algorithm of   ine on
500 million web sentences and extracts a list of all the relations that occur after nor-
malizing them (removing in   ection, auxiliary verbs, adjectives, and adverbs). each
relation r is added to the dictionary if it occurs with at least 20 different arguments.
fader et al. (2011) used a dictionary of 1.7 million normalized relations.

finally, a con   dence value is computed for each relation using a logistic re-
gression classi   er. the classi   er is trained by taking 1000 random web sentences,
running the extractor, and hand labelling each extracted relation as correct or incor-
rect. a con   dence classi   er is then trained on this hand-labeled data, using features
of the relation and the surrounding words. fig. 17.17 shows some sample features
used in the classi   cation.

(x,r,y) covers all words in s
the last preposition in r is for
the last preposition in r is on
len(s)     10
there is a coordinating conjunction to the left of r in s
r matches a lone v in the syntactic constraints
there is preposition to the left of x in s
there is an np to the right of y in s
figure 17.17 features for the classi   er that assigns con   dence to relations extracted by the
id10 system reverb (fader et al., 2011).

for example the following sentence:

(17.13) united has a hub in chicago, which is the headquarters of united

continental holdings.

has the relation phrases has a hub in and is the headquarters of (it also has has and
is, but longer phrases are preferred). step 3    nds united to the left and chicago to
the right of has a hub in, and skips over which to    nd chicago to the left of is the
headquarters of. the    nal output is:

18 chapter 17

   

information extraction

r1:
r2:

<united, has a hub in, chicago>
<chicago, is the headquarters of, united continental holdings>

the great advantage of unsupervised id36 is its ability to handle
a huge number of relations without having to specify them in advance. the disad-
vantage is the need to map these large sets of strings into some canonical form for
adding to databases or other knowledge sources. current methods focus heavily on
relations expressed with verbs, and so will miss many relations that are expressed
nominally.

17.2.6 evaluation of id36
supervised id36 systems are evaluated by using test sets with human-
annotated, gold-standard relations and computing precision, recall, and f-measure.
labeled precision and recall require the system to classify the relation correctly,
whereas unlabeled methods simply measure a system   s ability to detect entities that
are related.

semi-supervised and unsupervised methods are much more dif   cult to evalu-
ate, since they extract totally new relations from the web or a large text. because
these methods use very large amounts of text, it is generally not possible to run them
solely on a small labeled test set, and as a result it   s not possible to pre-annotate a
gold set of correct instances of relations.

for these methods it   s possible to approximate (only) precision by drawing a
random sample of relations from the output, and having a human check the accuracy
of each of these relations. usually this approach focuses on the tuples to be extracted
from a body of text rather than on the relation mentions; systems need not detect
every mention of a relation to be scored correctly. instead, the evaluation is based
on the set of tuples occupying the database when the system is    nished. that is,
we want to know if the system can discover that ryanair has a hub at charleroi; we
don   t really care how many times it discovers it. the estimated precision   p is then

  p =

# of correctly extracted relation tuples in the sample

total # of extracted relation tuples in the sample.

(17.14)

another approach that gives us a little bit of information about recall is to com-
pute precision at different levels of recall. assuming that our system is able to
rank the relations it produces (by id203, or con   dence) we can separately com-
pute precision for the top 1000 new relations, the top 10,000 new relations, the top
100,000, and so on. in each case we take a random sample of that set. this will
show us how the precision curve behaves as we extract more and more tuples. but
there is no way to directly evaluate recall.

17.3 extracting times

times and dates are a particularly important kind of named entity that play a role
in id53, in calendar and personal assistant applications. in order to
reason about times and dates, after we extract these temporal expressions they must
be normalized   converted to a standard format so we can reason about them. in this
section we consider both the extraction and id172 of temporal expressions.

17.3

    extracting times

19

absolute
relative

duration

17.3.1 temporal expression extraction
temporal expressions are those that refer to absolute points in time, relative times,
durations, and sets of these. absolute temporal expressions are those that can be
mapped directly to calendar dates, times of day, or both. relative temporal expres-
sions map to particular times through some other reference point (as in a week from
last tuesday). finally, durations denote spans of time at varying levels of granular-
ity (seconds, minutes, days, weeks, centuries, etc.). figure 17.18 lists some sample
temporal expressions in each of these categories.

absolute
april 24, 1916
the summer of    77
10:15 am
the 3rd quarter of 2006
figure 17.18 examples of absolute, relational and durational temporal expressions.

relative
yesterday
next semester
two weeks from yesterday
last quarter

durations
four hours
three weeks
six days
the last three quarters

lexical triggers

temporal expressions are grammatical constructions that have temporal lexical
triggers as their heads. lexical triggers might be nouns, proper nouns, adjectives,
and adverbs; full temporal expressions consist of their phrasal projections: noun
phrases, adjective phrases, and adverbial phrases. figure 17.19 provides examples.

examples
morning, noon, night, winter, dusk, dawn

category
noun
proper noun january, monday, ides, easter, rosh hashana, ramadan, tet
adjective
adverb
figure 17.19 examples of temporal lexical triggers.

recent, past, annual, former
hourly, daily, monthly, yearly

let   s look at the timeml annotation scheme, in which temporal expressions are
annotated with an xml tag, timex3, and various attributes to that tag (pustejovsky
et al. 2005, ferro et al. 2005). the following example illustrates the basic use of this
scheme (we defer discussion of the attributes until section 17.3.2).

a fare increase initiated <timex3>last week</timex3> by ual
corp   s united airlines was matched by competitors over <timex3>the
weekend</timex3>, marking the second successful fare increase in
<timex3>two weeks</timex3>.

the temporal expression recognition task consists of    nding the start and end of
all of the text spans that correspond to such temporal expressions. rule-based ap-
proaches to temporal expression recognition use cascades of automata to recognize
patterns at increasing levels of complexity. tokens are    rst part-of-speech tagged,
and then larger and larger chunks are recognized from the results from previous
stages, based on patterns containing trigger words (e.g., february) or classes (e.g.,
month). figure 17.20 gives a fragment from a rule-based system.

sequence-labeling approaches follow the same iob scheme used for named-
entity tags, marking words that are either inside, outside or at the beginning of a
timex3-delimited temporal expression with the i, o, and b tags as follows:

a
o

fare
o

increase
o

initiated
o

last
b

week
i

by
o

ual
o

corp   s...
o

20 chapter 17

   

information extraction

# yesterday/today/tomorrow
$string =   s/((($ot+the$ct+\s+)?$ot+day$ct+\s+$ot+(before|after)$ct+\s+)?$ot+$tereldayexpr$ct+
(\s+$ot+(morning|afternoon|evening|night)$ct+)?)/<timex$tever type=\"date\">$1
<\/timex$tever>/gio;

$string =   s/($ot+\w+$ct+\s+)<timex$tever type=\"date\"[  >]*>($ot+(today|tonight)$ct+)
<\/timex$tever>/$1$4/gso;

# this (morning/afternoon/evening)
$string =   s/(($ot+(early|late)$ct+\s+)?$ot+this$ct+\s*$ot+(morning|afternoon|evening)$ct+)/

<timex$tever type=\"date\">$1<\/timex$tever>/gosi;

$string =   s/(($ot+(early|late)$ct+\s+)?$ot+last$ct+\s*$ot+night$ct+)/<timex$tever

type=\"date\">$1<\/timex$tever>/gsio;

figure 17.20 perl fragment from the gutime temporal tagging system in tarsqi (verhagen et al., 2005).

features are extracted from the token and its context, and a statistical sequence
labeler is trained (any sequence model can be used). figure 17.21 lists standard
features used in temporal tagging.

explanation
the target token to be labeled

feature
token
tokens in window bag of tokens in the window around a target
shape
pos
chunk tags
lexical triggers
figure 17.21 typical features used to train iob-style temporal expression taggers.

character shape features
parts of speech of target and window words
base-phrase chunk tag for target and words in a window
presence in a list of temporal terms

temporal expression recognizers are evaluated with the usual recall, precision,
and f-measures. a major dif   culty for all of these very lexicalized approaches is
avoiding expressions that trigger false positives:
(17.15) 1984 tells the story of winston smith...
(17.16) ...u2   s classic sunday bloody sunday

17.3.2 temporal id172
temporal id172 is the process of mapping a temporal expression to either
a speci   c point in time or to a duration. points in time correspond to calendar dates,
to times of day, or both. durations primarily consist of lengths of time but may also
include information about start and end points. normalized times are represented
with the value attribute from the iso 8601 standard for encoding temporal values
(iso8601, 2004). fig. 17.22 reproduces our earlier example with the value attributes
added in.

temporal
id172

<timex3 i d =         t 1        

t y p e =   date    v a l u e =   2007   07   02    f u n c t i o n i n d o c u m e n t =   creation time   
i n i t i a t e d <timex3 i d =    t 2     t y p e =   date   

> j u l y 2 , 2007 </ timex3> a f a r e
v a l u e =   2007   w26    anchortimeid=    t 1    > l a s t week</ timex3> by u n i t e d a i r l i n e s was
matched by c o m p e t i t o r s o v e r <timex3 i d =    t 3     t y p e =   duration    v a l u e =   p1we   
anchortimeid=    t 1    > t h e weekend </ timex3> , marking t h e second s u c c e s s f u l
i n c r e a s e
weeks </ timex3>.

i n <timex3 i d =    t 4     t y p e =   duration    v a l u e =   p2w    anchortimeid=    t 1    > two

i n c r e a s e

f a r e

figure 17.22 timeml markup including normalized values for temporal expressions.

the dateline, or document date, for this text was july 2, 2007. the iso repre-
sentation for this kind of expression is yyyy-mm-dd, or in this case, 2007-07-02.

17.3

    extracting times

21

the encodings for the temporal expressions in our sample text all follow from this
date, and are shown here as values for the value attribute.

the    rst temporal expression in the text proper refers to a particular week of the
year. in the iso standard, weeks are numbered from 01 to 53, with the    rst week
of the year being the one that has the    rst thursday of the year. these weeks are
represented with the template yyyy-wnn. the iso week for our document date is
week 27; thus the value for last week is represented as    2007-w26   .

the next temporal expression is the weekend. iso weeks begin on monday;
thus, weekends occur at the end of a week and are fully contained within a single
week. weekends are treated as durations, so the value of the value attribute has
to be a length. durations are represented according to the pattern pnx, where n is
an integer denoting the length and x represents the unit, as in p3y for three years
or p2d for two days. in this example, one weekend is captured as p1we. in this
case, there is also suf   cient information to anchor this particular weekend as part of
a particular week. such information is encoded in the anchortimeid attribute.
finally, the phrase two weeks also denotes a duration captured as p2w. there is a
lot more to the various temporal annotation standards   far too much to cover here.
figure 17.23 describes some of the basic ways that other times and durations are
represented. consult iso8601 (2004), ferro et al. (2005), and pustejovsky et al.
(2005) for more details.

unit
fully speci   ed dates
weeks
weekends
24-hour clock times
dates and times
financial quarters
figure 17.23 sample iso patterns for representing various times and durations.

pattern
yyyy-mm-dd
yyyy-wnn
pnwe
hh:mm:ss
yyyy-mm-ddthh:mm:ss
qn

sample value
1991-09-28
2007-w27
p1we
11:13:45
1991-09-28t11:00:00
1999-q3

fully quali   ed

most current approaches to temporal id172 are rule-based (chang and
manning 2012, str  otgen and gertz 2013). patterns that match temporal expres-
sions are associated with semantic analysis procedures. as in the compositional
rule-to-rule approach introduced in chapter 15, the meaning of a constituent is com-
puted from the meaning of its parts using a method speci   c to the constituent, al-
though here the semantic composition rules involve temporal arithmetic rather than
   -calculus attachments.

fully quali   ed date expressions contain a year, month, and day in some con-
ventional form. the units in the expression must be detected and then placed in the
correct place in the corresponding iso pattern. the following pattern normalizes
expressions like april 24, 1916.

fqte     month date , year

{year.val     month.val     date.val}

the non-terminals month, date, and year represent constituents that have already
been recognized and assigned semantic values, accessed through the *.val notation.
the value of this fqe constituent can, in turn, be accessed as fqte.val during
further processing.

fully quali   ed temporal expressions are fairly rare in real texts. most temporal
expressions in news articles are incomplete and are only implicitly anchored, of-
ten with respect to the dateline of the article, which we refer to as the document   s

22 chapter 17

   

information extraction

temporal
anchor

temporal anchor. the values of temporal expressions such as today, yesterday, or
tomorrow can all be computed with respect to this temporal anchor. the semantic
procedure for today simply assigns the anchor, and the attachments for tomorrow
and yesterday add a day and subtract a day from the anchor, respectively. of course,
given the cyclic nature of our representations for months, weeks, days, and times of
day, our temporal arithmetic procedures must use modulo arithmetic appropriate to
the time unit being used.

unfortunately, even simple expressions such as the weekend or wednesday in-
troduce a fair amount of complexity. in our current example, the weekend clearly
refers to the weekend of the week that immediately precedes the document date. but
this won   t always be the case, as is illustrated in the following example.
(17.17) random security checks that began yesterday at sky harbor will continue

at least through the weekend.

in this case, the expression the weekend refers to the weekend of the week that the
anchoring date is part of (i.e., the coming weekend). the information that signals
this meaning comes from the tense of continue, the verb governing the weekend.

relative temporal expressions are handled with temporal arithmetic similar to
that used for today and yesterday. the document date indicates that our example
article is iso week 27, so the expression last week normalizes to the current week
minus 1. to resolve ambiguous next and last expressions we consider the distance
from the anchoring date to the nearest unit. next friday can refer either to the
immediately next friday or to the friday following that, but the closer the document
date is to a friday, the more likely it is that the phrase will skip the nearest one. such
ambiguities are handled by encoding language and domain-speci   c heuristics into
the temporal attachments.

17.4 extracting events and their times

event
extraction

the task of event extraction is to identify mentions of events in texts. for the
purposes of this task, an event mention is any expression denoting an event or state
that can be assigned to a particular point, or interval, in time. the following markup
of the sample text on page 19 shows all the events in this text.

[event citing] high fuel prices, united airlines [event said] fri-
day it has [event increased] fares by $6 per round trip on    ights to
some cities also served by lower-cost carriers. american airlines, a unit
of amr corp., immediately [event matched]
[event the move],
spokesman tim wagner [event said]. united, a unit of ual corp.,
[event said] [event the increase] took effect thursday and [event
applies] to most routes where it [event competes] against discount
carriers, such as chicago to dallas and denver to san francisco.

in english, most event mentions correspond to verbs, and most verbs introduce
events. however, as we can see from our example, this is not always the case. events
can be introduced by noun phrases, as in the move and the increase, and some verbs
fail to introduce events, as in the phrasal verb took effect, which refers to when the
event began rather than to the event itself. similarly, light verbs such as make, take,
and have often fail to denote events; for light verbs the event is often expressed by
the nominal direct object (took a    ight), and these light verbs just provide a syntactic
structure for the noun   s arguments.

17.4

    extracting events and their times

23

reporting
events

various versions of the event extraction task exist, depending on the goal. for
example in the tempeval shared tasks (verhagen et al. 2009) the goal is to extract
events and aspects like their aspectual and temporal properties. events are to be
classi   ed as actions, states, reporting events (say, report, tell, explain), perception
events, and so on. the aspect, tense, and modality of each event also needs to be
extracted. thus for example the various said events in the sample text would be
annotated as (class=reporting, tense=past, aspect=perfective).

event extraction is generally modeled via supervised learning, detecting events
via sequence models with iob tagging, and assigning event classes and attributes
with multi-class classi   ers. common features include surface information like parts
of speech, lexical items, and verb tense information; see fig. 17.24.

explanation
character-level pre   xes and suf   xes of target word
character level suf   xes for nominalizations (e.g., -tion)
part of speech of the target word
binary feature indicating that the target is governed by a light verb

feature
character af   xes
nominalization suf   x
part of speech
light verb
subject syntactic category syntactic category of the subject of the sentence
morphological stem
verb root
id138 hypernyms
figure 17.24 features commonly used in both rule-based and machine learning approaches to event detec-
tion.

stemmed version of the target word
root form of the verb basis for a nominalization
hypernym set for the target

17.4.1 temporal ordering of events
with both the events and the temporal expressions in a text having been detected, the
next logical task is to use this information to    t the events into a complete timeline.
such a timeline would be useful for applications such as id53 and
summarization. this ambitious task is the subject of considerable current research
but is beyond the capabilities of current systems.

a somewhat simpler, but still useful, task is to impose a partial ordering on the
events and temporal expressions mentioned in a text. such an ordering can provide
many of the same bene   ts as a true timeline. an example of such a partial ordering
is the determination that the fare increase by american airlines came after the fare
increase by united in our sample text. determining such an ordering can be viewed
as a binary relation detection and classi   cation task similar to those described earlier
in section 17.2. the temporal relation between events is classi   ed into one of the
standard set of allen relations shown in fig. 17.25 (allen, 1984), using feature-
based classi   ers as in section 17.2, trained on the timebank corpus with features
like words/embeddings, parse paths, tense and aspect.

the timebank corpus consists of text annotated with much of the information
we   ve been discussing throughout this section (pustejovsky et al., 2003b). time-
bank 1.2 consists of 183 news articles selected from a variety of sources, including
the id32 and propbank collections.

each article in the timebank corpus has had the temporal expressions and event
mentions in them explicitly annotated in the timeml annotation (pustejovsky et al.,
2003a).
in addition to temporal expressions and events, the timeml annotation
provides temporal links between events and temporal expressions that specify the
nature of the relation between them. consider the following sample sentence and

allen relations

timebank

24 chapter 17

   

information extraction

figure 17.25 the 13 temporal relations from allen (1984).

<timex3 tid="t57" type="date" value="1989-10-26"
10/26/89 </timex3>

functionindocument="creation_time">

<timex3 tid="t58" type="date" value="1989-q1" anchortimeid="t57"> the

delta air lines earnings <event eid="e1" class="occurrence"> soared </event> 33% to a
record in
fiscal first quarter </timex3>, <event eid="e3"
the industry trend toward <event eid="e4" class="occurrence">declining</event>
profits.

class="occurrence">bucking</event>

figure 17.26 example from the timebank corpus.

its corresponding markup shown in fig. 17.26, selected from one of the timebank
documents.
(17.18) delta air lines earnings soared 33% to a record in the    scal    rst quarter,

bucking the industry trend toward declining pro   ts.

as annotated, this text includes three events and two temporal expressions. the
events are all in the occurrence class and are given unique identi   ers for use in fur-
ther annotations. the temporal expressions include the creation time of the article,
which serves as the document time, and a single temporal expression within the text.
in addition to these annotations, timebank provides four links that capture the
temporal relations between the events and times in the text, using the allen relations
from fig. 17.25. the following are the within-sentence temporal relations annotated
for this example.

bababaaabbabtime a  before bb after  aa overlaps bb overlaps' aa meets bb meets' aa equals b(b equals a)a starts bb starts' aa finishes bb finishes' aba during bb during' aa17.5

    template filling

25

    soaringe1 is included in the    scal    rst quartert58
    soaringe1 is before 1989-10-26t57
    soaringe1 is simultaneous with the buckinge3
    declininge4 includes soaringe1

17.5 template filling

scripts

templates

template    lling

many texts contain reports of events, and possibly sequences of events, that often
correspond to fairly common, stereotypical situations in the world. these abstract
situations or stories, related to what have been called scripts (schank and abel-
son, 1977), consist of prototypical sequences of sub-events, participants, and their
roles. the strong expectations provided by these scripts can facilitate the proper
classi   cation of entities, the assignment of entities into roles and relations, and most
critically, the drawing of id136s that    ll in things that have been left unsaid. in
their simplest form, such scripts can be represented as templates consisting of    xed
sets of slots that take as values slot-   llers belonging to particular classes. the task
of template    lling is to    nd documents that invoke particular scripts and then    ll the
slots in the associated templates with    llers extracted from the text. these slot-   llers
may consist of text segments extracted directly from the text, or they may consist of
concepts that have been inferred from text elements through some additional pro-
cessing.

a    lled template from our original airline story might look like the following.

fare-raise attempt:                

lead airline:
amount:
effective date:
follower:

united airlines
$6
2006-10-26
american airlines

               

this template has four slots (lead airline, amount, effective date, fol-
lower). the next section describes a standard sequence-labeling approach to    lling
slots. section 17.5.2 then describes an older system based on the use of cascades of
   nite-state transducers and designed to address a more complex template-   lling task
that current learning-based systems don   t yet address.

17.5.1 machine learning approaches to template filling
in the standard paradigm for template    lling, we are trying to    ll    xed known tem-
plates with known slots, and also assumes training documents labeled with examples
of each template, and the    llers of each slot marked in the text. the is to create one
template for each event in the input documents, with the slots    lled with text from
the document.

the task is generally modeled by training two separate supervised systems. the
   rst system decides whether the template is present in a particular sentence. this
task is called template recognition or sometimes, in a perhaps confusing bit of
terminology, event recognition. template recognition can be treated as a text classi-
   cation task, with features extracted from every sequence of words that was labeled
in training documents as    lling any slot from the template being detected. the usual
set of features can be used: tokens, embeddings, word shapes, part-of-speech tags,
syntactic chunk tags, and named entity tags.

template
recognition

26 chapter 17

   

information extraction

role-   ller
extraction

the second system has the job of role-   ller extraction. a separate classi   er is
trained to detect each role (lead-airline, amount, and so on). this can be a
binary classi   er that is run on every noun-phrase in the parsed input sentence, or a
sequence model run over sequences of words. each role classi   er is trained on the
labeled data in the training set. again, the usual set of features can be used, but now
trained only on an individual noun phrase or the    llers of a single slot.

multiple non-identical text segments might be labeled with the same slot la-
bel. for example in our sample text, the strings united or united airlines might be
labeled as the lead airline. these are not incompatible choices and the corefer-
ence resolution techniques introduced in chapter 20 can provide a path to a solution.
a variety of annotated collections have been used to evaluate this style of ap-
proach to template    lling, including sets of job announcements, conference calls for
papers, restaurant guides, and biological texts. recent work focuses on extracting
templates in cases where there is no training data or even prede   ned templates, by
inducing templates as sets of linked events (chambers and jurafsky, 2011).

17.5.2 earlier finite-state template-filling systems
the templates above are relatively simple. but consider the task of producing a
template that contained all the information in a text like this one (grishman and
sundheim, 1995):

bridgestone sports co. said friday it has set up a joint venture in taiwan
with a local concern and a japanese trading house to produce golf clubs to be
shipped to japan. the joint venture, bridgestone sports taiwan co., capital-
ized at 20 million new taiwan dollars, will start production in january 1990
with production of 20,000 iron and    metal wood    clubs a month.

the muc-5    joint venture    task (the message understanding conferences were
a series of u.s. government-organized information-extraction evaluations) was to
produce hierarchically linked templates describing joint ventures. figure 17.27
shows a structure produced by the fastus system (hobbs et al., 1997). note how
the    ller of the activity slot of the tie-up template is itself a template with slots.

tie-up-1
relationship
entities

tie-up
bridgestone sports co.
a local concern
a japanese trading house

activity-1:
company
product
start date during: january 1990

bridgestone sports taiwan co.
iron and    metal wood    clubs

joint venture bridgestone sports taiwan co.
activity
amount
figure 17.27 the templates produced by fastus given the input text on page 26.

activity-1
nt$20000000

early systems for dealing with these complex templates were based on cascades

of transducers based on hand-written rules, as sketched in fig. 17.28.

the    rst four stages use hand-written regular expression and grammar rules to
do basic id121, chunking, and parsing. stage 5 then recognizes entities and
events with a fst-based recognizer and inserts the recognized objects into the ap-
propriate slots in templates. this fst recognizer is based on hand-built regular
expressions like the following (ng indicates noun-group and vg verb-group),
which matches the    rst sentence of the news story above.

17.6

    summary

27

no. step
1
2
3
4
5
6

tokens
complex words
basic phrases
complex phrases
semantic patterns
merging

description
tokenize input stream of characters
multiword phrases, numbers, and proper names.
segment sentences into noun and verb groups
identify complex noun groups and verb groups
identify entities and events, insert into templates.
merge references to the same entity or event

figure 17.28 levels of processing in fastus (hobbs et al., 1997). each level extracts a
speci   c type of information which is then passed on to the next higher level.

ng(company/ies) vg(set-up) ng(joint-venture) with ng(company/ies)

vg(produce) ng(product)

the result of processing these two sentences is the    ve draft templates (fig. 17.29)
that must then be merged into the single hierarchical structure shown in fig. 17.27.
the merging algorithm, after performing coreference resolution, merges two activi-
ties that are likely to be describing the same events.

# template/slot
1 relationship:

entities:
2 activity:
product:

3 relationship:

value
tie-up
bridgestone co., a local concern, a japanese trading house
production
   golf clubs   
tie-up

joint venture:    bridgestone sports taiwan co.   
amount:
4 activity:
company:
startdate:

nt$20000000
production
   bridgestone sports taiwan co.   
during: january 1990
production
   iron and    metal wood    clubs   

5 activity:
product:

figure 17.29 the    ve partial templates produced by stage 5 of fastus. these templates
are merged in stage 6 to produce the    nal template shown in fig. 17.27 on page 26.

17.6 summary

this chapter has explored techniques for extracting limited forms of semantic con-
tent from texts.

    named entities can be recognized and classi   ed by featured-based or neural

sequence labeling techniques.

    relations among entities can be extracted by pattern-based approaches, su-
pervised learning methods when annotated training data is available, lightly
supervised id64 methods when small numbers of seed tuples or
seed patterns are available, distant supervision when a database of relations
is available, and unsupervised or open ie methods.

    reasoning about time can be facilitated by detection and id172 of

28 chapter 17

   

information extraction

temporal expressions through a combination of statistical learning and rule-
based methods.

    events can be detected and ordered in time using sequence models and classi-
   ers trained on temporally- and event-labeled data like the timebank corpus.
    template-   lling applications can recognize stereotypical situations in texts
and assign elements from the text to roles represented as    xed sets of slots.

bibliographical and historical notes

the earliest work on information extraction addressed the template-   lling task in the
context of the frump system (dejong, 1982). later work was stimulated by the u.s.
government-sponsored muc conferences (sundheim 1991, sundheim 1992, sund-
heim 1993, sundheim 1995). early muc systems like circus system (lehnert
et al., 1991) and scisor (jacobs and rau, 1990) were quite in   uential and inspired
later systems like fastus (hobbs et al., 1997). chinchor et al. (1993) describe the
muc evaluation techniques.

due to the dif   culty of porting systems from one domain to another, attention

shifted to machine learning approaches.

early supervised learning approaches to ie ( cardie 1993, cardie 1994, riloff 1993,

soderland et al. 1995, huffman 1996) focused on automating the knowledge acqui-
sition process, mainly for    nite-state rule-based systems. their success, and the
earlier success of id48-based id103, led to the use of sequence la-
beling (id48s: bikel et al. 1997; memms mccallum et al. 2000; crfs: laf-
ferty et al. 2001), and a wide exploration of features (zhou et al., 2005). neural
approaches to ner mainly follow from the pioneering results of collobert et al.
(2011), who applied a crf on top of a convolutional net. bilstms with word and
character-based embeddings as input followed shortly and became a standard neural
algorithm for ner (huang et al. 2015, ma and hovy 2016, lample et al. 2016).

neural algorithms for id36 often explore architectures that can
handle entities far apart in the sentence: recursive networks (socher et al., 2012),
convolutional nets (dos santos et al., 2015), or chain or tree lstms (miwa and
bansal 2016, peng et al. 2017).

progress in this area continues to be stimulated by formal evaluations with shared
benchmark datasets, including the automatic content extraction (ace) evaluations
of 2000-2007 on id39, id36, and temporal ex-
pressions3, the kbp (knowledge base population) evaluations (ji et al. 2010, sur-
deanu 2013) of id36 tasks like slot    lling (extracting attributes (   slots   )
like age, birthplace, and spouse for a given entity) and a series of semeval work-
shops (hendrickx et al., 2009).

semisupervised id36 was    rst proposed by hearst (1992b), and
extended by systems like autoslog-ts (riloff, 1996), dipre (brin, 1998), snow-
ball (agichtein and gravano, 2000), and (jones et al., 1999). the distant super-
vision algorithm we describe was drawn from mintz et al. (2009), who coined the
term    distant supervision   , but similar ideas occurred in earlier systems like craven
and kumlien (1999) and morgan et al. (2004) under the name weakly labeled data,
as well as in snow et al. (2005) and wu and weld (2007). among the many exten-

3 www.nist.gov/speech/tests/ace/

kbp
slot    lling

exercises

29

sions are wu and weld (2010), riedel et al. (2010), and ritter et al. (2013). open
ie systems include knowitall etzioni et al. (2005), textrunner (banko et al.,
2007), and reverb (fader et al., 2011). see riedel et al. (2013) for a universal
schema that combines the advantages of distant supervision and open ie.

heideltime (str  otgen and gertz, 2013) and sutime (chang and manning, 2012)
are downloadable temporal extraction and id172 systems. the 2013 tempe-
val challenge is described in uzzaman et al. (2013); chambers (2013) and bethard
(2013) give typical approaches.

exercises

17.1 develop a set of id157 to recognize the character shape features

described on page 5.

17.2 the iob labeling scheme given in this chapter isn   t the only possible one. for
example, an e tag might be added to mark the end of entities, or the b tag
can be reserved only for those situations where an ambiguity exists between
adjacent entities. propose a new set of iob tags for use with your ner system.
experiment with it and compare its performance with the scheme presented
in this chapter.

17.3 names of works of art (books, movies, video games, etc.) are quite different
from the kinds of named entities we   ve discussed in this chapter. collect a
list of names of works of art from a particular category from a web-based
source (e.g., gutenberg.org, amazon.com, imdb.com, etc.). analyze your list
and give examples of ways that the names in it are likely to be problematic for
the techniques described in this chapter.

17.4 develop an ner system speci   c to the category of names that you collected in
the last exercise. evaluate your system on a collection of text likely to contain
instances of these named entities.

17.5 acronym expansion, the process of associating a phrase with an acronym, can
be accomplished by a simple form of relational analysis. develop a system
based on the relation analysis approaches described in this chapter to populate
if you focus on english three letter
a database of acronym expansions.
acronyms (tlas) you can evaluate your system   s performance by comparing
it to wikipedia   s tla page.

17.6 a useful functionality in newer email and calendar applications is the ability
to associate temporal expressions connected with events in email (doctor   s
appointments, meeting planning, party invitations, etc.) with speci   c calendar
entries. collect a corpus of email containing temporal expressions related to
event planning. how do these expressions compare to the kinds of expressions
commonly found in news text that we   ve been discussing in this chapter?

17.7 acquire the cmu seminar corpus and develop a template-   lling system by
using any of the techniques mentioned in section 17.5. analyze how well
your system performs as compared with state-of-the-art results on this corpus.

30 chapter 17    

information extraction

agichtein, e. and gravano, l. (2000). snowball: extract-
ing relations from large plain-text collections. in proceed-
ings of the 5th acm international conference on digital
libraries.

allen, j. (1984). towards a general theory of action and time.

arti   cial intelligence, 23(2), 123   154.

banko, m., cafarella, m., soderland, s., broadhead, m., and
etzioni, o. (2007). id10 for the
web. in ijcai, vol. 7, pp. 2670   2676.

bethard, s. (2013). cleartk-timeml: a minimalist ap-

proach to tempeval 2013. in semeval-13, pp. 10   14.

bikel, d. m., miller, s., schwartz, r., and weischedel,
r. (1997). nymble: a high-performance learning name-
   nder. in anlp 1997, pp. 194   201.

bizer, c., lehmann, j., kobilarov, g., auer, s., becker, c.,
cyganiak, r., and hellmann, s. (2009). dbpedia   a crys-
tallization point for the web of data. web semantics: sci-
ence, services and agents on the world wide web, 7(3),
154   165.

bollacker, k., evans, c., paritosh, p., sturge, t., and tay-
lor, j. (2008). freebase: a collaboratively created graph
in sigmod
database for structuring human knowledge.
2008, pp. 1247   1250.

brin, s. (1998). extracting patterns and relations from
in proceedings world wide web
the world wide web.
and databases international workshop, number 1590 in
lncs, pp. 172   183. springer.

cardie, c. (1993). a case-based approach to knowledge ac-
quisition for domain speci   c sentence analysis. in aaai-
93, pp. 798   803. aaai press.

cardie, c. (1994). domain-speci   c knowledge acquisition
for conceptual sentence analysis. ph.d. thesis, university
of massachusetts, amherst, ma. available as cmpsci
technical report 94-74.

chambers, n. (2013). navytime: event and time ordering

from raw text. in semeval-13, pp. 73   77.

chambers, n. and jurafsky, d. (2011). template-based in-
formation extraction without the templates. in acl 2011.
chang, a. x. and manning, c. d. (2012). sutime: a li-
brary for recognizing and normalizing time expressions..
in lrec-12, pp. 3735   3740.

chinchor, n., hirschman, l., and lewis, d. l. (1993). eval-
uating message understanding systems: an analysis of the
third message understanding conference. computational
linguistics, 19(3), 409   449.

chiticariu, l., danilevsky, m., li, y., reiss, f., and zhu, h.
(2018). systemt: declarative text understanding for enter-
prise. in naacl hlt 2018, vol. 3, pp. 76   83.

chiticariu, l., li, y., and reiss, f. r. (2013). rule-based
information extraction is dead! long live rule-based in-
formation extraction systems!. in emnlp 2013, pp. 827   
832.

cohen, k. b. and demner-fushman, d. (2014). biomedical

natural language processing. benjamins.

collobert, r., weston,

j., bottou, l., karlen, m.,
kavukcuoglu, k., and kuksa, p. (2011). natural language
processing (almost) from scratch. the journal of machine
learning research, 12, 2493   2537.

craven, m. and kumlien, j. (1999). constructing biolog-
ical knowledge bases by extracting information from text
sources. in ismb-99, pp. 77   86.

dejong, g. f. (1982). an overview of the frump system.
in lehnert, w. g. and ringle, m. h. (eds.), strategies for
natural language processing, pp. 149   176. lawrence erl-
baum.

dos santos, c., xiang, b., and zhou, b. (2015). classifying
relations by ranking with convolutional neural networks. in
acl 2015.

etzioni, o., cafarella, m., downey, d., popescu, a.-m.,
shaked, t., soderland, s., weld, d. s., and yates, a.
(2005). unsupervised named-entity extraction from the
web: an experimental study. arti   cial intelligence, 165(1),
91   134.

fader, a., soderland, s., and etzioni, o. (2011). identifying
relations for id10. in emnlp-11,
pp. 1535   1545.

ferro, l., gerber, l., mani, i., sundheim, b., and wilson, g.
(2005). tides 2005 standard for the annotation of temporal
expressions. tech. rep., mitre.

grishman, r. and sundheim, b. (1995). design of the muc-

6 evaluation. in muc-6, san francisco, pp. 1   11.

hearst, m. a. (1992a). automatic acquisition of hyponyms

from large text corpora. in coling-92, nantes, france.

hearst, m. a. (1992b). automatic acquisition of hyponyms
from large text corpora. in coling-92, nantes, france.
coling.

hearst, m. a. (1998). automatic discovery of id138 re-
in fellbaum, c. (ed.), id138: an electronic

lations.
lexical database. mit press.

hendrickx,
i., kim, s. n., kozareva, z., nakov, p.,
  o s  eaghdha, d., pad  o, s., pennacchiotti, m., romano, l.,
and szpakowicz, s. (2009). semeval-2010 task 8: multi-
way classi   cation of semantic relations between pairs of
in proceedings of the workshop on semantic
nominals.
evaluations: recent achievements and future directions,
pp. 94   99.

hobbs, j. r., appelt, d. e., bear, j., israel, d., kameyama,
m., stickel, m. e., and tyson, m. (1997). fastus: a
cascaded    nite-state transducer for extracting information
from natural-language text.
in roche, e. and schabes,
y. (eds.), finite-state language processing, pp. 383   406.
mit press.

huang, z., xu, w., and yu, k. (2015). bidirectional lstm-
in arxiv preprint

crf models for sequence tagging.
arxiv:1508.01991.

huffman, s. (1996). learning information extraction pat-
terns from examples.
in wertmer, s., riloff, e., and
scheller, g. (eds.), connectionist, statistical, and sym-
bolic approaches to learning natural language process-
ing, pp. 246   260. springer.

iso8601 (2004). data elements and interchange formats   
information interchange   representation of dates and
times. tech. rep., international organization for standards
(iso).

jacobs, p. s. and rau, l. f. (1990). scisor: a system
for extracting information from on-line news. communi-
cations of the acm, 33(11), 88   97.

ji, h., grishman, r., and dang, h. t. (2010). overview of
the tac 2011 knowledge base population track. in tac-11.

exercises

31

riloff, e. (1996). automatically generating extraction pat-

terns from untagged text. in aaai-96, pp. 117   124.

riloff, e. and jones, r. (1999). learning dictionaries for
in

information extraction by multi-level id64.
aaai-99, pp. 474   479.

ritter, a., zettlemoyer, l., mausam, and etzioni, o. (2013).
modeling missing data in distant supervision for informa-
tion extraction.. tacl, 1, 367   378.

schank, r. c. and abelson, r. p. (1977). scripts, plans,

goals and understanding. lawrence erlbaum.

snow, r., jurafsky, d., and ng, a. y. (2005). learning syn-
tactic patterns for automatic hypernym discovery. in saul,
l. k., weiss, y., and bottou, l. (eds.), nips 17, pp. 1297   
1304. mit press.

socher, r., huval, b., manning, c. d., and ng, a. y. (2012).
semantic compositionality through recursive matrix-vector
spaces. in emnlp 2012, pp. 1201   1211.

soderland, s., fisher, d., aseltine, j., and lehnert, w. g.
(1995). crystal: inducing a conceptual dictionary. in
ijcai-95, montreal, pp. 1134   1142.

str  otgen, j. and gertz, m. (2013). multilingual and cross-
domain temporal tagging. language resources and eval-
uation, 47(2), 269   298.

sundheim, b. (ed.). (1991). proceedings of muc-3.
sundheim, b. (ed.). (1992). proceedings of muc-4.
sundheim, b. (ed.). (1993). proceedings of muc-5, balti-

more, md.

sundheim, b. (ed.). (1995). proceedings of muc-6.
surdeanu, m. (2013). overview of the tac2013 knowledge
base population evaluation: english slot    lling and tempo-
ral slot    lling. in tac-13.

uzzaman, n., llorens, h., derczynski, l., allen, j., ver-
hagen, m., and pustejovsky, j. (2013). semeval-2013 task
1: tempeval-3: evaluating time expressions, events, and
temporal relations. in semeval-13, pp. 1   9.

verhagen, m., gaizauskas, r., schilder, f., hepple, m.,
moszkowicz, j., and pustejovsky, j. (2009). the tempeval
challenge: identifying temporal relations in text. language
resources and evaluation, 43(2), 161   179.

verhagen, m., mani, i., sauri, r., knippen, r., jang, s. b.,
littman, j., rumshisky, a., phillips, j., and pustejovsky,
j. (2005). automating temporal annotation with tarsqi. in
acl-05, pp. 81   84.

wu, f. and weld, d. s. (2007). autonomously semantifying

wikipedia. in cikm-07, pp. 41   50.

wu, f. and weld, d. s. (2010). id10

using wikipedia. in acl 2010, pp. 118   127.

zhou, g., su, j., zhang, j., and zhang, m. (2005). exploring
various knowledge in id36. in acl-05, ann
arbor, mi, pp. 427   434.

jones, r., mccallum, a., nigam, k., and riloff, e. (1999).
id64 for text learning tasks. in ijcai-99 work-
shop on id111: foundations, techniques and appli-
cations.

lafferty, j. d., mccallum, a., and pereira, f. c. n. (2001).
conditional random    elds: probabilistic models for seg-
menting and labeling sequence data. in icml 2001, stan-
ford, ca.

lample, g., ballesteros, m., subramanian, s., kawakami,
k., and dyer, c. (2016). neural architectures for named
entity recognition. in naacl hlt 2016.

lehnert, w. g., cardie, c., fisher, d., riloff, e., and
williams, r. (1991). description of the circus system
as used for muc-3. in sundheim, b. (ed.), muc-3, pp.
223   233.

ma, x. and hovy, e. h. (2016). end-to-end sequence label-

ing via bi-directional lstm-id98s-crf. in acl 2016.

mccallum, a., freitag, d., and pereira, f. c. n. (2000).
maximum id178 markov models for information extrac-
tion and segmentation. in icml 2000, pp. 591   598.

mikheev, a., moens, m., and grover, c. (1999). named en-
tity recognition without gazetteers. in eacl-99, bergen,
norway, pp. 1   8.

mintz, m., bills, s., snow, r., and jurafsky, d. (2009).
distant supervision for id36 without labeled
data. in acl ijcnlp 2009.

miwa, m. and bansal, m. (2016). end-to-end relation ex-
in

traction using lstms on sequences and tree structures.
acl 2016, pp. 1105   1116.

morgan, a. a., hirschman, l., colosimo, m., yeh, a. s.,
and colombe, j. b. (2004). gene name identi   cation and
id172 using a model organism database. journal
of biomedical informatics, 37(6), 396   410.

peng, n., poon, h., quirk, c., toutanova, k., and yih, w.-t.
(2017). cross-sentence n-ary id36 with graph
lstms. tacl, 5, 101   115.

pustejovsky, j., casta  no, j., ingria, r., saur    , r., gaizauskas,
r., setzer, a., and katz, g. (2003a). timeml: robust spec-
i   cation of event and temporal expressions in text. in pro-
ceedings of the 5th international workshop on computa-
tional semantics (iwcs-5).

pustejovsky, j., hanks, p., saur    , r., see, a., gaizauskas,
r., setzer, a., radev, d., sundheim, b., day, d. s., ferro,
l., and lazo, m. (2003b). the timebank corpus.
in
proceedings of corpus linguistics 2003 conference, pp.
647   656. ucrel technical paper number 16.

pustejovsky, j., ingria, r., saur    , r., casta  no, j., littman, j.,
gaizauskas, r., setzer, a., katz, g., and mani, i. (2005).
the speci   cation language timeml, chap. 27. oxford.

riedel, s., yao, l., and mccallum, a. (2010). modeling
relations and their mentions without labeled text. in ma-
chine learning and knowledge discovery in databases,
pp. 148   163. springer.

riedel, s., yao, l., mccallum, a., and marlin, b. m. (2013).
id36 with id105 and universal
schemas. in naacl hlt 2013.

riloff, e. (1993). automatically constructing a dictionary
for information extraction tasks. in aaai-93, washington,
d.c., pp. 811   816.

