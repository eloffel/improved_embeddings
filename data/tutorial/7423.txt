id147 and the noisy channel
the id147 task
applications for id147
2
web search
phones
word processing
spelling tasks
spelling error detection
spelling error correction:
autocorrect   
hte   the
suggest a correction
suggestion lists
3
types of spelling errors
non-word errors
graffe    giraffe
real-word errors
typographical errors
three    there
cognitive errors (homophones)
piece   peace, 
too     two

4
rates of spelling errors
26%:	web queries  wang et al. 2003 
13%:	retyping, no backspace: whitelaw et al. english&german
7%: words corrected retyping on phone-sized organizer
2%: words uncorrected on organizer soukoreff &mackenzie 2003
1-2%:  retyping: kane and wobbrock 2007, gruden et al. 1983


5
non-word spelling errors
non-word spelling error detection:
any word not in a dictionary is an error
the larger the dictionary the better
non-word spelling error correction:
generate candidates: real words that are similar to error
choose the one which is best:
shortest weighted id153
highest noisy channel id203

6
real word spelling errors
for each word w, generate candidate set:
find candidate words with similar pronunciations
find candidate words with similar spelling
include w in candidate set
choose best candidate
noisy channel 
classifier
7
id147 and the noisy channel
the id147 task
id147 and the noisy channel
the id87 of spelling
noisy channel intuition
10
noisy channel
we see an observation x of a misspelled word
find the correct word w 


11
history: noisy channel for spelling proposed around 1990
ibm
mays, eric, fred j. damerau and robert l. mercer. 1991. context based id147. information processing and management, 23(5), 517   522
at&t bell labs
kernighan, mark d., kenneth w. church, and william a. gale. 1990. a id147 program based on a id87. proceedings of coling 1990, 205-210
non-word spelling error example
acress
13
candidate generation
words with similar spelling
small id153 to error
words with similar pronunciation
small id153 of pronunciation to error
14
damerau-levenshtein id153
minimal id153 between two strings, where edits are:
insertion
deletion
substitution
transposition of two adjacent letters
15
words within 1 of acress
16
candidate generation
80% of errors are within id153 1
almost all errors within id153 2

also allow insertion of space or hyphen
thisidea      this idea
inlaw     in-law


17
language model
use any of the id38 algorithms we   ve learned
unigram, bigram, trigram
web-scale id147
stupid backoff
18
unigram prior id203
19
counts from 404,253,213 words in corpus of contemporary english (coca)

channel model id203
error model id203, edit id203
kernighan, church, gale  1990

misspelled word x = x1, x2, x3    xm
correct word w = w1, w2, w3,   , wn

p(x|w) = id203 of the edit 
(deletion/insertion/substitution/transposition)

20
computing error id203: confusion matrix
del[x,y]:    count(xy typed as x)
ins[x,y]:    count(x typed as xy)
sub[x,y]:    count(x typed as y)
trans[x,y]:  count(xy typed as yx)

insertion and deletion conditioned on previous character

21
confusion matrix for spelling errors
generating the confusion matrix
peter norvig   s list of errors
peter norvig   s list of counts of single-edit errors
23
channel model 
24
kernighan, church, gale 1990
channel model for acress
25
noisy channel id203 for acress
26
noisy channel id203 for acress
27
using a bigram language model
   a stellar and versatile acress whose combination of sass and glamour      
counts from the corpus of contemporary american english with add-1 smoothing
p(actress|versatile)=.000021 p(whose|actress) = .0010
p(across|versatile) =.000021 p(whose|across) = .000006

p(   versatile actress whose   ) = .000021*.0010 = 210 x10-10
p(   versatile across whose   )  = .000021*.000006 = 1 x10-10
28
using a bigram language model
   a stellar and versatile acress whose combination of sass and glamour      
counts from the corpus of contemporary american english with add-1 smoothing
p(actress|versatile)=.000021 p(whose|actress) = .0010
p(across|versatile) =.000021 p(whose|across) = .000006

p(   versatile actress whose   ) = .000021*.0010 = 210 x10-10
p(   versatile across whose   )  = .000021*.000006 = 1 x10-10
29
evaluation
some spelling error test sets
wikipedia   s list of common english misspelling
aspell filtered version of that list
birkbeck spelling error corpus
peter norvig   s list of errors (includes wikipedia and birkbeck, for training or testing)
30
id147 and the noisy channel
the id87 of spelling
id147 and the noisy channel
real-word id147
real-word spelling errors
   leaving in about fifteen minuets to go to her house.
the design an construction of the system   
can they lave him my messages?
the study was conducted mainly be john black.

25-40% of spelling errors are real words     kukich 1992
33
solving real-world spelling errors
for each word in sentence
generate candidate set
the word itself 
all single-letter edits that are english words
words that are homophones
choose best candidates
id87
task-specific classifier
34
noisy channel for real-word spell correction
given a sentence w1,w2,w3,   ,wn
generate a set of candidates for each word wi
candidate(w1) = {w1, w   1 , w      1 , w         1 ,   }
candidate(w2) = {w2, w   2 , w      2 , w         2 ,   }
candidate(wn) = {wn, w   n , w      n , w         n ,   }
choose the sequence w that maximizes p(w)
noisy channel for real-word spell correction
36
noisy channel for real-word spell correction
37
simplification: one error per sentence
out of all possible sentences with one word replaced
w1, w      2,w3,w4       two off thew     
w1,w2,w   3,w4             two of the
w         1,w2,w3,w4          too of thew 
   
choose the sequence w that maximizes p(w)
where to get the probabilities
language model
unigram
bigram
etc
channel model
same as for non-word id147
plus need id203 for no error, p(w|w)

39
id203 of no error
what is the channel id203 for a correctly typed word?
p(   the   |   the   )

obviously this depends on the application
.90 (1 error in 10 words)
.95 (1 error in 20 words)
.99 (1 error in 100 words)
 .995 (1 error in 200 words)

40
peter norvig   s    thew    example
41
id147 and the noisy channel
real-word id147
id147 and the noisy channel
state-of-the-art systems
hci issues in spelling
if very confident in correction
autocorrect
less confident
give the best correction
less confident
give a correction list
unconfident
just flag as an error
44
state of the art noisy channel
we never just multiply the prior and the error model
independence assumptions   probabilities not commensurate
instead: weigh them


learn    from a development test set
45
phonetic error model
metaphone, used in gnu aspell 
convert misspelling to metaphone pronunciation
   drop duplicate adjacent letters, except for c.   
   if the word begins with 'kn', 'gn', 'pn', 'ae', 'wr', drop the first letter.   
   drop 'b' if after 'm' and if it is at the end of the word   
   
find words whose pronunciation is 1-2 id153 from misspelling   s
score result list 
weighted id153 of candidate to misspelling
id153 of candidate pronunciation to misspelling pronunciation


46
improvements to channel model
allow richer edits    (brill and moore 2000)
ent   ant
ph   f
le   al
incorporate pronunciation into channel (toutanova and moore 2002)
47
channel model
factors that could influence p(misspelling|word)
the source letter
the target letter
surrounding letters
the position in the word
nearby keys on the keyboard
homology on the keyboard
pronunciations
likely morpheme transformations

48
nearby keys
classifier-based methods 
for real-word id147
instead of just channel model and language model
use many features in a classifier (next lecture).
build a classifier for a specific pair like:
      whether/weather
   cloudy    within +- 10 words
___ to verb
___ or not

50
id147 and the noisy channel
real-word id147
