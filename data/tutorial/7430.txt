id51

id51 (wsd)
given 
a word in context 
a fixed inventory of potential word senses
decide which sense of the word this is
why? machine translation, qa, id133
what set of senses?
english-to-spanish mt: set of spanish translations
id133:  homographs like bass and bow
in general: the senses in a thesaurus like id138
two variants of wsd task
lexical sample task
small pre-selected set of target words (line, plant)
and inventory of senses for each word
supervised machine learning: train a classifier for each word
all-words task
every word in an entire text
a lexicon with senses for each word
data sparseness: can   t train word-specific classifiers
wsd methods
supervised machine learning
thesaurus/dictionary methods
semi-supervised learning
4
id51
supervised machine learning
supervised machine learning approaches
supervised machine learning approach:
a training corpus of words tagged in context with their sense
used to train a classifier that can tag words in new text
summary of what we need:
the tag set (   sense inventory   )
the training corpus
a set of features extracted from the training corpus
a classifier
supervised wsd 1: wsd tags
what   s a tag?
a dictionary sense?
for example, for id138 an instance of    bass    in a text has 8 possible tags or labels (bass1 through bass8).
8 senses of    bass    in id138
bass - (the lowest part of the musical range)
bass, bass part - (the lowest part in polyphonic  music)
bass, basso - (an adult male singer with the lowest voice)
sea bass, bass - (flesh of lean-fleshed saltwater fish of the family serranidae)
freshwater bass, bass - (any of various north american lean-fleshed freshwater fishes especially of the genus micropterus)
bass, bass voice, basso - (the lowest adult male singing voice)
bass - (the member with the lowest range of a family of musical instruments)
bass - (nontechnical name for any of numerous edible  marine and freshwater spiny-finned fishes)

inventory of sense tags for bass

supervised wsd 2: get a corpus
lexical sample task:
line-hard-serve corpus - 4000 examples of each
interest corpus - 2369 sense-tagged examples
all words:
semantic concordance: a corpus in which each open-class word is labeled with a sense from a specific dictionary/thesaurus.
semcor: 234,000 words from brown corpus, manually tagged with id138 senses
senseval-3 competition corpora - 2081 tagged word tokens

semcor
<wf pos=prp>he</wf>
<wf pos=vb lemma=recognize wnsn=4 lexsn=2:31:00::>recognized</wf>
<wf pos=dt>the</wf>
<wf pos=nn lemma=gesture wnsn=1 lexsn=1:04:00::>gesture</wf>
<punc>.</punc>

11
supervised wsd 3: extract feature vectors
intuition from warren weaver (1955):
   if one examines the words in a book, one at a time as through an opaque mask with a hole in it one word wide, then it is obviously impossible to determine, one at a time, the meaning of the words    
but if one lengthens the slit in the opaque mask, until one can see not only the central word in question but also say n words on either side, then if n is large enough one can unambiguously decide the meaning of the central word    
the practical question is : ``what minimum value of n will, at least in a tolerable fraction of cases, lead to the correct choice of meaning for the central word?   

feature vectors
a simple representation for each observation
(each instance of a target word)
vectors of sets of feature/value pairs
represented as a ordered list of values
these vectors represent, e.g., the window of words around the target
two kinds of features in the vectors
collocational features and bag-of-words features
collocational
features about words at specific positions near target word
often limited to just word identity and pos
bag-of-words
features about words that occur anywhere in the window (regardless of position)
typically limited to frequency counts

examples
example text (wsj):
an electric guitar and bass player stand off to one side not really part of the scene
assume a window of +/- 2 from the target

examples
example text (wsj)
an electric guitar and bass player stand off to one side not really part of the scene, 
assume a window of +/- 2 from the target





collocational features
position-specific information about the words and collocations in window
guitar and bass player stand



word 1,2,3 grams in window of   3 is common





bag-of-words features
   an unordered set of words        position ignored
counts of words occur within the window.
first choose a vocabulary
then count how often each of those terms occurs in a given window
sometimes just a binary    indicator    1 or 0

co-occurrence example
assume we   ve settled on a possible vocabulary of 12 words in    bass    sentences: 

[fishing, big, sound, player, fly, rod, pound, double, runs, playing, guitar, band] 

the vector for:
	guitar and bass player stand
	[0,0,0,1,0,0,0,0,0,0,1,0] 



id51
classification
classification: definition
classification methods:
supervised machine learning
input: 
a word w in a text window d (which we   ll call a    document   )
 a fixed set of classes  c = {c1, c2,   , cj}
a training set of m hand-labeled text windows again called    documents    (d1,c1),....,(dm,cm)
output: 
a learned classifier   :d     c
22
classification methods:
supervised machine learning
any kind of classifier
naive bayes
id28
neural networks
support-vector machines
k-nearest neighbors

   
applying naive bayes to wsd
p(c) is the prior id203 of that sense
counting in a labeled training set.
p(w|c)  id155 of a word given a particular sense
p(w|c) = count(w,c)/count(c)
we get both of these from a tagged corpus like semcor

can also generalize to look at other features besides words.
then it would be p(f|c) 
id155 of a feature given a sense
choosing a class:
p(f|d5) 



p(g|d5) 



 1/4 * 2/9 * (2/9)2 * 2/9  
	    0.0006
25
conditional probabilities:
p(line|f) =
p(guitar|f)    =
p(jazz|f)     =
p(line|g) =
p(guitar|g)     =
p(jazz|g)      = 
priors:
p(f)= 

p(g)= 
3

4
1

4
(1+1) / (8+6) = 2/14
(0+1) / (8+6) = 1/14
(1+1) / (3+6) = 2/9 
(0+1) / (8+6) = 1/14
(1+1) / (3+6) = 2/9 
(1+1) / (3+6) = 2/9 
 3/4 * 2/14 * (1/14)2 * 1/14 
	    0.00003
v = {fish, smoked, line, haul, guitar, jazz}

id51
evaluations and baselines
wsd evaluations and baselines
best evaluation: extrinsic (   end-to-end   , `task-based   ) evaluation
embed wsd algorithm in a task and see if you can do the task better!
what we often do for convenience: intrinsic evaluation
exact match sense accuracy
% of words tagged identically with the human-manual sense tags
usually evaluate using held-out data from same labeled corpus
baselines
most frequent sense
the lesk algorithm
most frequent sense
id138 senses are ordered in frequency order
so    most frequent sense    in id138 =    take the first sense   
sense frequencies come from the semcor corpus
ceiling
human inter-annotator agreement
compare annotations of two humans
on same data
given same tagging guidelines
human agreements on all-words corpora with id138 style senses
75%-80% 
id51
dictionary and thesaurus methods
the simplified lesk algorithm
let   s disambiguate    bank    in this sentence:
the bank can guarantee deposits will eventually cover future tuition costs because it invests in adjustable-rate mortgage securities. 
given the following two id138 senses: 

the simplified lesk algorithm
the bank can guarantee deposits will eventually cover future tuition costs because it invests in adjustable-rate mortgage securities. 





choose sense with most word overlap between gloss and context
(not counting function words)
the corpus lesk algorithm
assumes we have some sense-labeled data (like semcor)
take all the sentences with the relevant word sense:
these short, "streamlined" meetings usually are sponsored by local banks1, chambers of commerce, trade associations, or other civic organizations.
now add these to the gloss + examples for each sense, call it the    signature    of a sense.
choose sense with most word overlap between context and signature.

corpus lesk: idf weighting
instead of just removing function words
weigh each word by its `promiscuity    across documents
down-weights words that occur in every `document    (gloss, example, etc)
these are generally function words, but is a more fine-grained measure
weigh each overlapping word by inverse document frequency




34
corpus lesk: idf weighting
weigh each overlapping word by inverse document frequency
n is the total number of documents
dfi =    document frequency of word i   
    = # of documents with word i





35
graph-based methods
first, id138 can be viewed as a graph
senses are nodes
relations (hypernymy, meronymy) are edges
also add edge between word and unambiguous gloss words
36
how to use the graph for wsd
insert target word and words in its sentential context into the graph, with directed edges to their senses
   she drank some milk   
now choose the
     most central sense
add some id203 to
   drink    and    milk    and 
compute node with
highest    id95   
37
id51
semi-supervised learning
semi-supervised learning
problem: supervised and dictionary-based approaches require large hand-built resources
what if you don   t have so much training data?
solution: id64
generalize from a very small hand-labeled seed-set.

id64
for bass
rely on    one sense per collocation    rule
a word reoccurring in collocation with the same word will almost surely have the same sense.

the word play occurs with the music sense of bass 
the word fish occurs with the fish sense of bass
sentences extracting using    fish    and    play   
summary: generating seeds
hand labeling
   one sense per collocation   :
a word reoccurring in collocation with the same word will almost surely have the same sense.
   one sense per discourse   :
the sense of a word is highly consistent within a document  - yarowsky (1995)
(at least for non-function words, and especially topic-specific words)
stages in the yarowsky id64 algorithm for the word    plant   
summary
id51: choosing correct sense in context
applications: mt, qa, etc.
three classes of methods
supervised machine learning: naive bayes classifier
thesaurus/dictionary methods
semi-supervised learning
main intuition
there is lots of information in a word   s context
simple algorithms based just on word counts can be surprisingly good
44
