a* heuristic 

search

andrew w. moore

professor

school of computer science
carnegie mellon university

www.cs.cmu.edu/~awm

awm@cs.cmu.edu

412-268-7599

note to other teachers and users of these slides. andrew would be delighted if you found this source 
material useful in giving your own lectures. feel free to use these slides verbatim, or to modify them to fit 
your own needs. powerpoint originals are available. if you make use of a significant portion of these 
slides in your own lecture, please include this message, or the following link to the source repository of 
andrew   s tutorials: http://www.cs.cmu.edu/~awm/tutorials . comments and corrections gratefully received. 

slide 1

overview

    the inadequacies of    best first greedy   

heuristic search.

    good trick: take account of your cost of getting 

to the current state.

    when should the search stop?
    admissible heuristics
    id67 is complete
    id67 will always terminate
    a*   s dark secret
    saving masses of memory with ida* (iterative 

deepening a*)

slide 2

1

let   s make    best first greedy    look 

stupid!

2

s

a

1

1

b

c

4

2

g

h=3

h=4
h=0
    best    first greedy is clearly not guaranteed 

h=1

h=2

to find optimal

    obvious question:  what can we do to 

avoid the stupid mistake?

slide 3

a* - the basic idea

    best-first greedy: when you expand a node n, take each 

successor n' and place it on priqueue with priority h(n')

    a*: when you expand a node n, take each successor n'

and place it on priqueue with priority

(cost of getting to n') + h(n')

let g(n) = cost of getting to n

and then define   

f(n) = g(n) + h(n)

(1)

(2)

(3)

slide 4

2

a* looking non-stupid

1

2

s

h=4

a

h=3

1

b

h=2

4

2

c

h=1

g

h=0

when should a* terminate?

idea:  as soon as it generates a goal state?
look at this example:

1

1

h = 7

a

s
h = 8

7

7

g

h = 0

b

d

h = 3

1

h = 2

c

1

h = 1

slide 5

slide 6

3

correct a* termination rule:

a* terminates only when a goal state is popped 
from the priority queue

1

1

h = 7

a

s
h = 8

7

7

g

h = 0

b

d

h = 3

1

h = 2

c

1

h = 1

slide 7

a* revisiting states

another question: what if a* revisits a state that was 
already expanded, and discovers a shorter path?

1

h = 7

a

s
h = 8

1/2

in this example a state that 
had been expanded gets 
re-expanded.  how and 
why?

g

1

7

b

d

h = 3

1

c

h = 2

1

h = 1

slide 8

4

a* revisiting states

what if a* visits a state that is already on the queue?

h = 3

1

c

h = 8

1

h = 1

note that this h 
value has changed 
from previous 
page.

slide 9

h = 8
s

1

1

h = 7

a

1/2

in this example a state that had 
been on the queue and was 
waiting for expansion had its 
priority bumped up.  how and 
why?

g

7

the a* algorithm

 

i s   c o s t
  g ( n )
:
  k n o w n   p a t h  

  o f
t o   n

r e m i n d e r
t e s t
s h o r

b

d

 

reminder: h(n) is a 
heuristic estimate of 
cost to a goal from n

    priority queue pq begins empty.
    v (= set of previously visited (state,f,backpointer)-triples) begins empty.
    put s into pq and v with priority f(s) = g(s) + h(s)
   

is pq empty?
(cid:190) yes? sadly admit there   s no solution
(cid:190) no? remove node with lowest f(n) from queue.  call it n.
(cid:190) if n is a goal, stop and report success.
(cid:190)    expand    n : for each n' in successors(n)   .

= h(s) because 

g(start) = 0

use sneaky trick 
to compute g(n)

    let f    = g(n') + h(n') = g(n) + cost(n,n') + h(n')
    if n' not seen before, or n' previously expanded with 

f(n')>f   , or n' currently in pq with f(n')>f   

    then place/promote n' on priority queue with priority f   

and update v to include (state=n', f    , backptr=n).

    else ignore n'

slide 10

5

is a* guaranteed to find the 

optimal path?

1

s

h = 7

1

a
h = 6

3

nope.  and this example shows why not.

h = 0
g

slide 11

admissible heuristics

    write h*(n) = the true minimal cost to goal 

from n.

    a heuristic h is admissible if

h(n) <= h*(n) for all states n.

    an admissible heuristic is guaranteed 

never to overestimate cost to goal.

    an admissible heuristic is optimistic.

slide 12

6

8-puzzle example

example 
state

1
5
362
847

goal 
state

321
654
87

which of the following are admissible heuristics?
    h(n) = number of tiles in wrong 

position in state n

    h(n) = 0
    h(n) = sum of manhattan 

distances between each tile and 
its goal location

    h(n) = 1

    h(n) = min (2, h*[n])
    h(n) = h*(n)
    h(n) = max (2, h*[n])

slide 13

a* with admissible heuristic 
guarantees optimal path

    simple proof
    your lecturer will attempt to give it from 

memory.

    he might even get it right.  but don   t hold 

your breath.

slide 14

7

is a* guaranteed to 

terminate?

i.e. is it 
complete?

    there are finitely many acyclic paths in the search 

    a* only ever considers acyclic paths.
    on each iteration of a* a new acyclic path is 

generated because:
    when a node is added the first time, a new path 

tree.

exists.

    when a node is    promoted   , a new path to that 

node exists.  it must be new because it   s shorter.
    so the very most work it could do is to look at every 

acyclic path in the graph.

    so, it terminates.

slide 15

comparing iterative deepening with a*
from russell and norvig, page 107, fig 4.8

for 8-puzzle, average number of 
states expanded over 100 
randomly chosen problems in 
which optimal path is length   
   4 steps

   8 steps

   12 steps

iterative deepening (see 
previous slides)
id67 using    number of 
misplaced tiles    as the heuristic
a* using    sum of manhattan 
distances    as the heuristic

112

6,300

3.6 x 106

13

12

39

25

227

73

slide 16

8

indeed there are 
comparing iterative deepening with a*
only a couple 
andrew   s editorial comments
1. at first sight might look like even    number of misplaced 
hundred thousand 
states for the entire 
tiles    is a great heuristic. but probably h(state)=0 would 
eight puzzle
from russell and norvig, page 107, fig 4.8
also do much much better than id, so the difference is 
mainly to do with id   s big problem of expanding the same 
state many times, not the use of a heuristic.
2. judging solely by    number of states expanded    does not 
account for overhead of maintaining hash tables and 
priority queue for a*, though it   s pretty clear here that this 
won   t dramatically change the results.

average number of states 
expanded over 100 randomly 
chosen problem in which optimal 
path is length   
   4 steps

   12 steps

   8 steps

iterative deepening (see 
previous slides)
id67 using    number of 
misplaced tiles    as the heuristic
a* using    sum of manhattan 
distances    as the heuristic

112

6,300

3.6 x 106

13

12

39

25

227

73

slide 17

a* : the dark side

    a* can use lots of memory.  

in principle:

o(number of states)

    for really big search 

spaces, a* will run out of 
memory.  

slide 18

9

   

   

ida* : memory bounded search
iterative deepening a*. actually, pretty different from a*. assume 
costs integer.
1.

do loop-avoiding dfs, not expanding any node with 

2.

3.

4.

f(n) > 0.  did we find a goal?  if so, stop.

do loop-avoiding dfs, not expanding any node with 

f(n) > 1.  did we find a goal?  if so, stop.

do loop-avoiding dfs, not expanding any node with 

f(n) > 2.  did we find a goal?  if so, stop.

do loop-avoiding dfs, not expanding any node with 

f(n) > 3.  did we find a goal?  if so, stop.

   keep doing this, increasing the f(n) threshold by 1 each 
time, until we stop.

this is
(cid:153) complete
(cid:153) guaranteed to find optimal
(cid:153) more costly than a* in general.

slide 19

what you should know

    thoroughly understand a*.
    be able to trace simple examples of a* execution.
    understand    admissibility    of heuristics.  proof of 

completeness, guaranteed optimality of path.

    be able to criticize best first search.

references:

nils nilsson. problem solving methods in artificial intelligence.  
mcgraw hill (1971) e&s-bk 501-5353 n71p.
judea pearl.  heuristics: intelligent search strategies for computer 
problem solving.  addison wesley (1984) e&s-bk 501-535 p35h.
chapters 3 & 4 of stuart russell and peter norvig.  artificial 
intelligence: a modern approach.  

slide 20

10

proof: a* with admissible heuristic guarantees optimal path

    suppose it finds a suboptimal path, ending in goal state g1
where f(g1) > f* where f* = h* (start) = cost of optimal path.

    there must exist a node n which is

(cid:131) unexpanded
(cid:131) the path from start to n (stored in the backpointers(n) 

values) is the start of a true optimal path

f(n) >= f(g1) (else search wouldn   t have ended)

   
    also f(n) = g(n) + h(n) 

because it   s on 
optimal path

= g*(n) + h(n)
<= g*(n) + h*(n)
= f*

because n is on 
the optimal path

by the 
admissibility 
assumption

why must such a node 
exist? consider any 
optimal path 
s,n1,n2   goal.  if all along 
it were expanded, the goal 
would   ve been reached 
along the shortest path.

so f* >= f(n) >= f(g1)

contradicting 
top of slide

slide 21

exercise part 1

in the following maze the successors of a cell include any cell directly to the 
east, south, west or north of the current cell except that no transition may pass 
through the central barrier.  for example successors(m) = { d , n , g }.

a
c
k
t

b
d
m
g

e
n

f
p

s
q

h
r

the search problem is to find a path from s to g.  we are going to examine the 
order in which cells are expanded by various search algorithms.  for example, 
one possible expansion order that breadth first search might use is:

s h f k p c q a r b t d g

there are other possible orders depending on which of two equal-distance-
from-start states happen to be expanded first.  for example s f h p k c q r a t b
g is another possible answer.

continued->

slide 22

11

exercise part 1 continued

a
c
k
t

b
d
m
g

e
n

f
p

s
q

h
r

assume you run depth-first-search until it expands the goal node.  assume 
that you always try to expand east first, then south, then west, then north.  
assume your version of depth first search avoids loops: it never expands a 
state on the current path.  what is the order of state expansion?

slide 23

exercise part 2

a
c
k
t

b
d
m
g

e
n

f
p

s
q

h
r

next, you decide to use a manhattan distance metric heuristic function
h(state) = shortest number of steps from state to g if there were no barriers
so, for example, h(k) = 2, h(s) = 4, h(g) = 0
assume you now use best-first greedy search using heuristic h (a version that 
never re-explores the same state twice).  again, give all the states expanded, in 
the order they are expanded, until the algorithm expands the goal node.
finally, assume you use id67 with heuristic h, and run it until it terminates 
using the conventional a* termination rule.  again, give all the states expanded, 
in the order they are expanded.  (note that depending on the method that a* 
uses to break ties, more than one correct answer is possible).

slide 24

12

another example  question

consider the use of the a* algorithm on a search graph with cycles, 
and assume that this graph does not have negative-length edges.  
suppose you are explaining this algorithm to pat, who is not familiar 
with ai.  after your elaborated explanation of how a* handles cycles, 
pat is convinced that a* does a lot of unnecessary work to guarantee 
that it works properly (i.e. finds the optimal solution) in graphs 
containing cycles.  pat suggests the following modification to improve 
the efficiency of the algorithm:

since the graph has cycles, you may detect new cycles from time to time 
when expanding a node.  for example, if you expand nodes a, b, and c 
shown on figure (a) on the next slide, then after expanding c and noticing 
that a is also a successor of c, you will detect the cycle a-b-c-a.  every 
time you notice a cycle, you may remove the last edge of this cycle from 
the search graph.  for example, after expanding c, you can remove the 
edge c-a  (see figure (b) on next slide).  then, if a* visits node c again in 
the process of further search, it will not need to traverse this useless edge 
the second time.

continued next slide

slide 25

more another example  question
does this modified version of a* always find the optimal path to a 
solution?  why or why not?

start

   

   

a

b

c

   

start

   

   

a

b

c

   

(a) detecting a cycle

(b) removing the detected cycle

slide 26

13

