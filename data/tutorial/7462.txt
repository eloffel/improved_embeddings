searching: 
deterministic 
single-agent

andrew w. moore

professor

school of computer science
carnegie mellon university

www.cs.cmu.edu/~awm

awm@cs.cmu.edu

412-268-7599

note to other teachers and users of these slides. andrew would be delighted if you found this source 
material useful in giving your own lectures. feel free to use these slides verbatim, or to modify them to fit 
your own needs. powerpoint originals are available. if you make use of a significant portion of these 
slides in your own lecture, please include this message, or the following link to the source repository of 
andrew   s tutorials: http://www.cs.cmu.edu/~awm/tutorials . comments and corrections gratefully received. 

slide 1

overview

    deterministic, single-agent, search problems
    breadth first search
    optimality, completeness, time and space 

complexity

    search trees
    depth first search
    iterative deepening
    best first    greedy    search

slide 2

1

a search problem

a

d

b

start

p

q

c

e

h

goal

f

r

how do we get from s to g?  and what   s the 
smallest possible number of transitions?

slide 3

formalizing a search problem
a search problem has five components:
q , s , g , succs , cost
    q is a finite set of states.
    s     q is a non-empty set of start states.
    g     q is a non-empty set of goal states.
    succs : q (cid:198) p(q) is a function which takes a state as 

input and returns a set of states as output. succs(s) 
means    the set of states you can reach from s in one 
step   .

    cost : q , q (cid:198) positive number is a function which takes 

two states, s and s   , as input.  it returns the one-step 
cost of traveling from s to s   .  the cost function is only 
defined when s    is a successor state of s.

slide 4

2

our search problem

a

d

b

start

p

q

c

e

h

goal

f

r

q = {start, a , b , c , d , e , f , h , p , q , r , goal}
s = { start }
g = { goal }
succs(b) = { a }
succs(e) = { h , r }
succs(a) = null     etc.
cost(s,s   ) = 1 for all transitions

slide 5

our search problem

a

d

b

start

p

q

c

e

h

goal

f

r

q = {start, a , b , c , d , e , f , h , p , q , r , goal}
s = { start }
g = { goal }
succs(b) = { a }
succs(e) = { h , r }
succs(a) = null     etc.
cost(s,s   ) = 1 for all transitions

w

o  w
h y d
m
ble
p r o

at 

h

?  w

s a r e lik e this ?
e c a r e

slide 6

3

search problems

slide 7

more search problems

scheduling

8-queens

what next?

slide 8

4

more search problems

but there are plenty of things which we   d 
scheduling
normally call search problems that don   t fit our 
rigid definition        a search problem has five components:

8-queens

    q , s , g , succs , cost
    q is a finite set of states.
    s     q is a non-empty set of start states.
    g     q is a non-empty set of goal states.
    succs : q (cid:198) p(q) is a function which takes a 
state as input and returns a set of states as 
output. succs(s) means    the set of states you 
can reach from s in one step   .

    cost : q , q (cid:198) positive number is a function 
which takes two states, s and s   , as input.  it 
what next?
returns the one-step cost of traveling from s to 
s   .  the cost function is only defined when s    is 
a successor state of s.

can you think of examples?

our definition excludes   

slide 9

slide 10

5

our definition excludes   

hidden state

chance

game 
against 
adversary

continuum (infinite 
number) of  states

all of the above, plus 
distributed team control

slide 11

breadth first search

a

d

b

start

p

q

c

e

h

goal

f

r

label all states that are reachable from s in 1 step but aren   t reachable 
in less than 1 step.
then label all states that are reachable from s in 2 steps but aren   t 
reachable in less than 2 steps.
then label all states that are reachable from s in 3 steps but aren   t 
reachable in less than 3 steps.
etc    until goal state reached.

slide 12

6

breadth-first search

a

d

p

q

c

e

h

breadth-first search

a

d

p

q

c

e

h

b

b

0 steps 
from start

start

1 step 
from start

0 steps 
from start

start

goal

f

r

goal

f

r

slide 13

slide 14

7

b

b

1 step 
from start

0 steps 
from start

start

1 step 
from start

0 steps 
from start

start

breadth-first search

a

d

p

c

e

h

q

2 steps 
from start

breadth-first search

a

d

p

c

e

h

q

2 steps 
from start

goal

f

r

slide 15

goal

f

r

3 steps 
from start

slide 16

8

1 step 
from start

b

0 steps 
from start

start

breadth-first search

4 steps 
from start

a

d

p

c

e

h

q

2 steps 
from start

goal

f

r

3 steps 
from start

slide 17

remember the path!

a

d

b

start

p

q

c

e

h

goal

f

r

also, when you label a state, record the predecessor state.  this record 
is called a backpointer.  the history of predecessors is used to 
generate the solution path, once you   ve found the goal:
   i   ve got to the goal.  i see i was at f before this.  and i was at r before i 
was at f.  and i was   
   . so solution path is s (cid:198) e (cid:198) r (cid:198) f (cid:198) g   

slide 18

9

1 step 
from start

0 steps 
from start

start

1 step 
from start

0 steps 
from start

start

b

b

p

p

backpointers

a

d

c

e

h

q

2 steps 
from start

backpointers

a

d

c

e

h

q

2 steps 
from start

4 steps 
from start

goal

f

r

3 steps 
from start

slide 19

4 steps 
from start

goal

f

r

3 steps 
from start

slide 20

10

starting breadth first search

for any state s that we   ve labeled, we   ll remember:
   previous(s) as the previous state on a shortest path from start state 
to s.
on the kth iteration of the algorithm we   ll begin with vk defined as the 
set of those states for which the shortest path from the start costs 
exactly k steps
then, during that iteration, we   ll compute vk+1, defined as the set of 
those states for which the shortest path from the start costs exactly k+1 
steps
we begin with k = 0, v0 = {start} and we   ll define, previous(start)
= null
then we   ll add in things one step from the start into v1.  and we   ll 
keep going.

slide 21

bfs

b

a

d

start

v0

p

q

c

e

h

goal

f

r

slide 22

11

a

d

a

d

bfs

b

start

v0

p

v1

bfs

b

start

v0

p

v1

e

h

c

c

e

h

v2

q

q

goal

f

r

goal

f

r

slide 23

slide 24

12

a

d

a

d

bfs

b

start

v0

p

v1

bfs

b

start

v0

p

v1

c

e

h

v2

c

e

h

v2

q

q

goal

v3

f

r

slide 25

v4

goal

v3

f

r

slide 26

13

breadth first search

v0 := s (the set of start states)
previous(start) := nil
k := 0
while (no goal state is in vk and vk is not empty) do

vk+1 := empty set
for each state s in vk

for each state s    in succs(s)

if s    has not already been labeled

set previous(s   ) := s
add s    into vk+1

k := k+1

if vk is empty signal failure
else build the solution path thus:  let si be the ith state in the shortest 
path.  define sk = goal, and forall i <= k, define si-1 = previous(si).

slide 27

bfs

a

b

c

v4

goal

start

v0

e

f

d

s u p p o s e   y o u r   s e a r c h   s p a c e   c o n v e n i e n t l y  
a l l o w e d   y o u   t o   o b t a i n   p r e d e c e s s o r s ( s t a t e ) .
    c a n   y o u   t h i n k   o f   a   d i f f e r e n t   w a y   t o   d o   b f s ?
    a n d   w o u l d   y o u   b e   a b l e   t o   a v o id   s t o r i n g  
s o m e t h i n g   t h a t   w e     d   p r e v i o u s l y   h a d   t o  
v1
s t o r e ?

q

h

p

r

v2

v3

slide 28

14

another way: work back

a

d

b

start

p

q

c

e

h

goal

f

r

label all states that can reach g in 1 step but can   t reach it in less than 
1 step.
label all states that can reach g in 2 steps but can   t reach it in less 
than 2 steps.
etc.     until start is reached.
   number of steps to goal    labels determine the shortest path.  don   t 
need extra bookkeeping info.

slide 29

breadth first details

    it is fine for there to be more than one goal state.
    it is fine for there to be more than one start state.
    this algorithm works forwards from the start.  any 

algorithm which works forwards from the start is 
said to be forward chaining.

    you can also work backwards from the goal. this 

algorithm is very similar to dijkstra   s algorithm.
    any algorithm which works backwards from the 

goal is said to be backward chaining.

    backward versus forward.  which is better?

slide 30

15

costs on transitions

a

1

d

2

b

3

1

p

2

8

9

q

4

1
5

start

c

2

4

e

1

3

h

5

9

goal

5

f

5

r

notice that bfs finds the shortest path in terms of number of 
transitions.  it does not find the least-cost path.
we will quickly review an algorithm which does find the least-cost path.  
on the kth iteration, for any state s, write g(s) as the least-cost path to 
s in k or fewer steps.

slide 31

least cost breadth first

vk = the set of states which can be reached in exactly k steps, and for which the least-
cost k-step path is less cost than any path of length less than k.  in other words, vk = the 
set of states whose values changed on the previous iteration.
v0 := s (the set of start states)
previous(start) := nil
g(start) = 0
k := 0
while (vk is not empty) do
vk+1 := empty set
for each state s in vk

for each state s    in succs(s)

if s    has not already been labeled
or if g(s) + cost(s,s   ) < g(s   )
set previous(s   ) := s
set g(s   ) := g(s) + cost(s,s   )
add s    into vk+1

k := k+1

if goal not labeled, exit signaling failure
else build the solution path thus:  let sk be the kth state in the shortest path.  
define sk = goal, and forall i <= k, define si-1 = previous(si).

slide 32

16

uniform-cost search

    a conceptually simple bfs approach 

when there are costs on transitions

    it uses priority queues

slide 33

priority queue refresher

a priority queue is a data structure 
in which you can insert and 
retrieve (thing, value) pairs with 
the following operations:
init-priqueue(pq)
insert-priqueue(pq, thing, value)
pop-least(pq)

initializes the pq to be empty.

inserts (thing, value) into the queue.
returns the (thing, value) pair with the lowest 
value, and removes it from the queue.

slide 34

17

priority queue refresher
for more details, see knuth 
or sedgwick or basically 
any book with the word 
   algorithms   prominently 
appearing in the title.

a priority queue is a data structure 
in which you can insert and 
retrieve (thing, value) pairs with 
the following operations:
init-priqueue(pq)
insert-priqueue(pq, thing, value)
pop-least(pq)

initializes the pq to be empty.

inserts (thing, value) into the queue.
returns the (thing, value) pair with the lowest 
value, and removes it from the queue.

priority queues can be 
implemented in such a way that 
the cost of the insert and pop 
operations are

very cheap (though 
not absolutely, 
incredibly cheap!)

o(log(number of things in priority queue))

slide 35

uniform-cost search

    a conceptually simple bfs approach when 

there are costs on transitions

    it uses a priority queue

pq = set of states that have been 
expanded or are awaiting expansion
priority of state s = g(s) = cost of 
getting to s using path implied by 
backpointers.

slide 36

18

starting ucs

2

a

b

3

1

1

p

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

start

pq = { (s,0) }

slide 37

ucs iterations

2

a

b

3

1

1

p

d

2

8

9

4

15

q

start

pq = { (s,0) }

c

2

2

9

e

1

h

4

3

goal

5

f

5

r

iteration:
1. pop least-cost state from pq
2. add successors

slide 38

19

ucs iterations

2

a

b

3

1

1

p

d

2

8

9

4

15

q

start

pq = { (p,1), (d,3) , (e,9) }

c

2

2

9

e

1

h

4

3

goal

5

f

5

r

iteration:
1. pop least-cost state from pq
2. add successors

slide 39

ucs iterations

2

a

b

3

1

1

p

start

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

pq = { (d,3) , (e,9) , (q,16) }

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 40

20

ucs iterations

2

a

b

3

1

1

p

start

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

pq = { (b,4) , (e,5) , (c,11) , (q,16) }

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 41

ucs iterations

2

a

2

b

1

8

goal

2

5

c

2

e

3

d

f

9

1

1

4

start

9
  h a p p e n e d   h e r e :
h
t o   e
n o t e   w h a t
t i n g  
t h e   p r e v i o u s l y   b e s t
  g e t
t h a t
4
3
r e a li z e d  
15
q
d
t h a n  
   
 
t e r
i t y   w a s   c h a n g e d
t o   e
b e t
 
t o   g e t
w a y  
p r i o r
pq = { (b,4) , (e,5) , (c,11) , (q,16) }
a n d   s o   e     s

5
-

p

r

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 42

v i a   d w a s  
k n o w n  

   

21

ucs iterations

2

a

b

3

1

1

p

start

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 43

pq = { (e,5) , (a,6) , (c,11) , (q,16) }

ucs iterations

2

a

b

3

1

1

p

start

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

pq = { (a,6),(h,6),(c,11),(r,14),(q,16) }

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 44

22

ucs iterations

2

a

b

3

1

1

p

start

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 45

pq = { (h,6),(c,11),(r,14),(q,16) }

ucs iterations

2

a

b

3

1

1

p

start

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

pq = { (q,10), (c,11),(r,14) }

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 46

23

ucs iterations
note what happened here:
    h found a new way to get to p
    but it was more costly than the best known way
    and so p   s priority was unchanged

2

2

2

b

a

c

8

1

goal

5

3

1

start

p

d

9

q

4

15

pq = { (q,10), (c,11),(r,14) }

2

e

1

9

h

4

3

f

5

r

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 47

ucs iterations

2

a

b

3

1

1

p

start

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

pq = { (c,11),(r,13) }

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 48

24

ucs iterations

2

a

b

3

1

1

p

start

pq = { (r,13) }

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 49

ucs iterations

2

a

b

3

1

1

p

start

pq = { (f,18) }

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 50

25

ucs iterations

2

a

b

3

1

1

p

start

pq = { (g,23) }

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 51

ucs iterations
question: is    terminate as soon as you discover 
the goal    the right stopping criterion?

a

2

8

9

d

c

2

2

9

e

1

h

4

3

4

15

q

goal

5

f

5

r

2

b

3

1

1

p

start

pq = { (g,23) }

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 52

26

ucs terminates

2

a

2

b

c

2

1

terminate only once the goal is popped from the 
priority queue. else we may miss a shorter path.

3

2

e

d

8

9

1

9

start

1

4

15

q

p

pq = { }

h

4

3

r

goal

5

f

5

iteration:
1. pop least-cost 
state from pq

2. add successors
slide 53

judging a search algorithm

    completeness: is the algorithm guaranteed to find a solution 

if a solution exists?

    guaranteed to find optimal? (will it find the least cost path?)
    algorithmic time complexity
    space complexity (memory use)
variables:

n
b

l

number of states in the problem
the average branching factor (the average 
number of successors) (b>1)
the length of the path from start to goal with the 
shortest number of steps

how would we judge our algorithms?

slide 54

27

judging a search algorithm

n
b
l
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

least cost 
bfs
uniform 
cost search

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))

o(min(n,bl))
o(min(n,bl))

slide 55

judging a search algorithm

n
b
l
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

least cost 
bfs
uniform 
cost search

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))

o(min(n,bl))
o(min(n,bl))

slide 56

28

search tree representation

a

d

b

start

p

q

c

e

h

goal

f

r

h  

g

u
o
o   t h r
o   w e   g
e   w it h   b f s ?
r e

slide 57

r   d
h   t

e
c

r d
r
a

a t   o
e
s
e  

w h
t h

depth first search

a

d

2

b

3

1

1

p

2

8

9

c

2

h

4

15

4

q

e

1

3

5

9

goal

5

f

5

r

start

an alternative to bfs.  always expand from the most-
recently-expanded node, if it has any untried successors.  
else backup to the previous node on the current path.

slide 58

29

dfs in action

b

a

d

p

q

c

e

h

goal

f

r

start

start
start d
start d b
start d b a
start d c
start d c a
start d e
start d e r
start d e r f
start d e r f c
start d e r f c a
start d e r f goal

dfs search tree traversal

a

d

b

start

p

q

c

e

h

goal

f

r

can you draw in 
the order in which 
the search-tree 
nodes are visited?

slide 59

slide 60

30

dfs algorithm

we use a data structure we   ll call a path to represent the , er, path from the 
start to the current state.
e.g. path p = <start, d, e, r >
along with each node on the path, we must remember which successors we 
still have available to expand.  e.g. at the following point, we   ll have

p = <start (expand=e , p) ,

d (expand = null) ,
e (expand = h) ,
r (expand = f) >

slide 61

dfs algorithm

let p = <start (expand = succs(start))>
while (p not empty and top(p) not a goal)

if expand of top(p) is empty
then

remove top(p) (   pop the stack   )

else

let s be a member of expand of top(p)
remove s from expand of top(p)
make a new item on the top of path p: 

s (expand = succs(s))

if p is empty

return failure

else

return the path consisting of states in p

this algorithm can be 
written neatly with 
recursion, i.e. using the 
program stack to 
implement p.

slide 62

31

judging a search algorithm

n
b
l
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

dfs

least cost 
bfs
uniform 
cost search
depth first 
search

y

y

n

optimal

time

space

if all 
transitions 
same cost
y

y

n

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
n/a

o(min(n,bl))
o(min(n,bl))
n/a

slide 63

judging a search algorithm

n
b
l
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

dfs

least cost 
bfs
uniform 
cost search
depth first 
search

y

y

n

optimal

time

space

if all 
transitions 
same cost
y

y

n

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
n/a

o(min(n,bl))
o(min(n,bl))
n/a

slide 64

32

judging a search algorithm

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

dfs**

least cost 
bfs
uniform 
cost search
depth first 
search

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)

o(min(n,bl))
o(min(n,bl))
o(lmax)

assuming acyclic 

search space

slide 65

judging a search algorithm

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

dfs**

least cost 
bfs
uniform 
cost search
depth first 
search

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)

o(min(n,bl))
o(min(n,bl))
o(lmax)

assuming acyclic 

search space

slide 66

33

questions to 

ponder

    how would you 

prevent dfs from 
looping?

    how could you 

force it to give an 
optimal solution?

slide 67

questions to 

ponder

    how would you 

prevent dfs from 
looping?

    how could you 

force it to give an 
optimal solution?

answer 1:
pc-dfs (path checking dfs):
don   t recurse on a state 
if that state is already in 
the current path

answer 2:
memdfs (memoizing dfs):
remember all states 
expanded so far. never 
expand anything twice.

slide 68

34

questions to 

ponder

    how would you 

prevent dfs from 
looping?

    how could you 

force it to give an 
optimal solution?

answer 1:
pc-dfs (path checking dfs):
don   t recurse on a state 
if that state is already in 
the current path

answer 2:
memdfs (memoizing dfs):
remember all states 
expanded so far. never 
expand anything twice.

slide 69

questions to 

ponder

c
s

d
?

    how would you 
f

s  is 
prevent dfs from 
h e n  p
a re th ere o c c a sio n s  w
f
d
looping?
m
e
b etter th a n  m
h e n  m
a re th ere o c c a sio n s  w
f
d
c
is b etter th a n  p
force it to give an 
optimal solution?

d
m
?
    how could you 

s  

f

e

s

answer 1:
pc-dfs (path checking dfs):
don   t recurse on a state 
if that state is already in 
the current path

answer 2:
memdfs (memoizing dfs):
remember all states 
expanded so far. never 
expand anything twice.

slide 70

35

judging a search algorithm

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest cycle-free path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

pcdfs

memdfs

least cost 
bfs
uniform 
cost search
path check 
dfs
memoizing
dfs

y

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

n

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)
o(min(n,blmax))

o(min(n,bl))
o(min(n,bl))
o(lmax)
o(min(n,blmax))

slide 71

judging a search algorithm

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest cycle-free path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

pcdfs

memdfs

least cost 
bfs
uniform 
cost search
path check 
dfs
memoizing
dfs

y

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

n

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)
o(min(n,blmax))

o(min(n,bl))
o(min(n,bl))
o(lmax)
o(min(n,blmax))

slide 72

36

judging a search algorithm

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest cycle-free path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

pcdfs

memdfs

least cost 
bfs
uniform 
cost search
path check 
dfs
memoizing
dfs

y

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

n

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)
o(min(n,blmax))

o(min(n,bl))
o(min(n,bl))
o(lmax)
o(min(n,blmax))

slide 73

maze example

imagine states are cells in a maze, you can move n, e, s, w.  what 
would plain dfs do, assuming it always expanded the e successor 
first, then n, then w, then s?

g

s

other questions:

expansion order e, n, w, s

what would bfs do?
what would pcdfs do?
what would memdfs do?

slide 74

37

two other dfs examples

g

g

order: n, e, s, w?

order: n, e, s, w
with loops prevented

slide 75

s

s

forward dfsearch or backward 

dfsearch

if you have a predecessors() function as well 
as a successors() function you can begin at 
the goal and depth-first-search backwards 
until you hit a start.

why/when might this be a good idea?

slide 76

38

invent an algorithm time!

here   s a way to dramatically decrease costs 
sometimes.  bidirectional search.  can you 
guess what this algorithm is, and why it can 
be a huge cost-saver?

slide 77

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest cycle-free path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

pcdfs

memdfs

bibfs

least cost 
bfs
uniform 
cost search
path check 
dfs
memoizing
dfs
bidirection
bf search

y

y

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

n

y

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)
o(min(n,blmax))
o(min(n,2bl/2))

o(min(n,bl))
o(min(n,bl))
o(lmax)
o(min(n,blmax))
o(min(n,2bl/2))

slide 78

39

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest cycle-free path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

pcdfs

memdfs

bibfs

least cost 
bfs
uniform 
cost search
path check 
dfs
memoizing
dfs
bidirection
bf search

y

y

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

n

all trans 
same cost

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)
o(min(n,blmax))
o(min(n,2bl/2))

o(min(n,bl))
o(min(n,bl))
o(lmax)
o(min(n,blmax))
o(min(n,2bl/2))

slide 79

iterative deepening
iterative deepening is a simple algorithm which 

uses dfs as a subroutine:

1. do a dfs which only searches for paths of 

length 1 or less.  (dfs  gives up any path of 
length 2)

2. if    1    failed, do a dfs which only searches 

paths of length 2 or less.

3. if    2    failed, do a dfs which only searches 

paths of length 3 or less.

   .and so on until success

cost is 
o(b1 + b2 + b3 + b4     + bl) = o(bl)

can be much better than regular 
greater than the number of states.
dfs.  but cost can be much 

slide 80

40

maze example

imagine states are cells in a maze, you can move n, e, s, w.  what 
would iterative deepening do, assuming it always expanded the e 
successor first, then n, then w, then s?

g

s

expansion order e, n, w, s

slide 81

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest cycle-free path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

pcdfs

memdfs

bibfs
id

least cost 
bfs
uniform 
cost search
path check 
dfs
memoizing
dfs
bidirection
bf search
iterative 
deepening

y

y

y

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

n

all trans 
same cost
if all 
transitions 
same cost

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)
o(min(n,blmax))
o(min(n,2bl/2))
o(bl)

o(min(n,bl))
o(min(n,bl))
o(lmax)
o(min(n,blmax))
o(min(n,2bl/2))
o(l)

slide 82

41

n
b
l
lmax
q

number of states in the problem
the average branching factor (the average number of successors) (b>1)
the length of the path from start to goal with the shortest number of steps
length of longest cycle-free path from start to anywhere
the average size of the priority queue

algorithm

bfs

comp
lete
y
breadth first 
search

lcbfs

ucs

pcdfs

memdfs

bibfs
id

least cost 
bfs
uniform 
cost search
path check 
dfs
memoizing
dfs
bidirection
bf search
iterative 
deepening

y

y

y

y

y

y

optimal

time

space

if all 
transitions 
same cost
y

y

n

n

all trans 
same cost
if all 
transitions 
same cost

o(min(n,bl))

o(min(n,bl))

o(min(n,bl))
o(log(q) * min(n,bl))
o(blmax)
o(min(n,blmax))
o(min(n,2bl/2))
o(bl)

o(min(n,bl))
o(min(n,bl))
o(lmax)
o(min(n,blmax))
o(min(n,2bl/2))
o(l)

slide 83

best first    greedy    search

needs a heuristic.  a heuristic function maps a state onto 
an estimate of the cost to the goal from that state.

can you think of examples of heuristics?

e.g. for the 8-puzzle?

e.g. for planning a path through a maze?

denote the heuristic by a function h(s) from states to a cost 
value.

slide 84

42

heuristic search

specification we also have a heuristic.  

suppose in addition to the standard search 
a heuristic function maps a state 

onto an estimate of the cost to the 
goal from that state.

can you think of examples of heuristics?
    e.g. for the 8-puzzle?
    e.g. for planning a path through a maze?

denote the heuristic by a function h(s) from states 

to a cost value.

slide 85

euclidian heuristic

2

a

h=8

1

b

h=11

3

d

h=8

2

8

9

start

h=12

1

p

h=11

4

15

q

h=9

2

9

c
h=5

2

h

4

h=4

e

1

h=6
3

goal

h=0

5

f

5

h=4

r

h=6

slide 86

43

euclidian heuristic

b

h=11

3

start

h=12

1

2

a

h=8

2

1

8
i
i o r
  p r
a n o t h e r
i m e ,
d
t
t h i s  
b u t
9
h=8
v a l u e .
4

 

15

q

h=9

   

   

p

h=11

i

c
t y   q u e u e   a l g o r
h=5
2
i o r
  p r

h=4
i s  

t h m .
2
t h e   h e u r

t y  

e

i

1

h

h=6
3

4

goal

h=0

5

i c  

i s t

9

f

5

h=4

r

h=6

slide 87

best first    greedy    search

init-priqueue(pq)
insert-priqueue(pq,start,h(start))
while (pq is not empty and pq does not contain a goal state)

(s , h ) := pop-least(pq)
foreach s    in succs(s)
if s    is not already in pq and s    never previously been visited

insert-priqueue(pq,s   ,h(s   ))

algorithm

bestfs

best first 
search

comp
lete
y

optimal

time

space

n

o(min(n,blmax))

o(min(n,blmax))

a few improvements to this algorithm can make things 
much better.  it   s a little thing we like to call: a*   .       

   to be continued!

slide 88

44

what you should know

    thorough understanding of bfs, lcbfs, 

ucs. pcdfs, memdfs

    understand the concepts of whether a 

search is complete, optimal, its time and 
space complexity

    understand the ideas behind iterative 

deepening and bidirectional search

    be able to discuss at cocktail parties the 

pros and cons of the above searches

slide 89

45

