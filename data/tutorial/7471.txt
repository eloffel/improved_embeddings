tractable learning in  

structured id203 spaces 

adnan darwiche 

computer science department 

representation learning workshop 
simons institute, 3/29/2017 

 
 
 

references 

probabilistic sentential decision diagrams 
doga kisa, guy van den broeck, arthur choi and adnan darwiche 
kr, 2014 
learning with massive logical constraints 
doga kisa, guy van den broeck, arthur choi and adnan darwiche 
icml 2014 workshop 
tractable learning for structured id203 spaces 
arthur choi, guy van den broeck and adnan darwiche 
ijcai, 2015 
tractable learning for complex id203 queries 
jessa bekker, jesse davis, arthur choi, adnan darwiche, guy van den broeck. 
nips, 2015 
structured features in naive bayes classifiers 
arthur choi, nazgol tavabi and adnan darwiche 
aaai, 2016 
tractable operations on arithmetic circuits 
jason shen, arthur choi and adnan darwiche 
nips, 2016 
 

structured id203 spaces? 

running example 

data 

courses: 
       logic (l) 
       id99 (k) 
       id203 (p)  
       artificial intelligence (a) 
 
 
prior knowledge 
       must take at least one of  
 
 
       id203 is a prerequisite for ai. 
 
       the prerequisites for kr is  
 
 

id203 or logic. 

either ai or logic. 
 

id203 space 

unstructured 

l	
0	
0	
0	
0	
0	
0	
0	
0	
1	
1	
1	
1	
1	
1	
1	
1	

k	
0	
0	
0	
0	
1	
1	
1	
1	
0	
0	
0	
0	
1	
1	
1	
1	

p	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	

a	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	

structured id203 space 

unstructured 

l	
0	
0	
0	
0	
0	
0	
0	
0	
1	
1	
1	
1	
1	
1	
1	
1	

k	
0	
0	
0	
0	
1	
1	
1	
1	
0	
0	
0	
0	
1	
1	
1	
1	

p	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	

a	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	

id203 or logic. 

       must take at least one of  
       id203 is a prerequisite for ai. 
       the prerequisites for kr is  

either ai or logic. 
 

7 out of 16 instantiations  

are impossible 

structured 

l	
0	
0	
0	
0	
0	
0	
0	
0	
1	
1	
1	
1	
1	
1	
1	
1	

k	
0	
0	
0	
0	
1	
1	
1	
1	
0	
0	
0	
0	
1	
1	
1	
1	

p	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	

a	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	

learning with constraints 

data 

constraints 

(background knowledge) 
(physics) 

learn          

statistical model 
(distribution) 

learn a statistical model that assigns  
zero id203 
to instantiations that violate the constraints. 

example: video 

   

[lu, w. l., ting, j. a., little, j. j., & murphy, k. p. (2013). learning to track and identify players from broadcast sports videos.] 

example: language 

       non-local dependencies: 

at least one verb in each sentence 

       sentence compression 

if a modifier is kept, its subject is also kept 

       information extraction 
       id14 
           and many more! 

   

[chang, m., ratinov, l., & roth, d. (2008). constraints as prior knowledge],   , [chang, m. w., ratinov, l., & roth, d. (2012). 

structured learning with constrained conditional models.], [https://en.wikipedia.org/wiki/constrained_conditional_model] 

id110 synthesized from specs of 

power system (nasa ames): 

has many constraints (0/1 parameters) due to 

domain ``physics        

example: deep learning 

[graves, a., wayne, g., reynolds, m., harley, t., danihelka, i., grabska-barwi  ska, a., et al.. (2016).  
hybrid computing using a neural network with dynamic external memory. nature, 538(7626), 471-476.] 

what are people doing now? 

ignore constraints 

      
       handcraft into models 
       use specialized distributions 
       find non-structured encoding 
       try to learn constraints 
       hack your way around 

 
 

accuracy ? 
specialized skill ? 
intractable id136 ? 
intractable learning ? 
waste parameters ? 
risk predicting out of space ? 
 
you are on your own 
 

structured id203 spaces 
       everywhere in ml! 

       configuration problems, inventory, video, text, deep learning 
       planning and diagnosis (physics) 
       causal models: cooking scenarios (interpreting videos) 
       combinatorial objects: parse trees, rankings, directed acyclic graphs, 

trees, simple paths, game traces, etc. 

 

no statistical ml boxes out there 

that take constraints as input! 

goal: constraints as important as data! general purpose! 

specification language: logic 

structured id203 space 

unstructured 

l	
0	
0	
0	
0	
0	
0	
0	
0	
1	
1	
1	
1	
1	
1	
1	
1	

k	
0	
0	
0	
0	
1	
1	
1	
1	
0	
0	
0	
0	
1	
1	
1	
1	

p	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	

a	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	

id203 or logic. 

       must take at least one of  
       id203 is a prerequisite for ai. 
       the prerequisites for kr is  

either ai or logic. 
 

7 out of 16 instantiations  

are impossible 

structured 

l	
0	
0	
0	
0	
0	
0	
0	
0	
1	
1	
1	
1	
1	
1	
1	
1	

k	
0	
0	
0	
0	
1	
1	
1	
1	
0	
0	
0	
0	
1	
1	
1	
1	

p	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	

a	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	

boolean constraints 

unstructured 

l	
0	
0	
0	
0	
0	
0	
0	
0	
1	
1	
1	
1	
1	
1	
1	
1	

k	
0	
0	
0	
0	
1	
1	
1	
1	
0	
0	
0	
0	
1	
1	
1	
1	

p	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	

a	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	

structured 

l	
0	
0	
0	
0	
0	
0	
0	
0	
1	
1	
1	
1	
1	
1	
1	
1	

k	
0	
0	
0	
0	
1	
1	
1	
1	
0	
0	
0	
0	
1	
1	
1	
1	

p	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	
0	
0	
1	
1	

a	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	
0	
1	

7 out of 16 instantiations  

are impossible 

combinatorial objects: rankings

rank
1
2
3
4
5
6
7
8
9
10

sushi
fatty tuna
sea urchin
salmon roe

shrimp
tuna
squid
tuna roll
see eel
egg

cucumber roll

rank
1
2
3
4
5
6
7
8
9
10

sushi
shrimp

sea urchin
salmon roe
fatty tuna

tuna
squid
tuna roll
see eel
egg

cucumber roll

10 items:  
3,628,800    
rankings 

20 items:  
2,432,902,008,176,640,000    
rankings 

combinatorial objects: rankings

rank
1
2
3
4
5
6
7
8
9
10

sushi
fatty tuna
sea urchin
salmon roe

shrimp
tuna
squid
tuna roll
see eel
egg

cucumber roll

rank
1
2
3
4
5
6
7
8
9
10

sushi
shrimp

sea urchin
salmon roe
fatty tuna

tuna
squid
tuna roll
see eel
egg

cucumber roll

aij  item i at position j    
(n items require n2  
 boolean variables)  
an item may be assigned   
to more than one position 
a position may contain  
more than one item 

aij  : item i at position j  

encoding rankings in logic
pos	1	 pos	2	 pos	3	 pos	4	
item	1	
a14	
item	2	
a21	
a24	
a11	
a34	
a31	
item	3	
item	4	
a41	
a44	

a12	
a22	
a32	
a42	

a13	
a23	
a33	
a43	

constraint: each item i assigned to  
a unique position (n constraints) 

constraint: each position j assigned 

a unique item (n constraints) 

structured space for paths

good variable assignment   
(represents route)
184

bad variable assignment
(does not represent route)
16,777,032
space easily encoded in logical constraints
unstructured id203 space: 184+16,777,032 = 224 

acyclicity    
constraints

undirected graphs (unstructured)
trees

dog 

cat 

s 
dog 

vp 

s 

vp 

s 

s 

s 

s 

label constraints   

(id18 production rules)

labeled trees

parse trees 

s 

np 

dt 

nn 

vp 

vi 

s 

the 

cat 

sleeps 

np 

vp 

dt 

nn 

vt 

np 

the 

dog 

saw 

dt 

nn 

the 

cat 

   deep representation    

 

logic + id203 

logical circuits 

  l k 

l       p  a    p      

l 

  l        p   a 

p 

  l   k  l       p 

  p      

k   k 

a   a 

a   a 

property: decomposability 

  l k 

l       p  a    p      

l 

  l        p   a 

p 

  l   k  l       p 

  p      

k   k 

a   a 

a   a 

property: determinism 

  l k 

l       p  a    p      

l 

  l        p   a 

p 

  l   k  l       p 

  p      

input: l, k, p, a 

k   k 

a   a 

a   a 

sentential decision diagram (sdd) 

  l k 

l       p  a    p      

l 

  l        p   a 

p 

  l   k  l       p 

  p      

input: l, k, p, a 

k   k 

a   a 

a   a 

tractable for logical id136 
       is structured space empty? (sat) 
       count size of structured space (#sat) 
       check equivalence of spaces 
       algorithms linear in circuit size  

(pass up, pass down, similar to backprop) 

psdd: probabilistic sdd  

0.1 

0.6 

0.3 

1 

0 

1 

0 

1 

0 

0.6 

0.4 

1 

0 

1 

0 

  l k 

l      

p  a    p      

l 

  l     

  p   a 

p 

  l   k  l      

p 

  p      

0.8 
0.2 
k   k 

0.25 

0.75 

a   a 

0.9 
0.1 
a   a 

psdd: probabilistic sdd  

0.1 

0.6 

0.3 

1 

0 

1 

0 

1 

0 

0.6 

0.4 

1 

0 

1 

0 

  l k 

l      

p  a    p      

l 

  l     

  p   a 

p 

  l   k  l      

p 

  p      

0.8 
0.2 
k   k 

input: l, k, p, a 

0.25 

0.75 

a   a 

0.9 
0.1 
a   a 

psdd: probabilistic sdd  

0.1 

0.6 

0.3 

1 

0 

1 

0 

1.0 

0 

0.6 

0.4 

1 

0 

1 

0 

  l k 

l      

p  a    p      

l 

  l     

  p   a 

p 

  l   k  l      

p 

  p      

0.8 
0.2 
k   k 

0.25 

0.75 

a   a 

0.9 
0.1 
a   a 

input: l, k, p, a 

pr(l,k,p,a) = 0.3 x 1.0 x 0.8 x 0.4 x 0.25 = 0.024 

psdd nodes induce 
a normalized 
distribution! 

0.1 

0.6 

0.3 

1 

0 

1 

0 

1 

0 

0.6 

0.4 

1 

0 

1 

0 

  l k 

l      

p  a    p      

l 

  l     

  p   a 

p 

  l   k  l      

p 

  p      

0.8 
0.2 
a   a 

0.25 

0.75 

a   a 

0.9 
0.1 
a   a 

can read probabilistic independences off the circuit structure  

tractable for  

probabilistic id136 

       map id136: find most-likely assignment  

(otherwise np-complete) 

       computing conditional probabilities pr(x|y) 

(otherwise pp-complete) 

       sample from pr(x|y) 

       algorithms linear in circuit size 

(pass up, pass down, similar to backprop) 

psdds are arithmetic circuits 

[darwiche, jacm 2003] 

  1 
  2 

  n 

* 

  1 

* 

p1 s1 p2 s2  pn sn 

p1 

s1 

psdd 

+ 

* 

* 

  2 

p2 

s2 
ac 

* 
* 

  n 

pn 

sn 

known in the ml literature as spns 

uai 2011, nips 2012 best paper awards 

[icml 2014]  
(spns equivalent to acs) 

learning psdds 

 

logic + id203 + ml 

parameters are interpretable 

0.1 

0.6 

0.3 

id203 of  p given l 

1 

0 

1 

0 

1 

0 

0.6 

0.4 

1 

0 

1 

0 

  l k 

l      

p  a    p      

l 

  l     

  p   a 

p 

  l   k  l      

p 

  p      

0.8 
0.2 
k   k 

student takes 
course l 

0.25 

0.75 

a   a 

student takes course p 

0.9 
0.1 
a   a 

explainable ai darpa program 

learning algorithms 

       parameter learning:  

closed form max likelihood from complete data 
one pass over data to estimate parameters 
 

note a lot to say: very easy! 

       structure learning: 

      compile constraints to sdd (naive) 
use sat solver technology (sdd library) 

      search for structure to fit data (ongoing work) 

learning preference distributions 

psdd 

special-purpose  
distribution: 
mixture-of-mallows 

       # of components 

from 1 to 20 

       em with  

10 random seeds 
       implementation of 

lu & boutilier 

this is the naive approach, without real structure learning! 

what happens if you  
ignore constraints? 

structured na  ve bayes classifier 

optimal, heuristic, random 

c	    

xn	

o

o
x o
x x x

x1	

x x o
o o x
x x o

x2	

x o x
o x
x

o

attribute with 362,880 values (possible game traces) 

structured na  ve bayes classifier 

c	    normal, abnormal 

xn	

s	

x1	

x2	

s	

s	

t	

t	

t	

attribute with 789,360,053,252 values (routes in 8    8 grid) 

ongoing work: learn anomalies from uber data 

structured datasets and queries 

incomplete data 

a classical 

complete dataset 

a classical 

 incomplete dataset 

a new type of 

 incomplete dataset 

id 

1 

2 

3 

4 

5 

x 
x1 
x2 
x2 
x1 
x1 

y 
y2 
y1 
y1 
y1 
y2 

z 
z1 
z2 
z2 
z1 
z2 

closed-form 

(maximum-likelihood  
estimates are unique) 

id 

1 

2 

3 

4 

5 

x 
x1 
x2 
? 
? 
x1 

y 
y2 
y1 
? 
y1 
y2 

z 
? 
? 
z2 
z1 
z2 

em algorithm  
(on psdds) 

1 

2 

3 

4 

5 

id 

x 

z 

y 
x     z 

x2 and (y2 or z2) 

x2     y1 

x     y     z     1 
x1 and y2 and z2 

missed in the  
ml literature 

structured datasets 

a classical complete dataset 

(e.g., total rankings) 

a classical incomplete dataset 

(e.g., top-k rankings) 

id 

1 

2 

3 

4 

5 

1st 

sushi 
fatty 
tuna 
fatty 
tuna 

tuna 

fatty 
tuna 
egg 

2nd 
sushi 
sea 
urchin 

tuna 

tuna 
roll 

salmon 

roe 
squid 

3rd 
sushi      
salmon 
roe      

shrimp      

sea 
eel      

tuna      

shrimp      

id 

1 

2 

3 

4 

5 

1st 

sushi 
fatty 
tuna 
fatty 
tuna 

tuna 

fatty 
tuna 

egg 

2nd 
sushi 
sea 
urchin 
? 
tuna 
roll 

salmon 

roe 
? 

3rd 
sushi      
?      
?      
?      
?      
?      

structured datasets 

a classical complete dataset 

(e.g., total rankings) 

a new type of incomplete dataset 

(e.g., partial rankings) 

id 

1 

2 

3 

4 

5 

1st 

sushi 
fatty 
tuna 
fatty 
tuna 

tuna 

fatty 
tuna 
egg 

2nd 
sushi 
sea 
urchin 

tuna 

tuna 
roll 

salmon 

roe 
squid 

3rd 
sushi      
salmon 
roe      

shrimp      

sea 
eel      

tuna      

shrimp      

id 

1 

2 

3 

4 

5 

1st 

2nd 
sushi 

3rd 
sushi      

sushi 
(fatty tuna > sea urchin) 
and (tuna > sea eel)  
(fatty tuna is 1st) and 
(salmon roe > egg) 

tuna > squid 

egg is last 

egg > squid > shrimp 

    

    

    
    
    

(represents constraints on  
possible total rankings) 

learning from incomplete data 

 

       movielens dataset: 
       3,900 movies, 6,040 users, 1m ratings 
       take ratings from 64 most rated movies 
       ratings 1-5 converted to pairwise prefs. 

       psdd for partial rankings 
       4 tiers 
       18,711 parameters  

movies by expected tier 

rank 

movie 

1 
2 
3 
4 
5 
6 
7 
8 
9 
10 

the godfather 

the usual suspects 

casablanca 

the shawshank redemption 

schindler   s list 

one flew over the cuckoo   s nest 

the godfather: part ii 

monty python and the holy grail 

raiders of the lost ark 

star wars iv: a new hope 

psdd sizes 

structured queries 

 
 
      
      

no other star wars movie in top-5 
at least one comedy in top-5 

rank 

movie 

rank 

movie 

1 
2 
3 
4 
5 

star wars v: the empire strikes back 

star wars iv: a new hope 

the godfather 

the shawshank redemption 

the usual suspects 

1 
2 
3 
4 
5 

star wars v: the empire strikes back 

american beauty 
the godfather 

the usual suspects 

the shawshank redemption 

diversified recommendations via 

logical constraints 

conclusions 
       structured spaces are everywhere 
       roles of boolean constraints in ml 

      domain constraints and combinatorial objects 
(structured id203 space) 
      incomplete examples (structured datasets) 
      questions and evidence (structured queries) 
       learn distributions over combinatorial objects 
       strong properties for id136 and learning: 
probabilistic sentential decision diagram (psdd) 

conclusions 

statistical ml 
   id203    

symbolic ai 

   logic    

psdd 

connectionism 

   deep    

references 

probabilistic sentential decision diagrams 
doga kisa, guy van den broeck, arthur choi and adnan darwiche 
kr, 2014 
learning with massive logical constraints 
doga kisa, guy van den broeck, arthur choi and adnan darwiche 
icml 2014 workshop 
tractable learning for structured id203 spaces 
arthur choi, guy van den broeck and adnan darwiche 
ijcai, 2015 
tractable learning for complex id203 queries 
jessa bekker, jesse davis, arthur choi, adnan darwiche, guy van den broeck. 
nips, 2015 
structured features in naive bayes classifiers 
arthur choi, nazgol tavabi and adnan darwiche 
aaai, 2016 
tractable operations on arithmetic circuits 
jason shen, arthur choi and adnan darwiche 
nips, 2016 
 

questions? 

psdd 

