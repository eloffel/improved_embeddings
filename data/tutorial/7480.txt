iterative improvement 

search

hill climbing, simulated annealing, 
walksat, and id107

andrew w. moore

professor

school of computer science
carnegie mellon university

www.cs.cmu.edu/~awm

awm@cs.cmu.edu

412-268-7599

note to other teachers and users of these slides. andrew would be delighted if you found this source 
material useful in giving your own lectures. feel free to use these slides verbatim, or to modify them to fit 
your own needs. powerpoint originals are available. if you make use of a significant portion of these 
slides in your own lecture, please include this message, or the following link to the source repository of 
andrew   s tutorials: http://www.cs.cmu.edu/~awm/tutorials . comments and corrections gratefully received. 

slide 1

example problems

channel 
routing

lots of chip real-estate

same connectivity, 
much less space

slide 2

1

example problems
also:
parking lot layout, 
product design, aero-
dynamic design, 
   million queens   
problem, radiotherapy 
treatment planning,    

slide 3

informal characterization

these are problems in which   
    there is some combinatorial structure being optimized.
    there is a cost function:  structure (cid:198) real, to be 

optimized, or at least a reasonable solution is to be 
found.
(so basic csp methods only solve part of the problem 
    they satisfy constraints but don   t look for optimal 
constraint-satisfier.)

   

    searching all possible structures is intractable.
    depth first search approaches are too expensive.
    there   s no known algorithm for finding the optimal 

solution efficiently.

    very informally, similar solutions have similar costs.

slide 4

2

iterative improvement

intuition: consider the configurations to be laid out on the 
surface of a landscape.  we want to find the highest point.
(unlike other ai search problems like 8-puzzle, we don   t 
care how we get there.)
   iterative improvement    methods:
start at a random configuration; repeatedly consider 
various moves; accept some & reject some.  when you   re 
stuck, restart.
we must invent a moveset that describes what moves we 
will consider from any configuration.  let   s invent movesets 
for out four sample problems.

slide 5

hill-climbing

hill-climbing:  attempt to maximize eval(x) by moving to 
the highest configuration in our moveset.  if they   re all 
lower, we are stuck at a    local optimum.   
1. let x := initial config
2. let e := eval(x) 
3. let n = moveset_size(x)
4. for ( i = 0 ; i<n ; i := i+1) 

let ei := eval(move(x,i)) 

if all ei   s are     e, terminate, return x

5.
6. else let i* = argmaxi ei
7. x := move(x,i*)
8. e := ei*
9. goto 3

(not the most sophisticated algorithm in 
the world.)

slide 6

3

hill-climbing issues

    trivial to program
    requires no memory (since no backtracking)
    moveset design is critical.  this is the real ingenuity     not the 

decision to use hill-climbing.

   

    evaluation function design often critical.
    problems: dense local optima or plateaux
if the number of moves is enormous, the algorithm may be 
inefficient.  what to do?
if the number of moves is tiny, the algorithm can get stuck easily.  
what to do?
it   s often cheaper to evaluate an incremental change of a previously 
evaluated object than to evaluate from scratch.  does hill-climbing 
permit that?

   

   

    what if approximate evaluation is cheaper than accurate evaluation?
   

inner-loop optimization often possible.

slide 7

randomized hill-climbing

1. let x := initial config
2. let e := eval(x) 
3. let i = random move from the moveset
4. let ei := eval(move(x,i))
5.

if e < ei then

x := move(x,i)
e := ei

6. goto 3 unless bored.

what stopping criterion should we use?

any obvious pros or cons compared with our previous hill 
climber?

slide 8

4

hill-climbing example: gsat

walksat (randomized gsat):

pick a random unsatisfied clause;
consider 3 moves: flipping each variable.
if any improve eval, accept the best.
if none improve eval, then 50% of the time, pick the move that is the 
least bad; 50% of the time, pick a random one.

this is the best known algorithm for satisfying boolean formulae! [selman]
slide 9

hill-climbing example: tsp

minimize: eval(config) = length of tour

moveset:  2-change     k-change
example:  2-change

slide 10

5

3-change example

slide 11

hill-climbing example: tsp
this class of algorithms for the tsp is usually referred to 
as k-opt

(moveset: 2-change,     k-change) for some constant k.

lin showed empirically:

    3-opt solutions are much better than 2-opt
    4-opt solutions are not sufficiently better than 3-opt to justify the 

extra compute time

    a 3-opt tour for the  48-city problem of held and karp has about 

a id203 of 0.05 of being optimal (100 random restarts will
yield the optimal solution with id203 0.99)

    further for his particular class of tsp, a 3-opt tour is optimal with 

id203 2-n/10 where n is a number of cities.

there is no theoretical justification for any of these results.
slide 12

6

simulated annealing

the 

1. let x := initial config
2. let e := eval(x) 
3. let i = random move from 
moveset
4. let ei := eval(move(x,i))
5.

if e < ei then

x := move(x,i)
e := ei

else with some id203, 
accept the move even though 
things get worse:
x := move(x,i)
e := ei

6. goto 3 unless bored.

slide 13

simulated annealing

the 

1. let x := initial config
2. let e := eval(x) 
3. let i = random move from 
moveset
4. let ei := eval(move(x,i))
5.

if e < ei then

x := move(x,i)
e := ei

else with some id203, 
accept the move even though 
things get worse:
x := move(x,i)
e := ei

6. goto 3 unless bored.

this may make the search 
fall out of mediocre local 
minima and into better local 
maxima.
how should we choose the 
id203 of accepting a 
worsening move?
    idea one. id203 =  

0.1

    idea two. id203 

decreases with time

    idea three. id203 

decreases with time, and 
also as e     ei increases.

slide 14

7

simulated annealing

if ei >= e then definitely accept the change.
if ei < e then accept the change with id203 

exp (-(e - ei)/ti)

(called the boltzman distribution)

   where ti is a    temperature    parameter that 
gradually decreases.  typical cooling schedule:  
ti = t0    r   

high temp: accept all moves (random walk)
low temp: stochastic hill-climbing
when enough iterations have passed without improvement, 
terminate.

this idea was introduced by metropolis in 1953.  it is    based    on    similarities   
and    analogies    with the way that alloys manage to find a nearly global minimum energy 
level when they are cooled slowly.

slide 15

aside: analogy-based algorithms
your lecturer predicts that for any natural phenomenon you can think 
of, there will be at least one ai research group that will have a 
combinatorial optimization algorithm    based    on    analogies    and 
   similarities    with the phenomenon.  here   s the beginning of the list   
    metal cooling annealing
    evolution / co-evolution / sexual reproduction
    thermodynamics
    societal markets
    management hierarchies
    ant/insect colonies
    immune system
    animal behavior conditioning
    neuron / brain models
    hill-climbing (okay, that   s a stretch   )
    particle physics
    inability of elephants to play chess

slide 16

8

simulated annealing issues
    moveset design is critical.  this is the real ingenuity    

not the decision to use simulated annealing.

    evaluation function design often critical.
    annealing schedule often critical.
   

it   s often cheaper to evaluate an incremental change of a 
previously evaluated object than to evaluate from 
scratch.  does simulated annealing permit that?

    what if approximate evaluation is cheaper than accurate 

evaluation?
inner-loop optimization often possible.

   

slide 17

manhattan channel routing

slide 18

9

channel routing: moveset

simple moveset: pick up a wire and move it to another track at random.  
(problem: almost all such moves are illegal!)
fancy moveset: makes search more efficient

draw vertical constraints in a 
graph (arrow means    must lie 
above   )

1

5

3

4

9

8

10

7

6

packing wires onto the same track 
= = merging nodes.  (the graph 
must remain acyclic, and you must 
check horizontal constraints too.)

4,10

7

9

5

1,6,8

slide 19

channel routing: cost function

   clearly, the objective function to be minimized is the channel width w.  
however, w is too crude a measure of the quality of intermediate 
solutions.  instead,     the following cost function is used:   

c = w2 +   p    p2 +   u    u

where

p is a lower bound on the size of the constraint graph after future 
merge operations,

u measures the variance of how tightly the horizontal tracks are 
packed,

and   p and   u are hand-tweaked constants.
--- wong, simulated annealing for vlsi design

slide 20

10

   modified lam    schedule

(this is just to give you and idea of how 
wacky these things can be.)
idea:  dynamically lower and raise temp to 
meet a target accept rate over time.
advantages:  few parameters to tweak; you 
know in advance how long the algorithm will 
run; works well empirically.

slide 21

sa discussion

simulated annealing is sometimes empirically much better 
at avoiding local minima than hill-climbing.  it is a 
successful, frequently-used, algorithm.  worth putting in 
your algorithmic toolbox.
sadly, not much opportunity to say anything formal about it 
(though there is a proof that with an infinitely slow cooling 
rate, you   ll find the global optimum).
there are mountains of practical, and problem-specific, 
papers on improvements.

slide 22

11

id107

in the basic ga, objects are coded up (carefully) as binary 
strings.  goal is to optimize some function of the bit-strings.

(diagram shamelessly 
copied from    dean et al: ai: 
theory and practice   .)
slide 23

genetic algorithm

a set of bitstrings.  this set is called a generation.  the algorithm 
produces a new generation from an old generation thusly:
    let g be the current generation of n bitstrings.
    for each bitstring (call them b0, b1,     bn-1) define

pi = eval(bi) /   j eval(bj).

    let g    be the next generation.  begin with it empty.
    for k = 0 ; k < n/2 ; k = k+1

    choose two parents each with id203

prob(parent = bi) = pi

    randomly swap bits in the two parents to obtain two new bitstrings
    for each bit in turn in the new bitstring, randomly invert it with some low 

id203

    add the two new bitstrings to g   

let your first generation consist of random bitstrings.

slide 24

12

ga issues

    bitstring representation is critical.  this is the real ingenuity     not the 

decision to use id107.  (how to encode tsp?)

    evaluation function design often critical.  in-laws always critical.
   

it   s often cheaper to evaluate an incremental change of a previously 
evaluated object than to evaluate from scratch.  do genetic 
algorithms permit that?

inner-loop optimization often possible.

    what if approximate evaluation is cheaper than accurate evaluation?
   
numerous twiddles:
    use rankings not evaluations in creating your pi parent selection 

probabilities.

    cross over contiguous chunks of the string instead of random bits?
    needn   t be bit strings .. could use strings over other finite alphabets.
    optimize over sentences from a grammar representing functions or

programs.  called genetic programming.

slide 25

general discussion

    often, the    second best way    to solve a problem.
    but relatively easy to implement.  can save a great deal 

of programming effort.

    but great care is needed in designing representations 

and movesets.  if someone tells you that sa/hillclimbing 
solved their problem, that person is probably not giving 
enough credit to their own problem-formulation-ability.
    don   t solve a problem with these methods that could 

be solved by id135, a-star search or 
constraint propagation!

    what if evaluating the objective function is really 

expensive?

slide 26

13

what you should know about 
iterative improvement algs.

    hill-climbing
    simulated annealing
    sat and channel routing domains
    given a simple problem (e.g. graph coloring from the csp 

lectures) be able to give sensible suggestions as to how 
to code it up for the above algorithms.

references:

simulated annealing: see numerical recipes in c, or for practical details of modified 
lam schedule etc.: ochotta 1994 ph.d. thesis, cmu ece.
hillclimbing: discussion in russell and norvig.
gsat, walksat: papers by bart selman and henry kautz (www.research.att.com)
channel routing: wong et al., simulated annealing for vlsi design, kluwer 1988.

slide 27

14

