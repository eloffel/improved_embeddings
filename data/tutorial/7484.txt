id116 and 
hierarchical 
id91

note to other teachers and users of 
these slides. andrew would be 
delighted if you found this source 
material useful in giving your own 
lectures. feel free to use these slides 
verbatim, or to modify them to fit your 
own needs. powerpoint originals are 
available. if you make use of a 
significant portion of these slides in 
your own lecture, please include this 
message, or the following link to the 
source repository of andrew   s tutorials: 
http://www.cs.cmu.edu/~awm/tutorials
. comments and corrections gratefully 
received. 

andrew w. moore

professor

school of computer science
carnegie mellon university

www.cs.cmu.edu/~awm

awm@cs.cmu.edu

412-268-7599

copyright    2001, andrew w. moore

nov 16th, 2001

some 
data

this could easily be 
modeled by a 
gaussian mixture 
(with 5 components)
but let   s look at an 
satisfying, friendly and 
infinitely popular 
alternative   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 2

1

lossy compression

suppose you transmit the 
coordinates of points drawn 
randomly from this dataset.
you can install decoding 
software at the receiver.
you   re only allowed to send 
two bits per point.
it   ll have to be a    lossy 
transmission   .
loss = sum squared error 
between decoded coords and 
original coords.
what encoder/decoder will 
lose the least information?

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 3

break into a grid, 
decode each bit-pair 
as the middle of 
each grid-cell

suppose you transmit the 
coordinates of points drawn 
randomly from this dataset.
you can install decoding 
software at the receiver.
you   re only allowed to send 
two bits per point.
it   ll have to be a    lossy 
transmission   .
loss = sum squared error 
between decoded coords and 
original coords.
what encoder/decoder will 
lose the least information?

idea one

00

10

01

11

?

s

a

i d e

 

r

t e

  b e t

a n y

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 4

2

idea two

break into a grid, decode 
each bit-pair as the 
centroid of all data in 
that grid-cell

suppose you transmit the 
coordinates of points drawn 
randomly from this dataset.
you can install decoding 
software at the receiver.
you   re only allowed to send 
two bits per point.
it   ll have to be a    lossy 
transmission   .
loss = sum squared error 
between decoded coords and 
original coords.
what encoder/decoder will 
lose the least information?

00

01

11

10

?

s

a

i d e

 

r

t h e

  f u r

a n y

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 5

id116

1. ask user how many 
clusters they   d like. 
(e.g. k=5) 

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 6

3

id116

1. ask user how many 
clusters they   d like. 
(e.g. k=5) 

2. randomly guess k 

cluster center 
locations

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 7

id116

1. ask user how many 
clusters they   d like. 
(e.g. k=5) 

2. randomly guess k 

cluster center 
locations

3. each datapoint finds 
out which center it   s 
closest to. (thus 
each center    owns    
a set of datapoints)

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 8

4

id116

1. ask user how many 
clusters they   d like. 
(e.g. k=5) 

2. randomly guess k 

cluster center 
locations

3. each datapoint finds 
out which center it   s 
closest to.

4. each center finds 
the centroid of the 
points it owns

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 9

id116

1. ask user how many 
clusters they   d like. 
(e.g. k=5) 

2. randomly guess k 

cluster center 
locations

3. each datapoint finds 
out which center it   s 
closest to.

4. each center finds 
the centroid of the 
points it owns   

5.    and jumps there
6.    repeat until 

terminated!

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 10

5

id116 

start

advance apologies: in 
black and white this 
example will deteriorate
example generated by 
dan pelleg   s super-duper 
fast id116 system:

dan pelleg and andrew 
moore. accelerating exact 
id116 algorithms with 
geometric reasoning. 
proc. conference on 
knowledge discovery in 
databases 1999, 
(kdd99) (available on 
www.autonlab.org/pap.html)

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 11

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 12

6

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 13

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 14

7

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 15

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 16

8

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 17

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 18

9

id116 
continues

   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 19

id116 
terminates

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 20

10

id116 questions

    what is it trying to optimize?
    are we sure it will terminate?
    are we sure it will find an optimal 

id91?

    how should we start it?
    how could we automatically choose the 

number of centers?

   .we   ll deal with these questions over the next few slides

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 21

distortion

given..
   an encoder function: encode :    m     [1..k] 
   a decoder function: decode : [1..k]        m
define   

distortion

=

r

   

i

1
=

(
x

i

   

[
decode

encode

(

x

i

)
2)]

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 22

11

distortion

given..
   an encoder function: encode :    m     [1..k] 
   a decoder function: decode : [1..k]        m
define   

distortion

=

r

   

i

1
=

(
x

i

   

[
decode

encode

(

x

i

)
2)]

we may as well write

so

distortion

decode
   

=

(

r

j
][
x

i

   

=
c

c

j

encode

(

x

)

i

2

)

i

1
=

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 23

the minimal distortion

distortion

=

r

   

i

1
=

(

x

i

   

c

encode

(

x

)

i

2

)

what properties must centers c1, c2,     , ck have 
when distortion is minimized?

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 24

12

the minimal distortion (1)

distortion

=

r

   

i

1
=

(

x

i

   

c

encode

(

x

)

i

2

)

what properties must centers c1, c2,     , ck have 
when distortion is minimized?
(1) xi  must be encoded by its nearest center

   .why?

c

encode

(

x

)

i

=

c

arg
cc
,{
   
1

(min
c
,...
}

2

k

j

x

i

   

c

2

)

j

..at the minimal distortion

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 25

the minimal distortion (1)

distortion

=

r

   

i

1
=

(

x

i

   

c

encode

(

x

)

i

2

)

what properties must centers c1, c2,     , ck have 
when distortion is minimized?
(1) xi  must be encoded by its nearest center

   .why?

otherwise distortion could be 
reduced by replacing encode[xi] 
by the nearest center

c

encode

(

x

)

i

=

c

arg
cc
,{
   
1

(min
c
,...
}

2

k

j

x

i

   

c

2

)

j

..at the minimal distortion

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 26

13

the minimal distortion (2)

distortion

=

r

   

i

1
=

(

x

i

   

c

encode

(

x

)

i

2

)

what properties must centers c1, c2,     , ck have 
when distortion is minimized?
(2) the partial derivative of distortion with respect 
to each center location must be zero.

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 27

(2) the partial derivative of distortion with respect 
to each center location must be zero.

distortion

distortion
   

c
   

j

=

=

=

=

=

encode

2

)

(

x

i

)

r

i

i

(

c

x

   

   
       

1
=
k

x
(
c
ownedby(

j

1
=    

i

i
j

   

c

2

)

j

)

ownedby(cj) = the set 
of records owned by 
center cj.

   
c
   

   

 0

2

j

)

i
j

)

c

   

   

j
2

x
(
c
i
ownedby(
   
   
x
(
j
c
i
ownedby(
   
minimum)
(for 
 a

   

c

)

i
j

)

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 28

14

(2) the partial derivative of distortion with respect 
to each center location must be zero.

distortion

distortion
   

c
   

j

=

=

=

=

=

encode

2

)

(

x

i

)

r

i

i

(

c

x

   

   
       

1
=
k

j

1
=    

i

x
(
c
ownedby(

i
j

   

c

2

)

j

)

   
c
   

   

 0

j

)

2

i
j

)

c

   

   

j
2

x
(
c
i
ownedby(
   
   
x
(
j
c
i
ownedby(
   
minimum)
(for 
 a
=

   

c

c

)

i
j

)

j

thus, at a minimum:

1

|

c
ownedby(

|)

j

   

x
i
c
i
ownedby(
   

)

j

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 29

at the minimum distortion

distortion

=

r

   

i

1
=

(

x

i

   

c

encode

(

x

)

i

2

)

what properties must centers c1, c2,     , ck have when 
distortion is minimized?
(1) xi  must be encoded by its nearest center
(2) each center must be at the centroid of points it owns.

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 30

15

improving a suboptimal configuration   

distortion

=

r

   

i

1
=

(

x

i

   

c

encode

(

x

)

i

2

)

what properties can be changed for centers c1, c2,     , ck
have when distortion is not minimized?
(1) change encoding so that xi  is encoded by its nearest center
(2) set each center to the centroid of points it owns.
there   s no point applying either operation twice in succession.
but it can be profitable to alternate.
   and that   s id116!

easy to prove this procedure will terminate in a state at 
which neither (1) or (2) change the configuration. why?

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 31

i

i

i

(

)

2

x

r

(

)

1
=

c

x

   

encode

   

improving a suboptimal configuration   

there are only a finite number of ways of partitioning r 
records into k groups.
distortion
=
so there are only a finite number of possible 
configurations in which all centers are the centroids of 
if the configuration changes on an iteration, it must have 
the points they own.
improved the distortion.
so each time the configuration changes it must go to a 
configuration it   s never been to before.
so if it tried to go on forever, it would eventually run out 
of configurations.

what properties can be changed for centers c1, c2,     , ck
have when distortion is not minimized?
(1) change encoding so that xi  is encoded by its nearest center
(2) set each center to the centroid of points it owns.
there   s no point applying either operation twice in succession.
but it can be profitable to alternate.
   and that   s id116!

easy to prove this procedure will terminate in a state at 
which neither (1) or (2) change the configuration. why?

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 32

16

will we find the optimal 

configuration?

    not necessarily.
    can you invent a configuration that has 

converged, but does not have the minimum 
distortion?

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 33

will we find the optimal 

configuration?

    not necessarily.
    can you invent a configuration that has 

converged, but does not have the minimum 
distortion? (hint: try a fiendish k=3configuration here   )

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 34

17

will we find the optimal 

configuration?

    not necessarily.
    can you invent a configuration that has 

converged, but does not have the minimum 
distortion? (hint: try a fiendish k=3configuration here   )

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 35

trying to find good optima
    idea 1: be careful about where you start
    idea 2: do many runs of id116, each 

from a different random start configuration

    many other ideas floating around.

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 36

18

trying to find good optima
    idea 1: be careful about where you start
    idea 2: do many runs of id116, each 

from a different random start configuration

    many other ideas floating around.

neat trick:
place first center on top of randomly chosen datapoint.
place second center on datapoint that   s as far away as 
possible from first center

:

place j   th center on datapoint that   s as far away as 
possible from the closest of centers 1 through j-1

:

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 37

choosing the number of centers
    a difficult problem
    most common approach is to try to find the 

solution that minimizes the schwarz 
criterion (also related to the bic)

distortion

  +

(# 
distortion

log)
parameters
r
 
log 

  mk

+

r
 

=

m=#dimensions

k=#centers

r=#records

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 38

19

common uses of id116
    often used as an exploratory data analysis tool
    in one-dimension, a good way to quantize real-

valued variables into k non-uniform buckets

    used on acoustic data in speech understanding to 

convert waveforms into one of k categories 
(known as vector quantization)

    also used for choosing color palettes on old 

fashioned graphical display devices!

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 39

single linkage hierarchical 

id91

1. say    every point is its 

own cluster   

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 40

20

single linkage hierarchical 

id91

1. say    every point is its 

own cluster   

2. find    most similar    pair 

of clusters

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 41

single linkage hierarchical 

id91

1. say    every point is its 

own cluster   

2. find    most similar    pair 

of clusters

3. merge it into a parent 

cluster

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 42

21

single linkage hierarchical 

id91

1. say    every point is its 

own cluster   

2. find    most similar    pair 

of clusters

3. merge it into a parent 

cluster
4. repeat

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 43

single linkage hierarchical 

id91

1. say    every point is its 

own cluster   

2. find    most similar    pair 

of clusters

3. merge it into a parent 

cluster
4. repeat

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 44

22

single linkage hierarchical 

how do we define similarity 

between clusters?

id91

    minimum distance between 
points in clusters (in which 
case we   re simply doing 
euclidian minimum spanning 
trees)

    maximum distance between 

points in clusters

    average distance between 

points in clusters 

you   re left with a nice 

dendrogram, or taxonomy, or 
hierarchy of datapoints (not 

shown here)

1. say    every point is its 

own cluster   

2. find    most similar    pair 

of clusters

3. merge it into a parent 

cluster

4. repeat   until you   ve 

merged the whole 
dataset into one cluster

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 45

also known in the trade as 
hierarchical agglomerative 
id91 (note the acronym)

single linkage comments

    it   s nice that you get a hierarchy instead of 

an amorphous collection of groups

    if you want k groups, just cut the (k-1) 

longest links

    there   s no real statistical or information-
theoretic foundation to this. makes your 
lecturer feel a bit queasy.

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 46

23

what you should know

    all the details of id116
    the theory behind id116 as an 

optimization algorithm

    how id116 can get stuck
    the outline of hierarchical id91
    be able to contrast between which problems 

would be relatively well/poorly suited to k-
means vs gaussian mixtures vs hierarchical 
id91

copyright    2001, 2004, andrew w. moore

id116 and hierarchical id91: slide 47

24

