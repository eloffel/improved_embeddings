ti o
o
e

c

u

h
e
s
 
r   d a

r

t

e

d
  t
e

o

s

o

e

a
  f

r

h

t

h

t
 i n
p
  t
d
n
a
 
p l e
e m ,  
y
b ilit
a
b

s

e
r
h

o

r

e

d
-
 i n
s ifi e
  t
g
p
 

s
d i n
n
o
 

r
  m o
c l a
s
n
o
e

u

e
r

r

u

t

c

f

o
b

s

a

r

r  
a

y

u
l e

 

e

 

  n a    v
e w     s
.
s
r
e

o

n

  t
 
y
r
d
n
  a
  m i n
a

na  ve bayes
classifiers

note to other teachers and users of 
these slides. andrew would be delighted 
if you found this source material useful in 
giving your own lectures. feel free to use 
these slides verbatim, or to modify them 
to fit your own needs. powerpoint 
originals are available. if you make use 
of a significant portion of these slides in 
your own lecture, please include this 
message, or the following link to the 
source repository of andrew   s tutorials: 
http://www.cs.cmu.edu/~awm/tutorials . 
comments and corrections gratefully 
received. 

andrew w. moore

professor

school of computer science
carnegie mellon university

www.cs.cmu.edu/~awm

copyright    2004, andrew w. moore

awm@cs.cmu.edu

412-268-7599

t h e s e   n o t e s   a s s u m e   y o u   h a v e   a l r e a d y  
m e t   b a y e s i a n   n e t w o r k s

a simple bayes net

j

c

z

r

j
c
z
r

person is a junior
brought coat to classroom
live in zipcode 15213
saw    return of the king    more than once

copyright    2004, andrew w. moore

slide 2

a simple bayes net

j

what parameters are 
stored in the cpts of 
this bayes net?

c

z

r

j
c
z
r

person is a junior
brought coat to classroom
live in zipcode 15213
saw    return of the king    more than once

copyright    2004, andrew w. moore

slide 3

a simple bayes net

p(j) =

j

j
c
z
r

person is a junior
brought coat to classroom
live in zipcode 15213
saw    return of the king    more 
than once

c

z

r

p(c|j) =
p(c|~j)=

p(z|j) =
p(z|~j)=

p(r|j) =
p(r|~j)=

s u p p o s e   w e   h a v e   a   d a t a b a s e   f r o m   2 0   p e o p l e  
w h o   a t t e n d e d   a   l e c t u r e .   h o w   c o u l d   w e   u s e  
t h a t   t o   e s t i m a t e   t h e   v a l u e s   i n   t h i s   c p t ?

copyright    2004, andrew w. moore

slide 4

a simple bayes net

p(j) =

j

 #

j
c
people
z
 #
r

person is a junior
brought coat to classroom
 walked
 who
 to
school
 
live in zipcode 15213
in 
 
people
database
saw    return of the king    more 
than once
brought 
 
and 
 to
school
 

coat

 a

 #

people
f

 who
 #

school
 
 to
 walked
r
 walked
 who

people

p(z|j) =
p(z|~j)=

p(r|j) =
p(r|~j)=

s u p p o s e   w e   h a v e   a   d a t a b a s e   f r o m   2 0   p e o p l e  
w h o   a t t e n d e d   a   l e c t u r e .   h o w   c o u l d   w e   u s e  
t h a t   t o   e s t i m a t e   t h e   v a l u e s   i n   t h i s   c p t ?

bringers
 who
didn'
 
didn'
t walk to
 
school
 who
 

t walk to
school
 

-
people

 #

coat
 #

c

p(c|j) =
p(c|~j)=

copyright    2004, andrew w. moore

slide 5

a na  ve bayes classifier

j

p(j) =

output attribute

walked to school
brought coat to classroom
live in zipcode 15213
saw    return of the king    more 
than once

j
c
z
r

c

z

r

p(c|j) =
p(c|~j)=

p(z|j) =

p(z|~j)=input attributes

p(r|j) =
p(r|~j)=

a new person shows up at class wearing an    i live right above the 
manor theater where i saw all the lord of the rings movies every
night    overcoat.
what is the id203 that they are a junior?

copyright    2004, andrew w. moore

slide 6

na  ve bayes classifier id136

cjp
(
^|

=

rz
)^
  
=
rz
cjp
^^(
)^
  
rz
cp
)^
^(
  
cjp
^^(
rz
)^
  

cjp
^^(

r

=

rz
)^
  
cjp
(
^^

  +

  

rz
)^

jpjrpjzpjcp
)(
(
jpjrpjzpjcp
(
)(

)
)

)
)

)
)

|
|

|
|

(
(

(
(

  
  

|
|
+
rpj
)
    

(

|

zpjcp
(

  

(

)

|

|

  

jpj
)
  

(

)

   
   
   
   
   

copyright    2004, andrew w. moore

slide 7

j

c

z

=

   
   
   
   
   

the general case

y

x1

x2

. . .

xm

1. estimate p(y=v) as fraction of records with y=v
2. estimate p(xi=u | y=v) as fraction of    y=v    records that also 

have x=u.

3. to predict the y value given observations of all the xi values, 

compute

predict

y

=

argmax

v

yp
(

=

xv
|

=

u
1

1

x

m

=

u

)

m

l

copyright    2004, andrew w. moore

slide 8

predict

y

predict

y

v

1

=

argmax

na  ve bayes classifier
u
x
=
=
l
u
x
=
m
u
)
=
m
vypv
)
=
=
u
=

yp
xv
u
(
|
=
1
xvyp
u
(
^
l
1
1
x
u
=
l
m
1
x
yu
|
=
m
m
u
x
=
1

=
xp
(
u
l
1
xp
(

argmax

)
m
)

xp
(

=

=

=

(

)

m

m

m

m

1

1

1

v

v

l

)

predict

y

=

argmax

predict

y

=

argmax

v

xp
(

1

=

u
1

x

m

=

l

vypvyu
=
m

=

(

)

|

)

predict

y

=

argmax

v

yp
(

=

v

yn

   
)

j

1
=

xp
(

=

yu
j

|

j

=

because of the structure of 

the bayes net
v
)

copyright    2004, andrew w. moore

slide 9

more facts about na  ve bayes

classifiers

    na  ve bayes classifiers can be built with real-valued 

inputs*

    rather technical complaint: bayes classifiers don   t try to 
be maximally discriminative---they merely try to honestly 
model what   s going on*

    zero probabilities are painful for joint and na  ve. a hack 

(justifiable with the magic words    dirichlet prior   ) can 
help*.

    na  ve bayes is wonderfully cheap. and survives 10,000 

attributes cheerfully!

*see future andrew lectures

copyright    2004, andrew w. moore

slide 10

what you should know

    how to build a bayes classifier
    how to predict with a bc

copyright    2004, andrew w. moore

slide 11

