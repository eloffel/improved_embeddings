why is go hard for computers to play?

game tree complexity = bd

brute force search intractable:

1. search space is huge
2.

   impossible    for computers 
to evaluate who is winning

convolutional neural network

value network

evaluation

v (s)(cid:7578)

s

(cid:7578)

position

policy network

      move probabilities

 p (a|s)(cid:7589)

(cid:7589)

s

position

neural network training pipeline

human expert

positions

supervised learning

policy network

id23

policy network

self-play data

value network

supervised learning of policy networks

policy network: 12 layer convolutional neural network

training data: 30m positions from human expert games (kgs 5+ dan)

training algorithm: maximise likelihood by stochastic id119

                              

 

training time: 4 weeks on 50 gpus using google cloud

results: 57% accuracy on held out test data (state-of-the art was 44%)

id23 of policy networks

policy network: 12 layer convolutional neural network

training data: games of self-play between policy network

training algorithm: maximise wins z by policy gradient id23

training time: 1 week on 50 gpus using google cloud

results: 80% vs supervised learning. raw network ~3 amateur dan. 

id23 of value networks

value network: 12 layer convolutional neural network

training data: 30 million games of self-play

training algorithm: minimise mse by stochastic id119

training time: 1 week on 50 gpus using google cloud

results: first strong position evaluation function - previously thought impossible

exhaustive search

reducing depth with value network

reducing breadth with policy network

evaluating alphago against computers

l

a
p
h
a
g
o
 
(
s
e
o
u

l
 
v
1
8
)

l

a
p
h
a
g
o
 
(

n
a
t
u
r
e
 
v
1
3
)

4500

4000

3500

3000

2500

2000

1500

1000

500

0

9p
7p
5p
3p
1p
9d

7d

5d

3d

1d
1k
3k
5k
7k

z
e
n

c
r
a
z
y
 
s
t
o
n
e

p
a
c
h

i

f
u
e
g
o

g
o

g
n
u

d
a
n
 
(
p
)

p
r
o
f
e
s
s
o
n
a

i

l
 

 

d
a
n
 
(
d
)

a
m
a
t
e
u
r

 

k
y
u

 
 
(
k
)

i

b
e
g
n
n
e
r

computer programs

calibration

human players

alphago (mar 2016)

deepmind challenge match

4-1

    beats

alphago (oct 2015)

       beats

nature match

5-0

crazy stone and zen

kgs

lee sedol (9p)
top player of 
past decade

  beats

fan hui (2p)

3-times reigning 
euro champion

 beats

amateur 
humans

what   s next?

demis hassabis

