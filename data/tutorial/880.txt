a survey of id39 and classification 

 

david nadeau, satoshi sekine 
national research council canada / new york university 
 

introduction 
 
the term    named entity   , now widely used in natural language processing, was coined 
for  the  sixth  message  understanding  conference  (muc-6)  (r.  grishman  &  sundheim 
1996).  at  that  time,  muc  was  focusing  on  information  extraction  (ie)  tasks  where 
structured  information  of  company  activities  and  defense  related  activities  is  extracted 
from  unstructured text,  such  as  newspaper  articles.  in  defining  the  task, people  noticed 
that  it  is  essential  to  recognize  information  units  like  names,  including  person, 
organization  and  location names,  and  numeric  expressions  including time,  date, money 
and percent expressions. identifying references to these entities in text was recognized as 
one  of  the  important  sub-tasks  of  ie  and  was  called     named  entity  recognition  and 
classification (nerc)   . 

we present here a survey of fifteen years of research in the nerc field, from 1991 
to  2006.  while  early  systems  were  making  use  of  handcrafted  rule-based  algorithms, 
modern  systems  most  often  resort  to  machine  learning  techniques.  we  survey  these 
techniques  as  well  as  other  critical  aspects  of  nerc  such  as  features  and  evaluation 
methods. it was indeed concluded in a recent conference that the choice of features is at 
least  as  important  as  the  choice  of  technique  for  obtaining  a  good  nerc  system  (e. 
tjong kim sang & de meulder 2003). moreover, the way nerc systems are evaluated 
and compared is essential to progress in the field. to the best of our knowledge, nerc 
features, techniques, and evaluation methods have not been surveyed extensively yet.  

the first section of this survey presents some observations on published work from 
the point of view of activity per year, supported languages, preferred textual genre and 
domain,  and  supported  entity  types.  it  was  collected  from  the  review  of  a  hundred 
english  language  papers  sampled  from  the  major  conferences  and  journals.  we  do  not 
claim this review to be exhaustive or representative of all the research in all languages, 
but we believe it gives a good feel for the breadth and depth of previous work. section 2 
covers  the  algorithmic  techniques  that  were  proposed  for  addressing  the  nerc  task. 
most  techniques  are  borrowed  from  the  machine  learning  (ml)  field.  instead  of 
elaborating  on  techniques  themselves, the third  section  lists and  classifies  the proposed 
features,  i.e.,  descriptions  and  characteristic  of  words  for  algorithmic  consumption. 
section 4 presents some of the evaluation paradigms that were proposed throughout the 
major forums. finally, we present our conclusions. 

1  observations: 1991 to 2006 
 
the  computational  research  aiming  at  automatically  identifying  named  entities  in  texts 
forms a vast and heterogeneous pool of strategies, methods and representations. one of 
the first research papers in the field was presented by lisa f. rau (1991) at the seventh 

 

2 

ieee conference on artificial intelligence applications. rau   s paper describes a system 
to    extract and recognize [company] names   . it relies on heuristics and handcrafted rules. 
from 1991 (1 publication) to 1995 (we found 8 publications in english), the publication 
rate remained relatively low. it accelerated in 1996, with the first major event dedicated 
to the task: muc-6 (r. grishman & sundheim 1996). it never declined since then with 
steady research and numerous scientific events:  hub-4 (n. chinchor et al. 1998), muc-
7 and met-2 (n. chinchor 1999), irex (s. sekine & isahara 2000), conll (e. tjong 
kim sang 2002, e. tjong kim sang & de meulder 2003), ace (g. doddington et al. 
2004)  and  harem  (d.  santos  et  al.  2006).  the  language  resources  and  evaluation 
conference (lrec)1 has also been staging workshops and main conference tracks on the 
topic since 2000. 

1.1  language factor 
a  good  proportion  of  work  in  nerc  research is devoted to the  study  of  english  but a 
possibly  larger  proportion  addresses  language  independence  and  multilingualism 
problems.  german  is  well  studied  in  conll-2003  and  in  earlier  works.  similarly, 
spanish  and  dutch  are  strongly  represented,  boosted  by  a  major  devoted  conference: 
conll-2002. japanese has been studied in the muc-6 conference, the irex conference 
and other work. chinese is studied in an abundant literature (e.g., l.-j. wang et al. 1992, 
h.-h.  chen  &  lee  1996,  s.  yu  et al. 1998)  and  so are  french  (g.  petasis et  al.  2001, 
poibeau  2003),  greek  (s.  boutsis  et  al.  2000)  and  italian  (w.  black  et  al.  1998,  a. 
cucchiarelli  &  velardi  2001).  many  other  languages  received  some  attention  as  well: 
basque (c. whitelaw & patrick 2003), bulgarian (j. da silva et al. 2004), catalan (x. 
carreras  et  al.  2003),  cebuano  (j.  may  et  al.  2003),  danish  (e.  bick  2004),  hindi  (s. 
cucerzan & yarowsky  1999, j. may et al. 2003), korean (c. whitelaw & patrick 2003), 
polish  (j.  piskorski  2004),  romanian  (s.  cucerzan  &  yarowsky    1999),  russian  (b. 
popov  et  al.  2004),  swedish  (d.  kokkinakis  1998)  and  turkish  (s.  cucerzan  & 
yarowsky  1999). portuguese was examined by (d. palmer & day 1997) and, at the time 
of writing this survey, the harem conference is revisiting that language. finally, arabic 
(f.  huang 2005) has  started to  receive  a  lot  of  attention in  large-scale  projects  such  as 
global autonomous language exploitation (gale)2. 

1.2  textual genre or domain factor 
the  impact  of  textual  genre  (journalistic,  scientific,  informal,  etc.)  and  domain 
(gardening, sports, business, etc.) has been rather neglected in the nerc literature. few 
studies are specifically devoted to diverse genres and domains. d. maynard et al. (2001) 
designed a system for emails, scientific texts and religious texts. e. minkov et al. (2005) 
created a system specifically designed for email documents. perhaps unsurprisingly, these 
experiments demonstrated that although any domain can be reasonably supported, porting 
a  system  to  a  new  domain  or  textual  genre  remains a  major  challenge.  t.  poibeau  and 
kosseim  (2001),  for  instance,  tested  some  systems  on  both  the  muc-6  collection 
composed of newswire texts, and on a proprietary corpus made of manual translations of 
phone conversations and technical emails. they report a drop in performance for every 
system (some 20% to 40% of precision and recall). 
                                                 
1 http://www.lrec-conf.org/ 
2 http://projects.ldc.upenn.edu/gale/ 

 

3 

1.3  entity type factor 
in  the  expression     named  entity   ,  the  word     named     aims  to  restrict  the  task  to  only 
those entities for which one or many rigid designators, as defined by s. kripke (1982), 
stands for the referent. for instance, the automotive company created by henry ford in 
1903  is  referred  to  as  ford  or  ford motor  company.  rigid  designators include  proper 
names as well as certain natural kind terms like biological species and substances. there 
is  a  general  agreement  in  the  nerc  community  about  the  inclusion  of  temporal 
expressions and some numerical expressions such as amounts of money and other types 
of  units.  while  some  instances  of  these  types  are  good  examples  of  rigid  designators 
(e.g.,  the  year  2001  is  the  2001st  year  of  the  gregorian  calendar)  there  are  also  many 
invalid ones (e.g., in june refers to the month of an undefined year     past june, this june, 
june  2020,  etc.).  it  is  arguable  that  the  ne  definition  is  loosened  in  such  cases  for 
practical reasons.  
 
early  work  formulates  the  nerc  problem  as  recognizing     proper  names     in 
general (e.g., s. coates-stephens 1992, c. thielen 1995). overall, the most studied types 
are  three  specializations  of     proper  names   :  names  of     persons   ,     locations     and 
   organizations   .  these  types  are  collectively  known  as     enamex     since  the  muc-6 
competition. the type    location    can in turn be divided into multiple subtypes of    fine-
grained locations   : city, state, country, etc. (m. fleischman 2001, s. lee & geunbae lee 
2005). similarly,    fine-grained person    sub-categories like    politician    and    entertainer    
appear  in  the  work  of  m.  fleischman  and  hovy  (2002).  the  type     person     is  quite 
common and used at least once in an original way by o. bodenreider and zweigenbaum 
(2000)  who  combines  it  with  other  cues  for  extracting  medication  and  disease  names 
(e.g.,    parkinson disease   ). in the ace program, the type    facility    subsumes entities of 
the types    location    and    organization   . the type    gpe    is used to represent a location 
which has a government, such as a city or a country.  

the type    miscellaneous    is used in the conll conferences and includes proper 
names falling outside the classic    enamex   . the class is also sometimes augmented with 
the type    product    (e.g., e. bick 2004). the    timex    (another term coined in muc) types 
   date     and     time     and  the     numex     types     money     and     percent     are  also  quite 
predominant in the literature. since 2003, a community named timex2 (l. ferro et al. 
2005) proposes an elaborated standard for the annotation and id172 of temporal 
expressions. finally, marginal types are sometime handled for specific needs:    film    and 
   scientist    (o. etzioni et al. 2005),    email address    and    phone number    (i. witten et al. 
1999, d. maynard et al. 2001),    research area    and    project name    (j. zhu et al. 2005), 
   book title    (s. brin 1998, i. witten et al. 1999),    job title    (w. cohen & sarawagi 2004) 
and    brand    (e. bick 2004). 

a recent interest in bioinformatics, and the availability of the genia corpus (t. 
ohta  et  al.  2002)  led  to  many  studies  dedicated  to  types  such  as     protein   ,     dna   , 
   rna   ,    cell line    and    cell type    (e.g., d. shen et al. 2003, b. settles 2004) as well as 
studies targeted to    protein    recognition only (y. tsuruoka & tsujii 2003). related work 
also includes    drug    (t. rindfleisch et al. 2000) and    chemical    (m. narayanaswamy et 
al. 2003) names. 

some recent work does not limit the possible types to extract and is referred as 
   open domain    nerc (see e. alfonseca & manandhar 2002, r. evans 2003). in this line 
of  research,  s.  sekine  and  nobata  (2004)  defined  a  named  entity  hierarchy  which 

 

4 

includes many fine grained subcategories, such as museum, river or airport, and adds a 
wide range of categories, such as product and event, as well as substance, animal, religion 
or color. it tries to cover most frequent name types and rigid designators appearing in a 
newspaper.  the  number  of  categories  is  about  200,  and  they  are  now  defining  popular 
attributes for each category to make it an ontology. 

1.4  what   s next? 
recent researches in multimedia indexing, semi-supervised learning, complex linguistic 
phenomena, and machine translation suggest some new directions for the field. on one 
side,  there  is  a  growing  interest  in  multimedia  information  processing  (e.g.,  video, 
speech) and particularly ne extraction from it (r. basili et al. 2005). lot of effort is also 
invested toward semi-supervised and unsupervised approaches to nerc motivated by the 
use  of  very  large  collections  of  texts  (o.  etzioni  et  al.  2005)  and  the  possibility  of 
handling multiple ne types (d. nadeau et al. 2006). complex linguistic phenomena (e.g., 
metonymy) that are common short-coming of current systems are under investigation (t. 
poibeau,  2006).  finally,  large-scale  projects  such  as  gale,  discussed  in  section  1.1, 
open the way to integration of nerc and machine translation for mutual improvement. 

2  learning methods 
 
the  ability  to  recognize  previously  unknown  entities  is  an  essential  part  of  nerc 
systems.  such  ability  hinges  upon  recognition  and  classification  rules  triggered  by 
distinctive features associated with positive and negative examples. while early studies 
were  mostly  based  on  handcrafted  rules,  most  recent  ones  use  supervised  machine 
learning (sl) as a way to automatically induce rule-based systems or sequence labeling 
algorithms  starting  from  a  collection  of  training  examples.  this  is  evidenced,  in  the 
research  community,  by  the  fact  that  five  systems  out  of  eight  were  rule-based  in  the 
muc-7  competition  while  sixteen  systems  were  presented  at  conll-2003,  a  forum 
devoted  to  learning  techniques.  when  training  examples  are  not  available,  handcrafted 
rules  remain  the  preferred  technique,  as  shown  in  s.  sekine  and  nobata  (2004)  who 
developed a nerc system for 200 entity types.  
 
the idea of supervised learning is to study the features of positive and negative 
examples  of  ne  over  a  large  collection  of  annotated  documents  and  design  rules  that 
capture  instances  of  a  given  type.  section  2.1  explains  sl  approaches  in  more  details. 
the  main  shortcoming  of  sl  is  the  requirement  of  a  large  annotated  corpus.  the 
unavailability  of  such  resources  and  the  prohibitive  cost  of  creating  them  lead  to  two 
alternative learning methods: semi-supervised learning (ssl) and unsupervised learning 
(ul). these techniques are presented in section 2.2 and 2.3 respectively. 

2.1  supervised learning 
the current dominant technique for addressing the nerc problem is supervised learning. 
sl techniques include id48 (id48) (d. bikel et al. 1997), decision 
trees (s. sekine 1998), maximum id178 models (me) (a. borthwick 1998), support 
vector  machines  (id166)  (m.  asahara  &  matsumoto  2003),  and  conditional  random 
fields (crf) (a. mccallum & li 2003). these are all variants of the sl approach that 

 

5 

typically  consist  of  a  system  that  reads  a  large  annotated  corpus,  memorizes  lists  of 
entities, and creates disambiguation rules based on discriminative features.  

a baseline sl method that is often proposed consists of tagging words of a test 
corpus when they are annotated as entities in the training corpus. the performance of the 
baseline  system  depends  on  the  vocabulary  transfer,  which  is  the  proportion  of  words, 
without  repetitions,  appearing  in  both  training  and  testing  corpus.  d.  palmer  and  day 
(1997)  calculated  the  vocabulary  transfer  on  the  muc-6  training  data.  they  report  a 
transfer of 21%, with as much as 42% of location names being repeated but only 17% of 
organizations and 13% of person names. vocabulary transfer is a good indicator of the 
recall  (number  of  entities  identified  over  the  total  number  of  entities)  of  the  baseline 
system  but  is  a  pessimistic  measure  since  some  entities  are  frequently  repeated  in 
documents. a. mikheev et al. (1999) precisely calculated the recall of the baseline system 
on the muc-7 corpus. they report a recall of 76% for locations, 49% for organizations 
and  26%  for  persons  with  precision  ranging  from  70%  to  90%.  whitelaw  and  patrick 
(2003) report consistent results on muc-7 for the aggregated enamex class. for the three 
enamex types together, the precision of recognition is 76% and the recall is 48%.  

2.2  semi-supervised learning 
the  term     semi-supervised     (or     weakly  supervised   )  is  relatively  recent.  the  main 
technique for ssl is called    id64    and involves a small degree of supervision, 
such as a set of seeds, for starting the learning process. for example, a system aimed at 
   disease names    might ask the user to provide a small number of example names. then 
the  system  searches  for  sentences  that  contain  these  names  and  tries  to  identify  some 
contextual  clues  common  to  the  five  examples.  then,  the  system  tries  to  find  other 
instances of disease names that appear in similar contexts. the learning process is then 
reapplied  to  the  newly  found  examples,  so  as  to  discover  new  relevant  contexts.  by 
repeating this process, a large number of disease names and a large number of contexts 
will eventually be gathered. recent experiments in semi-supervised nerc (nadeau et al. 
2006)  report  performances  that  rival  baseline  supervised  approaches.  here  are  some 
examples of ssl approaches. 

s. brin (1998) uses lexical features implemented by id157 in order 
to generate lists of book titles paired with book authors. it starts with seed examples such 
as {isaac asimov, the robots of dawn} and use some fixed lexical control rules such as 
the  following  regular  expression [a-z][a-za-z .,&]5,30[a-za-z.] used  to  describe  a title. 
the main idea of his algorithm, however, is that many web sites conform to a reasonably 
uniform format across the site. when a given web site is found to contain seed examples, 
new  pairs  can  often  be  identified  using  simple  constraints  such  as  the  presence  of 
identical text before, between or after the elements of an interesting pair. for example, 
the passage    the robots of dawn, by isaac asimov (paperback)    would allow finding, 
on the same web site,    the ants, by bernard werber (paperback)   . 

m. collins and singer (1999) parse a complete corpus in search of candidate ne 
patterns.  a  pattern  is,  for  instance,  a  proper  name  (as  identified  by  a  part-of-speech 
tagger) followed by a noun phrase in apposition (e.g., maury cooper, a vice president at 
s&p).  patterns  are  kept  in  pairs  {spelling,  context}  where  spelling  refers  to  the  proper 
name and context refers to the noun phrase in its context. starting with an initial seed of 
spelling rules (e.g., rule 1: if the spelling is    new york    then it is a location; rule 2: if 

 

6 

the spelling contains    mr.    then it is a person; rule 3: if the spelling is all capitalized 
then it is an organization), the candidates are examined. candidate that satisfy a spelling 
rule  are  classified  accordingly  and  their  contexts  are  accumulated.  the  most  frequent 
contexts  found  are  turned  into  a  set  of  contextual  rules.  following  the  steps  above, 
contextual  rules  can  be  used  to  find  further  spelling  rules,  and  so  on.  m.  collins  and 
singer and r. yangarber et al. (2002), demonstrate the idea that learning several types of 
ne  simultaneously  allows  the  finding  of  negative  evidence  (one  type  against  all)  and 
reduces over-generation. s. cucerzan and yarowsky (1999) also use a similar technique 
and apply it to many languages. 
 
e.  riloff  and  jones  (1999)  introduce  mutual  id64  that  consists  of 
growing a set of entities and a set of contexts in turn. instead of working with predefined 
candidate ne   s (found using a fixed syntactic construct), they start with a handful of seed 
entity examples of a given type (e.g., bolivia, guatemala, honduras are entities of type 
country) and accumulate all patterns found around these seeds in a large corpus. contexts 
(e.g., offices in x, facilities in x,    ) are ranked and used to find new examples. riloff 
and jones note that the performance of that algorithm can deteriorate rapidly when noise 
is introduced in the entity list or pattern list. while they report relatively  low precision 
and recall in their experiments, their work proved to be highly influential. 
a. cucchiarelli and velardi (2001) use syntactic relations (e.g., subject-object) to 
 
discover more accurate contextual evidence around the entities. again, this is a variant of 
e. riloff  and  jones  mutual id64  (1999).  interestingly,  instead  of  using human 
generated seeds, they rely on existing ner systems (called early ne classifier) for initial 
ne examples.   
 
m. pasca et al. (2006) are also using techniques inspired by mutual id64. 
however,  they  innovate  through  the  use  of  d.  lin   s  (1998)  distributional  similarity  to 
generate synonyms     or, more generally, words which are members of the same semantic 
class       allowing  pattern  generalization.  for  instance,  for  the  pattern  x  was  born  in 
november,  lin   s  synonyms  for  november  are  {march,  october,  april,  mar,  aug., 
february, jul, nov., ...} thus allowing the induction of new patterns such as x was born 
in march. one of the contribution of pasca et al. is to apply the technique to very large 
corpora  (100  million  web  documents)  and  demonstrate  that  starting  from  a  seed  of  10 
examples  facts  (defined  as  entities  of  type  person  paired  with  entities  of  type  year  - 
standing for the person year of birth) it is possible to generate one million facts with a 
precision of about 88%. 
 
the problem of unlabelled data selection is addressed by j. heng and grishman 
(2006). they show how an existing ne classifier can be improved using id64 
methods. the main lesson they report is that relying upon large collection of documents 
is  not  sufficient  by  itself.  selection  of  documents  using  information  retrieval-like 
relevance measures and selection of specific contexts that are rich in proper names and 
coreferences bring the best results in their experiments.   

2.3  unsupervised learning 
the typical approach in unsupervised learning is id91. for example, one can try to 
gather named entities from clustered groups based on the similarity of context. there are 
other unsupervised methods too. basically, the techniques rely on lexical resources (e.g., 

 

7 

id138), on lexical patterns and on statistics computed on a large unannotated corpus. 
here are some examples. 

e. alfonseca and manandhar (2002) study the problem of labeling an input word 
with an appropriate ne type. ne types are taken from id138 (e.g., location>country, 
animate>person,  animate>animal,  etc.).  the  approach  is  to  assign  a  topic  signature  to 
each id138 synset by merely listing words that frequently co-occur with it in a large 
corpus.  then,  given  an  input  word  in  a  given  document,  the  word  context  (words 
appearing in a fixed-size window around the input word) is compared to type signatures 
and classified under the most similar one.  

in  r.  evans  (2003),  the  method  for  identification  of  hyponyms/hypernyms 
described  in  the  work  of  m.  hearst  (1992)  is  applied  in  order  to  identify  potential 
hypernyms  of  sequences  of  capitalized  words  appearing  in  a  document.  for  instance, 
when x is a capitalized sequence, the query    such as x   , is searched on the web and, in 
the retrieved documents, the noun that immediately precede the query can be chosen as 
the hypernym of x. similarly, in p. cimiano and v  lker (2005), hearst patterns are used 
but this time, the feature consists of counting the number of occurrences of passages like: 
   city such as   ,    organization such as   , etc.  

y.  shinyama  and  sekine  (2004)  used  an  observation  that  named  entities  often 
appear  synchronously  in  several  news  articles,  whereas  common  nouns  do  not.  they 
found  a  strong  correlation  between  being  a  named  entity  and  appearing  punctually  (in 
time) and simultaneously in multiple news sources. this technique allows identifying rare 
named entities in an unsupervised manner and can be useful in combination with other 
nerc methods. 

in  o.  etzioni  et  al.  (2005),  pointwise  mutual  information  and  information 
retrieval  (pmi-ir)  is  used  as  a  feature  to  assess  that  a  named  entity  can  be  classified 
under  a  given  type.  pmi-ir,  developed  by  p.  turney  (2001),  measures the  dependence 
between two expressions using web queries. a high pmi-ir means that expressions tend 
to co-occur. o. etzioni et al. create features for each candidate entity (e.g., london) and a 
large  number  of  automatically  generated  discriminator  phrases  like     is  a  city   ,     nation 
of   , etc. 

3  feature space for nerc 
 
features  are  descriptors  or  characteristic  attributes  of  words  designed  for  algorithmic 
consumption. an example of a feature is a boolean variable with the value true if a word 
is capitalized and false otherwise. feature vector representation is an abstraction over text 
where typically each word is represented by one or many boolean, numeric and nominal 
values. for example, a hypothetical nerc system may represent each word of a text with 
3 attributes:  
 
1) a boolean attribute with the value true if the word is capitalized and false otherwise; 
2) a numeric attribute corresponding to the length, in characters, of the word; 
3) a nominal attribute corresponding to the lowercased version of the word. 
 
in  this  scenario,  the  sentence     the  president  of  apple  eats  an  apple.   ,  excluding  the 
punctuation, would be represented by the following feature vectors:  

 

 

8 

<true,  3,    the   >,  <false, 9,    president   >, <false, 2,    of   >, 
5,    apple   >, <false, 4,    eats   >, <false, 2,    an   >, <false, 5,    apple   > 

<true,  

 
usually, the nerc problem is resolved by applying a rule system over the features. for 
instance,  a  system  might  have  two  rules,  a  recognition  rule:     capitalized  words  are 
candidate  entities     and  a  classification  rule:     the  type  of  candidate  entities  of  length 
greater than 3 words is organization   . these rules work well for the exemplar sentence 
above.  however,  real  systems  tend  to  be  much  more  complex  and  their  rules  are  often 
created by automatic learning techniques.  

in  this  section,  we  present  the  features  most  often  used  for  the  recognition  and 
classification of named entities. we organize them along three different axes: word-level 
features, list lookup features and document and corpus features. 

3.1  word-level features 
word-level  features  are  related  to  the  character  makeup  of  words.  they  specifically 
describe  word  case,  punctuation,  numerical  value  and  special  characters.  table  1  lists 
subcategories of word-level features.  
table 1: word-level features 

features 

examples 

case 
 
 
 
punctuation 
 
 
digit 
 
 
 
 
character 
 
 
morphology 
 
 
part-of-speech 
 
function 

- starts with a capital letter 
- word is all uppercased 
- the word is mixed case (e.g., prosys, ebay) 
 
- ends with period, has internal period (e.g., st., i.b.m.) 
- internal apostrophe, hyphen or ampersand (e.g., o   connor) 
 
- digit pattern (see section 3.1.1) 
- cardinal and ordinal 
- roman number 
- word with digits (e.g., w3c, 3m) 
 
- possessive mark, first person pronoun 
- greek letters 
 
- prefix, suffix, singular version, stem 
- common ending (see section 3.1.2) 
 
- proper name, verb, noun, foreign word 
 
- alpha, non-alpha, id165 (see section 3.1.3) 
- lowercase,  uppercase version 
- pattern, summarized pattern (see section 3.1.4) 
- token length,  phrase length 

3.1.1  digit pattern 
digits  can  express  a  wide  range  of  useful  information  such  as  dates,  percentages, 
intervals, identifiers, etc. special attention must be given to some particular patterns of 
digits. for example, two-digit and four-digit numbers can stand for years (d. bikel et al. 
1997) and when followed by an    s   , they can stand for a decade; one and two digits may 
stand for a day or a month (s. yu et al. 1998).  

 

9 

3.1.2  common word ending 
morphological features are essentially related to words affixes and roots. for instance, a 
system may learn that a human profession often ends in    ist    (journalist, cyclist) or that 
nationality  and  languages  often  ends  in     ish     and     an     (spanish,  danish,  romanian). 
another example of common word ending is organization names that often end in    ex   , 
   tech   , and    soft    (e. bick 2004). 

3.1.3  functions over words 
features can be extracted by applying functions over words. an example is given by m. 
collins and singer (1999) who create a feature by isolating the non-alphabetic characters 
of a word (e.g., nonalpha(a.t.&t.) = ..&.) another example is given by j. patrick et al. 
(2002) who use character id165s as features.  

3.1.4  patterns and summarized patterns 
pattern features were introduced by m. collins (2002) and then used by others (w. cohen 
&  sarawagi  2004 and  b.  settles  2004).  their  role  is to  map  words  onto a  small  set  of 
patterns  over  character  types.  for  instance,  a  pattern  feature  might  map  all  uppercase 
letters to    a   , all lowercase letters to    a   , all digits to    0    and all punctuation to    -   : 
 

x = "g.m.": getpattern(x) = "a-a-" 
x = "machine-223": getpattern(x) = "aaaaaaa-000" 

 
the summarized pattern feature is a condensed form of the above in which consecutive 
character  types  are  not  repeated  in  the  mapped  string.  for  instance,  the  preceding 
examples become: 
 

x = "g.m.": getsummarizedpattern(x) = "a-a-" 
x = "machine-223": getsummarizedpattern(x) = "aa-0" 

3.2  list lookup features 
lists  are  the  privileged  features  in  nerc.  the  terms     gazetteer   ,     lexicon     and 
   dictionary    are often used interchangeably with the term    list   . list inclusion is a way to 
express  the  relation     is  a     (e.g.,  paris  is  a  city).  it  may  appear  obvious  that  if  a  word 
(paris) is an element of a list of cities, then the id203 of this word to be city, in a 
given text, is high. however, because of word polysemy, the id203 is almost never 1 
(e.g.,  the  id203  of     fast     to  represent  a  company  is  low  because  of  the  common 
adjective    fast    that is much more frequent).  

 

table 2: list lookup features. 

10 

features 
general list 
 
 
 
 
list of entities 
 
 
 
list of entity cues 

examples 
- general dictionary (see section 3.2.1) 
- stop words (function words) 
- capitalized nouns (e.g., january, monday) 
- common abbreviations 
 
- organization, government, airline, educational 
- first name, last name, celebrity 
- astral body, continent, country, state, city 
 
- typical words in organization (see 3.2.2) 
- person title, name prefix, post-nominal letters 
- location typical word, cardinal point 

 
in  table  2,  we  present  three  significant  categories  of  lists  used  in  literature.  we  could 
enumerate  many  more  list  examples  but  we  decided  to  concentrate  on  those  aimed  at 
recognizing enamex types. 

3.2.1  general dictionary 
common nouns  listed in  a dictionary  are  useful,  for  instance, in the  disambiguation  of 
capitalized words in ambiguous positions (e.g., sentence beginning). a. mikheev (1999) 
reports  that  from  2677  words  in  ambiguous  position  in  a  given  corpus,  a  general 
dictionary  lookup  allows  identifying  1841  common  nouns  out  of  1851  (99.4%)  while 
only discarding 171 named entities out of 826 (20.7%). in other words, 20.7% of named 
entities are ambiguous with common nouns, in that corpus. 

3.2.2  words that are typical of organization names  
many authors propose to recognize organizations by identifying words that are frequently 
used  in  their  names.  for  instance,  knowing  that     associates     is  frequently  used  in 
organization  names  could  lead  to  the  recognition  of     computer  associates     and 
   biomedia associates    (d. mcdonald 1993, r. gaizauskas et al. 1995). the same rule 
applies to frequent first words (   american   ,    general   ) of an organization (l. rau 1991). 
some authors also exploit the fact that organizations often include the name of a person 
(f.  wolinski  et  al.  1995,  y.  ravin  &  wacholder  1996)  as  in     alfred  p.  sloan 
foundation   .  similarly,  geographic  names  can  be  good  indicators  of  an  organization 
name (f. wolinski et al. 1995) as in    france telecom   . organization designators such as 
   inc    and    corp    (l. rau 1991) are also useful features. 

3.2.3  on the list lookup techniques 
most approaches implicitly require candidate words to exactly match at least one element 
of  a  pre-existing  list.  however,  we  may  want  to  allow  some  flexibility  in  the  match 
conditions. at least three alternate lookup strategies are used in the nerc field.  

first,  words  can  be  stemmed  (stripping  off  both  inflectional  and  derivational 
suffixes)  or  lemmatized  (normalizing  for  inflections  only)  before  they  are  matched  (s. 
coates-stephens  1992).  for  instance,  if  a  list  of  cue  words  contains     technology   ,  the 
inflected  form     technologies     will  be  considered  as  a  successful  match.  for  some 
languages  (m.  jansche  2002),  diacritics  can  be  replaced  by  their  canonical  equivalent 
(e.g.,          replaced by    e   ). 

 

11 

second, candidate words can be    fuzzy-matched    against the reference list using 
some kind of thresholded edit-distance (y. tsuruoka & tsujii 2003) or jaro-winkler (w. 
cohen & sarawagi 2004). this allows capturing small lexical variations in words that are 
not necessarily derivational or inflectional. for instance, frederick could match frederik 
because the edit-distance between the two  words is very small (suppression of just one 
character,  the     c   ).  jaro-winkler   s  metric  was  specifically  designed  to  match  proper 
names following the observation that the first letters tend to be correct while name ending 
often varies.  

third,  the  reference  list  can  be  accessed  using  the  soundex  algorithm  (h. 
raghavan & allan 2004) which normalizes candidate words to their respective soundex 
codes. this code is a combination of the first letter of a word plus a three digit code that 
represents its phonetic sound. hence, similar sounding names like lewinskey (soundex = 
l520) and lewinsky (soundex = l520) are equivalent in respect to their soundex code. 

3.3  document and corpus features 
document  features  are  defined  over  both  document  content  and  document  structure. 
large collections of documents (corpora) are also excellent sources of features. we list in 
this  section  features  that  go  beyond  the  single  word  and  multi-word  expression  and 
include meta-information about documents and corpus statistics.  
table 3: features from documents. 

features 
multiple occurrences  
 
 
 
local syntax 
 
 
meta information 
 
 
corpus frequency 
 

examples 
- other entities in the context 
- uppercased and lowercased occurrences (see 3.3.1) 
- anaphora, coreference (see 3.3.2) 
 
- enumeration, apposition 
- position in sentence, in paragraph, and in document 
 
- uri, email header, xml section, (see section 3.3.3) 
- bulleted/numbered lists, tables, figures 
 
- word and phrase frequency 
- co-occurrences 
- multiword unit permanency (see 3.3.4) 

3.3.1  multiple occurrences and multiple casing 
c.  thielen  (1995),  y.  ravin  and  wacholder  (1996)  and  a.  mikheev  (1999)  identify 
words that appear both in uppercased and lowercased form in a single document. those 
words  are  hypothesized  to  be  common  nouns  that  appear  both  in  ambiguous  (e.g., 
sentence beginning) and unambiguous position. 

3.3.2  entity coreference and alias 
the task of recognizing the multiple occurrences of a unique entity in a document dates 
back to the earliest research in the field (d. mcdonald 1993, l. rau 1991). coreferences 
are the occurrences of a given word or word sequence referring to a given entity within a 
document. deriving features from coreferences is mainly done by exploiting the context 
of  every  occurrence  (e.g.,  macdonald  was  the  first,  macdonald  said,  was  signed  by 
macdonald,     ).  aliases  of  an  entity  are  the  various  ways  the  entity  is  written  in  a 
document. for instance, we may have the following aliases for a given entity: sir john a. 

 

12 

macdonald, john a. macdonald, john alexander macdonald, and macdonald. deriving 
features from aliases is mainly done by leveraging the union of alias words (sir, john, a, 
alexander, macdonald).  

finding coreferences and aliases in a text can be reduced to the same problem of 
finding all occurrences of an entity in a document. this problem is of great complexity. 
r.  gaizauskas  et  al.  (1995)  use  31  heuristic  rules  to  match  multiple  occurrences  of 
company  names.  for  instance,  two  multi-word  expressions  match  if  one  is  the  initial 
subsequence of the other. an even more complex task is the recognition of entity mention 
across  documents.  x.  li  et  al.  (2004)  propose  and  compare  a  supervised  and  an 
unsupervised model for this task. they propose the use of word-level features engineered 
to  handle  equivalences  (e.g.,  prof.  is  equivalent  to  professor)  and  relational  features  to 
encode the relative order of tokens between two occurrences. 

word-level  features  are  often  insufficient  for  complex  problems.  a  metonymy, 
for  instance,  denotates  a  different  concept  than  the  literal  denotation  of  a  word  (e.g., 
   new york    that stands for    new york yankees   ,    hexagon    that stands for    france   ). 
t. poibeau (2006) shows that semantic tagging is a key issue in such case. 

3.3.3  document meta-information 
most  meta-information  about  documents  can  be  used  directly:  email  headers  are  good 
indicator of person names, news often start with a location name, etc. some authors make 
original  use  of  meta-information.  j.  zhu  et  al.  (2005)  uses  document  url  to  bias 
probabilities  of  entities.  for  instance,  many  names  (e.g.,  bird  names)  have  high 
id203  to  be  a     project  name     if  the  url  is  from  a  computer  science  department 
domain. 

3.3.4  statistics for multiword units 
j. da silva et al. (2004) propose some interesting feature functions for multi-word units 
that can be thresholded using corpus statistics. for example, they establish a threshold on 
the presence of rare and long lowercased words in entities. only multiword units that do 
not contain rare lowercased words (rarity calculated as relative frequency in the corpus) 
of  a  relatively  long  size  (mean  size  calculated  from  the  corpus)  are  considered  as 
candidate named entities. they also present a feature called permanency that consist of 
calculating  the  frequency  of  a  word  (e.g.,  life)  in  a  corpus divided  by  its  frequency  in 
case insensitive form (e.g., life, life, life, etc.) 
 

4  evaluation of nerc 
 
thorough  evaluation  of  nerc  systems  is  essential  to  their  progress.  many  techniques 
were proposed to rank systems based on their capability to annotate a text like an expert 
linguist. in the following section, we take a look at three main scoring techniques used for 
muc, irex, conll and ace conferences. but first, let   s summarize the task from the 
point of view of evaluation. 
in nerc, systems are usually evaluated based on how their output compares with 
 
the output of human linguists. for instance, here   s an annotated text marked up according 
to the muc guidelines. let   s call it the solution.  

 

  

13 

unlike <enamex type="person">robert</enamex>, <enamex type="person">john 
briggs jr</enamex> contacted <enamex type="organization">wonderful 
stockbrockers inc</enamex> in <enamex type="location">new york</enamex> 
and instructed them to sell all his shares in <enamex 
type="organization">acme</enamex>. 

 
let   s now hypothesize a system producing the following output: 
 

<enamex type="location">unlike</enamex> robert, <enamex 
type="organization">john briggs jr</enamex> contacted wonderful <enamex 
type="organization">stockbrockers</enamex> inc <enamex type="person">in 
new york</enamex> and instructed them to sell all his shares in <enamex 
type="organization">acme</enamex>. 

 
the  system  produced  five  different  errors3,  explained  in  table  4.  in  this  example,  the 
system  gives  one  correct  answer:  (<organization> acme </organization>).  ultimately, 
the question is    what score should we give to this system?    in the following sections, we 
survey how the question was answered in various evaluation forums.  
table 4: nerc type of errors. 

correct solution 

system output 

error 

unlike 

<enamex type="person"> 
robert 
</enamex> 
 
<enamex type="person"> 
john briggs jr 
</enamex> 
 

<enamex 
type="organization"> 
wonderful stockbrockers inc 
</enamex> 
 
<enamex type="location"> 
new york 
</enamex> 

 

<enamex type="location"> 
unlike 
</enamex> 
 

robert 

<enamex 
type="organization"> 
john briggs jr 
</enamex> 
 
<enamex 
type="organization"> 
stockbrockers  
</enamex> 

<enamex type="person"> 
in new york 
</enamex> 

the system 
hypothesized an 
entity where there is 
none. 
 
an entity was 
completely missed by 
the system. 

the system noticed an 
entity but gave it 
the wrong label. 

a system noticed 
there is an entity 
but got its 
boundaries wrong. 

the system gave the 
wrong label to the 
entity and got its 
boundary wrong. 

4.1  muc evaluations  
in muc events (r. grishman & sundheim 1996, n. chinchor 1999), a system is scored 
on two axes: its ability to find the correct type (type) and its ability to find exact text 
(text). a correct type is credited if an entity is assigned the correct type, regardless of 
boundaries as long as there is an overlap. a correct text is credited if entity boundaries 

                                                 
3 type of errors are inspired by an informal publication by christopher manning: 
http://nlpers.blogspot.com/2006/08/doing-named-entity-recognition-dont.html 

 

14 

are correct, regardless of the type. for both type and text, three measures are kept: 
the number of correct answers (cor), the number of actual system guesses (act) and 
the number of possible entities in the solution (pos).   
 
the  final  muc  score  is  the  micro-averaged  f-measure  (maf),  which  is  the 
harmonic  mean  of  precision  and  recall  calculated  over  all  entity  slots  on  both  axes.  a 
micro-averaged measure is performed on all entity types without distinction (errors and 
successes for all entity types are summed together). the harmonic mean of two numbers 
is  never  higher  than  the  geometrical  mean.  it  also  tends  toward  the  least  number, 
minimizing the impact of large outliers and maximizing the impact of small ones. the f-
measure therefore tends to privilege balanced systems. 
 
in muc, precision is calculated as cor / act and the recall is cor / pos. for 
the previous example, cor = 4 (2 type + 2 text), act = 10 (5 type + 5 text) and 
pos = 10 (5 type + 5 text). the precision is therefore 40%, the recall is 40% and the 
maf is 40%.  
this measure has the advantage of taking into account all possible types of errors 
 
of table 4. it also gives partial credit for errors occurring on one axis only. since there 
are two evaluation axes, each complete success is worth two points. the worst errors cost 
this two points (missing both type and text) while other errors cost only one point.  

4.2  exact-match evaluations 
irex  and  conll  share  a  simple  scoring  protocol.  we  can  call  it     exact-match 
evaluation   . systems are compared based on the micro-averaged f-measure (maf) with 
the precision being the percentage of named entities found by the system that are correct 
and the recall being the percentage of named entities present in the solution that are found 
by the system. a named entity is correct only if it is an exact match of the corresponding 
entity in the solution.  
 
for the previous example, there are 5 true entities, 5 system guesses and only one 
guess that exactly matches the solution. the precision is therefore 20%, the recall is 20% 
and the maf is 20%.  
 
for some application, the constraint of exact match is unnecessarily stringent. for 
instance,  in  some  bioinformatics  work,  the  goal  is  to  determine  whether  or  not  a 
particular  sentence  mentions  a  specific  gene  and  its  function. exact  ne boundaries are 
not  required:  all  is  needed  is  to  determine  if  the  sentence  does  refer  to  the  gene  (r. 
tzong-han tsai et al. 2006). 

4.3  ace evaluation 
ace  has  a  complex  evaluation  procedure.  it  includes  mechanisms  for  dealing  various 
evaluation issues (partial match, wrong type, etc.). the ace task definition is also more 
elaborated than previous tasks at the level of named entity    subtypes   ,    class    as well as 
entity  mentions  (coreferences),  and  more,  but  these  supplemental  elements  will  be 
ignored here. 
 
basically,  each  entity  type  has  a  parameterized  weight  and  contributes  up  to  a 
maximal proportion (maxval) of the final score (e.g., if each person is worth 1 point 
and each organization is worth 0.5 point then it takes two organizations to counterbalance 
one  person in  the  final  score).  some  entity  types  such as     facility     may  account  for  as 
little  as  0.05  points,  according  to  ace  parameters.  in  addition,  customizable  costs 

 

15 

(cost)  are  used  for  false  alarms,  missed  entities  and  type  errors.  partial  matches  of 
textual spans are only allowed if named entity head matches on at least a given proportion 
of characters. temporal expressions are not treated in ace since they are evaluated by 
the timex2 community (l. ferro et al. 2005).  
 
the  final  score  called  entity  detection  and  recognition  value  (edr)  is  100% 
minus the penalties. for the examples of table 4, the edr score is 31.3%. it is computed 
as follows, using ace parameters from 20044. each of the five entities contributes up to 
a maximum value to the final score. using default ace parameters, the maximal values 
(maxval) for person entities is 61.54% of the final score, the two organizations worth 
30.77% and the location worth 7.69%. these values sum up to 100%.  at the individual 
type  level,  one  person  span  was  recognized  (john  briggs  jr)  but  with  the  wrong  type 
(organization);  one  person  entity  was  missed  (robert);  the  two  organization  spans 
(wonderful  stockbrockers  inc  and  acme)  were  considered  correct,  even  if  the  former 
partially matches; one geopolitical span was recognized (in new york) but with the wrong 
type and there was one false alarm (unlike). globally, the error (function of cost and 
maxval) for the person entities accounts for 55.31% of the final edr loss (30.77 for 
the miss and 24.54 for the type error), the false alarm account for 5.77% of loss and the 
location  type  error  accounts  for  7.58%.  the  final  edr  of  31.3%  is  100%  minus  these 
losses. 
 
ace  evaluation  may  be  the  most  powerful  evaluation  scheme  because  of  its 
customizable  cost  of  error  and  its  wide  coverage  of  the  problem.  it  is  however 
problematic because the final scores are only comparable when parameters are fixed. in 
addition, complex methods are not intuitive and make error analysis difficult. 

5  conclusion 
 
the id39 field has been thriving for more than fifteen years. it aims 
at  extracting  and  classifying  mentions  of  rigid  designators,  from  text,  such  as  proper 
names, biological species, and temporal expressions. in this survey, we have shown the 
diversity of languages, domains, textual genres and entity types covered in the literature. 
more  than  twenty  languages  and  a  wide  range  of  named  entity  types  are  studied. 
however, most of the work has concentrated on limited domains and textual genres such 
as news articles and web pages.  
 
we have also provided an overview of the techniques employed to develop nerc 
systems,  documenting  the  recent  trend  away  from  hand-crafted  rules  towards  machine 
learning approaches. handcrafted systems provide good performance at a relatively high 
system  engineering  cost.  when  supervised  learning  is  used,  a  prerequisite  is  the 
availability of a large collection of annotated data. such collections are available from the 
evaluation forums but remain rather rare and limited in domain and language coverage. 
recent  studies  in  the  field  have  explored  semi-supervised  and  unsupervised  learning 
techniques that promise fast deployment for many entity types without the prerequisite of 
an  annotated  corpus.  we  have  listed  and  categorized  the  features  that  are  used  in 
recognition  and  classification  algorithms.  the  use  of  an  expressive  and  varied  set  of 
features turns out to be just as important as the choice of machine learning algorithms. 
finally we have also provided an overview of the evaluation methods that are in use in 
                                                 
4 http://www.nist.gov/speech/tests/ace/ace04/index.htm 

 

16 

 

the major forums of the nerc research community.  we saw that in a simple example 
made of only five named entities, the score of three different evaluation techniques vary 
from 20% to 40%. 
 
nerc  will  have  a  profound  impact in  our  society.  early  commercial  initiatives 
are  already  modifying  the  way  we  use  yellow  pages  by  providing  local  search  engines 
(search your neighborhood for organizations, product and services, people, etc.). nerc 
systems also enable monitoring trends in the huge space of textual media produced every 
day  by  organizations,  governments  and  individuals.  it  is  also  at  the  basis  of  a  major 
advance in biology and genetics, enabling researchers to search the abundant literature for 
interactions between named genes and cells.  

acknowledgement 

thanks to ralph grishman, stan matwin and peter d. turney for helpful comments. 

references 
 
alfonseca,  enrique;  manandhar,  s.  2002.  an  unsupervised  method  for  general  named  entity 
recognition  and  automated  concept  discovery.  in  proc.  international  conference  on 
general id138. 

asahara,  masayuki;  matsumoto,  y.  2003.  japanese  named  entity  extraction  with  redundant 
morphological  analysis.  in  proc.  human  language  technology  conference  -  north 
american chapter of the association for computational linguistics. 

basili, roberto; cammisa, m.;  donati,  e. 2005. ritroverai:  a  web  application for semantic 
indexing  and  hyperlinking  of  multimedia  news.  in  proc.  international  semantic  web 
conference. 

bick, eckhard 2004. a named entity recognizer for danish. in proc. conference on language 

resources and evaluation. 

bikel, daniel m.;  miller, s.; schwartz,  r.;  weischedel, r. 1997. nymble: a  high-performance 

learning name-finder. in proc. conference on applied natural language processing. 

black, william j.; rinaldi, f.; mowatt, d. 1998. facile: description of the ne system used for 

muc-7. in proc. message understanding conference. 

bodenreider,  olivier;  zweigenbaum,  p.  2000.  identifying  proper  names  in  parallel  medical 

terminologies. stud health technol inform 77.443-447, amsterdam: ios press. 

boutsis,  sotiris;  demiros,  i.;  giouli,  v.;  liakata,  m.;  papageorgiou,  h.;  piperidis,  s.  2000.  a 
system for recognition of named entities in greek. in proc. international conference on 
natural language processing. 

borthwick,  andrew;  sterling,  j.;  agichtein,  e.;  grishman,  r.  1998.  nyu:  description  of  the 
mene named entity system as used in muc-7. in proc. seventh message understanding 
conference. 

brin,  sergey.  1998.  extracting  patterns  and  relations  from  the  world  wide  web.  in  proc. 

conference of extending database technology. workshop on the web and databases. 

carreras,  xavier;  m  rques,  l.;  padr  ,  l.  2003.  named  entity  recognition  for  catalan  using 
spanish  resources.  in  proc.  conference  of  the  european  chapter  of  association  for 
computational linguistic. 

chen, h. h.; lee, j. c. 1996. identification and classification of proper nouns in chinese texts. 

in proc. international conference on computational linguistics. 

chinchor,  nancy.  1999.  overview  of  muc-7/met-2.  in  proc.  message  understanding 

conference muc-7. 

 

17 

chinchor, nancy; robinson, p.; brown, e. 1998. hub-4 named entity task definition. in proc. 

darpa broadcast news workshop.  

cimiano,  philipp;  v  lker,  j.  2005.  towards  large-scale,  open-domain  and  ontology-based 
named  entity  classification.  in  proc.  conference  on  recent  advances  in  natural 
language processing. 

coates-stephens,  sam.  1992.  the  analysis  and  acquisition  of  proper  names  for  the 
understanding  of  free  text.  computers  and  the  humanities  26.441-456,  san  francisco: 
morgan kaufmann publishers. 

cohen,  william  w.;  sarawagi,  s.  2004.  exploiting  dictionaries  in  named  entity  extraction: 
combining  semi-markov  extraction  processes  and  data  integration  methods.  in  proc. 
conference on knowledge discovery in data. 

collins,  michael.  2002.  ranking  algorithms  for  named   entity  extraction:  boosting  and  the 

voted id88. in proc. association for computational linguistics. 

collins,  michael;  singer,  y.  1999.  unsupervised  models  for  named  entity  classification.  in 
proc.  of  the  joint  sigdat  conference  on  empirical  methods  in  natural  language 
processing and very large corpora. 

cucchiarelli,  alessandro;  velardi,  p.  2001.  unsupervised  named  entity  recognition  using 
syntactic  and  semantic  contextual  evidence.  computational  linguistics  27:1.123-131, 
cambridge: mit press. 

cucerzan,  silviu;  yarowsky,  d.  1999.  language  independent  named  entity  recognition 
combining morphological and contextual evidence. in proc. joint sigdat conference on 
empirical methods in natural language processing and very large corpora. 

da silva, joaquim ferreira; kozareva, z.; lopes, g. p. 2004. cluster analysis and classification 

of named entities. in proc. conference on language resources and evaluation. 

doddington,  george;  mitchell,  a.;  przybocki,  m.;  ramshaw,  l.;  strassel,  s.;  weischedel,  r. 
2004. the automatic content extraction (ace) program     tasks, data, and evaluation. in 
proc. conference on language resources and evaluation. 

etzioni, oren; cafarella, m.; downey, d.; popescu, a.-m.; shaked, t.; soderland, s.; weld, d. 
s.;  yates,  a.  2005.  unsupervised  named-entity  extraction  from  the  web:  an 
experimental study. artificial intelligence 165.91-134, essex: elsevier science publishers. 
evans, richard. 2003. a framework for id39 in the open domain. in proc. 

recent advances in natural language processing. 

ferro, lisa; gerber, l.; mani, i.; sundheim, b.; wilson g. 2005. tides 2005 standard for the 

annotation of temporal expressions. the mitre corporation. 

fleischman,  michael.  2001.  automated  subcategorization  of  named  entities.  in  proc. 

conference of the european chapter of association for computational linguistic. 

fleischman,  michael;  hovy.  e.  2002.  fine  grained  classification  of  named  entities.  in  proc. 

conference on computational linguistics. 

gaizauskas, robert.; wakao, t.; humphreys, k.; cunningham, h.; wilks, y. 1995. university of 
sheffield:  description  of  the  lasie  system  as  used  for  muc-6.  in  proc.  message 
understanding conference. 

grishman, ralph; sundheim, b. 1996. message understanding conference - 6: a brief history. 

in proc. international conference on computational linguistics. 

hearst,  marti.  1992.  automatic  acquisition  of  hyponyms  from  large  text  corpora.  in  proc. 

international conference on computational linguistics. 

heng, ji; grishman, r. 2006. data selection in semi-supervised learning for name tagging. in 
proc.  joint  conference  of  the  international  committee  on  computational  linguistics  and 
the  association  for  computational  linguistics.  information  extraction  beyond  the 
document. 

huang, fei. 2005. multilingual named entity extraction and translation from text and speech. 

ph.d. thesis. pittsburgh: carnegie mellon university. 

 

18 

jansche,  martin.  2002.  named  entity  extraction  with  conditional  markov  models  and 

classifiers. in proc. conference on computational natural language learning. 

kokkinakis,  dimitri.  1998.,  aventinus,  gate  and  swedish  lingware.  in  proc.  of  nordic 

computational linguistics conference.  

kripke, saul. 1982. naming and necessity. boston: harvard university press. 
lee, seungwoo;  geunbae  lee,  g. 2005. heuristic  methods for reducing errors of  geographic 
named  entities  learned  by  id64.  in  proc.  international  joint  conference  on 
natural language processing. 

li,  xin.;  morie,  p.;  roth,  d.  2004.  identification  and  tracing  of  ambiguous  names: 
discriminative  and  generative  approaches.  in  proc.  national  conference  on  artificial 
intelligence. 

lin,  d.  1998.  automatic  retrieval  and  id91  of  similar  words.  in  proc.  international 
conference  on  computational  linguistics  and  the  annual  meeting  of  the  association  for 
computational linguistics. 

mcdonald,  david  d.  1993.  internal  and  external  evidence  in  the  identification  and  semantic 

categorization of proper names. in proc. corpus processing for lexical acquisition. 

may,  jonathan;  brunstein,  a.;  natarajan,  p.;  weischedel,  r.  m.  2003.  surprise!  what   s  in  a 
cebuano or hindi name? acm transactions on asian language information processing 
2:3.169-180, new york: acm press. 

maynard,  diana;  tablan,  v.;  ursu,  c.;  cunningham,  h.;  wilks,  y.  2001.  named  entity 
recognition  from  diverse  text  types.  in  proc.  recent  advances  in  natural  language 
processing. 

mccallum, andrew; li, w. 2003. early results for id39 with conditional 
random fields, features induction and web-enhanced lexicons. in proc. conference on 
computational natural language learning. 

mikheev,  andrei.  1999.  a  knowledge-free  method  for  capitalized  word  disambiguation.  in 

proc. conference of association for computational linguistics. 

mikheev,  a.;  moens,  m.;  grover,  c.  1999.  named  entity  recognition  without  gazetteers.  in 

proc. conference of european chapter of the association for computational linguistics. 

minkov,  einat;  wang,  r.;  cohen,  w.  2005.  extracting  personal  names  from  email:  applying 
id39 to  informal  text.  in  proc.  human  language  technology  and 
conference conference on empirical methods in natural language processing. 

nadeau,  david;  turney,  p.;  matwin,  s.  2006.  unsupervised  named  entity  recognition: 
generating  gazetteers  and  resolving  ambiguity.  in  proc.  canadian  conference  on 
artificial intelligence. 

narayanaswamy,  meenakshi;  ravikumar  k.  e.;  vijay-shanker  k.  2003.  a  biological  named 

entity recognizer. in proc. pacific symposium on biocomputing. 

ohta,  tomoko;  tateisi,  y.;  kim,  j.;  mima,  h.;  tsujii,  j.  2002.  the  genia  corpus:  an 
annotated  research  abstract  corpus  in  molecular  biology  domain.  in  proc.  human 
language technology conference. 

pasca,  marius;  lin,  d.;  bigham,  j.;  lifchits,  a.;  jain,  a.  2006.  organizing  and  searching  the 
world  wide  web  of  facts   step  one:  the  one-million  fact  extraction  challenge.  in 
proc. national conference on artificial intelligence. 

patrick,  jon;  whitelaw,  c.;  munro,  r.  2002.  slinerc:  the  sydney  language-independent 
named  entity  recogniser  and  classifier.  in  proc.  conference  on  natural  language 
learning. 

palmer, david d.; day, d. s. 1997. a statistical profile of the named entity task. in proc. acl 

conference for applied natural language processing. 

petasis,  georgios;  vichot,  f.;  wolinski,  f.;  paliouras,  g.;  karkaletsis,  v.;  spyropoulos,  c.  d. 
2001.  using  machine  learning  to  maintain  rule-based  named-entity  recognition  and 
classification systems. in proc. conference of association for computational linguistics. 

 

19 

piskorski, jakub. 2004. extraction of polish named-entities. in proc. conference on language 

resources an evaluation. 

poibeau,  thierry.  2003.  the  multilingual  named  entity  recognition  framework.  in  proc. 

conference on european chapter of the association for computational linguistics.  

poibeau, thierry. 2006. dealing with metonymic readings of named entities. in proc. annual 

conference of the cognitive science society. 

poibeau,  thierry;  kosseim,  l.  2001.  proper  name  extraction  from  non-journalistic  texts.  in 

proc. computational linguistics in the netherlands. 

popov,  borislav;  kirilov,  a.;  maynard,  d.;  manov,  d.  2004.  creation  of  reusable  components 
and language resources for id39 in russian. in proc. conference on 
language resources and evaluation. 

raghavan, hema; allan, j. 2004. using soundex codes for indexing names in asr documents. 
in  proc.  human  language  technology  conference  -  north  american  chapter  of  the 
association  for  computational  linguistics.  interdisciplinary  approaches  to  speech 
indexing and retrieval. 

rau,  lisa  f.  1991.  extracting  company  names  from  text.  in  proc.  conference  on  artificial 

intelligence applications of ieee. 

ravin, yael; wacholder, n. 1996. extracting names from natural-language text. ibm research 

report rc 2033. 

riloff, ellen; jones, r 1999. learning dictionaries for information extraction using multi-level 

id64. in proc. national conference on artificial intelligence. 

rindfleisch, thomas c.; tanabe, l.; weinstein, j. n. 2000. edgar: extraction of drugs, genes 
and  relations  from  the  biomedical  literature.  in  proc.  pacific  symposium  on 
biocomputing. 

santos, diana; seco, n.; cardoso, n.; vilela, r. 2006. harem: an advanced ner evaluation 
contest  for  portuguese.  in  proc.  international  conference  on  language  resources  and 
evaluation. 

sekine, satoshi. 1998. nyu:  description of the japanese ne system used  for  met-2.  in  proc. 

message understanding conference. 

sekine,  satoshi;  isahara,  h.  2000.  irex:  ir  and  ie  evaluation  project  in  japanese.  in  proc. 

conference on language resources and evaluation. 

sekine, satoshi; nobata, c. 2004. definition, dictionaries and tagger for extended named entity 

hierarchy. in proc. conference on language resources and evaluation. 

settles, burr. 2004. biomedical id39 using id49 and 
rich feature sets. in proc. conference on computational linguistics. joint workshop on 
natural language processing in biomedicine and its applications. 

shen dan; zhang, j.; zhou, g.; su, j.; tan, c. l. 2003. effective adaptation of a hidden markov 
model-based  named  entity  recognizer  for  biomedical  domain.  in  proc.  conference  of 
association for computational linguistics. natural language processing in biomedicine. 

shinyama, yusuke; sekine, s. 2004. named entity discovery using comparable news articles. 

in proc. international conference on computational linguistics. 

thielen,  christine.  1995.  an  approach  to  proper  name  tagging  for  german.  in  proc. 
conference  of  european  chapter  of  the  association  for  computational  linguistics. 
sigdat. 

tjong  kim  sang,  erik.  f.  2002.  introduction  to  the  conll-2002  shared  task:  language-
independent  named  entity  recognition.  in  proc.  conference  on  natural  language 
learning. 

tjong kim sang, erik. f.; de meulder, f. 2003. introduction to the conll-2003 shared task: 
language-independent  named  entity  recognition.  in  proc.  conference  on  natural 
language learning. 

 

20 

tsuruoka, yoshimasa; tsujii, j. 2003. boosting precision and recall of dictionary-based protein 
name  recognition.  in  proc.  conference  of  association  for  computational  linguistics. 
natural language processing in biomedicine. 

turney, peter. 2001. mining the web for synonyms: pmi-ir versus lsa on toefl. in proc. 

european conference on machine learning. 

tzong-han tsai, richard; wu s.-h.; chou, w.-c.; lin, y.-c.; he, d.; hsiang, j.; sung, t.-y.; 
hsu,  w.-l.  2006.  various  criteria  in  the  evaluation  of  biomedical  named  entity 
recognition. bmc bioinformatics 7:92, biomed central. 

wang, liang-jyh; li, w.-c.; chang, c.-h. 1992. recognizing unregistered names for mandarin 

word identification. in proc. international conference on computational linguistics. 

whitelaw,  casey;  patrick,  j.  2003.  evaluating  corpora  for  named  entity  recognition  using 

character-level features. in proc. australian conference on artificial intelligence. 

witten, ian. h.; bray, z.; mahoui, m.; teahan w. j. 1999. using language models for generic 

entity extraction. in proc. international conference on machine learning. id111. 

wolinski, francis; vichot, f.; dillet, b.  1995. automatic processing proper names in texts. in 

proc. conference on european chapter of the association for computational linguistics. 

yangarber, roman; lin, w.; grishman, r. 2002. unsupervised learning of generalized names. 

in proc. of international conference on computational linguistics. 

yu, shihong; bai s.; wu, p. 1998. description of the kent ridge digital labs system used for 

muc-7. in proc. message understanding conference. 

zhu, jianhan; uren, v.; motta, e. 2005. espotter: adaptive id39 for web 
browsing. in proc. conference professional knowledge management. intelligent it tools 
for knowledge management systems. 

summary 
this survey covers fifteen years of research in the id39 and classification 
(nerc) field, from 1991 to 2006. we report observations about languages, named entity types, 
domains  and  textual  genres  studied  in  the  literature.  from  the  start,  nerc  systems  have  been 
developed using hand-made rules, but now machine learning techniques are widely used. these 
techniques are surveyed along with other critical aspects of nerc such as features and evaluation 
methods. features are word-level, dictionary-level and corpus-level representations of words in a 
document. evaluation techniques, ranging from intuitive exact match to very complex matching 
techniques with adjustable cost of errors, are an indisputable key to progress. 
 
author addresses: 
 
david nadeau 
national research council canada 
101 st-jean-bosco street 
gatineau, qc, k1a 0r6 
canada 
 
satoshi sekine 
new york university 
715 broadway, 7th floor 
new york, ny 10003 
usa 

