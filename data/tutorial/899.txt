id53 techniques
for the world wide web

jimmy lin and boris katz
mit artificial intelligence laboratory

tutorial presentation at
the 11th conference of the european chapter of the 
association of computational linguistics (eacl-2003)

april 12, 2003

abstract

id53 systems have become increasingly popular because they deliver 
users short, succinct answers instead of overloading them with a large number of 
irrelevant documents. the vast amount of information readily available on the world 
wide web presents new opportunities and challenges for id53. in order 
for id53 systems to benefit from this vast store of useful knowledge, they 
must cope with large volumes of useless data.

many characteristics of the world wide web distinguish web-based id53 
from id53 on closed corpora such as newspaper texts. the web is vastly 
larger in size and boasts incredible    data redundancy,    which renders it amenable to 
statistical techniques for answer extraction. a data-driven approach can yield high levels 
of performance and nicely complements traditional id53 techniques 
driven by information extraction. 

in addition to enormous amounts of unstructured text, the web also contains pockets of 
structured and semistructured knowledge that can serve as a valuable resource for 
id53. by organizing these resources and annotating them with natural 
language, we can successfully incorporate web knowledge into id53 
systems.

this tutorial surveys recent web-based id53 technology, focusing on two 
separate paradigms: knowledge mining using statistical tools and knowledge annotation 
using database concepts. both approaches can employ a wide spectrum of techniques 
ranging in linguistic sophistication from simple    bag-of-words    treatments to full 
syntactic parsing.

1

introduction
(cid:124) why id53?

(cid:122) id53 provides intuitive information 

access

(cid:122) computers should respond to human information needs 

with    just the right information   

(cid:124) what role does the world wide web play in 

id53?
(cid:122) the web is an enormous store of human knowledge
(cid:122) this knowledge is a valuable resource for question 

answering

how can we effectively utilize the world wide 
web to answer natural language questions?

qa techniques for the www: introduction

different types of questions

what does cog look like?

who directed gone 
with the wind?

gone with the wind (1939) was 
directed by george cukor, victor 
fleming, and sam wood.

how many cars left the garage 
yesterday between noon and 1pm?

what were the causes of 
the french revolution?

qa techniques for the www: introduction

2

   factoid    id53
(cid:124) modern systems are limited to answering fact-

based questions
(cid:122) answers are typically named-entities

who discovered oxygen?
when did hawaii become a state?
where is ayer   s rock located?
what team won the world series in 1992?

(cid:124) future systems will move towards    harder 

questions   , e.g.,
(cid:122) why and how questions
(cid:122) questions that require simple id136s

this tutorial focuses on using the web to answer 
factoid questions   

qa techniques for the www: introduction

two axes of exploration
(cid:124) nature of the information

(cid:122) what type of information is the system utilizing to 

answer natural language questions?

structured knowledge

(databases)

unstructured knowledge

(free text)

(cid:124) nature of the technique

(cid:122) how linguistically sophisticated are the techniques 

employed to answer natural language questions?

linguistically
sophisticated

(e.g., syntactic parsing)

linguistically
uninformed

(e.g., id165 generation)

qa techniques for the www: introduction

3

two techniques for web qa

nature of the 
technique

linguistically
sophisticated

knowledge 
annotation

database concepts

nature of the information
structured knowledge

(databases)

unstructured knowledge

(free text)

qa techniques for the www: introduction

linguistically
uninformed

knowledge 

mining

statistical tools

outline: top-level
(cid:124) general overview: origins of web-based 

id53

(cid:124) knowledge mining: techniques that effectively 

employ unstructured text on the web for question 
answering 

(cid:124) knowledge annotation: techniques that 

effectively employ structured and semistructured 
sources on the web for id53

qa techniques for the www: introduction

4

outline: general overview
(cid:124) short history of id53

(cid:122) id139 to databases
(cid:122) blocks world
(cid:122) plans and scripts
(cid:122) modern id53 systems

(cid:124) id53 tracks at trec

(cid:122) evaluation methodology
(cid:122) formal scoring metrics

qa techniques for the www: introduction

outline: knowledge mining
(cid:124) overview 

(cid:122) how can we leverage the enormous quantities of 

unstructured text available on the web for question 
answering?

(cid:124) leveraging data redundancy
(cid:124) survey of selected end-to-end systems
(cid:124) survey of selected knowledge mining techniques
(cid:124) challenges and potential solutions

(cid:122) what are the limitations of data redundancy?
(cid:122) how can linguistically-sophisticated techniques help?

qa techniques for the www: introduction

5

outline: knowledge annotation
(cid:124) overview

(cid:122) how can we leverage structured and semistructured 

web sources for id53?

(cid:124) start and omnibase

(cid:122) the first id53 system for the web

(cid:124) other annotation-based systems
(cid:124) challenges and potential solutions
(cid:122) can research from related fields help?
(cid:122) can we discover structured data from free text?
(cid:122) what role will the semantic web play?

qa techniques for the www: introduction

general overview

id53 techniques for the world wide web

6

a short history of qa
(cid:124) id139 to databases
(cid:124) blocks world
(cid:124) plans and scripts
(cid:124) emergence of the web
(cid:124) ir+ie-based qa and large-scale evaluation
(cid:124) re-discovery of the web

overview: history of qa

nl interfaces to databases
(cid:124) id139 to relational 

databases
(cid:122) baseball     baseball statistics
who did the red sox lose to on july 5?
on how many days in july did eight teams play?

[green et al. 1961]

(cid:122) lunar     analysis of lunar rocks

[woods et al. 1972]

what is the average concentration of aluminum in high alkali rocks?
how many brescias contain olivine?

(cid:122) lifer     personnel statistics

[hendrix 1977ab]

what is the average salary of math department secretaries?
how many professors are there in the compsci department?

overview: history of qa

7

typical approaches
direct translation: determine mapping rules between 
syntactic structures and database queries (e.g., lunar)

s

np

vp

det

n

v

n

which

rock contains magnesium

(for_every x

(is_rock x)
(contains x magnesium)
(printout x))

semantic grammar: parse at the semantic level directly 
into database queries (e.g., lifer)

top

present

item

employee

attribute

name

what

is

the

salary

of

martin devine

overview: history of qa

properties of early nl systems
(cid:124) often brittle and not scalable

(cid:122) natural language understanding process was a mix of 

syntactic and semantic processing

(cid:122) domain knowledge was often embedded implicitly in the 

parser

(cid:124) narrow and restricted domain

(cid:122) users were often presumed to have some knowledge of 

underlying data tables

(cid:124) systems performed syntactic and semantic 

analysis of questions
(cid:122) id59ing (e.g., anaphora, ellipsis) is easier in 

a narrow domain

overview: history of qa

8

blocks world
(cid:124) interaction with a robotic arm in a world filled with  

colored blocks
(cid:122) not only answered questions, but also followed 

[winograd 1972]

commands 

what is on top of the red brick?
is the blue cylinder larger than the one you are holding?
pick up the yellow brick underneath the green brick.

(cid:124) the    blocks world    domain was a fertile ground 

for other research
(cid:122) near-miss learning
(cid:122) understanding line drawings
(cid:122) acquisition of problem solving strategies [sussman 1973]

[winston 1975]

[waltz 1975]

overview: history of qa

plans and scripts
(cid:124) qualm

[lehnert 1977,1981]

(cid:122) application of scripts and plans for story comprehension
(cid:122) very restrictive domain, e.g., restaurant scripts
(cid:122) implementation status uncertain     difficult to separate 

discourse theory from working system

(cid:124) unix consultant

[wilensky 1982; wilensky et al. 1989]

(cid:122) allowed users to interact with unix, e.g., ask    how do i 

delete a file?   

(cid:122) user questions were translated into goals and matched 
with plans for achieving that goal: paradigm not suitable 
for general purpose id53

(cid:122) effectiveness and scalability of approach is unknown 

due to lack of rigorous evaluation

overview: history of qa

9

emergence of the web
(cid:124) before the web   

(cid:122) id53 systems had limited audience
(cid:122) all knowledge had to be hand-coded and specially 

prepared

(cid:124) with the web   

(cid:122) millions can access id53 services
(cid:122) id53 systems could take advantage of 

already-existing knowledge:    virtual collaboration   

overview: history of qa

mit: [katz 1988,1997; katz et al. 2002a]

start
(cid:124) the first id53 system for the world 

wide web
(cid:122) on-line and continuously operating since 1993
(cid:122) has answered millions of questions from hundreds of 

thousands of users all over the world

(cid:122) engages in    virtual collaboration    by utilizing knowledge 

freely available on the web

(cid:124) introduced the knowledge annotation approach to 

id53

http://www.ai.mit.edu/projects/infolab

overview: history of qa

10

additional start applications
start is easily adaptable to different domains:

(cid:122) analogy/explanation-based learning
(cid:122) answering questions from the gre
(cid:122) answering questions in the jpl press room regarding 

[winston et al. 1983]
[katz 1988]

the voyager flyby of neptune (1989)

[katz 1990]

(cid:122) start bosnia server dedicated to the u.s. mission in 

bosnia (1996)

(cid:122) start mars server to inform the public about nasa   s 

planetary missions (2001)

(cid:122) start museum server for an ongoing exhibit at the 

mit museum (2001)

overview: history of qa

start in action

overview: history of qa

11

start in action

overview: history of qa

start in action

overview: history of qa

12

start in action

overview: history of qa

related strands: ir and ie
(cid:124) information retrieval has a long history

(cid:122) origins can be traced back to vannevar bush (1945)
(cid:122) active field since mid-1950s
(cid:122) primary focus on document retrieval
(cid:122) finer-grained ir: emergence of passage retrieval 

techniques in early 1990s

(cid:124) information extraction seeks to    distill    information 

from large numbers of documents
(cid:122) concerned with filling in pre-specified templates with 

participating entities

(cid:122) started in the late 1980s with the message 

understanding conferences (mucs)

overview: history of qa

13

ir+ie-based qa
(cid:124) recent id53 systems are based 

on information retrieval and information extraction
(cid:122) answers are extracted from closed corpora, e.g., 

newspaper and encyclopedia articles

(cid:122) techniques range in sophistication from simple keyword 

matching to some parsing

(cid:124) formal, large-scale evaluations began with the 

trec qa tracks
(cid:122) facilitated rapid dissemination of results and formation 

of a community

(cid:122) dramatically increased speed at which new techniques 

have been adopted

overview: history of qa

re-discovery of the web
(cid:124) ir+ie-based systems focus on answering 

questions from a closed corpus
(cid:122) artifact of the trec setup

(cid:124) recently, researchers have discovered a wealth 

of resource on the web
(cid:122) vast amounts of unstructured free text
(cid:122) pockets of structured and semistructured sources

(cid:124) this is where we are today   

how can we effectively utilize the web to 
answer natural language questions?

overview: history of qa

14

the short answer
(cid:124) knowledge mining: techniques that effectively 

employ unstructured text on the web for question 
answering

(cid:124) knowledge annotation: techniques that 

effectively employ structured and semistructured 
sources on the web for id53

overview: history of qa

general overview:
trec id53 tracks

id53 techniques for the world wide web

15

trec qa tracks
(cid:124) id53 track at the text retrieval 

conference (trec)
(cid:122) large-scale evaluation of id53 
(cid:122) sponsored by nist (with later support from arda)
(cid:122) uses formal evaluation methodologies from information 

retrieval

(cid:124) formal evaluation is a part of a larger    community 

process   

overview: trec qa

the trec cycle

call for 

participation

task 

definition

proceedings
publication

trec

conference

results 
analysis

results 
evaluation

relevance

assessments

overview: trec qa

document
procurement

topic

development

evaluation
experiments

16

trec qa tracks
(cid:124) trec-8 qa track

[voorhees and tice 1999,2000b]
(cid:122) 200 questions: backformulations of the corpus
(cid:122) systems could return up to five answers

answer = [ answer string, docid ]

(cid:122) two test conditions: 50-byte or 250-byte answer strings
(cid:122) mrr scoring metric
(cid:124) trec-9 qa track

[voorhees and tice 2000a]

(cid:122) 693 questions: from search engine logs
(cid:122) systems could return up to five answers

answer = [ answer string, docid ]

(cid:122) two test conditions: 50-byte or 250-byte answer strings
(cid:122) mrr scoring metric

overview: trec qa

trec qa tracks
(cid:124) trec 2001 qa track

[voorhees 2001,2002a]

(cid:122) 500 questions: from search engine logs
(cid:122) systems could return up to five answers

answer = [ answer string, docid ]

(cid:122) 50-byte answers only
(cid:122) approximately a quarter of the questions were definition 

questions (unintentional)
(cid:124) trec 2002 qa track

[voorhees 2002b]
(cid:122) 500 questions: from search engine logs
(cid:122) each system could only return one answer per question

answer = [ exact answer string, docid ]

(cid:122) all answers were sorted by decreasing confidence
(cid:122) introduction of    exact answers    and cws metric

overview: trec qa

17

id74
(cid:124) mean reciprocal rank (mrr) (through trec 2001)

(cid:122) reciprocal rank = inverse of rank at which first correct 

answer was found: {1, 0.5, 0.33, 0.25, 0.2, 0}

(cid:122) mrr = average over all questions
(cid:122) judgments: correct, unsupported, incorrect

correct: answer string answers the question in a    responsive    

fashion and is supported by the document

unsupported: answer string is correct but the document does not 

support the answer

incorrect: answer string does not answer the question

(cid:122) strict score: unsupported counts as incorrect
(cid:122) lenient score: unsupported counts as correct

overview: trec qa

id74
(cid:124) confidence-weighted score (cws) (trec 2002)
(cid:122) evaluates how well    systems know what they know   

q

c   
i
q

=1

i

/

i

ic = number of correct answers in first i questions
q = total number of questions 

(cid:122) judgments: correct, unsupported, inexact, wrong

exact answers

mississippi
the mississippi
the mississippi river
mississippi river
mississippi

inexact answers

at 2,348 miles the mississippi river is 
the longest river in the us.
2,348; mississippi
missipp

overview: trec qa

18

knowledge mining

id53 techniques for the world wide web

knowledge mining:
overview

id53 techniques for the world wide web

19

knowledge mining
(cid:124) definition: techniques that effectively employ 

unstructured text on the web for question 
answering
(cid:124) key ideas:

(cid:122) leverage data redundancy
(cid:122) use simple statistical techniques to bridge question and 

answer gap

(cid:122) use linguistically-sophisticated techniques to improve 

answer quality

knowledge mining: overview

key questions
(cid:124) how is the web different from a closed corpus?
(cid:124) how can we quantify and leverage data 

redundancy?

(cid:124) how can data-driven approaches help solve 

some nlp challenges?

(cid:124) how do we make the most out of existing search 

engines?

how can we effectively employ unstructured 
text on the web for id53?

knowledge mining: overview

20

knowledge mining

nature of the 
technique

linguistically
sophisticated

nature of the information
structured knowledge

(databases)

unstructured knowledge

(free text)

knowledge mining: overview

linguistically
uninformed

knowledge 

mining

statistical tools

   knowledge    and    data    mining
how is knowledge mining related to data mining?

knowledge mining
(cid:124) answers specific natural 

language questions
(cid:124) benefits from well-

specified input and output
(cid:124) primarily utilizes textual 

sources

data mining

(cid:124) discovers interesting 

patterns and trends

(cid:124) often suffers from vague 

goals

(cid:124) utilizes a variety of data 

from text to numerical 
databases

similarities:

(cid:124) both are driven by enormous quantities of data
(cid:124) both leverage statistical and data-driven techniques

knowledge mining: overview

21

present and future
(cid:124) current state of knowledge mining:

(cid:122) most research activity concentrated in the last two years
(cid:122) good performance using statistical techniques

(cid:124) future of knowledge mining:
(cid:122) build on statistical techniques
(cid:122) overcome brittleness of current natural language 

techniques

(cid:122) address remaining challenges with linguistic knowledge
(cid:122) selectively employ linguistic analysis: use it only in 

beneficial situations

knowledge mining: overview

origins of knowledge mining
the origins of knowledge mining lie in information 
retrieval and information extraction

information retrieval
document retrieval

passage retrieval

information extraction

ir+ie-based qa

knowledge mining

   traditional    
id53 
on closed corpora

id53 
using the web

knowledge mining: overview

22

   traditional    ir+ie-based qa

nl question

question analyzer

ir query

document retriever

documents

passage retriever

passages

answer extractor

question type

answers

knowledge mining: overview

   traditional    ir+ie-based qa
(cid:124) question analyzer

input = natural language question

(cid:122) determines expected answer type
(cid:122) generates query for ir engine

(cid:124) document retriever

input = ir query

(cid:122) narrows corpus down to a smaller set of potentially 

relevant documents
(cid:124) passage retrieval

input = set of documents

(cid:122) narrows documents down to a set of passages for 

additional processing

(cid:124) answer extractor

input = set of passages + question type

(cid:122) extracts the final answer to the question
(cid:122) typically matches entities from passages against the 

expected answer type

(cid:122) may employ more linguistically-sophisticated processing

knowledge mining: overview

23

references: ir+ie-based qa
(cid:124) general survey
(cid:124) sample systems

[hirschman and gaizauskas 2001]

(cid:122) cymfony at trec-8

[srihari and li 1999]

    three-level information extraction architecture

(cid:122) ibm at trec-9 (and later versions)

[prager et al. 1999]

    predictive annotations: perform named-entity detection at 

time of index creation

(cid:122) falcon (and later versions)

[harabagiu et al. 2000a]

    employs question/answer logic unification and feedback 

loops
(cid:124) tutorials

[harabagiu and moldovan 2001, 2002]

knowledge mining: overview

just another corpus?
(cid:124) is the web just another corpus?
(cid:124) can we simply apply traditional ir+ie-based 
id53 techniques on the web?

questions

questions

?

closed corpus
(e.g., news articles)

answers

the web

answers

knowledge mining: overview

24

not just another corpus   
(cid:124) the web is qualitatively different from a closed 

corpus

(cid:124) many ir+ie-based id53 

techniques will still be effective

(cid:124) but we need a different set of techniques to 

capitalize on the web as a document collection

knowledge mining: overview

size and data redundancy
(cid:124) how big?

(cid:122) tens of terabytes? no agreed upon methodology to 

even measure it

(cid:122) google indexes over 3 billion web pages (early 2003)

(cid:124) size introduces engineering issues

(cid:122) use existing search engines? limited control over 

search results

(cid:122) crawl the web? very resource intensive
(cid:124) size gives rise to data redundancy

(cid:122) knowledge stated multiple times   

in multiple documents
in multiple formulations

knowledge mining: overview

25

other considerations
(cid:124) poor quality of many individual pages

(cid:122) documents contain misspellings, incorrect grammar, 

wrong information, etc.

(cid:122) some web pages aren   t even    documents    (tables, lists 
of items, etc.): not amenable to named-entity extraction 
or parsing

(cid:124) heterogeneity

(cid:122) range in genre: encyclopedia articles vs. weblogs
(cid:122) range in objectivity: id98 articles vs. cult websites
(cid:122) range in document complexity: research journal papers 

vs. elementary school book reports

knowledge mining: overview

ways of using the web
(cid:124) use the web as the primary corpus of information

(cid:122) if needed,    project    answers onto another corpus (for 

verification purposes)

(cid:124) combine use of the web with other corpora

(cid:122) employ web data to supplement a primary corpus (e.g., 

collection of newspaper articles)

(cid:122) use the web only for some questions
(cid:122) combine web and non-web answers (e.g., weighted 

voting)

knowledge mining: overview

26

capitalizing on search engines
data redundancy would be useless unless we could easily 
access all that data   
(cid:124) leverage existing information retrieval 

infrastructure
(cid:122) the engineering task of indexing and retrieving 

[brin and page 1998]

terabyte-sized document collections has been solved

(cid:124) existing search engines are    good enough   

(cid:122) build systems on top of commercial search engines, 

e.g., google, fast, altavista, teoma, etc.

question

question
analysis

web

search engine

results

processing

answer

knowledge mining: overview

knowledge mining:
leveraging data redundancy

id53 techniques for the world wide web

27

leveraging data redundancy
(cid:124) take advantage of different reformulations

(cid:122) the expressiveness of natural language allows us to 

say the same thing in multiple ways

(cid:122) this poses a problem for id53

question asked 
in one way
   when did colorado 
become a state?   

how do we bridge these two?

answer stated 
in another way

   colorado was admitted to 
the union on august 1, 1876.   

(cid:122) with data redundancy, it is likely that answers will be 

stated in the same way the question was asked

(cid:124) cope with poor document quality

(cid:122) when many documents are analyzed, wrong answers 

become    noise   

knowledge mining: leveraging data redundancy

leveraging data redundancy
data redundancy = surrogate for sophisticated nlp
obvious reformulations of questions can be easily found

who killed abraham lincoln?

(1) john wilkes booth killed abraham lincoln.
(2) john wilkes booth altered history with a bullet.  he will forever be 

known as the man who ended abraham lincoln   s life.

when did wilt chamberlain score 100 points?

(1) wilt chamberlain scored 100 points on march 2, 1962 against the 

new york knicks.

(2) on december 8, 1961, wilt chamberlain scored 78 points in a triple 
overtime game. it was a new nba record, but warriors coach frank
mcguire didn   t expect it to last long, saying,    he   ll get 100 points 
someday.    mcguire   s prediction came true just a few months later in 
a game against the new york knicks on march 2.

knowledge mining: leveraging data redundancy

28

leveraging data redundancy
data redundancy can overcome poor document quality
lots of wrong answers, but even more correct answers

what   s the rainiest place in the world?

(1) blah blah seattle blah blah hawaii blah blah blah blah blah blah
(2) blah sahara desert blah blah blah blah blah blah blah amazon
(3) blah blah blah blah blah blah blah mount waiale'ale in hawaii blah
(4) blah blah blah hawaii blah blah blah blah amazon blah blah
(5) blah mount waiale'ale blah blah blah blah blah blah blah blah blah

what is the furthest planet in the solar system?

(1) blah pluto blah blah blah blah planet x blah blah
(2) blah blah blah blah pluto blah blah blah blah blah blah blah blah
(3) blah blah blah planet x blah blah blah blah blah blah blah pluto
(4) blah pluto blah blah blah blah blah blah blah blah pluto blah blah

knowledge mining: leveraging data redundancy

general principles
(cid:124) match answers using surface patterns

(cid:122) apply id157 over textual snippets to 

extract answers

(cid:122) bypass linguistically sophisticated techniques, e.g., 

parsing

(cid:124) rely on statistics and data redundancy

(cid:122) expect many occurrences of the answer mixed in with 

many occurrences of wrong, misleading, or lower 
quality answers

(cid:122) develop techniques for filtering, sorting large numbers 

of candidates

can we    quantify    data redundancy?

knowledge mining: leveraging data redundancy

29

leveraging massive data sets

[banko and brill 2001]

grammar correction: {two, to, too} {principle, principal}

knowledge mining: leveraging data redundancy

observations: banko and brill
(cid:124) for some applications, learning technique is less 

important than amount of training data
(cid:122) in the limit (i.e., infinite data), performance of different 

algorithms converges

(cid:122) it doesn   t matter if the data is (somewhat) noisy
(cid:122) why compare performance of learning algorithms on 

(relatively) small corpora?

(cid:124) in many applications, data is free!
(cid:124) throwing more data at a problem is sometimes 
the easiest solution (hence, we should try it first)

knowledge mining: leveraging data redundancy

30

effects of data redundancy
[breck et al. 2001; light et al. 2001]
are questions with more answer occurrences    easier   ?
examined the effect of answer occurrences on id53 
performance (on trec-8 results)

~27% of systems produced a correct answer for questions with 1 answer occurrence.
~50% of systems produced a correct answer for questions with 7 answer occurrences.

knowledge mining: leveraging data redundancy

effects of data redundancy
[clarke et al. 2001a]
how does corpus size affect performance?
selected 87    people    questions from trec-9; tested effect of corpus 
size on passage retrieval algorithm (using 100gb trec web corpus)

knowledge mining: leveraging data redundancy

conclusion: having more data improves performance

31

effects of data redundancy
[dumais et al. 2002]
how many search engine results should be used?
plotted performance of a id53 system against the 
number of search engine snippets used

performance drops as too many 
irrelevant results get returned

# snippets
1
5
10
50
200

mrr
0.243
0.370
0.423
0.501
0.514

knowledge mining: leveraging data redundancy

mrr as a function of number of snippets returned 
from the search engine. (trec-9, q201-700)

knowledge mining:
system survey

id53 techniques for the world wide web

32

knowledge mining: systems
(cid:124) ionaut (at&t research)
(cid:124) mulder (university of washington)
(cid:124) askmsr (microsoft research)
(cid:124) insightsoft-m (moscow, russia)
(cid:124) multitext (university of waterloo)
(cid:124) shapaqa (tilburg university) 
(cid:124) aranea (mit)
(cid:124) textmap (usc/isi)
(cid:124) lamp (national university of singapore)
(cid:124) nsir (university of michigan)
(cid:124) pris (national university of singapore)
(cid:124) answerbus (university of michigan)

knowledge mining: system survey

selected systems, apologies for any omissions

   generic system   

nl question

question analyzer

automatically learned or 
manually encoded
surface patterns

web query

web interface

question type

snippets

redundancy-based

modules

web answers

answer projection

trec answers

knowledge mining: system survey

33

common techniques
(cid:124) match answers using surface patterns

(cid:122) apply id157 over textual snippets to 

extract answers
surface patterns may also help in generating queries; they 
are either learned automatically or entered manually

(cid:124) leverage statistics and multiple answer 

occurrences
(cid:122) generate id165s from snippets
(cid:122) vote, tile, filter, etc.

(cid:124) apply information extraction technology

(cid:122) ensure that candidates match expected answer type

knowledge mining: system survey

ionaut at&t research: [abney et al. 2000]
application of ir+ie-based id53 paradigm 
on documents gathered from a web crawl

passage retrieval

entity extraction

entity classification

query classification

entity ranking

knowledge mining: system survey

http://www.ionaut.com:8400/

34

ionaut: overview
(cid:124) passage retrieval
(cid:122) smart ir system
[salton 1971; buckley and lewit 1985]
(cid:122) segment documents into three-sentence passages

(cid:124) entity extraction

(cid:122) cass partial parser
(cid:124) entity classification

[abney 1996]

(cid:122) proper names: person, location, organization
(cid:122) dates
(cid:122) quantities
(cid:122) durations, linear measures

knowledge mining: system survey

ionaut: overview
(cid:124) query classification: 8 hand-crafted rules

(cid:122) who, whom     person
(cid:122) where, whence, whither     location
(cid:122) when     date
(cid:122) and other simple rules

(cid:124) criteria for entity ranking:

(cid:122) match between query classification and entity 

classification

(cid:122) frequency of entity
(cid:122) position of entity within retrieved passages

knowledge mining: system survey

35

ionaut: evaluation
(cid:124) end-to-end performance: trec-8 (informal)
(cid:122) exact answer: 46% answer in top 5, 0.356 mrr
(cid:122) 50-byte: 39% answer in top 5, 0.261 mrr
(cid:122) 250-byte: 68% answer in top 5, 0.545 mrr

(cid:124) error analysis

(cid:122) good performance on person, location, date, and 

quantity (60%)

(cid:122) poor performance on other types

knowledge mining: system survey

mulder u. washington: [kwok et al. 2001]

question

parsing

mei

pc-kimmo

parse trees

question 

classification

link parser

classification

rules

query formulation

query

formulation

rules

original
question

quote np

pc-kimmo

id138

t-form
grammar

search engine 

queries

search
engine

web
pages

answer

answer selection

final
ballot

id91

scoring

candidate
answers

answer extraction

match
phrase
type

nlp
parser

summary
extraction
+ scoring

knowledge mining: system survey

36

mulder: parsing
(cid:124) question parsing 

(cid:122) maximum id178 parser (mei)
(cid:122) pc-kimmo for tagging of unknown words

[charniak 1999]

[antworth 1999]

(cid:124) question classification

[sleator and temperly 1991,1993]

(cid:122) link parser
(cid:122) manually encoded rules (e.g., how adj = measure)
(cid:122) id138 (e.g., find hypernyms of object)

knowledge mining: system survey

mulder: querying
(cid:124) query formulation

(cid:122) id183 (use    attribute nouns    in id138)

how tall is mt. everest        the height of mt. everest is   

(cid:122) id121

id53        id53   

(cid:122) transformations 

who was the first american in space        was the first american 
in space   ,    the first american in space was   

who shot jfk        shot jfk   

when did nixon visit china        nixon visited china   

(cid:124) search engine: submit results to google

knowledge mining: system survey

37

mulder: answer extraction
(cid:124) answer extraction: extract summaries directly 

from web pages
(cid:122) locate regions with keywords
(cid:122) score regions by keyword density and keyword idf

values

(cid:122) select top regions and parse them with mei
(cid:122) extract phrases of the expected answer type

(cid:124) answer selection: score candidates based on

(cid:122) simple frequency     voting
(cid:122) closeness to keywords in the neighborhood

knowledge mining: system survey

mulder: evaluation

(cid:124) evaluation on trec-8 (200 questions)

(cid:122) did not use mrr metric: results not directly comparable
(cid:122)    user effort   : how much text users must read in order to find 

the correct answer

knowledge mining: system survey

38

askmsr [brill et al. 2001; banko et al. 2002; brill et al. 2002]

askmsr-a

{ansa1, ansa2 ,    , ansam}

question

askmsr-b

{ansb1, ansb2 ,    , ansbn}

query 

reformulator

harvest 
engine

answer 
filtering

answer 
tiling

search
engine

knowledge mining: system survey

system

combination

{ans1, ans2 ,    , ans5}

answer
projection

[ans1, docid1]
[ans2, doc ]
[ans3, doc ]
[ans4, doc ]
nil

askmsr: id165 harvesting
use text patterns derived from question to extract 
sequences of tokens that are likely to contain the answer

question: who is bill gates married to?

look five tokens to the right

<   bill gates is married to   ,  right,  5>

... it is now the largest software company in the world. today, bill gates is married
to co-worker melinda french. they live together in a house in the redmond ... 

... i also found out that bill gates is married to melinda french gates and they have
a daughter named jennifer katharine gates and a son named rory john gates. i ... 

... of microsoft, and they both developed microsoft. * presently bill gates is married
to melinda french gates. they have two children: a daughter, jennifer, and a ... 

generate id165s from google 
summary snippets (bypassing 
original web pages)

co-worker, co-worker melinda, co-worker melinda french, melinda,
melinda french, melinda french they, french, french they, french they live   

knowledge mining: system survey

39

askmsr: query reformulation
(cid:124) transform english questions into search engine 

queries

(cid:124) anticipate possible answer fragments

question: who is bill gates married to?

query reformulator
    simple regular expression 

matching (half a dozen rules)
    no parsing or part of speech 

tagging

<   is bill gates married to   , right, 5>
<   bill is gates married to   , right, 5>
<   bill gates is married to   , right, 5>
<   bill gates married is to   , right, 5>
<   bill gates married to is   , right, 5>
<{bill, gates, married}>

(bag-of-words backoff)

knowledge mining: system survey

askmsr: filter/vote/tile
(cid:124) answer filtering: filter by question type

(cid:122) simple id157, e.g., for dates

(cid:124) answer voting: score candidates by frequency 

of occurrence

(cid:124) answer tiling: combine shorter candidates into 

longer candidates

united nations international
nations international

international children   s emergency

emergency fund

united nations international children   s emergency fund

knowledge mining: system survey

40

askmsr: performance
(cid:124) end-to-end performance: trec-2001 (official)

(cid:122) mrr: 0.347 (strict), 0.434 (lenient)

(cid:124) lenient score is 25% higher than strict score
(cid:124) answer projection = weakest link

(cid:122) for 20% of correct answers, no adequate supporting 

document could be found

(cid:124) observations and questions

(cid:122) first id53 system to truly embrace data 

redundancy: simple counting of id165s

(cid:122) how would mulder and askmsr compare?

knowledge mining: system survey

insightsoft-m [soubbotin and soubbotin 2001,2002]
application of surface pattern matching techniques directly on 
the trec corpus

question:

what year was mozart born?

query:
   mozart   

passage with a 

query term

type of 
question:

   when (what-year)

-born?   

snippets

answer:

   mozart (1756-1791) please pin it      

patterns for this query type:
1. in strict order: capitalized word; parenthesis; four digits; dash; four digits; parenthesis 
2. in any word: capitalized word;    in   ; four digits;    born   
3.    

knowledge mining: system survey

41

insightsoft-m: patterns
some patterns for    what is    questions:

<a; is/are;[a/an/the]; x> 
<x; is/are;[a/an/the]; a>
example:    michigan's state flower is the apple blossom    

(23 correct responses in trec 2001)

<a; comma; [a/an/the]; x; [comma/period]>
<x; comma; [a/an/the]; a; [comma/ period]>
example: "moulin id8, a cabaret " 

(26 correct responses)

<a; [comma]; or; x; [comma]>
example: "shaman, or tribal magician,    

(12 correct responses)

<a; [comma]; [also] called; x [comma]>
< x; [comma]; [also] called; a [comma]>
<x; is called; a> <a; is called; x>
example: "naturally occurring gas called methane    

(10 correct responses)

knowledge mining: system survey

insightsoft-m: evaluation
(cid:124) end-to-end performance:

(cid:122) trec 2001: mrr 0.676 (strict) 0.686 (lenient)
(cid:122) trec 2002: cws 0.691, 54.2% correct

(cid:124) observations:

(cid:122) unclear how precision of patterns is controlled
(cid:122) although the system used only the trec corpus, it 
demonstrates the power of surface pattern matching

knowledge mining: system survey

42

multitext u. waterloo: [clarke et al. 2001b, 2002]

web

use of the web as an 
auxiliary corpus to 
provide data redundancy

questions

altavista
frontend

google
frontend

urls

download

web pages

auxiliary
corpus

parsing

query

selection rules

passage
retrieval

passages

answer
selection

term statistics

trec
corpus

answers

knowledge mining: system survey

multitext: trec 2001
(cid:124) download top 200 web documents to create an 

auxiliary corpus

(cid:124) select 40 passages from web documents to 

supplement passages from trec corpus

(cid:124) candidate term weighting:

cw
=
t
t

log

(

fn

)t

n = sum of lengths of all documents in the corpus
ft = number of occurrences of t in corpus
ct = number of distinct passages in which t occurs

   redundancy factor    where web passages help

(cid:124) end-to-end performance: trec 2001 (official)

(cid:122) mrr 0.434 (strict) 0.457 (lenient)
(cid:122) web redundancy contributed to 25% of performance

knowledge mining: system survey

43

multitext: trec 2002
(cid:124) same basic setup as multitext in trec 2001
(cid:124) two sources of web data:

(cid:122) one terabyte crawl of the web from mid-2001
(cid:122) altavista

(cid:124) end-to-end performance: trec 2002 (official)

(cid:122) 36.8% correct, cws 0.512
(cid:122) impact of altavista not significant (compared to using 

1tb of crawled data)

knowledge mining: system survey

shapaqa ilk, tilburg university: [buchholz 2001]

question

question
analysis

answer
extraction

answer
projection

50-byte answer

google

analyze google snippets for 
semantic roles. match 
semantic role from question 
with those extracted from 
google snippets.

return most frequently-
occurring answer

trec

documents

find web answer that occurs 
in trec sentences (from 
nist documents)

knowledge mining: system survey

44

shapaqa: overview
(cid:124) extracts answers by determining the semantic 

role the answer is likely to play
(cid:122) sbj (subject), obj (object), lgc (logical subjects of 
passive verbs), loc (locative adjunct), tmp (temporal 
adjunct), prp (adjust of purpose and reason), mnr
(manner adjunct), oth (unspecified relation between 
verb and pp)

(cid:122) does not utilize named-entity detection

when was president kennedy shot?

verb = shot
obj = president kennedy
tmp = ?

semantic realization of answer. 
parse google snippets to 
extract the temporal adjunct

(cid:124) end-to-end performance: trec-2001, official

(cid:122) mrr: 0.210 (strict), 0.234 (lenient)

knowledge mining: system survey

aranea mit: [lin, j. et al. 2002]

questions

knowledge
annotation

knowledge

mining

knowledge
boosting

answer
projection

[ answer, docid ]

confidence
ordering

aquaint
corpus

confidence sorted answers

knowledge mining: system survey

question

formulate requests

execute requests

generate id165s

vote

filter candidates

combine candidates

score candidates

get support

candidate answers

45

aranea: overview
(cid:124) integrates knowledge mining and knowledge 
annotation techniques in a single framework

(cid:124) employs a modular xml framework
(cid:122) modules for manipulating search results
(cid:122) modules for manipulating id165s: voting, filtering, etc.

(cid:124) scores candidates using a tf.idf metric

(cid:122) tf = frequency of candidate occurrence (from voting)
(cid:122) idf =    intrinsic    score of candidate (idf values extracted 

from the trec corpus)

(cid:124) projects web answer back onto the trec corpus

(cid:122) major source of errors

knowledge mining: system survey

aranea: querying the web
a flexible query language for mining candidate answers 

question: when did the mesozoic period end?

query: when did the mesozoic period end

type: inexact
score: 1
number of snippets to mine: 100

query: the mesozoic period ended ?x

type: exact
score: 2
number of snippets to mine: 100
max byte length of ?x: 50
max word count of ?x: 5

inexact query: get snippets 
surrounding these keywords

exact query: get snippets 
matching exactly this pattern

text snippets from google

    a major extinction occurred at the end of the mesozoic, 65 million years ago   
    the end of the mesozoic era a half-act play may 1979   
    the mesozoic period ended 65 million years ago   

knowledge mining: system survey

46

aranea: evaluation
(cid:124) end-to-end performance: trec 2002 (official)

(cid:122) official score: 30.4% correct, cws 0.433
(cid:122) knowledge mining component contributed 85% of the 

performance
(cid:124) observations:

(cid:122) projection performance: ~75%
(cid:122) without answer projection: 36.6% correct, cws 0.544
(cid:122) knowledge mining component: refinement of many 

techniques introduced in askmsr

knowledge mining: system survey

textmap
(cid:124) natural language based reformulation resource

usc/isi: [hermjakob et al. 2002]

cf. s-rules [katz and levin 1988], dirt [lin and pantel 2001ab]

:anchor-pattern    somebody_1 died of something_2.   
:is-equivalent-to    somebody_1 died from something_2.   
:is-equivalent-to    somebody_1   s death from something_2.   
:answers    how did somebody_1 die?    :answer something_2

:anchor-pattern    person_1 invented something_2.   
:is-equivalent-to    person_1   s invention of something_2   
:answers    who is person_1?    :answer    the inventor of something_2   

(cid:124) reformulations are used in two ways:

(cid:122) id183: retrieve more relevant documents
(cid:122) answer selection: rank and choose better answers

question: who was johan vaaler?
reformulation: johan vaaler   s invention of <what>
text:     johan vaaler   s invention of the paper clip    
answer: the inventor of the paper clip

knowledge mining: system survey

47

textmap
(cid:124) applied reformulations to two sources

(cid:122) ir on trec collection: modules developed for 

webclopedia

[hovy et al. 2001ab,2002]

(cid:122) ir on the web: manually specified id183, 
e.g., morphological expansion, adding synonyms, etc.

(cid:124) end-to-end performance: trec 2002 (official)

(cid:122) 29.8% correct, cws 0.498

reformulations in textmap are manual generalizations 
of automatically derived patterns   

knowledge mining: system survey

pattern learning
automatically learn surface patterns for answering 
questions from the world wide web

[ravichandran and hovy 2002]

birthyear questions: when was <name> born?

<name> was born on <birthyear>
<name> (<birthyear>-
born in <birthyear>, <name>
   

cf. [zhang and lee 2002]

1. start with a    seed   , e.g. (mozart, 1756)
2. download web documents using a search engine
3. retain sentences that contain both question and answer terms
4. construct a suffix tree for extracting the longest matching 

substring that spans <question> and <answer>
    suffix trees: used in computational biology for detecting 

dna sequences

[gusfield 1997; andersson 1999]

5. calculate precision of patterns

    precision for each pattern = # of patterns with correct 

answer / # of total patterns

knowledge mining: system survey

48

pattern learning
example: discoverer questions

1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.95
0.91
0.9

when <answer> discovered <name>
<answer>   s discovery of <name>
<answer>, the discoverer of <name>
<answer> discovers <name>
<answer> discover <name>
<answer> discovered <name>, the
discovery of <name> by <answer>
<name> was discovered by <answer>
of <answer>   s <name>
<name> was discovered by <answer> in

(cid:124) observations

(cid:122) surface patterns perform better on the web than on the 

trec corpus

(cid:122) surface patterns could benefit from notion of 

constituency, e.g., match not words but nps, vps, etc.

knowledge mining: system survey

lamp national university of singapore: [zhang and lee 2002]

qa examples

transforming

recognizing

learning

question

transforming

recognizing

handle do-aux and be-aux 
extract keyphrase (regexp)

answering

answer

patterns of the form:
q s1 a s2
s1 a s2 q

google

question
templates

textual
patterns

search engines

web

knowledge mining: system survey

http://www.comp.nus.edu.sg/~smadellz/lamp/lamp_index.html

49

lamp: overview
(cid:124) reformulate question

analysis with mei [charniak 1999]
and pc-kimmo [antworth 1990]

(cid:122) undo movement of auxiliary verbs

when did nixon visit china     nixon visited china   
when was oxygen discovered     oxygen was discovered   

(cid:124) extract keyphrase (_q_):

(cid:122) classify questions into 22 classes using regular 
expression templates (which bind to keyphrases)

(cid:124) mine patterns from google:
(cid:122) patterns of the following forms

    _q_ <intermediate> _a_ <boundary>
    <boundary> _a_ <intermediate> _q_

cf. [ravichandran and hovy 2002]

_a_ = answers matched by 
answer regexps

(cid:122) score confidence based on accuracy of mined patterns

knowledge mining: system survey

lamp: overview
learning 
example:

who was the first american in space?
keyphrase (_q_) =    the first american in space   
answer (_a_) = ((alan (b\. )?)?shepard)

examples of learned patterns:

, _a_ became _q_ (0.09)
_a_ was _q_ 0.11 (0.11)
_a_ made history as _q_ (1.00)

from nist-supplied
   answer key   

(cid:124) answering questions:

(cid:122) obtain search results from google
(cid:122) extract answers by applying learned patterns
(cid:122) score candidates by confidence of pattern (duplicate 

answers increase score)

(cid:124) end-to-end performance: trec 2002 (official)

(cid:122) 21% correct, 0.396 cws

knowledge mining: system survey

50

nsir for www u. michigan: [radev et al. 2002]
question: what is the largest city in northern afghanistan?

query modulation

(largest or biggest) city    northern afghanistan   

document retrieval

retrieve top 40 documents from web search

sentence retrieval

retrieve top 50 sentences from documents
(weighted id165 scoring)

answer extraction

generate phrases using a chunker

answer ranking

answer: mazer-e-sharif

two components of candidate phrase score:
1. proximity to question words
2. phrase signatures: p(phrase-type|pos-sig)

e.g., p(person|nnp nnp) = 0.458

knowledge mining: system survey

performance: mrr 0.151 (trec-8 informal)

nsir for trec u. michigan: [qi et al. 2002]

questions
questions
questions

document 
retrieval

question

type

top docs

ranked list

chunker

questions
questions
phrases

corpus

feature extraction

frequency, overlap, length, proximity, possig
lexsig, word list, named-entity, web ranking

web ranking as a feature

answer ranking
(for one question)

answer reranking

(nil/confidence)

questions
questions
answers
(by confidence)

knowledge mining: system survey

51

nsir: trec
(cid:124) question classification: allow multiple categories 

with a probabilistic classifier

(cid:124) phrase extraction: extract phrases from top 20 

nist documents using lt-chunk 

(cid:124) feature extraction: compute nine features of 

each phrase
(cid:122) web ranking is one such feature

(cid:124) answer ranking: linearly combine individual 

features to produce final score for each candidate
(cid:122) feature weights specific to each question type

(cid:124) end-to-end performance: trec 2002 (official)

(cid:122) 17.8% correct, cws 0.283

knowledge mining: system survey

answerbus u. michigan: [zheng 2002ab]

user question

english, german, french, spanish,
italian, or portuguese questions

translated question

altavista   s babelfish service

question type

matching words

search engine
specific query

selected 

search engines

hit lists from search engines

extracted sentence

answer candidates

ranked answers

google, yahoo, wisenut,
altavista, and yahoo news

knowledge mining: system survey

http://misshoover.si.umich.edu/~zzheng/qa-new/

52

answerbus: overview
(cid:124) search query

(cid:122) stopword filtering, low tf keyword filtering, some verb 

conjugation

(cid:124) simple sentence scoring:

score =

q

   
    q
q if
0 otherwise

    1
1 +   

similar to the mitre algorithm
[breck et al. 2001; light et al. 2001]

q = number of matching words in query
q = total number of query words

(cid:124) other techniques:

(cid:122) question type classification
(cid:122) coreference resolution (in adjacent sentences)

knowledge mining: system survey

knowledge mining:
selected techniques

id53 techniques for the world wide web

53

knowledge mining techniques
(cid:124) projecting answers onto another corpus
(cid:124) using the web (and id138) to rerank answers 
(cid:124) using the web to validate answers

(cid:122) verifying the correctness of question answer pairs
(cid:122) estimating the confidence of question answer pairs

(cid:124) tweaking search engines: getting the most out of 

a search
(cid:122) id183 for search engines
(cid:122) learning search engine specific reformulations

knowledge mining: selected techniques

answer projection
(cid:124) just an artifact of trec competitions?
(cid:122) trec answers require [answer, docid] pair
(cid:122) document from the trec corpus must support answer
(cid:122) if answers were extracted form an outside source, a 

supporting trec document must still be found

(cid:124) perhaps not   

(cid:122) people prefer paragraph-sized answers

[lin, j. et al. 2003]
find exact answers from the web (using data redundancy), 
but present answers from another source

(cid:124) sample answer projection algorithms:

(cid:122) use document-retrieval or passage retrieval algorithms
(cid:122) query = keywords from question + keywords from 

answer

knowledge mining: selected techniques

54

answer projection performance
(cid:124) askmsr answer projection:

[brill et al. 2001]
(cid:122) used the okapi ir engine (bm25 weighting)
(cid:122) generated query = question + answer
(cid:122) selected top-ranking document as support
(cid:122) performance: ~80% (i.e., 20% of    supporting 

documents    did not actually support the answer)

(cid:124) aranea answer projection:

[lin, j. et al. 2002]

(cid:122) projected answer onto nist-supplied documents
(cid:122) used sliding window technique

window score = # keywords from question + # keywords 
from answer (neither term could be zero)

(cid:122) selected document of highest scoring window as 

support

(cid:122) performance: ~75%

knowledge mining: selected techniques

answer projection: analysis

question: who was the first black heavyweight champion?
answer: jack johnson

    louis was the first african-american heavyweight since 
jack johnson who was allowed to get close to that symbol 
of ultimate manhood, the heavyweight crown    

question: who was the roman god of the sea?
answer: neptune

    romanian foreign minister petre roman wednesday met 
at the neptune resort of the black sea shore with his 
slovenian counterpart, alojz peterle,    

question: what is the nickname of oklahoma?
answer: sooner state

    the victory makes the sooners the no. 3 seed in the 
conference tournament. oklahoma state (23-5, 12-4) will be 
the fourth seed   

knowledge mining: selected techniques

55

answer reranking
use the web and id138 to rerank answers to 
definition questions

[lin, c.y. 2002]

input:

definition question
n candidate answers

reranking
procedure

web data

id138

reranking procedure 
boosts correct 
answers to a higher 
rank

output:

reordered candidate answers

knowledge mining: selected techniques

answer reranking
(cid:124) web reranking

(cid:122) obtain pages from google and calculate tf.idf values for 

keywords

(cid:122) matching score = sum of tf.idf values of keywords in 

answer candidates

(cid:122) new score = original candidate score    matching score

(cid:124) id138 reranking

(cid:122) create a definition database from id138 glosses; 

calculate idf values for keywords

(cid:122) matching score = sum of idf values of keywords in 

answer candidates

(cid:122) new score = original candidate score    matching score

knowledge mining: selected techniques

56

answer reranking
what is wimbledon?

original
the french open and the u.s. open
which includes a japanese-style garden
the most famous front yard in tennis 
nil
sampras    biggest letdown of the year

1
2
3
4
5

web reranking
the most famous front yard in tennis 
the french open and the u.s. open
nil
sampras    biggest letdown of the year
lawn tennis & croquet club

what is autism?

original
down   s syndrome
mental retardation
the inability to communicate with others
nil
a group of similar-looking diseases

1
2
3
4
5

id138 reranking
the inability to communicate with others
mental disorder
nil
down   s syndrome
mental retardation

performance

either method: +19% mrr
both methods: +25% mrr

knowledge mining: selected techniques

answer validation
(cid:124) can we use the web to validate answers?
(cid:122) to automatically score and evaluate qa systems
(cid:122) to rerank and rescore answers from qa systems

[magnini et al. 2002ac]

the basic idea: compute a continuous function that takes 
both the question and answer as input (as    bag of words   )

answer validation function: f(question, answer) = x

if x > threshold, then answer is valid, 
otherwise, answer is invalid

what functions satisfy this property?
can these functions be easily calculated using web data?

knowledge mining: selected techniques

57

answer validation
three different answer validation functions:
(various statistical measures of co-occurrence)

all three can be easily calculated from search engine results
1. pointwise mutual information (pmi)
2. maximal likelihood ratio (mlhr)
3. corrected id155 (ccp)

ccp

qsp
(

,

asp

)

=

p

)

asp
(
|
p
asp
(

qsp
2
)
3

   

( hits
( hits

qsp
  
qsp

near
(hits
  )

)

asp
  
asp
)

maxpages

2

3

treat questions and 
answers as    bag of words   

qsp = question sub-pattern (content words + expansions)
asp = answer sub-pattern
maxpages = total number of pages in search engine index

knowledge mining: selected techniques

answer validation performance

evaluation metric: agreement between machine algorithm 
and human judgment (from trec)

ccp     relative
ccp     absolute
pmi     relative
pmi     absolute
mlhr     relative
mlhr     absolute

agreement
81.25%
78.42%
79.56%
77.79%
79.60%
77.40%

absolute threshold: fixed threshold
relative threshold: threshold set to a percentage of the score of the 
highest scoring answer

knowledge mining: selected techniques

58

diogene

[magnini et al. 2001, 2002b]

application of web answer validation techniques

question

id121 and

id52

multiwords
recognition

word sense
disambiguation

answer type
identification

keywords
expansion

answer

document 
collection

world wide web

query 

reformulation

search 
engine

query

composition

answer validation

and ranking

candidate answer

filtering

named entities

recognition

question processing

search

answer extraction

knowledge mining: selected techniques

diogene: answer validation
(cid:124) two measures

(cid:122)    statistical approach   : corrected id155 

(using web page hit counts only)

(cid:122)    content-based approach   : co-occurrence between 

question and answer (from downloaded snippets)

(cid:124) performance: trec 2002 (official)

(cid:122) 38.4%, cws 0.589 (content-based measure)
(cid:122) content-based measure beat statistical measure and 

combination of both measures

(cid:122) overall contribution of answer validation techniques is 

unclear

knowledge mining: selected techniques

59

confidence estimation
estimating the id203 that a question answer 
pair is correct

[xu et al. 2002]

(cid:122) result useful for confidence estimation
(cid:122) similar to magnini et al. except without thresholding

bbn2002b
p(correct|q,a)     p(correct|t, f)     p(correct|t)  0.5 + p(correct|f)  0.5

t = question type
f = frequencies of a in google summaries

bbn2002c
p(correct|q,a)     p(correct|f, intrec)

f = frequencies of a in google summaries
intrec = boolean indicator variable, true iff answer also found in trec 

trec-9 and trec 2001 questions used for parameter estimation

knowledge mining: selected techniques

confidence estimation
(cid:124) performance: trec 2002 (official)

(cid:122) baseline (without web): 18.6% correct, cws 0.257
(cid:122) bbn2002b: 28.8% correct, cws 0.468
(cid:122) bbn2002c: 28.4% correct, cws 0.499

(cid:124) observations

(cid:122) use of web significantly boosts performance
(cid:122) performance contribution of confidence estimation 

procedure is unclear

knowledge mining: selected techniques

60

tweaking search engines
   getting the most out of an existing search engine   
(cid:124) large ir literature on id183

(cid:122) expand queries based on synonyms and lexical-
[voorhees 1994]

semantic relations (from id138)

even with sense disambiguated queries, synonymy 
expansion provides little benefit

(cid:122) expand queries based on relevant terms in top-ranking 

documents

[mitra et al. 1998]

(cid:122) expand queries with terms from top-ranking documents 

that co-occur with query terms

[xu and croft 2000]

knowledge mining: selected techniques

id183 for the web
(cid:124) id183 is difficult with web search 

engines
(cid:122) search algorithm is hidden: the service must be treated 

like an opaque black box

(cid:122) no principled way for developing id183 

techniques: trial and error required

(cid:122) it is beneficial to use more than one service, but how do 

we assess the relative strengths and weaknesses of  
each search engine?

knowledge mining: selected techniques

61

expanding boolean queries

[magnini and prevete 2000]
exploiting lexical expansions and boolean compositions

expand keywords: synonyms and morphological derivations

inventore (inventor)

synonyms

derivation

derivation

scopritore (discoverer)
ideatore (artificer)
invenzione (invention)

synonyms

inventare  (invent)

invenzione (invention)

scoprire (discover)

synonyms

luce_elettrica (electric light)

synonyms

lampada_a_incandescenza (incandescent lamp)

how do we combine these keywords into boolean queries?

knowledge mining: selected techniques

id183 strategies
kas: keyword    and    composition search
conjoin original keywords

(inventore     luce_elettrica) 

kis: keyword insertion search
or of ands; each and clause = original keywords + one derived word

(  (inventore     luce_elettrica     scopritore)
    (inventore     luce_elettrica     ideatore)
    (inventore     luce_elettrica     invenzione)
   )

kcs: keyword cartesian search
or of ands; and clauses = cartesian product of all derivations

(  (inventore     luce_elettrica)
    (inventore     lampada_a_incandescenza)
    (scopritore     luce_elettrica)
    (scopritore     lampada_a_incandescenza)
   )

knowledge mining: selected techniques

62

kas vs. kis vs. kcs
(cid:124) evaluation: 20 questions, documents from excite
(cid:124) relevance determined by three human judges
(cid:124) measures: compared to kas baseline

(cid:122) with f-, document ordering is not taken into account
(cid:122) with f+, document ordering is taken into account

kis

kcs

f-
+7%
-3%
+18%

f+
-15%
+19%
+17%

f-
+7%
+59%
+23%

f+
-15%
+77%
+17%

+19%

+13%

+33%

+22%

qs1
qs2
qs3
all

qs1: subset of questions 
where number of morphological 
derivations and synonyms is  
greater than 3

qs2: equal to 2 or 3

qs3: less than 2

knowledge mining: selected techniques

web id183: pris

[yang and chua 2002]

use of the web for id183

question

question analysis

question

classification

question
parsing

original

content words

external 

knowledge bases

web

id138

answer

answer 
extraction

candidate 
sentences

sentence
ranking

relevant
trec doc

document
retrieval

expanded

content words

reduce number of expanded content words

knowledge mining: selected techniques

63

pris: overview
(cid:124) use the web for id183: supplement 
original query with keywords that co-occur with 
the question
(cid:122) technique similar to 

[xu and croft 2000]
(cid:124) performance: trec 2002 (official)

(cid:122) 58% correct, cws 0.61
(cid:122) 3rd highest scoring system
(cid:122) however, the contribution of the web is unclear

knowledge mining: selected techniques

search engine specific queries
(cid:124) specific expressive forms: query transformation 

rules that improve search results
[lawrence and giles 1998; joho and sanderson 2000]
(cid:122) focus is on improving document retrieval, not question 

answering per se

   what is x           x is   

   x refers to   
   

(cid:124) shortcomings:

(cid:122) transformation rules were hand crafted
(cid:122) transformation rules did not take into account    quirks    

of different search engines

knowledge mining: selected techniques

64

[agichtein et al. 2001]

tritus
learn query transformations optimized for each 
search engine

   what is a   

   is usually   
   refers to   
   usually   
   refers   
   is used   

   is usually   
   usually   
   called   
   sometimes   
   is one   

altavista

google

transformations capture the    quirks    of different search engines

knowledge mining: selected techniques

tritus: transformation learning

select question phrase (qp): group questions by their 
initial tokens

who was albert einstein?
how do i fix a broken television?
where can i find a lisp machine?
what is a pulsar?

generate candidate transformations (tr): from <q, a> pairs, 
generate all id165s of answers that do not contain content words

   what is a   

   refers to   
   refers   
   meets   
   driven   
   named after   
   often used   
   to describe   

knowledge mining: selected techniques

two components to tr score:
    frequency of co-occurrence 

between tr and qp

    okapi bm25 weighting on tr

[robertson and walker 1997; robertson et al. 1998]

65

tritus: transformation learning
train candidate transformations (tr) against search engines
1. break questions into {qp c}
2. submit the query {tr c} to various search engines
3. score tr with respect to known answer (okapi bm25 weighting)
4. keep highest scoring tr for each particular search engine

c = question     question phrase

experimental setting:
(cid:124) training set 

(cid:122) ~10k <question, answer> pairs from internet faqs
(cid:122) seven question types
(cid:122) three search engines (google, altavista, askjeeves)

(cid:124) test set

(cid:122) 313 questions in total (~50 per question type)
(cid:122) relevance of documents manually evaluated by human 

judges

knowledge mining: selected techniques

tritus: results

indeed, transformations 
learned for each search 
engine were slightly 
different

tritus + search engine 
performs better than 
search engine alone

knowledge mining: selected techniques

what                  

how                 

where         

who

66

[radev et al. 2001]

qasm
(cid:124) qasm = id53 using statistical 

models

cf. [mann 2001, 2002]

(cid:124) query reformulation using a noisy channel 

translation model

keyword query
(biggest or largest) 
producer tungsten

noisy channel

natural language question

what country is the biggest 
producer of tungsten?

setup: the keyword query is somehow    scrambled    in the noisy 
channel and converted into a natural language question
task: given the natural language question and known 
properties about the noisy channel, recover the keyword query

applications of similar techniques in other domains: machine translation [brown et al. 1990],

speech processing [jelinek 1997], 
information retrieval [berger and lafferty 1999]

knowledge mining: selected techniques

qasm: noisy channels

keyword query
(biggest or largest) 
producer tungsten

noisy channel

natural language question

what country is the biggest 
producer of tungsten?

what is the noisy channel    allowed to do   ?

channel operators = possible methods by which the message 
can be corrupted

delete: e.g., delete prepositions, stopwords, etc.
replace: e.g., replace the n-th noun phrase with id138 
expansions
disjunct: e.g., replace the n-th noun phrase with or disjunction

once the properties of the noisy channel are learned, we can 
   decode    natural language questions into keyword queries

knowledge mining: selected techniques

67

qasm: training
(cid:124) training using em algorithm

(cid:122) use {question, answer} pairs from trec (and from 

custom collection) 

(cid:122) measure the    fitness    of a keyword query by scoring the 

documents it returns

(cid:122) maximize total reciprocal document rank

(cid:124) evaluation: test set of 18 questions

(cid:122) increase of 42% over the baseline
(cid:122) for 14 of the questions, sequence of same two 

operators were deemed the best: delete stopwords and 
delete auxiliary verbs

couldn   t we have hand-coded these two operators 
from the beginning?

knowledge mining: selected techniques

knowledge mining:
challenges and potential solutions
id53 techniques for the world wide web

68

knowledge mining: challenges
(cid:124) search engine behavior changes over time
(cid:124) sheer amount of useless data floods out answers
(cid:124) anaphora poses problems

andorra is a tiny land-locked country in southwestern europe, 
between france and spain.
   
tourism, the largest sector of its tiny, well-to-do economy, 
accounts for roughly 80% of gdp   

what is the biggest sector in andorra   s economy? i don   t know

knowledge mining: challenges and potential solutions

more challenges
(cid:124) answers change over time

who is the governor of alaska?
what is the population of gambia?

(cid:124) relative time and temporal expressions 

complicate analysis
(cid:122) documents refer to events in the past or future (relative 

to the date the article was written)

date: january 2003     five years ago, when bill clinton was 
still the president of the united states   

who is the president of the united states? bill clinton

knowledge mining: challenges and potential solutions

69

even more challenges
(cid:124) surface patterns are often wrong

(cid:122) no notion of constituency

in may jane goodall spoke at orchestra hall in minneapolis/st. 
paul   
who spoke at orchestra hall? may jane goodall

(cid:122) patterns can be misleading

the 55 people in massachusetts that have suffered from the 
recent outbreak of   
what is the population of massachusetts? 55 people

(cid:124) most popular     correct

what is the tallest mountain in europe?

most common incorrect answer = mont blanc (4807m)
correct answer = mount elbrus (5642m)

knowledge mining: challenges and potential solutions

still more challenges
(cid:124)    bag-of-words    approaches fail to capture 

syntactic relations
(cid:122) named-entity detection alone isn   t sufficient to 

determine the answer!

lee harvey oswald, the gunman who assassinated president 
john f. kennedy, was later shot and killed by jack ruby. 
who killed lee harvey oswald? john f. kennedy

(cid:124) knowledge coverage is not consistent

when was albert einstein born? march 14, 1879
when was alfred einstein born? [who   s alfred einstein?]

albert einstein is more famous than alfred einstein, so questions 
about alfred are    overloaded    by information about albert.

knowledge mining: challenges and potential solutions

70

really hard challenges
(cid:124) myths and jokes

in march, 1999, trent lott claimed to have invented the paper 
clip in response to al gore   s claim that he invented the internet
who invented the paper clip? trent lott

george bush jokes   george bush thinks that steven spielberg
is the prime minister of israel   
who is the prime minister of israel? steven spielberg

because: who is the prime minister of israel? 

    x is the prime minister of israel

where does santa claus live?
what does the tooth fairy leave under pillows?
how many horns does a unicorn have?

we really need semantics to solve these problems!

knowledge mining: challenges and potential solutions

nlp provides some solutions
(cid:124) linguistically-sophisticated techniques:

(cid:122) parse embedded constituents (bush thinks that   )
(cid:122) determine the correct semantic role of the answer (who 

visited whom?)

(cid:122) resolve temporal referring expressions (last year   )
(cid:122) resolve pronominal anaphora (it is the tallest   )
[biber 1986; kessler et al. 1997]

(cid:124) genre classification

(cid:122) determine the type of article
(cid:122) determine the    authority    of the article (based on 

sentence structure, etc.)

knowledge mining: challenges and potential solutions

71

logic-based answer extraction
(cid:124) parse text and questions into logical form
(cid:124) attempt to    prove    the question

(cid:122) logical form of the question contains unbound variables
(cid:122) determine bindings (i.e., the answer) via unification

example from [aliod et al. 1998], cf. [zajac 2001]

question: which command 
copies files?

answer: cp copies the contents 
of filename1 onto filename2

?- findall(s, (object(command,x)/s,

(evt(copy,e,[x,y])/s;
evt(duplicate,e,[x,y])/s;
object(n,y)/s), r).

holds(e1)/s1.
object(cp,x1)/s1.
object(command,x1)/s1.
evt(copy,e1,[x1,x2])/s1.
object(content,x2)/s1.
object(filename1,x3)/s1.
object(file,x3)/s1. of(x2,x3)/s1.
object(filename2,x4)/s1.
object(file,x4)/s1. onto(e1,x4)/s1.

knowledge mining: challenges and potential solutions

logic-based answer validation

[harabagiu et al. 2000ab; moldovan et al. 2002]
use abductive proof techniques to justify answer
1. parse text surrounding candidate answer into 

logical form

2. parse natural language question into logical 

form

3. can the question and answer be logically 

unified?
if unification is successful, then the answer 
justifies the question

4.

knowledge mining: challenges and potential solutions

72

how can relations help?
(cid:124) lexical content alone cannot capture meaning
the largest planet   s volcanoes
the planet   s largest volcanoes

the bird ate the snake.
the snake ate the bird.

the meaning of life
a meaningful life

the house by the river
the river by the house

(cid:124) two phenomena where syntactic relations can 
overcome failures of    bag-of-words    approaches
[katz and lin 2003]
(cid:122) semantic symmetry     selectional restrictions of 

different arguments of the same head overlap

(cid:122) ambiguous modification     certain modifiers can 

potentially modify a large number of heads

knowledge mining: challenges and potential solutions

semantic symmetry
the selectional restrictions of different arguments of the 
same head overlap, e.g., when verb(x,y) and verb(y,x)
can both be found in the corpus

question: what do frogs eat?

correct lexical content, correct syntactic relations

(1) adult frogs eat mainly insects and other small animals, including 

earthworms, minnows, and spiders.

correct lexical content, incorrect syntactic relations

(2) alligators eat many kinds of small animals that live in or near the 
water, including fish, snakes, frogs, turtles, small mammals, and 
birds.

(3) some bats catch fish with their claws, and a few species eat lizards, 

rodents, small birds, tree frogs, and other bats.

knowledge mining: challenges and potential solutions

73

ambiguous modification
some modifiers can potentially modify a large number of 
co-occurring heads
question: what is the largest volcano in the solar system?

correct lexical content, correct syntactic relations

(1) mars boasts many extreme geographic features; for example, 
olympus mons, is the largest volcano in the solar system.

(2) olympus mons, which spans an area the size of arizona, is the 

largest volcano in the solar system.

correct lexical content, incorrect syntactic relations

(3) the galileo probe's mission to jupiter, the largest planet in the 

solar system, included amazing photographs of the volcanoes on 
io, one of its four most famous moons.

(4) even the largest volcanoes found on earth are puny in comparison 
to others found around our own cosmic backyard, the solar system.

knowledge mining: challenges and potential solutions

sapere: using nlp selectively
[lin, j. 2001; katz and lin 2003]
(cid:124) sophisticated linguistic techniques are too brittle 

to apply indiscriminately

natural language techniques often achieve high precision, 
but poor recall

(cid:124) simple and robust statistical techniques should 

not be abandoned

(cid:124) sophisticated linguistic techniques should be 
applied only when necessary, e.g., to handle
(cid:122) semantic symmetry
(cid:122) ambiguous modification

(cid:124) our prototype sapere system is specially 

designed to handle these phenomena

knowledge mining: challenges and potential solutions

74

using syntactic relations
(cid:124) automatically extract syntactic relations from 

questions and corpus, e.g.,
(cid:122) subject-verb-object relations
(cid:122) adjective-noun modification relations
(cid:122) possessive relations
(cid:122) np-pp attachment relations

(cid:124) match questions and answers at the level of 

syntactic relations

knowledge mining: challenges and potential solutions

why syntactic relations?
syntactic relations can approximate    meaning   

the bird ate the snake.
< bird subject-of eat >
< snake object-of eat >
the snake ate the bird.
< bird object-of eat >
< snake subject-of eat >

the meaning of life
< life poss meaning >
a meaningful life
< meaning mod life >

the largest planet   s volcanoes
< largest mod planet >
< planet poss volcanoes >
the planet   s largest volcanoes
< planet poss volcanoes >
< largest mod volcanoes >

the house by the river
< house by river >
the river by the house
< river by house >

knowledge mining: challenges and potential solutions

75

benefit of relations
preliminary experiments with the worldbook 
encyclopedia show significant increase in precision 

avg. # of sentence returned
avg. # of correct sentences
avg. precision

sapere
4
3.13
0.84

baseline
43.88
5.88
0.29

sapere: entire corpus is parsed into syntactic relations, relations 
are matched at the sentential level

baseline: standard boolean keyword retriever (indexed at 
sentential level)

test set = 16 question hand-selected questions designed to 
illustrate semantic symmetry and ambiguous modification

knowledge mining: challenges and potential solutions

trec examples
ambiguous modification is prevalent in the trec 
corpus  

(q1003) what is the highest dam in the u.s.?

typical wrong answers from the trec corpus:

extensive flooding was reported sunday on the chattahoochee river in 
georgia as it neared its crest at tailwater and george dam, its highest
level since 1929.

a swollen tributary the ganges river in the capital today reached its 
highest level in 34 years, officials said, as soldiers and volunteers 
worked to build dams against the rising waters.

two years ago, the numbers of steelhead returning to the river was the 
highest since the dam was built in 1959.

knowledge mining: challenges and potential solutions

76

knowledge mining:
conclusion

id53 techniques for the world wide web

summary
(cid:124) the enormous amount of text available on the 

web can be successfully utilized for qa

(cid:124) knowledge mining is a relatively new, but active 

field of research

(cid:124) significant progress has been made in the past 

few years

(cid:124) significant challenges have yet to be addressed 
(cid:124) linguistically-sophisticated techniques promise to 

further boost knowledge mining performance

knowledge mining: conclusion

77

the future

nature of the 
technique

linguistically
sophisticated

knowledge mining
linguistic techniques
relations-based matching, logic, etc.

unstructured knowledge

(free text)

statistical techniques
id165 generation, voting, tiling, etc.

linguistically
uninformed

nature of the information
structured knowledge

(databases)

knowledge mining: conclusion

knowledge annotation

id53 techniques for the world wide web

78

knowledge annotation:
general overview

id53 techniques for the world wide web

knowledge annotation
(cid:124) definition: techniques that effectively employ 
structured and semistructured sources on the 
web for id53

(cid:124) key ideas:

(cid:122)    wrap    web resources for easy access
(cid:122) employ annotations to connect web resources to 

natural language 

(cid:122) leverage    zipf   s law of id53   

knowledge annotation: overview

79

key questions
(cid:124) how can we organize diverse, heterogeneous, 

and semistructured sources on the web?

(cid:124) is it possible to    consolidate    these diverse 

resources under a unified framework?

(cid:124) can we effectively integrate this knowledge into a 

id53 system?

(cid:124) how can we ensure adequate knowledge 

coverage?

how can we effectively employ structured and 
semistructured sources on the web for 
id53?

knowledge annotation: overview

knowledge annotation

nature of the 
technique

linguistically
sophisticated

knowledge 
annotation

database concepts

nature of the information
structured knowledge

(databases)

unstructured knowledge

(free text)

knowledge annotation: overview

linguistically
uninformed

80

the big picture
(cid:124) start with structured or semistructured resources 

on the web

(cid:124) organize them to provide convenient methods for 

access

(cid:124)    annotate    these resources with metadata that 

describes their information content

(cid:124) connect these annotated resources with natural 

language to provide id53 
capabilities

knowledge annotation: overview

why knowledge annotation?
(cid:124) the web contains many databases that offer a 

wealth of information

(cid:124) they are part of the    hidden    or    deep    web

(cid:122) information is accessible only through specific search 

interfaces

(cid:122) pages are dynamically generated upon request
(cid:122) content cannot be indexed by search engines
(cid:122) knowledge mining techniques are not applicable

(cid:124) with knowledge annotation, we can achieve high-

precision id53

knowledge annotation: overview

81

sample resources
(cid:124) internet movie database

(cid:122) content: cast, crew, and other movie-related 

information

(cid:122) size: hundreds of thousands of movies; tens of 

thousands of actors/actresses

(cid:124) cia world factbook

(cid:122) content: geographic, political, demographic, and 

economic information

(cid:122) size: approximately two hundred countries/territories in 

the world

(cid:124) biography.com

(cid:122) content: short biographies of famous people
(cid:122) size: tens of thousands of entries

knowledge annotation: overview

   zipf   s law of qa   
observation: a few    question types    account for a 
large portion of all question instances

similar questions can be parameterized and grouped into 
question classes, e.g.,

when was                         born?

mozart
einstein
gandhi
   

alabama
alaska
what is the                               of                    
arizona
   

state bird
state capital
state flower
   

?

the eiffel tower
the statue of liberty
where is                        
taj mahal
   

located?

knowledge annotation: overview

82

zipf   s law in web search
frequency distribution of user queries from askjeeves    search logs

[lowe 2000]

frequently occurring questions 
dominate all questions

f
r
e
q
u
e
n
c
y

1

rank

knowledge annotation: overview

zipf   s law in trec [lin, j. 2002]
cumulative distribution of question types in the trec test collections

qa performance

e
g
a
t
r
c
e
e
v
r
o
r
o
c
c
 
 
e
e
g
g
d
a
t
e
n
l
e
w
c
o
r
n
e
p
k

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

0

trec-9
trec-2001
trec-9/2001

10

20

30

40

50

60

schemas
question types

ten question types alone account for ~20% of questions 
from trec-9 and ~35% of questions from trec-2001

knowledge annotation: overview

83

applying zipf   s law of qa
(cid:124) observation: frequently occurring questions 

translate naturally into database queries

what is the population of x? x     {country}

get population of x from world factbook

when was x born? x     {famous-person}

get birthdate of x from biography.com

(cid:124) how can we organize web data so that such 

   database queries    can be easily executed?

knowledge annotation: overview

slurp or wrap?
(cid:124) two general ways for conveniently accessing 
structured and semistructured web resources

(cid:124) wrap

(cid:122) also called    screen scraping   
(cid:122) provide programmatic access to web resources (in 

essence, an api)

(cid:122) retrieve results dynamically by

    imitating a cgi script
    fetching a live html page

(cid:124) slurp

(cid:122)    vacuum    out information from web sources
(cid:122) restructure information in a local database

knowledge annotation: overview

84

tradeoffs: wrapping
(cid:124) advantages:

(cid:122) information is always up-to-date (even when the content 

of the original source changes)

(cid:122) dynamic information (e.g., stock quotes and weather 

reports) is easy to access

(cid:124) disadvantages:

(cid:122) queries are limited in expressiveness

queries limited by the cgi facilities offered by the website
aggregate operations (e.g., max) are often impractical
(cid:122) reliability issues: what if source goes down?
(cid:122) wrapper maintenance: what if source changes 

layout/format?

knowledge annotation: overview

tradeoffs: slurping
(cid:124) advantages:

(cid:122) queries can be arbitrarily expressive

allows retrieval of records based on different keys
aggregate operations (e.g., max) are easy

(cid:122) information is always available (high reliability)

(cid:124) disadvantages:

(cid:122) stale data problem: what if the original source changes 

or is updated?

(cid:122) dynamic data problem: what if the information changes 

frequently? (e.g., stock quotes and weather reports)

(cid:122) resource limitations: what if there is simply too much 

data to store locally?

knowledge annotation: overview

85

data modeling issues
(cid:124) how can we impose a data model on the web?

two constraints:
1. the data model must accurately capture both structure 

2. the data model must naturally mirror natural language 

and content

questions

(cid:124) difficulties

(cid:122) data is often inconsistent or incomplete
(cid:122) data complexity varies from resource to resource

knowledge annotation: overview

putting it together
connecting natural language questions to structured and 
semistructured data

natural 
language 
system

structured 

query

semistructured 

database

(slurp or wrap)

what is the population of x? x     {country}

get population of x from cia factbook

when was x born? x     {famous-person}

get birthdate of x from biography.com

knowledge annotation: overview

86

knowledge annotation:
start and omnibase

id53 techniques for the world wide web

start and omnibase

[katz 1988,1997; katz et al. 2002a]

the first id53 system for the world wide 
web     employs knowledge annotation techniques

structured 

query

start

omnibase

questions

biography.com
world factbook
merriam-webster
potus
imdb
nasa
etc.

world wide web

how does omnibase work?
how does start work?
how is omnibase connected to start?

knowledge annotation: start and omibase

87

omnibase: overview
(cid:124) a    virtual    database that integrates structured and 

semistructured data sources

(cid:124) an abstraction layer over heterogeneous sources

omnibase

uniform query language

wrapper

wrapper

wrapper

wrapper

web 

data source

web 

data source

web 

data source

local database

knowledge annotation: start and omibase

omnibase: opv model
(cid:124) the object-property-value (opv) data model
(cid:122) relational data model adopted for natural language
(cid:122) simple, yet pervasive

sources contain objects
objects have properties
properties have values

many natural language questions can be analyzed as 
requests for the value of a property of an object

(cid:124) the    get    command:

(get source object property)     value

knowledge annotation: start and omibase

88

omnibase: opv examples
(cid:124)    what is the population of taiwan?   

(cid:122) source: cia world factbook
(cid:122) object: taiwan
(cid:122) property: population
(cid:122) value: 22 million

(cid:124)    when was andrew johnson president?   

(cid:122) source: internet public library
(cid:122) object: andrew johnson
(cid:122) property: presidential term
(cid:122) value: april 15, 1865 to march 3, 1869

knowledge annotation: start and omibase

omnibase: opv coverage
10 web sources mapped into the object-property-value data 
model cover 27% of the trec-9 and 47% of the trec-2001 
qa track questions

question
who wrote the music for the 
titanic?

object
titanic

property
composer

value
john williams

who invented dynamite?

dynamite

inventor

alfred nobel

what languages are spoken in 
guernsey?

guernsey

languages

english, french

show me paintings by monet.

monet

works

knowledge annotation: start and omibase

89

omnibase: wrappers
omnibase query
(get ipl    abraham lincoln    spouse)

mary todd (1818-1882), on november 4, 1842

knowledge annotation: start and omibase

omnibase: wrapper operation
1. generate url

(cid:122) map symbols onto url

sometimes urls can be computed directly from symbol
sometimes the mapping must be stored locally
   abraham lincoln   
   abe lincoln   
   lincoln   

http://www.ipl.org/div/potus/alincoln.html

2. fetch web page
3. extract relevant information

(cid:122) search for textual landmarks that delimit desired 

information (usually with id157)
<strong>married:  </strong>(.*)<br>

relevant information

knowledge annotation: start and omibase

90

connecting the pieces

knowledge annotation: start and omibase

start and omnibase

structured 

query

start

omnibase

questions

natural language annotations

biography.com
world factbook
merriam-webster
potus
imdb
nasa
etc.

world wide web

(cid:124) natural language annotation technology connects start 

and omnibase

(cid:124) detour into annotation-based id53   

knowledge annotation: start and omibase

91

natural language annotations

[katz 1997]

+

an object at 
rest tends to 
remain at rest.

four score and 
seven years ago 
our forefathers 
brought forth

in 1492,
columbus sailed 
the ocean blue.

knowledge base

natural language annotations: sentences/phrases that 
describe the content of various information segments

knowledge annotation: start and omibase

annotation flow

+

on mars, a year lasts 687 earth days   annotation

   a martian year is 687 days.   

start
knowledge 

base

annotator

questions
       how long is the martian year?   
       how long is a year on mars?   
       how many days are in a martian year?   

user

on mars, a year lasts 687 earth days   

knowledge annotation: start and omibase

92

matching annotations

natural language questions

1

both questions and 
annotations are parsed 
into ternary expressions

natural language annotations
annotated segment

annotated segment
parsed annotations retain 
pointers back to original segment

ternary expressions 

matcher

annotated segment

2

3

questions are matched 
with annotations at the 
syntactic level

annotated segments are 
processed and returned to the 
user (the exact processing 
depends on the segment type)

knowledge annotation: start and omibase

syntactic matching
(cid:124) allows utilization of linguistic techniques to aid in 

the matching process:
(cid:122) synonyms
(cid:122) hypernyms and hyponyms
(cid:122) transformation rules to handle syntactic alternations

knowledge annotation: start and omibase

93

transformation rules [katz and levin 1988]
the president impressed the 
the president   s determination 
country with his determination.
impressed the country.
s-rule for the property factoring alternation:

someone1 emotional-reaction-
verb someone2 with something

someone1   s something emotional-
reaction-verb someone2

with

related-to

related-to

emotional-
reaction-

verb

something

someone1

emotional-
reaction-

verb

something1

someone1

someone1

someone2

something1

someone2

knowledge annotation: start and omibase

emotional reaction 
verbs:
surprise
amaze
impress
etc.

stun
startle
please

matching and retrieval

1

2

3

both questions and 
annotations are parsed 
into ternary expressions

questions are matched 
with annotations at the 
syntactic level

annotated segments are 
processed and returned to the 
user

the action taken when an annotation 
matches a question depends on the 
type of annotated segment

ternary expressions 

matcher

annotated segment

almost anything can be annotated:

text
pictures
images
movies
sounds
database queries
arbitrary procedures
   etc

knowledge annotation: start and omibase

94

what can we annotate?

direct parseables

multimedia content

the annotated segment is the 
annotation itself. this allows us 
to assert facts and answer 
questions about them

structured queries
(get    imdb-movie    x    director   )
omnibase

annotating omnibase queries 
provides start access to 
semistructured data 

knowledge annotation: start and omibase

annotating pictures, sounds, 
images, etc. provides access to 
content we otherwise could not 
analyze directly

arbitrary procedures

get-time

  

annotating procedures (e.g., a 
system call to a clock) allows 
start to perform a computation 
in response to a question

retrieving knowledge
(cid:124) matching of natural language annotations triggers 

the retrieval process

(cid:124) retrieval process depends on the annotated 

segment:
(cid:122) direct parseables     generate the sentence
(cid:122) multimedia content     return the segment directly
(cid:122) arbitrary procedures     execute the procedure
(cid:122) database queries     execute the database query

(cid:124) annotations provide access to content that our 

systems otherwise could not analyze

knowledge annotation: start and omibase

95

parameterized annotations
natural language annotations can contain parameters 
that stand in for large classes of lexical entries

who directed                                            ?

gone with the wind
good will hunting
citizen kane
   

who directed x ?

x     {set-of-imdb-movies}

alabama
alaska
what is the                               of                    
arizona
   

state bird
state capital
state flower
   

?

what is the p of y ?

p     {state bird, state flower   }
y     {alabama, alaska   }

natural language annotations can be sentences, phrases, or questions

knowledge annotation: start and omibase

recognizing objects
in order for parameterized annotations to match, objects 
have to be recognized

extraction of objects makes parsing possible:

compare

who directed smultronstallet?
who directed mfbflxt?

which one is gibberish?
which one is a real question?

compare

who directed gone with the wind?
who hopped flown past the street?

omnibase serves as a gazetteer for start (to recognize objects)

who directed smultronstallet?
    who directed x ? 

x =    smultronst  llet (1957)    (   wild strawberries   ) from imdb-movie

who directed gone with the wind?
    who directed x ? 

x =    gone with the wind (1939)    from imdb-movie

knowledge annotation: start and omibase

96

the complete qa process
(cid:124) start, with the help of omnibase, figures out 

which sources can answer the question

(cid:124) start translates the question into a structured 

omnibase query

(cid:124) omnibase executes the query by

(cid:122) fetching the relevant pages
(cid:122) extracting the relevant fragments

(cid:124) start performs additional generation and 

returns the answer to the user

knowledge annotation: start and omibase

start: performance
from january 2000 to december 2002, about a million 
questions were posed to start and omnibase

2001
100k (37.6%)
answer: omnibase
answer: start native
74k (27.9%)
don   t know
65k (24.3%)
don   t understand
15k (5.5%)
unknown word
12k (4.7%)
total
266k (100%)
don   t know = question successfully parsed, but no knowledge available
don   t know = question couldn   t be parsed

2000
85k (27.1%)
123k (39.3%)
72k (22.9%)
19k (6.0%)
15k (4.8%)
313k (100%)

2002
129k (37.9%)
107k (31.5%)
78k (22.8%)
14k (4.2%)
12k (3.6%)
342k (100%)

of those, 619k questions were successfully answered

total answered correctly
answered using omnibase
answer with native kb

2000
208k (66.4%)
40.9%
59.1%

2001
174k (65.5%)
57.4%
42.6%

2002
237k (69.4)
54.6%
45.4%

knowledge annotation: start and omibase

97

knowledge annotation:
other annotation-based systems

id53 techniques for the world wide web

annotation-based systems
(cid:124) askjeeves
(cid:124) faq finder (u. chicago)
(cid:124) aranea (mit)
(cid:124) ksp (ibm)
(cid:124)    early answering    (u. waterloo)
(cid:124) annotation-based id162

knowledge annotation: other annotation-based systems

98

www.ask.com

askjeeves
(cid:124) lots of manually annotated urls
(cid:124) includes keyword-based matching
(cid:124) licenses certain technologies pioneered by start

alabama
alaska
what is the                               of                    
arizona
   

state bird
state capital
state flower
   

?

knowledge annotation: other annotation-based systems

compare

faq finder u. chicago: [burke et al. 1997]
id53 using lists of frequently asked questions 
(faq) mined from the web: the questions from faq lists can 
be viewed as annotations for the answers

user   s question

list of faqs

choice of faqs

q&a pairs

uses smart [salton 1971] to find potentially 
relevant lists of faq

user manually chooses which faqs to search

system matches user question with faq 
questions and returns q&a pairs

metrics of similarity
    statistical: tf.idf scoring
    semantic: takes into account the length 

of path between words in id138

knowledge annotation: other annotation-based systems

99

aranea mit: [lin, j. et al. 2002]

questions

knowledge
annotation

knowledge

mining

knowledge
boosting

answer
projection

[ answer, docid ]

confidence
ordering

database access schemata

question signature:
when was x born?
what is the birth date of x?
   

database query:
(biography.com x birthdate)

wrapper

wrapper

wrapper

web resources

confidence sorted answers

knowledge annotation: other annotation-based systems

aranea: overview
(cid:124) database access schemata

(cid:122) id157 connect question signatures to 

wrappers

(cid:122) if user question matches question signature, database 

query is executed (via wrappers)

(cid:124) overall performance: trec 2002 (official)

(cid:122) official score: 30.4% correct, cws 0.433
(cid:122) knowledge annotation component contributed 15% of 

the performance (with only six sources)

(cid:124) observations:

(cid:122) high precision, lower recall
(cid:122) failure modes: question signature mismatch, wrapper 

malfunction

knowledge annotation: other annotation-based systems

100

aranea: integration
capitalize on the zipf   s law of question distribution:

handle frequently 
occurring questions 
with knowledge 
annotation

knowledge 
annotation

knowledge 

mining

handle infrequently occurring 
questions with knowledge mining

f
r
e
q
u
e
n
c
y

1

knowledge annotation: other annotation-based systems

rank

ibm: [chu-carroll et al. 2002]

ksp
(cid:124) ksp = knowledge server portal

(cid:122) a    structured knowledge agent    in a multi-agent qa 

architecture: ibm   s entry to trec 2002

(cid:122) composed of a set of knowledge-source adaptors
(cid:122) performance contribution is unclear

(cid:124) supports queries that the question analysis 
component is capable of recognizing, e.g.,
(cid:122)    what is the capital of syria?   
(cid:122)    what is the state bird of alaska?   

(cid:124) sample sources

(cid:122) us geological survey 
(cid:122) www.uselessknowledge.com
(cid:122) id138

knowledge annotation: other annotation-based systems

101

   early answering    u. waterloo: [clarke et al. 2002]
answer specific types of questions using a structured 
database gathered from web sources

sample resources:

table
airports (code, name, location)
rulers (location, period, title)
acronyms
colleges and universities (name, location)
holidays
animal names (baby, male, female, group)

# elements
1,500
25,000
112,000
5,000
171
500

performance: +10-14% in correct answers +16-24% cws

knowledge annotation: other annotation-based systems

id162
(cid:124) annotation-based techniques are commonly used 

for id162
e.g., [flank et al. 1995; smeaton and quigley 1996]
(cid:122) image captions are natural sources of annotations

this viking 1 orbiter image shows clouds to the north of 
valles marineris that look similar to cirrus clouds on earth

knowledge annotation: other annotation-based systems

102

knowledge annotation:
challenges and potential solutions
id53 techniques for the world wide web

four challenges
(cid:124) the knowledge integration problem:

[katz and lin 2002b; katz et al. 2002b]

(cid:122) how can we integrate information from multiple 

sources?

(cid:124) the scaling problem:

(cid:122) annotations are simple and intuitive, but   
(cid:122) there is simply too much data to annotate

(cid:124) the knowledge engineering bottleneck:
(cid:122) only trained individuals can write wrappers
(cid:122)    knowledge engineers    are required to integrate new 

data sources

(cid:124) the fickle web problem:

(cid:122) layout changes, content changes, and   
(cid:122) our wrappers break

knowledge annotation: challenges and potential solutions

103

cross pollination

can research from other fields help tackle 
these challenges?

managing structured and semistructured data is a 
multidisciplinary endeavor:

(cid:122) id53
(cid:122) information retrieval
(cid:122) database systems
(cid:122) digital libraries
(cid:122) knowledge management
(cid:122) wrapper induction (machine learning)

knowledge annotation: challenges and potential solutions

semistructured databases
(cid:124) semistructured databases is an active field of 

research:
(cid:122) ariadne
(cid:122) araneus
(cid:122) disco
(cid:122) garlic
(cid:122) lore
(cid:122) information manifold
(cid:122) tsimmis

usc/isi: [knoblock et al. 2001]

universit   di roma tre: [atzeni et al. 1997]

inria rocquencourt/u. maryland: [tomasic et al. 1996]

ibm: [haas et al. 1997]
stanford: [mchugh et al. 1997]

u. washington: [levy et al. 1996]

stanford: [hammer et al. 1997]

(cid:124) what can we learn from this field?

(cid:122) query planning and efficient implementations thereof
(cid:122) formal models of both structure and content
(cid:122) alterative ways of building wrappers

knowledge annotation: challenges and potential solutions

104

knowledge integration
(cid:124) how can we integrate knowledge from different 

sources?

(cid:124) knowledge integration requires cooperation from 

both language and database systems
(cid:122) language-side: complex queries must be broken down 

into multiple simpler queries

(cid:122) database-side:    join    queries across multiple sources 

must be supported
when was the president of taiwan born?

who is the president of taiwan? + 
when was he born?

(get resource1 

(get resource2    taiwan    president)
birthdate)

knowledge annotation: challenges and potential solutions

integration challenges
(cid:124) name variations must be equated

when was bill clinton born?
when was william jefferson clinton born?
when was mr. clinton born?

how does a system know that these three questions 
are asking for the birth date of the same person?

the omnibase solution:    synonym scripts    proceduralize 
domain knowledge about name variants

(cid:124) name variation problem is exacerbated by 

multiple resources

in resource1: chen shui-bian
in resource2: shui bian, chen

how do we equate 
name variants?

knowledge annotation: challenges and potential solutions

105

two working solutions
(cid:124) ariadne: manual    mapping tables   

[knoblock et al. 2001]

manually specify 
mappings between 
object names from 
different sources

(cid:124) whirl:    soft joins   

[cohen 2000]

(cid:122) treat names as term vectors (with tf.idf weighting)
(cid:122) calculate similarity score from the vectors: 

sim

vu
vv
=),(

vu
vv
   
v
u
v
v
   

knowledge annotation: challenges and potential solutions

complex and brittle wrappers
(cid:124) most wrappers are written in terms of textual 

   landmarks    found in a document, e.g.,
(cid:122) category headings (such as    population:   )
(cid:122) html tags (such as    <b>   </b>   )
(cid:124) disadvantages of this approach:

(cid:122) requires knowledge of the underlying encoding 

language (i.e., html), which is often very complex

(cid:122) wrappers are brittle and may break with minor changes 

in page layout (tags change, different spacing, etc.)

knowledge annotation: challenges and potential solutions

106

lameth
(cid:124)    semantic wrapper    approach: describe relevant 

mit: [katz et al. 1999]

information in terms of content elements, e.g.
(cid:122) tables (e.g., 4th row, 3rd column) 
(cid:122) lists (e.g., 5th bulleted item) 
(cid:122) paragraphs (e.g., 2nd paragraph on the page)

(cid:124) advantages of this approach:

(cid:122) wrappers become more intuitive and easier to write
(cid:122) wrappers become more resistant to minor changes in 

page layout

knowledge annotation: challenges and potential solutions

lameth: example

(get-column 3 (get-row 1 (get-table 5 (get-profile    sun microsystems   ))))

   get the 3rd column from the 1st row of the 5th table in sun   s profile   

write wrappers in terms of content blocks, 
not in terms of the underlying encoding

knowledge annotation: challenges and potential solutions

107

simplifying wrapper creation
(cid:124) manual wrapper creation is time-consuming and 

laborious

(cid:124) how can we simplify and speed up this process?
(cid:124) potential solutions:

(cid:122) gui interfaces
(cid:122) wrapper toolkits
(cid:122) machine learning approaches

knowledge annotation: challenges and potential solutions

nodose
(cid:124) nodose = northwestern document structure 

[adelberg 1998; adelberg and denny 1999]

extractor

(cid:124) a gui for hierarchically composing wrappers

wrappers are 
specified in terms 
of textual markers 
and offsets

includes analyzer 
to detect non-
functional scripts

knowledge annotation: challenges and potential solutions

108

[sahuguet and azavant 1999]

w4f
(cid:124) w4f = wysiwyg web wrapper factory
(cid:124) a wrapper construction gui with point-and-click 

functionality

html document is 
analyzed as a tree

pointing at an element 
automatically calculates 
its    extraction path        an 
xpath-like expression

complex elements in a schema (e.g., regular 
expressions) must be specified manually

knowledge annotation: challenges and potential solutions

wrapper toolkits
(cid:124) isi   s wrapper toolkit

[ashish and knoblock 1997]

(cid:122) system guesses web page structure; user manually 

corrects computer mistakes

(cid:122) extraction parser is generated using lex and yacc

(cid:124) umd   s wrapper toolkit

[gruser et al. 1998]

(cid:122) user must manually specify output schema, input 

attributes, and input-output relations

(cid:122) simple extractors analyze html as a tree and extract 

specific nodes

(cid:124) autowrapper

[gao and sterling 1999]

(cid:122) wrappers are generated automatically using similarity 

heuristics

e.g., tables

(cid:122) approach works only on pages with repeated structure, 

(cid:122) system does not allow human intervention

knowledge annotation: challenges and potential solutions

109

wrapper induction
(cid:124) apply machine learning algorithms to generate 

wrappers automatically

(cid:124) from a set of labeled training examples, induce a 

wrapper that
(cid:122) parses new sample documents
(cid:122) extracts the relevant information

for example:
restaurants review site    

{ (name1, location1, cuisine-type1, rating1,    ),
(name2, location2, cuisine-type2, rating2,    ),
   

}

(cid:124) output of a wrapper is generally a set of tuples

knowledge annotation: challenges and potential solutions

finite state wrapper induction
(cid:124) hlrt approach

[kushmerick et al. 1997; kushmerick 1997]
(cid:122) finds head-left-right-tail delimiters from examples 
and induces a restricted class of finite-state automata

(cid:122) works only on tabular content layout
[hsu 1998; hsu and chang 1999]

(cid:124) softmealy

(cid:122) induces finite-state transducers from examples; single-

pass or multi-pass (hierarchical) variants

(cid:122) works on tabular documents and tagged-list documents
(cid:122) requires very few training examples

knowledge annotation: challenges and potential solutions

110

hierarchical wrapper induction
stalker
ec (embedded catalog) formalism: web documents are 
analyzed as trees where non-terminal nodes are lists of tuples

[muslea et al. 1999]

extraction rules are attached to edges
list iteration rules are attached to list nodes
rules implemented as finite state automata

example: 
r1 = skipto(</b>) 
   ignore everything until a </b> marker   

knowledge annotation: challenges and potential solutions

wrapper induction: issues
(cid:124) machine learning approaches require labeled 

training examples
(cid:122) labeled examples are not reusable in other domains 

and for other applications

(cid:122) what is the time/effort tradeoff between labeling training 

examples and writing wrappers manually?

(cid:124) automatically induced wrappers are more suited 

for    slurping   
(cid:122) wrapper induction is similar in spirit to information 

extraction: both are forms of template filling

(cid:122) all relations are extracted from a page at the same time
(cid:122) less concerned with support services, e.g., dynamically 

generating urls and fetching documents

knowledge annotation: challenges and potential solutions

111

discovering structure
(cid:124) the web contains mostly unstructured 

documents

(cid:124) can we organize unstructured sources for use by 

knowledge annotation techniques?

(cid:124) working solutions: automatically discover 

structured data from free text
(cid:122) dipre
(cid:122) snowball
(cid:122) webkb

knowledge annotation: challenges and potential solutions

extract relations from patterns
(cid:124) duality of patterns and relations

(cid:122) relations can be gathered by applying surface patterns 

over large amounts of text
for example, the relation between name and birthdate 
can be used for id53

(cid:122) surface patterns can be induced from sample relations 

by searching through large amounts of text
for example, starting with the relation    albert einstein    and 
   1879   , a system can induce the pattern    was born in   

(cid:124) what if   

relations     patterns     more relations    
more patterns     more relations    

knowledge annotation: challenges and potential solutions

112

dipre [brin 1998; yi and sundaresan 1999]

dipre = dual iterative pattern id36

small set of seed of tuples

relations like (author, title)
experiment started with five seed tuples

find occurrences of tuples

generate patterns from tuples

search for more tuples using patterns

pattern = <url, prefix, middle, suffix>
four-tuple of id157
overly-general patterns were discarded

knowledge annotation: challenges and potential solutions

dipre: results

example of a learned pattern:

www.sff.net/locus/c.*    <li><b>title</b> by author (

<url,                   prefix,           middle,           suffix>

(cid:124) results: extracted 15,257 (author, title) relations
(cid:124) evaluation: randomly selected 20 books

(cid:122) 19 out of 20 were real books
(cid:122) 5 out of 20 were not found on amazon

(cid:124) control of error propagation is critical

(cid:122) are the relations correct?
(cid:122) are the patterns correct?

bogus relations     bad patterns    
more bogus relations     even more bad patterns    

knowledge annotation: challenges and potential solutions

113

snowball [agichtein et al. 2000]
snowball: several enhancements over dipre

(organization, headquarter)

seed tuples

find occurrences of seed tuples

generate new seed tuples

tag entities

augment table

generate extraction patterns

knowledge annotation: challenges and potential solutions

named-entity detection using 
alembic workbench [day et al. 1997]

snowball: features
(cid:124) pattern: <left, tag1, mid, tag2, right>

(cid:122) left, mid, and right are vectors of term weights

example pattern:
<{<   the   , 0.2>}, location, {<   -   , 0.5>, <   based   , 0.5>}, organization, {}>
right

tag1

tag2

mid

left

example text:

the irving-based exxon corporation     (exxon, irving)

matching patterns with text: take sum of dot products between term vectors

match(tp, ts) =

lp     ls + mp     ms + rp     rs
0                                      otherwise

if tags match

(cid:124) pattern learning: using tuples, find all pattern 
occurrences; cluster left, mid, and right vectors

knowledge annotation: challenges and potential solutions

114

snowball: features
(cid:124) confidence of a pattern is affected by

(cid:122) accuracy of a pattern
(cid:122) number of relations it generates

(cid:124) confidence of a tuple is affected by

(cid:122) confidence of the patterns that generated it
(cid:122) degree of match between relations and patterns

(cid:124)    learning rate    is used to control increase in 

pattern confidence
(cid:122) dampening effect: system trusts new patterns less on 

each iteration

knowledge annotation: challenges and potential solutions

snowball: results

the more often a tuple 
occurs, the more likely it 
will be extracted

dipre has a tendency to 
   blow up    as irrelevant 
results are accumulated 
during each iteration. 
snowball achieves both 
higher precision and recall

snowball: punctuation used
snowball-plain: punctuation ignored
dipre: from [brin 1998]
baseline: frequency of co-occurrence

ground truth = 13k organizations from hoover   s online crossed with 
extracted relations from snowball

knowledge annotation: challenges and potential solutions

115

[craven et al. 1998ab]

webkb
(cid:124) input:

(cid:122) ontology that specifies classes and relations
(cid:122) training examples that represent instances of relevant 

classes and relations

(cid:124) output:

(cid:122) a set of general procedures for extracting new 

instances of classes and relations

knowledge annotation: challenges and potential solutions

webkb: overview

automatically learns extraction rules such as:
members-of-project(a,b) :- research_project(a), person(b), 
link_to(c,a,d), link_to(e,d,b), neighborhood_word_people(c).

translation: person b is a member of project a if there is a 
link from b to a near the keyword    people   

knowledge annotation: challenges and potential solutions

116

webkb: machine learning
(cid:124) learns extraction rules using foil

foil = a greedy covering algorithm for learning function 
free horn clauses [quinlan and cameron-jones 1993]

(cid:124) background relations used as    features   , e.g.,

(cid:122) has_word: boolean predicate that indicates the 

presence of a word on a page

(cid:122) link_to: represents a hyperlink between two pages
(cid:122) length: the length of a particular field
(cid:122) position: the position of a particular field

(cid:124) experimental results

(cid:122) extracting relations from a cs department web site 

(e.g., student, faculty, project, course)
(cid:122) typical performance: 70-80% accuracy

knowledge annotation: challenges and potential solutions

extracting relations: issues
(cid:124) how useful are these techniques?
(cid:124) can we extract relations that we don   t already 

have lists for?
{author, title}: amazon.com or the library of congress already 
possess comprehensive book catalogs

{organization, headquarter}: sites like yahoo! finance contains such 
information in a convenient form

(cid:124) can we extract relations that have hierarchical 

structure? it is an open research question

knowledge annotation: challenges and potential solutions

117

from www to sw
(cid:124) the world wide web is a great collection of 

knowledge   

(cid:124) but it was created by and for humans
(cid:124) how can we build a    web of knowledge    that can 

be easily understood by computers?

(cid:124) this is the semantic web effort   

[berners-lee 1999; berners-lee et al. 2001]

knowledge annotation: challenges and potential solutions

what is the semantic web?
(cid:124) make web content machine-understandable
(cid:124) enable agents to provide various services (one 

of which is information access)

   arrange my trip to eacl.   
    my personal travel agent knows that arranging conference trips 

involves booking the flight, registering for the conference, and
reserving a hotel room.

    my travel agent talks to my calendar agent to find out when and 

where eacl is taking place. it also checks my appointments 
around the conference date to ensure that i have no conflicts.

    my travel agent talks to the airline reservation agent to arrange 
a flight. this requires a few (automatic) iterations because i have 
specific preferences in terms of price and convenience. for 
example, my travel agent knows that i like window seats, and 
makes sure i get one.

       

knowledge annotation: challenges and potential solutions

118

components of semantic web
(cid:124) syntactic standardization (xml)
(cid:124) semantic standardization (rdf)
(cid:124) service layers
(cid:124) software agents

knowledge annotation: challenges and potential solutions

syntactic standardization
(cid:124) make data machine-readable
(cid:124) xml is an interchange format
(cid:124) xml infrastructure exists already:

(cid:122) parsers freely available
(cid:122) xml databases
(cid:122) xml-based rpc (soap)

(cid:124) broad industry support and adoption

in our fictional    arrange trip to eacl scenario   , xml 
allows our software agents to exchange information in a 
standardized format

knowledge annotation: challenges and potential solutions

119

semantic standardization
(cid:124) make data machine-understandable
(cid:124) rdf (resource description framework)

(cid:122) portable encoding of a general semantic network
(cid:122) triples model (subject-relation-object)
(cid:122) labeled directed graph
(cid:122) xml-based encoding

(cid:124) sharing of ontologies, e.g., dublin core
(cid:124) grassroots efforts to standardize ontologies
in our fictional    arrange trip to eacl scenario   , rdf 
encodes ontologies that inform our software agents 
about the various properties of conferences (e.g., dates, 
locations, etc.), flights (e.g., origin, destination,  arrival 
time, departure time, etc.), and other entities.

knowledge annotation: challenges and potential solutions

service layers and agents
(cid:124) service layers: utilize xml and rdf as 

foundations for id136, trust, proof layer, etc.
(cid:122) important considerations: reasoning about uncertainty, 

reasoning with contradicting/conflicting information

in our fictional    arrange trip to eacl scenario   , the 
service layers allow us to purchase tickets, reserve 
hotel rooms, arrange shuttle pick-up, etc.

(cid:124) software agents: help users locate, compare, 

cross-reference content
(cid:122) in the semantic web vision, communities of cooperative 

agents will interact on behalf of the user

in our fictional    arrange trip to eacl scenario   , the 
software agents ultimately do our bidding

120

semantic web: what   s missing?
(cid:124) where in the loop is the human?
(cid:124) how will we communicate with our software 

agents?

(cid:124) how will we access information on the semantic 

web?
obviously, we cannot expect ordinary semantic web users to 
manually manipulate ontologies, query with formal logic 
expressions, etc.
we would like to  communicate with software agents in natural 
language   

what is the role of natural language in the 
semantic web?

knowledge annotation: challenges and potential solutions

rdf + nl annotations

[katz and lin 2002a; katz et al. 2002c; karger et al. 2003]

+

in 1492,
columbus sailed 
the ocean blue.

an object at 
rest tends to 
remain at rest.

four score and 
seven years ago 
our forefathers 
brought forth

the semantic web

annotate rdf as if it were any other type of content 
segment, i.e., describe rdf fragments with natural language 
sentences and phrases

knowledge annotation: challenges and potential solutions

121

nl and the semantic web
(cid:124) natural language should be an integral 

component of the semantic web

(cid:124) general strategy:

(cid:122) weave natural language annotations directly into the 

rdf (resource description framework)

(cid:122) annotate rdf ontology fragments with natural 

language annotations
in effect, we want to create    sticky notes    for the 
semantic web

[karger et al. 2003]

(cid:124) prototype: start-haystack collaboration

haystack: a semantic web platform

[huynh et al. 2002]

+ start: a id53 system
= a id53 system for the semantic web

knowledge annotation: challenges and potential solutions

knowledge annotation:
conclusion

id53 techniques for the world wide web

122

summary
(cid:124) structured and semistructured web resources 
can be organized to answer natural language 
questions

(cid:124) linguistically-sophisticated techniques for 

connecting questions with resources permit high 
precision id53

(cid:124) knowledge annotation brings together many 

related fields of research, most notably nlp and 
database systems

(cid:124) future research focuses on discovery and 

management of semistructured resources, and 
the semantic web

knowledge annotation: conclusion

the future

knowledge 
annotation

database concepts

easier management 
of existing resources

automatic discovery 
of new resources

the semantic web

knowledge annotation: conclusion

123

conclusion

id53 techniques for the world wide web

the future of web qa
(cid:124) two dimensions for organizing web-based 

id53 strategies
(cid:122) nature of the information
(cid:122) nature of the technique

(cid:124) the web-based id53 system of 

the future   
(cid:122) will be able to utilize the entire spectrum of available 

information from free text to highly structured databases

(cid:122) will be able to seaid113ssly integrate robust, simple 

techniques with highly accurate linguistically-
sophisticated ones

qa techniques for the www: conclusion

124

the future of web qa

linguistically
sophisticated

structured 
knowledge

id53 
techniques for the 
world wide web

unstructured 
knowledge

qa techniques for the www: conclusion

linguistically
uninformed

acknowledgements
(cid:124) we would like to thank aaron fernandes, vineet 

sinha, stefanie tellex, and olzem uzuner for 
their comments on earlier drafts of these slides. 
all remaining errors are, of course, our own.

125

references
steven abney, michael collins, and amit singhal. 2000. answer extraction. in proceedings of the sixth applied

natural language processing conference (anlp-2000).

steven p. abney. 1996. partial parsing via    nite-state cascades. journal of natural language engineering,

2(4):337   344.

brad adelberg. 1998. nodose   a tool for semi-automatically extracting structured and semistructured data from

text documents. sigmod record, 27:283   294.

brad adelbery and matt denny. 1999. building robust wrappers for text sources. technical report, northwestern

university.

eugene agichtein and luis gravano. 2000. snowball: extracting relations from large plain-text collections. in

proceedings of the 5th acm international conference on digital libraries (dl   00).

eugene agichtein, steve lawrence, and luis gravano. 2001. learning search engine speci   c query transforma-
tions for id53. in proceedings of the tenth international world wide web conference (www10).

diego moll  a aliod, jawad berri, and michael hess. 1998. a real world implementation of answer extraction. in
proceedings of 9th international conference on database and id109, natural language and informa-
tion systems workshop (nlis   98).

arne andersson, n. jesper larsson, and kurt swanson. 1999. suf   x trees on words. algorithmica, 23(3):246   

260.

evan l. antworth. 1990. pc-kimmo: a two-level processor for morphological analysis. occasional publica-

tions in academic computing 16, summer institute of linguistics, dallas, texas.

naveen ashish and craig knoblock. 1997. wrapper generation for semi-structured internet sources. in proceed-

ings of the workshop on management of semistructured data at pods/sigmod   97.

paolo atzeni, giansalvatore mecca, and paolo merialdo. 1997. to weave the web. in proceedings of the 23rd

international conference on very large databases (vldb 1997).

michele banko and eric brill. 2001. scaling to very very large corpora for natural language disambiguation. in

proceedings of the 39th annual meeting of the association for computational linguistics (acl-2001).

michele banko, eric brill, susan dumais, and jimmy lin. 2002. askmsr: id53 using the world
wide web. in proceedings of 2002 aaai spring symposium on mining answers from texts and knowledge
bases.

adam berger and john lafferty. 1999. information retrieval as statistical translation. in proceedings of the 22nd
annual international acm sigir conference on research and development in information retrieval (sigir-
1999).

tim berners-lee, james hendler, and ora lassila. 2001. the semantic web. scienti   c american, 284(5):34   43.

tim berners-lee. 1999. weaving the web. harper, new york.

douglas biber. 1986. spoken and written textual dimensions in english: resolving the contradictory    ndings.

language, 62(2):384   413.

eric breck, marc light, gideon s. mann, ellen riloff, brianne brown, pranav anand, mats rooth, and michael
thelen. 2001. looking under the hood: tools for diagnosing your id53 engine. in proceedings
of the 39th annual meeting of the association for computational linguistics (acl-2001) workshop on open-
domain id53.

eric brill, jimmy lin, michele banko, susan dumais, and andrew ng. 2001. data-intensive id53.

in proceedings of the tenth text retrieval conference (trec 2001).

eric brill, susan dumais, and michele banko. 2002. an analysis of the askmsr question-answering system. in

proceedings of the 2002 conference on empirical methods in natural language processing (emnlp 2002).

sergey brin and lawrence page. 1998. the anatomy of a large-scale hypertextual web search engine. in pro-

ceedings of the sixth international world wide web conference (www6).

sergey brin. 1998. extracting patterns and relations from the world wide web. in proceedings of the webdb

workshop   international workshop on the web and databases, at edbt    98.

peter f. brown, john cocke, stephen della pietra, vincent j. della pietra, frederick jelinek, john d. lafferty,
robert l. mercer, and paul s. roossin. 1990. a statistical approach to machine translation. computational
linguistics, 16(2):79   85.

sabine buchholz. 2001. using grammatical relations, answer frequencies and the world wide web for question

answering. in proceedings of the tenth text retrieval conference (trec 2001).

chris buckley and a. f. lewit. 1985. optimization of inverted vector searches. in proceedings of the 8th annual

international acm sigir conference on research and development in information retrieval (sigir-1985).

robin d. burke, kristian j. hammond, vladimir a. kulyukin, steven l. lytinen, noriko tomuro, and scott
schoenberg. 1997. id53 from frequently-asked question    les: experiences with the faq finder
system. technical report tr-97-05, university of chicago.

eugene charniak. 1999. a maximum-id178-inspired parser. technical report cs-99-12, brown university,

computer science department.

jennifer chu-carroll, john prager, christopher welty, krzysztof czuba, and david ferrucci. 2002. a multi-
strategy and multi-source approach to id53. in proceedings of the eleventh text retrieval con-
ference (trec 2002).

charles clarke, gordon cormack, and thomas lynam. 2001a. exploiting redundancy in id53.
in proceedings of the 24th annual international acm sigir conference on research and development in
information retrieval (sigir-2001).

charles clarke, gordon cormack, thomas lynam, c.m. li, and greg mclearn. 2001b. web reinforced question
answering (multitext experiments for trec 2001). in proceedings of the tenth text retrieval conference
(trec 2001).

charles clarke, gordon cormack, graeme kemkes, michael laszlo, thomas lynam, egidio terra, and philip
tilker. 2002. statistical selection of exact answers (multitext experiments for trec 2002). in proceedings of
the eleventh text retrieval conference (trec 2002).

william cohen. 2000. whirl: a word-based information representation language. arti   cial intelligence, 118(1   

2):163   196.

mark craven, dan dipasquo, dayne freitag, andrew mccallum, tom mitchell, kamal nigam, and sean slattery.
1998a. automatically deriving structured knowledge bases from on-line dictionaries. technical report cmu-
cs-98-122, carnegie mellon university.

mark craven, dan dipasquo, dayne freitag, andrew mccallum, tom mitchell, kamal nigam, and sean slattery.
1998b. learning to extract symbolic knowledge from the world wide web. in proceedings of the fifteenth
national conference on arti   cial intelligence (aaai-1998).

david day, john aberdeen, lynette hirschman, robyn kozierok, patricia robinson, and marc vilain. 1997.
mixed-initiative development of language processing systems. in proceedings of the fifth acl conference on
applied natural language processing (anlp-1997).

susan dumais, michele banko, eric brill, jimmy lin, and andrew ng. 2002. web id53: is more
in proceedings of the 25th annual international acm sigir conference on research and

always better?
development in information retrieval (sigir-2002).

sharon flank, david gar   eld, and deborah norkin. 1995. digital image libraries: an innovating method for
storage, retrieval, and selling of color images. in proceedings of the first international symposium on voice,
video, and data communications of the society of photo-optical instrumentation engineers (spie).

xiaoying gao and leon sterling. 1999. autowrapper: automatic wrapper generation for multiple online services.

in proceedings of asia paci   c web conference 1999 (apweb99).

bert green, alice wolf, carol chomsky, and kenneth laughery. 1961. baseball: an automatic question

answerer. in proceedings of the western joint computer conference.

jean-robert gruser, louiqa raschid, mar  ia esther vidal, and laura bright. 1998. wrapper generation for web
accessible data sources. in proceedings of the 3rd ifcis international conference on cooperative information
systems (coopis 1998).

dan gus   eld. 1997. linear time construction of suf   x trees. in algorithms on strings, trees and sequences:

computer science and computational biology. university of cambridge.

laura m. haas, donald kossmann, edward l. wimmers, and jun yang. 1997. optimizing queries across diverse

data sources. in proceedings of 23rd international conference on very large data bases (vldb 1997).

joachim hammer, jason mchugh, and hector garcia-molina. 1997. semistructured data: the tsimmis ex-
perience. in proceedings of the first east-european symposium on advances in databases and information
systems (adbis   97).

sanda harabagiu and dan moldovan. 2001. open-domain textual id53: tutorial given at naacl-

2001.

sanda harabagiu and dan moldovan. 2002. open-domain textual id53: tutorial given at coling-

2002.

sanda harabagiu, dan moldovan, marius pas  ca, rada mihalcea, mihai surdeanu, r  azvan bunescu, roxana g   irju,
vasile rus, and paul mor  arescu. 2000a. falcon: boosting knowledge for answer engines. in proceedings of
the ninth text retrieval conference (trec-9).

sanda harabagiu, marius pas  ca, and steven maiorano. 2000b. experiments with open-domain textual question
answering. in proceedings of the 18th international conference on computational linguistics (coling-2000).

gary g. hendrix. 1977a. human engineering for applied natural language processing. technical note 139, sri

international.

gary g. hendrix. 1977b. human engineering for applied natural language processing. in proceedings of the fifth

international joint conference on arti   cial intelligence (ijcai-77).

ulf hermjakob, abdessamad echihabi, and daniel marcu. 2002. natural language based reformulation resource
and web exploitation for id53. in proceedings of the eleventh text retrieval conference (trec
2002).

lynette hirschman and robert gaizauskas. 2001. natural language id53: the view from here.

journal of natural language engineering, special issue on id53, fall   winter.

eduard hovy, laurie gerber, ulf hermjakob, chin-yew lin, and deepak ravichandran. 2001a. towards
semantics-based answer pinpointing. in proceedings of the first international conference on human language
technology research (hlt 2001).

eduard hovy, ulf hermjakob, and chin-yew lin. 2001b. the use of external knowledge in factoid qa.

proceedings of the tenth text retrieval conference (trec 2001).

in

eduard hovy, ulf hermjakob, chin-yew lin, and deepak ravichandran. 2002. using knowledge to facilitate
factoid answer pinpointing. in proceedings of the 19th international conference on computational linguistics
(coling-2002).

chun-nan hsu and chien-chi chang. 1999. finite-state transducers for semi-structured id111. in proceed-

ings of the ijcai-99 workshop on id111: foundations, techniques, and applications.

chun-nan hsu. 1998.

initial results on wrapping semistructured web pages with    nite-state transducers and

contextual rules. in proceedings of aaai-1998 workshop on ai and information integration.

david huynh, david karger, and dennis quan. 2002. haystack: a platform for creating, organizing and vi-
sualizing information using rdf. in proceedings of the eleventh world wide web conference semantic web
workshop.

frederick jelinek. 1997. statistical methods for id103. mit press, cambridge, massachusetts.

hideo joho and mark sanderson. 2000. retrieving descriptive phrase from large amounts of free text. in pro-

ceedings of the ninth international conference on information and knowledge management (cikm 2000).

david karger, boris katz, jimmy lin, and dennis quan. 2003. sticky notes for the semantic web. in proceedings

of the 2003 international conference on intelligent user interfaces (iui 2003).

boris katz and beth levin. 1988. exploiting lexical regularities in designing natural language systems.

proceedings of the 12th international conference on computational linguistics (coling-1988).

in

boris katz and jimmy lin. 2002a. annotating the semantic web using natural language. in proceedings of the

2nd workshop on nlp and xml at coling-2002.

boris katz and jimmy lin. 2002b. start and beyond. in proceedings of 6th world multiconference on systemics,

cybernetics, and informatics (sci 2002).

boris katz and jimmy lin. 2003. selectively using relations to improve precision in id53. in

proceedings of the eacl-2003 workshop on natural language processing for id53.

boris katz, deniz yuret, jimmy lin, sue felshin, rebecca schulman, adnan ilik, ali ibrahim, and philip osafo-
kwaako. 1999. integrating large lexicons and web resources into a natural language query systen. in proceed-
ings of the international conference on multimedia computing and systems (ieee icmcs    99).

boris katz, sue felshin, deniz yuret, ali ibrahim, jimmy lin, gregory marton, alton jerome mcfarland, and
baris temelkuran. 2002a. omnibase: uniform access to heterogeneous data for id53.
in
proceedings of the 7th international workshop on applications of natural language to information systems
(nldb 2002).

boris katz, jimmy lin, and sue felshin. 2002b. the start multimedia information system: current technology
and future directions. in proceedings of the international workshop on multimedia information systems (mis
2002).

boris katz, jimmy lin, and dennis quan. 2002c. natural language annotations for the semantic web.

in
proceedings of the international conference on ontologies, databases, and application of semantics (odbase
2002).

boris katz. 1988. using english for indexing and retrieving. in proceedings of the 1st riao conference on

user-oriented content-based text and image handling (riao    88).

boris katz. 1990. using english for indexing and retrieving. in patrick henry winston and sarah alexandra

shellard, editors, arti   cial intelligence at mit: expanding frontiers, volume 1. mit press.

boris katz. 1997. annotating the world wide web using natural language. in proceedings of the 5th riao

conference on computer assisted information searching on the internet (riao    97).

brett kessler, geoffrey nunberg, and hinrich sch  utze. 1997. automatic detection of text genre. in proceedings of
the 35th annual meeting of the association for computational linguistics and 8th conference of the european
chapter of the association for computational linguistics (acl/eacl-1997).

craig knoblock, steven minton, jose luis ambite, naveen ashish, ion muslea, andrew philpot, and sheila
tejada. 2001. the ariadne approach to web-based information integration. international journal on coop-
erative information systems (ijcis) special issue on intelligent information agents: theory and applications,
10(1/2):145   169.

nickolas kushmerick, daniel weld, and robert doorenbos. 1997. wrapper induction for information extraction.

in proceedings of the fifteenth international joint conference on arti   cial intelligence (ijcai-97).

nickolas kushmerick. 1997. wrapper induction for information extraction. ph.d. thesis, department of com-

puter science, university of washington.

cody kwok, oren etzioni, and daniel s. weld. 2001. scaling id53 to the web. in proceedings of

the tenth international world wide web conference (www10).

steve lawrence and c. lee giles. 1998. context and page analysis for improved web search. ieee internet

computing, 2(4):38   46.

wendy g. lehnert. 1977. a conceptual theory of id53. in proceedings of the fifth international

joint conference on arti   cial intelligence (ijcai-77).

wendy g. lehnert. 1981. a computational theory of human id53. in aravind k. joshi, bonnie l.
webber, and ivan a. sag, editors, elements of discourse understanding, pages 145   176. cambridge university
press, cambridge, england.

alon y. levy, anand rajaraman, and joann j. ordille. 1996. querying heterogeneous information sources using
source descriptions. in proceedings of 22nd international conference on very large data bases (vldb 1996).

marc light, gideon s. mann, ellen riloff, and eric breck. 2001. analyses for elucidating current question
answering technology. journal of natural language engineering, special issue on id53, fall   
winter.

dekang lin and patrick pantel. 2001a. dirt   discovery of id136 rules from text. in proceedings of the acm

sigkdd conference on knowledge discovery and data mining.

dekang lin and patrick pantel. 2001b. discovery of id136 rules for id53. journal of natural

language engineering, special issue on id53, fall   winter.

jimmy lin, aaron fernandes, boris katz, gregory marton, and stefanie tellex. 2002. extracting answers from
the web using knowledge annotation and knowledge mining techniques. in proceedings of the eleventh text
retrieval conference (trec 2002).

jimmy lin, dennis quan, vineet sinha, karun bakshi, david huynh, boris katz, and david r. karger. 2003.
the role of context in id53 systems. in proceedings of the 2003 conference on human factors
in computing systems (chi 2003).

jimmy lin. 2001.

indexing and retrieving natural language using ternary expressions. master   s thesis, mas-

sachusetts institute of technology.

chin-yew lin. 2002a. the effectiveness of dictionary and web-based answer reranking. in proceedings of the

19th international conference on computational linguistics (coling-2002).

jimmy lin. 2002b. the web as a resource for id53: perspectives and challenges. in proceedings

of the third international conference on language resources and evaluation (lrec-2002).

john b. lowe. 2000. what   s in store for id53? (invited talk). in proceedings of the joint sigdat
conference on empirical methods in natural language processing and very large corpora (emnlp/vlc-
2000).

bernardo magnini and roberto prevete. 2000. exploiting lexical expansions and boolean compositions for web

querying. in proceedings of the acl-2000 workshop on recent advances in nlp and ir.

bernardo magnini, matteo negri, roberto prevete, and hristo tanev. 2001. multilingual id53: the

diogene system. in proceedings of the tenth text retrieval conference (trec 2001).

bernardo magnini, matteo negri, roberto prevete, and hristo tanev. 2002a. is it the right answer? exploiting
in proceedings of the 40th annual meeting of the association for

web redundancy for answer validation.
computational linguistics (acl-2002).

bernardo magnini, matteo negri, roberto prevete, and hristo tanev. 2002b. mining knowledge from repeated
co-occurrences: diogene at trec 2002. in proceedings of the eleventh text retrieval conference (trec
2002).

bernardo magnini, matteo negri, roberto prevete, and hristo tanev. 2002c. towards automatic evaluation of
question/answering systems. in proceedings of the third international conference on language resources
and evaluation (lrec-2002).

gideon mann. 2001. a statistical method for short answer extraction. in proceedings of the 39th annual meeting
of the association for computational linguistics (acl-2001) workshop on open-domain id53.

gideon mann. 2002. learning how to answer question using trivia games. in proceedings of the 19th interna-

tional conference on computational linguistics (coling-2002).

jason mchugh, serge abiteboul, roy goldman, dallan quass, and jennifer widom. 1997. lore: a database
management system for semistructured data. technical report, stanford university database group, february.

mandar mitra, amit singhal, and chris buckley. 1998. improving automatic id183. in proceedings of
the 21st annual international acm sigir conference on research and development in information retrieval
(sigir-1998).

dan moldovan, sanda harabagiu, roxana g  irju, paul mor  arescu, finley lacatusu, adrian novischi, adriana
badulescu, and orest bolohan. 2002. lcc tools for id53. in proceedings of the eleventh text
retrieval conference (trec 2002).

ion muslea, steve minton, and craig knoblock. 1999. a hierarchical approach to wrapper induction. in proceed-

ings of the 3rd international conference on autonomous agents.

john prager, dragomir radev, eric brown, anni coden, and valerie samn. 1999. the use of predictive annotation

for id53 in trec8. in proceedings of the eighth text retrieval conference (trec-8).

hong qi, jahna otterbacher, adam winkel, and dragomir r. radev. 2002. the university of michigan at
trec2002: id53 and novelty tracks. in proceedings of the eleventh text retrieval conference
(trec 2002).

j. ross quinlan and r. mike cameron-jones. 1993. foil: a midterm report. in proceedings of the 12th european

conference on machine learning.

dragomir radev, hong qi, zhiping zheng, sasha blair-goldensohn, zhu zhang, waiguo fan, and john prager.
2001. mining the web for answers to natural language questions. in proceedings of the tenth international
conference on information and knowledge management (cikm 2001).

dragomir radev, weiguo fan, hong qi, harris wu, and amardeep grewal. 2002. probabilistic question answer-

ing on the web. in proceedings of the eleventh international world wide web conference (www2002).

deepak ravichandran and eduard hovy. 2002. learning surface text patterns for a id53 system. in

proceedings of the 40th annual meeting of the association for computational linguistics (acl-2002).

steven e. robertson and steve walker. 1997. on relevance weights with little relevance information. in proceed-
ings of the 20th annual international acm sigir conference on research and development in information
retrieval (sigir-1997).

stephen e. robertson, steve walker, and micheline hancock-beaulieu. 1998. okapi at trec-7: automatic ad

hoc,    ltering, vlc and interactive. in proceedings of the 7th text retrieval conference (trec-7).

arnaud sahuguet and fabien azavant. 1999. wysiwyg web wrapper factory (w4f). in proceedings of the

eighth international world wide web conference (www8).

gerard salton. 1971. the smart retrieval system   experiments in automatic document processing. prentice-

hall, englewood cliffs, new jersey.

daniel sleator and davy temperly. 1991. parsing english with a link grammar. technical report cmu-cs-91-

196, carnegie mellon university, department of computer science.

daniel sleator and davy temperly. 1993. parsing english with a link grammar. in proceedings of the third

international workshop on parsing technology.

alan f. smeaton and ian qigley. 1996. experiments on using semantic distances between words in image caption
retrieval. in proceedings of the 19th annual international acm sigir conference on research and develop-
ment in information retrieval (sigir-1996).

martin m. soubbotin and sergei m. soubbotin. 2001. patterns of potential answer expressions as clues to the right

answers. in proceedings of the tenth text retrieval conference (trec 2001).

martin m. soubbotin and sergi m. soubbotin. 2002. use of patterns for detection of likely answer strings: a

systematic approach. in proceedings of the eleventh text retrieval conference (trec 2002).

rohini srihari and wei li. 1999. information extraction supported id53. in proceedings of the

eighth text retrieval conference (trec-8).

gerald j. sussman. 1973. a computational model of skill acquisition. technical report 297, mit arti   cial

intelligence laboratory.

anthony tomasic, louiqa raschid, and patrick valduriez. 1996. scaling heterogeneous distributed databases and

the design of disco. in proceedings of the 16th international conference on distributed computing systems.

ellen m. voorhees and dawn m. tice. 1999. the trec-8 id53 track evaluation. in proceedings

of the eighth text retrieval conference (trec-8).

ellen m. voorhees and dawn m. tice. 2000a. overview of the trec-9 id53 track. in proceedings

of the ninth text retrieval conference (trec-9).

ellen m. voorhees and dawn m. tice. 2000b. the trec-8 id53 track evaluation. in proceedings

of the 2nd international conference on language resources and evaluation (lrec-2000).

ellen m. voorhees. 1994. id183 using lexical-semantics relations. in proceedings of the 17th annual

international acm sigir conference on research and development in information retrieval (sigir-1994).

ellen m. voorhees. 2001. overview of the trec 2001 id53 track. in proceedings of the tenth text

retrieval conference (trec 2001).

ellen m. voorhees. 2002a. the evaluation of id53 systems: lessons learned from the trec qa

track. in proceedings of the id53: strategy and resources workshop at lrec-2002.

ellen m. voorhees. 2002b. overview of the trec 2002 id53 track. in proceedings of the eleventh

text retrieval conference (trec 2002).

david l. waltz. 1973. understanding line drawings of scenes with shadows.

psychology of id161. mit press, cambridge, massachusetts.

in patrick h. winston, editor,

robert wilensky, david ngi chin, marc luria, james h. martin, james may   eld, and dekai wu. 1989. the
berkeley unix consultant project. technical report csd-89-520, computer science division, the university
of california at berkeley.

robert wilensky. 1982. talking to unix in english: an overview of an on-line unix consultant. technical

report csd-82-104, computer science division, the university of california at berkeley.

terry winograd. 1972. understanding natural language. academic press, new york, new york.

patrick h. winston, boris katz, thomas o. binford, and michael r. lowry. 1983. learning physical descriptions
from functional de   nitions, examples, and precedents. in proceedings of the third national conference on
arti   cial intelligence (aaai-1983).

patrick h. winston. 1975. learning structural descriptions from examples. in patrick h. winston, editor, the

psychology of id161. mcgraw-hill book company, new york, new york.

william a. woods, ronald m. kaplan, and bonnie l. nash-webber. 1972. the lunar sciences natural lanaugage

information system: final report. technical report 2378, bbn.

jinxi xu and w. bruce croft. 2000.

improving the effectiveness of information retrieval with local context

analysis. acm transactions on information systems, 18(1):79   112.

jinxi xu, ana licuanan, jonathan may, scott miller, and ralph weischedel. 2002. trec2002 qa at bbn:
answer selection and con   dence estimation. in proceedings of the eleventh text retrieval conference (trec
2002).

hui yang and tat-seng chua. 2002. the integration of lexical knowledge and external resources for question

answering. in proceedings of the eleventh text retrieval conference (trec 2002).

jeonghee yi and neel sundaresan. 1999. mining the web for acronyms using the duality of patterns and relations.

in proceedings of the 1999 workshop on web information and data management.

r  emi zajac. 2001. towards ontological id53. in proceedings of the 39th annual meeting of the

association for computational linguistics (acl-2001) workshop on open-domain id53.

dell zhang and wee sun lee. 2002. web based pattern mining and matching approach to id53. in

proceedings of the eleventh text retrieval conference (trec 2002).

zhiping zheng. 2002a. answerbus id53 system. in proceeding of 2002 human language tech-

nology conference (hlt 2002).

zhiping zheng. 2002b. developing a web-based id53 system.

international world wide web conference (www2002).

in proceedings of the eleventh

