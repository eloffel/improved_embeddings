rich prior knowledge in 

learning for nlp

gregory druck, kuzman ganchev, jo  o gra  a

why incorporate prior knowledge?

have: unlabeled data

option: hire

linguist

annotators

why incorporate prior knowledge?

have: unlabeled data

option: hire

this approach does not 
scale to every task and 
domain of interest.

however, we already 
know a lot about most 
problems of interest.

linguist

annotators

example: document classi   cation 

documents

labels

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

    prior knowledge: 

    labeled features: information about the label 

distribution when word w is present

sentiment polarity
positive
memorable

negative

perfect
exciting

terrible
boring
mess

newsgroups classi   cation

baseball

hit

braves
runs

mac
apple

macintosh
powerbook

politics
senate
taxes
liberal

...
...
...
...

example: information extraction

extraction from 
research papers:

w. h. enright. improving the ef   ciency of matrix operations 
in the numerical solution of stiff ordinary differential 
equations. acm trans. math. softw., 4(2), 127-136, june 1978.

    prior knowledge: 
    labeled features: 

    the word acm should be labeled either journal or 

booktitle most of the time

    non-markov (long-range) dependencies:

    each reference has at most one segment of each type

example: part-of-speech induction

tags

text

a career with the european 
institutions must become more 
attractive. too many young, new...

    prior knowledge: 

    linguistic knowledge: each sentence should have a verb
    posterior sparsity: the total number of different pos tags 

assigned to each word type should be small

example: dependency grammar induction

    prior knowledge: 

    linguistic rules: nouns are usually dependents of verbs
    noisy labeled data: target language parses should be 

similar to aligned parses in a resource-rich source language 

example: word alignment

a career with the european institutions must become more attractive. 

uma carreira nas institui    es europeias t  m de se tornar mais atractiva. 

    prior knowledge: 

    bijectivity: alignment should be mostly one-to-one
    symmetry: source   target and target   source 

alignments should agree

this tutorial

in general, how can we leverage such knowledge 

and an unannotated corpus during learning?

notation & models

input variables (documents, sentences):

structured output variables (parses, sequences):

unstructured output variables (labels):

input / output variables for entire corpus: 

probabilistic model parameters:

generative models:

discriminative models:

model feature function:  

x
y
y

x y

  

p  (x, y)
p  (y|x)
f (x, y)

learning scenarios

    unsupervised: 

    unlabeled data + prior knowledge

    lightly supervised: 

    unlabeled data +    informative    prior knowledge
    i.e. provides speci   c information about labels 

    semi-supervised: 

    labeled data + unlabeled data + prior knowledge

running example #1:

document classi   cation

    model: maximum id178 classi   er (id28) 

1

z(x)

p  (y|x) =

exp(      f (x, y))
    setting: lightly supervised; no labeled data
    prior knowledge: 

    labeled features: information about the label 

distribution when word w is present

    label is often hockey or baseball when game is present

running example #2:

word alignment

    model:    rst-order hidden markov model (id48)
p  (yi|yi   1)p  (xi|yi)

p  (y, x) = p  (y0)

n   i=1

1

0
sabemos       el       camino      null

2

3

1

1

2

3

we

know

the

way

    setting: unsupervised
    prior knowledge: 

    bijectivity: alignment should be mostly one-to-one

problem

model
y1

y2

x1

x2

y3

x3

+

data

output

(cid:15482)

jugaban

de

una

manera

animada

y

muy

cordial

it

was

an

animated

,

very

convivial

game

this output does not agree with prior knowledge!

    six target words align to source word animada
       ve source words do not align with any target word 

limited approach: labeling data

approach: convert prior knowledge to labeled data.

prior 

knowledge

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

prototypes (+ cluster features):    

     [haghighi & klein 06]

others: 

    [raghavan & allan 07]                                      
    [schapire et al. 02]

limitation: often unclear how to do conversion
    example #1: often (not always) game     {hockey,baseball} 
    example #2: alignment should be mostly one-to-one

limited approach: bayesian approach

approach: encode prior knowledge with a prior on parameters.

specifying 

p(  )

  

y1

x1

  

y2

x2

y3

x3

natural:       should be small (or sparse)   

  
[johnson 07], among many others
possible:        should be close to      
    i

  i

( informative prior )

[dayanik et al. 06]

limitation: our prior knowledge is not about parameters! 
parameters are dif   cult to interpret; hard to get desired effect.
    example #1: often (not always) game     {hockey,baseball}
    example #2: alignment should be mostly one-to-one

limited approach: augmenting model

approach: encode prior knowledge with 
additional variables and dependencies.

y1

z1

y2

y3

x3

x1

x2
limitation: can be dif   cult to get desired effect
    example #1: often (not always) game     {hockey,baseball}
limitation: may make exact id136 intractable
    example #2: bijectivity makes id136 #p-complete

this tutorial

develop:
    a language for directly encoding prior knowledge
    methods for learning with knowledge in this language
    ( approximations to modeling this language directly )

    (loosely) these methods perform mappings for us: 
    encoded prior knowledge            parameters
  
    encoded prior knowledge            labeling 

----- -- -- 
--- ---- 
--- --- --- 

--- --- 

      

--- --- 

----- -- -- 
--- ---- 
--- --- --- 

--- --- 

----- -- -- 
--- ---- 
--- --- --- 

a language for encoding prior knowledge

our prior knowledge is about distributions over latent 
output variables. (output variables are interpretable)

speci   cally, we know some properties of this distribution:
    example #1: often (not always) game   {hockey,baseball}

formulation: know about the expectations of some 
functions under distribution over latent output variables

constraint features

    constraint feature function: 
    example #1: 

  w(x, y) = 1(y = l)1(w     x)

  (x, y)

    for document x, returns a vector with a 1 in the lth 

position if y is the lth label and the word w is in x

    example #2: 

  (x, y) =

1(yi = m)

    returns a vector with mth value = number of target 
words in sentence x that align with source word m

n   i=1

expectations of constraint features

    example #1:  corpus expectation: 

ep   [  (x, y)] =
    vector with expected distribution over labels for 
documents that contain w (     is the count of w)

p  (y|x)  w(x, y)

cw

1

cw   x    y

    example #2:  per-example expectation: 
ep   [  (x, y)] =   y
    vector with mth value = expected number of target 

p  (y|x)  (x, y)

words that align with source word m 

expressing preferences

    express preferences using target values: 

    

    example #1:                           
ep   [  w(x, y)]         

    label distribution for game is close to [40% 40% 20%]

    example #2:                           
ep   [  (x, y)]         

    expected number of target words that align with each 

source word is at most one

preview: labeled features
user experiments [druck et al. 08]

pc vs. mac

~2 minutes, 100 
features labeled 
(or skipped): 
82% accuracy

~15 minutes, 100 
documents labeled 

(or skipped):
78% accuracy

1

0.9

0.8

0.7

0.6

0.5

y
c
a
r
u
c
c
a
g
n
i
t
s
e
t

 

ge
er

600

700

800

300
labeling time in seconds

400

500

 

targets set with 
simple heuristic: 
majority label gets 
90% of mass
complete set of 
labeled features

mac
mac
apple
quadra

pc
dos
ibm
hp
dx

 
0.4
0

100

200

95

86.25

77.5

68.75

60

preview:  word alignment

[gra  a et al. 10]

id48

id48 + bijectivity constraint

en-pt

pt-en

en-es

es-en

overview of the frameworks

running example

model family: conditional exponential models

p  (y|x) =

z(x) =   y

exp(      f (x, y))

z(x)

exp(      f (x, y))

                   are model features

f (x, y)

                choosing parameters

  

model family: conditional exponential models

p  (y|x) =

exp(      f (x, y))

z(x)

objective: maximize observed data likelihood
max

log p  (yl|xl) + log p(  ) def= l(  ; dl)

  

note: frameworks also suitable for 
generative models (no labeled data necessary)                   

visual example: maximum likelihood

model:                                      

p(y|x) =   i

exp(yixi      )

z(xi)

objective:

max

  

log p  (yl|xl)     0.1        2

2

-

o o

o

o
o

o

o

o

+

a language for prior information

the expectations of user-de   ned constraint 
    
features             are close to some value 

  (x, y)

e[  (x, y)]         

running example:

want to ensure that 25% of unlabeled 
documents are about politics
    constraint features
 

  (x, y) =   1 if y is    politics   

0 otherwise
    preferred expected value

     = 0.25

    expectation w.r.t. unlabeled data

constraint-driven learning

m. chang, l. ratinov, d. roth (2007).

motivation: hard em algorithm with preferences
hard em: 
e-step: set   y = arg max

m-step: set    = arg max

  

y

log p  (y|x)
log p  (   y|x)

constraint driven learning:
e-step: set   y = arg max

y

m-step: set    = arg max

  

log p  (y|x)   penalty(y)
log p  (   y|x)

constraint-driven learning

motivation: hard em algorithm with preferences
constraint driven learning:
e-step: set   y = arg max

y

log p  (y|x)   penalty(y)
log p  (   y|x)

m-step: set    = arg max
    penalties encode similar information as 

  

e[  ]         

* more on this later *
    e-step can be hard; use id125

visual example: constraint driven learning

max
  ,   y

log p  (yl|xl)     0.1        2
  y
    where     are    imagined    labels and

2

s.t.   (   y) = 2

  [   y] = count(+,   y)

-

o o

o

o
o

o

o

o

+

posterior id173
j. gra  a, k. ganchev, b. taskar (2007).

motivation: em algorithm with sane posteriors

em:

e-step: set q(y) = arg min

q
m-step: set    = arg max

dkl(q(y)||p  (y|x))

eq(y)[p  (y|x)]

constrained em:

  

e-step: set q(y) = arg min

m-step: set    = arg max

q   q dkl(q(y)||p  (y|x))
eq(y)[p  (y|x)]

  

posterior id173

motivation: em algorithm with sane posteriors
idea:                  provide constraints

e[  ]         
de   ne q: set of q such that eq[  ]         

run em-like procedure but use proposal q     q
objective:

max

  

l(  ; dl)     dkl(q || p  (y|x))

where
dkl is id181
x = du are the input variables for unlabeled corpus
y is label for entire unlabeled corpus

posterior id173

hard constraints:

max

  

l(  ; dl)     min

q   q dkl(q(y)|| p  (y|x))

q =   q(y) :         eq[  (y)] =              

2

2           

soft constraints:

max

  

l(  ; dl)     min

q     dkl(q(y)|| p  (y|x)) +
           eq[  (y)] =              

2    

2

visual example: posterior id173 

max

  

log p  (yl|xl)     0.1        2

2     dkl(q||p  )
q dkl(q||p  ) s.t. eq[  ] = 2

 where: 

dkl(q||p  ) = min

-

o o

o

o
o

o

o

o

+

generalized expectation constraints

g. mann, a. mccallum (2007). 

motivation: augment log-likelihood with cost for    bad    
posteriors.
objective:

max

   l(  ; dl)             ep  (y|x)[  ]                    

ep  (y|x)[  ] =ep  (y|x)[  (x, y)]

where

                                                                    is short-hand

p  (y|x)  (x, y)

=   y

optimization: id119 on    
  

a visual comparison of the frameworks

objective: generalized expectation constraints

max

  

log p  (yl|xl)     0.1        2

2     500   ep   [  ]     2   2

2

-

o o

o

o
o

o

o

o

+

types of constraints

constraint driven learning: penalized viterbi

arg max

y

log p  (y|x)          (x, y)              

    easy if                           decompose as the model.

     (x, y)              
                 and
pc(yc|x)

p(y|x) =   c

    otherwise:

    id125
    integer linear program 

     (x, y)               =   c

  c(x, yc)

types of constraints

posterior id173: kl projection

q dkl(q||p  ) s.t.    eq[  ]                      
min

    usually easy if               decompose as the model:

  (y, x)

p(y|x) =   c
  (x, y) =   c

pc(yc|x)
     and

  c(x, yc)

   

q(y|x) =   c

qc(yc|x)

    otherwise: sample (e.g. k. bellare, g. druck, and a. mccallum, 2009)

types of constraints

generalized expectation constraints: direct gradient

    usually easy if:

max

   l(  ; dl)             ep  (y|x)[  ]                    
  (x, y) =   c

  (y, x)

    decomposes as the model

    can compute                * more on this later *

e[      f ]

    unstructured
    sequence, grammar (semiring trick)

  c(x, yc)

    otherwise: sample or approximate the gradient.

a bayesian view: measurements

p. liang, m. jordan, d. klein (2009)

  

xl

yl

x

y

  (x, y)

b

figure 4.1: the model used by liang et al. [2009], using our notation. we have separated
treatment of the labeled data (xl, yl) from treatment of the unlabeled data x.

objective: mode of    given observations

  

max

  

log p(  ) +    (x,y)   dl

log p  (y|x) = l(  ; dl)

and produce some value   (x, y), which is never observed directly. instead, we observe
some noisy version b       (x, y). the measured values b are distributed according to
some noise model pn (b|  (x, y)). liang et al. [2009] note that the optimization is convex
for log-concave noise and use box noise in their experiments, giving b uniform id203
in some range near   (x, y).

in the bayesian setting, the model parameters    as well as the observed measurement
values b are random variables. liang et al. [2009] use the mode of p(  |xl, yl, x, b) as a
point estimate for   :

a bayesian view: measurements

(4.6)

=

arg max

  

p(  |xl, yl, x, b) = arg max

  

x

xl

  (x, y)
p(  , y, b|x, xl, yl),

      y

with

equality

because
yl

p(  |xl, yl, x, b)

   

p(  , b|xl, yl, x)
b

max

  

   y p(  , y, b|x, xl, yl). liang et al. [2009] focus on computing p(  , y, b|x, xl, yl).

figure 4.1: the model used by liang et al. [2009], using our notation. we have separated
they de   ne their model for this quantity as follows:
objective: mode of    given observations
treatment of the labeled data (xl, yl) from treatment of the unlabeled data x.
p(  , y, b|x, xl, yl) = p(  |xl, yl) p  (y|x) pn (b|  (x, y))

(4.7)

y

  

l(  ; dl) + log ep  (y|x)   p(     |  (x, y))   

and produce some value   (x, y), which is never observed directly. instead, we observe
where the y and x are particular instantiations of the random variables in the entire unla-
some noisy version b       (x, y). the measured values b are distributed according to
beled corpus x. equation 4.7 is a product of three terms: a prior on   , the model id203
some noise model pn (b|  (x, y)). liang et al. [2009] note that the optimization is convex
p  (y|x), and a noise model pn (b|  ). the noise model is the id203 that we observe
for log-concave noise and use box noise in their experiments, giving b uniform id203
a value, b, of the measurement features   , given that its actual value was   (x, y). the
in some range near   (x, y).
idea is that we model errors in the estimation of the posterior probabilities as noise in the
in the bayesian setting, the model parameters    as well as the observed measurement

what's wrong with this picture?

max

  

objective: mode of    given observations

  

example: exactly 25% of articles are    politics   

l(  ; dl) + log ep  (y|x)   p(     |  (x, y))   
p(     |  (x, y)) = 1         =   (x, y)   
ep  (y|x)   1(      =   (x, y))   

what is the id203 exactly 25% of the articles are 
labeled ``politics''?

how do we optimize this with respect to  ?
  

what's wrong with this picture?

example: compute prob:  25% of docs are    politics   .

article p(   politics   )

1
2
3
4

0.2
0.4
0.1
0.6

    naively:

0.2    (1     0.4)    (1     0.1)    (1     0.6)
+ . . . +
+(1     0.2)    (1     0.4)    (1     0.1)    0.6

      in this case we can use a dp, but if 
there are many constraints, that doesn   t 
work.

easier: what is the expected number of    politics    articles?

0.2 + 0.4 + 0.1 + 0.6

probabilities and expectations

dif   cult to compute expectations of arbitrary functions but...
usually:             decomposes as a sum
e.g. 25% of articles are    politics   

  (x, y)

  (x, y) =    instances

  (x, y)

idea: approximate 

ep  (y|x)   p         |   (x, y)           p         | ep  (y|x) [  (x, y)]   

probabilities and expectations

approximation:

objective:

max

  

ep  (y|x)   p         |              p         | ep  (y|x) [  ]   
l(  ; dl) + log p         | ep  (y|x) [  ]   

   

example:                      is gaussian     
                                              is 

p         | e[  ]   
   

log p         | e[  ]   
log p         | e[  ]   

2

2

         e[  ]                  

so for appropriate                           this is identical to ge!

optimizing ge objective

ge objective:
oge = max
    gradient involves covariance

l(  ; dl)             ep  (y|x)[  (x, y)]                    

  

cov(  , f ) = e[      f ]     e[  ]    e[f ]

this can be hard because

e[      f ] =   y

p(y)  (y)    f (y)

and the usual dynamic programs (inside outside, forward 
backward) can   t compute this.

optimizing ge objective

y1

y2

y3

y4

x1

x2

x3

x3

  (y)    f (y) =      i

p(y)  (y)    f (y)

e[      f ] =   y
f (yj)      
  (yi)               j

maintaining both     and      in the dp is expensive

yi

yj

* semiring trick can help for some problems *
   e.g. if id136 is a hypergraph problem.

a variational approximation

ge objective:
oge = max
    can be hard to compute                   in gradient. 

l(  ; dl)                       ep  (y|x)[  (x, y)]           

cov(  , f )

  

idea: use variational approximation

q(y)     p  (y|x)

max  ,q(y) l(  ; dl)   dkl   q(y) || p  (y|x)                eq[  (x, y)]                    

* note: this is the pr objective *

approximating with the mode

pr objective: 

max  ,q(y) l(  ; dl)   dkl   q(y) || p  (y|x)                eq[  (x, y)]                    

sometimes minimizing the kl is hard.  
idea: use hard assignment                               :
q(y)     1(y =   y)
                                        becomes 
log p(   y)
                                     becomes 
log p(      |   (x,   y))
    use em-like procedure to optimize
constraint driven learning objective:

dkl   q(y) || p  (y|x)   
         eq[  (x, y)]                    

  ,   y l(  ; dl) + log p  (   y) + log p(     |  (x,   y))
max

visual summary

measurements

log e[pn (     |  )]     log pn (     |e[  ])

variational approximation;

jensen   s inequality

generalized
expectation

variational

approximation

posterior

id173

distribution
distribution

matching
matching

map

approximation

map

approximation

constraint

driven
learning

coupled semi-

supervised
learning

applications

    unstructured problems:

    document classi   cation
    sequence problems:

information extraction

   
   
pos-induction 
    word alignment
    tree problems:
    grammar induction

document classi   cation

documents

labels

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

--- --- ----- 
-- -- --- ---- 
--- --- --- --- 
-- ---------  
------- ---- -- 

    model: max. id178 classi   er (id28)

exp(      f (x, y))

p  (y|x) =

   y exp(      f (x, y))
    challenge: what if we have no labeled data?
   y
    cannot use standard unsupervised learning:

p  (y|x) = 1

labeled features

    often we can still provide some light supervision
    prior knowledge: labeled features

sentiment polarity
positive
memorable

negative

perfect
exciting

terrible
boring
mess

newsgroups classi   cation

baseball

hit

braves
runs

mac
apple

macintosh
powerbook

politics
senate
taxes
liberal

...
...
...
...

    formally: have an estimate of the distribution over labels 

for documents that contain word w:     w

leveraging labeled features with ge

[mann & mccallum 07], [druck et al. 08]

    constraint feature: 

  w(x, y) = 1(y = l)1(w     x)

    for a document x, returns a vector with a 1 in the lth 

position if y is the lth label and the word w is in x

    expectation: label distribution for docs that contain w

    ge penalty: kl divergence from target distribution

1

cw   x
dkl        w||

ep  (y|x)[  w(x, y)]

1

cw   x

ep  (y|x)[  w(x, y)]   

user experiments with labeled features

[druck et al. 08]

pc vs. mac

~2 minutes, 100 
features labeled 
(or skipped): 
82% accuracy

~15 minutes, 100 
documents labeled 

(or skipped):
78% accuracy

1

0.9

0.8

0.7

0.6

0.5

y
c
a
r
u
c
c
a
 
g
n
i
t
s
e
t

 
0.4
0

100

200

300
labeling time in seconds

400

500

ge
er

600

700

800

 

targets set with 
simple heuristic: 
majority label gets 
90% of mass
complete set of 
labeled features

mac
mac
apple
quadra

pc
dos
ibm
hp
dx

experiments with labeled features

[druck et al. 08]

learning about    unlabeled features    through 

covariance improves generalization
3.5x

6.5x

estimated speed-up over 

labeling documents

15x

80

75

70

65

60

sentiment (50)

webkb (100) newsgroups (500)

ge (model contains only labeled features)
ge (model also contains unlabeled features)

information extraction: example tasks

    citation extraction: 

cousot, p. and cousot, r. 1978. static determination of 
dynamic properties of recursive procedures. in proceedings of 
the ifip conference on programming concepts, e. neuhold, 
ed. north-holland pub. co., 237-277.

    apartment listing extraction: 

detached single family house. 3 bedrooms 1 1/2 baths.  almost 
1000 square feet in living area. 1 car garage. new pergo    oor 
and tile kitchen    oor. new interior/exterior paint. close to 
shopping mall and bus stop. near 101/280. available july 1, 
2004. if you are interested, email for more details.

information extraction: markov models

    models for sequence labeling based ie
    hidden markov model (id48):  
p  (y, x) = p  (y0)

p  (yi|yi   1)p  (xi|yi)

n   i=1

    conditional random field (crf):  
p  (y|x) =

      f (x, yi   1, yi))

z(x)

exp(

1

n   i=1

information extraction: labeled features

[mann & mccallum 08], [liang et al. 09]

apartments example 

labeled features:
roommates

respectful

contact

features

*phone*

laundry

constraint features:
  q(x, yi, i) = 1(yi = l)q(x, i)
vector with a 1 in the lth 
position if y is the lth label 
and predicate q is true (i.e. w 
is present at i)

expectation:
1

cq   x    i

ep  (yi|x)[  q(x, yi, i)]
label distribution when q is true
model: linear chain crf

note: semiring trick makes ge 
o(l2) instead of o(l3) as in 
[mann & mccallum 08]

information extraction: labeled features
[haghighi & klein 06], [mann & mccallum 08], [liang et al. 09]

850

800

750

700

650

apartment listing extraction

prototype
ge (kl)
measurements/pr

    accurate with constraints alone 
    outperform fully supervised with 

constraints and labeled data

supervised crf (100) [mm08]

0 labeled

10 labeled

100 labeled

limitations of markov models

    predicted: 

cousot, p. and cousot, r. 1978. static determination of 
dynamic properties of recursive procedures. in proceedings of 
the ifip conference on programming concepts, e. neuhold, 
ed. north-holland pub. co., 237-277.

    prediction has two author and two title segments:

    error #1: neuhold, ed. should be editor
    error #2: north-holland pub. co., should be 

publisher

    a markov model cannot represent that at most one segment 

of each type appears in each reference.

long-range constraints
[chang et al. 07] [bellare et al. 09]

       each    eld is a contiguous sequence of tokens and appears 

at most once in a citation.   

each type

    constraint feature: counts the number of segments of 
    constrained to be     1 using pr or codl
    additional constraints: 10 labeled features such as:
    pages   pages 
    proc.   booktitle

long-range constraints
[chang et al. 07] [bellare et al. 09]

crf
id48

crf + pr
id48 + codl

constraints improve both 
crf (pr) and id48 (codl)

90

80

70

60

50

5 labeled

20 labeled

other applications in 
information extraction

citation

model method description

[mann et al. 07]

maxent

[druck et al. 09]

crf

[bellare & 

mccallum 09] 

[singh et al. 10] 

alignment 

crf

semi-markov 

crf

[druck et al. 10]

id48

ge

ge

ge

pr

pr

constraints on 
label marginals
actively labeled 

features

labeled features

labeled gazetteers 

constraints derived 
from labeled data

pos induction

low tag ambiguity

[gra  a et al. 09] 

e[degree] = 10000

e[degree] = 1.5

jj
vb
nn

car
object
offensive
romantic
being

distribution of 
word ambiguity
supervised
id48

 200  400  600  800  1000 1200 1400 1600 1800

rank of word by l1l!

 10
 8
 6
 4
 2
 0

 0

!

l
1

l

measuring tag ambiguity

[gra  a et al. 09] 

a run into town.
of the mile run.
run gold.
run errands.
run for mayor.

n

0.9

0.7

0.1

0.3

0.3

v

0.1

0.1

0.3

0.6

0.7

adj

prep

adv

0

0.1

0

0

0

0

0

0.6

0

0

0

0.1

0

0.1

0

max

0.9

0.7

0.1

0.6

0.2

sum

2.5

sum

1
sum
1

1
1

1

1

   pick a particular word type: run

   stack all occurrences

   calculate posterior id203 
   take the maximum for each tag
   sum the maxes

  wti :word type w  has hidden state t at occurrence i
min
cwt

eq(y)[  wti]     cwt

   1/       =   wt

cwt

tag sparsity
[gra  a et al. 09] 

average ambiguity 

difference

e
c
n
e
r
e
f
f
i

d
 
y
t
i
u
g
i
b
m
a

5

3.75

2.5

1.25

0

en
id48

pt

es

l1lmax

distribution of 
word ambiguity

supervised
id48
id48+sp

!

l
1

l

 10
 8
 6
 4
 2
 0

 0

 200  400  600  800  1000 1200 1400 1600 1800

rank of word by l1l!

results

[gra  a et al. 09] 

id48

id48+sp

80

6.5 % average improvement

72.5

3.8

6.7

65

57.5

50

7.6

9.6

7.4

3.8

en

pt

bg

es

dk

tr

word alignments

[gra  a et al. 10] 

    bijectivity constraints:

    each word should align to at most one other word

    symmetry constraints:

    directional models should agree

bijectivity constraints

[gra  a et al. 10]

bijective constraints - after projection

bijective constraints

0
1
2
3
4
5
6
7
8

0 1 2 3 4 5 6 7 8

   
   
   
   
   
   
   
   
jugaban         1
    de
   
   
   
   
   
   
   
        1
    una
   
   
   
   
   
   
   
        1
    manera         1
   
   
   
   
   
   
   
                animada         1
                   
   
           
   
   
   
    y
        1
           
    muy
   
   
   
   
        1
   
   
   
   
   
   
    cordial         1
   
   
   
   
   
   
   
       .
        1

   
   
   
   
   
   
   
   

it w

, v

a
nim

ery

as

.

c

a

a

o

g

n

n

m

ate

d

e

vivial

0
1
2
3
4
5
6
7
8

   
   
   
   
   
   
   
   
   

0 1 2 3 4 5 6 7 8

   
   
   
   
   
   
   
jugaban         1
    de
   
   
   
   
   
   
        1
    una
   
   
   
           
        1
    manera         1
   
   
   
   
   
   
    animada         1
   
   
           
   
           
    y
   
   
   
        1
    muy
           
   
   
   
        1
                cordial         1
   
   
   
   
   
   
   
   
   
   
   .
        1

   
   
   
   
   
   
   
   

, v

a
nim

ery

as

.

c

a

a

o

g

n

n

m

it w

ate

d

e

vivial

feature: 

  (x, y) =

50 / 74

1(yi = m)

51 / 74

n   i=1

constraint: 

eq[  (x, y)]     1

symmetric - original posteriors

symmetry constraints

[gra  a et al. 10]

      p  t

p  t
q

      p  t

      p   (y|x)
      p   t (z | x)

      p   (y|x)
      p   t (z | x)

feature:

constraint: 

1
2
3

0 1 2 3 4

0 1 2 3 4

   
0        
   
   
   
                    estad    sticas
   
   
   
0        
   
   
   
   
       
   
   
   
   
statistic

    no
   
    hay
   
       .
   
    no
   
    hay
   
    estad    sticas
       .

xists

1
2
3

ata

.

e

o

n

d

al

  (x, y) =               

eq[  (x, y)] = 0

+1 y           y and       y i = j
   1 y           y and       y j = i

0

otherwise

55 / 74

symmetry constraints

symmetric - after projection

[gra  a et al. 10]

before projection:

e-step qs(z) = arg min
q(z)   qs

      p   (y|x)
      p   t (z | x)

      p   (y|x)
      p   t (z | x)

1
2
3

0 1 2 3 4

0 1 2 3 4

    no
   
    hay
   
       .
   
    no
   
    hay
   
    estad    sticas
       .

   
0        
   
   
   
                    estad    sticas
   
   
   
0        
   
   
   
   
       
   
   
   
   
statistic
m-step does not change

xists

1
2
3

ata

al

.

e

o

n

d

0
1
2
3

0 1 2 3 4

after projection:
kl [qs(z)|| p  t (z | xs)]
    no
   
   
   
            hay
   
           
    estad    sticas
   
   
       .
   
    no
   
   
   
            hay
           
    estad    sticas
   
   
       .
statistic

0 1 2 3 4

   
   
   
   
   
   
   
   

xists

0
1
2
3

ata

.

e

o

n

d

al

      q (y)
      q (z)

      q (y)
      q (z)

56 / 74

results

[gra  a et al. 10]

evolution with data size

evolution with data size

 100

 90

i

i

 80

n
o
s
c
e
r
p

 70

 100

 90

 80

 70

 60

i

i

n
o
s
c
e
r
p

 100

 90

 80

 70

 60

i

i

n
o
s
c
e
r
p

 60

 50
 1000

 50
 1000

 10000

 10000

 50
 1000
size

size

i

i

n
o
s
c
e
r
p

 100

 90

 80

 70
s-id48
b-id48
 60
m4
id48

 50
 100000
 1000

i

i

n
o
s
c
e
r
p

s-id48
b-id48
m4
id48

 100000

 10000

s-id48
b-id48
 1e+06
id48
size

 100000

 1e+06

 100

 90

 80

i

i

n
o
s
c
e
r
p

 70

 100

 90

 80

 70

 60

 50
 1000
size

 60
 1e+06
 10000
 50
 1000

s-id48
b-id48
m4
id48

 100000

 10000

 10000

s-id48
b-id48
m4
id48

 100000

 1e+06

s-id48
b-id48
id48

 100000

 1e+06

 1e+06
size

size

61 / 74

61 / 74

 95

 90

 85

 80

 75

 70

 65

 60

results

[gra  a et al. 10]

.

4
8
8

.

7
2
8

.

2
7
8

.

6
4
8

.

1
9
8

.

2
7
8

.

9
8
8

.

5
6
8

.

0
4
8

.

9
0
8

.

7
5
7

.

9
4
7

.

6
4
9

.

6
1
9

.

4
3
9

.

8
0
9

.

8
1
9

.

1
0
9

.

6
4
8

.

.

4
2
8

5
2
8

.

8
9
7

.

3
8
7

.

3
6
7

.

2
6
8

.

0
5
8

.

0
5
8

.

9
7
8

.

3
6
8

.

4
2
8

.

6
7
7

5
.
0
7

.

4
4
7

5
.
7
6

.

0
3
7

3
.
1
7

en-pt

pt-en

pt-fr

fr-pt

en-es

es-en

es-fr

fr-es

pt-es

es-pt

en-fr

fr-en

languages

id48

b-id48

s-id48

id33

dmv model
[gra  a et al. 04]

dependency model with valence

(klein and manning, acl 2004)

y

x

n

id173

v

creates

adj
sparse

n

grammars

p  (x, y) =   root(v )

    stop(nostop|v ,right,false)      child(n|v ,right)

    stop(stop|v ,right,true)      stop(nostop|v ,left,false)      child(n|v ,left)

. . .

3/9

id33

    transfer annotations from another language
    [ganchev et al. 09]
    constrain the number of child/parent 

relations
    [gillenwater et al. 11]
    use linguistic rules
    [druck et al. 09] [naseem et al. 10]

id33
transfer annotations

[ganchev et al. 09]

language

    use information from a resource rich 
    make the annotation transfer robust
    preserve n % of the edges

id33
transfer annotations

[ganchev et al. 09]

eq[  (x, y)] =

1

|cx|    y   cx

q(y|x)

eq[  (x, y)]     b

id33
transfer annotations

[ganchev et al. 09]

dmv

pr-transfer

70

69

68

67

66

es

bg

id33

posterior sparsity

[gra  a et al. 10]

    ml learns very ambiguous grammars
    all productions have some id203
    constrain the number of possible 

productions

id33

posterior sparsity
[gillenwater et al. 11]

measuring ambiguity on distributions over trees

n

n

   
n

   
v

n

   

j
d
a

v

v

   
n

   
v

v

   

j
d
a

j
d
a

j
d
a

   
n

   
v

j
d
a

   

j
d
a

0

1

0

0

.7

.3

.4

.6

0

0.4

0.6

n

sparsity

v
is

v

working

0.4

0.6

n

sparsity

v
is

v

working

0.7

0.3

v
use

adj
good

n

grammars

0.6

0.4

v
use

adj
good

n

grammars

.4

.6

0

max    
sum = 3.3     0

1

.3

.4

.6

0

.4

.6

0

7/9

id33

posterior sparsity
[gillenwater et al. 11]

gillenwater, ganchev, gra  a, pereira, taskar

gold:

una
d

papelera

nc

1.00

1.00

una
d

papelera

nc

es
vs

un
d

1.00

1.00

0.49

es
vs

un
d

objeto

nc
0.57

0.51

objeto

nc
0.35

civilizado

aq

civilizado

aq

0.43

0.48

1.00

0.83 0.75

0.92

0.99

una
d

papelera

nc

es
vs

un
d

objeto

nc

civilizado

aq

dvm:

dmv+sparsity:

figure 14: posterior edge probabilities for an example sentence from the spanish test corpus. top

is gold, middle is em, and bottom is pr.

since then it does not have to pay the cost of assigning a parent with a new tag to cover each noun
that does not come with a determiner.

id33

table 4 contrasts the most frequent types of errors em, sdp, and pr make on several test sets
where pr does well. the    acc    column is accuracy and the    errs    column is the absolute number
of errors of the key type. accuracy for the key    parent pos truth/guess     child pos    is computed
as a function of the true relation. so, if the key is pt/pg     c, then accuracy is:

posterior sparsity
[gillenwater et al. 11]

dmv

dmv+sparsity

acc =

# of pt     c in viterbi parses
# of pt     c in gold parses .

in the following subsections we provide some analysis of the results from table 4.

70

(25)

52.5

17.5

7.1 english corrections
considering english    rst, there are several notable differences between em and pr errors. similar
to the example for spanish, the direction of the noun-determiner relation is corrected by pr. this is
35
re   ected by the vb/dt     nn key, the nn/vbz     dt key, the nn/in     dt key, the in/dt    
nn key, the nn/vbd     dt key, the nn/vbp     dt key, and the nn/vb     dt key, which for
em and sdp have accuracy 0. pr corrects these errors.
a second correction pr makes is re   ected in the vb/to     vb key. one explanation for the
reason pr is able to correctly identify vbs as the parents of other vbs instead of mistakenly making
0
to the parent of vbs is that    vb cc vb    is a frequently occurring sequence. for example,    build
and hold    and    panic and bail    are two instances of the    vb cc vb    pattern from the test corpus.
presented with such scenarios, where there is no to present to be the parent of vb, pr chooses the
   rst vb as the parent of the second. it maintains this preference for making the    rst vb a parent of
the second when encountered with    vb to vb    sequences, such as    used to eliminate   , because it
would have to pay an additional penalty to make to the parent of the second vb. in this manner,
pr corrects the vb/to     vb key error of em and sdp.

bulgarian portuguese checz

german

spanish

english

using universal linguistic knowledge to guide grammar induction

id33

tahira naseem, harr chen, regina barzilay

computer science and arti   cial intelligence laboratory

massachusetts institute of technology

mark johnson

department of computing

macquarie university

linguistic rules
[naseem et al. 10]

{tahira, harr, regina} @csail.mit.edu

mark.johnson@mq.edu.au
small set of 
universal rules

abstract

we present an approach to grammar induc-
tion that utilizes syntactic universals to im-
prove id33 across a range of
languages. our method uses a single set
of manually-speci   ed language-independent
rules that identify syntactic dependencies be-
tween pairs of syntactic categories that com-
monly occur across languages. during infer-
ence of the probabilistic model, we use pos-
terior expectation constraints to require that a
minimum proportion of the dependencies we
infer be instances of these rules. we also auto-
matically re   ne the syntactic categories given
in our coarsely tagged input. across six lan-
guages our approach outperforms state-of-the-
art unsupervised methods by a signi   cant mar-

despite surface differences, human languages ex-
hibit striking similarities in many fundamental as-
pects of syntactic structure. these structural corre-
spondences, referred to as syntactic universals, have
been extensively studied in linguistics (baker, 2001;
carnie, 2002; white, 2003; newmeyer, 2005) and
underlie many approaches in multilingual parsing.
in fact, much recent work has demonstrated that
learning cross-lingual correspondences from cor-
pus data greatly reduces the ambiguity inherent in
syntactic analysis (kuhn, 2004; burkett and klein,
2008; cohen and smith, 2009a; snyder et al., 2009;
berg-kirkpatrick and klein, 2010).

1the source code for the work presented in this paper is

available at http://groups.csail.mit.edu/rbg/code/dependency/

  (x, y)

= 1 if edge in rule set

eq[  (x, y)]     b

root     auxiliary noun     adjective
root     verb
verb     noun
verb     pronoun
verb     adverb
verb     verb
auxiliary     verb

noun     article
noun     noun
noun     numeral
preposition     noun
adjective     adverb

table 1: the manually-speci   ed universal dependency
rules used in our experiments. these rules specify head-
dependent relationships between coarse (i.e., unsplit)
syntactic categories. an explanation of the ruleset is pro-
vided in section 5.

id33

linguistic rules
[naseem et al. 10]

in this paper, we present an alternative gram-
mar induction approach that exploits these struc-
tural correspondences by declaratively encoding a
small set of universal dependency rules. as input
to the model, we assume a corpus annotated with
coarse syntactic categories (i.e., high-level part-of-
speech tags) and a set of universal rules de   ned over
these categories, such as those in table 1. these
rules incorporate the de   nitional properties of syn-
tactic categories in terms of their interdependencies
and thus are universal across languages. they can
potentially help disambiguate structural ambiguities
that are dif   cult to learn from data alone     for
example, our rules prefer analyses in which verbs
are dependents of auxiliaries, even though analyz-
ing auxiliaries as dependents of verbs is also consis-
tent with the data. leveraging these universal rules
has the potential to improve parsing performance
for a large number of human languages; this is par-
ticularly relevant to the processing of low-resource

dmv+rules

dmv

60

80

40

20

0

english

danish portuguese slovene

spanish

swedish

id33:

applications using other models

    tree crf
    [druck et al. 09]
    mst parser
    [ganchev et al. 09]

other applications

    multi view learning:
    [ganchev et al. 08]
    id36:
    [chen et al. 11]

implementation tips and tricks

off-the-shelf tools: mallet

http://mallet.cs.umass.edu

    off-the-shelf support for labeled features
    models: maxent classi   er, linear chain crf (one and two 

label constraints)

    methods: ge and pr
    constraints on label distributions for input features
    ge penalties:  kl divergence,     (+ soft inequalities)
    pr penalties:     (+ soft inequalities)
    in development: tree crf,      and other penalties

   2
2

   2
2

   1

off-the-shelf tools: mallet

http://mallet.cs.umass.edu

    import data in id166light-like or conll03-like formats

positive interesting:2 film:1 ...
negative tired:1 sequel:1 ...
positive best:1 recommend:2 ...

u.n.       nnp  b-np  b-org 
official   nn   i-np  o 
heads      vbz  b-vp  o 

    import constraints in a simple text format:

tired negative:0.8 positive:0.2
best positive:0.9 negative:0.1

u.n. b-org:0.7,0.9
b-vp o:0.95,

    easily specify method options (i.e. simpletagger):

java cc.mallet.fst.semi_supervised.tui.semisupsimpletagger \
--train true --test lab --loss l2 --learning ge \
unlabeled.txt test.txt constraints.txt

new ge constraints: mallet

http://mallet.cs.umass.edu

    java interfaces for implementing new ge constraints
    covariance computation implemented (maxent, crf)
    primarily need to write methods to:
compute constraint features and expectations
compute ge objective value
compute ge objective gradient (but not covariance)
    restriction: constraints must factor with model
    restriction: ge objective must be differentiable

new pr constraints: mallet

http://mallet.cs.umass.edu

    java interfaces for implementing new pr constraints
    id136 algorithms implemented (maxent, crf)
    primarily need to write methods for e-step (projection):
compute constraint features and expectations
compute scores under q for e-step
compute objective function for e-step
compute gradient for e-step
    restriction: constraints must factor with model

ge implementation advice

    computing covariance (required for gradient): 

    trick: compute cov. of composite constraint feature
    example:     penalty: 
2(          e[  ])  (x, y)
    result: only need to store vectors of size            in 

  c(x, y) =     

dim(f )

computation, rather than covariance matrix

   2
2

    trick: ef   cient gradient computation in hypergraphs

    use semiring algorithms of [li & eisner 09] 
    result: same time complexity as supervised (w. both)

ge implementation advice

    parameter id173: 

        id173 encourages id64 by penalizing 

   2
2
very large parameter values:

>

    optimization: non-convex

    usually l-bfgs still preferable (use    restart trick   )
    zero initialization usually works well
    other init: supervised, maxent, ge in simpler model

off-the-shelf tools: pr toolkit
http://code.google.com/p/pr-toolkit/

    off-the-shelf support for pr
    models:  

    maxent classi   er, id48,dmv

    applications:  

    word alignment, pos induction, grammar induction
    constraints: posterior sparsity, bijectivity, agreement
    no command line mode
    smaller support base

pr implementation example:

word alignment - bijectivity

    learning: em, pr

   
   
   

   
   
   

void estep(counts, lattices);
void mstep(counts);
lattice constraint.project(lattice);

    model: id48

lattice computeposteriors(lattice);
void addcount(lattice, counts);
void updateparameters(counts);

    constraints: bijectivity

   

lattice project(lattice);

pr implementation example:

em

class em {
 model;
 	
void em(n){
 lattices= model.getlattices();
 counts = model.counts();	 	
	
 for(i=0; i< n; i++) {	 	
	
	
estep(counts, lattices);
	
mstep(counts);
 }
}
	

void estep(counts, lattices) {	
	
	
	
	
	
}	

counts.clear();
for(l : lattices)  {		
 model.computeposterior(l);
 model.addcount(l,counts);	
}

	

void mstep(counts) {
	
}

model.updateparameters(counts);

......

}

pr implementation example:

pr

class pr {
 model;
 constraint;
	
void em(n){
 lattices= model.getlattices();
 counts = model.counts();	 	
	
 for(i=0; i< n; i++) {	 	
	
estep(counts, lattices);
	
	
mstep(counts);
 }
}
	

void estep(counts, lattices) {	
	
	
	
	
    constraint.project(l);
	
	
}	

counts.clear();
for(l : lattices){	
 model.computeposterior(l);
 model.addcount(l,counts);	
}

	

void mstep(counts) {
	
}

model.updateparameters(counts);

......

}

pr implementation example:

id48

class id48 {
 obsprob, transprobs,initprobs;
	
lattice computerposteriors(lattice){
    run forward backward   
}
	
void addcount(lattice,counts){
    add posteriors to count table   
}
void updateparams(counts){
    normalize counts   
    copy counts to params table   
}

void getcounts(){
    return copy of params structures   
}
void getlattices(){
    return structure of all lattices 
in the corpus   
}

......

}

pr implementation example:

bijective constraints

    constraint: returns a vector with mth value = number of 
target words in sentence x that align with source word m

1(yi = m) q = {q : eq[  (x, y)]     1}

  (x, y) =

n   i=1
    primal: hard

    dual: easy

q

arg max

dkl(q|p  ) = arg min
dkl(q|p  )
     0    bt           log z(  )     ||  ||2
z(  ) =   y
p  (y|x) exp(           (x, y))

pr implementation example:

bijective constraints

class bijectiveconstraints {
model;
lattice project(lattice){
 obj = bijectiveobj(model,lattice);
 optimizer.optimize(obj);
}
	
}

class bijectiveobj {
  lattice;
  

void updatemodel(newlambda){
 lattice_ = lattice*exp(newlambda);
 computerposteriors(lattice)
}

double getobj(){
  obj = -dot(lambda,b);
  obj -= lattice.likelihood;
  obj -= l2norm(lambda);
}
double[] getgrad(){
 grad = lattice.posteriors - b;
 grad -= norm(lambda);
 return grad;
}

other software packages

    learning based java:  

    http://cogcomp.cs.illinois.edu/page/software_view/11
    support for constraint-driven learning

    factorie:   

    http://code.google.com/p/factorie/
    support for ge and pr in development

rich prior knowledge in learning for natural

language processing

bibliography

for a more up-to-date bibliography as well as additional information about

these methods, point your browser to: http://sideinfo.wikkii.com/

1 constraint-driven learning

constraint driven learning (codl) was    rst introduced in chang et al. [2007],
and has been used also in chang et al. [2008]. a further paper on the topic is
in submission [chang et al., 2010].

2 generalized expectation

generalized expectation (ge) constraints were    rst introduced by mann and
mccallum [2007]1 and were used to incorporate prior knowledge about the label
distribution into semi-supervised classi   cation. ge constraints have also been
used to leverage    labeled features    in document classi   cation [druck et al., 2008]
and information extraction [mann and mccallum, 2008, druck et al., 2009b,
bellare and mccallum, 2009], and to incorporate linguistic prior knowledge
into dependency grammar induction [druck et al., 2009a].

3 posterior id173

the most clearly written overview of posterior id173 (pr) is ganchev
et al. [2010]. pr was    rst introduced in graca et al. [2008], and has been
applied to dependency grammar induction [ganchev et al., 2009, gillenwater
et al., 2009, 2011, naseem et al., 2010], part of speech induction [gra  ca et al.,
2009a], multi-view learning [ganchev et al., 2008], word alignment [graca et al.,
2008, ganchev et al., 2009, gra  ca et al., 2009b], and cross-lingual semantic
alignment [platt et al., 2010]. the framework was independently discovered
by bellare et al. [2009] as an approximation to ge constraints, under the name
alternating projections, and used under that name also by singh et al. [2010]
and druck and mccallum [2010] for information extraction. the framework
was also independently discovered by liang et al. [2009] as an approximation to

1in mann and mccallum [2007] the method was called expectation id173.

a bayesian model motivated by modeling prior information as measurements,
and applied to information extraction.

4 closely related frameworks

quadrianto et al. [2009] introduce a distribution matching framework very
closely related to ge constraints, with the idea that the model should pre-
dict the same feature expectations on labeled and undlabeled data for a set of
features, formalized as a kernel.

carlson et al. [2010] introduce a framework for semi-supervised learning
based on constraints, and trained with an iterative update algorithm very similar
to codl, but introducing only con   dent constraints as the algorithm progresses.
gupta and sarawagi [2011] introduce a framework for agreement that is
closely related to the pr-based work in ganchev et al. [2008], with a slightly
di   erent objective and a di   erent training algorithm.

references

k. bellare, g. druck, and a. mccallum. alternating projections for learning

with expectation constraints. in proc. uai, 2009.

kedar bellare and andrew mccallum. generalized expectation criteria for boot-
strapping extractors using record-text alignment. in emnlp, pages 131   140,
2009.

andrew carlson, justin betteridge, richard c. wang, estevam r. hruschka jr.,
and tom m. mitchell. coupled semi-supervised learning for information
extraction. in proceedings of the third acm international conference on
web search and data mining (wsdm), 2010.

m. chang, l. ratinov, and d. roth. guiding semi-supervision with constraint-

driven learning. in proc. acl, 2007.

ming-wei chang, lev ratinov, and dan roth. structured learning with con-

strained conditional models. 2010. in submission.

m.w. chang, l. ratinov, n. rizzolo, and d. roth. learning and id136
in proceedings of the national conference on arti   cial

with constraints.
intelligence (aaai). aaai, 2008.

g. druck, g. mann, and a. mccallum. learning from labeled features using

generalized expectation criteria. in proc. sigir, 2008.

g. druck, g. mann, and a. mccallum. semi-supervised learning of dependency
parsers using generalized expectation criteria. in proc. acl-ijcnlp, 2009a.

gregory druck and andrew mccallum. high-performance semi-supervised
learning using discriminatively constrained generative models. in proceedings
of the international conference on machine learning (icml 2010), pages
319   326, 2010.

gregory druck, burr settles, and andrew mccallum. active learning by label-

ing features. in emnlp, pages 81   90, 2009b.

k. ganchev, j. gra  ca, j. blitzer, and b. taskar. multi-view learning over

structured and non-identical outputs. in proc. uai, 2008.

k. ganchev, j. gillenwater, and b. taskar. dependency grammar induction via

bitext projection constraints. in proc. acl-ijcnlp, 2009.

kuzman ganchev, joo graa, jennifer gillenwater, and ben taskar. posterior
sparsity in unsupervised id33. journal of machine learn-
ing research, 11:2001   2049, july 2010. url http://jmlr.csail.mit.edu/
papers/v11/ganchev10a.html.

jennifer gillenwater, kuzman ganchev, joo graa, ben taskar, and fernando
pereira. sparsity in grammar induction. in nips workshop on grammar
induction, representation of language and language learning, 2009.

jennifer gillenwater, kuzman ganchev, joo graa, fernando pereira, and ben
taskar. posterior sparsity in unsupervised id33. journal of
machine learning research, 12:455   490, february 2011. url http://jmlr.
csail.mit.edu/papers/v12/gillenwater11a.html.

joao graca, kuzman ganchev, and ben taskar. expectation maximization
and posterior constraints. in j.c. platt, d. koller, y. singer, and s. roweis,
editors, advances in neural information processing systems 20, pages 569   
576. mit press, cambridge, ma, 2008.

j. gra  ca, k. ganchev, f. pereira, and b. taskar. parameter vs. posterior

sparisty in latent variable models. in proc. nips, 2009a.

j. gra  ca, k. ganchev, and b. taskar. postcat - posterior constrained alignment

toolkit. in the third machine translation marathon, 2009b.

rahul gupta and sunita sarawagi. joint training for open-domain extraction
on the web: exploiting overlap when supervision is limited. in proceedings of
the fourth acm international conference on web search and data mining
(wsdm), 2011.

p. liang, m. i. jordan, and d. klein. learning from measurements in exponen-

tial families. in proc. icml, 2009.

g. s. mann and a. mccallum. simple, robust, scalable semi-supervised learning

via expectation id173. in proc. icml, 2007.

g. s. mann and a. mccallum. generalized expectation criteria for semi-

supervised learning of conditional random    elds. in proc. acl, 2008.

tahira naseem, harr chen, regina barzilay, and mark johnson. using uni-
in proceedings of
versal linguistic knowledge to guide grammar induction.
the 2010 conference on empirical methods in natural language processing,
pages 1234   1244, cambridge, ma, october 2010. association for computa-
tional linguistics. url http://www.aclweb.org/anthology/d10-1120.

john platt, kristina toutanova, and wen-tau yih. translingual document rep-
resentations from discriminative projections. in proceedings of the 2010 con-
ference on empirical methods in natural language processing, pages 251   261,
cambridge, ma, october 2010. association for computational linguistics.
url http://www.aclweb.org/anthology/d10-1025.

novi quadrianto, james petterson, and alex smola. distribution matching for
transduction. in y. bengio, d. schuurmans, j. la   erty, c. k. i. williams,
and a. culotta, editors, advances in neural information processing systems
22, pages 1500   1508. mit press, 2009.

sameer singh, dustin hillard, and chris leggetter. minimally-supervised ex-
traction of entities from text advertisements.
in human language tech-
nologies: the 2010 annual conference of the north american chapter of
the association for computational linguistics, pages 73   81, los angeles,
california, june 2010. association for computational linguistics. url
http://www.aclweb.org/anthology/n10-1009.

