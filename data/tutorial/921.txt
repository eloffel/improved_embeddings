sentiment	analysis		

 

 

 

 

a literature survey 

by 

subhabrata	mukherjee	

roll	no:	10305061	

supervisor:	dr.	pushpak	bhattacharyya	

june	29,	2012	

indian	institute	of	technology,	bombay	

department	of	computer	science	and	engineering 

 

1 

abstract 

our day-to-day life has always been influenced by what people think. ideas and opinions of 

others have always affected our own opinions. the explosion of web 2.0 has led to increased 

activity  in  podcasting,  blogging,  tagging,  contributing  to  rss,  social  bookmarking,  and 

social networking. as a result there has been an eruption of interest in people to mine these 

vast  resources  of  data  for  opinions.  sentiment  analysis  or  opinion  mining  is  the 

computational  treatment  of  opinions,  sentiments  and  subjectivity  of  text.  in  this  report,  we 

take a look at the various challenges and applications of id31. we will discuss 

in  details  various  approaches  to  perform  a  computational  treatment  of  sentiments  and 

opinions.  various  supervised  or  data-driven  techniques  to  sa  like  na  ve  byes,  maximum 

id178, id166, and  voted id88s will be discussed and their strengths and drawbacks 

will be touched upon. we will also see a new dimension of analyzing sentiments by cognitive 

psychology  mainly  through  the  work  of  janyce  wiebe,  where  we  will  see  ways  to  detect 

subjectivity, perspective in narrative and understanding the discourse structure.  we will also 

study some specific topics in id31 and the contemporary works in those areas. 

 

 

 

 

 

 

 

2 

table of contents 

1. 

introduction ........................................................................................... 5 

1.1

  what is id31? ....................................................................................... 5 

1.2

  applications of id31............................................................................. 6 

1.3

  challenges for id31 .............................................................................. 7 

1.3.1 

implicit sentiment and sarcasm ........................................................................... 7 

1.3.2  domain dependency ............................................................................................ 7 

1.3.3 

1.3.4 

thwarted expectations ......................................................................................... 8 

pragmatics ............................................................................................................ 8 

1.3.5  world knowledge................................................................................................. 8 

1.3.6 

1.3.7 

subjectivity detection .......................................................................................... 9 

entity identification .............................................................................................. 9 

1.3.8  negation................................................................................................................ 9 

1.4

 

features for id31 ................................................................................ 10 

1.5

  machine learning approaches .................................................................................. 17 

1.6

  cognitive approaches (discourse) ............................................................................ 22 

1.6.1  what is subjectivity analysis, perspective and narratives? .............................. 22 

1.6.2  discourse-level analysis ................................................................................... 23 

1.6.3 

1.6.4 

1.6.5 

1.6.6 

subjective contexts ............................................................................................ 24 

identifying a subjective character ..................................................................... 25 

identifying perspective in narrative ................................................................... 28 

evaluation ........................................................................................................... 30 

1.7

 

id31 at iit bombay ............................................................................ 32 

1.8

  discourse specific id31 ..................................................................... 34 

1.9

 

feature specific id31 ......................................................................... 35 

1.10

  semantic similarity metrics ...................................................................................... 36 

1.11

  id31 in twitter ................................................................................... 37 

1.12

  extractive summarization .......................................................................................... 39 

1.13

  subjectivity analysis .................................................................................................. 39 

1.14

  concept expansion using wikipedia ......................................................................... 40 

1.15

  conclusions ................................................................................................................ 40 

2.  references ........................................................................................... 42 

 

 

3 

table	of	figures	

equation 1.1: sequence kernel ................................................................................................ 11 
equation 1.2: combining sequential kernels of different order ............................................ 11 
 

figure 1.1: ratio of true positives and false positives using subsequence kernel based 
voted id88s..................................................................................................................... 19 
figure 1.2: ratio of true positives and false positives using bag-of-features id166 ............. 19 
figure 1.3: distribution of voted id88 model scores by number of stars ................... 20 
 

table 1.1: word list containing positive and negative adjectives ......................................... 12 
table 1.2: phrase patterns used for extracting value phrases - turney (2002) ...................... 15 
table 1.3: accuracy comparison of different classifiers in sa on movie review dataset .. 18 
table 1.4: accuracy comparison of different classifiers, without boosting (skewed dataset)
 .................................................................................................................................................. 20 
table 1.5: accuracy comparison of different classifiers, with boosting (skewed dataset) . 20 
table 1.6: accuracy comparison of different classifiers, without boosting .......................... 21 
table 1.7: accuracy comparison of different features on id166 using a linear kernel ........ 22 
table 1.8: results for lonesome drove by interpretation ....................................................... 30 
table 1.9: results for lonesome drove by point-of-view operation ..................................... 31 
table 1.10: results for the magic of the glits by interpretation ............................................ 31 
table 1.11: results for the magic of the glits by point-of-view operations ........................ 32 
 

 

 

 

 

 

 

 

 

 

 

4 

1. introduction 

1.1

  what is id31? 

sentiment  analysis  is  a  natural  language  processing  and  information  extraction  task  that 

aims  to  obtain  writer   s  feelings  expressed  in  positive  or  negative  comments,  questions  and 

requests, by analyzing a large numbers of documents. generally speaking, id31 

aims to determine the attitude of a speaker or a writer with respect to some topic or the overall 

tonality  of  a  document.  in  recent  years,  the  exponential  increase  in  the  internet  usage  and 

exchange of public opinion is the driving force behind id31 today. the web is 

a  huge  repository  of  structured  and  unstructured  data.  the  analysis  of  this  data  to  extract 

latent public opinion and sentiment is a challenging task. 

liu et al. (2009) defines a sentiment or opinion as a quintuple-  

   <oj, fjk, soijkl, hi, tl >, where oj is a target object, fjk is a feature of the object oj, soijkl is 
the sentiment value of the opinion of the opinion holder hi on feature fjk of object oj at 
time tl, soijkl is +ve,-ve, or neutral, or a more granular rating, hi is an opinion holder, 
tl is the time when the opinion is expressed.    

the  analysis  of  sentiments  may  be  document  based  where  the  sentiment  in  the  entire 

document  is  summarized  as  positive,  negative  or  objective.  it  can  be  sentence  based  where 

individual  sentences,  bearing  sentiments,  in  the  text  are  classified.  sa  can  be  phrase  based 

where the phrases in a sentence are classified according to polarity. 

id31 identifies the phrases in a text that bears some sentiment. the author may 

speak about some objective facts or subjective opinions. it is necessary to distinguish between 

the  two.  sa  finds  the  subject  towards  whom  the  sentiment  is  directed.  a  text  may  contain 

many entities but it is necessary to find the entity towards which the sentiment is directed. it 

identifies  the  polarity  and  degree  of  the  sentiment.  sentiments  are  classified  as  objective 

(facts),  positive  (denotes  a  state  of  happiness,  bliss  or  satisfaction  on  part  of  the  writer)  or 

negative (denotes  a state of sorrow, dejection or  disappointment on part  of the writer). the 

sentiments  can  further  be  given  a  score  based  on  their  degree  of  positivity,  negativity  or 

objectivity. 

 

   

 

5 

1.2

  applications of id31 

word of mouth (wom) is the process of conveying information from person to person and 

plays  a  major  role  in  customer  buying  decisions.  in  commercial  situations,  wom  involves 

consumers  sharing  attitudes,  opinions,  or  reactions  about  businesses,  products,  or  services 

with  other  people.  wom  communication  functions  based  on  social  networking  and  trust. 

people  rely  on  families,  friends,  and  others  in  their  social  network.  research  also  indicates 

that  people  appear  to  trust  seemingly  disinterested  opinions  from  people  outside  their 

immediate social network, such as online reviews. this is where id31 comes 

into play. growing availability of opinion rich resources like online review sites, blogs, social 

networking sites have made this    decision-making process    easier for us. with explosion of 

web 2.0 platforms consumers have a soapbox of unprecedented  reach and power by which 

they can share opinions. major companies have realized these consumer voices affect shaping 

voices of other consumers. 

id31 thus finds its use in consumer market for product reviews, marketing for 

knowing consumer attitudes and trends, social media for finding general opinion about recent 

hot topics in town, movie to find whether a recently released movie is a hit.  

pang-lee et al. (2002) broadly classifies the applications into the following categories. 

a.  applications to review-related websites 

movie reviews, product reviews etc. 

b.  applications as a sub-component technology 

detecting  antagonistic,  heated  language  in  mails,  spam  detection,  context  sensitive 

information detection etc. 

c.  applications in business and government intelligence 

knowing consumer attitudes and trends 

d.  applications across different domains 

knowing public opinions for political leaders or their notions about rules and regulations 

in place etc. 

 

 

 

6 

1.3

  challenges for id31 

id31 approaches aim to extract positive and negative sentiment bearing words 

from  a  text  and  classify  the  text  as  positive,  negative  or  else  objective  if  it  cannot  find  any 

sentiment bearing words. in this respect, it can be thought of as a text categorization task.  in 

text  classification  there  are  many  classes  corresponding  to  different  topics  whereas  in 

id31 we have only 3 broad classes. thus it seems id31 is easier 

than text classification which is not quite the case. the general challenges can be summarized 

as: 

1.3.1  implicit sentiment and sarcasm 

a  sentence  may  have  an  implicit  sentiment  even  without  the  presence  of  any  sentiment 

bearing words. consider the following examples. 

how can anyone sit through this movie? 

one should question the stability of mind of the writer who wrote this book. 

both  the  above  sentences  do  not  explicitly  carry  any  negative  sentiment  bearing  words 

although  both  are  negative  sentences.  thus  identifying  semantics  is  more  important  in  sa 

than syntax detection. 

1.3.2  domain dependency  

there  are  many  words  whose  polarity  changes  from  domain  to  domain.  consider  the 

following examples. 

the story was unpredictable. 

the steering of the car is unpredictable. 

go read the book. 

in the first example, the sentiment conveyed is positive whereas the sentiment conveyed in the 

second  is  negative.  the  third  example  has  a  positive  sentiment  in  the  book  domain  but  a 

negative sentiment in the movie domain (where the director is being asked to go and read the 

book). 

 

 

7 

1.3.3  thwarted expectations  

sometimes  the  author  deliberately  sets  up  context  only  to  refute  it  at  the  end.  consider  the 

following example: 

this  film  should  be  brilliant.  it  sounds  like  a  great  plot,  the  actors  are  first  grade,  and  the 

supporting  cast  is  good  as  well,  and  stallone  is  attempting  to  deliver  a  good  performance. 

however, it can   t hold up. 

inspite  of  the  presence  of  words  that  are  positive  in  orientation  the  overall  sentiment  is 

negative  because  of  the  crucial  last  sentence,  whereas  in  traditional  text  classification  this 

would have been classified as positive as  term  frequency is more important there than  term 

presence. 

1.3.4  pragmatics 

it  is  important  to  detect  the  pragmatics  of  user  opinion  which  may  change  the  sentiment 

thoroughly. consider the following examples: 

i just finished watching barca destroy ac milan 

that final completely destroyed me. 

capitalization  can  be  used  with  subtlety  to  denote  sentiment.  the  first  example  denotes  a 

positive  sentiment  whereas  the  second  denotes  a  negative  sentiment.  there  are  many  other 

ways of expressing pragmatism. 

1.3.5  world knowledge 

often  world  knowledge  needs  to  be  incorporated  in  the  system  for  detecting  sentiments. 

consider the following examples: 

he is a frankenstein. 

just finished doctor zhivago for the first time and all i can say is russia sucks. 

the  first  sentence  depicts  a  negative  sentiment  whereas  the  second  one  depicts  a  positive 

sentiment.  but  one  has  to  know  about  frankenstein  and  doctor  zhivago  to  find  out  the 

sentiment. 

 

8 

1.3.6  subjectivity detection 

this is to differentiate between opinionated and non-opinionated text. this is used to enhance 

the  performance  of  the  system  by  including  a  subjectivity  detection  module  to  filter  out 

objective facts. but this is often difficult to do. consider the following examples: 

i hate love stories. 

i do not like the movie    i hate stories   . 

the first example presents an objective fact whereas the second example depicts the opinion 

about a particular movie. 

1.3.7  entity identification 

a text or sentence may have multiple entities. it is extremely important to find out the entity 

towards which the opinion is directed. consider the following examples. 

 samsung is better than nokia 

ram defeated hari in football. 

the  examples  are  positive  for  samsung  and  ram  respectively  but  negative  for  nokia  and 

hari.  

1.3.8  negation 

handling negation is a challenging task in sa. negation can be expressed in subtle ways even 

without the explicit use of any negative word. a method often followed in handling negation 

explicitly in sentences like    i do not like the movie   ,  is to reverse the polarity of all the words 

appearing after the negation operator (like not). but this does not work for    i do not like the 

acting but i like the direction   . so we need to consider the scope of negation as well, which 

extends  only  till  but  here.  so  the  thing  that  can  be  done  is  to  change  polarity  of  all  words 

appearing  after  a  negation  word  till  another  negation  word  appears.  but  still  there  can  be 

problems. for example, in the sentence    not only did i like the acting, but also the direction   , 

the  polarity  is  not  reversed  after     not     due  to  the  presence  of     only   .  so  this  type  of 

combinations of    not    with other words like    only    has to be kept in mind while designing the 

algorithm. 

 

 

9 

1.4

  features for id31 

feature  engineering  is  an  extremely  basic  and  essential  task  for  sentiment  analysis. 

converting a piece of text to a feature vector is the basic step in any data driven approach to 

sa.  in  the  following  section  we  will  see  some  commonly  used  features  used  in  sentiment 

analysis and their critiques. 

term presence vs. term frequency 

term frequency has always been considered essential in traditional information retrieval and 

text  classification  tasks.  but  pang-lee  et  al.  (2002)  found  that  term  presence  is  more 

important to id31 than term frequency. that is, binary-valued feature vectors in 

which the entries merely indicate whether a term occurs (value 1) or not (value 0). this is not 

counter-intuitive  as  in  the  numerous  examples  we  saw  before  that  the  presence  of  even  a 

single  string  sentiment  bearing  words  can  reverse  the  polarity  of  the  entire  sentence.  it  has 

also  been  seen  that  the  occurrence  of  rare  words  contain  more  information  than  frequently 

occurring words, a phenomenon called hapax legomena. 

term position 

words  appearing  in  certain  positions  in  the  text  carry  more  sentiment  or  weightage  than 

words  appearing  elsewhere.  this  is  similar  to  ir  where  words  appearing  in  topic  titles, 

subtitles or abstracts etc are given more weightage than those appearing in the body. in the 

example  given  in  section  1.3.c,  although  the  text  contains  positive  words  throughout,  the 

presence of a negative sentiment at the end sentence plays the deciding role in determining the 
sentiment. thus generally words appearing in the 1st few sentences and last few sentences in a 
text are given more weightage than those appearing elsewhere. 

id165 features 

id165s  are  capable  of  capturing  context  to  some  extent  and  are  widely  used  in  natural 

language  processing  tasks.  whether  higher  order  id165s  are  useful  is  a  matter  of  debate. 

pang et al. (2002) reported that unigrams outperform bigrams when classifying movie reviews 

by  sentiment  polarity,  but  dave  et  al.  (2003)  found  that  in  some  settings,  bigrams  and 

trigrams perform better. 

subsequence kernels 

most  of  the  works  on  sentiment  analysis  use  word  or  sentence  level  model,  the  results  of 

which  are  averaged  across  all  words/sentences/id165s  in  order  to  produce  a  single  model 

 

10 

output for each review. bikel et al. (2007) use subsequences. the intuition is that the feature 

space implicitly captured by subsequence kernels is sufficiently rich to obviate the need for 

explicit knowledge engineering or modeling of word- or sentence-level sentiment. 

 

word  sequence  kernels  of  order  n  are  a  weighted  sum  over  all  possible  word 

sequences of length n that occur in both of the strings being compared. 

 

mathematically, the word sequence kernel is defined as    

equation 1.1: sequence kernel 

 

where     is a kernel parameter that can be thought of as a gap penalty, i refers to a vector of 

length n that consists of the indices of string s that correspond to the subsequence u. and, the 

value  i[n]       i[1]  +  1  can  be  regarded  as  the  total  length  of  the  span  of  s  that  constitutes  a 

particular occurrence of the subsequence u. following rousu et al. (2005), they combine the 

kernels of orders one through four through an exponential weighting, 

equation 1.2: combining sequential kernels of different order 

 

parts of speech 

parts of speech information is most commonly exploited in all nlp tasks. one of the most 

important reasons is that they provide a crude form of id51.  

adjectives only 

adjectives have been used most frequently as features amongst all parts of speech. a strong 

correlation  between  adjectives  and  subjectivity  has  been  found.  although  all  the  parts  of 

speech are important people most commonly used adjectives to depict most of the sentiments 

and a high accuracy have been reported by all the works concentrating on only adjectives for 

feature  generation.  pang  lee  et  al.  (2002)  achieved  as  accuracy  of  around  82.8%  in  movie 

review domains using only adjectives in movie review domains. 

 

proposed word lists 

human 1  positive: dazzling, brilliant, phenomenal, excellent, fantastic 

negative: suck, terrible, awful, unwatchable, hideous  

 

11 

human 2  positive: gripping, mesmerizing, riveting, spectacular, cool, awesome, thrilling, 

badass, excellent, moving, exciting 

negative: bad, clich  d, sucks, boring, stupid, slow 

table 1.1: word list containing positive and negative adjectives 

adjective-adverb combination  

most  of  the  adverbs  have  no  prior  polarity.  but  when  they  occur  with  sentiment  bearing 

adjectives, they can play a major role in determining the sentiment of a sentence. benamara et 

al. (2007) have shown how the adverbs alter the sentiment value of the adjective that they are 

used with. adverbs of degree, on the basis of the extent to which they modify this sentiment 

value, are classified as: 

o  adverbs of affirmation: certainly, totally 
o  adverbs of doubt: maybe, probably 
o  strongly intensifying adverbs: exceedingly, immensely 
o  weakly intensifying adverbs: barely, slightly 
o  negation and minimizers: never 

the work defined two types of aacs: 

1.  unary  aacs:  containing  one  adverb  and  one  adjective.  the  sentiment  score  of  the 

adjective is modified using the adverb adjoining it. 

2.  binary aacs: containing more than one adverb and an adjective. the sentiment score 

of the aac is calculated by iteratively modifying the score of the adjective as each 

adverb gets added to it. this is equivalent to defining a binary aac in terms of two 

unary aacs iteratively defined. 

to calculate the sentiment value of an aac, a score is associated with it based on the score of 

the  adjective  and  the  adverb.  certain  axiomatic  rules  are  specified  to  specify  the  way  the 

adverbs modify the sentiment of the adjective. one such axiom can be stated as: 

   each weakly intensifying adverb and each adverb of doubt has a score less than or equal to 

each strongly intensifying adverb / adverb of affirmation.    

then, certain functions are described in order to quantify the axioms. a function f takes an 

adjective-adverb pair and returns its resultant score. 

1.  affirmative and strongly intensifying adverbs 

 

12 

for  example,  f  value  for     immensely  good     is  more  positive  than  the  score  for  the  positive 

 

adjective    good   . 

2.  weakly intensifying adverbs 

for  example,  f  value  for     barely  good     is  more  negative  than  the  score  for  the  positive 

adjective    good   . this is the effect that the weakly intensifying adverb has. 

 

3.  adverbs of doubt 

for example, f value for    probably good    is less than    immensely good    

 

4.  minimizers 

for example,    hardly good    is less positive than the positive adjective    good    

 

scoring algorithms 

a. variable scoring algorithm: 

the algorithm modifies the score of the aac using the function f defined as follows: 

 

13 

algorithm 1.1: scoring algorithm for adjective adverb combination 

thus, the resultant score of the aac is the score of the adjective which is suitably adjusted 

 

with the effect of the adverb. 

b. adjective priority scoring algorithm: 

they give priority to adjectives over the adverbs and modify the score of the adjective by a 

weight  r.  this  weight  r  decides  the  extent  to  which  an  adverb  influences  the  score  of  an 

 

adjective. 

c. adverb priority scoring algorithm   

topic-oriented features  

 

bag-of-words and phrases are extensively used as features. but in many domains, individual 

phrase  values  bear  little  relation  with  overall  text  sentiment.  a  challenge  in  sentiment 

 

14 

analysis of a text is to exploit those aspects of the text which are in some way representative 

of  the  tone  of  the  whole  text.  often  misleading  phrases  (thwarted  expectations)  are  used  to 

reinforce sentiments. using bag-of-words or individual phrases will not be able to distinguish 

between what is said locally in phrases and what is meant globally in the text like drawing of 

contrasts  between  the  reviewed  entity  and  other  entities,  sarcasm,  understatement,  and 

digressions,  all of which are used in abundance in many discourse domains. these features 

were developed by turney et al. (2002). 

1  semantic orientation with pmi 

semantic  orientation  (so)  refers  to  a  real  number  measure  of  the  positive  or  negative 

sentiment expressed by a word or phrase. the value phrases are phrases that are the source of 

so  values.  once  the  desired  value  phrases  have  been  extracted  from  the  text,  each  one  is 

assigned an so value. the so of a phrase is determined based upon the phrase   s pointwise 

mutual  information  (pmi)  with  the  words   excellent     and   poor   .  pmi  is  defined  by  church 

and hanks (1989) as follows: 

pmi(w1,w2)=log2(p(w1 & w2)/p(w1)p(w2)).  
the so for a phrase is the difference between its pmi with the word   excellent    and its pmi 

with the word   poor.    i.e 

so (phrase)=pmi (phrase,   excellent   )- pmi (phrase,   poor   ) 

intuitively,  this  yields  values  above  zero  for  phrases  with  greater  pmi  with  the 

word   excellent    and below zero for greater pmi with   poor   . a so 

value of zero would indicate a completely neutral semantic orientation. 

 

1. 

first word 

second word 

third word (not extracted) 

jj 

nn or nns 

anything 

2.  rb, rbr or rbs 

3. 

4. 

jj 

nn or nns 

jj 

jj 

jj 

not nn nor nns 

not nn nor nns 

not nn or nns 

5.  rb, rbr or rbs  vb, vbd, vbn or vbc 

anything 

table 1.2: phrase patterns used for extracting value phrases - turney (2002) 

 

 

15 

osgood semantic differentiation with id138 

id138  relationships  are  used  to  derive  three  values  pertinent  to  the  emotive  meaning  of 

adjectives.  the  three  values  correspond  to  the  potency  (strong  or  weak),  activity  (active  or 

passive) and the evaluative (good or bad) factors introduced in charles osgood   s theory of 

semantic  differentiation  (osgood  et  al.,  1957).  these  values  are  derived  by  measuring  the 

relative  minimal  path  length  (mpl)  in  id138  between  the  adjective  in  question  and  the 

pair of words appropriate for the given factor. in the case of the evaluative factor (eva) for 

example, the comparison is between the mpl between the adjective and   good    and the mpl 

between the adjective and   bad   . the values can be averaged over all the adjectives in a text, 

yielding three real valued feature values for the text. 

   sentiment expressed with regard to a particular subject can best be identified with reference 

to the subject itself   ,  natsukawa and yi (2003). 

in some application domains, it is known in advance what the topic is toward which sentiment 

is to be evaluated. this can be exploited by creating several classes of features based upon the 

so values of phrases given their position in relation to the topic of the text. in opinionated 

texts  there  is  generally  a  single  primary  subject  about  which  the  opinion  is  favorable  or 

unfavorable. but secondary subjects are also useful to some extent. 

ex: opinion (reference) to author in a book review may be useful in a book review. 

ex: in a product review, the attitude towards the company which manufactures the product 

may be pertinent.  

the work considers the following classes of features: 

a.  turney value  

the average value of all value phrases    so values for the text 

b.  in sentence with this work  

the average value of all value phrases which occur in the same sentence as a reference to the 

work being reviewed 

c.  following this work  

the average value of all value phrases which follow a reference to the work being reviewed 

directly, or separated only by the copula or a preposition 

d.  preceding this work  

 

16 

the average value of all value phrases which precede a reference to the work being reviewed 

directly, or separated only by the copula or a preposition 

e.  in sentence with this artist 

with reference to the artist 

f.  following this artist  

with reference to the artist 

g.  preceding this artist  

with reference to the artist 

h.  text-wide eva  

the average eva value of all adjectives in a text 

i.  text-wide pot  

the average pot value of all adjectives in a text 

j.  text-wide act  

the average act value of all adjectives in a text 

k.  topic-sentence eva  

the average eva value of all adjectives which share a sentence with the topic of the text 

l.  topic-sentence pot  

the average pot value of all adjectives which share a sentence with the topic of the text 

m.  topic-sentence act  

the average act value of all adjectives which share a sentence with the topic of the text 

1.5

  machine learning approaches 

in  his  work,  pang  lee  et  al.  (2002,  2004),  compared  the  performance  of  na  ve  bayes, 

maximum id178 and support vector machines in sa on different features like considering 

only  unigrams,  bigrams,  combination  of  both,  incorporating  parts  of  speech  and  position 

information, taking only adjectives etc. the result has been summarized in the table 1.3. 

it is observed from the results that: 

a.  feature presence is more important than feature frequency. 
b.  using bigrams the accuracy actually falls. 
c.  accuracy improves if all the frequently occurring words from all parts of speech are 

taken, not only adjectives. 

17 

 

d.  incorporating position information increases accuracy. 
e.  when the feature space is small, na  ve bayes performs better than id166. but id166   s 

perform better when feature space is increased. 

when feature space is increased, maximum id178 may perform better than na  ve bayes but 

it may also suffer from overfitting. 

features 

n umber of 

features 

frequency or 

presence? 

nb 

me 

id166 

bigrams 

unigrams+bigrams 

unigrams 

unigrams 

n/a 

pres. 

freq. 

32330 

16165 

16165 

78.7 
81.0 

72.8 
82.9 
82.7 
77.1 
81.9 
75.1 
81.4 
81.6 
table 1.3: accuracy comparison of different classifiers in sa on movie review dataset 

80.8 
77.4 
80.4 
77.7 
81.0 

22430 

16165 

16695 

2633 

2633 

pres. 

pres. 

pres. 

pres. 

pres. 

pres. 

77.0 

80.3 

81.0 

80.1 

81.5 

80.4 

80.6 

77.3 

top 2633 unigrams 

unigrams+position 

unigrams+pos 

adjectives 

bikel et al. (2007) implemented a subsequence kernel based voted id88 and compares 

its performance with standard support vector machines. it is observed that as the number of 

true  positives  increase,  the  increase  in  the  number  of  false  positives  is  much  less  in 

subsequence  kernel  based  voted  id88s  compared  to  the  bag-of-words  based  id166   s 

where the increase in false positives with true positives is almost linear. their model, despite 

being trained only on the extreme one and five star reviews, formed an excellent continuum 

over  reviews  with  intermediate  star  ratings,  as  shown  in  the  figure  below.  the  authors 

comment that    it is rare that we see such behavior associated with lexical features which are 

typically regarded as discrete and combinatorial. finally, we note that the voted id88 is 

making distinctions that humans found difficult      . 

 

18 

figure 1.1: ratio of true positives and false positives using subsequence kernel based 

voted id88s 

 

figure 1.2: ratio of true positives and false positives using bag-of-features id166 

 

 

19 

 

figure 1.3: distribution of voted id88 model scores by number of stars 

pande,  iyer  et  al.  performs  a  detailed  comparison  of  the  different  classifiers  in  two  phases 

under two settings. in phase 1, the classifiers are made to distinguish between subjective and 

objective  documents.  in  phase  2,  the  classifiers  are  made  to  classify  positive  from  negative 

documents  filtered  by  phase  1.  in  each  phase  classifiers  have  been  tested  without  and  with 

boosting  to  enhance  performance.  the  classifiers  tested  are  bayesian  logistic  regression 

(blr) with gaussian and laplacian prior, na  ve bayes, support vector machines with linear, 

polynomial and radial basis functions kernels and voted id88s. 

avg f1  avg acc.  max acc. 
classifier 
0.4985  78.66 
na  ve bayes 
0.4700  80.83 
id166(linear) 
0.4536  79.71 
id166(poly) 
0.0864  78.05 
id166(rbf) 
voted id88  0.4300  78.64 

81.55 
83.42 
81.97 
79.4 
83.66 

table 1.4: accuracy comparison of different classifiers, without boosting (skewed dataset) 

avg f1  avg acc.  max acc. 
classifier 
0.515 
blr(gauss) 
0.510 
blr(laplace) 
0.563 
na  ve bayes 
0.557 
id166(linear) 
0.499 
id166(poly) 
voted id88  0.508 

80.09 
79.98 
75.63 
80.2 
79.22 
78.70 

85.51 
87.04 
84.18 
85.44 
83.37 
83.62 

table 1.5: accuracy comparison of different classifiers, with boosting (skewed dataset) 

 

20 

avg f1  avg acc.  max acc. 
classifier 
0.882 
83.91 
na  ve bayes 
0.880 
83.29 
id166(linear) 
0.8571  80.80 
id166(poly) 
0.757 
68.22 
id166(rbf) 
82.96 
voted id88  0.875 

84.80 
85.736 
82.946 
74.573 
85.43 

table 1.6: accuracy comparison of different classifiers, without boosting  

(balanced dataset) 

in phase 1, it is observed that: 
1.  accuracy  very  high  but  f1  scores  are  low  due  to  skewed  data  (number  of  objective 

samples were 10,000 whereas number of polar samples were 25000) due to which either 

recall is low or false-positive rate is considerably high. 

2.  without boosting, undersampling or oversampling maximum recall attained was 65%. 
3.  lowest recall was attained for feature based on gain ratio and/or id166 with rbf kernel. 
4.  with boosting highest recall attained was 85% with false negative rate 30%. 
5.  na  ve bayes and  smo gave the best recall. 
6.  voted id88s, blr gave less than 65% recall 
7.  voted id88s and id166(linear) give the best accuracy. 
8.  it  is  astonishing  to  see  id166(rbf)  give  the  lowest  accuracy.  the  reason  may  be 

overfitting. 

in phase 2, it is observed that: 
1.  id166 with rbf again performs badly. 

2.  id166 (linear) and voted id88s again have the best accuracy. they are found to give 

good results with both information gain, chi-square feature selection methods. 

3.  na  ve bayes favors chi-square over information gain. 

4.  boosting does not improve performance much. 

mullen  et  al.  (2004)  used  support  vector  machines  with  diverse  information  measures  by 

using features like the pmi, lemma, turney, osgood values along with other topic oriented 

features. 

it is observed that: 
1.  using only turney values, a high accuracy can be achieved. 
2.  the addition of osgood values does not seem to yield improvement in any of the models. 
3.  using only lemmas instead of unigrams result in a much better performance. 

 

21 

4.  the  inclusion  of  all  pmi  values  with  lemmas  outperforms  the  use  of  only  the  turney 

values, suggesting that the incorporation of the available topic relations is helpful. 
5.  the best performance is achieved by using lemmas and pmi or osgood values. 

5 folds   10 folds   20 folds   100 folds 
model  
72% 
turney values only  
69% 
all (this work and this artist) pmi  
71% 
this work pmi  
64% 
all osgood  
72% 
all pmi and osgood  
82% 
unigrams  
82% 
unigrams, pmi, osgood  
84% 
lemmas  
84% 
lemmas and osgood  
84% 
lemmas and turney  
84% 
lemmas, turney, text wide osgood  
86% 
lemmas, pmi, osgood  
86% 
lemmas and pmi  
hybrid id166 (pmi/osgood and lemmas)  
89% 
table 1.7: accuracy comparison of different features on id166 using a linear kernel 

72% 
70% 
72% 
64% 
74% 
79% 
81% 
83% 
83% 
84% 
84% 
84% 
84% 
86% 

72% 
68% 
70% 
65% 
74% 
78% 
82% 
84% 
84% 
84% 
84% 
84% 
85% 
84% 

73% 
70% 
69% 
64% 
71% 
80% 
80% 
85% 
84% 
85% 
85% 
85% 
85% 
87% 

1.6

  cognitive approaches (discourse) 

1.6.1  what is subjectivity analysis, perspective and narratives? 

the  input  to  the  sentiment  classifier  is  always  an  opinionated  text  i.e.  a  text  containing 

positive  or  negative  sentiment.  thus  one  needs  to  filter  out  objective  facts  from  a  text  and 

subject only the opinions to the sentiment classifier. this work of extracting or filtering out 

the objective facts from subjective opinions is called subjectivity analysis. 

 

a piece of text often contains other person   s point of view or accounts from a third 

person  which  contain  a  gamut  of  emotions  or  opinions  from  different  characters  or 

perspectives. thus it is important to identify the character to who an opinion can be attributed 

to. thus the objective here is not only to detect whether a piece of text is opinionated or not 

but also who is responsible for that opinion.  

 

a narrative is a story that is created in a constructive format. it describes a sequence 

of fictional and non-fictional events. a narrative can also be told by a character within a larger 

narrative.  it  is  the fiction-writing  mode whereby  the  narrator  communicates  directly  to  the 

reader.  

a perspective is the point of view. narrative is told from the perspective of one or more of its 

characters. it can also contain passages not told from the perspective of any character. 

 

22 

subjective sentences portray a character   s thoughts     represented thoughts or present a scene 

perceived by the character     represented perception, private state such as seeing, wanting or 

feeling ill     that is some perceptual, psychological or experiential state not open to objective 

observation or verification. 

 

objective  sentences  present  the  story  directly,  rather  than  through  thoughts  or 

perceptions of a character. 

thus subjective sentences take a character   s psychological point of view or pov (uspensky 

1973).  for  narrative  understanding  it  is  absolutely  essential  to  track  the  pov  as  it 

distinguishes between beliefs of characters and facts of the story. 

1.6.2  discourse-level analysis 

but in order to identify the character and its perspective a sentence level analysis will not do. 

this demands a discourse level analysis as the sentences are not always explicitly marked by 

subjective  elements  and  the  subjective  sentences  do  not  directly  imply  the  subjective 

character, wiebe et al. (1991). 

example:  [1.1]he  wanted  to  talk  to  dennys.    [1.2]how  were  they  going  to  be  able  to  get 

home from this strange desert land into which they had been cast and which was heaven knew 

where in all the countless solar systems in all the countless galaxies? [l'engle, many waters, 

p. 91] 

sentence (1.2) is a represented thought, and (2.2) is a represented perception, presenting what 

the character sees as he sees it, yet neither is explicitly marked as such. also, neither indicates 

who the subjective character is.  

subjective  sentences  which  do  no  contain  any  subjective  elements  or  subjective  character 

appear in the midst of other subjective sentences attributed to the same subjective character. 

thus subjectivity needs to be determined at discourse level. instead of subjective or objective 

sentences  we  have  subjective  and  objective  contexts  consisting  of  1  or  more  subjective  or 

objective sentences attributed to the same subjective character or objective sentences. 

 

there  are  regularities in a way the author initiate, continue or resumes a character   s 

pov.    certain  combination  of  the  sentence  features  (like  tense,  aspect,  lexical  items 

expressing  subjectivity,  identity  of  actors  or  experiencers  of  those  states  of  affairs)  and  the 

current  context  (like  whether  the  previous  sentence  was  subjective  or  objective  or  whether 

there was a scene break or paragraph break) helps in detecting the continuity of the pov of a 

character. 

 

23 

the pov tracking needs an extensive discourse analysis. for example, the use of a full noun 

when a pronoun would have sufficed denotes that change in pov has occurred. on the other 

hand use of anaphoric pronoun denotes continuity in current pov.   

 

the private state reports of a character, that expresses whether the subjective character 

is ill or angry, can only be reported. now, if   john was furious    is the subjective statement of 

a  character  mary,  it  is  only  her  represented  thought  or  opinion  about  john.  thus  the 

distinction  between  private  state  report  and  represented  thought  is  essential  for  discourse 

processing. this is because, as the subjective character is always the subject of a private state 

report,  pronouns  can  be  used  to  refer  him  despite  references  to  some  other  entity  of  same 

number and gender. but in a represented thought the referent of a pronoun can be someone in 

an earlier represented thought. 

example: 

   dwayne  wasn   t  sure  what  john  was  scared  of.  what  in  the  arcade  could  scare  a  boy  like 

that? he could see tear   s in john   s eyes. he could tell they were tears because    . maybe that 

was why he was crying. 

 

   i want to leave   , he said.    

here  the  last  sentence  is  objective  but  the  previous  sentences  are  subjective  sentences  of 

dwayne.    he    in the last sentence refers to dwayne even though john is the last previously 

mentioned entity. this suggests there is a change of pov and discourse analysis is required to 

detect it.  

1.6.3  subjective contexts 

recognition  of  a  subjective  context  requires  the presence  of  linguistic  signals.  wiebe  et  al. 

(1988) recognizes the following subjective signals.. 

a. psychological verbs, actions, adjectives and perceptual verbs 
1.  psychological verbs (e.g. 'think', 'wonder', 'realize', 'went') 
2.  perceptual verbs (e.g.. 'see', 'hear')  
3.  psychological adjectives (e.g., 'delighted', 'happy', 'jealous', 'scared')  
4.  psychological actions- (e.g.,   he smiled   ,   she gasped   ,   she winced    

a.  subjective elements  

1.  exclamations, which express emotions 
2.  questions, which express wonder 

 

24 

3.  epithets, such as 'the bastard', which express some qualification of the referent.  
4.  kinship terms, e.g., 'daddy', 'morn', and 'aunt margaret', which express a relationship to 

the referee.  

5.  evaluative  adjectives,  which  express  an  attitude  toward  the  referent,  e.g.,  'ghastly', 

'surprising', 'poor', and 'damned',  

6.  intensifiers such as 'too', 'quite', and 'so' are also evaluative 
7.  emphasizers like   really   ,   just    

b.  more subjective elements 

1.  modal  verbs  of  obligation,  possibility,  and  necessity.  for  example,  'should       is  a  modal 

verb of obligation)  

2.  content  (or  attitudinal)  disjuncts  which  comment  on  the  content  of  the  utterance.  for 

example,   likely', 'maybe', 'probably', and 'perhaps' express some degree of doubt 

3.  conjuncts,  which  comment  on  the  connection  between  items.  for  example,  'anyhow', 

'anyway', 'still', and 'after all' express concession 

4.  uses  of  'this',  'that',  'these',  and  'those'  that  robin  lakoff  (1974)  has  identified  as 

emotional deixis.  

in  conversation,  they  are   generally  linked  to  the  speaker's  emotional  involvement  in  the 

subject-matter of his utterance    (lakoff 1974: 347); in thlrd-person narrative, they are linked 

to  the  subjective  character's  emotional  involvement  in  the  subject  matter  of  his  thoughts  or 

perceptions. 

examples: 

[2.1]she [hannah] winced as she heard them crash to the platform. 

[3.1]he could tell they were tears because his eyes were too shiny. too round. 

[4.1]jody managed a frail smile. [4.2]she was a little bit ashamed. [4.3] she should really try 

to be more cheerful for aunt margaret's sake. [4.4]after all, aunt margaret had troubles of 

her own--she was the mother of that ghastly dill. 

in  the  above  examples,  the  words  in  bold  are  subjective  elements.  the  presence  of  a 

subjective element indicates the presence of a subjective character. 

1.6.4  identifying a subjective character  

subjective  character  can  sometimes  be  directly  identified  in  a  sentence  (for  example  when 

there is a narrative parenthetical), wiebe et al. (1990). 

 

25 

if it is not identifiable, then it is one of the 2 previously mentioned characters- 

1. the subjective character of the previous subjective sentence 

it either continues the pov of the subjective character or resumes it. 

2. actor of an action denoted by a previous objective sentence 

examples:  

[5.1]why,  jake,you  lazy  bean,     augustus  said,  [5.2]  and  walked  off.  [5.3]  jake  had  a 

stubborn streak in him, [5.4]and once it was activated even call could seldom do much with 

him. 

(5.3) and (5.4) represent the point of view of augustus, the actor of an action denoted by a 

previous  objective  sentence,  (5.1).  but  the  last  subjective  character  is  jake,  so  augustus's 

point of view is initiated, not merely resumed or continued. 

 

in  order  to  identify  the  subjective  character  one  needs  to  keep  track  of  expected 

subjective  characters  encountered.  however  drastic  spatial  and  temporal  discontinuities  can 

block the continuation or resumption of a character   s pov. 

ex: scene break, paragraph break 

the  subjective  character  may  also  be  identified  from  a  private-state  sentence.  it  can  be  the 

experiencer  of  a  private  state  sentence.  exception  occurs  when  a  subjective  sentence  is 

followed by a private state report without paragraph break where the experiencer is different 

from the subjective character. 

example of a scene break: 

[6.l]drown  me?     augustus  said. [6.2]  why  if'  anybody  had  tried  it,  those  girls  would  have 

clawed  them  to  shreds.     [6.3]  he  knew  call  was  mad,  [6.4]  but  wasn't  much  inclined  to 

humor him. [6.5] it was his dinner table as much as call's, [6.6] and if call didn't like the 

conversation he could go to bed.  

 

[6.7] call knew there was no point in arguing. [6.8] that was what augustus wanted: 

argument.  [6.9]  he  didn   t  really  care  what  the  question  was,  [6.10]  and  it  made  no  great 

difference to him which side he was on. [6.11] he just plain loved to argue. 

sentences (6.1)-(6.2) are augustus's subjective sentences and (6.7)-(6.11) are call's. so, (6.7) 

initiates a new point of view. it is a private-state sentence and the subjective character, call, is 

the experiencer of the private state denoted. 

 

26 

subjective character of a private state report is always the experiencer which can be directly 

determined  from  the  sentence.  but  such  cannot  be  said  in  case  of  a  represented  thought.  if 

private-state report is indicated to be  a represented thought, then subjective character is the 

expected subjective character. but an important aspect is the scope of the subjective element. 

consider the following examples. 

[7.1]  japheth,  evidently  realizing  that  they  were  no  longer  behind  him,  turned  around 

[7.2]and jogged back toward them, seemingly cool and unwinded. 

[8.1]urgh! she) the [girl] thought. [8.2]how could the poor thing have married him in the 

first place? 

[8.3]johnnie martin could not believe that he was seeing that old bag's black eyes sparkling 

with disgust and unsheathed contempt at him. 

sentence (8.3) is a private-state report and the subjective character is the experiencer (johnnie 

martin).  this  is  so  even  though  (8.3)  contains  the  subjective  element  'old  bag'  and  even 

though there is an expected subjective character (the girl) when it is encountered. because 'old 

bag'  appears  within  the  scope  of  the  private-state  term  'believe',  it  is  not  considered  in 

identifying the subjective character. on the other hand, the subjective clement 'evidently ' in 

(7.1) is not in the scope of 'realizing' (i.e., it is non-subordinated), so it can be used to identify 

the subjective character.

if the sentence contains a narrative parenthetical then  

 

sc is the subject of the parenthetical 

else if the sentence is a private-state sentence then 

if it has a non-subordinated subjective clement 

or the text situation is continuing-subjective then 

 

sc is identified from the previous context 

else sc is the experiencer 

end if 

 

 

 

 

 

else  

 

sc is identified from the previous context 

end if 

 

algorithm 1.2: to identify the subjective character 

27 

 

 

if there are two expected subjective characters then 

 

 

 

 

if the sentence is about the last active character then 

 

sc is the last subjective character 

else sc is the last active character 

end if 

else if there is an expected subjective character then 

 

sc is the expected subjective character 

else sc is unidentified 

end if 

 

 

algorithm 1.3: to identify the subjective character from previous context 

1.6.5  identifying perspective in narrative 

a belief space is accessed by a stack of individuals. it consists of what the bottom member of 

the stack believes that what the top member believes. 

the reader is always the bottom member. the belief space corresponding to a stack consisting 

only of the reader  contains the set of propositions that the reader believes are true. the cp 

determines the current belief space with respect to which references are understood. 

if 'x' is an indefinite noun phrase of the form 'a y' then  

 

 

create a new concept, n; build in cp's belief space the proposition that n is a y; 

return n 

else if 'x' is a definite noun phrase or proper name, 

 

 

 

 

 

 

if a proposition that n is x can be found in the cp's belief space, 

 

return n 

else if a proposition that n is x can be found in a belief space other than the 

cp's, then add the found proposition to the cp's belief space; 

 

return n 

else create a new concept, n; build in cp's belief space the proposition that n is x; 

return n 

algorithm 1.4: algorithm for understanding a non-anaphoric, specific reference 'x' in 

 

third-person narrative 

28 

 

 

if  a reference is a subjective element, such as 'the bastard', it cannot be understood entirely 

propositionally, since it expresses subjectivity. how it should be understood depends on the 

particular subjective element. 

 

it does not understand anaphoric references. however, anaphor comprehension can be 

affected by perspective.  

examples: 

[9.1]the man had turned. [9.2]he started to walk away quickly in the direction of the public 

library. 

[9.3]   o.k.,    said joe,   get rosie.    

[9.4]zoe  crept  back  to  the  blinker.  [9.5]she  felt  hollow  in  her  stomach.  [9.6]she'd  never 

really expected to see the enemy again. [ones], war work, p. 64] 

'the enemy' is an anaphoric reference that occurs in a subjective context (established by (9.5), 

which is a psychological report). it co-specifies 'the man' in (9.1) and 'he' in (9.2). it reflects 

zoe's belief that the man is an enemy spy, although it is not at all clear to the reader, at point' 

that he is. 

 

 

personal pronouns can also reflect the beliefs of a character. 

assertive  indefinite  pronouns  ex.  'someone',  'something',     somebody     refer  to 

particular  people,  things,  etc.,  without  identifying  them.  when  referring  to  a  particular 

referent, a speaker typically uses an assertive indefinite pronoun if  

(1) she doesn't know the identity of the referent 

(2) she doesn't want the addressee to know the identity of the referent, or  

(3) she doesn't believe that the identity of the referent is relevant to the conversation.  

a character's thoughts end perceptions are not directed toward an addressee, and so the first of 

these uses is the predominant one in subjective contexts. 

example:[10] suddenly she [zoe] gasped. she had touched somebody! [o   neal, war work, 

p. 129] 

there is no explicit statement in the novel that zoe does not know whom she touched; this has 

to be inferred from the use of 'somebody'. 

 

definite references are used only if the speaker believes that the addressee has enough 

information to interpret them. specific indefinite references are used in a subjective context 

when the referent is unfamiliar to the subjective character. however, the referent may not be 

unknown to the reader or to the other characters. 

 

29 

[11]  there  they  [the  king  and  his  men]  saw  close  beside  them  a  great  rubbleheap;  and 

suddenly they were aware of two small figures lying on it at their ease, grey-clad, hardly to 

be seen among the stones. [tolkien, the two towers, p. 206] 

the reader knows that the king and his men have come upon two hobbits, merry end pippin. 

the king and his men do not know the hobbits, but other characters also present in the scene 

do know them. when the king and his man are on the top of the cp (after 'saw' and continued 

by 'were aware of'), the hobbits are not referred to by name, but as 'two small figures'. thus 

new  referents  are  created  and  propositions  are  built  in  the  belief  space  of  the  king  and  his 

men that they are small figures. the new referents can be asserted to be co-extensional with 

the concepts who the reader and other characters believe are named 'merry' and 'pippin'. 

1.6.6  evaluation  

the algorithms were tested on 450 sentential input items (exclusive of paragraph and scene 

breaks) from each of two novels, lonesome dove by larry mcmurtry and the magic of the 

glits  by  carole  s.  adler.  lonesome  dove  is  an  adult  novel  that  has  many  subjective 

characters,  and  the  magic  of  the  glits  is  a  children   s'  novel  that  has  one  main  subjective 

character.  the  input  items  are  those  of  the  complete  sentences  of  every  fifth  page  of  these 

novels, starting in lonesome dove with page 176 and ending with page 236 (13 pages total), 

and starting in the magic of the glits with page 1 and ending with page 86 (18 pages total). 

(for  each  book,  the  first  part  of  an  additional  page  was  used  to  make  the  number  of  input 

items exactly equal to 450.) page 176 in lonesome dove is the beginning of a chapter in the 

middle of the novel. the earlier pages of the novel were considered during the development 

of the algorithm. 

interpretation 

actual instances 

primary 

incorrect interpretations 

<subjective, x> 

271/450 (60%) 

20/271 (7%) 

13 objective 

errors 

7 (subjective, y), y     x 

objective 

179/450 (40%) 

7/179 (4%) 

7 (subjective, x) 

objective, other than simple 

54/450 (12%) 

7/54 (13%) 

7 (subjective, x) 

quoted speech 

 

table 1.8: results for lonesome drove by interpretation 

 

30 

point-of-view operation 

actual instances 

primary 

incorrect interpretations 

errors 

continuation 

215/450 (48%) 

11/215 (5%) 

1 initiation 

10 objective 

resumption 

initiation 

20/450 (4%) 

36/450 (8%) 

0/20 (0%) 

- 

9/36 (25%) 

5 resumptions 

1 initiation 

3 objective 

objective 

179/450 (40%) 

7/179 (4%) 

4 continuations  

3 resumptions 

objective, other than 

54/450 (12%) 

7/54 (13%) 

4 continuations  

simple quoted speech 

3 resumptions 

table 1.9: results for lonesome drove by point-of-view operation 

in  lonesome  dove,  out  of  the  450  input  items,  the  algorithm  committed  27  primary  errors 

(6%) and 28 secondary errors (6%). many of the input items, 125 of them (28%), are simple 

items of quoted speech (i.e., they do not have potential subjective elements in the discourse 

parenthetical, or subordinated clauses outside the quoted string that have private-state terms, 

private-state-action terms, or potential subjective elements). 

 

in table 2.8, the first row, is interpreted as: out of the 271 actual subjective sentences, 

the  algorithm  committed  20  primary  errors.  it  interpreted  13  subjective  sentences  to  be 

objective, and 7 to be the subjective sentence of the wrong subjective character. 

in  table  2.9,  the  first  row,  is  interpreted  as:  out  of  the  215  items  that  actually  continue  a 

character's point of view, the algorithm committed 11 primary errors. it interpreted 1 of them 

to be an initiation and 10 to be objective. notice that the last column of the row for initiations 

includes an initiation. this means that for one actual initiation, the algorithm was correct that 

a character's point of view was initiated, but incorrect as to the identity of that character. 

interpretation 

actual instances 

primary errors 

incorrect interpretations 

<subjective, x> 

125/450 (28%) 

12/125 (10%) 

10 objective 

2 (subjective, y), y     x 

objective 

325/450 (72%) 

22/325 (7%) 

22 (subjective, x) 

objective, other than simple 

97/450 (22%) 

22/97 (23%) 

22 (subjective, x) 

quoted speech 

 

table 1.10: results for the magic of the glits by interpretation 

31 

point-of-view operation 

actual instances 

primary 

incorrect interpretations 

continuation 

resumption 

initiation 

objective 

errors 

79/450 (18%) 

4/79 (5%) 

4 objective 

41/450 (9%) 

7/41 (17%) 

2 initiations 

5 objective 

5/450 (1%) 

1/5 (20%) 

1 objective 

325/450 (72%) 

22/325 (7%) 

4 continuations  

9 resumptions 

9 initiations 

objective, other than simple 

97/450 (22%) 

22/97 (23%) 

4 continuations  

quoted speech 

9 resumptions 

9 initiations 

table 1.11: results for the magic of the glits by point-of-view operations 

in  the  magic  of  the  glits,  out  of the  450  input items,  the  algorithm  committed  34  primary 

errors (8%) and 21 secondary errors (5%). there are 228 items that are simple quoted speech 

(51%). tables 2.10 and 11 present the kinds of results for this novel that were given above in 

tables 2.8 and 2.9 for lonesome dove. 

1.7

  id31 at iit bombay 

balamurali  et  al.  (2011)  presents  an  innovative  idea  to  introduce  sense  based  sentiment 

analysis. this implies shifting from lexeme feature space to semantic space i.e. from simple 

words to their synsets. the works in sa, for so long, concentrated on lexeme feature space or 

identifying relations between words using parsing. the need for integrating sense to sa was 

the need of the hour due to the following scenarios, as identified by the authors: 

a.  a word may have some sentiment-bearing and some non-sentiment-bearing senses 
b.  there may be different senses of a word that bear sentiment of opposite polarity 
c.  the same sense can be manifested by different words (appearing in the same synset) 

using  sense  as  features  helps  to  exploit  the  idea  of  sense/concepts  and  the  hierarchical 

structure of the id138. the following feature representations were used by the authors and 

their performance were compared to that of lexeme based features: 
a.  a group of word senses that have been manually annotated (m) 
b.  a group of word senses that have been annotated by an automatic wsd (i) 

 

32 

c.  a  group  of  manually  annotated  word  senses  and  words  (both  separately  as  features) 

(sense + words(m)) 

d.  a group of automatically annotated word senses and words (both separately as features) 

(sense + words(i)) 

sense + words(m) and sense + words(i) were used to overcome non-coverage of id138 

for some noun synsets.  

 

the  authors  used  synset-replacement  strategies  to  deal  with  non-coverage,  in  case  a 

synset  in  test  document  is  not  found  in  the  training  documents.  in  that  case  the  target 

unknown synset is replaced with its closest counterpart among the id138 synsets by using 

some metric. the metrics used by the authors were lin, lesk and lch.  

id166   s were used for classification of the feature vectors and iwsd was used for automatic 

wsd.  extensive  experiments  were  done  to  compare  the  performance  of  the  4  feature 

representations  with  lexeme  representation.  best  performance,  in  terms  of  accuracy,  was 

obtained by using sense based sa with manual annotation (with an accuracy of 90.2% and an 

increase  of  5.3%  over  the  baseline  accuracy)  followed  by  sense(m),  sense  +  words(i), 

sense(i) and lexeme feature representation. lesk was found to perform the best among the 3 

metrics used in replacement strategies. 

 

one  of  the  reasons  for  improvements  was  attributed  to  feature  abstraction  and 

id84 leading to noise reduction.  the work achieved its target of bringing 

a new dimension to sa by introducing sense based sa. 

 

aditya et al. (2010) introduced id31 to indian languages namely, hindi. 

though, much work has been done in sa in english, little or no work has been done so-far in 

hindi. the authors exploited 3 different approaches to tackling sa in hindi: 

1. they developed a sense annotated corpora for hindi, so that any supervised classifier can 

be trained on that corpora. 

2. they  translated  the  hindi  document  to  english  and  used  a  classifier  trained  in  english 

documents to classify it. 

3. they developed a sentiment lexicon for hindi called the hindi sentiid138 (h-swn). 

the authors first tried to use the in-language classifier and if training data was not available, 

they settled for a rough machine translation of the document to resource-rich english. in case 

mt could not be done they used the h-swn and used a majority voting approach to find the 

polarity of the document. 

 

33 

as expected, the classifier trained in in-language documents gave the best performance. this 

was  followed  by  the  mt  system  of  converting  the  source  document  to  english.  one  of  the 

reasons  for  its  degraded  performance  can  be  attributed  to  the  absence  of  word  sense 

disambiguation,  which  led  to  a  different  meaning  of  the  hindi  word  in  english  after 

translation. the lexical resource based approach gave the worse performance amongst the 3 

approaches. this was mainly due to the coverage of the h-swn which was quite low. 

 

aditya  et  al.  (2010)  took  sentiment  analysis  to  a  new  terrain  by  introducing  it  to 

micro-blogs namely, twitter. they developed the c-feel-it system that extracted posts called 

tweets  from  the  twitter,  related  to  the  user  query,  and  evaluated  its  sentiment  based  on  4 

lexical  resources.  twitter  is  a  very  noisy  medium  where  the  user  posts  different  forms  of 

slangs, abbreviations, smileys etc. there is also a high occurrence of spams generated by bots. 

due to these reasons, the accuracy of the system deteriorated mainly because the words in the 

post  were  not  present  in  the  lexical  resources.  however,  the  authors  used  some  form  of 

id172  to  compensate  somewhat  for  the  inherent  noise.  they  also  used  a  slang  and 

emoticon dictionary for polarity evaluation. the authors used the 4 lexical resources taboada, 

inquirer, sentiid138 and subjectivity lexicon and settled for a majority voting for the final 

polarity of the tweet. this work is novel mainly because it exploits a new domain. 

1.8

  discourse specific id31 

marcu  (2000)  discussed  probabilistic  models  for  identifying  elementary  discourse  units  at 

clausal level and generating trees at the sentence level, using lexical and syntactic information 

from  discourse-annotated  corpus  of  rst.  wellner  et  al.  (2006)  considered  the  problem  of 

automatically identifying arguments of discourse connectives in the pdtb. they modeled the 

problem  as  a  predicate-argument  identification  where  the  predicates  were  discourse 

connectives  and  arguments  served  as  anchors  for  discourse  segments.  wolf  et  al.  (2005) 

present a set of discourse structure relations and ways to code or represent them. the relations 

were  based  on  hobbs  (1985).  they  report  a  method  for  annotating  discourse  coherent 

structures and found different kinds of crossed dependencies. 

 

in the work, contextual valence shifters (polanyi et al., 2004), the authors investigate 

the effect of intensifiers, negatives, modals and connectors that changes the prior polarity or 

valence of the words and brings out a new meaning or perspective. they also talk about pre-

suppositional items and irony and present a simple weighting scheme to deal with them.  

 

34 

somasundaran et al. (2009) and asher et al. (2008) discuss some discourse-based supervised 

and unsupervised approaches to opinion analysis. zhou et al. (2011) present an approach to 

identify discourse relations as identified by rst. instead of depending on cue-phrase based 

methods  to  identify  discourse  relations,  they  leverage  it  to  adopt  an  unsupervised  approach 

that would generate semantic sequential representations (ssrs) without cue phrases. 

taboada  et  al.  (2008)  leverage  discourse  to  identify  relevant  sentences  in  the  text  for 

sentiment  analysis.  however,  they  narrow  their  focus  to  adjectives  alone  in  the  relevant 

portions of the text while ignoring the remaining parts of speech of the text.  

 

most of these discourse based works make use of a discourse parser or a dependency 

parser to identify the scope of the discourse relations and the opinion frames. as said before, 

the parsers fare poorly in the presence of noisy text like ungrammatical sentences and spelling 

mistakes  (dey  et  al.,  2009).  in  addition,  the  use  of  parsing  slows  down  any  real-time 

interactive  system  due  to  increased  processing  time.  for  this  reason,  the  micro-blog 

applications mostly build on a bag-of-words model.  

1.9

  feature specific id31 

chen  et  al.  (2010)  uses  dependency  parsing  and  shallow  semantic  analysis  for  chinese 

opinion  related  expression  extraction.  they  categorize  relations  as,  topic  and  sentiment 

located in the same sub-sentence and quite close to each other (like rule    an adjective plus a 

noun    is mostly a potential opinion-element relation), topic and sentiment located in adjacent 

sub-sentences  and  the  two  sub-sentences  are  parallel  in  structure  (that  is  to  say,  the  two 

adjacent  sub-sentences  are  connected  by  some  coherent  word,  like  although/but,  and  etc), 

topic and sentiment located in different sub-sentences, either being adjacent or not, but the 

different sub sentences are independent of each other, no parallel structures any more. 

 

wu  et  al. (2009) use phrase id33 for opinion mining.  in  dependency 

grammar,  structure  is  determined  by  the  relation  between  a  head  and  its  dependents.  the 

dependent  is  a  modifier  or  complement  and  the  head  plays  a  more  important  role  in 

determining  the  behaviors  of  the  pair.    the  authors  want  to  compromise  between  the 

information loss of the word level dependency in id33 as it does not explicitly 

provide  local  structures  and  syntactic  categories  of  phrases  and  the  information  gain  in 

extracting long distance relations. hence they extend the dependency tree node with phrases.    

 

hu et al. (2004) used frequent item sets to extract the most relevant features from a 

domain and pruned it to obtain a subset of features. they extract the nearby adjectives to a 

 

35 

feature  as  an  opinion  word  regarding  that  feature.  using  a  seed  set  of  labeled  adjectives, 

which they manually develop for each domain, they further expand it using id138 and use 

them to classify the extracted opinion words as positive or negative.  

 

lakkaraju  et  al.  (2011)  propose  a  joint  sentiment  topic  model  to  probabilistically 

model the set of features and sentiment topics using id48-lda. it is an unsupervised system 

which models the distribution of features and opinions in a review and is thus a  generative 

model. 

 

most of the works mentioned above require labeled datasets for training their models 

for  each  of  the  domains.  if  there  is  a  new  domain  about  which  no  prior  information  is 

available  or  if  there  are  mixed  reviews  from  multiple  domains  inter-mixed  (as  in  twitter), 

where the domain for any specific product cannot be identified, then it would be difficult to 

train the models. the works do not exploit the fact that majority of the reviews have a lot of 

domain independent components. if those domain independent parameters are used to capture 

the associations between features and their associated opinion expressions, the models would 

capture majority of the feature specific sentiments with minimal data requirement. 

1.10

  semantic similarity metrics 

various approaches for evaluating the similarity between two words can be broadly classi   ed 

into two categories: edge-based methods and informationcontent-based methods. one of the 

earliest works in edge-based calculation of similarity is by rada et al. (1989), where in, they 

propose a metric   distance    over a semantic net of hierarchical relations as the shortest path 

length  between  the  two  nodes.  this  has  been  the  basis  for  all  the  metrics  involving  simple 

edge-counting  to  calculate  the  distance  between  two  nodes.  however,  the  simple  edge-

counting fails to consider the variable density of nodes across the taxonomy. it also fails to 

include  relationships  other  than  the  is-a  relationship,  thus,  missing  out  on  important 

information in a generic semantic ontology, like id138.  

 

in  contrast  to  edge-based  methods,  richardson  et  al.  (1994)  and  resnik  (1995a) 

propose a node-based approach to    nd the semantic similarity. they approximate conceptual 

similarity  between  two  id138  concepts  as  the  maximum  information  content  among 

classes  that  subsume  both  the  concepts.  resnik  (1995b)  advanced  this  idea  by  de   ning  the 

information content of a concept based on the id203 of encountering an instance of that 

concept. alternatively, wu & palmer (1994) compare two concepts based on the length of the 

path between the root of the hierarchy and the least common subsumer of the concepts.  

 

36 

jiang  &  conrath  (1997)  and  leacock  et  al.  (1998)  combine  the  above  two  approaches  by 

using  the  information  content  as  weights  for  the  edges  between  concepts.  they  further 

reinforce  the  de   nition  of  information  content  of  a  concept  by  adding  corpus  statistical 

information.  

 

instead of measuring the similarity of concepts, some other approaches measure their 

relatedness. hirst & st-onge (1997) introduce an additional notion of direction along with the 

length of paths for measuring the relatedness of  two concepts. banerjee  & pedersen (2003) 

and  patwardhan  (2003)  leverage  the  gloss  information  present  in  id138  in  order  to 

calculate  the  relatedness  of  two  concepts.  banerjee  &  pedersen  (2003)  assigns  relatedness 

scores based on the overlap between the gloss of the two concepts. patwardhan (2003) use a 

vector representation of the gloss, based on the context vector of the terms in the gloss. the 

relatedness is then the cosine between the gloss vectors of the two concepts.  

 

our work is most related to the work of wan  & angryk (2007) which improves on 

banerjee & pedersen (2003) and patwardhan (2003) by including relations other than the is-a 

relationship.  they  use  an  extended  gloss  de   nition  for  a  concept  which  is  de   ned  as  the 

original  gloss  appended  by  the  gloss  of  all  the  concepts  related  to  the  given  concept.  they 

create concept vectors for each sense based on which they create context vectors which are an 

order higher to the concept vectors. finally, they use cosine of the angle between the vectors 

of  the  different  concepts  to     nd  their  relatedness.  this  approach  is  better  than  other 

approaches  as  it  captures  the  context  of  the  concepts  to  a  much  larger  extent.  however,  all 

these methods lack on a common ground. they fail to incorporate sentiment information in 

calculating  the  similarity/relatedness  of  two  concepts.  we  postulate  that  sentiment 

information is crucial in    nding the similarity between two concepts. 

1.11

  id31 in twitter 

twitter  is  a  micro-blogging  website  and  ranks  second  amongst  the  present  social  media 

websites (prelovac 2010). a micro-blog allows users to exchange small elements of content 

such as short sentences, individual pages, or video links. alec et al. (2009) provide one of the 

first  studies  on  sentiment  analysis  on  micro-blogging  websites.  barbosa  et  al.  (2010)  and 

bermingham et al. (2010) both cite noisy data as one of the biggest hurdles in analyzing text 

in such media. alec et al. (2009) describes a distant supervision-based approach for sentiment 

classification. they use hashtags in tweets to create training data and implement a multi-class 

classifier  with  topic-dependent  clusters.  barbosa  et  al.  (2010)  propose  an  approach  to 

 

37 

sentiment  analysis  in  twitter  using  pos-tagged  id165  features  and  some  twitter  specific 

features  like  hashtags.  our  system  is  inspired  from  c-feel-it,  a  twitter  based  sentiment 

analysis system (joshi et al., 2011). however, our system is an enhanced version of their rule 

based system with specialized modules to tackle twitter spam, text id172 and entity 

specific id31.  

to the best of our knowledge, there has not been any specific work regarding spam filtering 

for  tweets  in  the  context  of  sentiment  analysis.  general  spam  filtering  techniques  include 

approaches  that  implement  bayesian  filter  (sahami,  1998;  graham,  2006),  or  id166-based 

filters along  with various boosting algorithms to further enhance the accuracies (drucker  et 

al., 1999).  

 

twitter is a very noisy medium. however, not much work has been done in the area of 

text  id172  in  the  social  media  especially  pertaining  to  twitter.  but  there  has  been 

some work in the related area of sms-es. aw et al., (2006) and raghunathan et al., (2009) 

used a mt-based system for text id172. choudhury et al., (2007) deployed a id48 

for  word-level  decoding  in  sms-es;  while  catherine  et  al.,  (2008)  implemented  a 

combination  of  both  by  using  two  id172  systems:  first  a  smt  model,  and  then  a 

second model for id103 system. another approach to text id172 has been 

to consider each word as a corrupt word after being passed through a noisy channel, which 

essentially  boils  down  to  spell-checking  itself.  mayes  (1991)  provide  one  such  approach. 

church  et  al.,  (1991)  provide  a  more  sophisticated  approach  by  associating  weights  to  the 

probable edits required to correct the word.  

 

we follow the approach of church et al., (1991) and attempt to infuse linguistic rules 

within the minimum id153 (levenstein, 1966). we adopt this simpler approach due to 

the lack of publicly available parallel corpora for text id172 in twitter.  

 

unlike  in  twitter,  there  has  been  quite  a  few  works  on  general  entity  specific 

id31. nasukawa et al., (2003) developed a lexicon and sentiment transfer rules 

to extract sentiment phrases. mullen et al., (2004) used osgood and turney values to extract 

value phrases, i.e. sentiment bearing phrases from the sentence. many approaches have also 

tried  to  leverage  dependency  parsing  in  entity-specific  sa.  mosha  (2010)  uses  dependency 

parsing and shallow semantic analysis for chinese opinion related expression extraction. wu 

et  al.,  (2009)  used  phrase  dependency  parsing  for  opinion  mining.  mukherjee  et  al.  (2012) 

exploit id33 for  graph based id91 of opinion expressions about various 

features  to  extract  the  opinion  expression  about  a  target  feature.  we  follow  a  dependency 

 

38 

parsing based approach for entity specific sa as it captures long distance relations, syntactic 

discontinuity and variable word order, as is prevalent in twitter. 

 

the  works  (alec  et  al.,  2009;  read  et  al.,  2005;  pak  et  al.,  2010;  gonzalez  et  al. 

(2011))  evaluate  their  system  on  a  dataset  crawled  and  auto-annotated  based  on  emoticons, 

hashtags. we show, in this work, that a good performance on such a dataset does not ensure a 

similar performance in a general setting. 

1.12

  extractive summarization 

there  are  2  prominent  paradigms  in  automatic  text  summarization  (das  et  al.,  2007): 

extractive and abstractive text summarization. while extractive text summarization attempts 

to  identify  prominent  sections  of  a  text  by  giving  more  emphasis  on  the  content  of  the 

summary, abstractive text summarization gives more emphasis on the form so that sentences 

are  syntactically  and  semantically  coherent.  the  topic-driven  summarization  paradigm  is 

more common to ir where the summary content is based on the user query about a particular 

topic.  luhn  (1958)  attempts  to  find  the  top-ranked  significant  sentences  based  on  the 

frequency  of  the  content  words  present  in  it.  edmundson  (1969)  gives  importance  to  the 

position  of  a  sentence  i.e.  where  the  sentence  appears  in  the  text  and  comes  up  with  an 

optimum  position  policy  and  emphasis  on  the  cue  words.  aone  et  al.  (1999)  use  tf-idf  to 

retrieve signature words, ner to retrieve tokens, shallow discourse analysis for cohesion and 

also  use  synonym  and  morphological  variants  of  lexical  terms  using  id138.  lin  (1999) 

uses  a  rich  set  of  features  for  the  creation  of  feature  vector  like  title,  tf  &  tf-idf  scores, 

position  score,  query  signature,  ir  signature,  sentence  length,  average  lexical 

connectivity,  numerical  data,  proper  name,  pronoun  &  adjective,  weekday  &  month, 

quotation,  first  sentence  etc.  and  use  decision  tree  to  learn  the  feature  weights.  there  are 

other  works  based  on  id48  (conroy  et  al.,  2008),  rts  (marcu,  1998),  lexical  chain  and 

cohesion (barzilay et al., 1997).  

1.13

  subjectivity analysis 

yu et al. (2003) propose to find subjective sentences using lexical resources where the authors 

hypothesize that subjective sentences will be more similar to opinion sentences than to factual 

sentences.  as  a  measure  of  similarity  between  two  sentences  they  used  different  measures 

including shared words, phrases and the id138. potthast et al. (2010) focus on extracting 

 

39 

top  sentiment  keywords  which  is  based  on  pointwise  mutual  information  (pmi)  measure 

(turney, 2002). 

 

the pioneering work for subjectivity detection is done in (pang  et  al., 2004), where 

the  authors  use  min-cut  to  leverage  the  coherency  between  the  sentences.  the  fundamental 

assumption  is  that  local  proximity  preserves  the  objectivity  or  subjectivity  relation  in  the 

review. but the work is completely supervised requiring two levels of tagging. firstly, there is 

tagging  at  the  sentence  level  to  train  the  classifier  about  the  subjectivity  or  objectivity  of 

individual  sentences.  secondly,  there  is  tagging  at  the  document  level  to  train  another 

classifier to distinguish between positive and negative reviews. hence, this requires a lot of 

manual effort. alekh et al. (2005) integrate graph-cut with linguistic knowledge in the form of 

id138 to exploit similarity in the set of documents to be classified. 

1.14

  concept expansion using wikipedia 

wikipedia is used in a number of works for concept expansion in ir, for expanding the query 

signature  (muller  et  al.,  2009;  wu  et  al.,  2008;  milne  et  al.,  2007)  as  well  as  topic  driven 

multi document summarization (wang et al., 2010).  

 

there has been a few works in id31 using wikipedia (gabrilovich et al., 

2006;  wang  et  al.,  2008).  gabrilovich  et  al.  (2006)  focus  on  concept  expansion  using 

wikipedia where they expand the feature vector constructed from a movie review with related 

concepts  from  the  wikipedia.  this  increases  accuracy  as  it  helps  in  unknown  concept 

classification  due  to  expansion  but  it  does  not  address  the  concern  of  separating  subjective 

concepts from objective ones. 

 

these works do not take advantage of the ontological and sectional arrangement of 

the  wikipedia  articles  into  categories.  each  wikipedia  movie  article  has  sections  like  plot, 

cast, production etc. which can be explicitly used to train a system about the different aspects 

of a movie. in this work, our objective is to develop a system that classifies the opinionated 

extractive summary of the movie, requiring no labeled data for training; where the summary is 

created based on the extracted information from wikipedia. 

1.15

  conclusions 

this  report  discusses  in  details  the  various  approaches  to  sentiment  analysis,  mainly  machine 

learning  and  cognitive  approaches.  it  provides  a  detailed  view  of  the  different  applications  and 

potential challenges of id31 that makes it a difficult task.  

 

40 

we have seen the applications of machine learning techniques like na  ve bayes, maximum id178, 

support vector machines and voted id88s in sa and their potential drawbacks. as all of these 

are  bag-of-words  model,  they  do  not  capture  context  and  do  not  analyze  the  discourse  which  is 

absolutely essential for sa. we have also seen the use of subsequence kernels in voted id88s 

that is somewhat successful to capture context as a result of which it achieves a high accuracy. also it 

achieves the difficult task of performing prediction over a continuum even though trained only on the 

extreme reviews. thus machine learning models with a proper kernel that can capture the context will 

play an important role in sa.  

 

feature  engineering,  as  in  several  machine  learning  and  natural  language  processing 

applications, plays a vital role in sa. we have seen the use of phrases as well as words as features. it 

has been seen that adjectives as word features can capture majority of the sentiment. use of topic-

oriented  features  and  value  phrases  play  a  significant  role  to  detect  sentiment  when  the  domain  of 

application is known. it is also seen that use of lemmas capture sentiment better than using unigrams. 

 

we have also discussed in details the application of cognitive psychology in sa. the reason 

why it is absolutely essential for sa is for its power of analyzing the discourse. discourse analysis, as 

we  have  seen,  plays  a  significant  role  in  detecting  sentiments.  the  use  of  discourse  analysis  and 

tracking point of view are necessary for analyzing opinions in blogs, newspaper and articles where a 

third person narrates his/her views. 

 

we  also  discus  some  specific  topics  in  sentiment  analysis  and  the  contemporary  works  in 

those areas. 

 

 

 

 

 

 

 

 

 

 

 

 

41 

2. references 

1. aditya  joshi,  balamurali  a.r.,  pushpak  bhattacharyya,  2010,  a  fall-back  strategy  for 

id31 in a new language: a case study for hindi, icon 2010, kharagpur, 

india 

2. alec, g.; lei, h.; and richa, b. twitter sentiment classification using distant supervision. 

technical report, standford university. 2009 

3. alekh  agarwal  and  pushpak  bhattacharyya,  sentiment  analysis:  a  new  approach  for 

effective use of linguistic knowledge and exploiting similarities in a set of documents 

to  be  classified,  international  conference  on  natural  language  processing  (icon  05), 

iit kanpur, india, december, 2005 

4. alistair kennedy and diana inkpen, sentiment classification of movie and product reviews 

using contextual valence shifters, computational intelligence, 22(2):110   125, 2006 

5. aone,  c.,  okurowski,  m.  e.,  gorlinsky,  j.,  and  larsen,  b.,  a  trainable  summarizer  with 

knowledge acquired from robust nlp techniques, in mani, i. and maybury, m. t., editors, 

advances in automatic text summarization, pages 71-80, 1999 

6. asher, nicholas  and  benamara, farah  and  mathieu, yvette yannick. distilling opinion 

in discourse: a preliminary study, in proceedings of computational linguistics (coling), 

2008 

7. b. wellner, j. pustejovski, a. havasi, a. rumshisky, and r. suair. 2006, classification of 

discourse coherence relations: an exploratory study using multiple knowledge sources, in 

proc. of sigdial, 2006 

8. balaji polepalli p. ramesh, hong yu, identifying discourse connectives in biomedical text, 

in annual symposium proceedings, amia symposium, vol. 2010,pp. 657-661, 2010 

9. balamurali  a.r.,  aditya  joshi,  pushpak  bhattacharyya,  robust  sense  based  sentiment 

classification, acl wassa 2011, portland, usa, 2011 

10. balamurali a.r., aditya joshi, pushpak bhattacharyya, harnessing id138 senses for 

supervised sentiment classification, in proceedings of emnlp, edinburgh, 2011 

11. banerjee,  s.  &  pedersen,  t.,  an  adapted  lesk  algorithm  for  word  sense  disambiguation 

using id138, in    proc. of cicling   02   , london, uk, pp. 136   145, 2002 

12. banerjee,  s.  &  pedersen,  t.,  extended  gloss  overlaps  as  a  measure  of  semantic 

relatedness,  in     in  proceedings  of  the  eighteenth  international  joint  conference  on 

artificial intelligence   , pp. 805   810, 2003 

 

42 

13. barbosa,  l.,  and  feng,  j.,  robust  sentiment  detection  on  twitter  from  biased  and  noisy 

data,  in  23rd  international  conference  on  computational  linguistics:  posters,  36   44, 

2010 

14. barzilay,  r.  and  elhadad,  m.  (1997),  using  lexical  chains  for  text  summarization,  in 

proceedings ists'97, 1997 

15. bermingham,  a.,  and  smeaton,  a,  classifying  sentiment  in  microblogs:  is  brevity  an 

advantage acm 1833   1836, 2010 

16. liu, bing, id31 and opinion mining, 5th text analytics summit, boston, 

june 1-2, 2009 

17. pang,  bo  and  lee,  lillian,  opinion  mining  and  sentiment  analysis,  foundations  and 

trends in information retrieval volume 2 issue 1-2, 2008  

18. borth,  damian  and  hees,  j\"{o}rn  and  koch,  markus  and  ulges,  adrian  and  schulze, 

christian  and  breuel,  thomas  and  paredes,  roberto,    tubefiler       an  automatic  web 

video categorizer, proceedings of the 17th acm international conference on multimedia, 

mm '09, 2009 

19. boucher, jerry  d. and charles e. osgood, the pollyanna hypothesis, journal of verbal 

learning and verbal behaviour, 8:1   8, 1969 

20. brian  eriksson,  sentiment  classification  of  movie  reviews  using 

linguistic parsing   , processing, citeseer, pages: 4-9, volume 838, 2006 

21. c. whitelaw, n. garg, and s. argamon, using appraisal groups for id31, in 

proceedings of the acm sigir conference on information and knowledge management 

(cikm), pp. 625   631, acm, 2005 

22. chen  mosha,  combining  dependency  parsing  with  shallow  semantic  analysis  for 

chinese opinion-element relation identification, ieee, pp. 299-305, 2010 

23. christof m  ller and iryna gurevych, using wikipedia and wiktionary in domain-specific 

information retrieval, proceeding clef' 08, springer-verlag berlin, heidelberg, 2009 

24. conroy,  j.  m.  and  o'leary,  d.  p.,  text  summarization  via  hidden  markov  models,  in 

proceedings of sigir '01, pages 406-407, 2001 

25. cui,  bin  and  zhang,  ce  and  cong,  gao,  content-enriched  classifier  for  web  video 

classification, proceedings of the 33rd international acm sigir, 2010 

26. daniel m. bikel, jeffrey sorensen, if we want your opinion, international conference 

on semantic computing (icsc 2007), 2007 

 

43 

27. das,  d.  and  martins,  a.  f.  t.  a  survey  on  automatic  text  summarization,  literature 

survey for the language and statistics ii course at cmu, pittsburg 2007 

28. david  n.  milne  and  ian  h.  witten  and  david  m.  nichols,  a  knowledge-based  search 

engine  powered  by  wikipedia,  proceedings  of  the  sixteenth  acm  conference  on 

conference  on  information  and  knowledge  management,  acm  new  york,  ny,  usa 

2007 

29. dey, lipika and haque, sk. opinion mining from noisy text data, international journal 

on document analysis and recognition 12(3). pp 205-226, 2009 

30. edmundson,  h.  p.,  new  methods  in  automatic  extracting,  journal  of  the  acm,  16(2): 

264-285, 1969 

31. ekenel, hazim kemal and semela, tomas and stiefelhagen, rainer, content-based video 

genre classification using multiple cues, proceedings of the 3rd international workshop on 

automated information extraction in media production, aiempro '10, 2010 

32. elwell, robert and baldridge, jason, discourse connective argument identification with 

connective  specific  rankers.  in  proceedings  of  ieee  international  conference  on 

semantic computing, 2008 

33. esuli a, sebastiani f., sentiid138: a publicly available lexical resource for opinion 

mining,  in  proceedings  from  international  conference  on  language  resources  and 

evaluation (lrec), genoa, 2006 

34. esuli,  a.  &  sebastiani,  f.,  sentiid138:  a  publicly  available  lexical  resource  for 

opinion mining, in proceedings of lrec-06, genova, it, pp. 417   422, 2006 

35. f.wolf  and  e.  gibson,  representing  discourse  coherence:  a  corpus-based  study, 

computational linguistics, 31(2), pp. 249   287, 2005 

36. farah  benamara,  carmine  cesarano,  antonio  picariello,  vs  subrahmanian  et  al; 

id31: adjectives and adverbs are better than adjectives alone, in icwsm 

   2007 boulder, co usa, 2007 

37. fei wu, daniel s. weld, automatically refining the wikipedia infobox ontology, www 

2008 

38. filippova, katja and hall, keith b., improved video categorization from text metadata 

and  user  comments,  proceedings  of  the  34th  international  acm  sigir,  pp.  835-842, 

2011 

39. gabrilovich,  evgeniy  and  markovitch,  shaul,  overcoming  the  brittleness  bottleneck 

using  wikipedia:  enhancing  text  categorization  with  encyclopedic  knowledge, 

 

44 

proceedings of the 21st national conference on artificial intelligence - volume 2, aaai 

2006 

40. giuliano  armano  and  alessandro  giuliani  and  eloisa  vargiu,  experimenting  text 

summarization  techniques  for  contextual  advertising,  proceedings  of  the  2nd  italian 

information retrieval (iir) workshop, milan, italy, 2011 

41. gonz\'{a}lez-ib\'{a}\~{n}ez,  roberto  and  muresan,  smaranda  and  wacholder,  nina. 

identifying sarcasm in twitter: a closer look, in proc. of acl: short paper, 2011 

42. grishman, r., adaptive information extraction and sublanguage analysis, in proceedings 

of the 17th international joint conference on artificial intelligence, 2001  

43. himabindu  lakkaraju,  chiranjib  bhattacharyya,  indrajit  bhattacharya  and  srujana 

merugu,  exploiting  coherence  for  the  simultaneous  discovery  of  latent  facets  and 

associated  sentiments,  siam  international  conference  on  data  mining  (sdm),  april 

2011 

44. hirst, g. & st-onge, d.,    lexical chains as representation of context for the detection and 

correction malapropisms, 1997 

45. hobbs,  jerry  r.,  and  michael  agar.the  coherence  of  incoherent  discourse,  journal  of 

language and social psychology, vol. 4, nos. 3-4, pp. 213-232, 1985 

46. huang,  chunneng  and  fu,  tianjun  and  chen,  hsinchun,  text-based  video  content 

classification  for  online  video-sharing  sites,  journal  of  the  american  society  for 

information science and technology volume 61, issue 5, pages 891   906, 2010 

47. j. rousu and j. shawe-taylor, efficient computation of gapped substring kernels on large 

alphabets, j. mach. learn. res., 6:1323   1344, 2005 

48. janyce m. wiebe, identifying subjective characters in narrative, proceeding coling '90, 

proceedings of the 13th conference on computational linguistics- volume 2, 1990 

49. janyce  m.  wiebe,  point  of  view  and  discourse  processing,  working  notes  of  the  1991 

aaai  fall  symposium  on  discourse  structure  in  natural  language  understanding  and 

generation, 1991 

50. janyce  m.  wiebe,  william  j.  rapaport,  a  computational  theory  of  perspective  and 

reference  in  narrative,  proceedings  of  the  26th  annual  meeting  on  association  for 

computational linguistics, 1988 

51. janyce  wiebe  m.,  identifying  subjective  characters  in  narrative,  in  proc.  13th 

international conference on computational linguistics (coling-90), pp. 401-408, 1990 

 

45 

52. janyce wiebe m., references in narrative text, no  s (special issue on cognitive science 

and ai) 25 (4), pp. 457-486, 1991  

53. janyce wiebe m., tracking point of view in narrative, computational linguistics 20 (2), 

pp. 233-287, 1994 

54. jaynce  m.  wiebe,  tracking  point  of  view  in  narrative,  journal  computational 

linguistics, volume 20, cambridge u.s.a, 1994 

55. jianbo  shi  and  jitendra  malik,  normalized  cuts  and  image  segmentation,  ieee 

transactions on pattern analysis and machine intelligence, 22(8):888   905, 2000 

56. jiang, j. j. & conrath, d. w., semantic similarity based on corpus statistics and lexical 

taxonomy, 

in     international  conference  research  on  computational  linguistics 

(rocling x)   , p. 9008, 1997 

57. joshi,  a.;  balamurali,  a.  r.;  bhattacharyya,  p.;  and  mohanty,  r,  c-feel-it:  a  sentiment 

analyzer  for  microblogs,  in  proceedings  of  acl:  systems  demonstrations,  hlt     11, 

127   132, 2011 

58. jurafsky, daniel, and james h. martin, speech and language processing: an introduction 

to  natural  language  processing,  speech  recognition,  and  computational  linguistics, 

prentice-hall, 2000 

59. k. dave, s. lawrence, and d. m. pennock, mining the peanut gallery: opinion extraction 

and  semantic  classification  of  product  reviews,  in  proceedings  of  www,  pp.  519   528, 

2003 

60. kimberly voll and maite taboada, not all words are created equal: extracting semantic 

orientation  as  a  function  of  adjective  relevance,  in  proceedings  of  the  20th  australian 

joint conference on artificial intelligence, pages 337   346, 2007 

61. leacock, c. & chodorow, m., combining local context with id138 similarity for word 

sense identification, in id138: a lexical reference system and its application, 1998 

62. leacock, c., miller, g. a. & chodorow, m., using corpus statistics and id138 relations 

for sense identification, comput. linguist. 24, 147   165, 1998 

63. li,  tao  and  zhang,  yi  and  sindhwani,  vikas,  a  nonnegative  matrix  tri-factorization 

approach  to  sentiment  classification  with  lexical  prior  knowledge,  in  proceedings  of 

(acl-ijcnlp), pages 244   252, 2009 

64. lin,  c.-y.,  training  a  selection  function  for  extraction,  in  proceedings  of  cikm  '99, 

pages 55-62, 1999 

 

46 

65. lin,  chenghua  and  he,  yulan  and  everson,  richard,  a  comparative  study  of  bayesian 

models for unsupervised sentiment detection, conll, 2010 

66. lin,  d.,  an  information-theoretic  definition  of  similarity,  in     in  proceedings  of  icml 

   98   , morgan kaufmann, pp. 296   304, 1998  

67. luhn,  h.  p.,  the  automatic  creation  of  literature  abstracts,  ibm  journal  of  research 

development. 2(2):159-165, 1958 

68. m.  potthast  and  s.  becker,  opinion  summarization  of  web  comments,  proceedings  of 

the 32nd european conference on information retrieval, ecir, 2010 

69. macdonald, craig and ounis, iadh, expertise drift and id183 in expert search, 

proceedings  of  the  sixteenth  acm  conference  on  conference  on  information  and 

knowledge management, cikm '07, 2007 

70. mann,  william  c.  and  sandra  a.  thompson,  rhetorical  structure  theory:  toward  a 

functional theory of text organization, text, 8 (3), 243-281, 1988 

71. manning, christopher d. and raghavan, prabhakar and schtze, hinrich,  introduction to 

information retrieval. cambridge university press, 2008 

72. marcu, d., improving summarization through rhetorical parsing tuning, in proceedings of 

the sixth workshop on very  large corpora, pages 206-215, pages 206-215, montreal, 

canada, 1998 

73. marcu, daniel, the theory and practice of discourse parsing and summarization, mit 

press, cambridge, ma, 2000 

74. marcu, daniel, the theory and practice of discourse parsing and summarization, mit 

press, cambridge, ma., 2000 

75. mccarthy,  diana    and    koeling,  rob    and    weeds,  julie    and    carroll,  john,  finding 

predominant  word  senses  in  untagged  text,  proceedings  of  the  42nd  meeting  of  the 

association for computational linguistics (acl'04), 2004 

76. mccarthy,  diana    and    koeling,  rob    and    weeds,  julie    and    carroll,  john,  finding 

predominant  word  senses  in  untagged  text,  proceedings  of  the  42nd  meeting  of  the 

association for computational linguistics (acl'04), 2004 

77. minqing hu and bing liu, mining and summarizing customer reviews, in proc. of acm 

sigkdd, 2004 

78. mitesh khapra, sapan shah, piyush kedia, and pushpak bhattacharyya, domain-specific 

word  sense  disambiguation  combining  corpus  basedand  id138  based  parameters,  in 

proc. of gwc   10, mumbai, india, 2010 

 

47 

79. ng, vincent and dasgupta, sajib and arifin, s. m. niaz, examining the role of linguistic 

knowledge  sources  in  the  automatic  identification  and  classification  of  reviews. 

proceedings of the coling/acl on main conference poster sessions, 2006 

80. p.  turney,  thumbs  up  or  thumbs  down?  semantic  orientation  applied  to  unsupervised 

classification of reviews, in proceedings of the 40th annual meeting of the association 

for computational linguistics (acl   02), 2002 

81. pak,  alexander  and  paroubek,  patrick,  twitter  as  a  corpus  for  sentiment  analysis  and 

opinion mining, lrec, 2010 

82. pang,  bo  and  lee,  lillian  and  vaithyanathan,  shivakumar,  thumbs  up?  sentiment 

classification using machine learning techniques, proceedings of emnlp 2002 

83. pang,  bo  and  lee,  lillian  and  vaithyanathan,  shivakumar,  thumbs  up?:  sentiment 

classification  using  machine  learning  techniques,  in  proceedings  of  the  acl-02 

conference on empirical methods in natural language, 2002  

84. pang,  bo  and  lee,  lillian,  a  sentimental  education:  sentiment  analysis  using 

subjectivity summarization based on minimum cuts, proceedings of the acl, 2004 

85. patwardhan,  s.,  incorporating  dictionary  and  corpus  information  into  a  context  vector 

measure of semantic relatedness, master   s thesis, university of minnesota, duluth, 2003 

86. pedersen,  t.,  patwardhan,  s.  &  michelizzi,  j.,  id138::similarity:  measuring  the 

relatedness of concepts, in    demonstration papers at hlt-naacl   04   , pp. 38   41, 2004 

87. pitler,  emily  and  louis,  annie  and  nenkova,  ani.  automatic  sense  prediction  for 

implicit discourse relations in text, in proc. of acl and ijcnlp, 2009 

88. polanyi, livia and zaenen, annie, contextual valence shifters, in exploring attitude and 

affect in text: theories and applications, aaai spring symposium series, 2004 

89. prelovac, v., top social media sites. web, 2010 
90. qi  zhang,  yuanbin  wu,  tao  li,  mitsunori  ogihara,  joseph  johnson,  xuanjing  huang, 

mining product reviews based on shallow id33, proceedings of the 32nd 

international  acm  sigir  conference  on  research  and  development  in  information 

retrieval, 2009 

91. r.  soricut  and  d.  marcu,  sentence  level  discourse  parsing  using  syntactic  and  lexical 

information, in proc of hlt-naacl, 2003 

92. rada, r., mili, h., bicknell, e. & blettner, m., development and application of a metric 

on  semantic  nets   ,  ieee  transactions  on  systems  management  and  cybernetics  19(1), 

17   30, 1989 

 

48 

93. ramanathan  narayanan,  bing  liu  and  alok  choudhary,  sentiment  analysis  of 

conditional  sentences,  in  proceedings  of  conference  on  empirical  methods  in  natural 

language processing, 2009 

94. read,  jonathon,  using  emoticons  to  reduce  dependency  in  machine  learning  techniques 

for sentiment classification, in acl. the association for computer linguistics, 2005 

95. resnik,  p.,  disambiguating  noun  groupings  with  respect  toid138  senses,  in  d. 

yarovsky  &  k.  church,  proceedings  of  the  third  workshop  on  very  large  corpora, 

association for computational linguistics, somerset, new jersey, pp. 54   68, 1995 

96. resnik, p., using information content to evaluate semantic similarity in a taxonomy,  in 

   in proceedings of the 14th international joint conference on artificial intelligence   , pp. 

448   453, 1995 

97. richardson,  r.,  smeaton,  a.  f.  &  murphy,  j.,  using  id138  as  a  knowledge  base  for 

measuring semantic similarity between words, technical report, in proceedings of aics 

conference, 1994 

98. s.  zanetti,  l.  zelnik-manor,  and  p.  perona,  a  walk  through  the  web   s  video  clips,  in 

proc. of cvpr workshop on internet vision, 2008 

99. sajib  dasgupta  and  vincent  ng,  topic-wise,  sentiment-wise,  or  otherwise?  identifying 

the hidden dimension for unsupervised text classification, emnlp, 2009 

100. socher,  richard  and  pennington,  jeffrey  and  huang,  eric  h.  and  ng,  andrew  y.  and 

manning,  christopher  d.,  semi-supervised  recursive  autoencoders  for  predicting 

sentiment distribution, emnlp, 2011 

101. somasundaran,  swapna,  discourse-level  relations  for  opinion  analysis,  phd  thesis, 

university of pittsburgh, 2010 

102. song, yicheng and zhang, yong-dong and zhang, xu and cao, juan and li, jing-tao, 

google  challenge:  incremental-learning  for  web  video  categorization  on  robust 

semantic  feature  space,  proceedings  of  the  17th  acm  international  conference  on 

multimedia, 2009 

103. stefano baccianella and andrea esuli and fabrizio sebastiani, sentiid138 3.0: 

an enhanced lexical resource for id31 and opinion mining, lrec, 2010 
104. stone,  p.j.,  dunphy,  d.c.,  smith,  m.s.,  ogilvie,  d.m.  and  associates,  the  general 

inquirer: a computer approach to content analysis. the mit press, 1966 

 

49 

105. t. mullen and n. collier, id31 using support vector machines with diverse 

information sources, in proceedings of the conference on empirical methods in natural 

language processing (emnlp), pp. 412   418, 2004 

106. taboada, maite and brooke, julian and tofiloski, milan and voll, kimberly and stede, 

manfred, lexicon-based methods for id31, computational linguistics, 2011 
107. taboada,  maite  and  brooke,  julian  and  voll,  kimberly,  extracting  sentiment  as  a 

function  of  discourse  structure  and  topicality,  simon  fraser  univeristy  school  of 

computing science technical report, 2008 

108. tetsuji  nakagawa  and  kentaro  inui  and  sadao  kurohashi,  dependency  tree-based 

sentiment classification using crfs with hidden variables, naacl, 2010 

109. tetsuya  nasukawa,  jeonghee  yi,  sentiment  analysis:  capturing  favorability  using 

natural language processing, in k-cap    03, pages 1-8, florida, 2003 

110. vipul  pandey  and  c.v.krishnakumar  iyer,  sentiment  analysis  of  microblogs,  cs  229 

project report, stanford university 

111. wan, s. & angryk, r.  a., measuring semantic  similarity using id138-based context 

vectors., in    smc   07   , pp. 908   913, 2007 

112. wang  h.,  zhou  g.,  topic-driven  multi-document  summarization,  in  proceedings 

international conference on asian language processing, 2010 

113. wang,  pu  and  domeniconi,  carlotta,  building  semantic  kernels  for  text  classification 

using wikipedia, proc. of sigkdd, 2008 

114. webber, bonnie and knott, alistair and stone, matthew and joshi, aravind, discourse 

relations: a structural and presuppositional account using lexicalized tag, in proceedings 

of acl, 1999 

115. wellner, ben and pustejovsky, james and havasi, catherine and rumshisky, anna and 

saur\'{\i},  roser,  classification  of  discourse  coherence  relations:  an  exploratory  study 

using  multiple  knowledge  sources,  proceedings  of  the  7th  sigdial  workshop  on 

discourse and dialogue, 2006 

116. wolf,  f.,  gibson,  e.  and  desmet,  t.,  discourse  coherence  and  pronoun  resolution, 

language and cognitive processes, 19(6), pp. 665   675, 2004 

117. wolf, florian and gibson, edward, representing discourse coherence: a corpus-based 

study, computational linguistics, 31(2), pp. 249   287, 2005 

 

50 

118. wu,  xiao  and  ngo,  chong-wah  and  zhu,  yi-ming  and  peng,  qiang,  boosting  web 

video  categorization  with  contextual  information  from  social  web,  world  wide  web 

volume 15 issue 2, 2012 

119. wu, z. & palmer, m., verb semantics and lexical selection, in    32nd. annual meeting of 

the  association  for  computational  linguistics   ,  new  mexico  state  university,  las 

cruces, new mexico, pp. 133    138, 1994 

120. yang,  linjun  and  liu,  jiemin  and  yang,  xiaokang  and  hua,  xian-sheng,  multi-

modality web video categorization, proceeding mir '07 proceedings of the international 

workshop on workshop on multimedia information retrieval, 2007 

121. yew, jude and shamma, david a. and churchill, elizabeth f., knowing funny:  genre 

perception  and  categorization  in  social  video  sharing,  in  proceedings  of  chi'2011, 

pp.297-306, 2011 

122. yu,  hong  and  vasileios,  hatzivassiloglou,  towards  answering  opinion  questions: 

separating  facts  from  opinions  and  identifying  the  polarity  of  opinion  sentences,  in 

emnlp, 2003  

123. yuanbin  wu,  qi  zhang,  xuanjing  huang,  lide  wu,  phrase  dependency  parsing  for 

opinion  mining,  proceedings  of  the  2009  conference  on  empirical  methods  in  natural 

language processing, 2009 

124. zhang, john r. and song, yang and leung, thomas, improving video classification via 

youtube  video  co-watch  data,  acm  workshop  on  social  and  behavioural  network 

media access at acm mm 2011 

125. zhang,  ruofei  and  sarukkai,  ramesh  and  chow,  jyh-herng  and  dai,  wei  and  zhang, 

zhongfei,  joint  categorization  of  queries  and  clips  for  web-based  video  search, 

proceeding mir '06 proceedings of the 8th acm international workshop on multimedia 

information retrieval, 2006 

126. zheshen  wang,  ming  zhao,  yang  song,  sanjiv  kumar,  and  baoxin  li,  youtubecat: 

learning  to  categorize  wild  web  videos,  ieee  computer  society  conference  on 

id161 and pattern recognition (cvpr), 2010 

127. zhong,  z.  &  ng,  h.  t.,  it  makes  sense:  a  wide-coverage  word  sense  disambiguation 

system for free text. in    acl (system demonstrations)    10   , pp. 78   83, 2010 

128. zirn,  c\"{a}cilia    and    niepert,  mathias    and    stuckenschmidt,  heiner    and    strube, 

michael, fine-grained id31 with structural features, in proc. of ijcnlp. 

2011 

 

51 

