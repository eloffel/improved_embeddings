foundations and trends r! in
information retrieval
vol. 5, nos. 2   3 (2011) 103   233
c! 2011 a. nenkova and k. mckeown
doi: 10.1561/1500000015

id54

by ani nenkova and kathleen mckeown

contents

1 introduction

1.1 types of summaries
1.2 how do summarization systems work?
1.3 evaluation issues
1.4 where does summarization help?
1.5 article overview

2 sentence extraction: determining importance

2.1 unsupervised data-driven methods
2.2 machine learning for summarization
2.3 sentence selection vs. summary selection
2.4 sentence selection for query-focused summarization
2.5 discussion

3 methods using semantics and discourse

3.1 lexical chains and related approaches
3.2 latent semantic analysis
3.3 coreference information
3.4 rhetorical structure theory
3.5 discourse-motivated graph representations of text
3.6 discussion

104

104
107
114
115
117

120

121
131
134
136
141

143

143
145
146
147
149
150

4 generation for summarization

information fusion

4.1 sentence compression
4.2
4.3 context dependent revisions
4.4
4.5 discussion

information ordering

5 genre and domain speci   c approaches

5.1 medical summarization
5.2 journal article summarization in non-medical domains
5.3 email
5.4 web summarization
5.5 summarization of speech
5.6 discussion

6 intrinsic evaluation

6.1 precision and recall
6.2 relative utility
6.3 duc manual evaluation
6.4 automatic evaluation and id8
6.5 pyramid method
6.6 linguistic quality evaluation
6.7

intrinsic evaluation for speech summarization

7 conclusions

references

152

153
162
165
168
171

173

174
180
184
189
193
198

199

199
201
202
204
204
205
206

210

216

foundations and trends r! in
information retrieval
vol. 5, nos. 2   3 (2011) 103   233
c! 2011 a. nenkova and k. mckeown
doi: 10.1561/1500000015

id54

ani nenkova1 and kathleen mckeown2

1 university of pennsylvania, usa, nenkova@seas.upenn.edu
2 columbia university, usa, kathy@cs.columbia.edu

abstract

it has now been 50 years since the publication of luhn   s seminal paper
on id54. during these years the practical need for
id54 has become increasingly urgent and numer-
ous papers have been published on the topic. as a result, it has become
harder to    nd a single reference that gives an overview of past e   orts
or a complete view of summarization tasks and necessary system com-
ponents. this article attempts to    ll this void by providing a com-
prehensive overview of research in summarization, including the more
traditional e   orts in sentence extraction as well as the most novel recent
approaches for determining important content, for domain and genre
speci   c summarization and for evaluation of summarization. we also
discuss the challenges that remain open, in particular the need for lan-
guage generation and deeper semantic understanding of language that
would be necessary for future advances in the    eld.

we would like to thank the anonymous reviewers, our students and noemie elhadad,
hongyan jing, julia hirschberg, annie louis, smaranda muresan and dragomir radev
for their helpful feedback. this paper was supported in part by the u.s. national science
foundation (nsf) under iis-05-34871 and career 09-53445. any opinions,    ndings and
conclusions or recommendations expressed in this material are those of the authors and do
not necessarily re   ect the views of the nsf.

1

introduction

today   s world is all about information, most of it online. the world
wide web contains billions of documents and is growing at an expo-
nential pace. tools that provide timely access to, and digest of, various
sources are necessary in order to alleviate the information overload peo-
ple are facing. these concerns have sparked interest in the development
of id54 systems. such systems are designed to take
a single article, a cluster of news articles, a broadcast news show, or an
email thread as input, and produce a concise and    uent summary of the
most important information. recent years have seen the development
of numerous summarization applications for news, email threads, lay
and professional medical information, scienti   c articles, spontaneous
dialogues, voicemail, broadcast news and video, and meeting record-
ings. these systems, imperfect as they are, have already been shown to
help users and to enhance other automatic applications and interfaces.

1.1 types of summaries

there are several distinctions typically made in summarization and here
we de   ne terminology that is often mentioned in the summarization
literature.

104

1.1 types of summaries

105

extractive summaries (extracts) are produced by concatenating
several sentences taken exactly as they appear in the materials being
summarized. abstractive summaries (abstracts), are written to convey
the main information in the input and may reuse phrases or clauses
from it, but the summaries are overall expressed in the words of the
summary author.

early work in summarization dealt with single document summa-
rization where systems produced a summary of one document, whether
a news story, scienti   c article, broadcast show, or lecture. as research
progressed, a new type of summarization task emerged: multi-document
summarization. id57 was motivated by use
cases on the web. given the large amount of redundancy on the web,
summarization was often more useful if it could provide a brief digest
of many documents on the same topic or the same event. in the    rst
deployed online systems, id57 was applied
to clusters of news articles on the same event and used to produce
online browsing pages of current events [130, 171].1 a short one-
paragraph summary is produced for each cluster of documents per-
taining to a given news event, and links in the summary allow the
user to directly inspect the original document where a given piece of
information appeared. other links provide access to all articles in the
cluster, facilitating the browsing of news. user-driven clusters were also
produced by collecting search engine results returned for a query or by
   nding articles similar to an example document the user has    agged as
being of interest [173].

summaries have also been distinguished by their content. a sum-
mary that enables the reader to determine about-ness has often been
called an indicative summary, while one that can be read in place of the
document has been called an informative summary [52]. an indicative
summary may provide characteristics such as length, writing style, etc.,
while an informative summary will include facts that are reported in
the input document(s).

1 http://lada.si.umich.edu:8080/clair/nie1/nie.cgi,
edu.

http://newsblaster.columbia.

106

introduction

most research in summarization deals with producing a short,
paragraph-length summary. at the same time, a speci   c application
or user need might call for a keyword summary, which consists of a set
of indicative words or phrases mentioned in the input, or headline sum-
marization in which the input document(s) is summarized by a single
sentence.

much of the work to date has been in the context of generic
summarization. generic summarization makes few assumptions about
the audience or the goal for generating the summary. typically, it is
assumed that the audience is a general one: anyone may end up read-
ing the summary. furthermore, no assumptions are made about the
genre or domain of the materials that need to be summarized. in this
setting, importance of information is determined only with respect to
the content of the input alone. it is further assumed that the summary
will help the reader quickly determine what the document is about,
possibly avoiding reading the document itself.

in contrast, in query focused summarization, the goal is to sum-
marize only the information in the input document(s) that is relevant
to a speci   c user query. for example, in the context of information
retrieval, given a query issued by the user and a set of relevant doc-
uments retrieved by the search engine, a summary of each document
could make it easier for the user to determine which document is rel-
evant. to generate a useful summary in this context, an automatic
summarizer needs to take the query into account as well as the docu-
ment. the summarizer tries to    nd information within the document
that is relevant to the query or in some cases, may indicate how much
information in the document relates to the query. producing snippets
for search engines is a particularly useful query focused application
[207, 213]. researchers have also considered cases where the query is
an open-ended question, with many di   erent facts possibly being rel-
evant as a response. a request for a biography is one example of an
open-ended question as there are many di   erent facts about a person
that could be included, but are not necessarily required.

update summarization addresses another goal that users may
have. it is id57 that is sensitive to time; a

1.2 how do summarization systems work?

107

summary must convey the important development of an event beyond
what the user has already seen.

the contrast between generic, query-focused, and update summa-
rization is suggestive of other issues raised by sparck jones in her 1998
call to arms [194]. sparck jones argued that summarization should
not be done in a vacuum, but rather should be viewed as part of a
larger context where, at the least, considerations such as the purpose
of summarization (or task which it is part of), the reader for which it
is intended, and the genre which is being summarized, are taken into
account. she argued that generic summarization was unnecessary and
in fact, wrong-headed. of course, if we look at both sides of the ques-
tion, we see that those who write newspaper articles do so in much the
same spirit in which generic summaries are produced: the audience is a
general one and the task is always the same. nonetheless, her arguments
are good ones as they force the system developer to think about other
constraints on the summarization process and they raise the possibility
of a range of tasks other than to simply condense content.

1.2 how do summarization systems work?

summarization systems take one or more documents as input and
attempt to produce a concise and    uent summary of the most impor-
tant information in the input. finding the most important information
presupposes the ability to understand the semantics of written or spo-
ken documents. writing a concise and    uent summary requires the
capability to reorganize, modify and merge information expressed in
di   erent sentences in the input. full interpretation of documents and
generation of abstracts is often di   cult for people,2 and is certainly
beyond the state of the art for id54.

how then do current automatic summarizers get around this conun-
drum? most current systems avoid full interpretation of the input
and generation of    uent output. the current state of the art in the
vast majority of the cases relies on sentence extraction. the extractive
approach to summarization focuses research on one key question: how

2 for discussion of professional summarization, see [114].

108

introduction

can a system determine which sentences are important? over the years,
the    eld has seen advances in the sophistication of language processing
and machine learning techniques that determine importance.

at the same time, there have been recent advances in the    eld which
move toward semantic interpretation and generation of summary lan-
guage. semantic interpretation tends to be done for specialized summa-
rization. for example, systems that produce biographical summaries or
summaries of medical documents tend to use extraction of information
rather than extraction of sentences. research on generation for sum-
marization uses a new form of generation, text-to-text generation and
focuses on editing input text to better    t the needs of the summary.

1.2.1 early methods for sentence extraction

most traditional approaches to summarization deal exclusively with
the task of identifying important content, usually at the sentence level.
the very    rst work on id54, done by luhn [111]
in the 1950s, set the tradition for sentence extraction.

his approach was implemented to work on technical papers and
magazine articles. luhn put forward a simple idea that shaped much
of later research, namely that some words in a document are descriptive
of its content, and the sentences that convey the most important infor-
mation in the document are the ones that contain many such descriptive
words close to each other that. he also suggested using frequency of
occurrence in order to    nd which words are descriptive of the topic of
the document; words that occur often in the document are likely to be
the main topic of this document. luhn brought up two caveats: some
of the most common words in a technical paper or a magazine arti-
cle, and in fact in any type of document, are not at all descriptive of
its content. common function words such as determiners, prepositions
and pronouns do not have much value in telling us what the document
is about. so he used a prede   ned list, called a stop word list, consist-
ing of such words to remove them from consideration. another class
of words that do not appear in the stop word list but still cannot be
indicative of the topic of a document are words common for a par-
ticular domain. for example, the word    cell    in a scienti   c paper in

1.2 how do summarization systems work?

109

cell biology is not likely to give us much idea about what the paper is
about. finally, words that appear in the document only a few times are
not informative either. luhn used empirically determined high and low
frequency thresholds for identifying descriptive words, with the high
thresholds    ltering out words that occur very frequently throughout
the article and the low thresholds    ltering out words that occur too
infrequently. the remaining words are the descriptive words, indicative
of the content that is important. sentences characterized by high den-
sity of descriptive words, measured as clusters of    ve consecutive words
by luhn, are the most important ones and should be included in the
summary.

in the next section we discuss how later work in sentence extraction
adopted a similar view of    nding important information but re   ned the
ideas of using raw frequency by proposing weights for words, such as
tf   idf, in order to circumvent the need for coming up with arbitrary
thresholds in determining which words are descriptive of a document.
later, statistical tests on word distributions were proposed to decide
which words are topic words and which are not. other approaches
abandoned the idea of using words as the unit of operation, and used
word frequency indirectly to model the similarity between sentences
and derive measures of sentence importance from these relationships.
we present these approaches in greater detail in section 2, as they have
proven to be highly e   ective, relatively robust to genre and domain, and
are often referenced in work on id54.

there are some obvious problems with luhn   s approach. the same
concept can be referred to using di   erent words: consider for exam-
ple    approach   ,    method       algorithm   , and    it   . di   erent words may
indicate a topic when they appear together; for example    hurricane   ,
   damage   ,    casualties   ,    relief    evoke a natural disaster scenario. the
same word can appear in di   erent morphological variants        show   ,
   showing   ,    showed        and counts of words as they appear in the text
will not account for these types of repetition. in fact, luhn was aware
of these problems and he employed a rough approximation to morpho-
logical analysis, collapsing words that are similar except for the last
six letters, to somewhat address this problem. after our presentation
of word frequency-driven approaches in section 2.1, we brie   y discuss

110

introduction

work based on the use of coreference systems and knowledge sources
that perform input analysis and interpretation. these methods can bet-
ter address these challenges and are discussed in section 3. in essence
these are still frequency approaches, but counting is performed in a
more intelligent manner. such approaches incur more processing over-
head, which is often undesirable for practical purposes, but comes closer
to the ideal of developing systems that are in fact interpreting the input
before producing a summary.

edmundson   s [52] work was the foundation of several other trends
in summarization research which eventually led to machine learning
approaches in summarization. he expanded on luhn   s approach by
proposing that multiple features may indicate sentence importance. he
used a linear combination of features to weight sentences in a scien-
ti   c article. his features were: (1) number of times a word appears in
the article, (2) the number of words in the sentence that also appear
in the title of the article, or in section headings, (3) position of the
sentence in the article and in the section, (4) the number of sen-
tence words matching a pre-compiled list of cue words such as    in
sum   . a compelling aspect of edmundson   s work that foreshadows
today   s empirically based approaches, was the creation of a document/
extractive summary corpus. he used the corpus both to determine
weights on the four features and to do evaluation. his results inter-
estingly suggest that word frequency is the least important of the four
classes of features, for his speci   c task and corpus. his other features
take advantage of knowledge of the domain and genre of the input
to the summarizer. we discuss such domain dependent approaches,
which make use of domain-dependent knowledge sources and of speci   c
domain characteristics, for summarization of scienti   c articles, medical
information and email in section 5.

in other relatively early and seminal work, paice [164, 165] shifted
the research focus toward the need for language generation techniques
in summarization. he focused on the problem in extractive summa-
rization of accidentally selecting sentences that contain unresolved ref-
erences to sentences not included in the summary or not explicitly
included in the original document. the problem can arise not only
because of the presence of a pronouns but also because of a wide variety

1.2 how do summarization systems work?

111

of other phrases (exophora) such as    our investigations have shown this
to be true.    and    there are three distinct methods to be considered.   
paice built an extractive summarizer which uses the presence of phrases
from a list that he compiled, such as    the main goal of our paper . . .    ,
to determine an initial set of seed sentences that should be selected.
then an aggregation procedure adds sentences preceding or following
the seed until all exophora are resolved. paice also suggested modifying
sentences to resolve exophora when the reference can be found but did
not implement an actual system for doing this. paice   s research was
the    rst to point out the problem of accidentally including exophora
in extractive summaries, but the solution of simply adding more sen-
tences until the antecedent is found is not satisfactory and much later
research on using language generation for summarization has revisited
the problem as we discuss in section 4.

1.2.2 non-extractive approaches

the current state of the art in the vast majority of the cases completely
ignores issues of language generation and relies on sentence extrac-
tion, producing extractive summaries composed of important sentences
taken verbatim from the input. the sole emphasis in such systems is to
identify the important sentences that should appear in the summary.
meanwhile, the development of automatic methods for language gen-
eration and text quality has become somewhat independent sub   elds
of research motivated but not directly linked to the    eld of summa-
rization. below we brie   y introduce some of the main areas of research
that are needed for enhancing current summarization systems.

sentence ordering. this is the problem of taking several sentences,
such as those deemed to be important by an extractive summarizer,
and presenting them in the most coherent order.

below we reproduce an example from [9], that shows two di   erent
orderings of the same content. the    rst example is one rated as poor
by readers, and the second is one rated as good. the examples make
it clear that the order of presentation makes a big di   erence for the
overall quality of the summary and that certain orderings may pose

112

introduction

problems for the reader trying to understand the gist of the presented
information.

summary 1; rated poor

p1 thousands of people have attended a ceremony in nairobi commemorating the
   rst anniversary of the deadly bombings attacks against u.s. embassies in
kenya and tanzania.

p2 saudi dissident osama bin laden, accused of masterminding the attacks, and

nine others are still at large.

p3 president clinton said, the intended victims of this vicious crime stood for

everything that is right about our country and the world.

p4 u.s. federal prosecutors have charged 17 people in the bombings.
p5 albright said that the mourning continues.
p6 kenyans are observing a national day of mourning in honor of the 215 people

who died there.

summary 2; rated good

p1 thousands of people have attended a ceremony in nairobi commemorating the
   rst anniversary of the deadly bombings attacks against u.s. embassies in
kenya and tanzania. kenyans are observing a national day of mourning
in honor of the 215 people who died there.

p2 saudi dissident osama bin laden, accused of masterminding the attacks, and
nine others are still at large. u.s. federal prosecutors have charged 17 people
in the bombings.

p3 president clinton said,    the intended victims of this vicious crime stood for
everything that is right about our country and the world   . albright said
that the mourning continues.

sentence revision. sentence revision was historically the    rst lan-
guage generation task attempted in the context of summarization
[89, 116, 146, 147, 162]. sentence revision involves re-using text col-
lected from the input to the summarizer, but parts of the    nal summary
are automatically modi   ed by substituting some expressions with other
more appropriate expressions, given the context of the new summary.
types of revisions proposed by early researchers include elimination
of unnecessary parts of the sentences, combination of information
originally expressed in di   erent sentences and substitution of a pro-
noun with a more descriptive noun phrase where the context of the
summary requires this [116]. given that implementation of these revi-
sion operations can be quite complex, researchers in the    eld eventually

1.2 how do summarization systems work?

113

established largely non-overlapping sub-   elds of research, each concen-
trating on only one type of revision.
sentence fusion. sentence fusion is the task of taking two sentences
that contain some overlapping information, but that also have frag-
ments that are di   erent. the goal is to produce a sentence that con-
veys the information that is common between the two sentences, or a
single sentence that contains all information in the two sentences, but
without redundancy.

here we reproduce two examples of fusion from [96]. the    rst one
conveys only the information that is common to two di   erent sentences,
a and b, in the input documents to be summarized (intersection), while
the second combines all the information for the two sentences (union).

sentence a post-traumatic stress disorder (ptsd) is a psychological disorder

which is classi   ed as an anxiety disorder in the dsm-iv.

sentence b post-traumatic stress disorder (abbrev. ptsd) is a psychological dis-
order caused by a mental trauma (also called psychotrauma) that can
develop after exposure to a terrifying event.

fusion 1 post-traumatic stress disorder (ptsd) is a psychological disorder.
fusion 2 post-traumatic stress disorder (ptsd) is a psychological disorder, which
is classi   ed as an anxiety disorder in the dsm-iv, caused by a mental
trauma (also called psychotrauma) that can develop after exposure to a
terrifying event.

sentence compression. researchers interested in sentence compres-
sion were motivated by the observation that human summaries often
contain parts of sentences from the original documents which are being
summarized, but some portions of the sentence are removed to make it
more concise.

below we reproduce two examples from the zi   -davis corpus of
sentence compression performed by a person, alongside the original
sentence from the document. it is clear from the examples that com-
pression not only shortens the original sentences but also makes them
much easier to read.

comp1 the reverse engineer tool is priced from $8,000 for a single user to $90,000

for a multiuser project site.

orig1 the reverse engineer tool is available now and is priced on a site-licensing
basis, ranging from $8,000 for a single user to $90,000 for a multiuser project
site.

114

introduction

comp2 design recovery tools read existing code and translate it into de   nitions

and structured diagrams.

orig2 essentially, design recovery tools read existing code and translate it into
the language in which case is conversant     de   nitions and structured
diagrams.

we discuss sentence ordering and language generation approaches
in section 4. the examples above clearly demonstrate the need for
such approaches in order to build realistic, human-like, summarization
systems. yet the majority of current systems rely on sentence extraction
for selecting content and do not use any of the text-to-text generation
techniques, leaving the opportunity for signi   cant improvements with
further progress in language generation.

1.3 evaluation issues

the tension between generic and query-focused summarization,
sentence-extraction and more sophisticated methods was also apparent
in the context of the duc (document understanding conference) eval-
uation workshops [163]. despite its name, duc was initially formed
in 2001 to evaluate work on summarization and was open to any group
interested in participating. its independent advisory board was charged
with identifying tasks for evaluation. generic summarization was the
initial focus, but in later years it branched out to cover various task-
based e   orts, including a variation on query-focused summarization,
topic-based summarization. the    rst of the topic-based tasks was to
provide a summary of information about a person (similar to a biog-
raphy), given a set of input documents on that person, while later on,
a system was provided with a paragraph-length topic and a set of doc-
uments and was to use information within the documents to create a
summary that addressed the topic.

generic single document summarization of news was discontinued
as a task at duc after the    rst two years of the evaluations because no
automatic summarizer could outperform the simple baseline consist-
ing of the beginning of the news article, when using manual evaluation
metrics. similarly, for the task of headline generation     creating a
10-word summary of a single news article     no automatic approach

1.4 where does summarization help?

115

outperformed the baseline of using the original headline of the article.
for both tasks, human performance was signi   cantly higher than that
of the baselines, showing that while not yet attainable, better perfor-
mance for automatic systems is possible [148].

duc, which was superseded by the text analysis conference
(tac) in 2007, provided much needed data to the research community,
allowing the development of empirical approaches. given the di   culty
of evaluation, duc fostered much research on evaluation. however,
because the metrics emphasized content selection, research on the lin-
guistic quality of a summary was not necessary. furthermore, given the
short time-frame within which tasks were introduced, summarization
researchers who participated in duc were forced to come up with a
solution that was quick to implement. exacerbating this more, given
that people like to win, researchers were more likely to try incremen-
tal, safe approaches that were likely to come out on top. thus, duc
in part encouraged the continuation of the    safe    approach, sentence
extraction, even while it encouraged research on summarization and
evaluation.

1.4 where does summarization help?

while evaluation forums such as duc and tac enable experimental
setups through comparison to a gold standard, the ultimate goal in
development of a summarization system is to help the end user perform
a task better. numerous task-based evaluations have been performed to
establish that summarization systems are indeed e   ective in a variety of
tasks. in the tipster text summarization evaluation (summac),
single-document summarization systems were evaluated in a task-based
scenario developed around the tasks of real intelligence analysts [113].
this large-scale study compared the performance of a human in judging
if a particular document is relevant to a topic of interest, by reading
either the full document or a summary thereof. it established that
automatic text summarization is very e   ective in relevance assessment
tasks on news articles. summaries as short as 17% of the full text length
sped up decision-making by almost a factor of two, with no statistically
signi   cant degradation in accuracy. query-focused summaries are also

116

introduction

very helpful in making relevance judgments about retrieved documents.
they enable users to    nd more relevant documents more accurately,
with less need to consult the full text of the document [203].

id57 is key for organizing and present-
ing search results in order to reduce search time, especially when the
goal of the user is to    nd as much information as possible about a
given query [112, 131, 181]. in mckeown et al. [131], users were given a
task of writing reports on speci   ed topics, with an interface containing
news articles, some relevant to the topic and some not. when articles
were clustered and summaries for the related articles were provided,
people tended to write better reports, but moreover, they reported
higher satisfaction when using the information access interface aug-
mented with summaries; they felt they had more time to complete the
task. similarly, in the work of mana-l  opez et al. [112], users had to
   nd as many aspects as possible about a given topic. id91 simi-
lar articles returned from a search engine together proved to be more
advantageous than traditional ranked list presentation, and consider-
ably improved user accuracy in    nding relevant information. providing
a summary of the articles in each cluster that conveys the similarities
between them, and single-document summaries highlighting the infor-
mation speci   c to each document, also helped users in    nding informa-
tion, but in addition considerably reduced time as users read fewer full
documents.

in summarization of scienti   c articles, the user goal is not only to
   nd articles relevant to their interest, but also to understand in what
respect a scienti   c paper relates to the previous work it describes and
cites. in a study to test the utility of scienti   c paper summarization
for determining which of the approaches mentioned in the paper are
criticized and which approaches are supported and extended, automatic
summaries were found to be almost as helpful as human-written ones,
and signi   cantly more useful than the original article abstract [199].

voicemail summaries are helpful for recognizing the priority of the
message, the call-back number, or the caller [95]; summaries of threads
in help forums are useful in deciding if the thread is relevant [151], and
summaries of meetings are a necessary part of interfaces for meeting
browsing and search [205].

1.5 article overview 117

numerous studies have also been performed to investigate and con-
   rm the usefulness of single document summaries for improvement of
other automated tasks. for example, sakai and sparck jones [182]
present the most recent and extensive study (others include [22] and
several studies conducted in japan and published in japanese) on the
usefulness of generic summaries for indexing in information retrieval.
they show that, indeed, indexing for retrieval based on automatic
summaries rather than full document text helps in certain scenarios
for precision-oriented search. similarly, id183 in informa-
tion retrieval is much more e   ective when potential expansion terms
are selected from a summary of relevant documents instead of the full
document [100].

another unexpectedly successful application of summarization for
improvement of an automatic task has been reported by [23]. they
examined the impact of summarization on the automatic topic classi   -
cation module that is part of a system for automatic scoring of student
gmat essays. their results show that summarization of the student
essay signi   cantly improves the performance of the topical analysis
component. the conjectured reason for the improvement is that the
students write these essays under time constraints and do not have
su   cient time for revision and thus their writing contains some digres-
sions and repetitions, which are removed by the summarization module,
allowing for better assessment of the overall topic of the essay.

the potential uses and applications of summarization are incredibly
diverse as we have seen in this section. but how do these systems work
and what are the open problems not currently handled by systems? we
turn to this discussion next.

1.5 article overview

we begin our summarization overview with a presentation of research
on sentence extraction in section 2. in that section, we    rst present
earlier research on summarization that experimented with methods for
determining sentence importance that are based on variants of fre-
quency. machine learning soon became the method of choice for deter-
mining pertinent features for selecting sentences. from there, we move

118

introduction

to graph-based approaches that select sentences based on their rela-
tions to other sentences. finally, we close section 2 by looking at the
use of sentence extraction for query-focused summarization. one case
of query-focused summarization is the generation of biographical sum-
maries and we see that when the task is restricted (here to one class of
queries), researchers begin to develop approaches that di   er substan-
tially from the typical generic extraction based approach.

in section 3, we continue to survey extractive approaches, but
move to methods that do more sophisticated analysis to determine
importance. we begin with approaches that construct lexical chains
which represent sentence relatedness through word and synonym over-
lap across sentences. the hypothesis is that each chain represents a
topic and that topics that are pursued for greater lengths are likely to
be more salient. we then turn to approaches that represent or compute
concepts and select sentences that refer to salient concepts. finally, we
turn to methods that make use of discourse information, either in the
form of rhetorical relations between sentences, or to augment graph-
based approaches.

in section 4, we examine the di   erent sub-   elds that have grown
up around various forms of sentence revision. we look at methods that
compress sentences by removing unnecessary detail. we then turn to
methods that combine sentences by fusing together repeated and salient
information from di   erent sentences in the input. next, we turn to work
that edits summary sentences, taking into account the new context of
the summary. we close with research on ordering of summary sentences.
in the    nal section on approaches, section 5, we survey research
that has been carried out for speci   c genres and domains. we    nd that
often documents within a speci   c genre have an expected structure and
that structure can be exploited during summary generation. this is the
case, for example, with journal article summarization. at other times,
we    nd that while the form of the genre creates problems (e.g., speech
has dis   uencies and errors resulting from recognition that cause di   -
culties), information beyond the words themselves may be available to
help improve summarization results. in speech summarization, acous-
tic and prosodic clues can be used to identify important information,
while in very recent work on web summarization, the structure of the

1.5 article overview 119

web can be used to determine importance. in some domains, we    nd
that domain dependant semantic resources are available and the nature
of the text is more regular so that semantic interpretation followed by
generation can be used to produce the summary; this is the case in the
medical domain.

before concluding, we provide an overview in section 6 on research
in summarization evaluation. much of this work was initiated with
duc as the conference made evaluation data available to the commu-
nity for the    rst time. methodology for evaluation is a research issue
in itself. when done incorrectly, evaluation does not accurately reveal
which system performs better. in section 6, we review intrinsic methods
for evaluation. intrinsic refers to methods that evaluate the quality of
the summary produced, usually through comparison to a gold stan-
dard. this is in contrast to extrinsic evaluation where the evaluation
measures the impact of the summary on task performance such as the
task-based evaluations that we just discussed. we review metrics used
for comparison against a gold standard as well as both manual and
automatic methods for comparison. we discuss the di   erence between
evaluation of summary content and evaluation of the linguistic quality
of the summary.

2

sentence extraction: determining importance

in this section, we survey methods for determining sentence importance
for extractive summarization.

we begin with a detailed discussion of robust, easily computable
features for determining the importance of a sentence; these features
do not rely on any sources of information beyond the input to the
summarizer. the approaches in this class are completely unsupervised,
and do not require any sort of human judgements about what sen-
tences need to be present in the summary. the features vary in terms
of expressive power and sophistication but are all ultimately directly
related to tracking some form of repetition, redundancy or frequency in
the input. frequency can be counted on the word level and we present
three approaches with increasing complexity and descriptive power for
doing so: word id203, tf   idf word weight, and the log-likelihood
ratio (llr) test for determining if a word is indicative of the topic of the
input. we discuss these in detail because variants of tf   idf weights
are used in some form in most extractive summarizers, while a system
that relies on the llr test achieved the best performance in determin-
ing content in the o   cial duc evaluations for multi-document sum-
marization of news [40]. we also introduce methods in which repetition

120

2.1 unsupervised data-driven methods

121

of information is tracked on the sentence level, through sentence clus-
tering, or via a combination of lexical and sentence information, as in
graph-based models.

the repetition of the same entity or topic can be done using di   erent
lexical items: either synonyms or related words, or pronouns. in order
to make possible a more accurate account of frequency, researchers
have made use of coreference resolution systems and of existing lexi-
cal resources which are either manually or automatically constructed
and which contain information about related words. in these methods,
importance is determined for concepts, lexical chains or entities instead
of words. latent semantic analysis, which has been extensively used for
summarization of meetings, combines aspects of the lexical frequency
approaches and those informed by knowledge on lexical relationships,
but the knowledge is implicit, derived from word co-occurrences in a
large number of di   erent documents.

use of machine learning approaches allows researchers the freedom
to use numerous features. we overview only the main machine learn-
ing approaches that had the most signi   cant impact on summarization
research at the time they were proposed. numerous later papers discuss
machine learning either as a standard tool or in the context of com-
paring di   erent machine learning approaches and techniques, without
direct bearing on summarization itself.

finally, we discuss a distinction in sentence extraction that is
rarely emphasized: are sentences selected one by one, or jointly. in
greedy approaches in the tradition of maximal marginal relevance, sen-
tences are selected in order, one after the other. in global optimization
approaches, the best overall summary is selected, consisting of several
sentences that jointly satisfy some conditions.

2.1 unsupervised data-driven methods

unsupervised methods for sentence extraction are the predominant
paradigm in extractive summarization. they do not require human
annotation for training statistical methods for importance. they are
   data-driven    because they do not rely on any external knowledge
sources, models or on linguistic processing and interpretation.

122

sentence extraction: determining importance

2.1.1 methods based on word frequency

as we discussed in our historical overview of id54
in section 1, the earliest work in the area, conducted by luhn, explored
the use of lexical frequency as an indicator of importance. one way to
capture his intuitions is to calculate word id203 for content words
from the input to the summarizer. but as luhn pointed out, some of
the most frequent words in the document might not be indicative of
what is important in a particular document because they occur often in
many documents. tf   idf weights have been proposed in information
retrieval to deal with exactly this problem; in addition to frequency in
the input, this method incorporates evidence from a background cor-
pus to adjust the weights of individual words so that the words with
highest weights are those most likely to be descriptive of the topic of
the particular document. log-likelihood ratio approaches not only use a
background corpus, but also allow for the de   nition of topic signature
words that are the sole words in the input that determine importance
of sentences while other words are entirely ignored in the calculation
of importance. of these three approaches, the log-likelihood one leads
to best results for greedy sentence-by-sentence multi-document sum-
marization of news [40, 70].

word id203 is the simplest form of using frequency in the
input as an indicator of importance.1 the id203 of a word w, p(w)
is computed from the input, which can be a cluster of related documents
or a single document. it is calculated as the number of occurrences of
a word, c(w) divided by the number of all words in the input, n:

p(w) = c(w)
n

(2.1)

given this id203 distribution over words, the likelihood of a

summary can be computed based on a multinomial distribution:

l[sum] = m!

n1! . . . nr! p(w1)n1              p(wr)nr

(2.2)

1 raw frequency would be even simpler, but this measure is too strongly in   uenced by
document length. a word appearing twice in a 10 word document may be important,
but not necessarily so in a 1000 word document. computing word id203 makes an
adjustment for document length.

2.1 unsupervised data-driven methods

123

where m is the number of words in the summary, n1 +        + nr = m
and for each i, ni is the number of times word wi appears in the sum-
mary and p(wi) is the id203 of wi appearing in the summary
estimated from the input documents.

nenkova et al. [155] analyzed 30 duc inputs consisting of multiple
news articles on the same topic, along with four human abstracts for
each, and found that for this data, the likelihood of human summaries is
higher than that of automatically produced summaries. these    ndings
indicate that when writing abstracts for multi-document inputs, people
do tend to be guided by frequency in their selections of topics to be
included in their summaries.

sumbasic is one system developed to operationalize the idea of
using frequency for sentence selection. it relies only on word prob-
in the
ability to calculate importance [212]. for each sentence sj
input it assigns a weight equal to the average id203 p(wi) of
the content words in the sentence, estimated from the input for
summarization:

weight(sj) = !wi   sj

p(wi)
|{wi|wi     sj}|

(2.3)

then, in a greedy fashion, sumbasic picks the best scoring sentence
that contains the word that currently has the highest id203.
this selection strategy assumes that at each point when a sentence
is selected, a single word     that with highest id203     repre-
sents the most important topic in the document and the goal is to
select the best sentence that covers this word. after the best sentence
is selected, the id203 of each word that appears in the chosen
sentence is adjusted. it is set to a smaller value, equal to the square
of the id203 of the word at the beginning of the current selection
step, to re   ect the fact that the id203 of a word occurring twice
in a summary is lower than the id203 of the word occurring only
once. this selection loop is repeated until the desired summary length
is achieved.

an approach that optimizes the occurrence of important words glob-
ally over the entire summary instead of greedy selection outperforms
sumbasic [198].

124

sentence extraction: determining importance

tf*idf weighting (term frequency   inverse document fre-
quency) one problem with frequency as an indicator of importance is
the fact that in any general text the occurrence of words follows a zip-
   an distribution [3], with a few words appearing very often and many
words appearing infrequently. the most frequent words are known in
information retrieval as stop words. stop words include determiners,
prepositions and auxiliary verbs, or common domain words. obviously,
such words are not indicative of topicality. determining a useful cut-o   
threshold that works for a variety of documents and document lengths
is not trivial. instead, researchers have opted for use of a stop word list
consisting of the most frequent words in a language and a particular
domain     such words would not play any role in determining sentence
importance. deciding what words should be included in the stop word
list is not straightforward though and some most recent methods have
attempted to dynamically model which words should be considered
representative of general english rather than of the topic of a given
document [45].

alternatively, the tf   idf weighting of words [184, 193], as tradi-
tionally used in information retrieval, can be employed. this weighting
exploits counts from a large background corpus, which is a large col-
lection of documents, normally from the same genre as the document
that is to be summarized; the background corpus serves as indication
of how often a word may be expected to appear in an arbitrary text.
the only additional information besides the term frequency c(w)
that we need in order to compute the weight of a word w which appears
c(w) times in the input for summarization is the number of documents,
d(w), in a background corpus of d documents that contain the word.
this allows us to compute the inverse document frequency:

tf   idfw = c(w)    log d
d(w)

(2.4)

in many cases c(w) is divided by the maximum number of occur-
rences of any word in the document, which normalizes for document
length. descriptive topic words are those that appear often in a docu-
ment, but are not very common in other documents. in contrast, stop-
words appear in practically all documents, so their idf weight will

2.1 unsupervised data-driven methods

125

be close to zero. the tf   idf weights of words are good indicators of
importance, and they are easy and fast to compute. these properties
explain why tf   idf is one of the most commonly used features for
extractive summarization: it is incorporated in one form or another in
most current systems [56, 58, 61, 62, 63, 81].

log-likelihood ratio test for topic signatures an even more
powerful use of frequency is the application of the log-likelihood ratio
test [51] for identi   cation of words that are highly descriptive of the
input. such words have been traditionally called    topic signatures    in
the summarization literature [106].

topic signatures are words that occur often in the input but are
rare in other texts, similarly to words with high tf   idf weight. unlike
tf   idf, the log-likelihood ratio test provides a way of setting a thresh-
old to divide all words in the input into either descriptive or not.

information about the frequency of occurrence of words in a large
background corpus is necessary to compute the statistic on the basis
of which topic signature words are determined. the likelihood of the
input i and the background corpus is computed under two assumptions:
(h1) that the id203 of a word in the input is the same as in the
background b or (h2) that the word has a di   erent, higher id203,
in the input than in the background.

h1: p (w|i) = p (w|b) = p (w is not descriptive)
h2: p (w|i) = pi and p (w|b) = pb and pi > pb (w is descriptive)
the likelihood of a text with respect to a given word of interest, w,
is computed via the binomial distribution formula. the input and the
background corpus are treated as a sequence of words wi: w1w2 . . . wn.
the occurrence of each word is a bernoulli trial with id203 p of
success, which occurs when wi = w. the overall id203 of observing
the word w appearing k times in the n trials is given by the binomial
distribution

b(k, n, p) ="n

k#pk(1     p)n   k

(2.5)

for h1, the id203 p is computed from the input and the back-
ground collection taken together. for h2, p1 is computed from the
input, p2 from the background, and the likelihood of the entire data

126

sentence extraction: determining importance

is equal to the product of the binomial for the input and that for the
background. more speci   cally, the likelihood ratio is de   ned as

   =

b(k, n, p)

b(ki, ni, pi).b(kb, nb, pb)

(2.6)

where the counts with subscript i are computed only from the input to
the summarizer and those with index b are computed over the back-
ground corpus.

the statistic equal to    2   has a known statistical distribution (  2),
which can be used to determine which words are topic signatures. topic
signature words are those that have a likelihood statistic greater than
what one would expect by chance. the id203 of obtaining a given
value of the statistic purely by chance can be looked up in a   2 distri-
bution table; for instance a value of 10.83 can be obtained by chance
with id203 of 0.001.

the importance of a sentence is computed as the number of topic
signatures it contains, or the proportion of topic signatures in the sen-
tence; words are no longer assigned weights in this approach.

an example summary produced using topic signature words as indi-
cators of importance [38], as well as a human abstract and a baseline
summary consisting of the beginning of the latest article in the input
are shown below (set d30003 from duc 2004). the example shows that
the baseline, as expected, focuses on only a single aspect of the story,
while the topic words summarizer is able to select sentences from the
input that cover most of the information chosen by the person writing
the model abstract.

baseline the swiss government has ordered no investigation of possible bank
accounts belonging to former chilean dictator augusto pinochet, a
spokesman said wednesday. weekend newspaper reports in spain said a
spanish judge who ordered pinochet   s arrest has issued a petition aimed
at freezing any accounts the 82-year-old general might have in luxem-
bourg and switzerland. but government spokesman achille casanova said
no accounts have so far been frozen in switzerland and no investigation
order has been given to federal banking authorities. pinochet has been
held at a london clinic since his arrest earlier this month.

2.1 unsupervised data-driven methods

127

topic signatures as his lawyers in london tried to quash a spanish arrest
warrant for gen. augusto pinochet, the former chilean dictator, e   orts
began in geneva and paris to have him extradited. britain has defended
its arrest of gen. augusto pinochet, with one lawmaker saying that chile   s
claim that the former chilean dictator has diplomatic immunity is ridicu-
lous. margaret thatcher entertained former chilean dictator gen. augusto
pinochet at her home two weeks before he was arrested in his bed in a
london hospital, the ex-prime minister   s o   ce said tuesday, amid growing
diplomatic and domestic controversy over the move.

human abstract former chilean dictator augusto pinochet has been arrested
in london at the request of the spanish government. pinochet, in london
for back surgery, was arrested in his hospital room. spain is seeking extra-
dition of pinochet from london to spain to face charges of murder in the
deaths of spanish citizens in chile under pinochet   s rule in the 1970s and
1980s. the arrest raised confusion in the international community as the
legality of the move is debated. pinochet supporters say that pinochet   s
arrest is illegal, claiming he has diplomatic immunity. the    nal outcome
of the extradition request lies with the spanish courts.

the idea of topic signature terms for summarization was introduced
by lin and hovy [106] in the context of single document summarization,
as part of the summarist [81] system. later systems also used topic
signature features for the task of id57 of
news [38, 40, 98]. topic signatures are more powerful than direct use
of frequency because they give a natural cut-o    for deciding which
words should be considered topical, based on an actual id203
distribution [70].

2.1.2 sentence id91

in id57 of news, the input by de   nition con-
sists of several articles, possibly from di   erent sources, on the same
topic. in this setting, it is very likely that across the di   erent articles
there will be sentences that contain similar information. information
that occurs in many of the input documents is considered important
and worth selecting in a summary. of course, verbatim repetition on

128

sentence extraction: determining importance

the sentence level is not that common across sources. rather, similar
sentences can be clustered together [133, 76, 190]. clusters with many
sentences represent important topic themes in the input. selecting one
representative sentence from each main cluster is one way to produce
an extractive summary using this approach, while minimizing possible
redundancy in the summary.

the sentence id91 approach to id57
again exploits repetition, but at the sentence rather than the word
level. the more sentences there are in a cluster, the more important
the information in the cluster is considered. below is an example of
a sentence cluster from di   erent documents in the input to a multi-
document summarizer. all four sentences share common content, which
is considered important.

s1 pal was devastated by a pilots    strike in june and by the region   s currency

crisis.

s2 in june, pal was embroiled in a crippling three-week pilots    strike.
s3 tan wants to retain the 200 pilots because they stood by him when the majority

of pal   s pilots staged a devastating strike in june.

s4 in june, pal was embroiled in a crippling three-week pilots    strike.

a drawback of the id91 approach is that each sentence is
assigned to only one cluster, which is a restrictive requirement for typ-
ical sentences that express several facts. the graph-based approaches
discussed next allow for much more    exibility in representation and
lead to better overall results in content selection for multi-document
summarization.

2.1.3 graph-based methods for sentence ranking

graph-based methods for sentence ranking productively exploit repe-
tition in the input, both on the word and sentence level. sentence simi-
larity is measured as a function of word overlap, so frequently occurring
words would link many sentences, and similar sentences give support
for each other   s importance. in this way, graph approaches combine
advantages from word frequency and sentence id91 methods [169].
moreover, such methods provide a formal model for computing sentence
importance.

2.1 unsupervised data-driven methods

129

in the graph-based models that have been most popular recently and
have been evaluated on duc data [56, 135], the input is represented
as a highly connected graph. vertices represent sentences and edges
between sentences are assigned weights equal to the similarity between
the two sentences. the method most often used to compute similarity is
cosine similarity with tf   idf weights for words. the weights of edges
connecting sentences that share many lexical items will be higher than
for those connecting sentences that have fewer lexical items in com-
mon. in this way, word frequency plays a direct role in determining
the structure of the graph. sometimes, instead of assigning weights to
edges, the connections between vertices can be determined in a binary
fashion: the vertices are connected only if the similarity between the
two sentences exceeds a pre-de   ned threshold. in addition, this graph
representation is more    exible than sentence id91     tightly con-
nected cliques in the graph could be seen as representing a cluster, but
sentences are no longer constrained to belong to exactly one cluster.

vertex importance or centrality can be computed using general
graph algorithms, such as id95 [56, 135]. when the weights of
the edges are normalized to form a id203 distribution so that
the weight of all outgoing edges from a given vertex sum up to one, the
graph becomes a markov chain and the edge weights correspond to the
id203 of transitioning from one state to another. standard algo-
rithms for stochastic processes can be used to compute the id203
of being in each vertex of the graph at time t while making consecutive
transitions from one vertex to next. as more and more transitions are
made, the id203 of each vertex converges, giving the stationary
distribution of the chain. the stationary distribution simply gives the
id203 of (being at) a given vertex and can be computed using
iterative approximation. vertices with higher probabilities correspond
to more important sentences that should be included in the summary.
a summary produced using this graph-based approach for a duc

2004 input set is shown below [55]:

graph-based summary cuban president fidel castro said sunday he dis-
agreed with the arrest in london of former chilean dictator augusto
pinochet calling it a case of international meddling. pinochet, 82, was

130

sentence extraction: determining importance

placed under arrest in london friday by british police acting on a war-
rant issued by a spanish judge. the chilean government has protested
pinochet   s arrest insisting that as a senator he was traveling on a diplo-
matic passport and had immunity from arrest. castro, latin america   s only
remaining authoritarian leader, said he lacked details on the case against
pinochet but said he thought it placed the government of chile and presi-
dent eduardo frei in an uncomfortable position.

in the o   cial duc 2004 manual evaluation where both the topic
words summarizer discussed in section 2.1 [40] and the graph-based
summarizer [55] were evaluated, the topic signature summarizer per-
formed better in content selection. both summarizers outperform by a
wide margin the two traditional baselines for multi-document summa-
rization: the beginning of the latest article in the cluster or a collec-
tion of the    rst sentences of most recent articles. both topic word and
graph-based approaches are concerned only with pinpointing important
content and do not make any special decisions about sentence ordering,
for example, even though the topic words system does perform some
linguistic processing of the input text.

graph-based approaches have been shown to work well for both
single-document and id57 [56, 135]. since
the approach does not require language-speci   c linguistic processing
beyond identifying sentence and word boundaries, it can also be applied
to other languages, for example, brazilian portuguese [136]. at the
same time, incorporating syntactic and semantic role information in the
building of the text graph leads to superior results over plain tf   idf
cosine similarity [29].

using di   erent weighting schemes for links between sentences that
belong to the same article and sentences from di   erent articles can
help separate the notions of topicality within a document and recurrent
topics across documents. this distinction can be easily integrated in the
graph-based models for summarization [216].

graph representations for summarization had been explored even
before the id95 models became popular. for example, the pur-
pose of a graph-based system for id57 devel-
oped by mani and bloedorn [115] is to identify salient regions of each

2.2 machine learning for summarization

131

story related to a topic given by a user, and compare the stories by
summarizing similarities and di   erences. the vertices in the graph
are words, phrases and named entities rather than sentences and their
initial weight is assigned using tf   idf. edges between vertices are
de   ned using synonym and hypernym links in id138, as well as
coreference links. spreading activation is used to assign weights to non-
query terms as a function of the weight of their neighbors in the graph
and the type of relation connecting the nodes.

in order to avoid problems with coherence that may arise with the
selection of single sentences, salton et al. [183] argue that a summa-
rizer should select full paragraphs to provide adequate context. their
algorithm constructs a text graph for a document using cosine simi-
larity between each pair of paragraphs in the document. the shape of
the text graph determines which paragraphs to extract. in their exper-
iments, they show that two strategies, selecting paragraphs that are
well connected to other paragraphs or    rst paragraphs of topical text
segments within the graph, both produce good summaries.

a combination of the subsentential granularity of analysis where
nodes are words and phrases rather than sentences and edges are syn-
tactic dependencies has also been explored [103]. using machine learn-
ing techniques, leskovec et al. [103] attempt to learn what portions of
the input graph would be included in a summary. in their experiments
on single document summarization of news articles, properties of the
graph such as incoming and outgoing links, connectivity and id95
weights are identi   ed as the best class of features that can be used for
content selection.

2.2 machine learning for summarization

as researchers proposed more and more indicators for sentence impor-
tance,
it became necessary to come up with ways in which the
di   erent indicators can be combined. to address these problems,
kupiec et al. [97] introduced their proposal for using machine learn-
ing techniques on a corpus of summary/document pairs. kupiec et al.
claimed that statistical analysis of the corpus would both reveal what
features should be used and how they should be weighted relative to

132

sentence extraction: determining importance

each other. for their experiments they choose three features following
earlier work by paice [165], luhn [111], and edmundson [52]:    xed (cue)
phrases, paragraph features related to the position features of earlier
work distinguishing sentence-initial and sentence-   nal sentences within
a paragraph as well as paragraph-initial and paragraph-   nal positions,
and word frequency features. they also introduce two new features:
uppercase word feature to account for the importance of proper names
and acronyms and sentence length cut-o    to avoid including sentences
below a length threshold.

for learning, they used a naive bayes classi   er, making the assump-
tion that the employed features are independent of each other given the
class. their training corpus consisted of technical articles drawn from a
collection provided by engineering information. in addition, the corpus
contained abstracts for each article created by professional abstractors.
it consisted of a total of 188 document/summary pairs which were
drawn from 21 publications in the scienti   c and technical domains.
abstract sentences were matched against input article sentences using
a variety of techniques, such as exact match, join of two article sentences
for the abstract sentences, or incomplete partial matches. seventy-
nine percent of the abstract sentences in their corpus were exact
matches.

the results from the machine learning experiments for content selec-
tion show that a combination of location of the sentence,    xed-phrase
and sentence length gave the best results. when frequency features
were added for this single-document summarization task, performance
decreased slightly.

in later work, conroy and o   leary [39] show how a hidden markov
model (id48), which has fewer independence assumptions than naive
bayes learners, can be used for summarization. they experiment with
three features similar to those described in earlier work: position of
sentence in the document, number of terms in a sentence, and the
id203 of a term estimated from the input. conroy and o   leary
also deliberately exploit markov dependencies: they suggest that the
id203 that the next sentence in a document is included in a sum-
mary will depend on whether the current document sentence is already
part of the summary.

2.2 machine learning for summarization

133

to obtain training data, they asked a single person to produce

extractive summaries.

in later versions of the id48 summarizer, the number of topic sig-
nature words in the sentence was added as a feature. follow up exper-
iments showed that a data-driven summarizer using the topic word
features has a similarly high performance to that of the supervised
id48 system.

since this seminal work on summarization by learning, quite a
few others have also looked at the use of learning for summarization
[60, 74, 81, 103, 160, 220, 232]. this later work focuses primarily on the
comparison of di   erent learning techniques and feature classes. for
generic id57 of news, these methods have not
been shown to directly outperform competitive unsupervised methods
based on a single feature such as the presence of topic words and graph
methods. machine learning approaches have proved to be much more suc-
cessful in domain or genre speci   c summarization, where classi   ers can be
trained to identify speci   c types of information such as sentences describ-
ing literature background in scienti   c article summarization or utter-
ances expressing agreement or disagreement in meetings.

an additional problem inherent in the supervised learning paradigm
is the necessity of labeled data on which classi   ers can be trained. ask-
ing annotators to select summary-worthy sentences [209] is time con-
suming, and thus, many researchers have concentrated their e   orts on
developing methods for automatic alignment of human abstracts and
the input [8, 44, 88, 121, 232] in order to provide labeled data of sum-
mary and non-summary sentences for machine learning. this approach
could be potentially problematic because, as we discuss in section 6, dif-
ferent writers can choose di   erent content for their abstracts and there-
fore summary-worthy information may not be identi   able based on a
single abstract. to mitigate this issue, some researchers have proposed
to leverage the information from manual evaluation of content selec-
tion in summarization in which multiple sentences can be marked as
expressing the same fact that should be in the summary [41, 60]. alter-
natively, one could compute similarity between sentences in human
abstracts and those in the input in order to    nd very similar sentences,
not necessarily doing full alignment [28].

134

sentence extraction: determining importance

overall, given our current knowledge about sentence extraction
approaches and their evaluation, the introduction of supervised meth-
ods has not lead to measurable improvements in content selection for
generic summarization of news. extraction approaches using a single
feature, such as topic words or centrality measure weights in the graph
methods, are the ones that have the best reported results. currently,
there are no good ways to combine such features in a joint measure of
importance, except through supervised methods. future work will need
to establish if indeed the combination of strong data-driven indicators
of importance will outperform the individual unsupervised methods.

2.3 sentence selection vs. summary selection

most summarization approaches choose content sentence by sentence:
they    rst include the most informative sentence, and then if space con-
straints permit, the next most informative sentence is included in the
summary and so on. some process of checking for similarity between
the chosen sentences is also usually employed in order to avoid the
inclusion of repetitive sentences.

one of the early summarization approaches for both generic and
query focused summarization that has been widely adopted is maxi-
mal marginal relevance (mmr) [25]. in this approach, summaries are
created using greedy, sentence-by-sentence selection. at each selection
step, the greedy algorithm is constrained to select the sentence that is
maximally relevant to the user query and minimally redundant with
sentences already included in the summary. mmr measures relevance
and novelty separately and then uses a linear combination of the two to
produce a single score for the importance of a sentence in a given stage
of the selection process. to quantify both properties of a sentence, car-
bonell and goldstein use cosine similarity [118]. for relevance, similar-
ity is measured to the query, while for novelty, similarity is measured
against sentences selected so far. the mmr approach was originally
proposed for query-focused summarization in the context of informa-
tion retrieval, but could easily be adapted for generic summarization,
for example as using the entire input as a user query as proposed by
gong and liu [69]. many have adopted this seminal approach, mostly

2.3 sentence selection vs. summary selection

135

in its generic version, sometimes using di   erent measures of novelty to
select new sentences [142, 202, 221].

this greedy approach of sequential sentence selection might not be
that e   ective for optimal content selection of the entire summary. one
typical problematic scenario for greedy sentence selection (discussed
in mcdonald [127]) is when a very long and highly relevant sentence
happens to be evaluated as the most informative. such a sentence may
contain several pieces of relevant information, alongside some not so
relevant facts which could be considered noise. including such a sen-
tence in the summary will help maximize content relevance at the time
of selection, but at the cost of limiting the amount of space in the
summary remaining for other sentences. in such cases it is often more
desirable to include several shorter sentences, which are individually
less informative than the long one, but which taken together do not
express any unnecessary information.

general global optimization algorithms can be used to solve the
new formulation of the summarization task, in which the best over-
all summary is selected. given some constraints imposed on the sum-
mary, such as maximizing informativeness, minimizing repetition, and
conforming to required summary length, the task would be to select
the best summary. finding an exact solution to this problem is np-
hard [58], but approximate solutions can be found using a dynamic
programming algorithm [127, 224, 225].

even in global optimization methods, informativeness is still de   ned
and measured using features well-explored in the sentence selection lit-
erature (see section 2). these include word frequency and position in
the document [225], tf   idf [58, 127], and concept frequency [224].
global optimization approaches to content selection have been shown
to outperform greedy selection algorithms in several evaluations using
news data as input, and have proved to be especially e   ective for extrac-
tive summarization of meetings [67, 179].

in a detailed study of global id136 algorithms [127], it has been
demonstrated that it is possible to    nd an exact solution for the opti-
mization problem for content selection using integer linear program-
ming. the performance of the approximate algorithm based on dynamic
programming was lower, but comparable to that of the exact solutions.

136

sentence extraction: determining importance

in terms of running time, the greedy algorithm is very e   cient, almost
constant in the size of the input. the approximate algorithm scales
linearly with the size of the input and is thus indeed practical to use.
the running time for the exact algorithm grows steeply with the size
of the input and is unlikely to be useful in practice [127].

2.4 sentence selection for query-focused summarization

query-focused summarization became a task in the document under-
standing conference in 2004, reviving interest in this type of news
summarization which was considered standard in earlier summac
evaluations [113]. given a topic expressed as a short paragraph state-
ment, the idea was to generate a summary that addresses the topic.
the creation of this task was in reaction to claims that generic summa-
rization was too unconstrained and that human generated summaries
were typically produced in the context of a task. the    rst e   orts on
query-focused summarization addressed the problem of generating bio-
graphical summaries. later, the task was extended to more open-ended
topics.

in this section we look at two classes of approaches. the    rst adapts
techniques for generic summarization of news, following the reasonable
intuition that in query-focused summarization the importance of each
sentence will be determined by a combination of two factors: how rel-
evant is that sentence to the user question and how important is the
sentence in the context of the input in which it appears. the second
class of approaches develops techniques that are particularly appro-
priate given the question type. we illustrate this class of approaches
through a discussion of methods for generating biographical summaries.

2.4.1 adapting generic approaches

conroy et al. [40] propose adaptation of the use of topic signature
words, where sentences that contain more such words are considered
more suitable for inclusion in a generic summary and the weight of a
sentence is equal to the proportion of topic signature words it con-
tains. to extend this model for query-focused summarization, they

2.4 sentence selection for query-focused summarization

137

assume the words that should appear in a summary have the following
id203: a word has id203 zero of appearing in a summary for
a user de   ned topic if it neither appears in the user query nor is a topic
signature word for the input; the id203 of the word to appear in
the summary is 0.5 if it either appears in the user query or is a topic
signature, but not both; and the id203 of a word to appear in a
summary is 1 if it is both in the user query and in the list of topic sig-
nature words for the input. these probabilities are arbitrarily chosen,
but in fact work well when used to assign weights to sentences equal
to the average id203 of words in the sentence [40].

the graph-based approach of erkan and radev [56] has also
been adapted for query-focused summarization with minor modi   ca-
tions. for query-focused summarization, cosine similarity is computed
between each sentence and the user query as a measure of the relevance
of the sentence to the user need. the similarity between sentences in
the input is computed as in the generic summarization setting. rather
than picking one concrete value for the parameter that speci   es the
relative importance of the user topic and the input as done by conroy
et al. [40] who assigned equal weight to them, otterbacher et al. [161]
chose to    nd experimentally what parameters would give best results.
their experiments indicate that emphasizing the user query leads to
better overall performance of the id95 model for sentence weight-
ing. the graph formulation of the query-focused task signi   cantly out-
performs a competitive baseline which chooses sentences based on their
word overlap similarity with the user topic.

the intuitions behind the two approaches described above for adapt-
ing generic summarization approaches for the query-focused task can
be incorporated in a fully formal bayesian model for summarization
and passage retrieval [45]. in this framework, a sophisticated id136
procedure is used to derive a query model: the id203 of a given
word given the user information need. this model is based not only
on the words that actually appear in the user de   ned topic, but also
incorporates knowledge about what distinguished the input for sum-
marization, assumed to be relevant to the user request, from any other
documents that are not relevant to the user query.

138

sentence extraction: determining importance

2.4.2 biographical and de   nition summarization

early research on biographical summarization was carried out simul-
taneously by two di   erent groups of researchers who both proposed
hybrid solutions for the problem. both groups developed systems com-
bining approaches which look for particular types of information in
the input and approaches which are data driven, using summarization
techniques to sift through lots of information and pulling out the most
prominent facts. the systems handle questions asking for a biography
of a speci   ed person (   who is x?   ) as well as requests for de   nitions
(   what is x?   ).

blair-goldensohn et al. [16] developed a system, defscriber, which
uses rhetorical predicates to specify information that should be included
in a de   nition or biography. for a de   nition, they use three predicates:
genus, species and non-speci   c de   nitional. a sentence containing a
genus predicate speci   es the conceptual category of the person/entity
to be described, as for example in the sentence    the hajj is a type of
ritual   ; sentences expressing a species predicate convey unique charac-
teristics of the entity, as in    the hajj begins in the 12th month of the
islamic year   . pattern-based matches were used to    nd good sentences
expressing these kinds of target rhetorical predicates, where patterns
were represented as partially lexicalized trees. for example, a pattern
for genus looked for the query term x as subject, followed by a forma-
tive verb where the object represents the genus and modi   ers of the
object represent the species. when a pattern matched a sentence in an
input document, the sentence was included in the summary. defscriber
blended this top-down search for information with a bottom-up, data-
driven summarization which used search over the web to identify all
non-speci   c de   nitional sentences related to the term x. for example,
the sentence    pilgrims pay substantial tari   s to the rulers of the lands
they pass through    is a non-speci   c de   nition for the what is hajj?
question. defscriber applied a classi   er to select non-speci   c de   ni-
tional sentences from the set of documents returned from a search,
then ranked them based on distance from the centroid of all sentences.
defscriber also used coherence constraints when selecting which sen-
tence should come next, in some cases overriding the rank ordering.

2.4 sentence selection for query-focused summarization

139

while defscriber was originally developed to generate de   nitions of
queried objects, it also was adapted to generate biographies.

weischedel et al. [217] also developed a hybrid approach to gener-
ating summaries that answer de   nitional questions. they use linguistic
features to target information that should be included in a de   nitional
summary and evaluated the contribution of appositives, copulas, rela-
tions, and propositions. if one of these constructions is found modifying
a question term, it is extracted for the answer (e.g., in    tony blair, the
british prime minister   , where the appositive serves as a good answer
in a biography). they also experimented with manual and learned pat-
terns (e.g.,    x also known as y    is a pattern that yields good alterna-
tive terms for the query term). they also used a question pro   le which
represents typical responses to similar questions; the question pro   le
was used to rank information extracted using the patterns. they have
implemented their system for both biographies and de   nitional ques-
tions and have tested it for both english and chinese [167]. in their
evaluation, they investigated the contribution of targeting particular
linguistic features for extraction as an answer versus using the pat-
terns to extract answers, measuring the contribution of manual and
learned patterns separately and together. they found that they got
the best results with a combination of linguistic features and patterns;
since each type performs equally well alone, they conclude that lin-
guistic features and patterns are complementary and both are helpful.
they note that the improvement is greater for biographical questions
than for de   nitional questions, which overall seem harder. patterns are
more e   ective for biographical questions than for de   nitional questions.
of the linguistic features, they    nd that copulas are the most e   ective,
with appositives and relations a close second.

a similar combination of goal-driven and data-driven approaches
was used in systems developed speci   cally for generating biographical
summaries alone. schi   man et al. [185] target certain types of syntac-
tic phrases that they predict will more likely provide descriptions of a
person. they extract appositions and relative clauses which have the
person name as a head, as well as main clauses which have the per-
son as deep semantic subject. they then used information about the
verbs involved in the clauses to further    lter the content that should

140

sentence extraction: determining importance

be included in the biography. they carried out a corpus analysis to
gather semantic information about the verbs, determining whether a
verb carries important information by virtue of being a verb speci   c to
describing people of a particular occupation; clauses with descriptive
verbs are retained. in addition, they used typical summarization fea-
tures such as tf   idf to    lter out clauses. the resulting biographies
resemble a pro   le of a person (who is often mentioned in the news),
listing descriptions of the person and his/her typical activities.

zhou et al. [234] developed a system for multi-document summariza-
tion of biographical information. their system was entered in the duc
2004 evaluation of biographical summarization and was one of the top
performers. they identi   ed nine types of facts that should appear in
a biography (e.g., fame, nationality, scandal, work) and use text clas-
si   cation to classify sentences in potentially relevant documents into
one of these nine classes. their approach also included a redundancy
detection module. their approach, therefore, was more targeted than
any of the biographical response generators we have already described
as it sought information of particular types.

in quite recent work, biadsy et al. [15] used a combined top-down
and bottom-up approach to generate summaries. like zhou et al.,
they are aiming at the generation of more conventional biographies
as opposed to summaries that describe what a person has been up to
lately. they also developed a classi   er that can determine whether a
sentence is biographical or not, but rather than specifying particular
categories of information, they combine two novel techniques. first,
they use wikipedia biographies as models and train an information
extraction system to    nd similar types of information by using unsu-
pervised learning to mine extraction patterns. the top   down module of
the system uses the resulting patterns to    nd biographical information
in the input documents. in addition, they build two language models,
one based on the wikipedia biographies and the other trained on a
non-biographical news corpus. the biography can then be generated
by selecting sentences which match the biographical language model
more than they match the general news language model.

other approaches to biographical summarization have also used
learning to identify biographical type sentences. duboue et al. [50] used

2.5 discussion

141

a database of celebrity biographies and id107 to iden-
tify biographical sentences. feng and hovy [57] use a id64
method to learn patterns to    nd the answers for    ve    elds that typi-
cally occur in a biography: birth date, death date, birth place, death
place, and spouse. they use seed answer pairs, querying the web to
   nd a set of possible patterns and then prune the patterns using a
precision-based method (which requires additional training data) and
a re-ranking method using a variant of tf   idf. they get quite good
accuracy for dates, with lower accuracy for the other    elds.

2.5 discussion

in this section, we overviewed the main approaches for content selection
in extractive summarization, including basic features that are likely to
be mentioned in many publications on the topic, as well as competing
paradigms for selection such as data-driven vs. supervised, greedy selec-
tion vs. global summary optimization, and generic vs. query-focused
summaries. the emphasis on frequency-related features will prepare a
novice in the research area to better understand research articles in
which these methods are often assumed as common knowledge.

the majority of published work deals with unsupervised greedy
sentence selection for sentence extraction for generic summarization.
the use of supervised methods has not been well justi   ed in generic
summarization of news, but as we show in the case of biographical
summarization, is the standard when moving to a speci   c genre of
summaries, in which precise types of information have to be identi-
   ed. what works best, i.e., features or modeling approaches, is highly
dependent on the intended use. similarly, current work has not clearly
demonstrated if greedy selection or global optimization is to be pre-
ferred. global selection is algorithmically and theoretically much more
appealing, but greedy selection is generally faster and much more
likely to cognitively mirror the human process of summarization. as
for query focused summarization of general news, most approaches
seem to be simple adaptations of existing methods for generic summa-
rization. when dealing with a speci   c query type (e.g., biographies),
more sophisticated, targeted approaches can be used. these approaches

142

sentence extraction: determining importance

typically integrate methods that seek speci   c types of information (e.g.,
through the use of learned patterns) with data-driven, generic methods.
better capabilities for input interpretation are necessary in order to
develop even more sophisticated approaches.

we devote the remaining sections to methods using semantics and
discourse information and on domain and genre speci   c methods, which
utilize knowledge of the domain and additional resources to facilitate
the summarization process.

3

methods using semantics and discourse

all methods overviewed in the previous section compute sentence
importance on the basis of repeated occurrence of the same word in
di   erent places in the input. even early researchers acknowledged that
better understanding of the input would be achieved via methods that
instead track references to the same entity, or the same topic in the
document. these methods either rely on existing manually constructed
semantic resources (lexical chains, concepts), on coreference tools, or on
knowledge about lexical items induced from large collections of unan-
notated text (latent semantic analysis, verb speci   city).

3.1 lexical chains and related approaches

lexical chains [7, 64, 192] attempt to represent topics that are discussed
throughout a text or text segment. they capture semantic similarity
between noun phrases to determine the importance of sentences. the
lexical chains approach exploits the intuition that topics are expressed
using not a single word but instead di   erent related words. for exam-
ple, the occurrence of the words    car   ,    wheel   ,    seat   ,    passenger   
indicates a clear topic, even if each of the words is not by itself very
frequent. the approach heavily relies on id138 [137], a manually

143

144 methods using semantics and discourse

compiled thesaurus which lists the di   erent sense of each word, as well
as word relationships such as synonymy, antonymy, part-whole and
general-speci   c. in addition, the lexical chains approach requires some
degree of linguistic preprocessing, including id52 and
division into topically related segments of the input to the summarizer.
barzilay and elhadad [7] present a summarizer that segments an
input document, identi   es lexical chains    rst within segments and then
across segments, identi   es and scores lexical chains, and    nally selects
one sentence for each of the most highly scored chains.

a large part of barzilay and elhadad   s work is on new methods
for constructing good lexical chains, with emphasis on word sense dis-
ambiguation of words with multiple meaning: for example the word
   bank    can mean a    nancial institution or the land near a river or
lake. they develop an algorithm that improves on previous work by
waiting to disambiguate polysemous words until all possible chains for
a text have been constructed; word senses are disambiguated by select-
ing the interpretations (i.e., chains) with the most connections in the
text. later research further improved both the run-time of the algo-
rithms for building of lexical chains, and the accuracy of word sense
disambiguation [64, 192].

barzilay and elhadad claim that the most prevalent discourse topic
will play an important role in the summary and argue that lexical chains
provide a better indication of discourse topic than does word frequency
simply because di   erent words may refer to the same topic. they de   ne
the strength of a lexical chain by its length, de   ned as the number of
words found to be members of the same chain, and its homogeneity,
where homogeneity captures the number of distinct lexical items in the
chain divided by its length. they build the summary by extracting
a sentence for each strong chain, choosing the    rst sentence in the
document containing a representative word for the chain.

in later work, researchers chose to avoid the problem of word
sense disambiguation altogether but still used id138 to track the
frequency of all members of a concept set. in the robust multi-
document summarization system dems [186], concepts were derived
using id138 synonyms, hypernyms and hyponyms relations. rather
than attempting to disambiguate polysemous words and only then    nd
semantically related words, as was done in the lexical chains approach,

3.2 latent semantic analysis

145

in the dems system, words with more than    ve senses (   matter   ,
   issue   , etc.) are excluded from consideration. given that many com-
mon words are polysemous, this policy of exclusion can be viewed as too
restrictive. in order to compensate for the loss of information, highly
polysemous words were replaced by other nouns that were strongly
associated with the same verb. for example if the word    o   cer    is
excluded from consideration because it has many senses,    policeman   
would be added in, because both nouns are strongly associated with
the verb    arrest   .

after concepts are formed, frequency information can be collected
much more accurately, counting the occurrence of a concept rather than
a speci   c word. sample concepts for one article consisted of c1 ={war,
campaign, warfare, e   ort, cause, operation, con   ict}, c2 ={concern,
carrier, worry, fear, scare}, c3 ={home, base, source, support, back-
ing}. each of the individual words in the concept could appear only
once or twice in the input, but the concept itself appeared in the doc-
ument frequently.

shallow semantic interpretation on the level of concepts was also
employed by ye et al. [224]. they also used id138 to derive the
concepts, but to    nd semantically related words they employ a measure
of the content overlap of the id138 de   nitions, called glosses, of two
words rather than the id138 relations. the intuition is that the more
content is shared in the de   nitions, the more related two words are.
example concepts derived using their approach are {british, britain,
uk}, {war, fought, con   ict, military}, {area, zone}.
the heavy reliance on id138 is clearly a bottleneck for the
approaches above, because success is constrained by the coverage of
id138 and the sense granularity annotated there. because of this,
robust methods that do not use a speci   c static hand-crafted resource
have much appeal, explaining the adoption of latent semantic analysis
as an approximation for semantic interpretation of the input.

3.2 latent semantic analysis

latent semantic analysis (lsa) [46] is a robust unsupervised technique
for deriving an implicit representation of text semantics based on
observed co-occurrence of words. gong and liu [69] proposed the use

146 methods using semantics and discourse

of lsa for single and multi-document generic summarization of news,
as a way of identifying important topics in documents without the use
of lexical resources such as id138.

at the heart of the approach is the representation of the input docu-
ments as a word by sentence matrix a: each row corresponds to a word
that appears in the input and each column corresponds to a sentence
in the input. each entry aij of the matrix corresponds to the weight
of word i in sentence j. if the sentence does not contain the word, the
weight is zero, otherwise the weight is equal to the tf   idf weight of
the word. standard techniques for singular value decomposition (svd)
from id202 are applied to the matrix a, to represent it as
the product of three matrices: a = u  v t. gong and liu suggested
that the rows of v t can be regarded as mutually independent topics
discussed in the input, while each column represents a sentence from
the document. in order to produce an extractive summary, they con-
secutively consider each row of v t, and select the sentence with the
highest value, until the desired summary length is reached. steinberger
et al. [195] later provided an analysis of several variations of gong and
liu   s method, improving over the original method. neither method has
been directly compared with any of the approaches that rely on word-
net for semantic analysis, or with tf   idf or topic word summarizers.
an alternative way of using the singular value decomposition
approach was put forward by hachey et al. [73]. they followed more
directly the original lsa approach, and build the initial matrix a based
on the information of word occurrence in a large collection of documents
instead of based on the input documents to be summarized. they com-
pared the performance of their approach with and without svd, and
with a tf   idf summarizer. svd helped improve sentence selection
results over a general co-occurrence method but did not signi   cantly
outperform the tf   idf summarizer.

3.3 coreference information

yet another way of tracking lexically di   erent references to the same
semantic entity is the use of coreference resolution. coreference reso-
lution is the process of    nding all references to the same entity in a

3.4 rhetorical structure theory

147

document, regardless of the syntactic form of the reference: full noun
phrase or pronoun.

initial use of coreference information exclusively to determine
sentence importance for summarization [4, 18] did not lead to substantial
improvements in content selection compared to shallower methods.
however, later work has demonstrated that coreference resolution can
be incorporated in and substantially improve summarization systems
that rely on word frequency features. a case in point is a study on generic
single document summarization of news carried out by steinberger
et al. [195]. the output of an automatic system for id2
was used to augment an lsa-driven summarizer [69]. in one experiment,
all references to the same entity, including those when pronouns were
used, were replaced by the    rst mention of that entity and the result-
ing text was given as an input to the traditional lsa summarizer. in
another experiment, the presence of an entity in a sentence was used as
an additional feature to consider when determining the importance of the
sentence, and the references themselves remained unchanged. the    rst
approach led to a decrease in performance compared to the traditional
lsa summarizer, while the second gave signi   cant improvements. an
oracle study with gold-standard manual coreference resolution showed
that there is further potential for improvement as the performance of
coreference systems gets better.

3.4 rhetorical structure theory

other research uses analysis of the discourse structure of the input
document to produce single document summaries. rhetorical structure
theory (rst) [117], which requires the overall structure of a text to be
represented by a tree, a special type of graph (see section 2.1.3), is one
such approach that has been applied to summarization. in rst, the
smallest units of text analysis are elementary discourse units (edus),
which are in most cases sub-sentential clauses. adjacent edus are com-
bined through rhetorical relations into larger spans. the larger units
recursively participate in relations, yielding a hierarchical tree struc-
ture covering the entire text. the discourse units participating in a
relation are assigned nucleus or satellite status; a nucleus is considered

148 methods using semantics and discourse

to be more central in the text than a satellite. relations characterized
by the presence of a nucleus and a satellite are called mononuclear
relations. relations can also be multinuclear, when the information in
both participating edus is considered equally important. properties
of the rst tree used in summarization include the nucleus   satellite
distinction, notions of salience and the level of an edu in the tree.

in early work, ono et al. [159] suggested a penalty score for every
edu based on the nucleus   satellite structure of the rst tree. satellite
spans are considered less essential than spans containing the nucleus
of a relation. with the ono penalty, spans that appear with satellite
status are assigned a lower score than spans which mostly take nucleus
status. the penalty is de   ned as the number of satellite nodes found
on the path from the root of the discourse tree to the edu.

marcu [120] proposes another method to utilize the nucleus   
satellite distinction, rewarding nucleus status instead of penalizing
satellite. he put forward the idea of a promotion set, consisting of
salient/important units of a text span. the nucleus is considered as
the more salient unit in the full span of a mononuclear relation. in a
multinuclear relation, all the nuclei become salient units of the larger
span. at the leaves, salient units are the edus themselves. under this
framework, a relation between two spans is de   ned to hold between the
salient units in their respective promotion sets. units in the promotion
sets of nodes close to the root are hypothesized to be more important
than those appearing at lower levels. the highest promotion of an edu
occurs at the node closest to the root which contains that edu in its
promotion set. the depth of the tree from this node gives the impor-
tance for that edu. the closer to the root an edu is promoted, the
better its score.

a further modi   cation of the idea of a promotion set [120] takes into
account the length of the path from an edu to the highest promotion
set it appears in. an edu promoted successively over multiple levels
should be more important than one which is promoted fewer times. the
depth score fails to make this distinction; all edus in the promotion
sets of nodes at the same level receive the same scores. in order to
overcome this, a promotion score was introduced which is a measure of
the number of levels over which an edu is promoted.

3.5 discourse-motivated graph representations of text

149

the rst approach for content selection has been shown to give
good results for single document summarization of news and scienti   c
american articles [119, 120, 122].

3.5 discourse-motivated graph representations of text

in the rst based approaches, the importance of a discourse segment
is calculated on the basis of the depth of the discourse tree and the
position of the segment in it, relation importance, and nuclearity and
satellite status. marcu   s work on using rst for single document sum-
marization has been the most comprehensive study of tree-based text
representations for summarization [119, 120, 122] but suggestions for
using rst for summarization were proposed even earlier [159].

graph-based summarization methods are very    exible and allow for
the smooth incorporation of discourse and semantic information. for
example, graph representations of a text that are more linguistically-
informed than simply using sentence similarity can be created using
information about the discourse relations that hold between sentences.
wolf and gibson [219] have demonstrated that such discourse-driven
graph representations are more powerful for summarization than word-
or sentence level frequency for single document summarization. in their
work, sentences again are represented by vertices in a graph, but the
edges between vertices are de   ned by the presence of discourse coher-
ence relation between the sentences. for example, there is a cause   e   ect
relation between the sentences    there was bad weather at the airport.
so our    ight got delayed.    other discourse relations included violated
expectation, condition, similarity, elaboration, attribution and temporal
sequence. after the construction of the graph representation of text,
the importance of each sentence is computed as the stationary distribu-
tion of the markov chain, as in the sentence-similarity graph methods.
wolf and gibson claim that their method outperformed summariza-
tion approaches using more restricted discourse representations such
as rst.

both the rst approach and the graphbank work rely on the
structure of the text, be it a tree or a general graph, to de   ne impor-
tance of sentences. in recent work [110], the rst and graphbank

150 methods using semantics and discourse

methods were again compared directly with each other, as well as
against discourse information that also included the semantic type of
the discourse relation and non-discourse features including topic words,
word probabilities and sentence position. the summarizers were tested
on single-document summarization of news. of the three classes of
features     structural, semantic and non-discourse     the structural
features proposed by marcu lead to the best summaries in terms of con-
tent. the three classes of features are complimentary to each other, and
their combination results in even better summaries. such results indi-
cate that the development of robust discourse parsers has the potential
of contributing to more meaningful input interpretation, and overall
better summarization performance.

3.6 discussion

the discourse-informed summarization approaches described in this
section are appealing because they o   er perspectives for more semanti-
cally and linguistically rich treatment of text for summarization. at the
same time, these methods require additional processing time for coref-
erence resolution, lexical chain disambiguation or discourse structure.
because of this, they would often not be used for applications in which
speed is of great importance. furthermore, the above approaches have
been tested only on single document summarization and have not been
extended for id57 or for genre speci   c sum-
marization. discourse-informed summarization approaches will likely
have a comeback as recent duc/tac evaluations have shown that
systems have gotten impressively good at selecting important content
but lack in linguistic quality and organization. addressing these harder
problems will require linguistic processing anyway and some of the dis-
course approaches could be used as the basis for techniques for improv-
ing the linguistic quality of the summaries rather than the content
selection capabilities of summarizers (see section 4).

in concluding this section, we would like to point out that the use of
semantic interpretation in summarization seems intuitively necessary:
the majority of summarization systems still process text at the word
level, with minor pre-processing such as id121 and id30.

3.6 discussion

151

current systems are complex, relying on multiple representations of
the input and features and algorithms to compute importance. vir-
tually no recent work has attempted to analyze the direct bene   ts of
using semantic representations, either based on id138 or derived
from large corpora. in this sense, the development and assessment of
semantic modules for summarization remains much of an open prob-
lem. no clear answers can be given to questions such as how much
run-time overhead is incurred by using such methods. this can be
considerable, for example, if id51 for full lexi-
cal chains is performed, or a coreference resolution system is run as
a pre-processing step. also unclear is by how much content selection
is improved compared to simpler methods that do not use semantics
at all? future research is likely to address these questions, because the
need for semantic interpretation will grow as summarization approaches
move toward the goal of producing abstractive rather than extractive
summaries, which will most likely require semantics.

4

generation for summarization

determining which sentences in the input documents are important
and summary-worthy can be done very successfully in the extractive
summarization framework. sentence extraction, however, falls short of
producing optimal summaries both in terms of content and linguistic
quality. in contrast to most systems, people tend to produce abstractive
summaries, rewriting unclear phrases and id141 to produce a
concise version of the content found in the input. they do also re-use
portions of the input document, but they often cut and paste pieces
of input sentences instead of using the full sentence in the summary.
while extensive research has been done on extractive summarization,
very little work has been carried out in the abstractive framework. it is
clearly time to make more headway on this alternative approach.

content of an extractive summary may inadvertently include
unnecessary detail along with salient information. once an extractive
approach determines that a sentence in an input document contains
important information, all information in the sentence will be included
regardless of its relevance. while methods do attempt to extract sen-
tences that contain a large amount of salient material, this nonethe-
less remains an issue. in this section, we discuss two approaches that

152

4.1 sentence compression

153

address this problem: compression and sentence fusion. compression is
a method to remove unnecessary detail from selected sentences and has
been used primarily in single document summarization. sentence fusion
is a method that cuts and pastes phrases from di   erent sentences in
the input documents, thereby removing unnecessary information and
avoiding the possibility of short, choppy sentences in the summary.
it has been used primarily for id57. these
approaches are discussed in sections 4.1 and 4.2.

the linguistic quality of automatic summaries is also far from
optimal, even when content is well chosen. in duc 2005, for example,
more than half of the summaries were perceived as not having good
referential clarity, focus, structure and coherence. addressing these
problems requires the use of text generation techniques in order to
improve information ordering and to help in making context depen-
dent revisions to improve the    ow of the summary. approaches that
use editing of extracted sentences to improve referring expressions are
discussed in section 4.3 and approaches that dynamically determine
the order of sentences using constraints from discourse and from the
input articles are discussed in section 4.4.

4.1 sentence compression

in many cases, sentences in summaries contain unnecessary information
as well as useful facts. this is likely to happen when summarizing docu-
ments that contain long sentences, particularly the very long sentences
that occur in news articles. for example, in the sentence

(1) as u.s. court of appeals judge sonia sotomayor made her senate
debut with a series of private meetings, republicans said they would
prefer holding hearings on her nomination in september, which could
cloud the speedy summertime con   rmation obama wants.

two topics are mentioned: one about the series of meetings and the other
about the timing of senate hearings. depending on the set of articles,
one of these topics will not be relevant to the other sentences in the
summary and should be dropped. often the irrelevant information will
be presented in a clause modifying the main sentence or in a modi   er of
one of the a clause argument (e.g., in this case, in the clause beginning

154 generation for summarization

with    as   ), but if the set of input documents focuses on the meetings
that sotomayor had, then it would be better to keep the    rst clause,
dropping just the word    as    as well as the main clause of the sentence.
a summarizer that can    compress    a sentence, removing unnecessary
pieces, is able to produce a more concise and focused summary.

there is evidence that humans do exactly this when writing sum-
maries. in a corpus analysis of human single document summaries, jing
and mckeown [86] observed that sentence reduction was often used
by professional summarizers. for their analysis of human summarizing
behavior, jing and mckeown worked with the zi   -davis corpus,1 which
is a collection of newspaper articles about computer products along
with a (human) summary of each article. they automatically aligned
the sentences in the abstracts to sentences in the original article and
were able to study the sentence-level transformations employed by the
writers of the abstracts. they found that 78% of the summary sentences
were written by editing the input document and of those, more than
half of the edits were done using compression alone, removing informa-
tion from a sentence extracted from the input document. the remaining
edits used compression in addition to combining information from one
or more other sentences. thus, compression is an important component
of summarization which, even now, is infrequently addressed.

in this section, we describe two general approaches to sentence
compression, one using primarily linguistic techniques and the other,
statistical techniques. these two approaches have been used both for
single document summarization where useful corpora of paired human
abstracts and documents exist, as well as for the task of headline gener-
ation, where the key points of a document must be compressed down to
a few words. additional approaches to compression have been developed
for summarization of speech where it is important to remove dis   uencies.

4.1.1 rule-based approaches to compression

rule-based approaches to sentence compression [87, 226] use both
syntactic and discourse knowledge to determine how to compress a
sentence. syntactic knowledge includes the syntactic structure of an

1 available from the language data consortium, catalog number ldc93t3a.

4.1 sentence compression

155

extracted sentence and knowledge about which constituents are less
likely to be needed, while discourse knowledge includes information
about how each constituent is connected with the rest of the summary.
jing [87] developed a system for automatic sentence compression,
or reduction, that uses multiple sources of knowledge to decide which
phrases in an extracted sentence can be removed, including syntactic
knowledge, contextual information, and statistics computed from a cor-
pus of professionally written summaries. compression can be applied
at any granularity, including a word, a prepositional phrase, a gerund,
a to-in   nitive or a clause. in the    rst step of reduction, the candidate
sentences are parsed and all nodes in the tree that are necessary in order
to preserve the grammaticality of the sentence, such as the main verb or
head of a noun phrase, are marked. such nodes can not be removed by
the reduction module. obligatory arguments of verbs are also marked.
contextual information is used in order to decide which parts of a sen-
tence are most closely linked to the overall topic of the article and these
parts will not be deleted even if it is syntactically possible to do so. the
context weight for each word is computed as the number of links to the
rest of the article in terms of repetitions, occurrence of morphological
variants or of semantically related words identi   ed using the id138
database. finally, the likelihood of a human deleting a particular type
of constituent is looked up in a table of precomputed corpus statistics.
these three factors are weighted and a constituent below a certain
weight will be removed from the sentence. this approach seems e   ec-
tive as evaluation demonstrated that 81% of the sentence reductions
proposed by the system agreed with the reduction decisions made by a
professional human abstractor.

zajic et al. [226] also developed a set of rules to compress sentences.
there are two key di   erences between their work and that of compres-
sions for each document sentence before doing sentence extraction and
they base the removal of constituents intuitively, this should improve
selecting information can operate on system they originally developed
for headline generation, called hedgetrimmer, which was intended to
compress a sentence down to 10 words. compression is done iteratively,
removing one constituent at a time. the resulting compression at each
round is provided as input to the sentence extraction module, which

156 generation for summarization

uses six features to score sentences for extraction. most of these fea-
tures have been used in earlier sentence extraction approaches: sentence
position, relevance to query for query-focused summarization or to doc-
ument centroid for generic summarization, as well as a feature unique
to their approach, the number of trims applied to a sentence. sentence
compression uses linguistic heuristics, described in section 4.1.3, which
remove speci   c syntactic constituents. hedgetrimmer does not use
information about discourse connections.

zajic et al. entered their system in duc06 and noted that they did
not score well on    uency measures such as grammaticality, conclud-
ing that this indicates that a good number of trimmed sentences were
included as these typically would not be as grammatical as the original
human written sentences.

these results highlight why sentence extraction is by far the more
commonly used method for summarization, even though it is also less
innovative. novel approaches to summarization, such as compression,
are clearly needed as demonstrated by the amount of extraneous infor-
mation that is otherwise included. nonetheless, it often happens that
systems will perform worse on some standard evaluation scores when
di   cult tasks such as compression are attempted. it is important to
recognize that research progress can only be made if such decreases
in scores are tolerated and even welcomed, as research continues to
   nd the best way to produce compressions that are    uent. this line
of research will also become more attractive when metrics that reward
brevity and the inclusion of higher number of important facts are devel-
oped and adopted.

others have also used a combination of syntactic and lexical heuris-
tics to compress sentences. classy [37] used id66 combined
with lexical triggers to remove unnecessary constituents. siddharthan
et al. [190] found that sentence simpli   cation improves the quality of
sentence clusters in id57 and hence, signi   -
cantly improves the resulting summary, as measured by id8 scores.

4.1.2 statistical approaches to compression

statistical approaches to sentence compression have also been explored.
in this paradigm, rules about which syntactic constituents can be

4.1 sentence compression

157

deleted are learned by the program. thus, no linguistic rules need to
be provided as input. knight and marcu [94] experiment with two dif-
ferent statistical approaches. like jing, they also use the zi   -davis
corpus for their work. they develop and evaluate an approach based
on the id87, as well as one using id90. the
idea behind the id87 is to assume that the input to the
model was a short, compressed sentence, that somehow got distorted
with additional words yielding a long sentence. given the long sentence,
the task is to infer the    original    compressed version. they adapt the
id87 so that it operates on trees and thus, they work
with probabilities over trees. given a long sentence, their program    rst
produces a (large) parse tree and then hypothesizes di   erent ways it
can be pruned to produce smaller ones. they measure the goodness of
the smaller ones by computing the goodness of the tree using standard
probabilistic id18 (pid18) scores and the id203
of the sentence according to a bigram language model. they measure
the likelihood of the transformation from the large parse tree to the
small one using statistics collected over 1037 summary/document sen-
tence pairs from the zi   -davis corpus. a feature of this approach is
that it can produce many possible compressions, ranked by their score,
and depending on the required summary length, a compressed version
that    ts can be chosen. it does, however, have drawbacks as well. the
word order in the sentence cannot be changed and it does not allow
reorganization of the existing tree structure. for example the tree can-
not be revised by turning a prepositional phrase into an adjective.

knight and marcu compare this approach with a decision-based
model for compression. they use a shift   reduce   drop parsing paradigm,
where any of the rules in the grammar are applied to the long string,
attempting to build the tree of the short string. at any point, the rules
can shift a word from the input to the output string; reduce operations
manipulate the existing tree by combining pieces of trees produced
by the algorithm so far to make a new tree; drop is used to delete a
portion of the long input corresponding to a constituent, and a fourth
operation assigntype allows the processor to re-assign part of speech
tags to words. a decision tree learner is applied to learn the kinds of
rules applicable in di   erent contexts. this type of learning has more

158 generation for summarization

   exibility than the id87 as it does allow for changing
words, part of speech and for reorganization of the tree.

to evaluate the two models, they had assessors separately score
each compression for grammaticality and importance of retained
information. their evaluation shows that the decision tree approach
generally produces more highly compressed sentences and that both
approaches signi   cantly outperform the baseline. however, the per-
formances of the decision tree and the id87 are not
signi   cantly di   erent from each other. in determining which approach
to use, the need to adjust the level of compression is probably most
di   erentiating.

later work [65, 206] addressed some of the shortcomings of the
knight and marcu approach. galley and mckeown [65] make two
signi   cant improvements. they move to a lexicalized head-driven
approach that allows them to take the lexical heads of constituents
into account before making deletions. this helps them to avoid deleting
negation words such as    no    and    not   , which would completely change
the meaning of the sentence, a problem which knight and marcu   s
approach cannot handle. they add markovization, a standard tech-
nique applied in statistical parsing which deals with data sparsity issues
by conditioning the id203 of a node only on a small number of
other nodes rather than on the full context. finally, they develop tech-
niques for tree alignment which allow for insertions and substitutions,
not only deletion. by doing this, increases the amount of training data
they can use from the zi   -davis corpus by seven-fold over knight and
marcu   s approach.

turner and charaniak [206]

improve on knight and marcu   s
approach by developing a method for acquiring training data in an
unsupervised fashion. they demonstrate how to compute probabilities
of possible deletions by counting instances in the id32 which
match pairs of rules where the right-hand side of one id18 rule is a sub-
set of the right-hand side of another rule. for example, one rule might
specify np     dt jj nn while another may specify np     dt nn.
this method is applied to generate additional training data for the
original id87 algorithm. turner and charniak also pro-
pose an improvement on the model for measuring the goodness of the

4.1 sentence compression

159

resulting compression, replacing the bigram language model with the
syntax-based language model developed for the charniak parser.

since these seminal approaches, the    eld of sentence compression
has taken o    on its own. there has been considerable research on
the problem in isolation, considering it as a general purpose tool that
could be used in a variety of applications in addition to summarization,
such as generation of subtitles for television programs, generation for
small mobile devices, and generation for devices that allow the blind to
browse and search collections using audio [33, 36, 126, 157, 180, 206].
we focus here on just one of these approaches to represent this bur-
geoning new area. while primarily statistical in nature, it does draw
on additional linguistic information encoded as hard constraints. clarke
and lapate [33] present an approach that uses discourse information as
well as a statistical approach to compression using integer linear pro-
gramming (ilp). note that ilp is also explored by others [36, 126]. ilp
is an optimization approach which    nds the output that maximizes an
objective function subject to certain constraints. the constraints and
the objective can be formulated in a way that does not require labeled
data, which is in fact what clarke and lapata do. so their approach
has an advantage over id87 approaches [94, 65] in that
it is unsupervised and thus the problem of obtaining adequate training
data is not an issue.

on the other hand, their approach operates on the level of words,
deciding which words should be kept in the compression and which
should be deleted, and does not manipulate syntactic trees as done in
the id87s. thus, they are likely to have less control over
the grammaticality of their output. the ilp approach used by clarke
and lapata uses optimization to determine which words can be removed
from a long sentence given as input to produce a short sentence. a scor-
ing function is computed to determine the best word to remove. in
earlier work [32], they used a language model to score the sentence
resulting from each word deletion, almost the same as the model hori
and furui [78] use for speech summarization. in the new research,
they augment the constraints using information from discourse. they
include constraints from centering theory, weighting named entities
and noun phrases higher when they serve as backward-looking centers

160 generation for summarization

and weighting forward-looking centers, next highest, essentially weight-
ing more heavily the entities mentioned in adjacent sentences and
entities in syntactically prominent positions. they enforce hard con-
straints that these higher weighted entities should never be deleted.
they also incorporate lexical chains, weighting entities higher when
they occur in longer lexical chains across the documents. similarly to
jing   s rule-based approach, they enforce hard constraints that such
entities should not be deleted. they    nd it relatively easy to incorpo-
rate these discourse constraints into the ilp framework for scoring a
deletion.

4.1.3 headline generation

a key di   erence between the document summarization problem and
headline generation is in the length of the summary. headlines are
typically even shorter than a sentence, which makes the usual, generic
summarization approach of sentence extraction inappropriate for the
task. another critical di   erence is in the amount of data available for
training. since a headline typically appears with every news article
published, there are large amounts of training data that do not require
any special modi   cation. the two primary approaches to compression,
one based on linguistic rules and one statistical, have also been applied
to headline generation, and are surveyed here.

the main linguistic rule-based approach to headline generation [49]
was developed prior to the rule-based approach to compression in multi-
document summarization that we overviewed in the last section. it was
used to generate multiple possible compressed sentences that the multi-
document summmarizer could then opt to select as the headline for
the summary using a set of features. in their work on headline genera-
tion, dorr and her colleagues developed a system called hedgetrimmer
which uses linguistic heuristics to determine which syntactic constituents
can be dropped. the development of heuristics was done through man-
ual analysis of three di   erent sets of headline   article pairs containing
a total of almost 400 such pairs. through this analysis, they identi   ed
the types of constituents that are typically dropped. they postulate    rst
a set of heuristics that are always applied. for these, they identify the

4.1 sentence compression

161

lowest s node in the constituent parse of the sentence and its immedi-
ate arguments and drop the remaining constituents. they remove low-
content words such as determiners and function words and they also
delete time expressions. following the application of these heuristics,
they iteratively apply shortening rules until the sentence has reached the
desired length, which they set at 10 words based on observation, though
this number is parameterized and could easily be changed.

their iterative shortening rules remove prepositional phrases and
preposed adjuncts. they also have a general rule which they call xp-
over-xp which basically looks for constituents such as np or vp which
contain an embedded np or vp and remove all constituents except for
the embedded xp. for example, given a sentence such as    a    re killed
a    re   ghter who was fatally injured as he searched the house.   , hed-
getrimmer   s parser produces an analysis of the sentence as containing
an np    a    re   ghter who was fatally injured as he searched the house   
which contains an embedded np (   a    re   ghter   ). using the xp-over-
xp rule the relative clause is deleted. using the determiner rule,    a    is
deleted and the headline    fire killed    re   ghter    is produced.

statistical approaches to headline generation exploit the large
amounts of training data. witbrock and mittal
[218] and banko
et al. [5] use 8000 article   headline pairs, with 44,000 unique tokens
in the articles and 15,000 in the headlines. they use a much simpler
approach to compression than do knight and marcu. their approach
uses two models: one for content selection and the other for realization.
for content selection, they compute the id155 of a
word appearing in a headline, given its appearance in the article. for
realization, they use a bigram model, trained on the headlines. they
evaluated the system using unseen article   summary pairs, comparing
it against both the original headlines and the top ranked summary sen-
tence for the article. they generated headlines of multiple lengths since
their system was not able to predict the ideal length. overlap between
the system headline and the original article headline ranged from 0.87
to 0.90 and overlap with the top summary sentence ranged from 0.85 to
0.90 across the di   erent system headline lengths. they did not measure
the quality of the headline in terms of word order or structure although
this is clearly another factor that should in   uence evaluation.

162 generation for summarization

4.2

information fusion

while research on compression does result in summary sentences that
are not identical to sentences in the input document, those di   erences
are limited; each summary sentence can di   er at most by being a sub-
set of a sentence in the original document. in addition to removing
phrases from document sentences, human abstractors sometimes sub-
stitute one word for another and often combine information from two
sentences to create a novel sentence. this was noticed early on by jing
who coined the term    cut and paste    to refer to the kind of operations
performed [90]. she did extensive analysis of the types of edits that are
typically carried out by human abstractors, but implemented just one
operator other than compression. this operator created a new sentence
using conjunction between two reduced sentences from the input doc-
ument [89] under certain constraints such as having the same subject.
information from sev-
eral sentences was introduced in barzilay and mckeown [11]
for
the multi-document summarizer multigen. a common approach to
id57 is to    nd similarities across the input
documents and extract the similarities to form the summary. often
similarities are identi   ed using sentence id91; each cluster is con-
sidered to represent a theme in the input. while many systems simply
extract a sentence from each cluster, barzilay and mckeown introduce
a text-to-text generation technique, which takes as input a set of similar
sentences and produces a new sentence containing information common
to most of them. their approach addresses two challenges: the identi-
   cation of phrases across sentences that convey common information
and the combination of those phrases into a grammatical sentence.

a more general approach to fusion of

the identi   cation of common information is done using pairwise
alignment of all sentences in a cluster of similar sentences that the
algorithm receives as input. pairwise alignment for multi-document
summarization is quite di   erent from the alignment that is commonly
used for machine translation. first, only a subset of the subtrees in
one sentence will align with a subset of the subtrees in the other sen-
tences. second, the order of the matching trees will be di   erent in the
di   erent sentences and thus, there is no natural starting point for the

4.2 information fusion

163

alignment. the authors develop a bottom-up local multisequence align-
ment algorithm for this problem. it uses words and phrases as anchors
and operates on the dependency trees of the cluster sentences, consider-
ing a pair of sentences at a time. alignment is driven by both similarity
between the structure of the dependency trees and similarity between
lexical items, considering paraphrases as well as identical lexemes. once
identi   ed, the common phrases are combined by    rst building a fusion
lattice which represents the alignments and then linearizing the lattice
as a sentence using a language model.

multigen    rst selects a sentence which is most similar to other sen-
tences to serve as a basis sentence and then transforms it into a fusion
lattice by removing information that does not appear in the majority of
other sentences and by adding in phrases that do occur in the majority
of other sentences, but are missing from this one. finally, the fusion lat-
tice is linearized using a tree traversal performing lexical choice among
alternative verbalizations available at each node and placing function
words. the linearization component outputs all possible sentences that
can be derived from the lattice and multigen uses a language model
to choose the best one among these di   erent possible fusion sentences.
recent work has extended the sentence fusion algorithm to question-
answering. in this context, it makes sense to combine all information
that is relevant, regardless of whether it is repeated across sentences
in a cluster. thus, marsi and krahmer [123] introduce the notion of
union of two input sentences, producing an output sentence that con-
veys all information expressed in the two input sentences without rep-
etition. they note that this can enable generation of a sentence that
would provide complete information in response to a query. they    rst
explore di   erent possibilities for alignment using a manual annotation
of di   erent translations of the little prince. they develop an algo-
rithm for dependency tree alignment that is very similar to barzilay
and mckeown [11], but they experiment with merging and generation
on the annotations thus allowing generation from aligned nodes where
one is either identical, a paraphrase, a generalization, or more speci   c
than the other. as in [11], a language model is used to select the best
sentence. the resulting generated sentences can be either restatements
of the input, generalizations or speci   cations. their evaluation reveals

164 generation for summarization

that roughly 50% of the generated sentences are judged as    perfect   
(evaluation done by the authors), while the remainder are divided into
   acceptable    and    nonsense.    while not yet viable, this is an interest-
ing approach that clearly identi   es new avenues for further research.

filippova and strube [59] also explore a form of union fusion, accept-
ing a cluster of similar sentences as input and using dependency tree
alignment between pairs of sentences in the cluster. they use a much
simpler form of alignment than earlier work, however, combining any
nodes which share the same words. they then use integer linear pro-
gramming (ilp) to transform the resulting graph into a tree and to
remove unimportant nodes, using a sophisticated set of structural, syn-
tactic and semantic constraints. for example, since their focus is on
union fusion, they use semantic constraints to determine that a con-
junction can be used to combine two phrases when they are semanti-
cally similar and    ll the same roles of similar sentences (e.g., both are
objects of identical verbs in the two di   erent input sentences). rather
than overgenerating and using a language model to select from the
resulting sentences, they use a syntactically constrained linearization
approach. their evaluation shows that their approach produces signi   -
cantly more readable sentences than barzilay and mckeown   s, but that
there are no signi   cant di   erences in informativeness.

despite the interesting research problems,

few researchers in
summarization today attempt this line of work and most persist with
the safe, yet uninspired, extraction-based approach. the tasks selected
for large-scale, shared evaluation and the metrics used tend to encour-
age extraction. daume iii and marcu [43] present an empirical study
whose results also discourage research on sentence fusion, claiming
that it is an ill-de   ned task. they use the zi   -davis corpus as data,
extracting summary sentences that are aligned with two di   erent doc-
ument sentences. the summary sentences are used as the references.
to obtain examples of sentence fusion, annotators were presented with
the two document sentences both of which aligned to the same sum-
mary sentence, and were asked to create a single sentence from the
two that preserves important information and is 50% shorter than the
two sentences combined. the human subjects were to do this with-
out consulting the documents and thus, had no context in which the

4.3 context dependent revisions

165

sentences appeared. they measure agreement between humans by man-
ually identifying the factoids in each summary sentence elicited in the
experiment and comparing it with the corresponding reference. they
also compare the factoids from each elicited summary sentence against
every other elicited summary sentence from the same document sen-
tences. the kappa when comparing against the reference is low     less
than 0.251     and the highest kappa between two elicited summary
sentences is 0.47, still relatively low. they also perform two other eval-
uations, which they claim support this view.

it should be noted their de   nition of    sentence fusion    is more in
line with    union    as de   ned by marsi and krahmer, since it requires
extracting two semantically di   erent phrases from the input sentences
and combining them in one sentence.    intersection    requires identifying
semantically equivalent phrases from the di   erent sentences in a cluster
of similar sentences and expressing only such shared information. thus,
for intersection, the criteria for selecting phrases to combine is seman-
tic equivalence, while in the daume and marcu study, the criteria is
   importance    which is a much more vague and less restrictive criteria.
it is not surprising that    importance   , particularly with no context,
does not yield agreement. other work that deals with union uses more
concrete criteria for combination (e.g., connection to previous discourse
[87] or relevance to query [123]). in fact, recent work [96] shows that
sentence fusion is better de   ned when performed in the context of a
task like id53.

4.3 context dependent revisions

revision is another device for producing non-extractive summaries. dif-
ferent revision algorithms have been developed to merge phrases from
di   erent articles to revise references to people and to correct errors
arising from machine translation in multilingual summarization.

in a preliminary study of how summary revisions could be used to
improve cohesion in id57 [162], automatic
summaries were manually revised and the revisions classi   ed as pertain-
ing to discourse (34% of all revisions), entities (26%), temporal ordering
(22%) and grammar (12%). this study further supports    ndings from

166 generation for summarization

early research that shows that unclear references in summaries pose
serious problems for users [165].

early work investigated generation of references. in research on
id57, radev and mckeown [175] built a
prototype system called profile which extracts references to people
from news, merging and recording information about people mentioned
in various news articles. the idea behind the system was that the rich
pro   les collected for people could be used in summaries of later news in
order to generate informative descriptions. however, the collection of
information about entities from di   erent contexts and di   erent points
in time leads to complications in description generation that are not
faced in a pure multi-document environment     for example, past news
can refer to bill clinton as    clinton, an arkansas native   ,    the demo-
cratic presidential candidate bill clinton   ,    u.s. president clinton   ,
or    former president clinton   . which of these descriptions would be
appropriate to use in a summary of a novel news item? in later work,
radev developed an approach to learn correlations between linguistic
indicators and semantic constraints which could eventually be used to
address such problems [170].

single document summarization can also bene   t from techniques
for improving summaries through revision [116]. mani et al. de   ne
three types of revision rules     elimination (removing parentheticals,
sentence initial prepositional phrases and adverbial phrases), aggrega-
tion (combining constituents from two sentences) and smoothing. the
smoothing operators covers some reference editing operations. they
include substitution of a proper name with a name alias if the name
is mentioned earlier, expansion of a pronoun with coreferential proper
name in a parenthetical and replacement of a de   nite np with a coref-
erential inde   nite if the de   nite occurs without a prior inde   nite.

while the rules and the overall approach are based on reasonable
intuitions, in practice, entity rewrite for summarization does introduce
errors, some due to the rewrite rules themselves, others due to problems
with coreference resolution and parsing. readers are very sensitive to
such errors and notice them easily [149]. in the entity-driven rewrite for
id57 of news, nenkova [149] proposed incor-
porating noun phrase editing in a greedy sentence selection method for

4.3 context dependent revisions

167

summarization. references to the same entity from all input documents
were collected automatically using the heuristic that noun phrases with
the same head refer to the same entity (for example    the angry dog    and
   the black dog    would be considered co-referential). after a sentence
is selected for inclusion in the summary, all noun phrases co-referential
with noun phrases contained in the sentence are evaluated for their
informativeness, dependent on the information already included in the
summary, using word id203. the most informative noun phrase is
chosen and incorporated in the sentence. this method of noun phrase
rewrite leads to a natural selection of more informative and descrip-
tive references for the    rst mention of an entity, and short references
for subsequent mentions. the rewrite method produces summaries that
di   er in content from the summaries produced by the purely extrac-
tive version of the same algorithm by 20   50% as measured by lexical
overlap. in manual evaluation of linguistic quality, however, readers pre-
ferred the extractive summaries which consisted of sentences written
by journalists.

in contrast, when editing is restricted to references to people alone,
there are fewer edits per summary but the overall result is perceived by
readers as better than the original [147]. nenkova   s work on reference
to people distinguished two tasks: should the person be mentioned at
all and if so, what is the impact on    rst mention? nenkova et al. [154]
showed that it is possible to automatically distinguish two characteris-
tics of an entity: whether the entity is known to a general reader and
whether the entity is a major participant in the event discussed in the
input. if the entity is familiar to a general reader and is a major par-
ticipant, a short reference by last name only is appropriate and is often
used in human-written summaries. a rule-based system for deciding
whether to include attributes such as title or role words (e.g., prime
minister, physicist), temporal role modifying adjectives (e.g., former),
and a   liations (e.g., country or organization name) depending on the
expected familiarity of the reader with the entity was able to repro-
duce references used in human summaries with 80% accuracy. this
research complements earlier research [147] where a rewrite system for
references to people in multi-document summaries of news was devel-
oped based on a corpus analysis and human preference studies. for the

168 generation for summarization

   rst mention of the person in the summary, a reference containing the
full name of the person and the longest, in number of words, premod-
i   er of the name (e.g.,    swiss tennis star roger federer   ) is chosen
among the references to that person in the multiple input documents.
if no reference with premodi   cation is found in the input, a reference
with an appositive is selected (   roger federer, winner of    ve us open
titles   ). automatic summaries rewritten using these rules were almost
always prefered to the original extracts by human assessors.

rewriting references to people can also improve multi-lingual sum-
marization where the input for summarization is in a language di   er-
ent from the language in which the summary is produced. siddharthan
and mckeown [189] report their results on the task of summarizing
in english, news articles written in arabic. they use several auto-
matic machine translation systems to translate the input. as a result,
there are many errors in grammar and lexical choice in the input for
summarization. from the multiple translations of the input articles,
siddharthan and mckeown [189] automatically extract the name, role
and a   liation for each person mentioned in the summary. frequency of
occurrence in the di   erent translations is used to choose the best value
for each of these attributes of the reference and these are used in the
   nal summary, correcting the errors in machine translations. several
automatic evaluation measures show signi   cant improvement in the
output after error correction through rewrite of references to people.

4.4

information ordering

the order in which information is presented also critically in   uences the
quality of a text. reading and understanding a text in which sentences
are randomly permuted is di   cult. in a single document, summary
information can be presented by preserving the order in the original
document [104, 133, 174]. however, even in single document summaries
written by professional summarizers, extracted sentences do not always
retain their precedence orders in the summary. in multi-document sum-
marization, the problem is even harder because the input consists of
several documents and not all topics appear in all documents. sentences
with di   erent wording and varying content can express the topic in the

4.4 information ordering

169

di   erent articles, and topics are not discussed in the same order in
all documents. for this setting, a generalization of the original text
ordering for single document summarization works quite well. similar
sentences from the di   erent documents, discussing the same themes
or topics, can be clustered [76]. a graph representing local ordering
patterns in the input can be constructed, with each vertex represent-
ing a topic cluster. two vertices are connected by an edge if in some
document a sentence from one topic immediately preceeded a sentence
from the other topic. the weight of the edge is the number of arti-
cles in which that particular ordering pattern was observed. inferring
a global ordering from the graph is an np-complete problem [35], but
an approximation algorithm can be used to solve the problem with
remarkably good results. this approach to ordering has been called
majority ordering [9]. variations of the majority ordering approach
were later studied by several groups [19, 20, 84].

an alternative ordering approach studied in barzilay et al. [9] is
chronological ordering. using chronological order in the summary to
describe the main events helps the user understand what has happened.
for this approach, it is necessary to associate a time stamp with each
sentence or topic. the time when a topic occurred was approximated in
barzilay et al.   s work by its    rst publication time; that is, the publica-
tion date of the earliest article that contributed a sentence to the topic
cluster. when two topics have the same publication time, it means that
they both are reported for the    rst time in the same article and the
order in the article can be used to decide presentation in a summary.
the initial results from applying chronological ordering to automatic
summaries were discouraging and human assessments of the resulting
summaries were low. an error analysis revealed that problematic order-
ings were produced when the sentences that needed to be ordered con-
veyed background information, or states rather than events. another
problem in summaries rated as poor by human assessors was that they
contained abrupt switches of topic.

to address this issue, barzilay et al. [9] used a topic segmentation
tool to identify blocks of text in each article from the input that were
tightly related to each other as indicated by word distribution and
coreference cues. topics that appeared in the same segment in more

170 generation for summarization

than half of the input articles for id57 were
considered to be strongly related. finding the transitive closure of this
relation builds groups of related themes and, as a result, ensures that
themes that do not appear together in any article but which are both
related to a third theme will still be linked. the chronological ordering
algorithm is used to order blocks of topics rather than directly the topics
themselves as in the original algorithm. they show that this augmented
algorithm produced the best results compared to the majority and
chronological order approaches.

a more general approach to information ordering, applicable to
any text rather than speci   cally for summarization, was proposed by
barzilay and lapata [6]. the main insight in this approach is that con-
tinuity between adjacent sentences will determine the overall coherence
of the text. continuity is de   ned as the occurrence of the same entity in
two adjacent sentences. to capture patterns of continuity, barzilay and
lapata [6] de   ne a matrix m, called an entity grid in which rows corre-
spond to sentences in the text and the columns correspond to entities
that appear in the text. an element mij of the matrix corresponding
to the ith sentence and jth entity can take one of four values: subject,
object or other (depending on the grammatical function of entity j
in sentence i), or none if entity j is not mentioned at all in sentence i.
the entire text is characterized by 16 features, equal to the percentage
of each type of transition between adjacent sentences observed in the
text (for example ss, so, on, etc.). an id166 ranking model incor-
porating these features achieved 84% accuracy in predicting which of
two summaries is more coherent. the data for training and testing the
classi   er contained a mix of human and machine produced summaries.
the two models described in this section relate only to informa-
tion ordering, not content selection. for domain speci   c summarization,
id48 (id48) combining selection and ordering have
been proposed [10, 61]. these models capitalize on the fact that within
a speci   c domain, information in di   erent texts is presented following
a common presentation    ow. for example, news articles about earth-
quakes often    rst talk about where the earthquake happened, what its
magnitude was, then mention human casualties or damage, and    nally
discuss rescue e   orts. such    story    ow    can be learned from multiple

4.5 discussion

171

articles from the same domain. an id48 model is very appropriate for
the task. states correspond to topics in the domain, which discovered
via iterative id91 of similar sentences from many articles from the
domain of interest. transitions between states in the model correspond
to topic transitions in typical texts. these id48 models do not require
any labelled data for training and allow for both content selection and
ordering in summarization.

4.5 discussion

if we want to develop automatic systems that emulate human summa-
rization, then it is clear from all collected corpora of in vivo human
summarization that generation of abstractive summaries is necessary.
the research presented in this section takes a step toward that goal.
of the di   erent approaches to abstraction presented here, compression
is probably the most mature. since the early work introducing this topic
in the context of summarization and drawing on the zi   -davis corpus,
a sub-   eld on just this topic has grown. part of the interest in this
sub-   eld may come in part from its similarities to machine translation
since alignment is required and in part from its reliance on parsing, thus
drawing researchers outside of the summarization community. indeed,
recent work on this topic explores new methods for learning over parse
trees that enlarges the range of alignments allowed [222]. looking ahead
in this monograph to section 5.5, compression has also been heavily
used in the area of speech summarization, in part to remove dis   uen-
cies. it is a concretely circumscribed research problem with application
to other problems in addition to summarization. continuing research
on compression must still deal with issues such as scarcity of training
data, appropriate integration of syntax even when the input data comes
from a noisy genre, and compressions involving lexical substitution and
paraphrase.

sentence fusion and revision have also been growing as summariza-
tion sub-   elds. by combining phrases from di   erent sentences, fusion
approaches push the envelope of id57 in
a way that few other systems do. revision provides a more general
approach than compression to producing abstractive summaries. like

172 generation for summarization

many compression approaches, fusion relies on parsing and alignment of
parse trees, and in this respect, its robustness is an issue. for example,
in experiments at columbia using multigen in newsblaster, multigen
produced less than 10% of the summaries in part because of its need to
parse all input sentences, thus slowing down the process; newsblaster
runs in a limited period of time and will choose summaries from the
summarizers that    nish    rst. future research on fusion and revision will
need to further address grammaticality of summary sentences, some-
thing that is not an issue with extractive approaches. given that many
of the evaluation set-ups favor extraction, another area of research is
investigation into evaluations that jointly measure quality and content.
finally, if summaries are actually to be read by people, as opposed to
evaluated by comparison in content to human summaries, then sentence
ordering remains an important research issue.

5

genre and domain speci   c approaches

in the previous sections, we presented a variety of approaches for
generic summarization, applicable when we know little about the audi-
ence or user need. we also described how the generic summarization
approach can be adapted when summarization takes the user need,
speci   ed as a query, into account. similarly, generic approaches may
not be appropriate when the input for summarization comes from a
speci   c domain or type of genre. when the input documents have a
known, speci   ed structure or other unique characteristics, summariza-
tion algorithms can take advantage of these characteristics to more
accurately identify important information. journal articles, for exam-
ple, very often have a results or conclusion section that identi   es the
key contributions of the article and these sections will be the place
where important information for the summary will be located. speci   c
domains, such as medicine or law, may have speci   c requirements on
the kind of information that is needed in a summary. such domains
may also have resources that can help the summarization process.

in this section, we overview research on summarization that has
been carried out for genres and domains where the structure of the
underlying documents are markedly di   erent from news documents.

173

174 genre and domain speci   c approaches

we look at genres that have much more structure than news, in par-
ticular, journal articles. we also examine genres which are much more
informal than news, such as email, blogs, and speech. these genres are
based on exchanges and the dialog characteristics must be taken into
account. we also describe summarization in the medical domain, for
both lay users and health professionals as intended users. this is an
interesting domain not only because of the structure found in the doc-
uments, but also because it has a variety of resources that can aid the
summarization process. semantic resources are available and thus, sum-
marization techniques that exploit these resources operate at a deeper
semantic level than do techniques for generic summarization.

we    rst present summarization approaches within the medical
domain and then present genre-speci   c summarization approaches for
journal articles, email, blogs and speech.

5.1 medical summarization

summarization in the medical domain is a remarkable example of an
application where generic summarization approaches are simply not
applicable. in this domain, summarization algorithms are developed with
precisely de   ned intended uses such as to help doctors decide on a course
of treatment, to review the latest research relevant to a particular patient
or to help patients and their relatives access information pertinent to
a condition or disease. medical articles have predictable structure that
algorithms exploit, and furthermore, in the medical domain, there are
large-scale knowledge resources available, providing semantic informa-
tion for millions of concepts and concept names.

end users of summarization systems in the medical domain include
healthcare providers and consumers, both of whom turn online to    nd
information of interest. in the medical community, the number of jour-
nals relevant to even a single specialty is unmanageably large, making it
di   cult for physicians to keep abreast of all new results reported in their
   elds.1 similarly, patients and family members who need information
about their speci   c illness can also be overwhelmed with the choice of

1 there are    ve journals in the narrow specialty of cardiac anesthesiology but 35 di   erent
anesthesia journals; 100 journals in the closely related    elds of cardiology (60) and car-
diothoracic surgery (40); over 1000 journals in the more general    eld of internal medicine.

5.1 medical summarization

175

online information related to their interest. summarization can help
patients determine which articles in search results are relevant and can
also help them to browse more e   ciently.

a summary can be tailored to the type of user, whether a health-
care provider or a patient. the content of the summary can be further
tailored using information from the patient record, a unique form of
user model available in the medical domain. depending on the patient   s
diagnosis and various test results, di   erent information may be more or
less relevant for the summary; these can in   uence what is relevant both
for the patient   s physician as well as the patient and family. finally,
end users may either be looking for information on a speci   c problem
(essentially searching) or they may be browsing for information that
may be relevant to a patient problem. these two di   erent tasks may
also in   uence the kind of summary that is provided.

substantial resources are also available in the healthcare domain.
an ontology of medical concepts, the uni   ed medical language sys-
tem (umls) [210] is available and can be automatically linked to the
terms in the input articles. the entry for each concept includes multiple
alternative ways that can be used to refer to the concept. for example,
the entry for hodgkin disease also lists hodgkin   s sarcoma, hodgkin
lymphoma and lymphogranulomatosis, which are all terms that can
be used to refer to the disease. concepts are assigned semantic types
such as organisms, chemicals, events, and physical, spatial, tem-
poral, functional and conceptual relationships are explicitly encoded.
this enables more semantic processing than is currently possible in
other domains and as a result, summarizers developed in the medical
domain tend to do deeper analysis than the generic and query-focused
summarizers described so far. they also tend to use more generation
from semantic representations than pure sentence extraction.

in this section, we overview systems for summarization of journal
articles, intended for physicians, and summarization of consumer health
information.

5.1.1 summarization of healthcare documents for patients

patients and family members search for information in ways rather
di   erent from that of caregivers. often their initial search query is

176 genre and domain speci   c approaches

not precise, although they may desire a speci   c type of information.
although this problem is not limited to seekers of medical knowledge,
researchers [12] have noted that the problem of underspeci   cation is
particularly acute in medicine. in addition, berland et al. [14], in a
study of internet-accessible consumer healthcare information, concludes
that identi   cation of con   icting viewpoints needs to be clearly shown.
centrifuser [53, 92] is a summarizer that aims to help consumers in
their search for information. it generates three distinct summary com-
ponents that form an overview plus details embedded within a textual
user interface that speci   cally targets the cognitive needs of consumers.
the three components consist of: (1) hyperlinks to topics related to the
query to facilitate navigation and query reformulation, (2) a high-level
overview of the commonalities in the documents, and (3) a description
of di   erences between the retrieved documents to help searchers select
relevant items. an example of a summary generated by centrifuser,
taken from elhadad et al. [53], is shown in figure 5.1.

centrifuser   s summaries can be classi   ed as multi-document and
query-focused. this summarizer selects relevant information from mul-
tiple documents using the query to access topic segments in the doc-
ument that are most likely to contain pertinent information. these
segments provide navigation links in the    rst part of the tripartite
summary and thus we see that centrifuser also di   ers from the major-
ity of summarizers described in this overview in that it provides an
indicative summary that allows users to browse relevant documents.
centrifuser also generates similarities and di   erences between the doc-
uments it is summarizing. it uses sentence extraction to provide a
synopsis of commonalities across input documents. it computes quan-
titative metrics for the typicality or rare-ness of the di   erent topics
discussed in input documents by mapping these to a topic tree for
the particular domain. the topic tree itself is constructed o   -line in
an unsupervised manner by id91 segments from a large number
of documents from the domain. a document topic tree represents the
document as a hierarchy of topics (e.g., treatment topic consisting of
dieting, surgery and medication subtopics) and enables more precise
retrieval of relevant sentences by localizing query relevance to speci   c
document sections. centrifuser uses typicality scores in the tree in order

5.1 medical summarization

177

fig. 5.1 centrifuser summary of documents retrieved for the query what is atrial    brilla-
tion?. underlined portions represent links to related queries or documents.

to report di   erences between retrieved documents. for example, a user
may be interested in a document that describes a topic that is rarely
described in other documents, but is relevant to the user   s query.

5.1.2 medical journal article summarization

research on summarization of medical documents has also investigated
the problem of journal article summarization. in this section, we present
two journal article summarization systems, one of which uses more

178 genre and domain speci   c approaches

traditional sentence extraction techniques, while the other uses seman-
tic analysis and generation of summary sentences.

one system for journal summarization, tas [54], was developed as
part of persival [129], a patient speci   c digital library. it generates
a summary for a set of documents retrieved as relevant to a user query.
thus, tas also falls into the class of query-focused, multi-document sum-
marization. tas is strikingly di   erent from most other summarizers as it
does not use sentence extraction, but instead extracts information from
sub-sentential units to    ll in pre-de   ned templates, orders it, and gen-
erates summary sentences. the summaries produced by tas are brief-
ings containing results reported in clinical studies. tas uses information
extracted from the patient record to    lter    ndings from the article, thus
creating a summary for the physician of relevant journal article results
that are tailored for the patient under his/her care. the patient record,
which serves as a user model for tas, is available to persival from the
electronic patient record system webcis (web-based clinical informa-
tion system) [82]. any information that is repeated across the input arti-
cles is identi   ed and presented to the user, while any contradictory results
are explicitly signaled to the reader.

to produce a summary, tas    rst automatically classi   es the arti-
cle according to its primary clinical purpose. typical article types are
diagnosis, prognosis and treatment. at the content selection stage, a set
of templates, each representing a parameter (e.g., chest pain), relation
(e.g., association), and    nding (e.g., unstable angina), is instantiated for
each input article. in this stage, relevant results are extracted exploiting
the structure of the medical articles, each of which always has a result
section. the templates that are not speci   c to the patient are    ltered
out by matching parameters against information found in the patient
record. for instance, the template representing the result    chest pain
is associated with unstable angina    will only be included in a summary
for a patient with chest pain. during the content organization stage,
the relevant templates are clustered into semantically related units,
and ordered. finally, tas uses a phrase-based language generator to
produce a    uent summary.

yang et al. [223] also describe a query-focused multi-document
summarization system. they use sentence extraction in much the same

5.1 medical summarization

179

style as the generic summarizers described earlier, but their system is
critically di   erent in its attempt to summarize all information related
to a particular mouse gene, speci   ed in the user   s query. the search
for relevant information is performed in all of pubmed, a comprehen-
sive online repository of medical abstracts.2 given a query containing
a mouse gene of interest, their system returns a ranked list of all sen-
tences across all articles that are relevant and users can choose how
many sentences they would like to view. the number of sentences for
each gene varied from one to 30,216. like elhadad et al., yang and
his co-authors also use semantic information available in the medi-
cal domain, but they use it to extract features for id91 and for
extracting relevant sentences. in the    rst stage of their system, they
created a database of all sentences indexed by mouse gene using their
gene/protein id39 system [34]. they also stored
   elds such as the mesh headings (i.e., keywords) and publication date
for each sentence. their sentence extraction system uses a set of fea-
tures to score sentences for inclusion in the summary, including several
based on domain speci   c semantic information. they model their sen-
tence extraction on edmundson   s paradigm and thus, one feature is clue
phrases that can be indicative of importance (e.g.,    in conclusion   ).
another set of key features includes    ve descriptive features represent-
ing clusters of genes in the database (e.g., mesh terms, descriptive
words representing where the cluster falls in a gene ontology). the gene
clusters are computed using a standard id91 algorithm over gene
vectors consisting of mesh headings, gene ontology terms associated
with the gene, and the words in the sentence associated with each gene
as well as the sentences immediately preceding and following the target
sentence. other features for sentence extraction include the number of
genes a sentence mentions, domain speci   c keywords, sentnece length,
and recency of the article in which the sentence occurs. the scoring
yields a ranking of sentences for inclusion in the summary and it is left
to the user to specify summary length.

2 http://www.pubmedcentral.nih.gov.

180 genre and domain speci   c approaches

5.2

journal article summarization in non-medical domains

while summaries of medical journal articles are clearly important for
physicians, summarization of journal articles from other    elds is also
a topic of current research. given that journal articles are typically
organized in a more predictable way than texts from other genres,
proposed approaches often exploit that predictable structure to    nd
salient information. it is expected, for example, that the paper will
have an introduction, statement of goals, comparison with related work,
approach description, results and conclusions. in this section, we sur-
vey an approach using rhetorical status and others that use information
about citations.

5.2.1 using genre-speci   c rhetorical status

a summarization system for journal articles can take advantage of the
rhetorical status of a sentence in producing a summary. teufel and
moens [200] proposed an annotation scheme for rhetorical status of
sentences with seven categories. the categories include :

aim the speci   c research goal of the current paper.
own a neutral description of methodology, results and discussion.
contrast statements of comparison with other work or weak-

nesses of other work.

basis statements of agreement with other work or continuation of

other work.

human annotators were able to follow the scheme reliably to anno-
tate each sentence in scienti   c articles with one of these rhetorical
status categories. the annotated corpus was used to train a naive
bayes classi   er using a variety of features, including sentence location in
the article, the section and the paragraph, type of section (conclusion,
experiments, etc.), sentence length, number of words in the sentence
that also appear in the paper title, presence of words with high tf   idf
weight, verb tense, voice and presence of modal auxiliaries, presence
and nature of citation, rhetorical context, and presence of 644 formu-
laic expressions. the classi   er was able to predict the rhetorical status
of novel sentences with accuracy of 73%.

5.2 journal article summarization in non-medical domains

181

listing the sentences that ful   ll the aim, contrast, basis and
background for each paper gives an excellent generic summary of
a scienti   c article. the explicit indication of the rhetorical status is
helpful for users not familiar with the paper that is being summarized.
usually, there are relatively few aim, contrast and basis sen-
tences in the paper and all of them can be included in the summary.
background sentences, on the other hand, are more numerous so
displaying all of them might become problematic when stricter sum-
mary length restrictions are imposed. to solve this problem, one more
classi   er was trained to distinguish between summary-worthy sentences
and other sentences. the classi   er is used to select only the most
appropriate background sentences and its use increases the overall
performance of the summarizer.

5.2.2 exploiting citation links between papers

genre-speci   c summarization of scienti   c articles can take advantage
of a valuable and powerful source of information not available in most
other genres: the references (citations) that link papers. the sentences
and paragraphs in which references occur often contain concise sum-
maries of the cited paper or other information relevant to that paper.
consequently, the analysis of related articles becomes an essential
knowledge source for summarization.

three types of extractive summaries based on citation link analy-
sis have been proposed: overview of a research area (multi-document
scienti   c paper summary) [145], impact summary (single document
summary of a paper using sentences from the paper itself) [134] and
citation summary (a mix of multi- and single document summarization,
in which a single paper is summarized but the input to the summarizer
are the sentences from other papers in which that paper is cited) [169].
writing an overview of several related scienti   c papers is a di   cult
task, even for people. nanba and okumura [145] proposed a system
for facilitating writing such overviews, which visualizes connections
between papers and provides information on how the papers are related
to each other. they develop a rule-based system to identify refer-
ence areas in a paper, in which other papers are discussed and cited.

182 genre and domain speci   c approaches

in addition, each of these areas is classi   ed as belonging to one of three
types: (i) describing methods or approaches used in the paper, (ii) dis-
cussion of and comparison with related work, and (iii) other. classi   -
cation is performed using hundreds of manually coded cue words. the
user can request to see each type of reference area for a paper of interest.
with the ever increasing number of scienti   c publications, the need to
further develop and improve such aids for paper browsing and access
will only increase with time. in fact much progress has already been
achieved in the automatic identi   cation and classi   cations of citations
and citation types [191].

impact summarization is de   ned by mei and zhai [134] as the task
of extracting sentences from a paper that represent the most in   uen-
tial content of that paper. they employ a language model approach
to solve the task. for each paper to be summarized, they    nd other
papers in a large collection that cite that paper and extract the areas
in which the references occur. a language model is built using the col-
lection of all reference areas to a paper, giving the id203 of each
word to occur in a reference area. this language model gives a way of
scoring the importance of sentences in the original article: important
sentences are those that convey information similar to that which later
papers discussed when referring to the original paper. the measure of
similarity between a sentence and the language model was measured by
kullback   leibler (kl) divergence. in order to account for the impor-
tance of each sentence within the summarized article alone, they use
word probabilities estimated from the article. the    nal score of a sen-
tence is a linear combination of impact importance coming from kl
divergence and intrinsic importance coming from the word probabilities
in the input article. the method produces extractive summaries that
are vastly superior, as measured by the id8 automatic measure,
to baselines and to the generic summarization system mead [202].
one drawback of impact-based summaries is that, while they contain
valuable content, they have low linguistic quality and are hard to read
and understand, as can be seen from the example shown in figure 5.2.
citation summarization [169] is a di   erent approach to summarizing
a single article, based on the way other papers refer to it. citation sum-
marization does not use at all the text of the article being summarized.

5.2 journal article summarization in non-medical domains

183

1. figure 5: interpolation versus backo    for jelinek-mercer (top), dirichlet smooth-
ing (middle), and absolute discounting (bottom).
2. second, one can decouple the two di   erent roles of smoothing by adopting a two
stage smoothing strategy in which dirichlet smoothing is    rst applied to implement
the estimation role and jelinek   mercer smoothing and jelinek   mercer smoothing is
then applied to implement the role of query modeling.
3. we    nd that the backo    performance is more sensitive to the smoothing param-
eter than that of interpolation, especially in jelinek   mercer and dirichlet prior.
4. we then examined three popular interpolation-based smoothing methods
(jelinek   mercer method, dirichlet priors, and absolute discounting), as well as their
backo    versions, and evaluated them using several large and small trec retrieval
testing collections.
5. by rewriting the query-likelihood retrieval model using a smoothed document
language model, we derived a general retrieval formula where the smoothing of the
document language model can be interpreted in terms of several heuristics used in
traditional models, including tf-idf weighting and document length id172.
6. we    nd that the retrieval performance is generally sensitive to the smoothing
parameters, suggesting that an understanding and appropriate setting of smoothing
parameters is very important in the id38 approach.

fig. 5.2 an example of an impact-based summary.

instead, qazvinian and radev [169] propose to summarize the reference
areas in other articles related to the target paper that has to be sum-
marized. the input to the summarizer consists of the sentences or short
paragraphs from other papers that discuss the target article. there is
a high degree of repetition in the input because many papers refer to
the same aspect of the target paper: an approach, result, main contri-
bution, etc. given this characteristic of the data, a id91 method
for summarization seems highly appropriate (see section 2.1.2). simi-
lar sentences are clustered together and a representative sentence is cho-
sen to convey the information in that cluster. the best way to    nd the
most representative sentence in each cluster turned out to be applying the
graph-based method discussed in section 2.1.3 for summarization to each
cluster. the evaluation was performed on 25 articles from    ve sub-areas of
computational linguistics, using the manual pyramid evaluation method.

184 genre and domain speci   c approaches

1. the czech parser of collins et al. (1999) was run on a di   erent data set and
most other dependency parsers are evaluated using english.
2. more precisely, parsing accuracy is measured by the attachment score, which is a
standard measure used in studies of id33 (eisner, 1996; collins et al.,
1999).
3. in an attempt to extend a constituency-based parsing model to train on depen-
dency trees, collins transforms the pdt dependency trees into constituency trees
(collins et al., 1999).
4. more speci   cally for pdt, collins et al. (1999) relabel coordinated phrases after
converting dependency structures to phrase structures, and zeman (2004) uses a
kind of pattern matching, based on frequencies of the parts-of-speech of conjuncts
and conjunctions.
5. in particular, we used the method of collins et al. (1999) to simplify part-of-
speech tags since the rich tags used by czech would have led to a large but rarely
seen set of pos features.

fig. 5.3 an example of a citation summary.

citation summaries are even harder to read than impact summaries
because they mix information about the work done in the paper which
cites the target article with descriptions of the work described in the tar-
get article itself, as shown in figure 5.3. application of the approaches
developed for categorization of types of reference areas should be helpful
in overcoming this problem in future work.

all of these approaches reveal that there is much work that remains
in the    eld of journal summarization. very di   erent approaches from
generic summarization have been proposed that exploit the structure
and speci   c characteristics of journal articles and this is appealing. the
quality of the summaries that are produced, however, still leaves much
to be desired. further work is needed that takes these new approaches
to the next level, perhaps by integrating work on    uency, cohesion and
sentence ordering.

5.3 email

research in email summarization ranges from summarization of a single
email message to summarization of a email collection, including both

5.3 email

185

summarization of a mailbox and summarization of a thread of related
emails. the function of summarization varies in each of these tasks. for
single email summarization, a short reminder of the message topic can
su   ce. indications of topic can help users to prioritize incoming email,
determining when an immediate reply is required and to quickly    nd
older relevant messages. for a mailbox of emails, summarization can
provide a browsing interface to help the user    nd emails of interest.
focused summarization is also a possibility as, for example, the focus
may be to identify tasks that must be done. for an email thread, sum-
marization must convey the essence of an extended conversation.

summarization must be sensitive to the unique characteristics of
email, a distinct linguistic genre that exhibits characteristics of both
written text and spoken conversation. a thread or a mailbox contains
one or more conversations between two or more participants over time.
as in summarization of spoken dialog, therefore, summarization needs
to take the interactive nature of dialog into account; a response is often
only meaningful in relation to the utterance it addresses. unlike spoken
dialog, however, the summarizer need not concern itself with speech
recognition errors, the impact of pronunciation, or the availability of
speech features such as id144. furthermore, responses and reactions
are not immediate and due to the asynchronous nature of email, they
may explicitly mark the previous email passages to which they are
relevant.

5.3.1 summarization of individual email messages

summarization of a single email message can be accomplished by select-
ing noun phrases that are indicative of its topic. this is the approach
taken in gister [141, 208], a system that uses a combination of linguistic
   ltering and machine learning to select noun phrases for the summary.
researchers at microsoft research [42] note that email often con-
tains new tasks for the recipient. they suggest that it would be helpful
if a system could automatically identify and summarize the tasks con-
tained in emails. they have developed a system that uses machine
learning to classify sentences within emails as task-directive or not.
the system then reformulates each such sentence in the imperative to

186 genre and domain speci   c approaches

make the task explicit. to collect data for their supervised approach,
they had a group of annotators annotate a large body of email with
speech acts specifying task and non-task acts. the features used for
machine learning contained message-speci   c features (e.g., number of
addressees, number of forwarded messages), super   cial features (e.g.,
id165s) and linguistic features (e.g., structural features that could be
derived from part-of-speech tagging or parsing). they used support
vector machines for machine learning and performed feature ablation
to determine the impact of di   erent types of features. their evaluation
showed that the best results are achieved with all features, but there
was little di   erence between the use of deep linguistic features and sur-
face linguistic features, thus indicating that their system would still get
good results without parsing.

full document summarization has also been used to generate a sum-
mary of email messages. lam et al. [99] use an existing ibm summa-
rization system [17] to produce summaries. however, in order to make
this feasible, they    rst must pre-process the message to remove pieces
that would be problematic; their pre-processor removes certain headers,
quoted text, forward information and email signatures. summaries are
generated by including the context of the email messages. thus, an
email message plus all its ancestor messages in the thread are sent to
the document summarizer. the resulting summary is augmented with
the results of named entity extraction and includes a list of important
names and dates at the end of the textual summary. this summariza-
tion approach resembles some of the techniques that we describe in the
next section, where summarization of full threads is discussed.

5.3.2 summarization of an email thread

in early research on summarization of email threads, nenkova and
bagga [151] developed a system to generate indicative summaries of
email threads in an archived discussion. they used an extractive sum-
marizer to generate a summary for the    rst two levels of the dis-
cussion thread tree, producing relatively short    overview summaries.   
they extracted a sentence for each of the two levels, using over-
lap with preceding context. for the root message, they extracted the

5.3 email

187

shortest sentence with the largest number of nouns which also occur
in the email   s subject header. for the follow-up email, they extracted
the sentence with the most overlap of words with the root message.
the threads in their corpus of email were relatively short, so this
approach worked well.

later work on summarization of email threads [177] also used
extractive summarization. however, rambow et al.   s work zeroed in
on the dialogic nature of email. they experimented with two extractive
summarizers based on machine learning. the    rst used features simi-
lar to any text summarizer and considered the input thread as simply
a text document. the second summarizer relied on email speci   c fea-
tures in addition to traditional features, including features related to
the thread and features related to email structure such as the number
of responders to a message, similarity of a sentence with the subject,
etc. they used a rule-based classi   er, ripper, and their results show
that the full set of features yield the best summaries.

email conversations are a natural means of getting answers to one   s
questions and the asynchronous nature of email makes it possible for
one to pursue several questions in parallel. as a consequence, question   
answer exchanges    gure as one of the dominant uses of email conversa-
tions. these observations led to research on identi   cation of question
and answer pairs in email [140, 187] and the integration of such pairs in
extractive summaries of email [132]. mckeown et al. experiment with
di   erent methods for integrating question and answer pairs into email
summarization and show that all achieve signi   cant improvement over
an extractive approach alone, which may end up including either a
question without its answer or an answer without its question.

summarization of an email thread can also be used to allow a reader
to catch up on an extended discussion that took place in her absence
and make a decision about how to respond to an outstanding issue. wan
and mckeown [215] develop an approach that identi   es the main issue
within an email and the responses later in the thread that address that
issue. their approach makes the assumption that the issue will be found
in the    rst email in the thread, and subsequently extracts all responses
to the message. to determine the issue, they    nd the sentences that
are most similar to the response. they    nd that using a centroid based

188 genre and domain speci   c approaches

approach with singular value decomposition for similarity computation
produces the best results. the intuition that motivates this method is
very similar to that in impact summarization of scienti   c articles that
we discussed previously in section 5.2.1.

while the summarizers described here have sometimes used a tech-
niques developed for another genre, overall it seems clear that attention
to the characteristics that are speci   c to email result in better summa-
rization systems. those researchers that have experimentally compared
both approaches have seen an improvement when they include email
speci   c features. in general, machine learning results have shown that
including the linguistic features that are used in generic summarization
in addition to email speci   c features yields the best results.

5.3.3 summarization of an email archive

the research we have reported on so far has generated summaries for an
individual thread. archives and mailboxes, however, consist of multiple
threads and it can be di   cult for an end-user to organize his mailbox in
such a way that it is easy to    nd the email or thread of interest. newman
and blitzer [156] present a system that can be used for browsing an
email mailbox and that builds upon id57
techniques. they    rst cluster all email in topically related threads.
both an overview and a full-length summary are then generated for
each cluster. the resulting set of summaries could be presented as a
browsing page, much as is done with news summarization systems such
as newsblaster [130] or newsinessence [173]. newman and blitzer rely
on email speci   c features for generating both overviews and summaries.
they also take quotes into account. another key feature of overview
and summary generation is the similarity of a sentence to a cluster
centroid.

a more recent approach to summarization of email within a folder
uses a novel graph-based analysis of quotations within email [27]. using
this analysis, carenini et al.   s system computes a graph representing
how each individual email directly mentions other emails, on the gran-
ularity of fragments and individual sentences.    clue words    are de   ned
as stems of words in an email message that are repeated in either the

5.4 web summarization

189

parent or child node (fragment) from the quotation graph. the cws
(clue word summarizer) scores sentences for inclusion based on fre-
quency of the clue words they contain. carenini et al. compare how well
cws works relative to mead [56], to a modi   ed version of the statisti-
cal sentence extractor built by rambow et al. [177], and to a combina-
tion of cws with mead in which the cws and mead scores for each
sentence are normalized and combined. their results show that the clue
words summarizer does as well as or better than previous approaches.
the evaluation was performed using sentence precision and recall on
20 email conversations from the enron email dataset. annotators were
asked to produce extractive summaries with length 30% of the original
text to obtain the gold-standard.

5.4 web summarization

the quantity of information appearing on the web has been the moti-
vation for much research on summarization, yet research on summa-
rization of web sources started much later than other work. as with
the other genres and domains discussed in this section, systems devel-
oped for web summarization can take into account the characteristics
of the web and the data being summarized to produce higher quality
and more accurate summaries. to date, most research carried out for
this genre has focused on summarization of web pages, with a smaller
body of work looking at summarization of blogs.

5.4.1 web page summarization

research on web page summarization varies in terms of how much
the summary is in   uenced by web page content or by web page con-
text, that is, the text surrounding the links which point at that page.
most research in this area makes use of a large scale resource from the
open directory, known as dmoz,3 consisting of summary/web page
pairs all organized into a hierarchy with web pages on more general
topics occurring near the top of the hierarchy and more specialized
sub-topics occurring along the branches. the short human summaries

3 http://www.dmoz.org/.

190 genre and domain speci   c approaches

for each web page are a valuable resource and they can serve as model
summaries against which automatically generated summaries can be
compared.

early research on web page summarization [13, 24] relied on page
content alone to generate the summary. berger and mittal [13] take
an approach modeled on id151 (mt). they
use alignment from mt to align dmoz summaries with the web page
content. to generate the summary, they use two models, the    rst of
which determines the words of the summary and the second of which
determines their order. the novelty in their approach is that they gen-
erate a gist which may include words that did not occur in the web page
at all. their content model, which selects summary words, is based in
part on word frequency within the document but they also generate
semantically related words to replace one or more words in the docu-
ment. they use traditional alignment developed for machine translation
between dmoz summaries and the corresponding web pages to gen-
erate the semantically related words. their generation model is simply
an id165 model trained over the dmoz summaries. buyukkokten
et al. [24], in contrast, focus on producing adjustable-length summaries
that can be successively revealed on a small hand-held device. they use
a relatively simple summarization method, selecting the most impor-
tant sentence from a discourse segment within the web page, based
entirely on luhn   s summarization method. the contribution of their
approach is in their ability to expand and contract summaries by adding
sentences within a discourse segment or across segments.

later research on web page summarization takes an interesting turn
and explores the use of context on the web. discussion here centers
on whether summaries can be generated from the context alone    
as in the citation summarization approach for scienti   c articles     or
whether algorithms should take into account web page content as well.
one type of context to consider is the text in pages that link to the one
that has to be summarized, in particular the text surrounded by the
hyperlink tag pointing to the page. this text often provides a descrip-
tive summary of a web page (e.g.,    access to papers published within
the last year by members of the nlp group   ). proponents of using
context to provide summary sentences argue that a web site includes

5.4 web summarization

191

multimedia, may cover diverse topics, and it may be hard for a summa-
rizer to distinguish good summary content from bad [47]. the earliest
work on this approach was carried out to provide snippets for each
result from a search engine [2]. to determine a summary, their system
issued a search for a url, selected all sentences containing a link to
that url and the best sentence was identi   ed using heuristics. delort
et al. [47] use a very similar procedure to select context sentences. they
extend the older approach through an algorithm that allows selection
of a sentence that covers as many aspects of the web page as possible
and that is on the same topic. for coverage, delort et al. used word
overlap, normalized by sentence length, to determine which sentences
are entirely covered by others and thus can be removed from consid-
eration for the summary. to ensure topicality, delort   s system selects
a sentence that is a reference to the page (e.g.,    id98 is a news site   )
as opposed to content (e.g.,    the top story for today...   ). he computes
topicality by measuring overlap between each context sentence and the
text within the web page, normalizing by the number of words in the
web page. when the web page does not have many words, instead he
clusters all sentences in the context and chooses the sentence that is
most similar to all others using cosine distance. this algorithm thus
uses some aspects of the web page in addition to context, an advance
over earlier work, although it is clear that word overlap is a very rough
approximation of measuring representativeness.

sun et al. [197] propose another type of context: the use of click-
through data. they use data from microsoft   s search engine to gather
triples (u, q, p) representing queries (q) issued by user (u) who then
clicked through to page (p). in this work, a summary is constructed
by selecting sentences from the web page. they experiment with two
methods, one of which uses an adaptation of luhn   s method [111],
computing the signi   cance factor of words by a weighted mixture of
tf   idf computed by frequency on the web page and tf   idf com-
puted by frequency in the query set. luhn   s algorithm is then used
to compute the signi   cance factor of each sentence. they also adapt
latent semantic analysis in a similar way by changing the computation
for each term in the lsa matrix, weighting its frequency by the number
of times it appears in the query set. to account for web pages which

192 genre and domain speci   c approaches

are not covered by clickthrough data, they develop a thematic lexicon
using the open directory project, associating query terms with each
node in the dmoz hierarchy, where each node corresponds to one or
more web pages. thus, the query terms at the node can be used for web
pages with no clickthrough data. their comprehensive evaluation shows
that query words dramatically improve performance and that the latent
semantic analysis is better than the adaptation of luhn   s method. this
is a strong piece of work with interesting results when clickthrough data
is available. note that for researchers outside of search engine facilities,
such data is not readily available.

research on web site summarization is ongoing. choi et al. [30] use
web site summarization to enhance sponsored ad presentation, aug-
menting the ad with all or part of the landing page, using unsupervised
methods. it is clear that web site summarization is a very young area
of research, with lots of room for both improvement and new ways in
which summarization can be exploited. furthermore, the methods for
making use of web context have been only partially explored.

5.4.2 summarization of online interactive sites

a few people have looked at summarization of online discussion forums
and of blogs. zhou and hovy [233] use a method similar to methods for
speech and email in their work on summarization of online discussion
forums. they note that discussion forums involve asynchronous com-
munication between participants on multiple interleaved topics. their
work focuses on the identi   cation of adjacency pairs (similar to [66])
to identify who talks to whom and uses topic segmentation to identify
the di   erent topics under discussion,    nally producing a summary that
is structured into sub-summaries for each topic. for blogs, they exploit
the observation that in political blogs, posters base their discussion on
news articles and di   erent points in the discussion are linked directly
to the article. assuming that readers are interested in facts, they create
a summary from the sentences that directly link to the associated news
article. an alternate approach [83] creates a summary by extracting
sentences from the blog post using word frequency to measure sen-
tence importance, but this work critically di   ers from others in that

5.5 summarization of speech

193

it measures word frequency in the comments on posts, thus aiming at
extracting sentences that elicited discussion.

5.5 summarization of speech

like most research in genre-speci   c summarization, summarization of
speech also requires taking into account the speci   c features of the
medium. that can include features from the speech signal or fea-
tures that capture the dialog nature of exchanges. techniques for
id54 of spoken input have been developed for
many applications, most notably for summarization of broadcast news
[31, 79, 124], dyadic conversations [71, 72], meetings [63, 142, 214] and
lectures/presentations [68, 77, 93, 168, 230].

some of the techniques developed for text summarization have been
successfully applied to speech summarization without much modi   ca-
tion, in the setting when a written transcript of the audio is avail-
able to work with. the most widely applied techniques for transcript
summarization [31, 77, 142, 229] have been maximal marginal rele-
vance [25] and latent semantic analysis [69]. variations of frequency
features (total frequency, tf   idf) and positional features, as well as
length features, similar to the ones developed for text summarization
are employed in much of the existing work on speech summarization.
at the same time, there are some aspects unique to speech summa-
rization which have led to the need for research in directions unexplored
in work on text summarization. probably the most striking    nding that
will need further veri   cation and analysis in future work are results
indicating that very good summarization performance can be achieved
on the basis of acoustic features alone, with no recourse to transcripts
or textual features [124, 158, 231].

we overview some of the unique characteristics of speech as input

for summarization in the sections below.

5.5.1 dealing with errors from automatic

id103

in most realistic situations, manual transcripts of the audio input
to be summarized are not available. in this case, automatic speech

194 genre and domain speci   c approaches

recognition (asr) is used to obtain a textual transcript. depending on
the type of speech, asr can be errorful, with word error rates ranging
from 10% for more formal read speech to as high as 40% for spon-
taneous conversations or lectures [68]. speech summarization systems
intended to produce textual output need to develop techniques for    nd-
ing portions of the input that are not only informative but also have
lower recognition error rates.

to give an idea of how the use of automatic transcripts changes the
clarity and content of summaries, we reproduce murray et al.   s [142]
example of a snippet of a human summary of a meeting, an lsa sum-
mary of manual and automatic transcripts:

human the experiment consisted of leading a subject to believe she were talking
to a computer, then having the    computer    break down and be replaced
with a human.

lsa; manual transcript i should say the system was supposed to break down
and then these were the remaining three tasks that she was going to solve
with a human. one time to pretending to be a human which is actually
not pretending.

lsa; automatic transcript reverse should so the system were supposed to
break down and then this would be remaining three tasks that she was
going to solve with a human.

to address the problems with asr issues during content selection,
zechner and waibel [229] employ a combination of two features in
selecting passages, using speaker turns as selection units: the fraction
of words in the utterance whose con   dence score from the automatic
id103 system is greater than 0.95 and the importance of
the passage computed using mmr [25]. they test the technique on four
television shows consisting of conversations of multiple speakers. the
trade-o    between recognition con   dence and segment importance led to
an average word error rate reduction in the summary of about 10% and
a relative improvement of summary accuracy of about 15% compared
to the standard mmr approach developed for text summarization.

in later work, techniques for content selection accounting for recog-
nition accuracy have been re   ned. for example kikuchi et al. [93] use
tf   idf and trigram id203 of words to measure importance and
a recognition con   dence score equal to the logarithm of the ratio of

5.5 summarization of speech

195

the word hypothesis id203 and that of all other hypotheses to
measure con   dence in the quality of the automatic transcript.

alternatively, e   ort could be focused to improve asr performance
before summarization is performed [68]. changing the output modality
could also remove the need to explicitly deal with asr errors. for
example, errors would not matter much if the    nal summary is rendered
by playing the audio snippets [204] determined to be important by a
robust algorithm not sensitive to transcription errors [144].

5.5.2 dealing with dis   uencies: filled pauses

and repetitions

spontaneous speech is characterized by the presence of    lled pauses
(   um   ,    uh   ,    well   ) and repetitions (   i was going i was going to call
you tonight   ). the percentage of dis   uent words in informal conversa-
tions can be high: 15   25% of the total words spoken [227], so detecting
and removing dis   uencies has the potential of improving the readabil-
ity of summaries as well as to reduce noise in feature computation.
consider zechner   s example of original conversation utterance and its
cleaned up version:

a: well i um i think we should

discuss this you know with her

a   : i think we should discuss this with her

detection of dis   uencies is necessary for many other applications
besides summarization and has been addressed by numerous researchers
as a stand alone task [91, 138, 196]. such tools for dis   uency detection
can be used as initial preprocessing of the input, cleaning up the tran-
scripts as the    rst task for the summarization system [229].

another possible approach is that of hori et al. [79] who include tri-
gram id203 as one of the terms used to calculate how desirable for
selection an utterance is. the trigram id203 of utterances contain-
ing asr errors or dis   uencies would be low, so this measure is e   ective
in reducing out-of-context words in the summary.

in recent work, zhu and penn [236] put forward a suggestion for dif-
ferent treatment of dis   uencies. they argued that instead of removing

196 genre and domain speci   c approaches

dis   uencies from the input, systems should use their presence as a
feature in machine learning models for extractive summarization. they
maintain that dis   uencies could actually be a signal for important
sentences because dis   uencies are more likely to be inserted in the
beginning of discourse segments or before important concepts are men-
tioned. in their experiments, using dis   uency features     number of
repetitions and    lled pauses     leads to small improvements of less
than 1% of id8 scores. a more detailed feature analysis is nec-
essary in order to    nd out if dis   uencies are positively or negatively
correlated with the summary-worthy class, that is if they are indeed
predictive of summary content rather than of content that should be
avoided.

5.5.3 units for content extraction

in text, the typical unit on which extractive systems operate are
sentences. sentence boundaries are usually easy to identify, especially
for languages like english where punctuation is a relatively unambigu-
ous delimiter of sentence boundaries. in speech, the decision about
what unit to use for content selection is not that obvious. a speaker
might pause in the middle of a sentence, or two consecutive sentences
might not be delimited by a pause, so    nding the right granularity for
extractive summarization requires more sophisticated processing.

several approaches have been developed for automatic segmentation
of speech (transcripts) into sentences (for example see [108, 188]). the
system of liu et al. [108] simultaneously detects sentence boundaries
and dis   uencies, allowing for the transformation of original conversa-
tional speech that is hard to read into more usual textual form:

original but uh i i i i think that you know i mean we always uh i mean ive ive
had a a lot of good experiences with uh with many many people especially
where theyve had uh extended family and i and an- i i kind of see that that
you know perhaps you know we may need to like get close to the family
environment.

processed but ive had a lot of good experiences with many people especially where
theyve had extended family. i kind of see that perhaps we may need to get
close to the family environment.

5.5 summarization of speech

197

the use of systems for automatic sentence segmentation is necessary
when human transcripts for the input are not available. in many cases,
additional tuning of the sentence segmentation system for the speci   c
purposes of summarization might be necessary [109, 139].

some researchers have argued that segment granularities di   erent
from sentences would be even more appropriate for speech summa-
rization. adjacency pairs are motivated by pragmatic dependencies
between utterances, while intonational phrases are more faithful repre-
sentations of the properties of speech than sentence boundaries.

maskey et al. [125] compared three ways of segmenting speech for
extractive summarization: sentences, pause delimited fragments and
intonational pharses. the automatic system of liu et al. [108] was used
to    nd sentences; pause delimited segments were de   ned as snippets
of speech between pauses of 250 ms. intonational phrases were also
automatically detected by a machine learning predictor. for training
of the predictor, one transcript of abc    world news tonight    broad-
cast was manually annotated. when used for extractive summarization,
intonational phrases gave best results, signi   cantly higher than either
sentence or pause-delimited fragment extraction.

adjacency pairs, and question   answer pairs in particular, consist of
utterances that are pragmatically dependent on each other. such pairs
would usually involve utterances by two speakers and are informative
only when taken together: a summary should not contain a question
without its respective answer or an answer without the question it
was given in response to. zechner and lavie [228] were the    rst to
point out these issues. they proposed a heuristic method for identifying
question   answer pairs and showed that including these as a single unit
in the summary signi   cantly improved the readability of the output as
measured by subjective assessment of evaluators.

in later work, a machine learning model using structural, durational
and lexical features for the identi   cation of adjacency pairs in meetings
was shown to achieve impressive accuracy of 90% [66]. the automat-
ically identi   ed adjacency pairs certainly augment the capabilities for
summarization of conversational speech because they can be used to
identify agreement and disagreement in conversations [66], as well as
to better rank the importance of utterances in the conversation [63].

198 genre and domain speci   c approaches

5.6 discussion

many of the summarization approaches discussed in this section
diverge markedly from the generic sentence extraction approach.
instead, authors take advantage of the particular characteristics of the
genre, media, or domain. in journal article summarization, researchers
exploited consistency in structure of articles
(e.g., conclusions,
methods) and the use of citations. in email summarization, researchers
exploited the asynchronous nature of dialog that typically appears,
often using meta-data to help. in speech summarization, researchers
exploit information from the speech signal itself as well as indica-
tors about dialog structure. in web page summarization, researchers
exploited the context of links and search results to aid in determining
what is important to include in a summary. in many of these domains,
additional resources are available to help researchers advance beyond
pure sentence extraction. for example, in the medical domain, the com-
bination of the semantic information available in the umls along with
the speci   c structure of text (e.g., results sentences) enabled the use of
interpretation followed by generation.

just as the characteristics of the genre, media or domain enabled
exploration of new approaches, other characteristics create di   culties
for research in this area. many of the genres feature noisy text, with par-
tial or ungrammatical sentences, and dis   uencies. such hurdles some-
times spurred non-extractive approaches (e.g., gisting or compression)
and at other times, required research into approaches that could process
the data (e.g., the identi   cation of who talks to whom).

as opposed to generic news

single
document or multi-document, summarization in these areas is only
beginning. these are areas where the summarization    eld is poised
for break-throughs and where new researchers can    nd interesting,
unsolved problems.

summarization, whether

6

intrinsic evaluation

task-based evaluations are time-consuming, expensive and require a
considerable amount of careful planning. as a result, they are not that
suitable for system comparisons and evaluation during development.
intrinsic evaluations are normally employed in such cases, either by
soliciting human judgments on the goodness and utility of a given sum-
mary, or by a comparison of the summary with a human-authored gold
standard. when comparisons with a gold standard are involved, it is
desirable that these be done automatically to further reduce the need
for human involvement.

here we give an overview of the main intrinsic approaches used in
summarization evaluation and the motivation for developing certain
evaluation methods and for abandoning others.

6.1 precision and recall

most summarization systems select representative sentences from the
input to form an extractive summary; the selected sentences are strung
together to form a summary without any modi   cation of their original
wording. in such settings, the common information retrieval metrics of

199

200

intrinsic evaluation

precision and recall can be used to evaluate a new summary. a person
is asked to select sentences that seem to best convey the meaning of the
text to be summarized and then the sentences selected automatically
by a system are evaluated against the human selections. recall is the
fraction of sentences chosen by the person that were also correctly
identi   ed by the system

recall = |system   human choice overlap|
|sentences chosen by human|

(6.1)

and precision is the fraction of system sentences that were correct

precision = |system   human choice overlap|
|sentences chosen by system|

(6.2)

the appeal of precision and recall as evaluation measure is that
after a human de   nes the gold standard sentence selection, it can be
repeatedly used to evaluate automatically produced summaries by a
simple comparison of sentence identi   ers. yet, there are also several
problems with these measures, as we discuss next.

6.1.1 human variation

di   erent people tend to choose di   erent sentences when asked to con-
struct an extractive summary of a text. research as early as rath
et al. [178] reported that extracts selected by six di   erent human judges
for 10 articles from scienti   c american had only 8% overlap on aver-
age. it has been shown [48] that the same summary can obtain a recall
score with between 25% and 50% di   erence depending on which of two
available human extracts are used for evaluation. thus, a system can
choose a good sentence, but still be penalized in precision/recall evalu-
ation. in light of this observation, it also seems that in summarization
evaluation it will be more bene   cial to concentrate on recall rather than
precision. precision is overly strict     some of the sentences chosen by
the system might be good, even if they have not been chosen by the
gold standard creator. recall, on the other hand, measures the overlap
with already observed sentence choices.

6.2 relative utility

201

6.1.2 granularity

another problem with the precision/recall (p/r) measures is the fact
that sentences are not the best granularity for measuring content.
sentences di   er in word length and convey di   erent amounts of infor-
mation. selecting a longer and more informative sentence can be more
desirable than selecting a short sentence. imagine, for example, a
human extract consisting of the sentences    (1) we need urgent help.
(2) fires have spread in the nearby forest, and threaten several villages
in this remote area.    now imagine two systems, each choosing only
one sentence appearing in the human extract, one choosing sentence
(1) and the other choosing sentence (2). both summaries will have the
same p/r score, but can hardly be perceived as equally informative.

6.1.3 semantic equivalence

yet another problem with using sentences as the unit of evaluation
is that two distinct sentences can express the same meaning. this
situation is very common in news, and is particularly pertinent in multi-
document summarization of news, in which the input to the system con-
sists of many articles on the same topic. again, a human would select
only one of the equivalent sentences but a system will be penalized for
choosing an alternate sentence that expresses the same meaning.

many of the alternative evaluation measures were designed to
address the issues that were raised regarding p/r. for example, it has
been suggested to use multiple models rather than a single person   s
judgment [85]. smaller, more-semantically oriented units of analysis
have been proposed, and more emphasis has been given on recall.

6.2 relative utility

relative utility [172] has been proposed as a way to address the human
variation and semantic equivalence problems in p/r evaluation. in this
method, multiple judges score each sentence in the input on a scale from
0 to 10 as to its suitability for inclusion in a summary; highly ranked
sentences are very suitable for a summary, and low ranked sentences
should not be included in a summary. the judges also explicitly mark

202

intrinsic evaluation

which sentences are mutually substitutable because of semantic equiv-
alence. thus, each possible selection of sentences by a system can be
assigned a score showing how good a choice of sentences it represents.
the approach seems intuitive and quite appealing, but requires a
good deal of manual e   ort in sentence tagging. moreover, at times it
fails to discriminate between human and automatic summaries, a dis-
tinction which a good evaluation measure should be able to do. partic-
ularly when applied to the evaluation of switchboard summaries
[235], automatic summarizers achieved a score higher than that of the
humans, indicating that this approach for evaluation is not a good
choice for evaluation of summarization of conversational speech. the
approach has been used in only a handful of studies of text summa-
rization and is in general not a preferred metric to report in a paper.

6.3 duc manual evaluation

the document understanding conference/text analysis conference
(duc/tac)1 has been carrying out large-scale evaluations of summa-
rization systems on a common dataset since 2001. on average, over
20 teams participate in this nist-run evaluation each year and a lot
of e   ort has been invested by the conference organizers to improve
evaluation methods. duc content evaluations performed in the period
between 2001 and 2004 were based on a single human model. however,
in order to mitigate the bias coming from using gold standards from
only one person, di   erent annotators were creating the models for dif-
ferent subsets of the test data, never having the same person creating
gold standards for all test sets [75].

in order to address the need for more    ne-grained analysis than
the sentence level, duc adopted elementary discourse units (edus),
roughly correspond to clauses, as the basis for evaluation. the model
summary was automatically split into edus, and machine summaries
were evaluated by the degree to which they cover each edu in the
model. the overall score, called coverage, was the average score across

1 http://duc.nist.gov, http://www.nist.gov/tac/.

6.3 duc manual evaluation

203

all edus in the model. the measure was recall-oriented, in essence
measuring what fraction of the model edus were covered.

in an attempt to encourage research in abstractive summarization,
duc also started using human-generated abstracts as models, rather
than human selection of sentences. the above-described evaluation
method supported this transition, at the expense of requiring more
human involvement.

the availability of the output of many systems over many test inputs
has allowed researchers to study the factors that in   uence summariza-
tion performance. it has been reported that in anova analysis of
coverage scores with system, input and the human creators of mod-
els as factors, the model creator turned out to be the most signi   cant
factor [128]. this once again raised concerns about the advisability of
using a single human model for evaluation. the input document to be
summarized was also a signi   cant factor [148], suggesting that some
inputs are easier to summarize than others.2 summary length was also
a signi   cant factor, with summary coverage tending to increase as the
length of the summary increases.

two lines of research on evaluation emerged in an e   ort to address
some of the issues raised by the duc evaluation protocol: develop-
ing cheap automatic methods for comparing gold standards with auto-
matic summaries and better analysis of human variation in content
selection, relying on multiple models to avoid dependence on the gold
standard.

in later years (after 2004), the initial duc evaluation protocol was
no longer used. instead, the pyramid manual evaluation was used as
a measure for content selection [153]. in addition, a simpler metric of
content quality was introduced for the query-focused tasks in duc and
tac: responsiveness. for this evaluation, human annotators were asked
to rate on a scale from 1 to 5 how good they thought the summary was
in terms of providing information relevant to the user query.

2 this    nding shows that paired tests should be used to compare the performance of two
systems on the same test set. these tests eliminate the variation that is due to the input
di   culty and better assesses the signi   cance of di   erence between the systems.

204

intrinsic evaluation

6.4 automatic evaluation and id8

automatic evaluation measures have been known even before the
widely used id7 technique for machine translation evaluation [166]
and the id8 technique derived from it [105] (see for example [176]).
the problem has been that di   erent automatic evaluation approaches
give di   erent results, so it was not clear what the scores mean and
which automatic measure is to be preferred. in using id7 for machine
translation evaluation, however, researchers developed methods to val-
idate automatic approaches. they took manual evaluations generally
accepted in the research community, and looked for automatic mea-
sures which correlated well with the human scores over a large set of
test points, especially when multiple human models were used.

inspired by the success of the id7 id165 overlap based mea-
sure, similar id165 matching was tried for summarization. using
duc coverage scores to validate the method, the id83 system
for automatic evaluation of summarization was developed. id8 is
also based on the computation of id165 overlap between a summary
and a set of models. id8 has been preferred for summarization
because it is recall-oriented, unlike id7, which emphasizes precision
[107]. id8 has numerous parameters, including word id30,
stop word removal and id165 size. di   erent settings work best for
di   erent summarization tasks as can be seen from the detailed tables
in [105]. this means that di   erent parameters need to be tested for
new tasks, such as speech summarization of spontaneous conversations
or recordings of meetings.

id8 is the most commonly used metric of content selection
quality used in research papers because it is cheap and fast. many
researchers feel more comfortable to supplement id8    gures with
a manual evaluation of content such as the pyramid method, at least
on some small subset of the test data.

6.5 pyramid method

the pyramid method [152, 153] is concerned with analysis of the
content selection variation in human summaries [201, 211], as well

3 recall-oriented understudy for gisting evaluation.

6.6 linguistic quality evaluation

205

as how evaluation results can be made less dependent on the model
used for evaluation. multiple human abstracts are analyzed manually
to derive a gold standard for evaluation. the analysis is semantically
driven: information with the same meaning, even when expressed using
di   erent wording in di   erent summaries, is marked as expressing the
same summary content unit (scu). each scu is assigned a weight
equal to the number of human summarizers who expressed the scu
in their summaries. the distribution of scu weights is zip   an, with
few scus being included by many summarizers and a heavy tail of
low-weight scus.4 scu analysis shows that summaries that di   er in
content can be equally good and assigns a score that is stable with
respect to the models when 4 or 5 human summaries are used. the
actual pyramid score is equal to the ratio between the weight of con-
tent expressed in a summary and the weight of an ideally informative
summary with the same number of scus.

a drawback of this approach is that it is very labor intensive, despite
the fact that a special annotation tool (ducview5) has been developed
to facilitate the process. also, the method was developed for evaluation
of abstractive summaries, and requires analysis that is unnecessary for
extractive summaries, as we see in later sections.

6.6 linguistic quality evaluation

all the evaluation methods discussed so far have been focused on
evaluating the information content of a summary, or its overall informa-
tiveness. but summary readability is also an important factor in sum-
mary evaluation, albeit often neglected by summarization researchers.
in duc, a set of questions was developed to evaluate readability aspects
of summaries. are they ungrammatical? do they contain redundant
information? are the references to di   erent entities clear? does the
summary build up sentence by sentence? while much progress has
been seen in improving system content selection, most automatic sum-
maries score rather poorly on readability aspects such as coherence and

4 hence the name of the method. if scus are ordered in tiers from low to high weight, we
get a pyramid shape.
5 http://www1.cs.columbia.edu/  ani/ducview.html.

206

intrinsic evaluation

referential clarity [150]. improving automatic summary readability is an
open problem in summarization and developing suitable metrics that
will allow tracking of progress in this direction is important. recent
interest in sentence ordering and referential cohesion have led to a pro-
posal for automatic evaluation of cohesion [101]. hopefully, more future
e   ort will be focused on linguistic quality.

in tac 2008, the    responsiveness    measure was re-de   ned, and
included both the extent to which a summary succeeded in providing
information relevant to the user de   ned topic and the overall linguistic
quality of the summary.

human assessments of linguistic quality on a scale, usually 1   5, are
probably the fastest and cheapest to obtain. they do not require the
collection of gold standard summaries, nor any annotation or manual
analysis from the assessors in order to come up with a summary quality
score. because of these properties, this evaluation approach is rather
attractive especially when many systems have to be compared on many
inputs. at the same time, unlike for many other manual metrics, the
properties of this metric, such as inter-annotator agreement and repro-
ducibility, have not been well studied.

6.7

intrinsic evaluation for speech summarization

while many speech summarization researchers have used preci-
sion/recall of utterances [72, 124] or automatic measures such as
id8 to evaluate their results, there have been two proposals for
evaluation methods speci   cally designed for this new genre: summary
accuracy and summarization accuracy.

6.7.1 summary accuracy

summary accuracy was de   ned by zachner and waibel [229]: for each
word in an utterance, they de   ne a weight, which they call a relevance
score, equal to the average number of times the word occurred in a
phrase selected for inclusion in the summary by a human annotator.6

6 such a de   nition addresses the granularity problem discussed in section 6.1 for preci-
sions/recall, because using word-by-word comparison accounts for the possibly di   erent
informativeness of utterances.

6.7 intrinsic evaluation for speech summarization

207

so, if    ve annotators are asked to construct a summary, and three of
them select the same span of text, all the words in this span will be
assigned a relevance score equal to 3/5, even if some words appear in
the other two text spans as well. summary accuracy is then de   ned as
equal to the sum of relevance scores of the words in a system-selected
utterance that were correctly recognized by the asr system, divided by
the maximum achievable relevance score with the same number of words
somewhere in the text. this de   nition of word relevance (weight) and
overall summary score is very similar to the idea on which the pyramid
evaluation method for news is based. in fact, while attempting to apply
the pyramid method for evaluation of meeting transcripts, galley [63]
observed that, for meeting summarization, human summaries formed
by sentence extraction convey the same information only when the two
annotators extracted exactly the same sentence.7 he then computed
pyramid scores based on words rather than content units, with the
restriction that a given word is assigned a non-zero relevance score only
when it is part of the same utterance that the humans selected. this
scoring worked out quite well for the meeting domain, and is almost
equivalent to summary accuracy. such reinvention of scoring metrics is
indicative of the need for closer interaction between researchers tackling
di   erent types of summarization genres.

6.7.2 summarization accuracy

summarization accuracy has been de   ned in the context of the evalua-
tion of speech summarization systems performing sentence compaction
[80]. the sentence compaction task is to eliminate    unnecessary    words
from a sentence, similar to compression. again, multiple annotators are
asked to produce possible compactions; many possible compactions for
a given sentence can be produced. in order to extrapolate more likely
but unseen compactions from those produced by the annotators, all
human productions for a sentence are merged into a single network
and di   erent traversals of the network can produce new compaction
variants that were not produced by any of the humans, but that are

7 this fact suggests that the semantic equivalence problem of precision/recall might not be
an issue for meeting summarization evaluation.

208

intrinsic evaluation

considered possible. the thus enriched network is then used to evaluate
the summarization accuracy of the automatic compaction. this evalu-
ation procedure also allows for weighting of words that are included in
the summary by many humans.

the summarization accuracy measure has been found to work well
for high compression ratios where most of the original text is preserved,
but results in problems for summaries at small ratios such as 10%
[62]. in such cases, the authors propose the use of a score based on
individual comparisons between the automatic summary and each of
the manual summaries, choosing the best score among all the individual
comparisons. this idea is very interesting and has not been explored in
news summarization: it suggests that rather than using multiple human
summaries for weighting, one can    nd the human summary that is most
similar to the produced machine summary.

6.7.3 what about using id8 for speech

summarization?

the use of a generally agreed upon and automatic metric such as
id8 is hugely appealing. it allows for cheap evaluation and ease
in comparing results from di   erent research e   orts. for these reasons,
researchers have investigated the degree to which id8 scores cor-
relate with human judgments of informativeness of such summaries. in
murray et al. [143], subjective human judgments were collected for sum-
maries of meetings (six test meetings), and compared with several of the
popular id8 variants. id8 scores were not found to correlate
with the human judgments on this data. more disturbingly, when gal-
ley [63] compared automatic and human summaries for the same test
meetings, id8 scores were not able to distinguish between the two
types. both results suggest that the use of id8 is not advisable for
this type of data especially with so few test points.8 in a larger study
on 30 spoken presentations [62], id8, as well as summarization

8 the results are also consistent with those reported in [235], indicating that id8 scores
were not correlated with summary accuracy when evaluating summaries of telephone
conversations.

6.7 intrinsic evaluation for speech summarization

209

accuracy and f-score, measures were found to highly correlate with
human judgments on a    ve point scale. such    ndings suggest that
id8 should be used only when a large number of test points is
available and that its applicability should be tested for new types of
data.

7

conclusions

the vast majority of summarization systems today continue to rely
on sentence extraction. while approaches do resemble those that orig-
inated in the 1960s, we have seen numerous advances. many of these
advances have been pushed forward because of the establishment of an
annual evaluation for summarization, duc, which later became tac.
evaluation in duc has established that, of the various unsupervised
methods for determining sentence salience, the use of the log-likelihood
ratio test for topic signatures is the best measure of word importance
when used in the context of id57 of news.
the availability of previous years    evaluation data for duc has also
made possible the exploration of supervised methods for summariza-
tion. machine learning approaches allowed for automatic experimenta-
tion with the importance of di   erent features.

id57 is another landmark in the progres-
sion of summarization research. it was introduced as a problem in the
1990s when the web became a presence and people began to be over-
whelmed by the vast amount of information available on any one topic.
research interest in id57 further increased
when it was established as a task in duc in 2001. new methods for

210

211

sentence extraction also have arisen. they include graph-based meth-
ods that identify salience in part by links between sentences, the words
they contain or between the concepts within sentences. researchers
have also questioned the traditional approach to sentence extraction in
which sentences for the summary are selected one at a time in a greedy
fashion and have shown how, alternatively, a system can globally opti-
mize the selection of summary sentences.

independently of duc, other major advances within the extrac-
tive paradigm were also introduced. one was the introduction of more
sophisticated natural language analysis for the extraction of features.
the use of discourse to determine the importance of any individual
sentence was a signature theme of a number of approaches in single
document summarization. by measuring how connected a sentence is
to the remainder of the article, whether through coreferential or lexical
chains, a system could determine its importance. more sophisticated
uses of discourse investigate the detection of rhetorical relations which
can serve as guide for extracting salient information. while promising,
identi   cation of rhetorical relations is not yet robust enough for summa-
rization to use reliably. the use of semantics and discourse knowledge
are clearly areas where more research is needed. this area holds the
potential for further improvement of summarization systems.

following a rise in research on generic single document and multi-
document summarization, a concern arose that summarization was
being carried out in a vacuum, without taking speci   c user character-
istics and needs into account. researchers claimed that people usually
create summaries in the context of a task, with some information about
the needs of the summary reader. the    eld reacted and a task was cre-
ated for use in subsequent evaluations: the task of id53.
this move gave rise to query-focused summarization. query-focused
summarization has been carried out naturally in both information
retrieval and web-based id53 contexts. it allows for nice
synergy between the    elds to address the issues. it could, however, use
a further push through changes in how the query-focused evaluations
are carried out. in the evaluations, participants are usually provided
with a set of documents that are exactly on topic to use as input to
their summarization system. this allows them to test summarization

212 conclusions

independently of errors in information retrieval. in this context, how-
ever, it appears that generic summarization approaches perform almost
as well     and sometimes, as well     as approaches developed speci   -
cally for the query-focused task. a change in task scenario that required
summarizers to deal with the realities of irrelevant results from infor-
mation retrieval could help to push the    eld forward again in new ways
because it would demand researchers to develop new approaches instead
of re-using generic approaches.

while sentence extraction still dominates the    eld, there have been
major advances in research on the generation of sentences for a sum-
mary. one approach has been to remove information from an extracted
sentence that is not needed in the summary. the need for this kind
of compression has spawned an entire new research    eld on compres-
sion, sometimes divorced from summarization itself. there is extensive
data for research on compression, particularly in the area of headline
generation, since news articles are almost always published with head-
lines, and thus, statistical approaches to compression are the norm.
the problem of sentence fusion, or combining information from several
document sentences to create a summary sentence, is further behind
compression, but has also seen a surge in approaches in just the last few
years. research usually investigates how a system can take repeated
phrases from di   erent sentences and combine them in a new sen-
tence, thus forming a sentence that conveys the    intersection    of dif-
ferent sentences. common approaches involve pair-wise comparison of
aligned parse trees, with di   erences in approaches centering on how
the phrases identi   ed in this way are    nally combined. in very recent
work, researchers have also looked at how to generate sentences that
convey the    union    of information found in di   erent sentences and have
shown how this approach would be useful for id53. this
is a    eld that is still wide open for follow up research.

domain and genre-speci   c approaches provide some note-worthy
lessons. unlike news summarization, where most of the work has been
done, summarization research for speci   c domains and speci   c gen-
res often uses more sophisticated approaches and often has access to
semantic resources. while these approaches may use sentence extrac-
tion, the approaches for    nding salient sentences are quite di   erent.

213

in the medical domain, there are examples where actual generation
of sentences from semantics is performed. this is possible because of
expectations about the type of information required in a summary, how
it is typically expressed and where it typically appears in journal arti-
cles. research on summarization of the web typically relies on massive
resources of web page/summary pairs and thus, statistical, supervised
approaches are the norm. it also makes use of the structure on the web,
exploiting links and information around urls, to determine summary
content. speech summarization exploits information from the acoustic
signal in deciding what information is salient. both speech and email
summarization use information about dialog structure to determine
what is important.

the initiation of large-scale, cross-site evaluation, led by nist,
changed the summarization    eld in major ways. data for both training
and testing was systematically gathered, resulting in sets of input docu-
ments paired with one, and, more often, several human summaries. this
infusion of data into the community fueled learning-based approaches,
allowed comparison of di   erent methods, and probably most impor-
tantly, enabled research on evaluation itself. several new methods
for summary evaluation arose, including manual (e.g., pyramid) and
automatic methods (e.g., id8). while there are still many open
questions, the emergence of large-scale evaluation overall pushed the
   eld forward at a much faster speed than would otherwise have been
possible.

some problematic issues remain. given the large number of met-
rics that are used at the duc and tac evaluations, system developers
are free to choose and report the metric in follow-on publications that
makes their system look best. furthermore, authors often make their
comparisons with the systems that reported results at the evaluation
workshop, omitting the fact that duc/tac participants developed
their systems in a very short time-frame and had no access to the
test data, failing to mention that other systems have been developed
since the speci   c evaluation that improve on the original performance.
so, it can still be di   cult to determine whether a new approach is
actually state of the art. the id74 also clearly need fur-
ther work. id8, for example, rarely detects signi   cant di   erences

214 conclusions

between systems and, in some cases, shows that a system performs
better than or equal to humans. manual methods show that humans
outperform systems (particularly in the single document case), but can
require too much e   ort to use. these problems highlight the need for
additional evaluation research.

where should the    eld go from here? one obvious additional area
would be more intensive use of natural language analysis and gener-
ation. very few systems do much in the way of semantic analysis.
additional semantic analysis would be helpful in determining when
a phrase is relevant to a query in query-focused summarization or in
determining saliency. semantic analysis could also help in determining
when two phrases convey the same meaning. semantics in conjunction
with generation could be used for better determining how to combine
phrases without creating errors in reference.

there is beginning to be research on update summarization.
an update summary follows a stream of news over time and the sum-
mary attempts to include information on what is new compared to
what was reported in previous days. this is a problem that informa-
tion retrieval researchers tried some 10 years back [1] and concluded was
not a feasible task. recently, it has received attention again as part of
the tac evaluation framework. it proves to be a di   cult task because,
in contrast to typical id57, a system must
be able to determine not only what is important but also what is di   er-
ent. almost anything could be di   erent and yet, not everything should
be included in the summary. only the important di   erences should be
selected. how this is best done remains a topic of current research.

the growth in new types of online information also changes the
type of summarization that is of interest. summarization has recently
been combined with work on id31 [21, 26, 102]. in this
context, it is desirable to have summaries which list the pros and cons
of a service or product. for example, for a restaurant, one might want
to hear that the service was good, but the food bad. given the many
di   erent reviews that one can    nd on the web, the problem is to identify
common opinions. some of the approaches that have been tried so far
include determining semantic properties of an object, determining the
intensity of an opinion, or determining whether an opinion is important.

215

as social networking grows, summaries may be helpful in navigating
a network, determining who talks to who, or summarizing activities.
blogs or chat are a new form of media that, like email, share char-
acteristics of both text and speech. they typically involve interaction
between participants, often separated in time. there can be multiple
responses to the same posting. they often involve informal language
and in the case of chat, many abbreviations. new words appear and
given their appeal to young people, the language can be quite di   er-
ent from the kind of language that summarizers typically handle, such
as newswire. summarization of this kind of media is just beginning to
appear and we expect to see more of this in the near future.

references

[1] j. allan, c. wade, and a. bolivar,    retrieval and novelty detection at the
sentence level,    in proceedings of the annual international acm sigir con-
ference on research and development in information retrieval, pp. 314   321,
2003.

[2] e. amitay and c. paris,    automatically summarizing web sites - is there a
way around it?,    in proceedings of the acm conference on information and
knowledge management, pp. 173   179, 2000.

[3] r. h. baayen, word frequency distributions. kluwer academic publishers,

2001.

[4] b. baldwin and t. morton,    dynamic coreference-based summarization,    in
proceedings of the conference on empirical methods in natural language pro-
cessing, pp. 1   6, 1998.

[5] m. banko, v. o. mittal, and m. j. witbrock,    headline generation based on
statistical translation,    in proceedings of the annual meeting of the associa-
tion for computational linguistics, pp. 318   325, 2000.

[6] r. barzilay and m. lapata,    modeling local coherence: an entity-based

approach,    computational linguistics, vol. 34, no. 1, pp. 1   34, 2008.

[7] r. barzilay and m. elhadad,    text summarizations with lexical chains,    in
advances in automatic text summarization, (i. mani and m. maybury, eds.),
pp. 111   121, mit press, 1999.

[8] r. barzilay and n. elhadad,    sentence alignment for monolingual comparable
corpora,    in proceedings of the conference on empirical methods in natural
language processing, pp. 25   32, 2003.

216

references

217

[9] r. barzilay, n. elhadad, and k. mckeown,    inferring strategies for sentence
ordering in multidocument news summarization,    journal of arti   cial intel-
ligence research, vol. 17, pp. 35   55, 2002.

[10] r. barzilay and l. lee,    catching the drift: probabilistic content models,
with applications to generation and summarization,    in human language
technology conference of the north american chapter of the association for
computational linguistics, pp. 113   120, 2004.

[11] r. barzilay and k. r. mckeown,    sentence fusion for multidocument news
summarization,    computational linguistics, vol. 31, no. 3, pp. 297   328, 2005.
[12] m. becher, b. endres-niggemeyer, and g. fichtner,    scenario forms for web
information seeking and summarizing in bone marrow transplantation,    in
proceedings of the international conference on computational linguistic,
pp. 1   8, 2002.

[13] a. berger and v. mittal,    ocelot: a system for summarizing web pages.,   
in proceedings of the annual international acm sigir conference on
research and development in information retrieval, pp. 144   151, 2000.

[14] g. berland, m. eilliot, l. morales, j. algazy, r. kravitz, m. broder,
d. kanouse, j. m. noz, j.-a. puyol, m. lara, k. watkins, h. yang, and
e. mcglynn,    health information on the internet: accessibility, quality and
readability in english and spanish,    american medical association, vol. 285,
no. 20, pp. 2612   2621, 2001.

[15] f. biadsy, j. hirschberg, and e. filatova,    an unsupervised approach to
biography production using wikipedia,    in proceedings of the annual meet-
ing of the association for computational linguistics, pp. 807   815, 2008.

[16] s. blair-goldensohn, k. r. mckeown, and a. h. schlaikjer,    defscriber: a
hybrid system for de   nitional qa,    in proceedings of the annual interna-
tional acm sigir conference on research and development in information
retrieval, pp. 462   462, 2003.

[17] b. k. boguraev and m. s. ne   ,    discourse segmentation in aid of document
summarization,    in proceedings of the hawaii international conference on
system sciences-volume 3, p. 3004, 2000.

[18] b. boguraev and c. kennedy,    salience-based content characterization of text
documents,    in advances in automatic text summarization, pp. 2   9, the
mit press, 1997.

[19] d. bollegala, n. okazaki, and m. ishizuka,    a machine learning approach to
sentence ordering for multidocument summarization and its evaluation,    in
proceedings of the international joint conference on natural language pro-
cessing, pp. 624   635, 2005.

[20] d. bollegala, n. okazaki, and m. ishizuka,    a bottom-up approach to sentence
ordering for id57,    in proceedings of the interna-
tional conference on computational linguistics and the annual meeting of
the association for computational linguistics, pp. 385   392, 2006.

[21] s. branavan, h. chen, j. eisenstein, and r. barzilay,    learning document-
level semantic properties from free-text annotations,    in proceedings of
the annual meeting of
the association for computational linguistics,
pp. 263   271, 2008.

218 references

[22] r. brandow, k. mitze, and l. f. rau,    automatic condensation of electronic
publications by sentence selection,    information processing and management,
vol. 31, no. 5, pp. 675   685, 1995.

[23] j. burstein and d. marcu,    toward using text summarization for essay-
based feedback,    in proceedings of le conference annuelle sur le traitement
automatique des langues naturelles, pp. 51   59, 2000.

[24] o. buyukkokten, o. kaljuvee, h. garcia-molina, a. paepcke, and t. wino-
grad,    e   cient web browsing on handheld devices using page and form sum-
marization,    in acm transactions on information systems, vol. 20, no. 1,
pp. 82   115, january 2002.

[25] j. carbonell and j. goldstein,    the use of mmr, diversity-based rerunning
for reordering documents and producing summaries,    in proceedings of the
annual international acm sigir conference on research and development
in information retrieval, pp. 335   336, 1998.

[26] g. carenini and j. c. k. cheung,    extractive vs. id86-based abstractive sum-
marization of evaluative text: the e   ect of corpus controversiality,    in proceed-
ings of the international id86 conference, pp. 33   41,
2008.

[27] g. carenini, r. t. ng, and x. zhou,    summarizing email conversations with
clue words,    in proceedings of the international conference on world wide
web, pp. 91   100, 2007.

[28] y. chali, s. hasan, and s. joty,    do automatic annotation techniques have
any impact on supervised complex id53?,    in proceedings of
the joint conference of the annual meeting of the acl and the international
joint conference on natural language processing of the afnlp, pp. 329   332,
2009.

[29] y. chali and s. joty,    improving the performance of the random walk model
for answering complex questions,    in proceedings of the annual meeting of the
association for computational linguistics, short papers, pp. 9   12, 2008.

[30] y. choi, m. fontoura, e. gabrilovich, v. josifovski, m. mediano, and b. pang,
   using landing pages for sponsored search ad selection,    in proceedings of the
international conference on world wide web, 2010.

[31] h. christensen, b. kolluru, y. gotoh, and s. renals,    from text summariza-
tion to style-speci   c summarization for broadcast news,    in proceedings of the
european conference on ir research, 2004.

[32] j. clarke and m. lapata,    models for sentence compression: a comparison
across domains, training requirements and evaluation measures,    in proceed-
ings of the annual meeting of the association for computational linguistics,
pp. 377   384, 2006.

[33] j. clarke and m. lapata,    modelling compression with discourse constraints,   
in proceedings of the joint conference on empirical methods in natural lan-
guage processing and computational natural language learning, pp. 1   11,
2007.

[34] a. cohen,    unsupervised gene/protein entity id172 using automati-
cally extracted dictionaries,    in proceedings of the acl-ismb workshop on
linking biological literature, ontologies and databases: mining biological
semantics, pp. 17   24, association for computational linguistics, 2005.

references

219

[35] w. w. cohen, r. e. schapire, and y. singer,    learning to order things,   

journal of arti   cial intelligence research, vol. 10, pp. 243   270, 1998.

[36] t. cohn and m. lapata,    sentence compression beyond word deletion,    in
proceedings of the international conference on computational linguistic,
pp. 137   144, 2008.

[37] j. conroy, j. schlessinger, d. o   leary, and j. goldstein,    back to basics:
classy 2006,    in proceedings of the document understanding conference,
2006.

[38] j. conroy, j. schlesinger, j. goldstein, and d. o   leary,    left-brain/right-
the document

brain id57,    in proceedings of
understanding conference, 2004.

[39] j. m. conroy and d. p. o   leary,    text summarization via hidden markov
models,    in proceedings of the annual international acm sigir conference
on research and development in information retrieval, pp. 406   407, 2001.

[40] j. m. conroy, j. d. schlesinger, and d. p. o   leary,    topic-focused multi-
document summarization using an approximate oracle score,    in proceed-
ings of the international conference on computational linguistics and the
annual meeting of the association for computational linguistics, pp. 152   159,
2006.

[41] t. copeck and s. szpakowicz,    leveraging pyramids,    in proceedings of the

document understanding conference, 2005.

[42] s. corston-oliver, e. ringger, m. gamon, and r. campbell,    task-focused
summarization of email,    in proceedings of the acl text summarization
branches out workshop, pp. 43   50, 2004.

[43] h. daume iii and d. marcu,    generic sentence fusion is an ill-de   ned sum-
marization task,    in proceedings of the acl text summarization branches
out workshop, pp. 96   103, 2004.

[44] h. daum  e iii and d. marcu,    a phrase-based id48 approach to docu-
ment/abstract alignment,    in proceedings of the conference on empirical
methods in natural language processing, pp. 119   126, 2004.

[45] h. daum  e iii and d. marcu,    bayesian query-focused summarization,    in
proceedings of the international conference on computational linguistics and
the annual meeting of the association for computational linguistics, pp. 305   
312, 2006.

[46] s. deerwester, s. dumais, g. w. furnas, t. k. landauer, and r. harshman,
   indexing by latent semantic analysis,    journal of the american society for
information science, pp. 391   407, 1990.

[47] j.-y. delort, b. bouchon-meunier, and m. rifqi,    enhanced web document
summarization using hyperlinks,    in proceedings of the acm conference on
hypertext and hypermedia, pp. 208   215, 2003.

[48] r. l. donaway, k. w. drummey, and l. a. mather,    a comparison of rank-
ings produced by summarization evaluation measures,    in proceedings of the
naacl-anlp workshop on id54, pp. 69   78, 2000.

[49] b. dorr, d. zajic, and r. schwartz,    hedge trimmer: a parse-and-trim
approach to headline generation,    in proceedings of the hlt-naacl work-
shop on text summarization, pp. 1   8, 2003.

220 references

[50] p. a. duboue, k. r. mckeown, and v. hatzivassiloglou,    progenie: bio-
graphical descriptions for intelligence analysis,    in proceedings of nsf/nij
symposium on intelligence and security informatics, vol. 2665, pp. 343   345,
springer-verlag, 2003.

[51] t. dunning,    accurate methods for the statistics of surprise and coincidence,   

computational linguistics, vol. 19, no. 1, pp. 61   74, 1994.

[52] h. p. edmundson,    new methods in automatic extracting,    journal of the

acm, vol. 16, no. 2, pp. 264   285, 1969.

[53] n. elhadad, m.-y. kan, j. klavans, and k. mckeown,    customization in a
uni   ed framework for summarizing medical literature,    journal of arti   cial
intelligence in medicine, vol. 33, pp. 179   198, 2005.

[54] n. elhadad, k. mckeown, d. kaufman, and d. jordan,    facilitating physi-
cians    access to information via tailored text summarization,    in proceedings
of the amia annual symposium, pp. 226   300, 2005.

[55] g. erkan and d. radev,    the university of michigan at duc 2004,    in pro-

ceedings of the document understanding conference, 2004.

[56] g. erkan and d. r. radev,    lexrank: graph-based centrality as salience in

text summarization,    journal of arti   cial intelligence research, 2004.

[57] d. feng and e. hovy,    handling biographical questions with implicature,    in
proceedings of the conference on human language technology and empirical
methods in natural language processing, pp. 596   603, 2005.

[58] e. filatova and v. hatzivassiloglou,    a formal model for information selec-
tion in multi-sentence text extraction,    in proceedings of the international
conference on computational linguistic, pp. 397   403, 2004.

[59] k. filippova and m. strube,    sentence fusion via dependency graph com-
pression,    in proceedings of the conference on empirical methods in natural
language processing, pp. 177   185, 2008.

[60] m. fuentes, e. alfonseca, and h. rodr    guez,    support vector machines for
query-focused summarization trained and evaluated on pyramid data,    in
proceedings of the annual meeting of the association for computational lin-
guistics, companion volume: proceedings of the demo and poster sessions,
pp. 57   60, 2007.

[61] p. fung and g. ngai,    one story, one    ow: hidden markov story models for
multilingual multidocument summarization,    acm transactions on speech
and language processing, vol. 3, no. 2, pp. 1   16, 2006.

[62] s. furui, m. hirohata, y. shinnaka, and k. iwano,    sentence extraction-based
automatic speech summarization and evaluation techniques,    in proceedings
of the symposium on large-scale knowledge resources, pp. 33   38, 2005.

[63] m. galley,    a skip-chain conditional random    eld for ranking meeting utter-
ances by importance,    in proceedings of the conference on empirical methods
in natural language processing, pp. 364   372, 2006.

[64] m. galley and k. mckeown,    improving id51 in lexical
chaining,    in proceedings of the international joint conference on arti   cial
intelligence, pp. 1486   1488, 2003.

[65] m. galley and k. mckeown,    lexicalized markov grammars for sentence
compression,    in human language technologies: the conference of the

references

221

north american chapter of the association for computational linguistics,
pp. 180   187, 2007.

[66] m. galley, k. mckeown, j. hirschberg, and e. shriberg,    identifying agree-
ment and disagreement in conversational speech: use of id110s to
model pragmatic dependencies,    in proceedings of the annual meeting of the
association for computational linguistics, pp. 669   676, 2004.

[67] d. gillick, k. riedhammer, b. favre, and d. hakkani-tur,    a global
optimization framework for meeting summarization,    in proceedings of the
ieee international conference on acoustics, speech and signal processing,
pp. 4769   4772, 2009.

[68] j. glass, t. hazen, s. cyphers, i. malioutov, d. huynh, and r. barzilay,
   recent progress in the mit spoken lecture processing project,    in proceed-
ings of the annual conference of the international speech communication
association, pp. 2553   2556, 2007.

[69] y. gong and x. liu,    generic text summarization using relevance measure
and latent semantic analysis,    in proceedings of the annual international acm
sigir conference on research and development in information retrieval,
pp. 19   25, 2001.

[70] s. gupta, a. nenkova, and d. jurafsky,    measuring importance and query
relevance in topic-focused id57,    in proceedings of
the annual meeting of the association for computational linguistics, demo
and poster sessions, pp. 193   196, 2007.

[71] i. gurevych and t. nahnsen,    adapting lexical chaining to summarize conver-
sational dialogues,    in proceedings of the recent advances in natural language
processing conference, pp. 287   300, 2005.

[72] i. gurevych and m. strube,    semantic similarity applied to spoken dialogue
summarization,    in proceedings of the international conference on computa-
tional linguistic, pp. 764   770, 2004.

[73] b. hachey, g. murray, and d. reitter,    id84 aids term
co-occurrence based id57,    in sumqa    06: proceed-
ings of the workshop on task-focused summarization and question answer-
ing, pp. 1   7, 2006.

[74] d. hakkani-tur and g. tur,    statistical sentence extraction for information
distillation,    in proceedings of the ieee international conference on acous-
tics, speech and signal processing, vol. 4, pp. iv   1    iv   4, 2007.

[75] d. harman and p. over,    the e   ects of human variation in duc summariza-
tion evaluation,    in proceedings of acl text summarization branches out
workshop, pp. 10   17, 2004.

[76] v. hatzivassiloglou, j. l. klavans, m. l. holcombe, r. barzilay, m. yen kan,
and k. r. mckeown,    simfinder: a    exible id91 tool for summariza-
tion,    in proceedings of the naacl workshop on id54,
pp. 41   49, 2001.

[77] m. hirohata, y. shinnaka, k. iwano, and s. furui,    sentence-extractive auto-
matic speech summarization and evaluation techniques,    speech communica-
tion, vol. 48, no. 9, pp. 1151   1161, 2006.

222 references

[78] c. hori and s. furui,    speech summarization: an approach through word
extraction and a method for evaluation,    ieice transactions on information
and systems, vol. 87, pp. 15   25, 2004.

[79] c. hori, s. furui, r. malkin, h. yu, and a. waibel,    automatic speech sum-
marization applied to english broadcast news speech,    in proceedings of the
ieee international conference on acoustics, speech and signal processing,
pp. 1   9, 2002.

[80] c. hori, t. hori, and s. furui,    evaluation methods for automatic speech
summarization,    in proceedings of the european conference on speech com-
munication and technology, pp. 2825   2828, 2003.

[81] e. hovy and c.-y. lin,    automated text summarization in summarist,   

in advances in automatic text summarization, pp. 82   94, 1999.

[82] g. hripcsak, j. cimino, and s. sengupta,    webcis: large scale deployment of
a web-based clinical information system,    in proceedings of the amia annual
symposium, pp. 804   808, 1999.

[83] m. hu, a. sun, and e.-p. lim,    comments-oriented blog summarization by
sentence extraction,    in proceedings of the acm conference on information
and knowledge management, pp. 901   904, 2007.

[84] d. ji and y. nie,    sentence ordering based on cluster adjacency in multi-
document summarization,    in proceedings of the international joint confer-
ence on natural language processing, pp. 745   750, 2008.

[85] h. jing, r. barzilay, k. mckeown, and m. elhadad,    summarization evalua-
tion methods: experiments and analysis,    in aaai symposium on intelligent
summarization, pp. 51   59, 1998.

[86] h. jing and k. mckeown,    the decomposition of human-written summary
sentences,    in proceedings of the annual international acm sigir confer-
ence on research and development in information retrieval, pp. 129   136,
1999.

[87] h. jing,    sentence reduction for automatic text summarization,    in proceed-
ings of the conference on applied natural language processing, pp. 310   315,
2000.

[88] h. jing,    using hidden markov modeling to decompose human-written sum-

maries,    computational linguistics, vol. 28, no. 4, pp. 527   543, 2002.

[89] h. jing and k. r. mckeown,    cut and paste based text summarization,    in
proceedings of the north american chapter of the association for computa-
tional linguistics conference, pp. 178   185, 2000.

[90] h. jing, cut-and-paste text summarization. phd thesis, columbia university,

2001.

[91] m. johnson and e. charniak,    a tag-based noisy-channel model of speech
repairs,    in proceedings of the annual meeting of the association for compu-
tational linguistics, pp. 33   39, 2004.

[92] m.-y. kan,    combining visual layout and lexical cohesion features for text

segmentation,    tech. rep. cucs-002-01, columbia university, 2001.

[93] t. kikuchi, s. furui, and c. hori,    automatic speech summarization based on
sentence extraction and compaction,    in proceedings of the ieee international
conference on acoustics, speech and signal processing, pp. 384   387, 2003.

references

223

[94] k. knight and d. marcu,    summarization beyond sentence extraction:
a probabilistic approach to sentence compression,    artiitial intelligence,
vol. 139, no. 1, pp. 91   107, 2002.

[95] k. koumpis and s. renals,    id54 of voicemail messages
using lexical and prosodic features,    acm transactions on speech and lan-
guage processing, vol. 2, no. 1, pp. 1   24, 2005.

[96] e. krahmer, e. marsi, and p. van pelt,    query-based sentence fusion is better
de   ned and leads to more preferred results than generic sentence fusion,   
in proceedings of the annual meeting of the association for computational
linguistics, pp. 193   196, 2008.

[97] j. kupiec, j. pedersen, and f. chen,    a trainable document summarizer,    in
proceedings of the annual international acm sigir conference on research
and development in information retrieval, pp. 68   73, 1995.

[98] f. lacatusu, a. hickl, s. harabagiu, and l. nezda,    lite gistexter at
duc2004,    in proceedings of the document understanding conference, 2004.
[99] d. lam, s. l. rohall, c. schmandt, and m. k. stern,    exploiting e-mail
structure to improve summarization,    in proceedings of the acm conference
on computer supported cooperative work, 2002.

[100] a. m. lam-adesina and g. j. f. jones,    applying summarization techniques
for term selection in relevance feedback,    in proceedings of the annual interna-
tional acm sigir conference on research and development in information
retrieval, pp. 1   9, 2001.

[101] m. lapata and r. barzilay,    automatic evaluation of text coherence: models
and representations,    in proceedings of the international joint conference on
arti   cial intelligence, pp. 1085   1090, 2005.

[102] k. lerman, s. blair-goldensohn, and r. mcdonald,    sentiment summa-
rization: evaluating and learning user preferences,    in proceedings of the
conference of the european chapter of the association for computational
linguistics, pp. 514   522, 2009.

[103] j. leskovec, n. milic-frayling, and m. grobelnik,    impact of linguistic analysis
on the semantic graph coverage and learning of document extracts,    in pro-
ceedings of the national conference on arti   cial intelligence, pp. 1069   1074,
2005.

[104] c. lin and e. hovy,    from single to id57: a pro-
totype system and its evaluation,    in proceedings of the annual meeting of
the association for computational linguistics, pp. 457   464, 2002.

[105] c.-y. lin,    id8: a package for automatic evaluation of summaries,    in
proceedings of acl text summarization branches out workshop, pp. 74   81,
2004.

[106] c.-y. lin and e. hovy,    the automated acquisition of topic signatures for
text summarization,    in proceedings of the international conference on com-
putational linguistic, pp. 495   501, 2000.

[107] c.-y. lin and e. hovy,    automatic evaluation of summaries using id165 co-
occurance statistics,    in human language technology conference of the north
american chapter of the association for computational linguistics, 2003.

224 references

[108] y. liu, e. shriberg, a. stolcke, d. hillard, m. ostendorf, and m. harper,
   enriching id103 with automatic detection of sentence bound-
aries and dis   uencies,    ieee transactions on audio, speech and language
processing, vol. 14, pp. 1526   1540, 2006.

[109] y. liu and s. xie,    impact of automatic sentence segmentation on meet-
ing summarization,    in proceedings of the ieee international conference on
acoustics, speech and signal processing, pp. 5009   5012, 2008.

[110] a. louis, a. joshi, and a. nenkova,    discourse indicators for content selection
in summarization,    in proceedings of the annual meeting of the special interest
group on discourse and dialogue, pp. 147   156, 2010.

[111] h. p. luhn,    the automatic creation of literature abstracts,    ibm journal of

research and development, vol. 2, no. 2, pp. 159   165, 1958.

[112] m. mana-l  opez, m. d. buenaga, and j. m. g  omez-hidalgo,    multidocument
summarization: an added value to id91 in interactive retrieval,    acm
transactions on informations systems, vol. 22, no. 2, pp. 215   241, 2004.

[113] i. mani, g. klein, d. house, l. hirschman, t. firmin, and b. sundheim,
   summac: a text summarization evaluation,    natural language engineer-
ing, vol. 8, no. 1, pp. 43   68, 2002.

[114] i. mani, id54. john benjamins, 2001.
[115] i. mani and e. bloedorn,    summarizing similarities and di   erences among
related documents,    information retrieval, vol. 1, no. 1-2, pp. 35   67, april
1999.

[116] i. mani, b. gates, and e. bloedorn,    improving summaries by revising them,   
in proceedings of the annual meeting of the association for computational
linguistics, pp. 558   565, 1999.

[117] w. mann and s. thompson,    rhetorical structure theory: towards a func-

tional theory of text organization,    text, vol. 8, pp. 243   281, 1988.

[118] c. d. manning and h. schutze, foundations of natural language processing.

mit press, 1999.

[119] d. marcu,    from discourse structure to text summaries,    in proceedings of

acl/eacl 1997 summarization workshop, pp. 82   88, 1997.

[120] d. marcu,    to build text summaries of high quality, nuclearity is not su   -
cient,    in working notes of the aaai-98 spring symposium on intelligent
text summarization, pp. 1   8, 1998.

[121] d. marcu,    the automatic construction of large-scale corpora for summariza-
tion research,    in proceedings of the annual international acm sigir con-
ference on research and development in information retrieval, pp. 137   144,
1999.

[122] d. marcu, the theory and practice of discourse and summarization. the

mit press, 2000.

[123] e. marsi and e. krahmer,    explorations in sentence fusion,    in proceedings of
the european workshop on id86 2005, pp. 109   117,
2005.

[124] s. maskey and j. hirschberg,    summarizing speech without text using hid-
den markov models,    in human language technology conference of the north
american chapter of the association for computational linguistics, compan-
ion volume: short papers, pp. 89   92, 2006.

references

225

[125] s. maskey, a. rosenberg, and j. hirschberg,    intonational phrases for speech
summarization,    in proceedings of the annual conference of the international
speech communication association, pp. 2430   2433, 2008.

[126] r. mcdonald,    discriminative sentence compression with soft syntactic evi-
dence,    in proceedings of the conference of the european chapter of the asso-
ciation for computational linguistics, pp. 297   304, 2006.

[127] r. mcdonald,    a study of global id136 algorithms in multi-document
summarization,    in proceedings of the european conference on ir research,
pp. 557   564, 2007.

[128] k. mckeown, r. barzilay, d. evans, v. hatzivassiloglou, b. schi   man, and
s. teufel,    columbia id57: approach and evalua-
tion,    in proceedings of the document understanding conference, 2001.

[129] k. mckeown, s.-f. chang, j. cimino, s. feiner, c. friedman, l. gra-
vano, v. hatzivassiloglou, s. johnson, d. jordan, j. klavans, a. kushniruk,
v. patel, and s. teufel,    persival, a system for personalized search and
summarization over multimedia healthcare information,    in proceedings of the
acm/ieee-cs joint conference on digital libraries, pp. 331   340, 2001.

[130] k. mckeown, r. barzilay, d. evans, v. hatzivassiloglou, j. klavans,
a. nenkova, c. sable, b. schi   man, and s. sigelman,    tracking and sum-
marizing news on a daily basis with columbia   s newsblaster,    in proceedings
of the international conference on human language technology research,
2002.

[131] k. mckeown, r. j. passonneau, d. k. elson, a. nenkova, and j. hirschberg,
   do summaries help? a task-based evaluation of multi-document summariza-
tion,    in proceedings of the annual international acm sigir conference on
research and development in information retrieval, pp. 210   217, 2005.

[132] k. mckeown, l. shrestha, and o. rambow,    using question-answer pairs in
extractive summarization of email conversations,    in proceedings of the inter-
national conference on computational linguistics and intelligent text pro-
cessing, pp. 542   550, 2007.

[133] k. r. mckeown, j. l. klavans, v. hatzivassiloglou, r. barzilay, and e. eskin,
   towards multidocument summarization by reformulation: progress and
prospects,    in proceedings of the national conference on arti   cial intelli-
gence, pp. 453   460, 1999.

[134] q. mei and c. zhai,    generating impact-based summaries for scienti   c liter-
ature,    in proceedings of the annual meeting of the association for compu-
tational linguistics, pp. 816   824, 2008.

[135] r. mihalcea and p. tarau,    textrank: bringing order into texts,    in proceed-
ings of the conference on empirical methods in natural language processing,
pp. 404   411, 2004.

[136] r. mihalcea and p. tarau,    an algorithm for language independent single and
multiple document summarization,    in proceedings of the international joint
conference on natural language processing, pp. 19   24, 2005.

[137] g. miller, r. beckwith, c. fellbaum, d. gross, and k. j. miller,    introduction
to id138: an on-line lexical database,    international journal of lexicog-
raphy (special issue), vol. 3, no. 4, pp. 235   312, 1990.

226 references

[138] t. miller and w. schuler,    a syntactic time-series model for parsing    uent
and dis   uent speech,    in proceedings of the international conference on com-
putational linguistic, pp. 569   576, 2008.

[139] j. mrozinski, e. w. d. whittaker, p. chatain, and s. furui,    automatic sen-
tence segmentation of speech for id54,    in proceedings of
the ieee international conference on acoustics, speech and signal process-
ing, pp. 981   984, 2006.

[140] h. murakoshi, a. shimazu, and k. ochimizu,    construction of delibera-
tion structure in email conversation,    in proceedings of the conference of the
paci   c association for computational linguistics, pp. 570   577, 2004.

[141] s. muresan, e. tzoukermann, and j. l. klavans,    combining linguistic and
machine learning techniques for email summarization,    in proceedings of the
workshop on computational natural language learning, pp. 1   8, 2001.

[142] g. murray, s. renals, and j. carletta,    extractive summarization of meeting
recordings,    in proceedings of 9th european conference on speech communi-
cation and technology, pp. 593   596, 2005.

[143] g. murray, s. renals, j. carletta, and j. moore,    evaluating automatic sum-
maries of meeting recordings,    in proceedings of the acl workshop on eval-
uation measures for mt/summarization, 2005.

[144] g. murray and s. renals,    term-weighting for summarization of multi-party
spoken dialogues,    in proceedings of the international workshop on machine
learning for multimodal interaction, vol. 4892, pp. 155   166, 2007.

[145] h. nanba and m. okumura,    towards multi-paper summarization using ref-
erence information,    in proceedings of the international joint conference on
arti   cial intelligence, pp. 926   931, 1999.

[146] h. nanba and m. okumura,    producing more readable extracts by revising
them,    in proceedings of the international conference on computational lin-
guistic, pp. 1071   1075, 2000.

[147] a. nenkova and k. mckeown,    references to named entities: a corpus study,   
in human language technology conference of the north american chapter
of the association for computational linguistics, pp. 70   72, 2003.

[148] a. nenkova,    automatic text summarization of newswire: lessons learned from
the document understanding conference,    in proceedings of the national con-
ference on arti   cial intelligence, pp. 1436   1441, 2005.

[149] a. nenkova,    entity-driven rewrite for id57,    in
proceedings of the international joint conference on natural language pro-
cessing, 2008.

[150] a. nenkova, understanding the process of id57:
content selection, rewrite and evaluation. phd thesis, columbia university,
january 2006.

[151] a. nenkova and a. bagga,    facilitating email thread access by extractive sum-
mary generation,    in proceedings of the recent advances in natural language
processing conference, 2003.

[152] a. nenkova and r. passonneau,    evaluating content selection in summariza-
tion: the pyramid method,    in human language technology conference of
the north american chapter of the association for computational linguistics,
pp. 145   152, 2004.

references

227

[153] a. nenkova, r. passonneau, and k. mckeown,    the pyramid method: incor-
porating human content selection variation in summarization evaluation,   
acm transactions on speech and language processing, vol. 4, no. 2, 2007.

[154] a. nenkova, a. siddharthan, and k. mckeown,    automatically learning cog-
nitive status for id57 of newswire,    in proceedings
of the conference on human language technology and empirical methods in
natural language processing, pp. 241   248, 2005.

[155] a. nenkova, l. vanderwende, and k. mckeown,    a compositional context
sensitive multi-document summarizer: exploring the factors that in   uence
summarization,    in proceedings of the annual international acm sigir con-
ference on research and development in information retrieval, pp. 573   580,
2006.

[156] p. s. newman and j. c. blitzer,    summarizing archived discussions: a begin-
ning,    in proceedings of the international conference on intelligent user inter-
faces, pp. 273   276, 2003.

[157] m. l. nguyen, a. shmazu, s. horiguchi, t. b. ho, and m. fukushi,    proba-
bilistic sentence reduction using support vector machines,    in proceedings of
the international conference on computational linguistic, pp. 743   49, 2004.
[158] k. ohtake, k. yamamoto, y. toma, s. sado, s. masuyama, and s. nakagawa,
   newscast speech summarization via sentence shortening based on prosodic
features,    in proceedings of isca and ieee workshop on spontaneous speech
processing and recognition, pp. 247   254, 2003.

[159] k. ono, k. sumita, and s. miike,    abstract generation based on rhetorical
structure extraction,    in proceedings of the international conference on com-
putational linguistic, pp. 344   348, 1994.

[160] m. osborne,    using maximum id178 for sentence extraction,    in proceedings

of the acl workshop on id54, pp. 1   8, 2002.

[161] j. otterbacher, g. erkan, and d. radev,    using id93 for question-
focused sentence retrieval,    in proceedings of the conference on human lan-
guage technology and empirical methods in natural language processing,
pp. 915   922, 2005.

[162] j. otterbacher, d. radev, and a. luo,    revisions that improve cohesion in
multi-document summaries: a preliminary study,    in proceedings of the work-
shop on id54, pp. 2   7, 2002.

[163] p. over, h. dang, and d. harman,    duc in context,    information processing

and managemant, vol. 43, no. 6, pp. 1506   1520, 2007.

[164] c. d. paice,    the automatic generation of literature abstracts: an approach
based on the identi   cation of self-indicating phrases,    in proceedings of the
annual international acm sigir conference on research and development
in information retrieval, pp. 172   191, 1981.

[165] c. d. paice,    constructing literature abstracts by computer: techniques
and prospects,    information processing and management, vol. 26, no. 1,
pp. 171   186, 1990.

[166] k. papineni, s. roukos, t. ward, and w.-j. zhu,    id7: a method for auto-
matic evaluation of machine translation,    in proceedings of the annual meeting
of the association for computational linguistics, pp. 311   318, 2002.

228 references

[167] f. peng, r. weischedel, a. licuanan, and j. xu,    combining deep linguis-
tics analysis and surface pattern learning: a hybrid approach to chinese def-
initional id53,    in proceedings of the conference on human
language technology and empirical methods in natural language processing,
pp. 307   314, 2005.

[168] g. penn and x. zhu,    a critical reassessment of evaluation baselines for speech
summarization,    in proceedings of the annual meeting of the association for
computational linguistics, pp. 470   478, 2008.

[169] v. qazvinian and d. r. radev,    scienti   c paper summarization using cita-
tion summary networks,    in proceedings of the international conference on
computational linguistic, pp. 689   696, 2008.

[170] d. radev and k. mckeown,    generating natural

language summaries
from multiple on-line sources,    computational linguistics, vol. 24, no. 3,
pp. 469   500, 1998.

[171] d. radev, j. otterbacher, a. winkel, and s. blair-goldensohn,    news-
inessence: summarizing online news topics,    communications of the acm,
vol. 48, no. 10, pp. 95   98, 2005.

[172] d. radev and d. tam,    single-document and multi-document summary eval-
uation via relative utility,    in proceedings of the acm conference on infor-
mation and knowledge management, pp. 508   511, 2003.

[173] d. r. radev, s. blair-goldensohn, z. zhang, and r. s. raghavan,    news-
inessence: a system for domain-independent, real-time news id91 and
id57,    in proceedings of the international confer-
ence on human language technology research, pp. 1   4, 2001.

[174] d. r. radev, h. jing, and m. budzikowska,    centroid-based summarization
of multiple documents: sentence extraction, utility-based evaluation, and user
studies,    in proceedings of the naacl-anlp workshop on automatic sum-
marization, pp. 21   30, 2000.

[175] d. r. radev and k. r. mckeown,    building a generation knowledge source
using internet-accessible newswire,    in proceedings of the conference on
applied natural language processing, pp. 221   228, 1997.

[176] d. r. radev, s. teufel, h. saggion, w. lam, j. blitzer, h. qi, a. c   elebi,
d. liu, and e. drabek,    evaluation challenges in large-scale document sum-
marization: the mead project,    in proceedings of the annual meeting of the
association for computational linguistics, pp. 375   382, 2003.

[177] o. rambow, l. shrestha, j. chen, and c. lauridsen,    summarizing email
threads,    in human language technology conference of the north american
chapter of the association for computational linguistics, 2004.

[178] g. j. rath, a. resnick, and r. savage,    the formation of abstracts by the
selection of sentences: part 1: sentence selection by man and machines,    amer-
ican documentation, vol. 2, no. 12, pp. 139   208, 1961.

[179] k. riedhammer, d. gillick, b. favre, and d. hakkani-tur,    packing the meet-
ing summarization knapsack,    in proceedings of the annual conference of the
international speech communication association, pp. 2434   2437, 2008.

[180] s. riezler, t. h. king, r. crouch, and a. zaenen,    statistical sentence con-
densation using ambiguity packing and stochastic disambiguation methods for

references

229

lexical-functional grammar,    in human language technology conference of
the north american chapter of the association for computational linguistics,
pp. 118   125, 2003.

[181] d. g. roussinov and h. chen,    information navigation on the web by cluster-
ing and summarizing query results,    information processing and management,
vol. 37, no. 6, pp. 789   816, 2001.

[182] t. sakai and k. sparck jones,    generic summaries for indexing in informa-
tion retrieval,    in proceedings of the annual international acm sigir con-
ference on research and development in information retrieval, pp. 190   198,
2001.

[183] g. salton, a. singhal, m. mitra, and c. buckley,    automatic text structuring
and summarization,    information processing and management, vol. 33, no. 2,
pp. 193   208, 1997.

[184] g. salton and c. buckley,    term-weighting approaches in automatic text
retrieval,    information processing and management, vol. 24, pp. 513   523,
1988.

[185] b. schi   man, i. mani, and k. concepcion,    producing biographical sum-
maries: combining linguistic knowledge with corpus statistics,    in proceed-
ings of the annual meeting of the association for computational linguistics,
pp. 458   465, 2001.

[186] b. schi   man, a. nenkova, and k. mckeown,    experiments in multidocument
summarization,    in proceedings of the international conference on human
language technology research, pp. 52   58, 2002.

[187] l. shrestha and k. mckeown,    detection of question-answer pairs in email
conversations,    in proceedings of the international conference on computa-
tional linguistic, pp. 889   895, 2004.

[188] e. shriberg, a. stolcke, d. hakkani-t  ur, and g. t  ur,    id144-based auto-
matic segmentation of speech into sentences and topics,    speech communica-
tion, vol. 32, no. 1-2, pp. 127   154, 2000.

[189] a. siddharthan and k. mckeown,    improving multilingual summarization:
using redundancy in the input to correct mt errors,    in proceedings of the
conference on human language technology and empirical methods in natural
language processing, pp. 33   40, 2005.

[190] a. siddharthan, a. nenkova, and k. mckeown,    syntactic simpli   ca-
tion for improving content selection in id57,    in
proceedings of the international conference on computational linguistic,
pp. 896   902, 2004.

[191] a. siddharthan and s. teufel,    whose idea was this, and why does it matter?
attributing scienti   c work to citations,    in human language technology con-
ference of the north american chapter of the association for computational
linguistics, pp. 316   323, 2007.

[192] h. g. silber and k. f. mccoy,    e   ciently computed lexical chains as an inter-
mediate representation for automatic text summarization,    computational
linguistics, vol. 28, no. 4, pp. 487   496, 2002.

[193] k. sparck jones,    a statistical interpretation of term speci   city and its appli-

cation in retrieval,    journal of documentation, vol. 28, pp. 11   21, 1972.

230 references

[194] k. sparck jones,    automatic summarizing:

factors and directions,    in

advances in automatic text summarization, pp. 1   12, mit press, 1998.

[195] j. steinberger, m. poesio, m. a. kabadjov, and k. jeek,    two uses of
id2 in summarization,    information processing and manage-
ment, vol. 43, no. 6, pp. 1663   1680, 2007.

[196] a. stolcke and e. shriberg,    statistical id38 for speech dis   u-
encies,    in proceedings of the ieee international conference on acoustics,
speech and signal processing, pp. 405   408, 1996.

[197] j.-t. sun, d. shen, h.-j. zeng, q. yang, y. lu, and z. chen,    web-page
summarization using clickthrough data,    in proceedings of the annual inter-
national acm sigir conference on research and development in informa-
tion retrieval, pp. 194   201, 2005.

[198] w. tau yih, j. goodman, l. vanderwende, and h. suzuki,    multi-document
summarization by maximizing informative content-words,    in proceedings of
the international joint conference on arti   cial intelligence, pp. 1776   1782,
2007.

[199] s. teufel,    task-based evaluation of summary quality: describing relation-
ships between scienti   c papers,    in proceedings of the naacl workshop on
id54, pp. 12   21, 2001.

[200] s. teufel and m. moens,    summarizing scienti   c articles: experiments with
relevance and rhetorical status,    computational linguisics., vol. 28, no. 4,
pp. 409   445, 2002.

[201] s. teufel and h. van halteren,    evaluating information content by factoid
analysis: human annotation and stability,    in proceedings of the conference
on empirical methods in natural language processing, 2004.

[202] d. r. timothy, t. allison, s. blair-goldensohn, j. blitzer, a. elebi, s. dim-
itrov, e. drabek, a. hakim, w. lam, d. liu, j. otterbacher, h. qi,
h. saggion, s. teufel, a. winkel, and z. zhang,    mead     a platform for
multidocument multilingual text summarization,    in proceedings of the inter-
national conference on language resources and evaluation, 2004.

[203] a. tombros and m. sanderson,    advantages of query biased summaries in
information retrieval,    in proceedings of the annual international acm sigir
conference on research and development in information retrieval, pp. 2   10,
1998.

[204] s. tucker, n. kyprianou, and s. whittaker,    time-compressing speech: asr
transcripts are an e   ective way to support gist extraction,    in proceedings of
the international workshop on machine learning for multimodal interaction,
pp. 226   235, 2008.

[205] s. tucker and s. whittaker,    temporal compression of speech: an evalua-
tion,    ieee transactions on audio, speech and language processing, vol. 16,
pp. 790   796, 2008.

[206] j. turner and e. charniak,    supervised and unsupervised learning for sen-
tence compression,    in proceedings of the annual meeting of the association
for computational linguistics, (ann arbor, mi.), pp. 290   297, june 2005.

[207] a. turpin, y. tsegay, d. hawking, and h. e. williams,    fast generation of
result snippets in web search,    in proceedings of the annual international

references

231

acm sigir conference on research and development
retrieval, pp. 127   134, 2007.

in information

[208] e. tzoukermann, s. muresan, and j. l. klavans,    gist-it: summarizing
email using linguistic knowledge and machine learning,    in proceedings of
the workshop on human language technology and knowledge management,
pp. 1   8, 2001.

[209] j. ulrich, g. murray, and g. carenini,    a publicly available annotated corpus
for supervised email summarization,    in proceedings of the aaai email
workshop, pp. 77   87, 2008.

[210] umls,    umls knowledge sources,    national library of medicine, bethesda,

maryland, 9th edition, 1998.

[211] h. van halteren and s. teufel,    examining the consensus between human
summaries: initial experiments with factoid analysis,    in proceedings of the
hlt-naacl workshop on id54, 2003.

[212] l. vanderwende, h. suzuki, c. brockett, and a. nenkova,    beyond sum-
basic: task-focused summarization with sentence simpli   cation and lexical
expansion,    information processing and managment, vol. 43, pp. 1606   1618,
2007.

[213] r. varadarajan and v. hristidis,    a system for query-speci   c document
summarization,    in proceedings of the acm conference on information and
knowledge management, 2006.

[214] a. waibel, m. bett, and m. finke,    meeting browser: tracking and summa-
rizing meetings,    in proceedings of the darpa broadcast news workshop,
pp. 281   286, 1998.

[215] s. wan and k. mckeown,    generating state-of-a   airs summaries of ongoing
email thread discussions,    in proceedings of the international conference on
computational linguistic, 2004.

[216] x. wan and j. yang,    improved a   nity graph based multi-document summa-
rization,    in human language technology conference of the north american
chapter of the association for computational linguistics, companion vol-
ume: short papers, pp. 181   184, 2006.

[217] r. weischedel, j. xu, and a. licuanan,    a hybrid approach to answering bio-
graphical questions,    in new directions in id53, (m. maybury,
ed.), pp. 59   70, 2004.

[218] m. j. witbrock and v. o. mittal,    ultra-summarization (poster abstract):
a statistical approach to generating highly condensed non-extractive
summaries,    in proceedings of the annual international acm sigir con-
ference on research and development in information retrieval, pp. 315   316,
1999.

[219] f. wolf and e. gibson,    paragraph-, word-, and coherence-based approaches
to sentence ranking: a comparison of algorithm and human performance,   
in proceedings of the annual meeting of the association for computational
linguistics, pp. 383   390, 2004.

[220] k.-f. wong and w. wu, mingli sand li,    extractive summarization using
supervised and semi-supervised learning,    in proceedings of the international
conference on computational linguistic, pp. 985   992, 2008.

232 references

[221] s. xie and y. liu,    using corpus and knowledge-based similarity measure in
maximum marginal relevance for meeting summarization,    in proceedings of
the ieee international conference on acoustics, speech and signal process-
ing, pp. 4985   4988, 2008.

[222] e. yamangil and s. m. shieber,    bayesian synchronous tree-substitution
grammar induction and its application to sentence compression,    in proceed-
ings of the annual meeting of the association for computational linguistics,
pp. 937   947, 2010.

[223] j. yang, a. cohen, and w. hersh,    id54 of mouse gene
information by id91 and sentence extraction from medline abstracts,   
in proceedings of the amia annual symposium, pp. 831   835, 2007.

[224] s. ye, t.-s. chua, m.-y. kan, and l. qiu,    document concept lattice for text
understanding and summarization,    information processing and management,
vol. 43, no. 6, pp. 1643   1662, 2007.

[225] w. yih, j. goodman, l. vanderwende, and h. suzuki,    multi-document sum-
marization by maximizing informative content-words,    in proceedings of the
international joint conference on arti   cial intelligence, pp. 1776   1782, 2007.
[226] d. zajic, b. j. dorr, j. lin, and r. schwartz,    multi-candidate reduction: sen-
tence compression as a tool for document summarization tasks,    information
processing and management, vol. 43, no. 6, pp. 1549   1570, 2007.

[227] k. zechner,    summarization of spoken language - challenges, methods, and

prospects,    speech technology expert ezine, january 2002.

[228] k. zechner and a. lavie,    increasing the coherence of spoken dialogue sum-
maries by cross-speaker information linking,    in proceedings of the naacl
workshop on id54, pp. 22   31, 2001.

[229] k. zechner and a. waibel,    minimizing word error rate in textual summaries
of spoken language,    in proceedings of the north american chapter of the
association for computational linguistics conference, pp. 186   193, 2000.

[230] j. zhang, h. y. chan, and p. fung,    improving lecture speech summarization
using rhetorical information,    in proceedings of the ieee automatic speech
recognition and understanding workshop, pp. 195   200, 2007.

[231] j. zhang and p. fung,    speech summarization without lexical features for
mandarin broadcast news,    in human language technology conference of
the north american chapter of the association for computational linguistics;
companion volume, short papers, pp. 213   216, 2007.

[232] l. zhou and e. hovy,    a web-trained extraction summarization system,   
in proceedings of the conference of the north american chapter of the
association for computational linguistics on human language technology,
pp. 205   211, 2003.

[233] l. zhou and e. hovy,    on the summarization of dynamically introduced
information: online discussions and blogs,    in proceedings of aaai spring
symposium 2006, 2006.

[234] l. zhou, m. ticrea, and e. hovy,    multi-document biography summariza-
tion,    in proceedings of the conference on empirical methods in natural
language processing, pp. 434   441, 2004.

references

233

[235] x. zhu and g. penn,    evaluation of sentence selection for speech summariza-
tion,    in proceedings of the ranlp workshop on crossing barriers in text
summarization research, pp. 39   45, 2005.

[236] x. zhu and g. penn,    summarization of spontaneous conversations,    in pro-
ceedings of the annual conference of the international speech communication
association, pp. 1531   1534, 2006.

